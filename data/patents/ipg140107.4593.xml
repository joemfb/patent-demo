<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625681-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625681</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12217805</doc-number>
<date>20080709</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1018</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>409</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>217</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>37524029</main-classification>
<further-classification>37524027</further-classification>
</classification-national>
<invention-title id="d2e53">Rate-distortion cost reducing video encoding techniques</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2007/0058716</doc-number>
<kind>A1</kind>
<name>Blum</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524003</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2008/0247467</doc-number>
<kind>A1</kind>
<name>Rusanovskyy et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2010/0254448</doc-number>
<kind>A1</kind>
<name>Xu et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524002</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>EP</country>
<doc-number>1841230</doc-number>
<kind>A1</kind>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>JP</country>
<doc-number>2007-251881</doc-number>
<kind>A</kind>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>WO</country>
<doc-number>2006/108654</doc-number>
<kind>A2</kind>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>WO</country>
<doc-number>WO 2006108654</doc-number>
<kind>A2</kind>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-cpc-text>H04N 7/26</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>WO</country>
<doc-number>2007/111292</doc-number>
<kind>A1</kind>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>WO</country>
<doc-number>2008075247</doc-number>
<kind>A1</kind>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00010">
<othercit>S. Wittman &#x26; T. Wedi, &#x201c;Transmission of Post-Filter Hints for Video Coding Schemes&#x201d;, 1 IEEE Int'l Conf. on Image Processing 2007 (ICIP 2007) 81-84 (Oct. 2007).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>Office Action Received for Korean Patent Application No. 2009-0062562, mailed on Dec. 13, 2010, 3 pages of English Translation.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Vatis, Y. et al.,&#x201c;Coding of Coefficients of two-dimensional non-separable Adaptive Wiener Interpolation Filter&#x201d;, submitted to Visual Communications and Image Processing (VCIP) Jul. 2005, 9 Pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Chiu, Yi-Jen et al.,&#x201c;Adaptive (Wiener) Filtering for SVC Bit Depth Scalability&#x201d;, Document JVT-AA023, Apr. 2008, 14 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Wittmann, Steffen et al.,&#x201c;SEI message on post-filter hints&#x201d;, Document JVT-U035, Oct. 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Chiu, Yi-Jen et al., &#x201c;Adaptive (Wiener) Filter for Video Compression&#x201d;, ITU-T SC16/Q6, Geneva, Apr. 22-May 2, 2008, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Office Action Received for Chinese Patent Application No. 2200910152137.8, mailed on Jun. 2, 2011, 12 pages of Chinese Office Action including 7 pages of English Translation.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Office Action received for European Patent Application No. 09251758.0, mailed on Nov. 17, 2011, 9 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Wiegand et al., &#x201c;Rate-Constrained Coder Control and Comparison of Video Coding Standards&#x201d;, IEEE Transactions on Circuits and Systems for Video Technology, vol. 13, No. 7, Jul. 1, 2003, 16 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>&#x201c;Adaptive (Wiener) Filter for Video Compression&#x201d;, ITU-T SG16 Meeting, Apr. 22-May 2, 2008, Geneva, No. T05-SG16-C-0437, Apr. 14 2008, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>Office Action Received for Chinese Patent Application No. 200910152137.8, mailed on Nov. 8, 2011, 4 pages Chinese Office Action, 6 pages English Translation.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>European Search Report mailed Nov. 10, 2011 in EP 0925178.0, 4 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>&#x201c;Adaptive (Wiener) Filter for Video Compression&#x201d;, ITU-T SG16 Meeting, Jul. 16-18, 2008, Berlin Germany, Q.61 SG16, Jul. 11, 2008, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00023">
<othercit>Office Action Received for Korean Patent Application No. 2009-0062562, mailed on Jul. 22, 2011, 2 pages of English Translation only.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00024">
<othercit>Office Action received for European Application No. 09251758.0, mailed Jan. 17, 2013, 11 pages of Office Action.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>Office Action received for European Application No. 09251758.0, mailed Aug. 21, 2012, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Office Action Received in Chinese Patent Application No. 2 910152137,8, mailed on Apr. 25, 2012, 7 pages of Office Action, including 4 pages of English Translation.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>27</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>37524027</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524029</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100008417</doc-number>
<kind>A1</kind>
<date>20100114</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Xu</last-name>
<first-name>Lidong</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
<residence>
<country>CN</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Chiu</last-name>
<first-name>Yi-Jen</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Xu</last-name>
<first-name>Lidong</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Chiu</last-name>
<first-name>Yi-Jen</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Trop, Pruner &#x26; Hu, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Intel Corporation</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Czekaj</last-name>
<first-name>Dave</first-name>
<department>2487</department>
</primary-examiner>
<assistant-examiner>
<last-name>Werner</last-name>
<first-name>David N</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Techniques are described that can be used to determine parameters of an adaptive Wiener filter to apply to a video region. The following parameters of the Wiener filter may be adjusted: coefficients, coefficient quantization, filter type, filter size, prediction mode, entropy encoding, and number of filter tables. The parameters associated with the lowest rate distortion cost of the encoder are selected for transmission with the encoded video. If not using adaptive Wiener filtering results in a lowest rate distortion cost, then adaptive Wiener filtering is not used for the video region. If using adaptive Wiener filtering results in a lowest rate distortion cost, then the parameters applied by the adaptive Wiener filtering that result in the lowest rate distortion cost are communicated with the filtered video region.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="196.00mm" wi="165.78mm" file="US08625681-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="214.21mm" wi="176.70mm" file="US08625681-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="190.75mm" wi="132.84mm" file="US08625681-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="212.68mm" wi="145.03mm" file="US08625681-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="215.90mm" wi="167.47mm" file="US08625681-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="217.00mm" wi="123.02mm" orientation="landscape" file="US08625681-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD</heading>
<p id="p-0002" num="0001">The subject matter disclosed herein relates to generally to video encoders and decoders.</p>
<heading id="h-0002" level="1">RELATED ART</heading>
<p id="p-0003" num="0002">A video encoder compresses video information so that more information can be sent over a given bandwidth. The compressed signal may then be transmitted to a receiver that decodes or decompresses the signal prior to display.</p>
<p id="p-0004" num="0003">Conventional video encoding algorithms result in losses. That is, in the course of compressing the video information, some information may be lost, resulting in decreased picture quality. Ideally, the video quality is improved to the greatest possible extent and the compression is increased to the greatest possible extent. However, these two goals tend to conflict with one another.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0005" num="0004">Embodiments of the present invention are illustrated by way of example, and not by way of limitation, in the drawings and in which like reference numerals refer to similar elements.</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 1</figref> depicts an example encoder system in accordance with some embodiments of the present invention.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 2</figref> depicts an example embodiment of a quantizer, in accordance with an embodiment of the present invention.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 3</figref> depicts an example embodiment of a filter set selection logic, in accordance with an embodiment of the present invention.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 4</figref> depicts an example embodiment of a filter type selection logic, in accordance with an embodiment of the present invention.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 5</figref> depicts an example embodiment of a coefficient prediction mode selection logic, in accordance with an embodiment of the present invention.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 6</figref> depicts an entropy coder selection logic, in accordance with an embodiment of the present invention.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 7</figref> depicts an example flow diagram that can be used to determine filter parameters that result in a desirable rate distortion cost, in accordance with an embodiment of the present invention.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 8</figref> depicts a system, in accordance with an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0014" num="0013">Reference throughout this specification to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearances of the phrase &#x201c;in one embodiment&#x201d; or &#x201c;an embodiment&#x201d; in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in one or more embodiments.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> depicts an encoder system <b>100</b>, in accordance with an embodiment of the present invention. Encoder system <b>100</b> includes coefficient estimation logic <b>102</b>, quantizer <b>104</b>, global/local filter selection <b>106</b>, filter type selection logic <b>108</b>, filter coefficient prediction and entropy coder selection logic <b>110</b>, adaptive wiener filter <b>112</b>, and RD cost calculator <b>114</b>. In one embodiment, input pixels and reconstructed pixels (&#x201c;rec. pixels&#x201d;) from a video region may be provided to encoder system <b>100</b> from a video encoder described in U.S. patent application entitled &#x201c;IN-LOOP ADAPTIVE WIENER FILTER FOR VIDEO CODING AND DECODING,&#x201d; inventors Chiu and Xu, Ser. No. 12/082,182, filed Apr. 9, 2008 and &#x201c;ADAPTIVE FILTERING FOR BIT-DEPTH SCALABLE VIDEO CODEC,&#x201d; inventors Chiu and Xu, Ser. No. 12/082,561, filed Apr. 11, 2008 (collectively, hereafter &#x201c;References&#x201d;). More particularly, a video encoder loop such as that described with regard to FIG. 1 of U.S. patent application entitled &#x201c;IN-LOOP ADAPTIVE WIENER FILTER FOR VIDEO CODING AND DECODING,&#x201d; inventors Chiu and Xu, Ser. No. 12/082,182, filed Apr. 9, 2008, may provide input pixels and reconstructed pixels.</p>
<p id="p-0016" num="0015">Adaptive Wiener filter <b>112</b> may encode a video region according to parameters selected by each of coefficient estimation logic <b>102</b>, quantizer <b>104</b>, global/local filter selection logic <b>106</b>, filter type selection logic <b>108</b>, and filter coefficient prediction and entropy coder selection logic <b>110</b>. RD cost calculator <b>114</b> may determine the Rate-Distortion (RD) cost for applying adaptive Wiener filtering to the video region using the selected parameters. Moreover, RD cost calculator <b>114</b> determines the RD cost for when no adaptive Wiener filtering is applied. If RD cost calculator <b>114</b> determines that the lowest RD cost is associated with not using adaptive Wiener filtering, then the video region is transferred without applying adaptive Wiener filtering by encoder <b>100</b>. If RD cost calculator <b>114</b> determines that the lowest RD cost is associated with use of adaptive Wiener filtering, then the parameters associated with the lowest RD cost are transferred with the video encoded according to such parameters to a storage device or transmission media for decoding. The video region can be at a sequence level, group of picture (GOP) level, picture level, slice level, macroblock level, block level, or arbitrary picture regions.</p>
<p id="p-0017" num="0016">Coefficient estimation logic <b>102</b> may determine filter coefficients that adaptive Wiener filter <b>112</b> is to apply. One manner in which coefficient estimation logic <b>102</b> determines coefficients is described in the References. Coefficient estimation logic <b>102</b> may determine coefficients based on pixel intensities in a video region. Coefficient estimation logic <b>102</b> may determine a coefficient matrix that can be M by N in dimension. For example, the coefficient matrix size can be 3&#xd7;3, 5&#xd7;5, 7&#xd7;7, or 9&#xd7;9, or other sizes, but does not need to be symmetrical. Coefficient estimation logic outputs its floating point coefficients matrix to quantizer <b>104</b>.</p>
<p id="p-0018" num="0017">Quantizer <b>104</b> may determine fixed point coefficients by quantizing the floating point filter coefficients determined by coefficient estimation logic <b>102</b>. Various quantization steps can be used, such as a step of 8 bits, 10 bits, 12 bits, or other step values. Using a high quantization step can reduce the distortion, but may produce more bits and increase the bit rate used to transmit filter coefficients.</p>
<p id="p-0019" num="0018">Global/local filter selection logic <b>106</b> may select filtering of a picture and/or a region of a picture using one or more of a global filter table and one or more local filter table. Global/local filter selection logic <b>106</b> may use quantized coefficients from quantizer <b>104</b>. A global filter table may be produced from pixels from a picture. A local filter table may be produced from one or more pixels from a region of a picture. Using more local filter tables can reduce the distortion, but may increase the number of bits used for transmitting filter coefficients.</p>
<p id="p-0020" num="0019">Filter type selection logic <b>108</b> may select at least one of various Wiener filter types to apply, such as 2-D non-separable filter, 1-D separable filter, and/or symmetric filter.</p>
<p id="p-0021" num="0020">Filter coefficient prediction and entropy coder selection logic <b>110</b> may select one of various prediction and encoding modes to apply to the quantized coefficients, selected filter table, and filter type. Filter coefficients generally have spatial and temporal correlations. For filter coefficient prediction, filter coefficient prediction and entropy coder <b>110</b> may use at least one of spatial coefficient prediction, temporal coefficient prediction, spatial-temporal coefficient prediction, and direct mode (no coefficient prediction) to reduce the bitrate caused by transmitting filter coefficients.</p>
<p id="p-0022" num="0021">For entropy coding, filter coefficient prediction and entropy coder selection logic <b>110</b> may select one of Exp-Golomb code, fixed length code, and size-value code. Other and/or additional entropy coding modes can be applied. Determining a fixed length code may involve finding the Wiener filter coefficient with the largest absolute value (C), then using Ceil(log 2(C+1))+1 bits to encode all coefficients, encoding the number of Ceil(log 2(C+1))+1 using Exp-Golomb code, and then transmitting the codes to a decoder. Function Ceil may involve rounding to an upper integer.</p>
<p id="p-0023" num="0022">Determining a size-value code may involve the following. The following may be used to encode the size of a coefficient (i.e., number of bits in the coefficient): for each coefficient having an absolute value (C), coding its size to equal Ceil(log 2(C+1)) and using Exp-Golomb code. To encode a value of a size-value code, fixed-length coding is used. If the coefficient value is negative, then the coded value is (1&#x3c;&#x3c;Ceil(log 2(C+1)))&#x2212;C). If the coefficient value is not negative, then the coded value is the value of the coefficient.</p>
<p id="p-0024" num="0023">Each of coefficient estimation logic <b>102</b>, quantizer <b>104</b>, global/local filter selection <b>106</b>, filter type selection <b>108</b>, and filter coefficient prediction and entropy coder <b>110</b> may provide the selected parameters for a particular encoding of a video region to adaptive Wiener filter <b>112</b> and RD cost calculator <b>114</b>.</p>
<p id="p-0025" num="0024">Adaptive Wiener filter <b>112</b> may apply adaptive filtering on reconstructed pixels and output filtered pixels based on the parameters selected by logic <b>102</b>-<b>110</b>. A Wiener filter is a filter that may achieve the least mean square error among the source signal and the reconstructed signal modeled through the random noise. In one embodiment, adaptive Wiener filter <b>112</b> may filter reconstructed pixels by applying equation (1) below. One embodiment of adaptive Wiener filter <b>112</b> is described in the References. Adaptive Wiener filter <b>112</b> outputs filtered pixels, P&#x2032;<sub>x,y</sub>, to RD cost calculator <b>114</b>.</p>
<p id="p-0026" num="0025">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msubsup>
          <mi>P</mi>
          <mrow>
            <mi>x</mi>
            <mo>,</mo>
            <mi>y</mi>
          </mrow>
          <mi>&#x2032;</mi>
        </msubsup>
        <mo>=</mo>
        <mrow>
          <munderover>
            <mo>&#x2211;</mo>
            <mrow>
              <mi>j</mi>
              <mo>=</mo>
              <mn>0</mn>
            </mrow>
            <mrow>
              <mi>M</mi>
              <mo>-</mo>
              <mn>1</mn>
            </mrow>
          </munderover>
          <mo>&#x2062;</mo>
          <mrow>
            <munderover>
              <mo>&#x2211;</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>N</mi>
                <mo>-</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>&#x2062;</mo>
            <mrow>
              <msub>
                <mi>P</mi>
                <mrow>
                  <msup>
                    <mi>x</mi>
                    <mi>&#x2032;</mi>
                  </msup>
                  <mo>,</mo>
                  <msup>
                    <mi>y</mi>
                    <mi>&#x2032;</mi>
                  </msup>
                </mrow>
              </msub>
              <mo>&#x2062;</mo>
              <msub>
                <mi>C</mi>
                <mrow>
                  <mi>i</mi>
                  <mo>,</mo>
                  <mi>j</mi>
                </mrow>
              </msub>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where,
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0026">P<sub>x,y </sub>represents the reconstructed pixels (e.g., the deblocked pixels from the core encoding loop) and</li>
        <li id="ul0002-0002" num="0027">C<sub>i,j </sub>represents quantized coefficients from quantizer <b>104</b> obtained by minimizing the distortion between Q<sub>x,y </sub>and P&#x2032;<sub>x,y</sub>, where Q<sub>x,y </sub>represents the input pixels to encoder <b>100</b>.
<br/>
Adaptive Wiener filter <b>112</b> may reduce the distortion between P<sub>x,y </sub>and Q<sub>x,y </sub>in a manner described in the References. Adaptive filter <b>112</b> outputs encoded video using each parameter set for storage into memory or for transmission.
</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0027" num="0028">RD cost calculator <b>114</b> may determine the RD cost for every parameter permutation applied by adaptive Wiener filter <b>112</b> and may select the parameters that result in the lowest RD cost. For each parameter permutation, RD cost calculator <b>114</b> may determine the RD cost for each permutation from equation (2):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>J</i>(Pass)=<i>D</i>(Pass)+&#x3bb;<i>R</i>(Pass)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where,
</p>
<p id="p-0028" num="0029">R(Pass) is the bit rate of filter coefficients,</p>
<p id="p-0029" num="0030">D is a SSD is the Sum of Squared Difference, and</p>
<p id="p-0030" num="0031">&#x3bb; is a Lagrangian factor for pass decision.</p>
<p id="p-0031" num="0032">For example, let Pass<b>1</b> not use adaptive Wiener filter <b>112</b> and Pass<b>2</b> use adaptive Wiener filter <b>112</b>. Then, the following are the D and R representations:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>D</i>(Pass1)=<i>SSD</i>(<i>P</i><sub>x,y</sub><i>,Q</i><sub>x,y</sub>)<i>R</i>(Pass1)=0<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>D</i>(Pass2)=<i>SSD</i>(<i>P&#x2032;</i><sub>x,y</sub><i>,Q</i><sub>x,y</sub>)<i>R</i>(Pass2)=Bits(<i>C</i><sub>i,j</sub>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
RD cost calculator <b>114</b> determines whether use of adaptive Wiener filter <b>112</b> results in the lowest RD cost. If use of adaptive Wiener filter <b>112</b> does not result in the lowest RD cost, then the video region is transferred without encoding by adaptive Wiener filter <b>112</b>. If use of adaptive Wiener filter <b>112</b> results in the lowest RD cost, then RD cost calculator transfers the parameters applied by adaptive Wiener filter <b>112</b> that result in the lowest RD cost with the video region encoded according to such parameters. RD cost calculator <b>114</b> may encode the selected parameter set into a bit stream and transmit the bit stream to a storage or decoder.
</p>
<p id="p-0032" num="0033">The encoder of <figref idref="DRAWINGS">FIG. 1</figref> may be consistent with the H.264 (advanced video codec (AVC) and MPEG-4 Part 10), compression standard, for example. The H.264 standard has been prepared by the Joint Video Team (JVT), which includes ITU-T SG16 Q.6, also known as VCEG (Video Coding Expert Group), and of the ISO-IEC JTC1/SC29/WG11 (2003), known as MPEG (Motion Picture Expert Group). H.264 is designed for applications in the area of digital TV broadcast, direct broadcast satellite video, digital subscriber line video, interactive storage media, multimedia messaging, digital terrestrial TV broadcast, and remote video surveillance, to mention a few examples.</p>
<p id="p-0033" num="0034">While one embodiment may be consistent with H.264 video coding, the present invention is not so limited. Instead, embodiments may be used in a variety of video compression systems including MPEG-2 (ISO/IEC 13818-1 (2000) MPEG-2 available from International Organization for Standardization, Geneva, Switzerland) and VC1 (SMPTE 421M (2006) available from SMPTE White Plains, N.Y. 10601).</p>
<p id="p-0034" num="0035"><figref idref="DRAWINGS">FIG. 2</figref> depicts an example embodiment of a quantizer <b>200</b>, in accordance with an embodiment of the present invention, that can select a quantization step parameter. For example, quantizer <b>200</b> may select any quantization step among Q<b>0</b>, Q<b>1</b>, to Qn for application to coefficients from coefficient estimation logic <b>102</b>. Quantizer <b>200</b> may communicate the quantization step parameter to adaptive Wiener filter <b>112</b> and RD cost calculator <b>114</b>.</p>
<p id="p-0035" num="0036"><figref idref="DRAWINGS">FIG. 3</figref> depicts an example embodiment of a filter set selection logic <b>300</b>, in accordance with an embodiment of the present invention. For example, filter set selection logic <b>300</b> may select any filter table set among S<b>0</b> to Sn. A filter table set can be selected from among global and local filter tables. Filter set selection logic <b>300</b> may communicate the filter table set parameter to adaptive Wiener filter <b>112</b> and RD cost calculator <b>114</b>.</p>
<p id="p-0036" num="0037"><figref idref="DRAWINGS">FIG. 4</figref> depicts an example embodiment of a filter type selection logic <b>400</b>, in accordance with an embodiment of the present invention. For example, filter type selection logic <b>400</b> may select any filter type among T<b>0</b> to Tn. A filter type can be selected from among at least a 2-D non-separable filter, 1-D separable filter, non-symmetric filter, and/or symmetric filter. Filter type selection logic <b>400</b> may communicate the filter type parameter to adaptive Wiener filter <b>112</b> and RD cost calculator <b>114</b>.</p>
<p id="p-0037" num="0038"><figref idref="DRAWINGS">FIG. 5</figref> depicts an example embodiment of a coefficient prediction selection logic <b>500</b>, in accordance with an embodiment of the present invention. Coefficient prediction logic <b>500</b> may select one of direct mode (no coefficient prediction), spatial coefficient prediction, temporal coefficient prediction, and spatial-temporal coefficient prediction. Coefficient prediction selection logic <b>500</b> may transfer the selected coefficient prediction mode to adaptive Wiener filter <b>112</b> and RD cost calculator <b>114</b>.</p>
<p id="p-0038" num="0039"><figref idref="DRAWINGS">FIG. 6</figref> depicts an entropy coder <b>600</b>, in accordance with an embodiment of the present invention. Entropy coder <b>600</b> may select one of Exp-Golomb code, fixed length code, and size-value code to apply to the selected filter type, filter set, and quantized coefficients. Entropy coder <b>600</b> may transfer the selected entropy coding mode to adaptive Wiener filter <b>112</b> and RD cost calculator <b>114</b>.</p>
<p id="p-0039" num="0040"><figref idref="DRAWINGS">FIG. 7</figref> depicts an example flow diagram that can be used to determine encoder parameters that result in a desirable rate distortion cost, in accordance with an embodiment of the present invention. Block <b>702</b> may include receiving a video region at an encoder. A video region may include one or more pictures, slices, macroblocks, blocks or pixels.</p>
<p id="p-0040" num="0041">Block <b>704</b> may include determining the rate-distortion cost of the video region when an adaptive Wiener filter is not used. Rate-distortion cost can be measured using equation (1).</p>
<p id="p-0041" num="0042">Block <b>706</b> may include encoding the video region using adaptive Wiener filtering with a new parameter set. Adaptive filtering may include filtering that is content dependent or based on an analysis of pixel intensities in a portion of a picture, a picture as a whole, or a plurality of successive pictures. For example, the type of video information that is received, be it graphics or stream view video, results in different taps in the Wiener filter for different types of video. Thus, adaptive filter taps are the result of an examination of the intensity of each pixel in a given picture portion, picture, or series of pictures. Parameters can be selected from among various coefficients, quantization levels, filter size, filter types, coefficient prediction, and entropy coding. For example, the parameters can be selected in a manner similar to that described with regard to elements <b>102</b>-<b>110</b> of encoder <b>100</b>.</p>
<p id="p-0042" num="0043">Block <b>708</b> may include determining the rate-distortion cost for the video region resulting from adaptive Wiener filtering using the new parameter set.</p>
<p id="p-0043" num="0044">Block <b>710</b> may include determining whether the rate-distortion cost for the current encoder parameter set is the lowest measured rate-distortion cost. If the rate-distortion cost is the lowest, then block <b>712</b> follows block <b>710</b>. If the rate-distortion cost is not the lowest, then block <b>714</b> follows block <b>710</b>.</p>
<p id="p-0044" num="0045">Block <b>712</b> may include setting the rate-distortion cost for the current rate-distortion cost as the lowest measured rate-distortion cost. Block <b>712</b> may also include identifying the encoder parameter set associated with the lowest measured rate-distortion cost.</p>
<p id="p-0045" num="0046">Block <b>714</b> may include determining whether all parameter sets have been applied by the adaptive Wiener filter. If all parameter sets have been applied by the adaptive Wiener filter, then block <b>716</b> may follow block <b>714</b>. If all parameter sets have not been applied by the encoder, then block <b>706</b> may follow block <b>714</b>.</p>
<p id="p-0046" num="0047">Block <b>716</b> may include transferring the filter parameter set for the current video region that results in the lowest rate-distortion cost. The filter parameters can be transferred with the video region processed using the filter parameter set that result in lowest rate-distortion cost. For example, a frame buffer may store the current video region encoded with every filter parameter set. The frame buffer may transfer the video region encoded with the filter parameter set corresponding to the lowest measured video region encoded with every encoder parameter set.</p>
<p id="p-0047" num="0048">However, if the rate distortion cost associated with not using adaptive Wiener filtering is the lowest rate distortion cost, then adaptive Wiener filtering is not applied to the video region and no filter parameters are transferred with the video region.</p>
<p id="p-0048" num="0049">Referring to <figref idref="DRAWINGS">FIG. 8</figref>, the encoder and logic depicted in <figref idref="DRAWINGS">FIGS. 1-6</figref> may, in one embodiment, be part of a graphics processor <b>812</b>. Embodiments of the present invention may be implemented as any or a combination of: one or more microchips or integrated circuits interconnected using a motherboard, hardwired logic, software stored by a memory device and executed by a microprocessor, firmware, an application specific integrated circuit (ASIC), and/or a field programmable gate array (FPGA). The term &#x201c;logic&#x201d; may include, by way of example, software or hardware and/or combinations of software and hardware.</p>
<p id="p-0049" num="0050">In the case of a software implementation, the pertinent code may be stored in any suitable semiconductor, magnetic or optical memory, including the main memory <b>832</b>. Thus, in one embodiment, source code <b>839</b> may be stored in a machine readable medium, such as main memory <b>832</b>, for execution by a processor, such as the processor <b>800</b> or the graphics processor <b>812</b>.</p>
<p id="p-0050" num="0051">A computer system <b>830</b> may include a hard drive <b>834</b> and a removable medium <b>836</b>, coupled by a bus <b>804</b> to a chipset core logic <b>810</b>. The core logic may couple to the graphics processor <b>812</b> (via bus <b>805</b>) and the main processor <b>800</b> in one embodiment. The graphics processor <b>812</b> may also be coupled by a bus <b>806</b> to a frame buffer <b>814</b>. The frame buffer <b>814</b> may be coupled by a bus <b>807</b> to a display screen <b>818</b>, in turn coupled to conventional components by a bus <b>808</b>, such as a keyboard or mouse <b>820</b>.</p>
<p id="p-0051" num="0052">The graphics and/or video processing techniques described herein may be implemented in various hardware architectures. For example, graphics and/or video functionality may be integrated within a chipset. Alternatively, a discrete graphics and/or video processor may be used. As still another embodiment, the graphics and/or video functions may be implemented by a general purpose processor, including a multicore processor. In a further embodiment, the functions may be implemented in a consumer electronics device.</p>
<p id="p-0052" num="0053">Embodiments of the present invention may be provided, for example, as a computer program product which may include one or more machine-readable media having stored thereon machine-executable instructions that, when executed by one or more machines such as a computer, network of computers, or other electronic devices, may result in the one or more machines carrying out operations in accordance with embodiments of the present invention. A machine-readable medium may include, but is not limited to, floppy diskettes, optical disks, CD-ROMs (Compact Disc-Read Only Memories), and magneto-optical disks, ROMs (Read Only Memories), RAMs (Random Access Memories), EPROMs (Erasable Programmable Read Only Memories), EEPROMs (Electrically Erasable Programmable Read Only Memories), magnetic or optical cards, flash memory, or other type of media/machine-readable medium suitable for storing machine-executable instructions.</p>
<p id="p-0053" num="0054">The drawings and the forgoing description gave examples of the present invention. Although depicted as a number of disparate functional items, those skilled in the art will appreciate that one or more of such elements may well be combined into single functional elements. Alternatively, certain elements may be split into multiple functional elements. Elements from one embodiment may be added to another embodiment. For example, orders of processes described herein may be changed and are not limited to the manner described herein. Moreover, the actions of any flow diagram need not be implemented in the order shown; nor do all of the acts necessarily need to be performed. Also, those acts that are not dependent on other acts may be performed in parallel with the other acts. The scope of the present invention, however, is by no means limited by these specific examples. Numerous variations, whether explicitly given in the specification or not, such as differences in structure, dimension, and use of material, are possible. The scope of the invention is at least as broad as given by the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08625681-20140107-M00001.NB">
<img id="EMI-M00001" he="9.14mm" wi="76.20mm" file="US08625681-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>encoding a video region using first parameters, the encoding using first parameters including applying adaptive Wiener filtering to the video region using the first parameters;</claim-text>
<claim-text>encoding the video region using second parameters, the encoding using second parameters including applying adaptive Wiener filtering to the video region using the second parameters;</claim-text>
<claim-text>setting a lowest rate-distortion cost of the video region as the lowest among: a rate-distortion cost resulting from adaptive Wiener filtering of the video region using the first parameters, a rate-distortion cost resulting from adaptive Wiener filtering of the video region using the second parameters, and a rate-distortion cost resulting from not applying adaptive Wiener filtering to the video region;</claim-text>
<claim-text>selecting parameters from among the first and second parameters associated with a lowest rate-distortion cost in response to the lowest rate-distortion cost resulting from adaptive Wiener filtering of the video region using the first or the second parameters;</claim-text>
<claim-text>selectively transferring selected parameters for the video region in response to the lowest-rate distortion cost resulting from adaptive Wiener filtering using first or second parameters, wherein transferred selected parameters are for use to modify and replace at least one pixel; and</claim-text>
<claim-text>selectively transferring no filter parameters associated with the video region in response to the lowest rate-distortion cost resulting from not applying adaptive Wiener filtering to the video region.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the encoding using first parameters and encoding using second parameters include use of coefficients in at least two filter sizes, the filter sizes having dimensions m by n, where m and n are positive integers.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the encoding using first parameters and encoding using second parameters include use of a quantization step selected from among multiple quantization steps.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the encoding using first parameters and encoding using second parameters include use of at least one filter table selected from among global and local filter sizes.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the encoding using first parameters and encoding using second parameters include use of one of a 2-D non-separable filter, 1-D separable filter, non-symmetric filter, and symmetrical filter.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the encoding using first parameters and encoding using second parameters include use of a prediction mode selected from a group consisting of: no prediction, temporal prediction, spatial prediction, and temporal-spatial combined prediction.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the encoding using first parameters and encoding using second parameters include use of an entropy coding mode, wherein the entropy coding mode is selected from a group consisting of: Exp-Golomb coding mode, fixed length coding mode, and size-value coding mode.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>storing the video regions encoded according to the first and second parameters; and</claim-text>
<claim-text>transferring the selected parameters with the video region encoded according to the selected parameters.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the video region is selected from a group consisting of: sequence level, group-of-pictures, picture, slice level, one or more macroblocks, block level, and pixels.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the video region comprises a collection of pixels with similar features, the features comprising pixel value and gradient.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An apparatus comprising:
<claim-text>one or more adaptive Wiener filters to receive a video region and to filter the video region using parameters selected from among at least a first and second parameters; and</claim-text>
<claim-text>a rate-distortion cost calculator to determine a rate-distortion cost associated with no use of the adaptive Wiener filter for the video region and rate-distortion costs associated with the video region filtered by the adaptive Wiener filter according to the first and second parameters,
<claim-text>wherein the rate-distortion cost calculator is to set a lowest rate-distortion cost of the video region as a lowest rate-distortion cost associated with no use of the adaptive Wiener filter for the video region or one of the rate-distortion costs associated with the video region filtered by the adaptive Wiener filter using the first and second parameters and</claim-text>
<claim-text>wherein if the lowest rate-distortion cost is the one of the rate-distortion costs for one of the first and second parameters, the rate-distortion cost calculator is to provide the parameters associated with the lowest rate-distortion cost and if the lowest rate-distortion cost is the rate-distortion cost associated with no use of the adaptive Wiener filter of the video region, the rate-distortion cost calculator is to provide no parameters for filtering the video region, wherein the provided parameters are for use by a filter to modify and replace at least one pixel.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising selectively providing the video region with no applied filtering in response to a lowest rate-distortion cost associated with not using adaptive filtering on the region.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the parameters comprise coefficients and further comprising a coefficient determiner to determine the coefficients.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the parameters comprise a quantization level and further comprising a quantizer to select the quantization level.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the parameters comprise a global or local region and further comprising a filter selection logic to select a region in which to apply filter coefficients.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the parameters comprise a filter type selected from a group consisting of a 2-D non-separable filter, 1-D separable filter, non-symmetric filter, and symmetrical filter and further comprising filter type selection logic to select a filter type to apply.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the parameters comprise an encoding type selected from a group consisting of: no prediction, temporal prediction, spatial prediction, and temporal-spatial combined prediction and further comprising filter coefficient prediction logic to select an encoding type.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the parameters comprise an entropy coding mode selected from a group consisting of Exp-Golomb coding mode, fixed length coding mode, and size-value coding mode and further comprising entropy encoder logic to select an entropy coding mode to apply.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the video region is selected from a group consisting of: sequence level, group-of-pictures, picture, slice level, one or more macroblocks, block level, and pixels.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A system comprising:
<claim-text>a processor;</claim-text>
<claim-text>a graphics sub-system communicatively coupled to the processor, the graphics sub-system comprising:
<claim-text>one or more adaptive Wiener filters to filter a video region using parameters selected from among at least first and second parameters, and</claim-text>
<claim-text>a rate-distortion cost calculator to determine a rate-distortion cost associated with no use of the adaptive Wiener filter for the video region and rate-distortion costs associated with the video region filtered by the adaptive Wiener filter according to the first and second parameters,</claim-text>
<claim-text>wherein the rate-distortion cost calculator is to choose a lowest rate-distortion cost of the video region from among the rate-distortion cost associated with no use of the adaptive Wiener filter for the video region and the rate-distortion costs associated with the video region filtered by the adaptive Wiener filter according to the first and second parametersets;</claim-text>
<claim-text>wherein if the lowest rate-distortion cost is the one of the rate-distortion costs for one of the first and second parameters, the rate-distortion cost calculator is to provide the parameters associated with the lowest rate-distortion cost and if the lowest rate-distortion cost is the rate-distortion cost associated with no use of the adaptive Wiener filter of the video region, the rate-distortion cost calculator is to provide no parameters for filtering the video region, wherein the provided parameters are for use by a filter to filter and replace at least one pixel;</claim-text>
</claim-text>
<claim-text>a memory device communicatively coupled to the graphics sub-system; and</claim-text>
<claim-text>a display communicatively coupled to the graphics sub-system.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the memory device is to store the video region associated with the lowest rate-distortion cost.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein first parameters and second parameters include parameters selected from a group consisting of: filter coefficients, quantization levels, filter sizes, filter types, coefficient prediction modes, and entropy coding modes with which adaptive Wiener filtering is applied to the video region.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein first parameters and second parameters include coefficients in at least two filter sizes, the filter sizes having dimensions m by n, where m and n are positive integers.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein first parameters and second parameters include use of at least one filter table selected from among global and local filter sizes.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein first parameters and second parameters include use of one of a 2-D non-separable filter, 1-D separable filter, non-symmetric filter, and symmetrical filter.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein first parameters and second parameters include a prediction mode selected from a group consisting of: no prediction, temporal prediction, spatial prediction, and temporal-spatial combined prediction.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein first parameters and second parameters include an entropy coding mode, wherein the entropy coding mode is selected from a group consisting of: Exp-Golomb coding mode, fixed length coding mode, and size-value coding mode. </claim-text>
</claim>
</claims>
</us-patent-grant>
