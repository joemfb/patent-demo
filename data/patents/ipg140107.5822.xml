<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626930-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626930</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11724880</doc-number>
<date>20070315</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1751</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>29</main-group>
<subgroup>06</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709228</main-classification>
<further-classification>713153</further-classification>
<further-classification>713154</further-classification>
</classification-national>
<invention-title id="d2e53">Multimedia content filtering</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5924105</doc-number>
<kind>A</kind>
<name>Punch et al.</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715234</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6041360</doc-number>
<kind>A</kind>
<name>Himmel et al.</name>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6295559</doc-number>
<kind>B1</kind>
<name>Emens et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6366947</doc-number>
<kind>B1</kind>
<name>Kavner</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709203</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6374217</doc-number>
<kind>B1</kind>
<name>Bellegarda</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7076527</doc-number>
<kind>B2</kind>
<name>Bellegarda et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7124081</doc-number>
<kind>B1</kind>
<name>Bellegarda</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7149695</doc-number>
<kind>B1</kind>
<name>Bellegarda</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7194464</doc-number>
<kind>B2</kind>
<name>Kester et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>  1  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7343559</doc-number>
<kind>B1</kind>
<name>Fujita et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2002/0010757</doc-number>
<kind>A1</kind>
<name>Granik et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709218</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2002/0016786</doc-number>
<kind>A1</kind>
<name>Pitkow et al.</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2002/0103789</doc-number>
<kind>A1</kind>
<name>Turnbull et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2002/0152237</doc-number>
<kind>A1</kind>
<name>Cohen et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2002/1911020</doc-number>
<name>Kaply et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2003/0009526</doc-number>
<kind>A1</kind>
<name>Bellegarda et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709206</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2003/0090510</doc-number>
<kind>A1</kind>
<name>Shuping et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2005/0060404</doc-number>
<kind>A1</kind>
<name>Ahlander et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2005/0132018</doc-number>
<kind>A1</kind>
<name>Milic-Frayling et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2005/0179076</doc-number>
<kind>A1</kind>
<name>Lin et al.</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2006/0004716</doc-number>
<kind>A1</kind>
<name>Hurst-Hiller et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2006/0020714</doc-number>
<kind>A1</kind>
<name>Girouard et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709246</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2006/0101330</doc-number>
<kind>A1</kind>
<name>Godley</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2006/0224997</doc-number>
<kind>A1</kind>
<name>Wong et al.</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2006/0265417</doc-number>
<kind>A1</kind>
<name>Amato et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2007/0011616</doc-number>
<kind>A1</kind>
<name>Ording</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2007/0174389</doc-number>
<kind>A1</kind>
<name>Armstrong et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2008/0046840</doc-number>
<kind>A1</kind>
<name>Melton et al.</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>&#x201c;Customizing your computer&#x2014;To display hidden files and folders&#x201d; Windows XP Professional Product Documentation Dec. 30, 2007, XP002561535 (1 pg.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>&#x201c;Find and Return to Web Pages You've Recently Visited&#x201d; microsoft.com Aug. 23, 2006, XP002561531. Retrieved from the Internet: URL:http://www.microsoft.com/windows/ie/ie6/using/howto/basics/history/button.mspx&#x3e; (3 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00031">
<othercit>Anonymous: &#x201c;Awasu&#x2014;Features&#x201d; Internet citation Jan. 3, 2007, XP002561537. Retrieved from the Internet: URL:http://web.archive.org/web/20070103184812/www.awasu.com/features.php&#x3e; (3 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00032">
<othercit>EP Search Report for EP Application No. 09173177.8, mailed Jan. 28, 2010, (16 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00033">
<othercit>Glenn Derene: &#x201c;How Google's Simple Chrome Could Steer Web's Complex Future: Analysis&#x201d; popularmechanics.com Sep. 2, 2008, XP002561529 Retrieved from the Internet: URL:http://www.popularmechanics.com/technology/industry/4280717.html&#x3e; (3 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Jason Hiner: &#x201c;Google Chrome: The five best new features&#x201d; blogs.zdnet.com Sep. 3, 2008, XP002561528. Retrieved from the Internet: URL:http://blogs.zdnet.com/BTL/?p=9878&#x3e; (3 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Josh Lowensohn: &#x201c;FoxTab turns your browser tabs into a spectacle&#x201d; cnet news Sep. 17, 2008, XP002561530. Retrieved from the Internet: URL:http://news.cnet.com/8301-17939<sub>&#x2014;</sub>109-10044366-2.html&#x3e; (2 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>Kaasten S et al: &#x201c;Designing an Integrated Bookmark/History System for Web Browsing&#x201d; Mar. 1, 2000, Proceedings Western Computer Graphics Symposium, XX, XX, pp. 1-04 , XP008031090 p. 2, paragraph 2.2&#x2014;p. 3, paragraph 3.4; figure 1 (4 pgs).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>PCT Notification of Transmittal of the International Search Report and the Written Opinion of the International Searching Authority, or the Declaration for PCT/US09/60391, mailed Dec. 7, 2009, (3 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>Tommy A. Olsen: &#x201c;Speed dial tips&#x201d; my.opera.com Mar. 1, 2007, XP002561536. Retrieved from the Internet: URL:http://my.opera.com/toman/blog/show.dml/788600&#x3e; (4 pgs.).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>&#x201c;FoxTab Tab Switching Firefox Add-on&#x201d; http://www.youtube.com/watch?v=JJhvGqj5yNM, Oct. 7, 2008, 2 pages, retrieved from the Internet on Jan. 25, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>53</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709224-225</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709228-229</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 23- 30</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713153-154</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>13</number-of-drawing-sheets>
<number-of-figures>13</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080228928</doc-number>
<kind>A1</kind>
<date>20080918</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Donelli</last-name>
<first-name>Giovanni</first-name>
<address>
<city>Calerno</city>
<country>IT</country>
</address>
</addressbook>
<residence>
<country>IT</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Bellegarda</last-name>
<first-name>Jerome</first-name>
<address>
<city>Saratoga</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ko</last-name>
<first-name>Steve</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Scalo</last-name>
<first-name>John</first-name>
<address>
<city>Santa Cruz</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Donelli</last-name>
<first-name>Giovanni</first-name>
<address>
<city>Calerno</city>
<country>IT</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Bellegarda</last-name>
<first-name>Jerome</first-name>
<address>
<city>Saratoga</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Ko</last-name>
<first-name>Steve</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Scalo</last-name>
<first-name>John</first-name>
<address>
<city>Santa Cruz</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Kenyon &#x26; Kenyon, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Apple Inc.</orgname>
<role>02</role>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Shiferaw</last-name>
<first-name>Eleni</first-name>
<department>2437</department>
</primary-examiner>
<assistant-examiner>
<last-name>Vu</last-name>
<first-name>Phy Anh</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Methods and apparatuses to filter multimedia content are described. The multimedia content in one embodiment is analyzed for one or more parameters. The multimedia content in one embodiment is filtered based on the one or more parameters using a latent semantic mapping (&#x201c;LSM&#x201d;) filter. In one embodiment, the one or more parameters include information about a structure of the multimedia content. A tag that encapsulates the one or more parameters may be generated. Then, the tag is input into the latent semantic mapping filter. In one embodiment, the LSM filter is trained to recognize the multimedia content based on the one or more parameters. In one embodiment, more than two categories are provided for a multimedia content. The multimedia content is classified in more than two categories using the LSM filter. The multimedia content may be blocked based on the classifying.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="99.82mm" wi="112.78mm" file="US08626930-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="235.03mm" wi="158.07mm" file="US08626930-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="187.45mm" wi="146.90mm" file="US08626930-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="123.44mm" wi="114.22mm" file="US08626930-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="107.61mm" wi="144.10mm" file="US08626930-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="192.36mm" wi="107.87mm" orientation="landscape" file="US08626930-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="210.65mm" wi="138.60mm" file="US08626930-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="110.49mm" wi="115.40mm" file="US08626930-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="235.03mm" wi="148.08mm" file="US08626930-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="159.34mm" wi="145.80mm" file="US08626930-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="144.02mm" wi="119.97mm" file="US08626930-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="141.82mm" wi="122.26mm" file="US08626930-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="141.82mm" wi="142.66mm" file="US08626930-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="207.52mm" wi="144.95mm" file="US08626930-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">COPYRIGHT NOTICES</heading>
<p id="p-0002" num="0001">A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever. Copyright &#xa9;2006, Apple Inc., All Rights Reserved.</p>
<heading id="h-0002" level="1">FIELD</heading>
<p id="p-0003" num="0002">Embodiments of the invention relate to content filtering, and more particularly, to multimedia content filtering using latent semantic analysis.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">The use of computer systems and the Internet for communication and obtaining information has grown drastically over the years. The Internet may be described as a collection of interconnected computer networks. The World Wide Web (&#x201c;Web&#x201d;) may be described as a collection of interconnected documents and other resources, linked by hyperlinks and Uniform Resource Locators (&#x201c;URLs&#x201d;). The Web may be accessed using a computer via the Internet, and are many other services available through the Web including e-mail, file sharing, and others. Through the Internet, millions of people worldwide have easy, virtually instant access to a vast and diverse amount of on-line information. Compared to encyclopedias and traditional libraries, the World Wide Web has enabled a sudden and extreme decentralization of information and data. The Web is a fast changing place, as web sites may change and new ones may come up all the time.</p>
<p id="p-0005" num="0004">A content-control software, for example, Cyber Patrol&#x2122;, squidGuard&#x2122;, NetNanny&#x2122;, NetBarrier&#x2122;, ContentBarrier&#x2122;, DansGuardian&#x2122; may be used to control and restrict material delivered over the Web to a user. Typical users of such software includes parents who wish to limit what web sites their children may view from home computers, schools performing the same function with regard to computers found at school, employers restricting what content may be viewed by employees while on the job, and the like.</p>
<p id="p-0006" num="0005">Most existing content controls typically filter the access to web pages based on a list of banned sites. Some filters allow control of advertisements through features like blacklists, whitelists, and regular expression filters. Some web browsers include content filtering, which prevents certain external files from the blacklist from loading.</p>
<p id="p-0007" num="0006">Typically, the existing content-controlling filters operate at a proxy server. These programs work by caching and filtering content before it is displayed in a user's browser. DansGuardian&#x2122; , an Open Source proxy software, in addition to a list of banned sites, has a static list of weighted phrases and words. DansGuardian&#x2122; may filter the web pages based on phrase matching and URL matching. DansGuardian&#x2122;, however, ignores a new word that is not in the static list.</p>
<p id="p-0008" num="0007">The proxy content controlling filters, however, may not control all web traffic going through the system.</p>
<p id="p-0009" num="0008">Additionally, to adapt to the changes that happen on the Web, the existing content controlling filters solutions typically use neutral networks and baysian statistics methodologies.</p>
<heading id="h-0004" level="1">SUMMARY OF THE DESCRIPTION</heading>
<p id="p-0010" num="0009">Methods and apparatuses to filter multimedia content, e.g., web sites, are described. The multimedia content, in one embodiment, is analyzed for one or more parameters. The multimedia content is determined to be filtered based on the one or more parameters using a latent semantic mapping (&#x201c;LSM&#x201d;) filter. The one or more parameters may include information about a structure of the multimedia content. The structure of the multimedia content may include references (e.g., hyperlinks to other web pages), images (e.g., the number of images on a web page), textual and pictorial patterns, a size of the content, and the like. A tag that encapsulates the one or more parameters may be generated. The tag may then be provided to the LSM filter. In one embodiment, the LSM filter is trained to recognize the multimedia content based on the one or more parameters. In one embodiment, rating of the multimedia content is performed based on the one or more parameters.</p>
<p id="p-0011" num="0010">In one embodiment, more than two categories are provided for a multimedia content. The multimedia content is classified in the more than two categories using the LSM filter. The more than two categories may be any combination of an explicit content category and a plurality of legitimate content categories; a legitimate content category and a plurality of explicit content categories; or a plurality of explicit content categories and a plurality of legitimate content categories. The multimedia content may be blocked based on the classifying. A reference to the multimedia content may be stored. In one embodiment, an LSM filter is trained to recognize the multimedia content among more than two categories.</p>
<p id="p-0012" num="0011">In one embodiment, a blocked multimedia content is accepted to be unblocked in response to receiving an input from a user. In one embodiment, the unblocked multimedia content is added to a &#x201c;white&#x201d; list and/or may be used to train the LSM filter. Further, an unblocked multimedia content may be indicated to be in a first class or category (e.g., porn category), and to be added to a list and/or may be used to train an LSM filter.</p>
<p id="p-0013" num="0012">In one embodiment, a multimedia content is converted or processed into a plain text. In one embodiment, the multimedia content, e.g., a web page is converted into the plain text using an HTML stripper. In one embodiment, strings within a Javascript or other executable scripts are extracted to convert the multimedia content into the plain text or into another format. The multimedia content is analyzed for one or more parameters. A tag may be generated that encapsulates the one or more parameters. In one embodiment, the tag includes a string of characters. Further, the tag is inserted into (or otherwise associated with) the plain text and both, as tokens, become input for the LSM filter. The LSM filter has a vector space. Tokens may be mapped into a vector space of the LSM filter. In one embodiment, one or more stop words may be removed from the plain text; this may be done to protect against false positives. A false positive may include, for example, a legitimate material that is wrongly classified as an objectionable material. Filtering of the multimedia content may be performed based on the mapping of the tokens in the vector space.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013">The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1A</figref> illustrates an example of a plurality of systems in a network.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1B</figref> illustrates one embodiment of a system to perform multimedia content filtering.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2A</figref> shows a flowchart of one embodiment of a method to perform multimedia content filtering using an LSM filter.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2B</figref> shows a block-diagram of one embodiment of an apparatus to perform multimedia content filtering using an LSM filter.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3</figref> shows a block-diagram of one embodiment of an apparatus to perform multimedia content filtering based on one or more parameters using an LSM filter.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 4</figref> shows a flowchart of one embodiment of a method to perform multimedia filtering based on one or more parameters using an LSM filter.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 5</figref> illustrates one embodiment of a method to classify a new multimedia content based on mapping into a vector space of an LSM filter.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6</figref> shows a flowchart of one embodiment of a method of classify a multimedia content into more than two content categories using an LSM filter.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 7</figref> illustrates one embodiment of a method to classify a new multimedia content in more than two categories based on mapping into a vector space of an LSM filter.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 8</figref> illustrates one embodiment of a user interface for content filter options.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 9</figref> illustrates a user interface to configure a content filter.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 10</figref> illustrates one embodiment of a user interface that requires a password from a user to access a multimedia content that has been blocked by a content filter.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 11</figref> shows a flowchart of another embodiment of a method of classifying a multimedia content using an LSM filter.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0028" num="0027">The subject invention will be described with references to numerous details set forth below, and the accompanying drawings will illustrate the invention. The following description and drawings are illustrative of the invention and are not to be construed as limiting the invention. Numerous specific details are described to provide a thorough understanding of the present invention. However, in certain instances, well known or conventional details are not described in order to not unnecessarily obscure the present invention in detail.</p>
<p id="p-0029" num="0028">Reference throughout the specification to &#x201c;one embodiment&#x201d;, &#x201c;another embodiment&#x201d;, or &#x201c;an embodiment&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearance of the phrases &#x201c;in one embodiment&#x201d; or &#x201c;in an embodiment&#x201d; in various places throughout the specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.</p>
<p id="p-0030" num="0029">Methods and apparatuses to filter multimedia content based on one or more parameters using a latent semantic mapping filter and a system having a computer readable medium containing executable program code to filter multimedia content based on one or more parameters using a latent semantic mapping (&#x201c;LSM&#x201d;) filter are described below.</p>
<p id="p-0031" num="0030">Other methods and other features are also described.</p>
<p id="p-0032" num="0031">Generally, the term &#x201c;multimedia&#x201d; is referred to a media that uses multiple forms of information content and information processing (e.g., text, audio, graphics, animation, video, interactivity) to inform or entertain the (user) audience. The term &#x201c;multimedia&#x201d; also may refer to the use of (but not limited to) electronic media to store and experience multimedia content. On-line multimedia may be downloaded or streamed. Streaming multimedia may be live or on-demand. Multimedia content includes hypermedia content. The term &#x201c;hypermedia&#x201d; is referred to a combination of graphics, audio, video, text, and hyperlinks and generally offers a user interactivity to control progress of the content. World Wide Web is an example of hypermedia. Most of hypermedia content is typically delivered via electronic pages.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 1A</figref> illustrates one embodiment of a system <b>100</b> to perform multimedia content filtering as described in further detail below with respect to <figref idref="DRAWINGS">FIGS. 2-11</figref>. System <b>100</b> includes client computer systems coupled together through a network <b>119</b>, e.g. the Internet, as shown in <figref idref="DRAWINGS">FIG. 1A</figref>. The term &#x201c;Internet&#x201d; as used herein refers to a network of networks which uses certain protocols, such as the TCP/IP protocol, and possibly other protocols such as the hypertext transfer protocol (HTTP) for hypertext markup language (HTML) documents that make up the World Wide Web (web). The physical connections of the Internet and the protocols and communication procedures of the Internet are well known to those of skill in the art. Access to the Internet <b>119</b> is typically provided by Internet service providers (ISP), e.g., the ISPs <b>102</b> and <b>104</b>. Users on client systems, such as client computer systems <b>101</b>, <b>105</b>, <b>114</b>, and <b>115</b> may obtain access to the Internet through the Internet service providers, such as ISPs <b>102</b> and <b>104</b>. Access to the Internet allows users of the client computer systems to exchange information receive and send e-mails, and view documents, for example, documents which have been prepared in the HTML format. This information is often provided by web servers, such as web server <b>106</b>, which is considered to be &#x201c;on&#x201d; the Internet. Often these web servers are provided by the ISPs, such as ISP <b>102</b>, although a computer system can be set up and connected to the Internet without that system being also an ISP as is well known in the art.</p>
<p id="p-0034" num="0033">The web server <b>106</b> is typically at least one computer system which operates as a server computer system and is configured to operate with the protocols of the World Wide Web and is coupled to the Internet. Optionally, the web server <b>106</b> can be part of an ISP which provides access to the Internet for client systems. The web server <b>106</b> is shown coupled to the server computer system <b>109</b> which itself is coupled to web content <b>118</b>, which can be considered a form of a multimedia database. It will be appreciated that while two computer systems <b>106</b> and <b>109</b> are shown in <figref idref="DRAWINGS">FIG. 1A</figref>, the web server system <b>106</b> and the server computer system <b>109</b> can be one computer system having different software components providing the web server functionality and the server functionality provided by the server computer system <b>109</b>. It will be appreciated that multiple web servers, which serve multiple webpages, may be coupled to network <b>119</b>.</p>
<p id="p-0035" num="0034">Client computer systems <b>101</b>, <b>105</b>, <b>114</b>, and <b>115</b> can each, with the appropriate web browsing software, view HTML pages provided by the web server <b>106</b>. The ISP <b>102</b> provides Internet connectivity to the client computer system <b>101</b> through a modem <b>103</b> which can be considered part of the client computer system <b>102</b>. The client computer system can be a personal computer system, a network computer, a Web TV system, a handheld device, other such computer system, or other consumer electronic device. Similarly, the ISP <b>104</b> provides Internet connectivity for client systems <b>105</b>, <b>114</b>, and <b>115</b>, although as shown in <figref idref="DRAWINGS">FIG. 1A</figref>. Client computer system <b>105</b> is coupled through a modem interface <b>107</b> while client computer systems <b>115</b> and <b>114</b> are part of a LAN. While <figref idref="DRAWINGS">FIG. 1A</figref> shows the interfaces <b>103</b> and <b>107</b> as generically as a &#x201c;modem,&#x201d; it will be appreciated that each of these interfaces can be an analog modem, ISDN modem, cable modem, satellite transmission interface, or other interfaces for coupling a computer system to other computer systems. Client computer systems <b>114</b> and <b>115</b> are coupled to a Local Area Network (LAN) <b>110</b> through network interfaces <b>111</b> and <b>112</b>, which can be Ethernet network or other network interfaces. The LAN <b>110</b> is also coupled to a gateway computer system <b>108</b> which can provide firewall and other Internet related services for the local area network. This gateway computer system <b>108</b> is coupled to the ISP <b>104</b> to provide Internet connectivity to the client computer systems <b>114</b> and <b>115</b>. The gateway computer system <b>108</b> can be a conventional server computer system. Also, the web server system <b>106</b> can be a conventional server computer system.</p>
<p id="p-0036" num="0035">Alternatively, a server computer system <b>116</b> can be directly coupled to the LAN <b>110</b> through a network interface <b>113</b> to provide files <b>117</b> and other services to the clients <b>114</b>, <b>115</b>, without the need to connect to the Internet through the gateway system <b>110</b>. Furthermore, any combination of client systems <b>101</b>, <b>105</b>, <b>114</b>, <b>115</b> may be connected together in a peer-to-peer network using LAN <b>110</b>, Internet <b>119</b> or a combination as a communications medium. Generally, a peer-to-peer network distributes data across a network of multiple machines for storage and retrieval without the use of a central server or servers. Thus, each peer network node may incorporate the functions of both the client and the server described above.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 1B</figref> shows one embodiment of a computer system that can be used as a client computer system or a server computer system or as a web server system to perform multimedia content filtering, as described below with respect to <figref idref="DRAWINGS">FIGS. 2-11</figref>. It will also be appreciated that such a computer system can be used to perform many of the functions of an Internet service provider, such as ISP <b>102</b> depicted in <figref idref="DRAWINGS">FIG. 1A</figref>. A computer system <b>131</b> interfaces to external systems through the modem or network interface <b>130</b>. It will be appreciated that the modem or network interface <b>130</b> can be considered to be part of the computer system <b>131</b>. This interface <b>130</b> can be an analog modem, ISDN modem, cable modem, token ring interface, satellite transmission interface, or other interfaces for coupling a computer system to other computer systems.</p>
<p id="p-0038" num="0037">Computer system <b>131</b> includes a processing unit <b>121</b> that may include a microprocessor, such as an Intel Pentium&#xae; microprocessor, Motorola Power PC&#xae; microprocessor, Intel Core&#x2122; Duo processor, AMD Athlon&#x2122; processor, AMD Turion&#x2122; processor, AMD Sempron&#x2122; processor, and any other microprocessor. Processing unit <b>121</b> may include a personal computer (PC), such as a Macintosh&#xae; (from Apple Inc. of Cupertino, Calif.), Windows&#xae;-based PC (from Microsoft Corporation of Redmond, Wash.), or one of a wide variety of hardware platforms that run the UNIX operating system or other operating systems. For one embodiment, processing unit <b>121</b> includes a general purpose computer system based on the PowerPC&#xae;, Intel Core&#x2122; Duo, AMD Athlon&#x2122;, AMD Turion&#x2122; processor, AMD Sempron&#x2122;, HP Pavilion&#x2122; PC, HP Compaq&#x2122; PC, and any other processor families. Processing unit <b>121</b> may be a conventional microprocessor such as an Intel Pentium microprocessor or Motorola Power PC microprocessor.</p>
<p id="p-0039" num="0038">As shown in <figref idref="DRAWINGS">FIG. 1B</figref>, memory <b>122</b> is coupled to the processing unit <b>121</b> by a bus <b>123</b>. Memory <b>122</b> can be dynamic random access memory (DRAM) and can also include static random access memory (SRAM). A bus <b>123</b> couples processing unit <b>121</b> to the memory <b>122</b> and also to non-volatile storage <b>124</b> and to display controller <b>128</b> and to the input/output (I/O) controller <b>125</b>. Display controller <b>128</b> controls in the conventional manner a display on a display device <b>129</b> which can be a cathode ray tube (CRT) or liquid crystal display (LCD). The input/output devices <b>126</b> can include a keyboard, disk drives, printers, a scanner, and other input and output devices, including a mouse or other pointing device. The display controller <b>128</b> and the I/O controller <b>125</b> can be implemented with conventional well known technology. A digital image input device <b>127</b>, for example, a digital camera may be coupled to an I/O controller <b>125</b> input images into the computer system <b>131</b>. The non-volatile storage <b>124</b> is often a magnetic hard disk, an optical disk, or another form of storage for large amounts of data. Some of this data is often written, by a direct memory access process, into memory <b>122</b> during execution of software in the computer system <b>131</b>. One of skill in the art will immediately recognize that the terms &#x201c;computer-readable medium&#x201d; and &#x201c;machine-readable medium&#x201d; include any type of storage device that is accessible by the processing unit <b>121</b>.</p>
<p id="p-0040" num="0039">It will be appreciated that computer system <b>131</b> is one example of many possible computer systems which have different architectures. For example, personal computers based on an Intel microprocessor often have multiple buses, one of which can be an input/output (I/O) bus for the peripherals and one that directly connects the processing unit <b>121</b> and the memory <b>122</b> (often referred to as a memory bus). The buses are connected together through bridge components that perform any necessary translation due to differing bus protocols.</p>
<p id="p-0041" num="0040">Network computers are another type of computer system that can be used with the embodiments of the present invention. Network computers do not usually include a hard disk or other mass storage, and the executable programs are loaded from a network connection into the memory <b>122</b> for execution by the processing unit <b>121</b>. A Web TV system, which is known in the art, is also considered to be a computer system according to the embodiments of the present invention, but it may lack some of the features shown in <figref idref="DRAWINGS">FIG. 1B</figref>, such as certain input or output devices. A typical computer system will usually include at least a processor, memory, and a bus coupling the memory to the processor.</p>
<p id="p-0042" num="0041">It will also be appreciated that the computer system <b>131</b> is controlled by operating system software which includes a file management system, such as a disk operating system, which is part of the operating system software. One example of an operating system software is the family of operating systems known as Macintosh&#xae; Operating System (Mac OS&#xae;) or Mac OS X&#xae; from Apple Inc. of Cupertino, Calif. Another example of an operating system software is the family of operating systems known as Windows&#xae; from Microsoft Corporation of Redmond, Wash., and their associated file management systems. The file management system is typically stored in the non-volatile storage <b>124</b> and causes the processing unit <b>121</b> to execute the various acts required by the operating system to input and output data and to store data in memory, including storing files on the non-volatile storage <b>124</b>.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 2A</figref> shows a flowchart of one embodiment of a method to perform multimedia content filtering. The multimedia content may be classified and filtered using latent semantic mapping (&#x201c;LSM&#x201d;). The multimedia content may be, for example, a web page, a document, audio messages, emails, computer programs (e.g., computer viruses), text, and any other multimedia content, as described above. In one embodiment, the latent semantic mapping takes a multimedia content, for example, a web page, and/or a document, and maps that multimedia content into a space that describes relationships between multimedia contents based on data, e.g., words and/or other data (&#x201c;one or more parameters&#x201d;), that correlate with each other in the document. That is, the topic of the multimedia content is driven by relationships between the data representing the multimedia content. To perform the LSM, a training corpus that includes data, e.g., words, paragraphs, sentences, documents, and/or one or more parameters representing legitimate and non-legitimate (&#x201c;explicit&#x201d;) multimedia contents may be formed. In one embodiment, legitimate and explicit multimedia contents may be obtained, for example, from legitimate and explicit web sites. In another embodiment, the legitimate and explicit multimedia contents may be determined by a user. In one embodiment, co-occurrences of the data representing the legitimate and explicit multimedia contents may be determined based on the training corpus. For example, the number of times each word, and/or other data appears in each legitimate and each explicit multimedia content may be recorded to determine the co-occurrences. By leveraging these co-occurrences the multimedia contents may be mapped into corresponding vectors in a continuous vector space. The vectors may characterize the position of the data representing the multimedia contents in this vector space. In one embodiment, the data representing multimedia contents are mapped into corresponding vectors using a Singular Value Decomposition (&#x201c;SVD&#x201d;) technique. The latent semantic mapping using the SVD technique is described in U.S. patent application Ser. No. 09/267,334, which has been issued as U.S. Pat. No. 6,374,217 on Apr. 16, 2002; U.S. patent application Ser. No. 09/967,072, which has been issued as U.S. Pat. No. 7,124,081 on Oct. 17, 2006; U.S. patent application Ser. No. 09/881,986, which has been issued as U.S. Pat. No. 7,076,527 on Jul. 11, 2006; and U.S. patent application Ser. No. 09/688,010, which has been issued as U.S. Pat. No. 7,149,695 on Dec. 12, 2006, which are incorporated here in their entirety by reference.</p>
<p id="p-0044" num="0043">As shown in <figref idref="DRAWINGS">FIG. 2A</figref>, a method <b>200</b> begins with operation <b>201</b> that involves analyzing a multimedia content for one or more parameters. The multimedia content, e.g., a web page, an audio, a video, and any other multimedia content, is analyzed for certain characteristics to determine one or more parameters. The multimedia content may be analyzed for images, visible/non-visible texts, textual and image patterns, references (e.g., links), video, audio, and the like. The one or more parameters may include information about a structure of the multimedia content. The information about the structure of the multimedia content may include information about the size, an amount, and names of images, references, visible text, non-visible text, audio and video in the content. In one embodiment, the multimedia content, e.g., a web page, and any other multimedia content, is analyzed to determine a number of images in the multimedia content. In one embodiment, the multimedia content, e.g. a web page, is analyzed to determine, for example, a number of references (e.g., hypertext links to other web pages or URLs) in the multimedia content. Typically, explicit websites link to a lot of other websites. The multimedia content can be analyzed to determine a number of external links, a number of internal links, a number of broken links in the content. In one embodiment, the multimedia content is analyzed to determine the size of an image, for example, by looking for a total number of image pixels and/or megapixels which are displayed on a web page. An image may include several megapixels. In one embodiment, for example, when the image is resized, only a portion of the megapixels may be shown on the screen. The multimedia content can be analyzed for other characteristics, for example, a relative size of a portion of a screen or web page that is covered by images; names of images; presence of image tags that when the page is composed, provides alternate image to display. For example, a web page may have over 60% of its visible content made up of images, a characteristic that is common to a lot of pornography pages. On the other hand, if an image is a logo, it may occupy only a small portion of the web page. In one embodiment, the multimedia content may be analyzed to determine whether a non-visible text is present. In one embodiment, the multimedia content is analyzed to determine a length of the content. For example, the number of words in a document is determined. In one embodiment, the one or more parameters include a text-to-image ratio. In one embodiment, the one or more parameters include a ratio between the document length and image pixels. In one embodiment, the multimedia content is analyzed to determine the presence of one or more certain textual patterns, for example, &#x201c;USC section 2257&#x201d; or any of its substrings. This textual pattern typically refers to a law code regarding an explicit material, such as adult web sites. In one embodiment, the textual pattern may be a number, e.g., 18. Number 18 may be often used on adult websites to indicate that all models are over age of 18. In another embodiment, the multimedia content is analyzed to take into account the text or other information that is the same color as the background that may be embedded into web pages.</p>
<p id="p-0045" num="0044">Next, operation <b>202</b> is performed that involves filtering the multimedia content based on the one or more parameters using a latent semantic mapping (&#x201c;LSM&#x201d;) filter. In one embodiment, the multimedia content is mapped into a vector space by the LSM filter based on one or more parameters, as described below. In one embodiment, the multimedia content is rated based on the one or more parameters, as described in further detail below.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 2B</figref> shows a block-diagram of one embodiment of an apparatus <b>210</b> to perform multimedia content filtering. Apparatus <b>210</b> is a multimedia content filter that takes as an input a multimedia content and returns whether the multimedia content contains explicit material or not. As shown in <figref idref="DRAWINGS">FIG. 2B</figref>, apparatus <b>210</b> includes an analyzer <b>211</b> and LSM filter <b>212</b>. Input of the analyzer <b>211</b> receives a multimedia content <b>213</b>, e.g., an HTML web page, audio, video, and any other multimedia content. Analyzer <b>211</b> analyzes content <b>213</b> for certain characteristics to determine one or more parameters, as described above. Analyzer <b>211</b> outputs the multimedia content with the one or more parameters <b>214</b> into an LSM filter <b>212</b>. That is, analyzer <b>211</b> provides the multimedia content with the one or more parameters that include the information captured from and analyzed in regard to this multimedia content as an input <b>214</b> to LSM filter <b>212</b>.</p>
<p id="p-0047" num="0046">In one embodiment, the one or more parameters extracted from the multimedia content, e.g., a web page, audio, video, and any other multimedia content, are encapsulated as a tag. For example, if a web page has 10 images, a tag may be turned on that indicates that more than a predetermined amount of images (e.g., five) are in that page. In one embodiment the tag that encapsulates the one or more parameters is a string of characters. In one embodiment, the tag is a string of characters that is considered by LSM filter <b>212</b> as one or more words. The textual nature of the tags makes them amenable to LSM processing no matter what original multimedia content they characterize. As such, the multimedia content characterized by the tags may be a web page, an audio, a video, and any other multimedia content. The tag is inserted into the multimedia content <b>213</b> to provide an input <b>214</b> into LSM filter <b>212</b>. LSM filter <b>212</b> is first trained to recognize a specific set of multimedia contents based on the one or more parameters and then the data collected in the training phase is used to determine the legitimacy of new multimedia contents. Training of LSM filter <b>212</b> includes automatically reconfiguring the filter <b>212</b> based on the observed set of multimedia contents (data) that include one or more parameters. By inserting the tags into the multimedia content that is fed into LSM filter <b>212</b>, the LSM filter <b>212</b> is trained to recognize the multimedia content based on word contents and additional characteristics of the multimedia content. The additional characteristics of the multimedia contents include for example, a structure of the multimedia content, e.g., specific structural patterns of explicit and legitimate multimedia contents. The LSM filter can be trained by being fed with a plurality of multimedia contents including legitimate and non-legitimate (&#x201c;explicit&#x201d;) contents, as described in further detail below and a human can indicate whether the content is one type or the other type in order to train the filter.</p>
<p id="p-0048" num="0047">LSM filter <b>212</b> filters multimedia content <b>213</b> based on the one or more parameters encapsulated into the tag. In one embodiment, filter <b>212</b> uses the tag as a factor in determining a rating of the multimedia content <b>213</b>. In one embodiment, the tags of input <b>214</b> can be weighted to have greater or lesser importance. For example, the textual pattern &#x201c;USC section 2257&#x201d; does not necessarily mean that the content is explicit, but the tag that encapsulates the information about this textual pattern is weighted so that the content receives a certain score towards material that is explicit. In one embodiment, the title of the web page may be weighted more than once, if the title appears in the text representation of the webpage two or three times in comparison with the size of the page. In one embodiment, an API core in LSM filter <b>212</b> allows to weigh a particular word more than once. As shown in <figref idref="DRAWINGS">FIG. 2B</figref>, filter <b>212</b> outputs a filtered multimedia content <b>215</b>, as shown in <figref idref="DRAWINGS">FIG. 2B</figref>. In one embodiment, LSM filter <b>212</b> is trained to recognize the multimedia content based on the one or more parameters.</p>
<p id="p-0049" num="0048">In one embodiment apparatus <b>210</b> is a socket filter, which operates at a kernel level, so it affects all web traffic that goes through a data processing system. In another embodiment, apparatus <b>210</b> is a proxy filter that operates at a proxy server of a data processing system. In yet another embodiment, apparatus <b>210</b> operates at a proxy server and at a kernel level.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 3</figref> shows a block-diagram of one embodiment of an apparatus to perform multimedia content filtering. As shown in <figref idref="DRAWINGS">FIG. 3</figref>, multimedia content <b>301</b>, e.g., an HTML web page, is received by analyzer <b>303</b> and converter <b>302</b>. Converter <b>302</b> is used to convert or otherwise preprocess multimedia content <b>301</b>, e.g, an HTML web page, into a plain text (words) <b>305</b> to obtain significant content out of the multimedia content (e.g., from HTML). For example, all of the typesetting of the web page may be disregarded. In one embodiment, converter <b>302</b> is an HTML stripper which removes HTML code relating to formatting, etc. to extract plain text which is displayed, etc. on the web page. The HTML stripper checks for every tag of the HTML document and retains information that it considers relevant. For example, the HTML stripper may retain the title of the web page, meta tags that include meta information added to the HTML that is usually used by search engines or the Internet, or tools to categorize the page. Such information is useful for the content filter. Because some web pages may be Javascript&#xae; generated, e.g., Google&#xae; images, the Javascript&#xae; strings, for example, text contained in between quotation marks &#x201c; &#x201d;, are retained. In one embodiment, retaining the Javascript&#xae; strings is disabled when an LSM filter is trained, to prevent random strings from being part of the training data which may add noise to the filter evaluation. In one embodiment, the retained Javascript strings are used to add weight to a new multimedia content. Further, all the information regarding the images in the multimedia content is collected, e.g., size and the number of images. Further, the information regarding the number of links is collected.</p>
<p id="p-0051" num="0050">During the conversion, the content <b>301</b> is analyzed for certain characteristics to determine one or more parameters associated with the overall structure of the multimedia content.</p>
<p id="p-0052" num="0051">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, analyzer <b>303</b> is used to analyze the multimedia content <b>301</b> for certain characteristics to determine one or more parameters, as described above. Analyzer <b>303</b> and converter <b>302</b> may be included into one block, or may be in two separate blocks. Analyzer <b>303</b> determines one or more parameters that contain the information about the overall structure of the multimedia content. A tag <b>304</b> is generated that encapsulates the one or more parameters. In one embodiment the tag that encapsulates the one or more parameters is a string of characters, e.g., one or more words. As shown in <figref idref="DRAWINGS">FIG. 3</figref>, tag <b>304</b> is inserted into plain text <b>305</b> in block <b>306</b>. Text <b>305</b> and tag <b>304</b> are represented by tokens <b>307</b>. Tokens <b>307</b> are fed into an LSM filter <b>309</b>, as shown in <figref idref="DRAWINGS">FIG. 3</figref>. Tokens <b>307</b> are mapped as entries (vectors) in vector space <b>310</b>. Tokens that include words and tags are elements of information that are mapped to vector space <b>310</b> of LSM filter <b>309</b>. In one embodiment, each document of the multimedia content is a holder of tokens and each token is essential to hold documents in which it appears, appropriately weighted by the frequency of appearance. That is, documents, words, and tags represented by tokens can be mapped into vector space <b>310</b>. In one embodiment, each word has an entry in vector space <b>310</b> and each document has an entry into vector space <b>310</b>. In one embodiment, tokens represent a multimedia content, e.g., a document, a word in a document, a tag, or any combination thereof.</p>
<p id="p-0053" num="0052">Optionally, certain words, for example, stop words, are removed in block <b>308</b> from the text before feeding to LSM filter <b>309</b>. The term &#x201c;stop word&#x201d; is typically referred to the top <b>100</b> most frequently used words in English, and other most frequently used words on the Internet, e.g., &#x201c;click&#x201d;, &#x201c;password&#x201d;, and the like. Another example of the stop words (reverse stop words) can be the words that are strongly associated with one particular category, for example, a non-legitimate category. For example word &#x201c;sweet&#x201d;, &#x201c;teen&#x201d; can be strongly associated with the non-legitimate category, but could in fact, occur in the legitimate category. The content filter may mistakenly block the multimedia content having such reverse stop words that provides a false positive. The false positive may include a legitimate material, for example, a legitimate web page, that is wrongly classified as an objectionable material. Removing of the reverse stop words can decrease the amount of the false positives and improve the accuracy of the LSM filter when the amount of training data is limited. In one embodiment, block <b>308</b> is included into LSM filter <b>309</b>. In one embodiment, block <b>308</b> is an LSM filter interface.</p>
<p id="p-0054" num="0053">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, LSM filter <b>309</b> includes a vector space <b>310</b>. Vector space <b>310</b> describes the relationship (e.g., the distance) between multimedia contents, e.g., documents, in that space. Tokens <b>307</b> that represent the multimedia content <b>301</b> (e.g., a web page) are mapped as vectors into vector space <b>310</b>. That is, tokens <b>307</b> are mapped into vector space <b>310</b> of LSM filter <b>309</b>, as described in further detail below.</p>
<p id="p-0055" num="0054">In one embodiment, the multimedia content is classified based on the mapping into vector space <b>310</b>, and then the multimedia content is filtered based on the classification, as described in further detail below. In one embodiment, LSM filter <b>309</b> is trained to recognize the multimedia content based on the one or more parameters. Training of the filter <b>309</b> can be performed by analyzing legitimate and non-legitimate (&#x201c;explicit&#x201d;) contents, extracting tokens from these contents, and mapping the tokens into a vector space of the LSM filter <b>309</b>, as described above.</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 4</figref> shows a flowchart of one embodiment of a method to perform multimedia filtering based on one or more parameters using an LSM filter. Method <b>400</b> begins with operation <b>401</b> that involves converting or otherwise processing a multimedia content into a text, as described above.</p>
<p id="p-0057" num="0056">Analyzing the multimedia content for one or more parameters is performed in operation <b>402</b>, as described above. In one embodiment, operation <b>402</b> is performed during operation <b>401</b>. In another embodiment, operation <b>402</b> follows operation <b>401</b>. In yet another embodiment, operation <b>402</b> precedes operation <b>401</b>. Next, at operation <b>403</b>, a tag is generated that encapsulates the one or more parameters, as described above. Further, at operation <b>404</b>, the tag is added into the text to provide tokens for an LSM filter. Optionally, operation <b>405</b> is performed that involves removing one or more stop words from the text before feeding the text to the LSM filter. Next, method <b>400</b> continues with operation <b>406</b> that involves mapping the tokens into a vector space of the LSM filter. Next, method <b>400</b> continues with operation <b>407</b> of filtering of the multimedia content based on the mapping. In one embodiment, the multimedia content is classified using the mapping, and then the multimedia content is filtered based on the classification, as described in further detail below.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 5</figref> illustrates one embodiment of a method to classify a new multimedia content based on mapping into a vector space of an LSM filter. As shown in <figref idref="DRAWINGS">FIG. 5</figref>, a vector space <b>500</b> includes a cluster <b>501</b> and a cluster <b>502</b>. In one embodiment, cluster <b>501</b> includes a plurality of vectors representing legitimate multimedia contents, and cluster <b>502</b> includes a plurality of vectors representing non-legitimate (&#x201c;explicit&#x201d;) multimedia contents. For example, the legitimate multimedia contents may include sex education content. The explicit content may be, for example, adult web sites, hate/violence, gambling web sites, and the like. As shown in <figref idref="DRAWINGS">FIG. 5</figref>, cluster <b>502</b> is positioned in vector space <b>500</b> at a distance <b>506</b> (&#x201c;D1&#x201d;) from cluster <b>501</b>. As described above, tokens that are extracted from a new content are mapped as vectors into vector space <b>500</b>. As shown in <figref idref="DRAWINGS">FIG. 5</figref>, an entity <b>503</b> represents vectors of the new content in vector space <b>500</b>. In one embodiment, the distance between entity <b>503</b> and each of entities <b>501</b> and <b>502</b> is measured. As shown in <figref idref="DRAWINGS">FIG. 5</figref>, entity <b>503</b> is located at a distance <b>504</b> (&#x201c;d1&#x201d;) from cluster <b>501</b> and at a distance <b>505</b> (&#x201c;d2&#x201d;) from cluster <b>502</b>. In one embodiment, distance d<b>1</b> is compared to distance d<b>2</b> to classify the new content. If distance d<b>1</b> is greater than distance d<b>2</b>, the new content is classified as a content that belongs to an explicit content category. If distance d<b>1</b> is shorter than distance d<b>2</b>, the new content is classified as a content that belongs to a legitimate content category.</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 6</figref> shows a flowchart of one embodiment of a method of classify a multimedia content into more than two content categories using an LSM filter. Method <b>600</b> begins with operation <b>601</b> of providing more than two categories to describe a multimedia content. For example, a first category may include the material related to house, food, animals, pets; a second category may include the material related to body parts, clothing, medical, health; a third category may include the material related life, relationships, love issues, recreational activities, ethnicity issues; a fourth category may include an explicit material (e.g., nudity, pornography, hate/violence, and the like); and a fifth category may include any other legitimate material that does not match the previous categories. Method <b>600</b> continues with operation <b>602</b> that involves classifying the multimedia content in more than two categories using a latent semantic filter. The more than two categories may include more than one category for legitimate multimedia content, and one category for explicit content. By training the LSM filter with more than two categories instead of just two categories (explicit vs. legitimate) the occurrence of false positives is significantly reduced, so that the accuracy of the content filter is greatly improved.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 7</figref> illustrates one embodiment of a method to classify a new multimedia content in more than two categories based on mapping into a vector space of an LSM filter. As shown in <figref idref="DRAWINGS">FIG. 7</figref>, a vector space <b>700</b> includes a plurality <b>701</b> of vectors representing multimedia contents of a first legitimate category, a plurality <b>702</b> of vectors representing multimedia contents of a second legitimate category; a plurality <b>703</b> of vectors representing multimedia contents of a third legitimate category; and a plurality <b>704</b> of vectors representing multimedia contents of an explicit category. The explicit content may be, for example, adult web sites, hate/violence, gambling web sites, and the like. The tokens that are extracted from a first new content and a second new content, as described above, are mapped as vectors into vector space <b>700</b>.</p>
<p id="p-0061" num="0060">As shown in <figref idref="DRAWINGS">FIG. 7</figref>, vector <b>705</b> that represents a first new content and vector <b>706</b> that represents a second new content are mapped into vector space <b>700</b>. As shown in <figref idref="DRAWINGS">FIG. 7</figref>, the distances d<b>1</b>-d<b>4</b> between the vector <b>705</b> and each of the pluralities <b>701</b>-<b>704</b> are determined. As shown in <figref idref="DRAWINGS">FIG. 7</figref>, the distance d<b>1</b> is the shortest out of distances d<b>1</b>-d<b>4</b>. The new content having vector <b>705</b> is classified to be in the explicit content category based on the shortest distance d<b>1</b>. As shown in <figref idref="DRAWINGS">FIG. 7</figref>, the distances d<b>5</b>-d<b>8</b> between vector <b>706</b> and each of the pluralities <b>701</b>-<b>704</b> are determined. As shown in <figref idref="DRAWINGS">FIG. 7</figref>, the distance d<b>6</b> is the shortest out of distances d<b>5</b>-d<b>8</b>. The new content having vector <b>706</b> is classified to be in the first legitimate content category based on the shortest distance d<b>6</b>. Using more than two categories to classify the multimedia content trains the LSM filter to recognize the multimedia content that it wasn't able to recognize using only two categories (e.g., a legitimate category and an explicit category). That is, use of more than categories helps to define boundaries of the category in vector space <b>700</b> with substantially higher accuracy than just using a single legitimate category and a single explicit category. In one embodiment, using multiple legitimate categories to classify the multimedia content trains the LSM filter to recognize the legitimate multimedia content that it wasn't able to recognize as a legitimate with a single legitimate category. That is, use of multiple legitimate categories helps to define boundaries of the explicit category in vector space <b>700</b> with substantially higher accuracy than just using a single legitimate category. In another embodiment, an explicit multimedia content is classified in a plurality of categories, for example, porn, gambling, violence, and the like, to increase accuracy of defining of the content in vector space <b>700</b>. In yet another embodiment, a legitimate multimedia content is classified in a plurality of categories, and an explicit multimedia content is classified in a plurality of categories, to increase accuracy of defining the content in vector space <b>700</b>.</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 8</figref> illustrates one embodiment of a user interface <b>800</b> for content filter options. Interface <b>800</b> includes &#x201c;on&#x201d; <b>801</b>, automatic <b>802</b>, con<figref idref="DRAWINGS">figure 803</figref>, training <b>804</b>, and reset <b>805</b>, all of which may be items that the user may optionally select. The content filter options provides the menu item &#x201c;ON&#x201d; <b>801</b> to allow the user to request that the content filter be turned on to try to block an undesired content.</p>
<p id="p-0063" num="0062">The interface <b>800</b> has the menu item automatic <b>802</b> to allow the user to request that the content filter is put into automatic mode. While in automatic mode, the content filter automatically classifies the multimedia content, and takes appropriate actions based on the classifying, as described above.</p>
<p id="p-0064" num="0063">The user interface <b>800</b> has the menu item training <b>804</b> to allow the user to request that the content filter to be put into a training mode. While in training mode, the content filter is trained to recognize the kind of multimedia content that the user considers to filter out, as described above.</p>
<p id="p-0065" num="0064">The user interface <b>800</b> has the menu item reset <b>805</b> to allow the user to request that the training of the content filter is reset to initial factory settings. The reset <b>805</b> causes the content filter to undo all of the previous training. In one embodiment, the training data may be deleted. In another embodiment, the training data may be kept but ignored.</p>
<p id="p-0066" num="0065">The content filter user interface <b>800</b> has the menu item con<figref idref="DRAWINGS">figure 803</figref> to allow the user to specify the content (e.g., web sites) that the user wants to accept and sites that the user wants to block.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 9</figref> illustrates a user interface <b>900</b> that displays when the menu item con<figref idref="DRAWINGS">figure 803</figref> depicted in <figref idref="DRAWINGS">FIG. 8</figref> is checked. User interface <b>900</b> has a list of references (links, names, and the like) to multimedia contents (e.g., web sites) <b>901</b>, <b>902</b>, <b>903</b>, <b>904</b>. As shown in <figref idref="DRAWINGS">FIG. 9</figref>, two check boxes <b>905</b> and <b>906</b> are displayed next to each of the references <b>901</b>-<b>904</b>. Check box <b>905</b> is checked when the user wants the content to be accepted by the content filter. Check box <b>906</b> is checked when the user wants the content to be blocked by the content filter, as shown in <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0068" num="0067">Referring back to <figref idref="DRAWINGS">FIG. 8</figref>, interface <b>800</b> has button <b>806</b> to access to a blocked multimedia content. In one embodiment, a list of references (e.g., links, names) to multimedia contents that have been visiting most frequently and the list of references to the multimedia contents that have been blocked are stored in a memory. In one embodiment, if the list of most frequently accessed multimedia contents contains an undesirable content, the undesirable content may be automatically added to a &#x201c;black list&#x201d;. In one embodiment, the multimedia content added to the &#x201c;black list&#x201d; is provided to train the content filter.</p>
<p id="p-0069" num="0068">In one embodiment, if a user tries to access the multimedia content, e.g., a web site, that is blocked, then the user presses button <b>806</b>. A message asking for a password can be displayed in response to pressing button <b>806</b>.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 10</figref> illustrates one embodiment of a user interface that requires a password from a user to access a multimedia content that has been blocked by a content filter. As shown in <figref idref="DRAWINGS">FIG. 10</figref>, the user interface includes a message <b>1001</b> &#x201c;The site is automatically blocked. Please provide your password to unblock the site.&#x201d; Password box <b>1002</b> is displayed, so the user can type in the password to unblock the blocked content. In one embodiment, the blocked multimedia content is automatically added to a list of acceptable contents (&#x201c;white list&#x201d;) in response to providing the password. In one embodiment, reference to the added content is displayed on user interface <b>900</b>. In one embodiment, the unblocked multimedia content is provided to train the content filter, as described below.</p>
<p id="p-0071" num="0070">Referring back to <figref idref="DRAWINGS">FIG. 6</figref>, at operation <b>603</b>, a determination is made whether the multimedia content belong to a legitimate content category. If the multimedia content belongs to a legitimate content category, the multimedia content is provided to a user at operation <b>604</b>. Optionally, a reference, e.g., a link, to the multimedia content provided to the user may be stored in a memory at operation <b>605</b>. In one embodiment, a tag to this multimedia content is stored in a memory. In one embodiment, the multimedia content provided to the user in operation <b>603</b> may be added to a legitimate content list (&#x201c;white list&#x201d;), be used to train the LSM filter, or both. In another embodiment, the multimedia content initially provided to the user in operation <b>603</b> in response to a user request may be added to an explicit content list (&#x201c;black list&#x201d;), be used to train the LSM filter, or both.</p>
<p id="p-0072" num="0071">If the multimedia content belongs to an explicit category, the multimedia content is blocked at operation <b>606</b>. Optionally, a reference, e.g., a link, to the blocked multimedia content is stored in a memory at operation <b>607</b>. In one embodiment, the tag to the multimedia content is stored a memory. In one embodiment, the multimedia content blocked in operation <b>606</b> may be added to the &#x201c;black list&#x201d;, be used to train the LSM filter, or both. Next, at operation <b>608</b>, a determination is made whether a request from a user is received to accept the blocked content. If the request is received, an optional operation <b>609</b> can be performed that involves accepting the blocked multimedia content in response to the user's request. The previously blocked multimedia content can be provided to the user at operation <b>604</b> in response to the user request. Next, an optional operation <b>610</b> can be performed that involves adding the initially blocked at operation <b>606</b> multimedia content to a legitimate content list &#x201c;white list&#x201d; in response to the user request. In one embodiment, the initially blocked in operation <b>606</b> multimedia content in response to the user request may be added to the &#x201c;white list&#x201d;, be used to train the LSM filter, or both.</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. 11</figref> shows a flowchart of another embodiment of a method of classifying a multimedia content using an LSM filter. Method <b>1100</b> begins with operation <b>1101</b> that involves training a latent semantic filter by looking at a plurality of multimedia contents (including explicit and legitimate multimedia contents), as described above. Next, method continues with operation <b>1102</b> that involves extracting one or more first parameters from each of the multimedia contents, as described above. The multimedia contents are mapped into a vector space of an LSM filter based on the one or more first parameters at operation <b>1103</b>, as described above. Next, operation <b>1104</b> is performed that involves receiving a new multimedia content. In operation <b>1105</b>, the new multimedia content is pre-processed to obtain one or more second parameters. Next, operation <b>1106</b> that involves mapping the new multimedia content into a vector space of LSM filter is performed based on one or more second parameters. Method continues with operation <b>1107</b> is performed that involves determining a category of the new multimedia content based on the mapping. Further, a determination is made whether the new multimedia content belongs to an explicit content category at operation <b>1108</b>. If the new multimedia content does not belong to the explicit content category, the multimedia content is provided to a user in operation <b>1109</b>. If the new multimedia content is determined to belong to the explicit category, the new multimedia content is blocked in operation <b>1110</b>.</p>
<p id="p-0074" num="0073">In the foregoing specification, embodiments of the invention have been described with reference to specific exemplary embodiments thereof. It will be evident that various modifications may be made thereto without departing from the broader spirit and scope of the invention. The specification and drawings are, accordingly, to be regarded in an illustrative sense rather than a restrictive sense.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method, comprising:
<claim-text>analyzing, by one or more processing devices, a web page content for predetermined parameters, wherein at least one of the predetermined parameters is based on an image media content;</claim-text>
<claim-text>generating a tag that encapsulates the at least one predetermined parameter;</claim-text>
<claim-text>processing the web page content to provide text representing the web page Content;</claim-text>
<claim-text>inserting the tag into the text to provide tokens;</claim-text>
<claim-text>inputting the tokens into a latent semantic mapping (LSM) filter;</claim-text>
<claim-text>mapping the tokens into a vector space of the latent semantic mapping filter:</claim-text>
<claim-text>analyzing, by the one or more processing devices, the web page content using the latent semantic mapping filter wherein the vector space of the latent semantic mapping filter includes a first plurality of vectors at a first location and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and at least one input into the latent semantic mapping filter comprises one or more representations of the web page content that are mapped to a third location in the vector space;</claim-text>
<claim-text>determining, by the one or more processing devices, distances between</claim-text>
<claim-text>the third location and the first location, and</claim-text>
<claim-text>the third location and the second location; and</claim-text>
<claim-text>filtering, by the one or more processing devices, the web page content based on the determined distances.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined parameters include information about a structure of the web page content.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined parameters include information relating to a number of references.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined parameters include information relating to a number of images.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined parameters include information relating to a length of the web page content.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined parameters includes a textual pattern.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising rating the web page content based on the predetermined parameters.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the web page content includes an executable script from which text is extracted in processing the web page content.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising
<claim-text>training the LSM filter to recognize the web page content based on the predetermined parameters.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A method, comprising:
<claim-text>analyzing a multimedia content for one or more parameters;</claim-text>
<claim-text>generating one or more tags associated with the one or more parameters;</claim-text>
<claim-text>providing the one or more tags to a latent semantic (LSM) filter;</claim-text>
<claim-text>providing, by one or more processing devices, a vector space having at least two categories for the multimedia content, the vector space comprising a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein one or more representations of a new multimedia content are mapped to a third location in the vector space;</claim-text>
<claim-text>determining by the one or more processing devices distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>classifying, by the one or more processing devices, a new multimedia content based on the distances determined.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the at least two categories is any combination of an explicit content category and a first plurality of legitimate content categories, a legitimate content category and a second plurality of explicit content categories, or a third plurality of explicit content categories and a fourth plurality of legitimate content categories.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising
<claim-text>blocking the multimedia content based on the classifying.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising
<claim-text>storing a reference to the multimedia content.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising
<claim-text>accepting the multimedia content; and</claim-text>
<claim-text>adding the accepted multimedia content to a list to train the latent semantic filter.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A method to classify a multimedia content, comprising:
<claim-text>processing, by one or more processing devices, the multimedia content to</claim-text>
<claim-text>provide text for an analysis of the multimedia content;</claim-text>
<claim-text>analyzing, by the one or more processing devices, the multimedia content for predetermined parameters, wherein at least one of the predetermined parameters is based on image media content;</claim-text>
<claim-text>generating, by the one or more processing devices, a tag that encapsulates at least one of the predetermined parameters;</claim-text>
<claim-text>associating, by the one or more processing devices, the tag with the text to provide one or more tokens; and</claim-text>
<claim-text>mapping, by the one or more processing devices, the one or more tokens into a vector space containing a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein the one or more tokens are mapped into a third location in the vector space;</claim-text>
<claim-text>determining by the one or more processing devices distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>determining, by the one or more processing devices, whether to filter the multimedia content based on the distances.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the tag includes a string of characters.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the processing includes
<claim-text>extracting strings within an executable script.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further including
<claim-text>removing one or more stop words from the text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising
<claim-text>filtering the multimedia content based on the mapping.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. An article of manufacture comprising:
<claim-text>a non-transitory machine-accessible storage medium storing data that, when accessed by a machine, cause the machine to perform operations comprising:</claim-text>
<claim-text>analyzing a web page content for predetermined parameters, wherein at least one of the predetermined parameters is based on an image media content;</claim-text>
<claim-text>generating a tag that encapsulates the at least one predetermined parameter;</claim-text>
<claim-text>processing the web page content to provide text representing the web page content;</claim-text>
<claim-text>inserting the tag into the text to provide tokens;</claim-text>
<claim-text>inputting the tokens into a latent semantic mapping (LSM) filter;</claim-text>
<claim-text>mapping the tokens into a vector space of the latent semantic mapping filter;</claim-text>
<claim-text>analyzing the web page content using a latent semantic mapping filter, wherein the latent semantic mapping filter comprises a vector space containing a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and</claim-text>
<claim-text>wherein at least one input into the latent semantic mapping filter comprises one or more representations of the web page content that are mapped to a third location in a vector space;</claim-text>
<claim-text>determining distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>determining whether to filter the web page content based on the distances.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the predetermined parameters include information about a structure of the web page content.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the predetermined parameters include information relating to a number of references.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the predetermined parameters include information relating to a number of images.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the predetermined parameters include information relating to a length of the web page content.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the predetermined parameters includes a textual pattern.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the machine-accessible medium further includes data that cause the machine to perform operations comprising,
<claim-text>rating the web page content based on the predetermined parameters.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the web page content includes an executable script from which text is extracted in processing the web page content.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The article of manufacture of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the machine-accessible medium further includes data that cause the machine to perform operations comprising,
<claim-text>training the LSM filter to recognize the web page content based on the predetermined parameters.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. An article of manufacture comprising:
<claim-text>a non-transitory machine-accessible storage medium storing data that, when accessed by a machine, cause the machine to perform operations comprising:</claim-text>
<claim-text>analyzing a multimedia content for one or more parameters;</claim-text>
<claim-text>generating one or more tags associated with the one or more parameters;</claim-text>
<claim-text>providing the one or more tags to a latent semantic (LSM) filter;</claim-text>
<claim-text>providing a vector space having at least two categories for the multimedia content, the vector space comprising a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein one or more representations of a new multimedia content are mapped to a third location in the vector space;</claim-text>
<claim-text>determining distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>classifying a new multimedia content based on the distances determined.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The article of manufacture of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the at least two categories is any combination of an explicit content category and a first plurality of legitimate content categories, a legitimate content category and a second plurality of explicit content categories, or a third plurality of explicit content categories and a fourth plurality of legitimate content categories.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The article of manufacture of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the machine-accessible medium further includes data that cause the machine to perform operations comprising,
<claim-text>blocking the multimedia content based on the classifying.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The article of manufacture of <claim-ref idref="CLM-00029">claim 29</claim-ref>, further comprising
<claim-text>storing a reference to the multimedia content.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The article of manufacture of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the machine-accessible medium further includes data that cause the machine to perform operations comprising,
<claim-text>accepting the multimedia content; and</claim-text>
<claim-text>adding the accepted multimedia content to a list to train the latent semantic filter.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. An article of manufacture comprising:
<claim-text>a non-transitory machine-accessible storage medium storing data that, when accessed by a machine, cause the machine to perform operations to classify a multimedia content, comprising:</claim-text>
<claim-text>processing the multimedia content to provide text for an analysis of the multimedia content;</claim-text>
<claim-text>analyzing the multimedia content for predetermined parameters, wherein at least one parameter is based on image media content;</claim-text>
<claim-text>generating a tag that encapsulates at least one of the predetermined parameters;</claim-text>
<claim-text>associating the tag with the text to provide one or more tokens; and</claim-text>
<claim-text>mapping the one or more tokens into a vector space containing a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein the one or more tokens are mapped into a third location in the vector space;</claim-text>
<claim-text>determining distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>determining whether to filter the multimedia content based on the distances.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. The article of manufacture of <claim-ref idref="CLM-00034">claim 34</claim-ref>, wherein the tag includes a string of characters.</claim-text>
</claim>
<claim id="CLM-00036" num="00036">
<claim-text>36. The article of manufacture of <claim-ref idref="CLM-00034">claim 34</claim-ref>, wherein the processing includes extracting strings within an executable script.</claim-text>
</claim>
<claim id="CLM-00037" num="00037">
<claim-text>37. The article of manufacture of <claim-ref idref="CLM-00034">claim 34</claim-ref>, wherein the machine-accessible medium further includes data that cause the machine to perform operations comprising,
<claim-text>removing one or more stop words from the text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00038" num="00038">
<claim-text>38. The article of manufacture of <claim-ref idref="CLM-00034">claim 34</claim-ref>, wherein the machine-accessible medium further includes data that cause the machine to perform operations comprising,
<claim-text>filtering the multimedia content based on the mapping.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00039" num="00039">
<claim-text>39. A computer system, comprising:
<claim-text>a bus;</claim-text>
<claim-text>a data storage device coupled to the bus;</claim-text>
<claim-text>one or more processing devices coupled to the data storage device, wherein the data storage device stores instructions executed by the one or more processing devices to perform operations, comprising:</claim-text>
<claim-text>analyzing a web page content for predetermined parameters, wherein at least one parameter is based on an image media content;</claim-text>
<claim-text>generating a tag that encapsulates the at least one parameter;</claim-text>
<claim-text>processing the web page content to provide text for an analysis of the web page content;</claim-text>
<claim-text>inserting the tag into the text to provide tokens;</claim-text>
<claim-text>mapping the tokens into a vector space of a latent semantic mapping filter;</claim-text>
<claim-text>analyzing the web page content using the latent semantic mapping filter, wherein the latent semantic mapping filter comprises a vector space containing a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein at least one input into the latent semantic mapping filter comprises one or more representations of the image media content that are mapped to a third location in the vector space;</claim-text>
<claim-text>determining distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>determining whether to filter the web page content based the distances.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00040" num="00040">
<claim-text>40. The system of <claim-ref idref="CLM-00039">claim 39</claim-ref>, wherein the web page content includes an executable script from which text is extracted in processing the web page content.</claim-text>
</claim>
<claim id="CLM-00041" num="00041">
<claim-text>41. The system of <claim-ref idref="CLM-00039">claim 39</claim-ref>, wherein the one or more processing devices further performing operations, comprising:
<claim-text>training the LSM filter to recognize the web page content based on the predetermined parameters.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00042" num="00042">
<claim-text>42. A computer system, comprising:
<claim-text>a bus;</claim-text>
<claim-text>a data storage device coupled to the bus;</claim-text>
<claim-text>one or more processing devices coupled to the storage device, wherein the storage device stores instructions executed by the one or more processing devices to perform operations, comprising;</claim-text>
<claim-text>analyzing a multimedia content for one or more parameters;</claim-text>
<claim-text>generating one or more tags associated with the one or more parameters;</claim-text>
<claim-text>providing the one or more tags to a latent semantic (LSM) filter;</claim-text>
<claim-text>providing a vector space having at least two categories for the multimedia content, the vector space comprising a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein one or more representations of a new multimedia content are mapped to a third location in the vector space;</claim-text>
<claim-text>determining distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>classifying a new multimedia content based on distances determined.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00043" num="00043">
<claim-text>43. The system of <claim-ref idref="CLM-00042">claim 42</claim-ref>, wherein the at least two categories is any combination of an explicit content category and a first plurality of legitimate content categories, a legitimate content category and a second plurality of explicit content categories, or a third plurality of explicit content categories and a fourth plurality of legitimate content categories.</claim-text>
</claim>
<claim id="CLM-00044" num="00044">
<claim-text>44. The system of <claim-ref idref="CLM-00043">claim 43</claim-ref>, wherein the one or more processing devices further performing operations, comprising:
<claim-text>blocking the multimedia content based on the classifying.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00045" num="00045">
<claim-text>45. A computer system to classify a multimedia content, comprising:
<claim-text>a bus;</claim-text>
<claim-text>a data storage device coupled to the bus;</claim-text>
<claim-text>one or more processing devices coupled to the data storage device, wherein the data storage device stores instructions executed by the one or more processing devices to perform operations, comprising:</claim-text>
<claim-text>processing the multimedia content to provide text for analysis of the multimedia content;</claim-text>
<claim-text>analyzing the multimedia content for predetermined parameters, wherein at least one of the predetermined parameters is based on image media content;</claim-text>
<claim-text>generating a tag that encapsulates the at least one of the predetermined parameters;</claim-text>
<claim-text>associating the tag with the text to provide one or more tokens; and</claim-text>
<claim-text>mapping the one or more tokens into a vector space containing a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein the one or more tokens are mapped into a third location in the vector space;</claim-text>
<claim-text>determining distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>determining whether to filter the multimedia content based on the distances.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00046" num="00046">
<claim-text>46. The system of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the processing includes
<claim-text>extracting strings within an executable script.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00047" num="00047">
<claim-text>47. The system of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the processing includes
<claim-text>removing one or more stop words from the text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00048" num="00048">
<claim-text>48. A method, comprising:
<claim-text>processing, by one or more processing devices, multimedia content to provide processed content for use by a latent semantic mapping filter;</claim-text>
<claim-text>analyzing the multimedia content for predetermined parameters;</claim-text>
<claim-text>generating a tag that encapsulates at least one of the predetermined parameters;</claim-text>
<claim-text>processing the multimedia content to provide text representing the multimedia content;</claim-text>
<claim-text>inserting the tag into the text to provide tokens;</claim-text>
<claim-text>inputting the tokens into the latent semantic mapping filter;</claim-text>
<claim-text>mapping the tokens into a vector space of the latent semantic mapping filter;</claim-text>
<claim-text>classifying, by the one or more processing devices, the processed content with the latent semantic mapping filter including the vector space, the vector space having at least two categories for the multimedia content, the vector space comprising a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein one or more representations of the multimedia content are mapped to a third location in the vector space and wherein distances between the third location and the first location, and the third location and the second location; and</claim-text>
<claim-text>determining, by the one or more processing devices, whether to filter the multimedia content based upon the classifying.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00049" num="00049">
<claim-text>49. An article of manufacture, comprising:
<claim-text>a non-transitory machine-readable storage medium storing executable program instructions which when executed by a data processing system cause the system to perform operations comprising:</claim-text>
<claim-text>processing multimedia content to provide processed content for use by a latent semantic mapping filter; analyzing the multimedia content for predetermined parameters;</claim-text>
<claim-text>generating a tag that encapsulates at least one of the predetermined parameters;</claim-text>
<claim-text>processing the multimedia content to provide text representing the multimedia content;</claim-text>
<claim-text>inserting the tag into the text to provide tokens;</claim-text>
<claim-text>inputting the tokens into the latent semantic mapping filter;</claim-text>
<claim-text>mapping the tokens into a vector space of the latent semantic mapping filter;</claim-text>
<claim-text>classifying the processed content with the latent semantic mapping filter including the vector space, the vector space having at least two categories for the multimedia content, the vector space comprising a first plurality of vectors at a first location, and a second plurality of vectors at a second location, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein one or more representations of the multimedia content are mapped to a third location in the vector space and wherein distances between the third location and the first location, and the third location and the second location are determined; and</claim-text>
<claim-text>determining whether to filter the multimedia content based upon the classifying.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00050" num="00050">
<claim-text>50. A method, comprising:
<claim-text>presenting a user interface on a display device;</claim-text>
<claim-text>receiving, by one or more processing devices, input from the user interface;</claim-text>
<claim-text>placing, by the one or more processing devices, a latent semantic mapping filter of a web page content to operate in a training mode to recognize which kind of multimedia content to filter out in response to the input from the user interface;</claim-text>
<claim-text>analyzing, by the one or more processing devices, the web page content for predetermined parameters;</claim-text>
<claim-text>generating a tag that encapsulates at least one predetermined parameter;</claim-text>
<claim-text>processing the web page content to provide text representing the web page content;</claim-text>
<claim-text>inserting the tag into the text to provide tokens;</claim-text>
<claim-text>inputting the tokens into the latent semantic mapping filter; and</claim-text>
<claim-text>mapping the tokens into a vector space of the latent semantic mapping filter;</claim-text>
<claim-text>wherein the latent semantic mapping filter includes a first plurality of vectors at a first location in a vector space, and a second plurality of vectors at a second location in the vector space, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein one or more representations of the web page content are mapped to a third location in the vector space, and wherein distances between the third location and the first location, and the third location and the second location are determined to recognize the multimedia content.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00051" num="00051">
<claim-text>51. The method as in <claim-ref idref="CLM-00050">claim 50</claim-ref>, wherein the presenting is in response to receiving data relating to a web page.</claim-text>
</claim>
<claim id="CLM-00052" num="00052">
<claim-text>52. The method as in <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the training mode comprises modifying parameters of the latent semantic mapping filter.</claim-text>
</claim>
<claim id="CLM-00053" num="00053">
<claim-text>53. An article of manufacture, comprising:
<claim-text>a non-transitory machine-readable storage medium storing executable program instructions which when executed by a data processing system cause the system to perform operations comprising:</claim-text>
<claim-text>presenting a user interface;</claim-text>
<claim-text>receiving input from the user interface; and</claim-text>
<claim-text>placing a latent semantic mapping filter of a web page content to operate in a training mode to recognize which kind of multimedia content to filter out in response to the input from the user interface;</claim-text>
<claim-text>analyzing the web page content for predetermined parameters;</claim-text>
<claim-text>generating a tag that encapsulates at least one predetermined parameter;</claim-text>
<claim-text>processing the web page content to provide text representing the web page content;</claim-text>
<claim-text>inserting the tag into the text to provide tokens;</claim-text>
<claim-text>inputting the tokens into the latent semantic mapping filter; and</claim-text>
<claim-text>mapping the tokens into a vector space of the latent semantic mapping filter;</claim-text>
<claim-text>wherein the latent semantic mapping filter includes a first plurality of vectors at a first location in a vector space, and a second plurality of vectors at a second location in the vector space, wherein the first location comprises materials related to predefined legitimate multimedia content, the second location comprises materials related to predefined explicit multimedia content, and wherein one or more representations of the web page content are mapped to a third location in the vector space, and wherein distances between the third location and the first location, and the third location and the second location are determined to recognize the multimedia content.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
