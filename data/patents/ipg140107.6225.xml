<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627350-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627350</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13685205</doc-number>
<date>20121126</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>167</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>725 31</main-classification>
<further-classification>725116</further-classification>
<further-classification>725117</further-classification>
<further-classification>725145</further-classification>
<further-classification>725146</further-classification>
<further-classification>725147</further-classification>
<further-classification>725115</further-classification>
<further-classification>380239</further-classification>
</classification-national>
<invention-title id="d2e51">Systems and method for determining visual media information</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5541662</doc-number>
<kind>A</kind>
<name>Adams</name>
<date>19960700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6138147</doc-number>
<kind>A</kind>
<name>Weaver</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6282713</doc-number>
<kind>B1</kind>
<name>Kitsukawa</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6373960</doc-number>
<kind>B1</kind>
<name>Conover</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6490405</doc-number>
<kind>B1</kind>
<name>Speed et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6970640</doc-number>
<kind>B2</kind>
<name>Green</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7218635</doc-number>
<kind>B2</kind>
<name>Haddad</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2002/0032906</doc-number>
<kind>A1</kind>
<name>Grossman</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2002/0078467</doc-number>
<kind>A1</kind>
<name>Rosin</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2003/0156342</doc-number>
<kind>A1</kind>
<name>Yap</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2003/0159143</doc-number>
<kind>A1</kind>
<name>Chan</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2004/0008970</doc-number>
<kind>A1</kind>
<name>Junkersfeld</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2005/0185795</doc-number>
<kind>A1</kind>
<name>Song</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2006/0047967</doc-number>
<kind>A1</kind>
<name>Akhan</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2006/0153296</doc-number>
<kind>A1</kind>
<name>Deng</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2006/0156358</doc-number>
<kind>A1</kind>
<name>Adolph</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2007/0186228</doc-number>
<kind>A1</kind>
<name>Ramaswamy</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2007/0266414</doc-number>
<kind>A1</kind>
<name>Kahn</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2007/0271300</doc-number>
<kind>A1</kind>
<name>Ramaswamy</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2007/0294738</doc-number>
<kind>A1</kind>
<name>Kuo</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2009/0083781</doc-number>
<kind>A1</kind>
<name>Yang</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>WO</country>
<doc-number>WO-2005/079501</doc-number>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11940841</doc-number>
<date>20071115</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8365214</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13685205</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130083923</doc-number>
<kind>A1</kind>
<date>20130404</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>AT&#x26;T Intellectual Property I, LP</orgname>
<address>
<city>Atlanta</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Soo</last-name>
<first-name>Armstrong</first-name>
<address>
<city>San Ramon</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Ku</last-name>
<first-name>Bernard</first-name>
<address>
<city>Austin</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Li</last-name>
<first-name>Zhi</first-name>
<address>
<city>Martinez</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Guntin &#x26; Gust, PLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Gust</last-name>
<first-name>Andrew</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>AT&#x26;T Intellectual Property I, LP</orgname>
<role>02</role>
<address>
<city>Atlanta</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Chung</last-name>
<first-name>Jason J</first-name>
<department>2423</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A processor is configured to receive a digital video stream, calculate a hash of an I-Frame within the digital video stream, and submit the hash to a server. The processor is further configured to receive location information in response to submitting the hash to the server.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="166.62mm" wi="103.04mm" file="US08627350-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="240.28mm" wi="187.11mm" file="US08627350-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="165.35mm" wi="156.97mm" file="US08627350-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="157.65mm" wi="128.78mm" file="US08627350-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="182.63mm" wi="108.97mm" file="US08627350-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="176.19mm" wi="107.70mm" file="US08627350-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="151.21mm" wi="84.58mm" file="US08627350-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="233.26mm" wi="169.16mm" file="US08627350-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of and claims priority to U.S. patent application Ser. No. 11/940,841 filed Nov. 15, 2007 which is incorporated herein by reference in its entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE DISCLOSURE</heading>
<p id="p-0003" num="0002">The present disclosure generally relates to communications networks, and more particularly relates to systems and methods for determining visual media information.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE DISCLOSURE</heading>
<p id="p-0004" num="0003">Consumers today enjoy a wide variety of video sources including broadcast television, video on demand, streaming video, and physical media such as DVDs. The widespread use of digital video recorders (DVRs) enables consumers to view video content at a time convenient for the consumer rather than when the video content is broadcast. More recently, video enabled mobile devices, such as cellular telephones and portable media players, have enabled consumers to view video content at virtually any location. Traditional ways of determining popular content, such as measuring the number of viewers tuned into a channel when a program is broadcast, are difficult or impossible to adapt to time-shifted and mobile viewing habits.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0005" num="0004">It will be appreciated that for simplicity and clarity of illustration, elements illustrated in the Figures have not necessarily been drawn to scale. For example, the dimensions of some of the elements are exaggerated relative to other elements. Embodiments incorporating teachings of the present disclosure are shown and described with respect to the drawings presented herein, in which:</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating an Internet Protocol Television (IPTV) network in accordance with one embodiment of the present disclosure;</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a digital video stream;</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating a system for determining a location within a digital video stream;</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 4</figref> is a flow diagram illustrating a method for determining a location within a digital video stream;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 5</figref> is a flow diagram illustrating a method for determining a location within a digital video stream during playback;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 6</figref> is a flow diagram illustrating a method for providing a location within a digital video stream; and</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 7</figref> is an illustrative embodiment of a general computer system.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0013" num="0012">The use of the same reference symbols in different drawings indicates similar or identical items.</p>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013">The numerous innovative teachings of the present application will be described with particular reference to the presently preferred exemplary embodiments. However, it should be understood that this class of embodiments provides only a few examples of the many advantageous uses of the innovative teachings herein. In general, statements made in the specification of the present application do not necessarily delimit any of the various claimed inventions. Moreover, some statements may apply to some inventive features but not to others.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> shows an IPTV system <b>100</b> including a client facing tier <b>102</b>, an application tier <b>104</b>, an acquisition tier <b>106</b>, and an operations and management tier <b>108</b>. Each tier <b>102</b>, <b>104</b>, <b>106</b>, and <b>108</b> is coupled to one or both of a private network <b>110</b> and a public network <b>112</b>. For example, the client-facing tier <b>102</b> can be coupled to the private network <b>110</b>, while the application tier <b>104</b> can be coupled to the private network <b>110</b> and to the public network <b>112</b> such as the Internet. The acquisition tier <b>106</b> can also be coupled to the private network <b>110</b> and to the public network <b>112</b>. Moreover, the operations and management tier <b>108</b> can be coupled to the public network <b>112</b>.</p>
<p id="p-0016" num="0015">The various tiers <b>102</b>, <b>104</b>, <b>106</b>, and <b>108</b> communicate with each other via the private network <b>110</b> and the public network <b>112</b>. For instance, the client-facing tier <b>102</b> can communicate with the application tier <b>104</b> and the acquisition tier <b>106</b> via the private network <b>110</b>. The application tier <b>104</b> can also communicate with the acquisition tier <b>106</b> via the private network <b>110</b>. Further, the application tier <b>104</b> can communicate with the acquisition tier <b>106</b> and the operations and management tier <b>108</b> via the public network <b>112</b>. Moreover, the acquisition tier <b>106</b> can communicate with the operations and management tier <b>108</b> via the public network <b>112</b>. In a particular embodiment, elements of the application tier <b>104</b> can communicate directly with the client-facing tier <b>102</b>.</p>
<p id="p-0017" num="0016">The client-facing tier <b>102</b> can communicate with user equipment via a private access network <b>166</b>, such as an Internet Protocol Television (IPTV) network. In an illustrative embodiment, modems such as a first modem <b>114</b> and a second modem <b>122</b> can be coupled to the private access network <b>166</b>. The client-facing tier <b>102</b> can communicate with a first representative set-top box (STB) device <b>116</b> via the first modem <b>114</b> and with a second representative set-top box device <b>124</b> via the second modem <b>122</b>. The client-facing tier <b>102</b> can communicate with a large number of set-top boxes over a wide geographic area, such as a regional area, a metropolitan area, a viewing area, or any other suitable geographic area that can be supported by networking the client-facing tier <b>102</b> to numerous set-top box devices. In one embodiment, the client-facing tier <b>102</b> can be coupled to the modems <b>114</b> and <b>122</b> via fiber optic cables. Alternatively, the modems <b>114</b> and <b>122</b> can be digital subscriber line (DSL) modems that are coupled to one or more network nodes via twisted pairs, and the client-facing tier <b>102</b> can be coupled to the network nodes via fiber-optic cables. Each set-top box device <b>116</b> and <b>124</b> can process data received from the private access network <b>166</b> via an IPTV software platform such as Microsoft.&#xae;. TV IPTV Edition.</p>
<p id="p-0018" num="0017">The first set-top box device <b>116</b> can be coupled to a first display device <b>118</b>, such as a first television monitor, and the second set-top box device <b>124</b> can be coupled to a second display device <b>126</b>, such as a second television monitor. Moreover, the first set-top box device <b>116</b> can communicate with a first remote control <b>120</b>, and the second set-top box device can communicate with a second remote control <b>128</b>. In an exemplary, non-limiting embodiment, each set-top box device <b>116</b> and <b>124</b> can receive data or video from the client-facing tier <b>102</b> via the private access network <b>166</b> and render or display the data or video at the display device <b>118</b> or <b>126</b> to which it is coupled. The set-top box devices <b>116</b> and <b>124</b> thus may include tuners that receive and decode television programming information for transmission to the display devices <b>118</b> and <b>126</b>. Further, the set-top box devices <b>116</b> and <b>124</b> can include an STB processor <b>170</b> and an STB memory device <b>172</b> that is accessible to the STB processor. In a particular embodiment, the set-top box devices <b>116</b> and <b>124</b> can also communicate commands received from the remote controls <b>120</b> and <b>128</b> back to the client-facing tier <b>102</b> via the private access network <b>166</b>.</p>
<p id="p-0019" num="0018">In an illustrative embodiment, the client-facing tier <b>102</b> can include a client-facing tier (CFT) switch <b>130</b> that manages communication between the client-facing tier <b>102</b> and the private access network <b>166</b> and between the client-facing tier <b>102</b> and the private network <b>110</b>. As shown, the CFT switch <b>130</b> is coupled to one or more data servers <b>132</b> that store data transmitted in response to user requests, such as video-on-demand material. The CFT switch <b>130</b> can also be coupled to a terminal server <b>134</b> that provides terminal devices, such as a game application server and other devices with a common connection point to the private network <b>110</b>. In a particular embodiment, the CFT switch <b>130</b> can also be coupled to a video-on-demand (VOD) server <b>136</b>.</p>
<p id="p-0020" num="0019">The application tier <b>104</b> can communicate with both the private network <b>110</b> and the public network <b>112</b>. In this embodiment, the application tier <b>104</b> can include a first application tier (APP) switch <b>138</b> and a second APP switch <b>140</b>. In a particular embodiment, the first APP switch <b>138</b> can be coupled to the second APP switch <b>140</b>. The first APP switch <b>138</b> can be coupled to an application server <b>142</b> and to an OSS/BSS gateway <b>144</b>. The application server <b>142</b> provides applications to the set-top box devices <b>116</b> and <b>124</b> via the private access network <b>166</b>, so the set-top box devices <b>116</b> and <b>124</b> can provide functions such as display, messaging, processing of IPTV data and VOD material. In a particular embodiment, the OSS/BSS gateway <b>144</b> includes operation systems and support (OSS) data, as well as billing systems and support (BSS) data.</p>
<p id="p-0021" num="0020">The second APP switch <b>140</b> can be coupled to a domain controller <b>146</b> that provides web access, for example, to users via the public network <b>112</b>. The second APP switch <b>140</b> can be coupled to a subscriber and system store <b>148</b> that includes account information, such as account information that is associated with users who access the system <b>100</b> via the private network <b>110</b> or the public network <b>112</b>. In a particular embodiment, the application tier <b>104</b> can also include a client gateway <b>150</b> that communicates data directly to the client-facing tier <b>102</b>. In this embodiment, the client gateway <b>150</b> can be coupled directly to the CFT switch <b>130</b>. The client gateway <b>150</b> can provide user access to the private network <b>110</b> and the tiers coupled thereto.</p>
<p id="p-0022" num="0021">In a particular embodiment, the set-top box devices <b>116</b> and <b>124</b> can access the system via the private access network <b>166</b> using information received from the client gateway <b>150</b>. The private access network <b>166</b> provides security for the private network <b>110</b>. User devices can access the client gateway <b>150</b> via the private access network <b>166</b>, and the client gateway <b>150</b> can allow such devices to access the private network <b>110</b> once the devices are authenticated or verified. Similarly, the client gateway <b>150</b> can prevent unauthorized devices, such as hacker computers or stolen set-top box devices, from accessing the private network <b>110</b> by denying access to these devices beyond the private access network <b>166</b>.</p>
<p id="p-0023" num="0022">For example, when the set-top box device <b>116</b> accesses the system <b>100</b> via the private access network <b>166</b>, the client gateway <b>150</b> can verify subscriber information by communicating with the subscriber and system store <b>148</b> via the private network <b>110</b>, the first APP switch <b>138</b> and the second APP switch <b>140</b>. Further, the client gateway <b>150</b> can verify billing information and status by communicating with the OSS/BSS gateway <b>144</b> via the private network <b>110</b> and the first APP switch <b>138</b>. The OSS/BSS gateway <b>144</b> can transmit a query across the first APP switch <b>138</b>, to the second APP switch <b>140</b>, and the second APP switch <b>140</b> can communicate the query across the public network <b>112</b> to the OSS/BSS server <b>164</b>. After the client gateway <b>150</b> confirms subscriber and/or billing information, the client gateway <b>150</b> can allow the set-top box device <b>116</b> access to IPTV content and VOD content. If the client gateway <b>150</b> cannot verify subscriber information for the set-top box device <b>116</b>, such as because it is connected to a different twisted pair, the client gateway <b>150</b> can deny transmissions to and from the set-top box device <b>116</b> beyond the private access network <b>166</b>.</p>
<p id="p-0024" num="0023">The acquisition tier <b>106</b> includes an acquisition tier (AQT) switch <b>152</b> that communicates with the private network <b>110</b>. The AQT switch <b>152</b> can also communicate with the operations and management tier <b>108</b> via the public network <b>112</b>. In a particular embodiment, the AQT switch <b>152</b> can be coupled to a live acquisition server <b>154</b> that receives television content, for example, from a broadcast service <b>156</b>. Further, the AQT switch can be coupled to a video-on-demand importer server <b>158</b> that stores television content received at the acquisition tier <b>106</b> and communicate the stored content to the client-facing tier <b>102</b> via the private network <b>110</b>.</p>
<p id="p-0025" num="0024">The operations and management tier <b>108</b> can include an operations and management tier (OMT) switch <b>160</b> that conducts communication between the operations and management tier <b>108</b> and the public network <b>112</b>. In the illustrated embodiment, the OMT switch <b>160</b> is coupled to a TV2 server <b>162</b>. Additionally, the OMT switch <b>160</b> can be coupled to an OSS/BSS server <b>164</b> and to a simple network management protocol (SNMP) monitor <b>166</b> that monitors network devices. In a particular embodiment, the OMT switch <b>160</b> can communicate with the AQT switch <b>152</b> via the public network <b>112</b>.</p>
<p id="p-0026" num="0025">In a particular embodiment during operation of the IPTV system, the live acquisition server <b>154</b> can acquire television content from the broadcast service <b>156</b>. The live acquisition server <b>154</b> in turn can transmit the television content to the AQT switch <b>152</b> and the AQT switch can transmit the television content to the CFT switch <b>130</b> via the private network <b>110</b>. Further, the television content can be encoded at the D-servers <b>132</b>, and the CFT switch <b>130</b> can communicate the television content to the modems <b>114</b> and <b>122</b> via the private access network <b>166</b>. The set-top box devices <b>116</b> and <b>124</b> can receive the television content from the modems <b>114</b> and <b>122</b>, decode the television content, and transmit the content to the display devices <b>118</b> and <b>126</b> according to commands from the remote control devices <b>120</b> and <b>128</b>.</p>
<p id="p-0027" num="0026">Additionally, at the acquisition tier <b>106</b>, the VOD importer server <b>158</b> can receive content from one or more VOD sources outside the IPTV system <b>100</b>, such as movie studios and programmers of non-live content. The VOD importer server <b>158</b> can transmit the VOD content to the AQT switch <b>152</b>, and the AQT switch <b>152</b> in turn can communicate the material to the CFT switch <b>130</b> via the private network <b>110</b>. The VOD content can be stored at one or more servers, such as the VOD server <b>136</b>.</p>
<p id="p-0028" num="0027">When a user issues a request for VOD content to the set-top box device <b>116</b> or <b>124</b>, the request can be transmitted over the private access network <b>166</b> to the VOD server <b>136</b> via the CFT switch <b>130</b>. Upon receiving such a request, the VOD server <b>136</b> can retrieve requested VOD content and transmit the content to the set-top box device <b>116</b> or <b>124</b> across the private access network <b>166</b> via the CFT switch <b>130</b>. In an illustrative embodiment, the live acquisition server <b>154</b> can transmit the television content to the AQT switch <b>152</b>, and the AQT switch <b>152</b> in turn can transmit the television content to the OMT switch <b>160</b> via the public network <b>112</b>. In this embodiment, the OMT switch <b>160</b> can transmit the television content to the TV2 server <b>162</b> for display to users accessing the user interface at the TV2 server. For example, a user can access the TV2 server <b>162</b> using a personal computer <b>168</b> coupled to the public network <b>112</b>.</p>
<p id="p-0029" num="0028">The domain controller <b>146</b> communicates with the public network <b>112</b> via the second APP switch <b>140</b>. Additionally, the domain controller <b>146</b> can communicate via the public network <b>112</b> with the personal computer <b>168</b>. For example, the domain controller <b>146</b> can display a web portal via the public network <b>112</b> and allow users to access the web portal using the PC <b>168</b>. Further, in an illustrative embodiment, the domain controller <b>146</b> can communicate with at least one wireless network access point <b>178</b> over a data network <b>176</b>. In this embodiment, each wireless network access device <b>178</b> can communicate with user wireless devices such as a cellular telephone <b>184</b>.</p>
<p id="p-0030" num="0029">In a particular embodiment, the set-top box devices can include an STB computer program <b>174</b> that is embedded within the STB memory device <b>172</b>. The STB computer program <b>174</b> can contain instructions to receive and execute at least one user television viewing preference that a user has entered by accessing an Internet user account via the domain controller <b>146</b>. For example, the user can use the PC <b>168</b> to access a web portal maintained by the domain controller <b>146</b> via the Internet. The domain controller <b>146</b> can query the subscriber and system store <b>148</b> via the private network <b>110</b> for account information associated with the user. In a particular embodiment, the account information can associate the user's Internet account with the second set-top box device <b>124</b>. For instance, in an illustrative embodiment, the account information can relate the user's account to the second set-top box device <b>124</b> by associating the user account with an IP address of the second set-top box device, with data relating to one or more twisted pairs connected with the second set-top box device, with data related to one or more fiber optic cables connected with the second set-top box device, with an alphanumeric identifier of the second set-top box device, with any other data that is suitable for associating second set-top box device with a user account, or with any combination of these.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 2</figref> shows a block diagram illustrating a digital video stream <b>200</b> that can include I-Frames <b>202</b>, B-Frames <b>204</b>, and P-Frames <b>206</b>. Digital video stream <b>200</b> can be encrypted, such as by encrypting each frame of the digital video stream <b>200</b>. Each I-Frame <b>202</b> can encode a single frame of video. Each I-Frame <b>202</b> also can be independent of the other frames of the digital video stream <b>200</b>, and can be decoded without reference to the other frames of the digital video stream <b>200</b>. In contrast, each B-Frame <b>204</b> and each P-Frame <b>206</b> can be encoded relative to reference frames. Reference frames can include I-Frames <b>202</b> and P-Frames <b>206</b>. Each B-Frame <b>204</b> and each P-Frame <b>206</b> can describe a frame by describing the change or motion between the current frame and a reference frame and may require information from the reference frame during decoding. P-Frames <b>206</b> can be encoded relative to a closest previous reference frame, whereas B-Frames <b>204</b> can be encoded with reference to a closest previous reference frame, a closest next reference frame, or a combination thereof.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 3</figref> shows a block diagram illustrating a system <b>300</b> for determining a current location within a digital video stream, such as digital video stream <b>200</b>. The system <b>300</b> includes a video playback device <b>302</b>, a video source <b>304</b>, a video output <b>306</b>, and a video information server <b>308</b>. The video information server can include an I-Frame database <b>310</b>. The video playback device <b>302</b> may be an STB such as STB <b>124</b>. Alternatively, the video playback device <b>302</b> may be a media player such as a DVD player, or a video display such as TV monitor <b>126</b>. Additionally, the video playback device <b>302</b> may be implemented as software, hardware, or a combination thereof and incorporated into a computer such as PC <b>168</b>. In another embodiment, the video playback device <b>302</b> may be incorporated into mobile device such as cellular telephone <b>184</b>. The video playback device <b>302</b> receives a digital video stream from the video source <b>304</b>. The video source <b>304</b> may include physical media such as a DVD, a streaming digital video such as an IPTV data stream, or a digital video recorder such as DVR <b>182</b>. The video source <b>304</b> may provide either an encrypted digital video stream or an unencrypted digital video stream. The video playback device <b>302</b> can provide a video signal to the video output <b>306</b>. The video output <b>306</b> may be an integrated display such as when the video playback device is incorporated into TV monitor <b>126</b>. Alternatively, the video output may be an external device such as TV monitor <b>126</b> when the video playback device <b>302</b> is STB <b>124</b>. Additionally, the video output <b>306</b> may be a video recording device such as DVR <b>182</b> or a DVD recorder. The video playback device <b>302</b> can calculate a hash for an I-Frame within the digital video stream. When the digital video stream is encrypted, the hash may be calculated without decrypting the digital video stream for playback. The video playback device <b>302</b> may provide the hash of the I-Frame to the video information server <b>308</b>. The video information server <b>308</b> can retrieve location information from the I-Frame database <b>310</b>. The location information may include a timestamp representing the location of the I-Frame within the digital video stream. The video information server <b>308</b> can provide the location information to the video playback device <b>302</b>. Alternatively, the video playback device <b>302</b> may retrieve the location information from a local database that is periodically updated from the video information server <b>308</b>.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 4</figref> shows a flow diagram illustrating a method <b>400</b> for determining a location within a digital video stream, such as digital video stream <b>200</b>. As illustrated at <b>402</b>, a video information device, such as video playback device <b>302</b> or video information server <b>308</b>, receives the digital video stream. The digital video stream can include content, such as a movie, a television serial, or a live event. The video information device selects an I-Frame, such as I-Frame <b>202</b>, from within the digital video stream, at <b>404</b>. I-Frames can occur periodically throughout the digital video stream, such as about every 0.5 seconds. At <b>406</b>, the video information device determines a timestamp representing the location of the I-Frame within the digital video stream. For example, the timestamp may be a time such as a number of tenths of seconds since the beginning of the digital video stream. As illustrated at <b>408</b>, the video information device can calculate a hash of the I-Frame. Generally, hashes of similar data are significantly different. For example, a first I-Frame may be nearly identical to a second I-Frame, such as when only a small change has occurred in a scene. The hash of the first I-Frame can be significantly different from the hash of the second I-Frame, such that the first I-Frame can be distinguished from the second I-Frame based on the difference between the respective hashes. Generally, the algorithm used should generate a hash of sufficient length to have a high likelihood of providing a unique hash to each I-Frame of the digital video stream. In an exemplary embodiment, the algorithm can generate a hash of 128-bits. For example, the MDS, Blowfish, 3DES, and AES algorithms can generate a 128-bit hash. In another embodiment, the hash may be smaller, such as a 56-bit hash. In an alternate embodiment, the hash may be larger, such as 192 bits or 256 bits. At <b>410</b>, the hash and the timestamp may be stored in a database, such as I-Frame database <b>310</b>. Additionally, a title corresponding to the content of the digital video stream may be included in the database. At <b>404</b>, the video information device may select another I-Frame. When populating the I-Frame database as described, the video information device may calculate a hash for every I-Frame in the digital video stream</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 5</figref> shows a flow diagram illustrating a method <b>500</b> for determining a location within a digital video stream during playback. As illustrated at <b>502</b>, a video playback device such as video playback device <b>302</b> receives a digital video stream such as digital video stream <b>200</b>. At <b>504</b>, the video playback device selects an I-Frame such as I-Frame <b>202</b> from within the digital video stream. The video playback device can calculate a hash of the I-Frame, as illustrated at <b>506</b>. The hash can be calculated for the I-Frame as previously described. At <b>508</b>, the video playback device can submit the hash of the I-Frame to a video information server, such as video information server <b>308</b>. At <b>510</b>, the video playback device may receive location information from the video information server. The location information can include a timestamp corresponding to the location of the I-Frame within the digital video stream. Additionally, the video information server may provide instructions to the video playback device based upon the location information. Alternatively, the video playback device may retrieve the timestamp from a local database. The local database may be periodically updated from the video information server. The video playback device may select another I-Frame from the digital video stream, as illustrated at <b>504</b>. In an exemplary embodiment, the video playback device may calculate a hash for a subset of I-Frames within the digital video stream. For example, the video playback device may calculate a hash for at least one I-Frame per sixty seconds of the digital video stream, preferably at least one I-Frame per five to fifteen seconds.</p>
<p id="p-0035" num="0034">In an exemplary embodiment, the video playback device can use the location information to synchronize the digital video stream with a data stream such as a second digital video stream, an audio file, or a text file. For example, the video playback device may combine the digital video stream with an audio file to provide an alternate audio track to the video content. The video playback device can match a portion of the data stream to the digital video stream based on the location information. The video playback device may combine the portion of the data stream with the digital video stream to provide synchronized playback.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 6</figref> shows a flow diagram illustrating a method <b>600</b> providing a timestamp based on a hash of an I-Frame, such as I-Frame <b>202</b>. At <b>602</b>, a video information server, such as video information server <b>308</b>, can receive a request from a video playback device, such as video playback device <b>302</b>. The request can include a hash of an I-Frame within a digital video stream and a title of the content of the digital video stream. The request can further include a device or subscriber identification (ID). At <b>604</b>, the server retrieves location information from a database such as I-Frame database <b>310</b>. The location information can include a timestamp corresponding to a location of the I-Frame within the digital video stream. At <b>608</b>, the video information server may store information in a viewers database. For example, the information may include the title, the timestamp, the device or subscriber ID, and the current time. The viewers database may be used to track the number of subscribers viewing a title and the time subscribers view a title such as when the title is originally aired, when viewing is time-shifted, and when the title is viewed multiple times. At <b>610</b>, the video information server may provide the location information to the video playback device. The server may receive another request, as illustrated at <b>602</b>, from the same or an additional video playback device.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 7</figref> shows an illustrative embodiment of a general computer system <b>700</b>. The computer system <b>700</b> can include a set of instructions that can be executed to cause the computer system to perform any one or more of the methods or computer based functions disclosed herein. The computer system <b>700</b> may operate as a standalone device or may be connected such as by using a network, to other computer systems or peripheral devices.</p>
<p id="p-0038" num="0037">In a networked deployment, the computer system may operate in the capacity of a server or as a client user computer in a server-client user network environment, or as a peer computer system in a peer-to-peer (or distributed) network environment. The computer system <b>700</b> can also be implemented as or incorporated into various devices, such as a personal computer (PC), a tablet PC, an STB, a personal digital assistant (PDA), a mobile device, a palmtop computer, a laptop computer, a desktop computer, a communications device, a wireless telephone, a land-line telephone, a control system, a camera, a scanner, a facsimile machine, a printer, a pager, a personal trusted device, a web appliance, a network router, switch or bridge, or any other machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. In a particular embodiment, the computer system <b>700</b> can be implemented using electronic devices that provide voice, video or data communication. Further, while a single computer system <b>700</b> is illustrated, the term &#x201c;system&#x201d; shall also be taken to include any collection of systems or sub-systems that individually or jointly execute a set, or multiple sets, of instructions to perform one or more computer functions.</p>
<p id="p-0039" num="0038">The computer system <b>700</b> may include a processor <b>702</b>, such as a central processing unit (CPU), a graphics processing unit (GPU), or both. Moreover, the computer system <b>700</b> can include a main memory <b>704</b> and a static memory <b>706</b> that can communicate with each other via a bus <b>708</b>. As shown, the computer system <b>700</b> may further include a video display unit <b>710</b> such as a liquid crystal display (LCD), an organic light emitting diode (OLED), a flat panel display, a solid state display, or a cathode ray tube (CRT). Additionally, the computer system <b>700</b> may include an input device <b>712</b> such as a keyboard, and a cursor control device <b>714</b> such as a mouse. The computer system <b>700</b> can also include a disk drive unit <b>716</b>, a signal generation device <b>718</b> such as a speaker or remote control, and a network interface device <b>720</b> to communicate with a network <b>726</b>. In a particular embodiment, the disk drive unit <b>716</b> may include a computer-readable medium <b>722</b> in which one or more sets of instructions <b>724</b>, such as software, can be embedded. Further, the instructions <b>724</b> may embody one or more of the methods or logic as described herein. In a particular embodiment, the instructions <b>724</b> may reside completely, or at least partially, within the main memory <b>704</b>, the static memory <b>706</b>, and/or within the processor <b>702</b> during execution by the computer system <b>700</b>. The main memory <b>704</b> and the processor <b>702</b> also may include computer-readable media.</p>
<p id="p-0040" num="0039">The illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure, such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Additionally, the illustrations are merely representational and may not be drawn to scale. Certain proportions within the illustrations may be exaggerated, while other proportions may be minimized. Accordingly, the disclosure and the FIGs. are to be regarded as illustrative rather than restrictive.</p>
<p id="p-0041" num="0040">The Abstract of the Disclosure is provided with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description of the Drawings, various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments. Thus, the following claims are incorporated into the Detailed Description of the Drawings, with each claim standing on its own as defining separately claimed subject matter.</p>
<p id="p-0042" num="0041">The above disclosed subject matter is to be considered illustrative, and not restrictive, and the appended claims are intended to cover all such modifications, enhancements, and other embodiments which fall within the true spirit and scope of the present disclosed subject matter. Thus, to the maximum extent allowed by law, the scope of the present disclosed subject matter is to be determined by the broadest permissible interpretation of the following claims and their equivalents, and shall not be restricted or limited by the foregoing detailed description.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A non-transitory computer-readable storage device, comprising computer instructions which, responsive to being executed by a processor, cause the processor to perform operations comprising:
<claim-text>receiving an encrypted digital video stream and a data stream, wherein the encrypted digital video stream includes I-frames, B-frames and P-frames, and wherein the I-frames are decodable without reference to other frames in the encrypted digital video stream;</claim-text>
<claim-text>calculating a first hash of a first I-frame and for each of the I-frames of the encrypted digital video stream without location information and without hash values for each of the B-frames and P-frames of the encrypted digital video stream, wherein the first hash is calculated without decrypting the encrypted digital video stream;</claim-text>
<claim-text>submitting the first hash to a server that has access to a database identifying a one to one correspondence between each member of a set of hashes of I-frames and a corresponding member of a set of location information, wherein the database identifies the one to one correspondence only for the I-frames of the encrypted digital video stream;</claim-text>
<claim-text>receiving first location information of the set of location information in response to submitting the first hash to the server, wherein the first location information is provided by the server responsive to a determination that the first hash is included in the set of hashes of I-frames and responsive to identifying a location of the first I-frame within the encrypted digital video stream; and</claim-text>
<claim-text>synchronizing and combining the data stream and the encrypted digital video stream based on the first location information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The non-transitory computer-readable storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the operations further comprise:
<claim-text>receiving processing instructions associated with the first location information; and</claim-text>
<claim-text>submitting a title corresponding to the encrypted digital video stream to the server.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The non-transitory computer-readable storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first location information includes a time stamp.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The non-transitory computer-readable storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the calculating of the first hash comprises applying an advanced encryption standard algorithm to the first I-frame and for each of the I-frames of the encrypted digital video stream.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The non-transitory computer-readable storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the calculating of the first hash comprises generating a 128 bit hash.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The non-transitory computer-readable storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is within a set top box.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The non-transitory computer-readable storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data stream comprises a text file.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The non-transitory computer-readable storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data stream comprises an audio file.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method comprising:
<claim-text>receiving, by a system including a processor, an encrypted digital video stream and a data stream, wherein the encrypted digital video stream includes I-frames, B-frames and P-frames, and wherein the I-frames are decodable without reference to other frames in the encrypted digital video stream;</claim-text>
<claim-text>calculating, by the system, a first hash of a first I-frame and for each of the I-frames of the encrypted digital video stream without location information and without hash values for each of the B-frames and P-frames of the encrypted digital video stream, wherein the first hash is calculated without decrypting the encrypted digital video stream;</claim-text>
<claim-text>submitting, by the system, the first hash to a server that has access to a database identifying a one to one correspondence between each member of a set of hashes of 1-frames and a corresponding member of a set of location information, wherein the database identifies the one to one correspondence only for the I-frames of the encrypted digital video stream;</claim-text>
<claim-text>receiving, by the system, first location information of the set of location information in response to submitting the first hash to the server, wherein the first location information is provided by the server responsive to a determination that the first hash is included in the set of hashes of I-frames and responsive to identifying a location of the first I-frame within the encrypted digital video stream; and</claim-text>
<claim-text>synchronizing and combining, by the system, the data stream and the encrypted digital video stream based on the first location information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the first location information includes a time stamp.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising submitting a title corresponding to the encrypted digital video stream to the server.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first location information includes a time stamp.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the first hash is calculated by applying an advanced encryption standard algorithm to the first I-frame and to each other I-frame of the encrypted digital video stream.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the data stream comprises a text file.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the data stream comprises an audio file.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. An apparatus comprising:
<claim-text>a memory to store computer instructions; and</claim-text>
<claim-text>a processor coupled with the memory, wherein the processor, responsive to executing the computer instructions, performs operations comprising:
<claim-text>receiving an encrypted digital video stream and a data stream, wherein the encrypted digital video stream includes I-frames, B-frames and P-frames, and wherein the I-frames are decodable without reference to other frames in the encrypted digital video stream;</claim-text>
<claim-text>calculating a first hash of a first I-frame and for each of the I-frames of the encrypted digital video stream without location information and without hash values for each of the B-frames and P-frames of the encrypted digital video stream, wherein the first hash is calculated without decrypting the encrypted digital video stream;</claim-text>
<claim-text>submitting the first hash to a server that has access to a database identifying a one to one correspondence between each member of a set of hashes of 1-frames and a corresponding member of a set of location information, wherein the database identifies the one to one correspondence only for the I-frames of the encrypted digital video stream;</claim-text>
<claim-text>receiving first location information of the set of location information in response to submitting the first hash to the server, wherein the first location information is provided by the server responsive to a determination that the first hash is included in the set of hashes of I-frames and responsive to identifying a location of the first I-frame within the encrypted digital video stream; and</claim-text>
<claim-text>synchronizing and combining, by the system, the data stream and the encrypted digital video stream based on the first location information.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the operations further comprise submitting a title corresponding to the encrypted digital video stream to the server.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the first location information includes a time stamp.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The apparatus of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the first hash is calculated by applying an advanced encryption standard algorithm to the first I-frame and to each other I-frame of the encrypted digital video stream. </claim-text>
</claim>
</claims>
</us-patent-grant>
