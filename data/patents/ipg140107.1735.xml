<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622919-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622919</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12272072</doc-number>
<date>20081117</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>866</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>02</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>04</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>R</subclass>
<main-group>25</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>600528</main-classification>
<further-classification>600514</further-classification>
<further-classification>381375</further-classification>
</classification-national>
<invention-title id="d2e53">Apparatus, method, and computer program for detecting a physiological measurement from a physiological sound signal</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5492129</doc-number>
<kind>A</kind>
<name>Greenberger</name>
<date>19960200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600528</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2002/0091049</doc-number>
<kind>A1</kind>
<name>Hisano et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2006/0064037</doc-number>
<kind>A1</kind>
<name>Shalon et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2006/0107822</doc-number>
<kind>A1</kind>
<name>Bowen</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2008/0146890</doc-number>
<kind>A1</kind>
<name>LeBoeuf et al.</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2008/0171945</doc-number>
<kind>A1</kind>
<name>Dotter</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600514</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2009/0108082</doc-number>
<kind>A1</kind>
<name>Goldmann et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>236 491</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2009/0149699</doc-number>
<kind>A1</kind>
<name>Ullmann</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600 28</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2009/0259116</doc-number>
<kind>A1</kind>
<name>Wasserman et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600323</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2010/0037753</doc-number>
<kind>A1</kind>
<name>Wagner</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84612</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>GB</country>
<doc-number>2 419 946</doc-number>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>WO</country>
<doc-number>2006/050512</doc-number>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>International Search Report for corresponding application No. PCT/EP2009/056078 dated Nov. 12, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Written Opinion for corresponding application No. PCT/EP2009/056078 dated Nov. 12, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>37</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>600300</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600528-529</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600586</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 56</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381375</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>128903</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>128905</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>482148</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84612</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>484148</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>2</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100125218</doc-number>
<kind>A1</kind>
<date>20100520</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Haartsen</last-name>
<first-name>Jacobus Cornelis</first-name>
<address>
<city>Hardenberg</city>
<country>NL</country>
</address>
</addressbook>
<residence>
<country>NL</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sampimon</last-name>
<first-name>Gerrit</first-name>
<address>
<city>Erm</city>
<country>NL</country>
</address>
</addressbook>
<residence>
<country>NL</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Haartsen</last-name>
<first-name>Jacobus Cornelis</first-name>
<address>
<city>Hardenberg</city>
<country>NL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Sampimon</last-name>
<first-name>Gerrit</first-name>
<address>
<city>Erm</city>
<country>NL</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Renner, Otto, Boisselle &#x26; Sklar, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
<assignee>
<addressbook>
<orgname>Sony Mobile Communications AB</orgname>
<role>03</role>
<address>
<city>Lund</city>
<country>SE</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Koharski</last-name>
<first-name>Christopher D</first-name>
<department>3762</department>
</primary-examiner>
<assistant-examiner>
<last-name>Voorhees</last-name>
<first-name>Catherine</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An apparatus is disclosed, comprising a speaker suitable to be applied at a user's ear and enabled to be supplied with an audio signal for rendering; a microphone arranged in vicinity of the speaker to acquire a sound signal from sounds present in the ear of the user; and a signal processor, wherein the signal processor is arranged to subtract the audio signal from the sound signal to provide a physiological sound signal, and the signal processor is further arranged to detect a physiological measurement from the physiological sound signal. A method and a computer program are also disclosed.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="98.89mm" wi="161.88mm" file="US08622919-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="250.61mm" wi="177.38mm" file="US08622919-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="246.21mm" wi="177.46mm" file="US08622919-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to an apparatus, a method, and a computer program for detecting a physiological measurement from a physiological sound signal.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Devices for exercising aid and applications in other devices for the same, or applications for other purposes, such as just for amusement have become popular. Such other devices can be portable media players, mobile telephones, and portable digital assistants. Positioning information means, accelerometers, altitude meters, etc. included in such devices may be used for added value. Applications for gaming, exercise aid, log functions, etc. may rely on these measured quantities.</p>
<p id="p-0004" num="0003">Still, further measured quantities could enhance the devices. It is therefore a desire to add available quantities to measure. However, since the devices are intended to be used by an ordinary user without particular skills and the user normally appreciates gear that is easy to handle, sensors that are used for professional measurements are many times not suitable for these kinds of devices. It is therefore a further desire to provide gear that is easy to use by an ordinary user for the measurements.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0005" num="0004">The present invention is based on the understanding that an ordinary user is comfortable with using earphones, and that addition of a microphone in an earphone can be used for acquiring sounds from which measurements on physiological sounds present in the user's ear can be made. The physiological sounds are extracted by subtracting sounds provided by the speaker of the earphone. From the physiological sounds, desired quantities and/or qualities are determined, such as heart rate or breathing pattern.</p>
<p id="p-0006" num="0005">According to a first aspect, there is provided an apparatus comprising a speaker suitable to be applied at a user's ear and enabled to be supplied with an audio signal for rendering; a microphone arranged in vicinity of the speaker to acquire a sound signal from sounds present in the ear of the user; and a signal processor, wherein the signal processor is arranged to subtract the audio signal from the sound signal to provide a physiological sound signal, and the signal processor is further arranged to detect a physiological measurement from the physiological sound signal.</p>
<p id="p-0007" num="0006">The apparatus may further comprise a filter arranged to filter the sound signal, the audio signal to be subtracted or the physiological sound signal.</p>
<p id="p-0008" num="0007">The apparatus may further comprise an application arranged to control features of the application based on the physiological measurement. The application may be arranged to make music selection based on the physiological measurement, wherein the selected music is comprised in the supplied audio signal. The physiological measurement may comprise a breathing pattern. The signal processor may be arranged to determine a breathing rate from the breathing pattern. The music may be selected based on the music's beat rate such that the music's beat rate is a monotonic function of the breathing rate. The music may be selected based on the music's beat rate such that the music's beat rate is a function of the breathing rate wherein the music's beat rate is increased until a predetermined breathing rate is reached.</p>
<p id="p-0009" num="0008">The physiological measurement may comprise a heartbeat. The signal processor may be arranged to determine a heartbeat rate from the heartbeat. The music may be selected based on the music's beat rate such that the music's beat rate is a monotonic function of the heartbeat rate. The music may be selected based on the music's beat rate such that the music's beat rate is a function of the heartbeat rate wherein the music's beat rate is increased until a predetermined heartbeat rate is reached. The signal processor may be arranged to extract the heartbeat by low pass filtering the physiological sound signal in a low pass filter to provide a heartbeat signal. The low pass filter may have a cutoff frequency between 3 and 10 Hz, preferably between 3 and 5 Hz, preferably 4 Hz.</p>
<p id="p-0010" num="0009">The apparatus may further comprise a second speaker suitable to be provided at the user's other ear, wherein an audio signal provided to the second speaker comprises a sub-signal such that the sound signal comprises a signal component emanating from sound provided at the user's other ear and which sound is modulatedly attenuated by pulsating blood of veins of the user when the sound propagates through the head of the user, and such that the heartbeat is extractable from the signal component. The signal processor may be arranged to extract the heartbeat by low pass filtering the physiological sound signal in a low pass filter to provide the signal component signal. The low pass filter may have a cutoff frequency between 3 and 10 Hz, preferably between 3 and 5 Hz, preferably 4 Hz.</p>
<p id="p-0011" num="0010">The apparatus may comprise a heart rate estimator arranged to estimate heart rate from the breathing pattern. The physiological measurement may comprise a heartbeat, the signal processor may be arranged to determine a heartbeat rate from the heartbeat, and the apparatus may further be arranged to provide a comparison between the estimated heart rate and the determined heart rate.</p>
<p id="p-0012" num="0011">The physiological measurement may comprise a heartbeat and a breathing pattern.</p>
<p id="p-0013" num="0012">According to a second aspect, there is provided a method comprising supplying an audio signal to a speaker suitable to be applied at a user's ear for rendering the audio signal in the user's ear; acquiring a sound signal by a microphone arranged in vicinity of the speaker to acquire the sound signal from sounds present in the ear of the user; subtracting the audio signal from the sound signal to provide a physiological sound signal; and detecting a physiological measurement from the physiological sound signal.</p>
<p id="p-0014" num="0013">The method may further comprise filtering the sound signal, the audio signal to be subtracted or the physiological sound signal.</p>
<p id="p-0015" num="0014">The physiological measurement may comprise a breathing pattern, and the method further may comprise controlling features of an application based on the breathing pattern. The controlling of features of the application may comprise selecting music based on the breathing pattern, wherein the selected music is provided to be comprised in the supplied audio signal. The method may further comprise determining a breathing rate from the breathing pattern. The music may be selected based on the music's beat rate such that the music's beat rate is a monotonic function of the breathing rate.</p>
<p id="p-0016" num="0015">The method may further comprise selecting music based on the breathing pattern, wherein the selected music is provided to be comprised in the supplied audio signal; and determining a breathing rate from the breathing pattern, wherein the selection of music is based on the music's beat rate such that the music's beat rate is increased until a predetermined breathing rate is reached.</p>
<p id="p-0017" num="0016">The method may further comprise estimating a heart rate from the breathing pattern. The physiological measurement may comprise a heartbeat, the method may further comprise determining a heartbeat rate from the heartbeat; and comparing the estimated heart rate and the determined heart rate, wherein the result of the comparison is used for controlling the features of the application.</p>
<p id="p-0018" num="0017">The method may further comprise extracting a heartbeat by low pass filtering the physiological sound signal in a low pass filter to provide a heartbeat signal. The low pass filter may have a cutoff frequency between 3 and 10 Hz, preferably between 3 and 5 Hz, preferably 4 Hz.</p>
<p id="p-0019" num="0018">The physiological measurement may comprise a heartbeat, and the method may further comprise providing an audio signal which comprises a sub-signal to a second speaker suitable to be applied at the user's other ear, such that the sound signal comprises a signal component emanating from sound provided at the user's other ear and which sound is modulatedly attenuated by pulsating blood of veins of the user when the sound propagates through the head of the user; and detecting the heartbeat from the signal component. The method may further comprise low pass filtering the physiological sound signal in a low pass filter to provide the signal component signal. The low pass filter may have a cutoff frequency between 3 and 10 Hz, preferably between 3 and 5 Hz, preferably 4 Hz.</p>
<p id="p-0020" num="0019">The physiological measurement may comprise a heartbeat and a breathing pattern.</p>
<p id="p-0021" num="0020">According to a third aspect, there is provided a computer readable medium comprising program code comprising instructions which when executed by a processor is arranged to cause the processor to perform supplying an audio signal to a speaker suitable to be applied at a user's ear for rendering the audio signal in the user's ear; acquiring a sound signal by a microphone arranged in vicinity of the speaker to acquire the sound signal from sounds present in the ear of the user; subtracting the audio signal from the sound signal to provide a physiological sound signal; and detecting a physiological measurement from the physiological sound signal.</p>
<p id="p-0022" num="0021">The instructions may further be arranged to cause the processor to select music based on the physiological measurement, wherein the selected music is provided to be comprised in the supplied audio signal.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 1</figref> schematically illustrates an apparatus according to an embodiment.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart illustrating a method according to embodiments.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating functions between provided music beat rate and breathing pattern or heart rate.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram schematically illustrating an application according to an embodiment.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 5</figref> schematically illustrates a computer readable medium.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 1</figref> schematically illustrates an apparatus <b>100</b> according to an embodiment. The apparatus <b>100</b> comprises a speaker arrangement <b>102</b>, e.g. an earphone, which has a speaker <b>104</b> and a microphone <b>106</b> arranged together with the speaker <b>104</b>. The speaker <b>104</b> is provided with an audio signal, e.g. music, which preferably is provided by an amplifier <b>108</b>, which in turn may get the audio content from a media player element <b>109</b>. As will be demonstrated below, the audio signal can also comprise a sub-signal for heartbeat measurements. The microphone <b>106</b>, which is arranged to acquire heart or breathing sounds and of course the audio sound generated by the speaker <b>104</b>, provides its output signal to a subtractor <b>110</b>, which subtracts the audio signal from the microphone signal. Optionally, the microphone signal is filtered by a filter <b>111</b><i>a</i>. In addition, or alternatively, the audio sound provided by amplifier <b>108</b> may be filtered by a filter <b>111</b><i>b </i>before input to subtractor <b>110</b>. The output from the subtractor <b>110</b> essentially comprises a heart and/or breathing sound signal since the signal components emanating from the audio sound are deleted. The heart and/or breathing sound signal is provided to a physiological sound detector <b>112</b>. Here, it should be noted that a filter <b>111</b><i>c </i>can be arranged between the subtractor <b>110</b> and the physiological sound detector <b>112</b> instead of, or in addition to, the filter <b>111</b><i>a </i>between the microphone <b>106</b> and the subtractor <b>112</b> and/or the filter <b>111</b><i>b </i>between the amplifier <b>108</b> and the subtractor <b>110</b>. The breathing sound pattern can for example distinguish between breathing through the nose or the mouth. The breathing sound pattern can alternatively or additionally be a measure on breathing rate, e.g. breaths per minute or period between breaths, duty cycle of inhaling and/or exhaling, etc. From the breathing sound pattern, the physical status of a user can be estimated, e.g. during physical exercising. Similar applies for heart sounds, where heart rate and/or amplitude of heart sound can be determined. The subtractor <b>110</b>, the optional filter(s) <b>111</b><i>a, b, c</i>, and the pattern detector <b>112</b> can be part of a signal processor <b>114</b> performing the functions of the elements <b>110</b>, <b>111</b>(<i>a, b, c</i>), <b>112</b>, for example in analog or digital domain.</p>
<p id="p-0029" num="0028">In an embodiment, the breathing pattern can be used for controlling an application <b>115</b> such that features of the application are adapted to the breathing pattern and/or the heartbeat.</p>
<p id="p-0030" num="0029">For example, the application can be a music selection application which selects music with a beat rate that depends on for example the breathing rate. This can for example be neat when listening to music while running or jogging, as breathing is related to the physical effort, and also has a relation to step pace. For example, at running exercise, a 4-4 breathing means inhaling during 4 steps and exhaling during 4 steps, and during different parts of an exercise, different breathing strategies can be used, such as changing to 3-3, 2-2, 2-1 etc. If the music is in pace with breathing and thus steps, the exercise can be improved.</p>
<p id="p-0031" num="0030">Another example is by determining if breathing is nasal or oral. This can be determined on the different sound characteristics the breathing has when the air is flowing in the head. Nasal breathing can then be taken as a sign of low activity exercising, while oral breathing can be taken as a sign of high activity exercising. Music can then be selected accordingly.</p>
<p id="p-0032" num="0031">Further another example is by determining if breathing is deep or shallow. This can also be determined from sounds the flowing air is causing in the head, and which sounds can be acquired in the user's ear. An example is to select a lower beat rate on the music if breathing is shallow to calm the user to get into a deep breathing state, which is known to lower heart rate and improve efficiency in exercise. Similarly, if period of breathing is too short to give proper oxygenation in the lungs, lowered music beat rate can improve breathing and exercise.</p>
<p id="p-0033" num="0032">Still another example is a combination of any of the above breathing patterns, where a proper breathing according to a pre-configured or user-configured model is present, but still showing that pace of the exercise can be increased, and therefore an increased beat rate of the music is selected.</p>
<p id="p-0034" num="0033">Alternatively, or in combination with any of the examples given above, the heart rate and/or intensity of heartbeat sounds can be used for exercising aid, and optionally in combination with the music selection feature.</p>
<p id="p-0035" num="0034">Of course, the measured breathing pattern and/or heartbeat can also be used in an exercise aid application without controlling any music selection. Similar, the measured breathing pattern and/or heartbeat can also be used in an application without any connection to exercise aid.</p>
<p id="p-0036" num="0035">The application can of course combine other measured or estimated values and their derivatives too, such as step counter, positioning data, altitude, etc. The settings can be pre-defined or user-defined. The settings can also be down-loadable from a remote location, e.g. over a wireless communication interface such as a cellular telecommunication system. The measured and estimated values can also be saved in a log for post-exercise analysis. <figref idref="DRAWINGS">FIG. 4</figref> is a block diagram schematically illustrating an example on objects and features of an exercise enhancing application <b>400</b>. A breathing pattern signal and/or heartbeat signal is input to the application <b>400</b>, which is controlled by an application engine <b>402</b>. The application engine <b>402</b> is also enabled to receive settings from a settings object <b>404</b>, which for example can provide settings made by a user, pre-defined settings, or downloaded setting on age, weight, gender, body mass index, exercise limits, exercise type, music function, etc. to the application engine. The application engine can also control one or more function objects <b>406</b> for different features. The application <b>400</b> can also control other functions or applications, such as a media player, as demonstrated with reference to <figref idref="DRAWINGS">FIG. 1</figref>. The output interface for this control is preferably controlled by the application engine <b>402</b>. Here, it should be noted that the example given with reference to <figref idref="DRAWINGS">FIG. 4</figref> includes a multitude of functions <b>406</b>. Other examples are any application comprising one or more of the functions given with reference to <figref idref="DRAWINGS">FIG. 4</figref>. The application <b>400</b> can for example be implemented as a feature in a mobile phone, a media player, a GPS receiver or a personal digital assistant.</p>
<p id="p-0037" num="0036">The application can also be independent on physical exercising properties. Breathing can be used for controlling the apparatus <b>100</b> on the user's intention, where different breathing patterns are decoded to operation instructions for the apparatus <b>100</b>, for example changing or pausing music provided by the media player <b>109</b>.</p>
<p id="p-0038" num="0037">By nature, the heartbeat produces a weak sound in the head of the user with frequency components mainly corresponding to the heart rate. The heartbeat sound signal acquired by the microphone <b>106</b> can be amplified, filtered and processed to produce a heart rate value. The filtering can comprise low-pass filtering, since the heartbeat itself normally is within the range of 0.5 to 3 Hz. Since music content normally is very low at these frequencies, a narrow filter can enhance the heart sound signal significantly.</p>
<p id="p-0039" num="0038">Alternatively, as shown in <figref idref="DRAWINGS">FIG. 1</figref>, the heartbeat signal is produced by providing a sub-signal via a sub-signal generator <b>116</b> to one of the user's ears by a second speaker <b>118</b>, which can be done together with e.g. music. Preferably, the sub-signal is at a frequency not discernable by the user, e.g. an ultrasonic or a subsonic frequency should be used. As the sound of the sub-signal propagates through the head of the user to the other ear, the heartbeat will modulate, i.e. provide different attenuation, the sub-signal sound through the pulsation of the blood veins. The sound acquired by the microphone <b>106</b> in the other ear will comprise the modulated sub-signal sound. A low-pass filter in case of a subsonic sub-signal, and a high-pass filter in case of an ultrasonic sub-signal can be used to suppress the music signal while detecting the heartbeat. By similar signal processing as demonstrated above, the heart rate can be determined. This approach is particularly suitable for stereo earphones.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart illustrating a method according to embodiments, where hashed lines indicate optional actions. The flow chart is for illustrative purposes, and the order of the actions is not to be interpreted as a sequential order. Instead, the actions are preferably to be considered as real-time objects which can be performed in any order, or in parallel. In an audio supply step <b>200</b>, an audio signal is provided to a speaker suitable for applying in a user's ear, such as an earphone, for rendering of the audio content of the audio signal. In a sound acquisition step <b>202</b>, sound present in the user's ear is acquired by a microphone arranged together with the speaker. The sound present in the user's ear will be a mix of the rendered audio content and sounds generated in the user's head, such as breathing sounds which emanates from air flows in cavities of the head, and heartbeat sounds from blood pulsating in veins in the head according to any of the examples given with reference to <figref idref="DRAWINGS">FIG. 1</figref>. In an optional sound signal filtering step <b>203</b>, the acquired sound signal can be filtered to enhance the signal, e.g. attenuating frequencies out of frequency range for breathing sounds and/or heartbeat sounds. In an audio signal subtracting step <b>204</b>, the audio signal is subtracted from the sound signal to extract a breathing signal. In a physiological sound detection step <b>206</b>, a breathing pattern and/or heartbeat is detected, as demonstrated with reference to <figref idref="DRAWINGS">FIG. 1</figref>. Optionally, heart rate can be estimated from the detected breathing pattern in a heart rate estimation step <b>207</b>. Different models for estimating the heart rate from breathing pattern can be used. A user and/or exercise specific model can be used, where one or more characteristics of the breathing pattern are mapped to an expected heart rate. Alternatively, the heart rate can be estimated on the assumption that the faster the breathing rate, the faster the heart rate. Further alternatively, the heart rate can be estimated on the assumption that higher air flow, for example based on the amplitude and/or frequency components of the breathing signal, is mapped to a higher heart rate, and a shallow breathing is mapped to a higher heart rate then deep breathing. The optional heart rate estimation step <b>207</b> can be an alternative to the possible heartbeat determination of the physiological sound detection step <b>206</b>, or a complement for comparison between detected and estimated heart rate, where the comparison can be used as input to an application. In an optional application feature controlling step <b>209</b>, features of one or more applications can be controlled based on the breathing pattern, alternatively on the estimated heart rate.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating functions between provided music beat rate and breathing pattern or heart rate. For the case of breathing pattern, a determined breathing rate, periodicity, or duty cycle can be used for this type of relation. The solid line illustrates a linear relation between the breathing pattern or estimated heart rate and the music beat rate, while the dot-dashed lines illustrate different non-linear relations. The illustrated lines illustrate monotonic functions for the relation. The application of a monotonic function is particularly suitable when selecting music beat rate from heartbeat rate. Based on breathing pattern, a suitable model out of several non-linear models relating music to heartbeat rate, can be selected. This can further enhance an exercising aid.</p>
<p id="p-0042" num="0041">The methods according to the present invention are suitable for implementation with aid of processing means, such as computers and/or processors. Therefore, there is provided computer programs, comprising instructions arranged to cause the processing means, processor, or computer to perform the steps of any of the methods according to any of the embodiments described with reference to <figref idref="DRAWINGS">FIG. 2</figref>, in the apparatus. The computer programs preferably comprises program code which is stored on a computer readable medium <b>500</b>, as illustrated in <figref idref="DRAWINGS">FIG. 5</figref>, which can be loaded and executed by a processing means, processor, or computer <b>502</b> to cause it to perform the methods, respectively, according to embodiments of the present invention, preferably as any of the embodiments described with reference to <figref idref="DRAWINGS">FIG. 2</figref>. The computer <b>502</b>, which can be present in the apparatus as illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, and computer program product <b>500</b> can be arranged to execute the program code sequentially where actions of the any of the methods are performed stepwise, or be performed on a real-time basis, where actions are taken upon need and availability of needed input data. The processing means, processor, or computer <b>502</b> is preferably what normally is referred to as an embedded system. Thus, the depicted computer readable medium <b>500</b> and computer <b>502</b> in <figref idref="DRAWINGS">FIG. 5</figref> should be construed to be for illustrative purposes only to provide understanding of the principle, and not to be construed as any direct illustration of the elements.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An apparatus comprising
<claim-text>a media player element configured to provide audio content for rendering;</claim-text>
<claim-text>a speaker suitable to be applied at a user's ear and enabled to be supplied with an electronic audio signal for rendering, the electronic audio signal being generated based on the audio content provided by the media player element;</claim-text>
<claim-text>a microphone arranged in vicinity of the speaker to acquire a sound signal from sounds present in the ear of the user, the acquired sounds including audio sound generated by the speaker for rendering the audio content; and</claim-text>
<claim-text>a signal processor, wherein the signal processor has a first input and a second input, the second input of the signal processor being coupled to the microphone, wherein the first input of the signal processor is different from the second input and is coupled to an input of the speaker at which the electronic audio signal is supplied to the speaker, and the signal processor is arranged to filter the acquired sound signal and to then subtract the electronic audio signal which is supplied to the speaker for rendering and which is received at the first input of the signal processor from the filtered acquired sound signal to provide a physiological sound signal, and the signal processor is further arranged to detect a physiological measurement from the physiological sound signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a filter arranged to filter the sound signal, the audio signal to be subtracted or the physiological sound signal.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising an application arranged to control features of the application based on the physiological measurement.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the application is arranged to make a music selection based on the physiological measurement, wherein the selected music is comprised in the supplied audio signal.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the physiological measurement comprises a breathing pattern.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the signal processor is arranged to determine a breathing rate from the breathing pattern.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the music is selected based on the music's beat rate, the music's beat rate of the selected music being a monotonic function of the breathing rate.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the music is selected based on the music's beat rate, the music's beat rate of the selected music being a function of the breathing rate wherein the music's beat rate is increased until a predetermined breathing rate is reached.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the physiological measurement comprises a heartbeat.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the signal processor is arranged to determine a heartbeat rate from the heartbeat.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the music is selected based on the music's beat rate, the music's beat rate of the selected music being a monotonic function of the heartbeat rate.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the music is selected based on the music's beat rate, the music's beat rate of the selected music being a function of the heartbeat rate wherein the music's beat rate is increased until a predetermined heartbeat rate is reached.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the signal processor is arranged to extract the heartbeat by low pass filtering the physiological sound signal in a low pass filter to provide a heartbeat signal.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the low pass filter has a cutoff frequency between 3 and 10 Hz.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising a second speaker suitable to be provided at the user's other ear, wherein an audio signal provided to the second speaker comprises a sub-signal and wherein the sound signal comprises a signal component emanating from sound provided at the user's other ear and which sound is modulatedly attenuated by pulsating blood of veins of the user when the sound propagates through the head of the user, and the heartbeat is extractable from the signal component.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the signal processor is arranged to extract the heartbeat by low pass filtering the physiological sound signal in a low pass filter to provide the signal component signal.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the low pass filter has a cutoff frequency between 3 and 10 Hz.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, comprising a heart rate estimator arranged to estimate heart rate from the breathing pattern.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The apparatus according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the physiological measurement comprises a heartbeat, the signal processor is arranged to determine a heartbeat rate from the heartbeat, and the apparatus is further arranged to provide a comparison between the estimated heart rate and the determined heart rate.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the physiological measurement comprises a heartbeat and a breathing pattern.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. A method comprising
<claim-text>providing, by a media player element, audio content for rendering;</claim-text>
<claim-text>supplying an electronic audio signal to a speaker suitable to be applied at a user's ear for rendering the audio signal in the user's ear, the electronic audio signal being generated based on the audio content provided by the media player element;</claim-text>
<claim-text>acquiring a sound signal by a microphone arranged in vicinity of the speaker to acquire the sound signal from sounds present in the ear of the user, the acquired sounds including audio sound generated by the speaker for rendering the audio content, the acquired sounds being received by a signal processor which has a first input and a second input, the acquired sounds being received at the second input of the signal processor, and the first input of the signal processor being different from the second input and being coupled to an input of the speaker;</claim-text>
<claim-text>monitoring, by the signal processor, the electronic audio signal supplied to the speaker for rendering;</claim-text>
<claim-text>filtering the acquired sound signal;</claim-text>
<claim-text>subtracting the monitored electronic audio signal which is supplied to the speaker for rendering from the filtered acquired sound signal to provide a physiological sound signal; and</claim-text>
<claim-text>detecting a physiological measurement from the physiological sound signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising filtering the sound signal, the audio signal to be subtracted or the physiological sound signal.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the physiological measurement comprises a breathing pattern, and the method further comprising controlling features of an application based on the breathing pattern.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method according to <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the controlling of features of the application comprises selecting music based on the breathing pattern, wherein the selected music is provided to be comprised in the supplied audio signal.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method according to <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising determining a breathing rate from the breathing pattern.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method according to <claim-ref idref="CLM-00025">claim 25</claim-ref>, wherein the music is selected based on the music's beat rate, the music's beat rate of the selected music being a monotonic function of the breathing rate.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The method according to <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising
<claim-text>selecting music based on the breathing pattern, wherein the selected music is provided to be comprised in the supplied audio signal; and</claim-text>
<claim-text>determining a breathing rate from the breathing pattern,</claim-text>
<claim-text>wherein the selection of music is based on the music's beat rate, the music's beat rate of the selected music being increased until a predetermined breathing rate is reached.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The method according to <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising estimating a heart rate from the breathing pattern.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the physiological measurement comprises a heartbeat, the method further comprising determining a heartbeat rate from the heartbeat; and comparing the estimated heart rate and the determined heart rate, wherein the result of the comparison is used for controlling the features of the application.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The method according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising extracting a heartbeat by low pass filtering the physiological sound signal in a low pass filter to provide a heartbeat signal.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The method according to <claim-ref idref="CLM-00030">claim 30</claim-ref>, wherein the low pass filter has a cutoff frequency between 3 and 10 Hz.</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The method according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the physiological measurement comprises a heartbeat, and the method further comprises
<claim-text>providing an audio signal which comprises a sub-signal to a second speaker suitable to be applied at the user's other ear, wherein the sound signal comprises a signal component emanating from sound provided at the user's other ear and which sound is modulatedly attenuated by pulsating blood of veins of the user when the sound propagates through the head of the user; and</claim-text>
<claim-text>detecting the heartbeat from the signal component.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The method according to <claim-ref idref="CLM-00032">claim 32</claim-ref>, further comprising low pass filtering the physiological sound signal in a low pass filter to provide the signal component signal.</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. The method according to <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the low pass filter has a cutoff frequency between 3 and 10 Hz.</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. The method according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the physiological measurement comprises a heartbeat and a breathing pattern.</claim-text>
</claim>
<claim id="CLM-00036" num="00036">
<claim-text>36. A non-transitory computer readable medium comprising program code comprising instructions which when executed by a processor is arranged to cause the processor to perform
<claim-text>providing, by a media player element, audio content for rendering;</claim-text>
<claim-text>supplying an electronic audio signal to a speaker suitable to be applied at a user's ear for rendering the audio signal in the user's ear, the electronic audio signal being generated based on the audio content provided by the media player element;</claim-text>
<claim-text>acquiring a sound signal by a microphone arranged in vicinity of the speaker to acquire the sound signal from sounds present in the ear of the user, the acquired sounds including audio sound generated by the speaker for rendering the audio content, the acquired sounds being received by a signal processor which has a first input and a second input, the acquired sounds being received at the second input of the signal processor, and the first input of the signal processor being different from the second input and being coupled to an input of the speaker;</claim-text>
<claim-text>monitoring, by the signal processor, the electronic audio signal supplied to the speaker;</claim-text>
<claim-text>filtering the acquired sound signal;</claim-text>
<claim-text>subtracting the monitored electronic audio signal which is supplied to the speaker for rendering from the filtered acquired sound signal to provide a physiological sound signal; and</claim-text>
<claim-text>detecting a physiological measurement from the physiological sound signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00037" num="00037">
<claim-text>37. The computer readable medium according to <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein the instructions are further arranged to cause the processor to select music based on the physiological measurement, wherein the selected music is provided to be comprised in the supplied audio signal. </claim-text>
</claim>
</claims>
</us-patent-grant>
