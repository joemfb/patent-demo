<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624894-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624894</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13067411</doc-number>
<date>20110531</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2010-0092377</doc-number>
<date>20100920</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>255</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>40</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345422</main-classification>
<further-classification>345426</further-classification>
</classification-national>
<invention-title id="d2e71">Apparatus and method of early pixel discarding in graphic processing unit</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6476807</doc-number>
<kind>B1</kind>
<name>Duluk et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345421</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6930684</doc-number>
<kind>B2</kind>
<name>Tjew</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345421</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7385608</doc-number>
<kind>B1</kind>
<name>Baldwin</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345506</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>8094152</doc-number>
<kind>B1</kind>
<name>Myers et al.</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345422</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2002/0130886</doc-number>
<kind>A1</kind>
<name>Baldwin</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345611</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2003/0011594</doc-number>
<kind>A1</kind>
<name>Park et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345422</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2003/0164825</doc-number>
<kind>A1</kind>
<name>Baldwin et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2003/0164830</doc-number>
<kind>A1</kind>
<name>Kent</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345505</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2003/0164840</doc-number>
<kind>A1</kind>
<name>O'Driscoll</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345611</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2004/0246260</doc-number>
<kind>A1</kind>
<name>Kim et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345557</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0195187</doc-number>
<kind>A1</kind>
<name>Seiler et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2005/0195198</doc-number>
<kind>A1</kind>
<name>Anderson et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345506</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2006/0098021</doc-number>
<kind>A1</kind>
<name>Rim et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345543</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2007/0257905</doc-number>
<kind>A1</kind>
<name>French et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2007/0291030</doc-number>
<kind>A1</kind>
<name>Fowler et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345422</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2008/0059956</doc-number>
<kind>A1</kind>
<name>Su</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717140</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2008/0106551</doc-number>
<kind>A1</kind>
<name>Jung et al.</name>
<date>20080500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345506</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2009/0284535</doc-number>
<kind>A1</kind>
<name>Pelton et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345505</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2010/0007662</doc-number>
<kind>A1</kind>
<name>Cox et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345420</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2010/0141666</doc-number>
<kind>A1</kind>
<name>Christopher et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345520</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>2006-127556</doc-number>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>JP</country>
<doc-number>2009-181582</doc-number>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>KR</country>
<doc-number>10-0478767</doc-number>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>KR</country>
<doc-number>10-0485241</doc-number>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>KR</country>
<doc-number>10-0887012</doc-number>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>KR</country>
<doc-number>10-2009-0117809</doc-number>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>KR</country>
<doc-number>10-2010-0051750</doc-number>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Yu, Chang-Hyo; An Adaptive Spatial Filter for Early Depth Test; 2004; Circuits and Systems, ISCAS '04; vol. 2; pp. II-137-II-140.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>Timo Aila et al; Delay streams for graphics hardware; 2003; SIGGRAPH '03 ACM SIGGRAPH 2003; vol. 22 Issue 3; pp. 792-800.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>Woo-Chan Park, et al. &#x201c;An Effective Pixel Rasterization Pipeline Architecture for 3D Rendering Processors&#x201d;, IEEE Transactions on Computers, vol. 52, No. 11, Nov. 2003. (8pg).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345422</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345426</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120069021</doc-number>
<kind>A1</kind>
<date>20120322</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Son</last-name>
<first-name>Sung Jin</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Jung</last-name>
<first-name>Seok Yoon</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Park</last-name>
<first-name>Chan Min</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Min</last-name>
<first-name>Kyoung June</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Oak Woo</last-name>
<first-name>Sang</first-name>
<address>
<city>Anyang-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Son</last-name>
<first-name>Sung Jin</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Jung</last-name>
<first-name>Seok Yoon</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Park</last-name>
<first-name>Chan Min</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Min</last-name>
<first-name>Kyoung June</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Oak Woo</last-name>
<first-name>Sang</first-name>
<address>
<city>Anyang-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Staas &#x26; Halsey LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Samsung Electronics Co., Ltd</orgname>
<role>03</role>
<address>
<city>Suwon-Si</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>McDowell, Jr.</last-name>
<first-name>Maurice L</first-name>
<department>2677</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method to discard pixels early includes a first early depth test maintaining a depth value on a pixel to be discarded by a discard instruction, and a second early depth test updating the depth value on a pixel not to be discarded by the discard instruction. Because of the first and second early depth tests, a number of pixels to be processed by a pixel shading process may be reduced.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="80.60mm" wi="220.47mm" file="US08624894-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="220.13mm" wi="122.09mm" orientation="landscape" file="US08624894-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="223.69mm" wi="103.72mm" orientation="landscape" file="US08624894-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="223.44mm" wi="105.33mm" orientation="landscape" file="US08624894-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="176.53mm" wi="124.46mm" orientation="landscape" file="US08624894-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="183.90mm" wi="97.96mm" orientation="landscape" file="US08624894-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="212.85mm" wi="145.29mm" file="US08624894-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="220.47mm" wi="127.68mm" orientation="landscape" file="US08624894-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="200.49mm" wi="155.96mm" orientation="landscape" file="US08624894-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="232.66mm" wi="178.05mm" file="US08624894-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="179.15mm" wi="139.28mm" file="US08624894-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims the priority benefit of Korean Patent Application No. 10-2010-0092377, filed on Sep. 20, 2010, in the Korean Intellectual Property Office, the disclosure of which is incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">1. Field</p>
<p id="p-0004" num="0003">Example embodiments relate to an apparatus and a method of early pixel discarding in a graphic processing unit.</p>
<p id="p-0005" num="0004">More particularly, disclosed are an apparatus and a method of eliminating unnecessary pixels in advance in three-dimensional (3D) rendering operations to improve rendering performance.</p>
<p id="p-0006" num="0005">2. Description of the Related Art</p>
<p id="p-0007" num="0006">Three-dimensional (3D) rendering is image processing to synthesize 3D object data onto an image to be viewed from a viewpoint of a camera.</p>
<p id="p-0008" num="0007">In order to generate a 3D image in real time, a rasterization process which generates an image by projecting a 3D object on a screen is widely used.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0009" num="0008">The foregoing and/or other aspects are achieved by providing a three-dimensional (3D) rendering apparatus including a discard shading processor that performs a first early depth test maintaining a depth value and processing a discard shader to selectively discard a pixel, and a pixel shading processor that performs a second early depth test updating the depth value to selectively discard the pixel, and using a pixel shader to process the pixel, wherein the discard shading processor outputs a pixel not discarded to the pixel shading processor.</p>
<p id="p-0010" num="0009">The discard shader may correspond to a part associated with a discard instruction, and the pixel shader may correspond to another part excluding the part corresponding to the discard shader.</p>
<p id="p-0011" num="0010">The discard shading processor may include a first depth tester performing the first early depth test on the pixel to selectively discard the pixel, and a discard shader unit processing a pixel not discarded by the first depth tester using the discard shader and processing a discard instruction on the pixel to selectively discard the pixel, wherein the first depth tester may maintain a depth value of a depth buffer corresponding to the pixel.</p>
<p id="p-0012" num="0011">The pixel shading processor may include a second depth tester performing the second early depth test on the pixel to selectively discard the pixel, and a pixel shader unit processing a pixel not discarded by the second depth tester using the pixel shader, wherein the second depth tester may update a depth value of a depth buffer corresponding to the pixel to a depth value of the discarded pixel when the pixel is discarded.</p>
<p id="p-0013" num="0012">The 3D rendering apparatus may further include a discard determination unit determining whether the pixel is a target to be processed by the discard shading processor, wherein the discard determination unit may output the pixel to the discard shading processor when the pixel is the target to be processed by the discard shading processor, and may output the pixel to the pixel shading processor when the pixel is different from the target to be processed by the discard shading processor.</p>
<p id="p-0014" num="0013">The 3D rendering apparatus may further include a rasterizer unit performing rasterization on the pixel and outputting the pixel to the discard determination unit, and a color blending unit receiving the pixel from the pixel shading processor and performing color blending on the pixel.</p>
<p id="p-0015" num="0014">The discard determination unit may output the pixel to the discard shading processor when the pixel shader to process the pixel includes the discard instruction, and may output the pixel to the pixel shading processor when the pixel shader does not include the discard instruction.</p>
<p id="p-0016" num="0015">The 3D rendering apparatus may further include a compiler unit dividing all pixel shader code with respect to the pixel into discard shader code and pixel shader code, compiling the discard shader code to generate the discard shader, and compiling the pixel shader code to generate the pixel shader, wherein the discard shader code may correspond to discard instruction code and previous code to the discard instruction among the all pixel shader code, and the pixel shader code may correspond to subsequent code to the discard instruction among the all pixel shader code.</p>
<p id="p-0017" num="0016">Information about the pixel may be transmitted from the discard shade code to the pixel shader code by a variable in the discard shader code.</p>
<p id="p-0018" num="0017">The example embodiments may provide a 3D rendering method including a discard shading process performing, by at least one processor, a first early depth test maintaining a depth value and processing a discard shader to selectively discard a pixel, and a pixel shading process performing, by the at least one processor, a second early depth test updating the depth value to selectively discard the pixel, and using a pixel shader to process the pixel, wherein a pixel not discarded in the discard shading process is processed in the pixel shading process.</p>
<p id="p-0019" num="0018">The discard shading process may include a first depth testing performing the first early depth test on the pixel to selectively discard the pixel, and a discard shading processing a pixel not discarded by the first early depth test using the discard shader and processing a discard instruction on the pixel to selectively discard the pixel, wherein the first depth testing may maintain a depth value of a depth buffer corresponding to the pixel.</p>
<p id="p-0020" num="0019">The pixel shading processor may include a second depth testing performing the second early depth test on the pixel to selectively discard the pixel, and a pixel shading processing a pixel not discarded by the second early depth test using the pixel shader, wherein the second depth testing may update, to a depth value of the discarded pixel, a depth value of a depth buffer corresponding to the pixel.</p>
<p id="p-0021" num="0020">The 3D rendering method may further include a discard determining process to determine whether the pixel is a target to be processed in the discard shading process, wherein the discard shading process may be performed when the pixel is the target to be processed in the discard shading process, and the pixel shading process may be performed when the pixel is different from the target to be processed in the discard shading process.</p>
<p id="p-0022" num="0021">The 3D rendering method may further include a rasterizing process performing rasterization on the pixel, and a color blending process performing color blending on the pixel.</p>
<p id="p-0023" num="0022">The discard shading process may be performed after the discard determining process when the pixel shader to process the pixel includes the discard instruction, and the pixel shading process may be performed when the pixel shader does not include the discard instruction.</p>
<p id="p-0024" num="0023">The discard shading process may perform a process represented by a discard shader code, and the pixel shading process may perform a process represented by a pixel shader code.</p>
<p id="p-0025" num="0024">The discard shader code may correspond to discard instruction code and previous code to a discard instruction among all pixel shader code with respect to the pixel, and the pixel shader code may correspond to subsequent code to the discard instruction among the all pixel shader code.</p>
<p id="p-0026" num="0025">The discard shading process may include a first varying data patching process extracting information about the pixel based on a variable in the discard shader code, and the pixel shading process may include a second varying data patching process extracting information about the pixel based on a variable in the pixel shader code.</p>
<p id="p-0027" num="0026">According to another aspect of one or more embodiments, there is provided at least one non-transitory computer readable medium including computer readable instructions that control at least one processor to implement methods of one or more embodiments.</p>
<p id="p-0028" num="0027">Additional aspects of embodiments will be set forth in part in the description which follows and, in part, will be apparent from the description, or may be learned by practice of the disclosure.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0029" num="0028">These and/or other aspects and advantages will become apparent and more readily appreciated from the following description of embodiments, taken in conjunction with the accompanying drawings of which:</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a pipeline of a rasterization-based three-dimensional (3D) graphics rendering technique according to example embodiments;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a pipeline in a pixel stage according to example embodiments;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a pipeline performing a simple early depth test according to example embodiments;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a resulting image based on a depth of objects according to example embodiments;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 5</figref> illustrates processing an object by a rendering pipeline according to example embodiments;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 6</figref> illustrates problems due to an early depth test and a process by a discard instruction according to example embodiments;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 7</figref> illustrates a structure of a 3D rendering apparatus according to example embodiments;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 8</figref> illustrates generation of code of a compiler according to example embodiments;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating a 3D rendering method according to example embodiments; and</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 10</figref> illustrates a result of a 3D rendering process according to example embodiments.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0040" num="0039">Reference will now be made in detail to embodiments, examples of which are illustrated in the accompanying drawings, wherein like reference numerals refer to the like elements throughout. Embodiments are described below to explain the present disclosure by referring to the figures.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a pipeline <b>100</b> of a rasterization-based three-dimensional (3D) graphics rendering technique according to example embodiments.</p>
<p id="p-0042" num="0041">The term &#x2018;pipeline&#x2019; refers to parallel operations on different pixels in each stage.</p>
<p id="p-0043" num="0042">The pipeline <b>100</b> may include a geometry stage <b>110</b> and a pixel stage <b>150</b>.</p>
<p id="p-0044" num="0043">In the geometry stage <b>110</b>, transformation and a back-face culling of a vertex in a space may be performed, and a coordinate of the vertex may be projected to a screen.</p>
<p id="p-0045" num="0044">In the pixel stage <b>150</b>, based on projected coordinates of vertices, pixels may be generated in a triangle or a polygon formed by the vertices, and color values of the respective pixels may be calculated.</p>
<p id="p-0046" num="0045">The geometry stage <b>110</b> may include a primitive processor <b>120</b>, a vertex shader <b>130</b>, and a primitive assembly <b>140</b>.</p>
<p id="p-0047" num="0046">The pixel stage <b>150</b> may include a rasterizer <b>160</b>, a pixel shader <b>170</b>, and a raster operation <b>180</b>.</p>
<p id="p-0048" num="0047">Figures in a lower part of <figref idref="DRAWINGS">FIG. 1</figref> illustrate processing a vertex or a pixel in each stage.</p>
<p id="p-0049" num="0048">The primitive processor <b>120</b> may obtain application-specific data and data structures from an application and generate vertices.</p>
<p id="p-0050" num="0049">A shader is a group of software instructions. The shader may be generally used to calculate rendering effects in graphics hardware. The shader may be used to program a rendering pipeline programmable by a graphics processing unit (GPU).</p>
<p id="p-0051" num="0050">The vertex shader <b>130</b> may be used once for each vertex provided to the GPU and transform a 3D position of each vertex in a virtual space into a 2D coordinate and a depth value of a Z-buffer to be displayed on a screen.</p>
<p id="p-0052" num="0051">The primitive assembly <b>140</b> may collect runs of vertex data output from the vertex shader <b>130</b> and form the runs into a viable primitive, for example, a line, a point, and a triangle.</p>
<p id="p-0053" num="0052">The rasterizer <b>160</b> may generate information about inside pixels by interpolating screen coordinates, texture coordinates, and the like, defined for each vertex in a primitive.</p>
<p id="p-0054" num="0053">The pixel shader <b>170</b> may perform code realized by a shader programmer to perform complex per-pixel effects with respect to each inside pixel. The pixel shader <b>170</b> may calculate color of pixels by texture mapping and calculation of reflection of light, or discard a particular pixel using a discard instruction. The discard instruction may eliminate a particular pixel in a pixel shader from a pipeline. The eliminated pixel is different from an object to be rendered.</p>
<p id="p-0055" num="0054">The raster operation <b>180</b> may perform a depth test and color blending to generate a raster image, such as pixels or dots, based on information about the pixels. The generated raster image may be copied into a frame buffer.</p>
<p id="p-0056" num="0055">The frame buffer is a video output device that may drive a video display from a memory buffer containing a complete frame of data.</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a pipeline in a pixel stage according to example embodiments.</p>
<p id="p-0058" num="0057">The pipeline <b>200</b> in the pixel stage may include a rasterizer <b>210</b>, a pixel shader <b>220</b>, a depth test <b>230</b>, and color blending <b>240</b>.</p>
<p id="p-0059" num="0058">The rasterizer <b>210</b> corresponds to the rasterizer <b>150</b> of <figref idref="DRAWINGS">FIG. 1</figref>, and the pixel shader <b>220</b> corresponds to the pixel shader <b>160</b> of <figref idref="DRAWINGS">FIG. 1</figref>. Thus, redundant descriptions are omitted.</p>
<p id="p-0060" num="0059">The raster operation <b>170</b> of <figref idref="DRAWINGS">FIG. 1</figref> corresponds to the depth test <b>230</b> and the color blending <b>240</b>.</p>
<p id="p-0061" num="0060">The depth test <b>230</b> may be a process of discarding pixels distant from a camera among pixels having the same coordinate so that only an object which is the closest to the camera may be shown in a final image. When the object closest to the camera is transparent, a next object may be shown.</p>
<p id="p-0062" num="0061">The depth test <b>230</b> may decrease a number of 3D rendering operations by representing only objects close to the camera as an image and early discarding pixels which are not displayed in the image.</p>
<p id="p-0063" num="0062">The color blending <b>240</b> may calculate color of a final image by mixing color of calculated pixels, for example, semi-transparent pixels having the same coordinates or pixels having a value of alpha.</p>
<p id="p-0064" num="0063">In a 3D rendering process, when pixels to be eliminated by a discard or a depth test are detected before a process by the pixel shader <b>220</b>, the pixel shader <b>220</b> may perform minimum operations to improve 3D rendering performance.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a pipeline performing a simple early depth test according to example embodiments.</p>
<p id="p-0066" num="0065">When pixels are selectively discarded by a depth test before a process by a pixel shader, a number of pixels to be processed by the pixel shader may decrease, and 3D rendering performance may be improved.</p>
<p id="p-0067" num="0066">The pipeline <b>300</b> performing the simple early depth test may include a rasterizer <b>310</b>, an early depth test <b>320</b>, a pixel shader <b>330</b>, and color blending <b>340</b>.</p>
<p id="p-0068" num="0067">The rasterizer <b>310</b> and the color blending <b>340</b> respectively correspond to the rasterizer <b>210</b> and the color blending <b>240</b> of <figref idref="DRAWINGS">FIG. 2</figref>. Thus, redundant descriptions are omitted.</p>
<p id="p-0069" num="0068">The early depth test <b>320</b> corresponds to the depth test <b>230</b> of <figref idref="DRAWINGS">FIG. 2</figref>, however, is performed before a process by the pixel shader <b>330</b>. The pixel shader <b>330</b> corresponds to the pixel shader <b>220</b> of <figref idref="DRAWINGS">FIG. 2</figref>, however, only processes pixels which are not eliminated by the early depth test <b>320</b>.</p>
<p id="p-0070" num="0069">When a first pixel which is closest to a camera is eliminated by a discard instruction of the pixel shader <b>330</b>, a second pixel behind the first pixel is shown. However, when the depth test is performed before the process by the pixel shader <b>330</b> to discard a pixel, the second pixel is already discarded by the depth test and is not shown.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIGS. 4 to 6</figref> illustrate problems of a depth test and an early depth test according to example embodiments.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a resulting image based on a depth of objects according to example embodiments.</p>
<p id="p-0073" num="0072">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, a first object <b>410</b>, a second object <b>420</b>, and a third object <b>430</b> are illustrated.</p>
<p id="p-0074" num="0073">The first object <b>410</b> and the second object <b>420</b> are opaque objects, and the third object <b>430</b> is a transparent object.</p>
<p id="p-0075" num="0074">The third object <b>430</b> may be positioned closest to a camera or an observer. The second object <b>420</b> may be positioned between the third object <b>430</b> and the first object <b>410</b>, and the first object may be positioned farthest away from the camera. That is, the third object <b>430</b> has a depth value of 3, the second object has a depth value of 2, and the first object <b>410</b> has a depth value of 1.</p>
<p id="p-0076" num="0075">When rendering is performed, an object closest to the camera may be displayed as a resulting image <b>440</b>. However, according to the example embodiments, because the closest object is transparent, a next closest object that is the second object <b>420</b> may be displayed as the resulting image <b>440</b>. Here, the resulting image <b>440</b> has a depth value of 3 that corresponds to the depth value of the transparent third object <b>430</b>, different from a depth value of 2 that corresponds to the depth value of the second object <b>420</b>.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 5</figref> illustrates processing an object by a rendering pipeline according to example embodiments.</p>
<p id="p-0078" num="0077">Referring to <figref idref="DRAWINGS">FIG. 5</figref>, the first object <b>410</b>, the second object <b>420</b>, and the third object <b>430</b> of <figref idref="DRAWINGS">FIG. 4</figref> may be sequentially processed by the rendering pipeline. The first object <b>410</b> is processed first, the third object <b>430</b> is then processed, and the second object <b>420</b> is finally processed.</p>
<p id="p-0079" num="0078">As shown in <figref idref="DRAWINGS">FIG. 5</figref>, an order of processing the objects may be different from an order of the objects based on the depth values.</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. 6</figref> illustrates problems because of the early depth test and a process of a discard instruction according to example embodiments.</p>
<p id="p-0081" num="0080">Depth test <b>640</b> corresponds to the early depth test <b>320</b> of <figref idref="DRAWINGS">FIG. 3</figref>. A pixel shader <b>650</b> corresponds to the pixel shader <b>330</b> of <figref idref="DRAWINGS">FIG. 3</figref>. Thus, redundant descriptions are omitted.</p>
<p id="p-0082" num="0081">A depth buffer <b>660</b> may store a depth value. The depth value may be a depth value of an object displayed in a particular coordinate. The depth value of the depth buffer <b>660</b> may be initialized to a value to represent the farthest distance, for example, 0.</p>
<p id="p-0083" num="0082">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, the three objects or pixels <b>410</b>, <b>430</b>, and <b>420</b> having the depth values, may be sequentially processed by pipelines <b>640</b> and <b>650</b>. <b>610</b>, <b>620</b>, and <b>630</b> processing the respective objects may be separately described.</p>
<p id="p-0084" num="0083">In <b>610</b>, the first object <b>410</b> may be processed.</p>
<p id="p-0085" num="0084">The first object <b>410</b> may have a depth value of 1 that is greater than an initial value stored in the depth buffer <b>660</b>. Thus, the first object <b>410</b> may pass through the depth test <b>640</b> and is not discarded by the depth test <b>640</b>. The depth value of the depth buffer <b>660</b> may be updated to 1, which is the depth value of the first object <b>410</b>.</p>
<p id="p-0086" num="0085">The first object <b>410</b> may pass through the pixel shader <b>650</b> and is not discarded by the pixel shader <b>650</b>. Thus, the resulting image <b>440</b> corresponds to the first object <b>410</b>.</p>
<p id="p-0087" num="0086">In <b>620</b>, the third object <b>430</b> may be processed.</p>
<p id="p-0088" num="0087">The third object <b>430</b> may have a depth value of 3 which is greater than the initial depth value of 1 stored in the depth buffer <b>660</b>. Thus, the third object <b>430</b> may pass through the depth test <b>640</b> and is not discarded by the depth test <b>640</b>. The depth value of the depth buffer <b>660</b> may be updated to 3, which is the depth value of the third object <b>430</b>.</p>
<p id="p-0089" num="0088">However, the third object <b>430</b> is a transparent object, and as a result the third object <b>430</b> is discarded by the pixel shader <b>650</b> and does not pass through the pixel shader <b>650</b>. Thus, the resulting image <b>440</b> is still the first object <b>410</b>.</p>
<p id="p-0090" num="0089">In <b>630</b>, the second object <b>420</b> is processed.</p>
<p id="p-0091" num="0090">The second object <b>420</b> may have a depth value of 2 which is less than the depth value of 3 stored in the updated depth buffer <b>660</b>. Thus, the third object <b>430</b> may be discarded by the depth test <b>640</b> and does not pass through the depth test <b>640</b>.</p>
<p id="p-0092" num="0091">Thus, the result image <b>440</b> is still the first object <b>410</b>, which is different from a proper result described above with reference to <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0093" num="0092">When the early depth test is applied to each of a plurality of objects processed in optional order, and a part of the objects is discarded by a discard instruction, an incorrect image may be generated.</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. 7</figref> illustrates a structure of a 3D rendering apparatus according to example embodiments.</p>
<p id="p-0095" num="0094">The 3D rendering apparatus <b>700</b> may include a rendering pipeline unit <b>710</b>, a compiler unit <b>770</b>, and a frame buffer <b>780</b>.</p>
<p id="p-0096" num="0095">The rendering pipeline unit <b>710</b> may include a rasterizer unit <b>720</b>, a discard determination unit <b>730</b>, a discard shading processor <b>740</b>, a pixel shading processor <b>750</b>, and a color blending unit <b>760</b>. The rendering pipeline unit <b>710</b> may further include the primitive processor <b>120</b>, the vertex shader <b>130</b>, and the primitive assembly <b>140</b> of <figref idref="DRAWINGS">FIG. 1</figref>, or may further include components corresponding to the above components.</p>
<p id="p-0097" num="0096">The rasterizer unit <b>720</b> may perform rasterization on a pixel input to the rendering pipeline unit <b>710</b> and output the pixel to the discard determination unit <b>730</b>.</p>
<p id="p-0098" num="0097">The discard determination unit <b>730</b> may output the input pixel to the discard shading processor <b>740</b> when the input pixel is a target to be processed by the discard shading processor <b>740</b>. The discard determination unit <b>730</b> may output the input pixel to the pixel shading processor <b>750</b> when the input pixel is different from a target pixel to be processed by the discard shading processor <b>740</b>.</p>
<p id="p-0099" num="0098">In other words, the discard determination unit <b>730</b> may function as a switch with respect to an input pixel.</p>
<p id="p-0100" num="0099">The discard determination unit <b>730</b> may output the input pixel to the discard shading processor <b>740</b> when a pixel shader to process the input pixel includes a discard instruction. The discard determination unit <b>730</b> may output the input pixel to the pixel shading processor <b>750</b> when the pixel shader to process the input pixel does not include a discard instruction.</p>
<p id="p-0101" num="0100">The color blending unit <b>760</b> may receive a pixel from the pixel shading processor <b>750</b> and perform color blending on the pixel. A result of color blending may be output to the frame buffer <b>780</b>.</p>
<p id="p-0102" num="0101">The discard shading processor <b>740</b> may perform an early depth test maintaining a depth value and process the discard shader to selectively discard an input pixel. The discard shading processor <b>740</b> may output an input pixel not discarded to the pixel shading processor <b>750</b>.</p>
<p id="p-0103" num="0102">Part of the input pixels is discarded by the early depth test and the discard instruction, but the remaining pixels are output to the pixel shading processor <b>750</b>.</p>
<p id="p-0104" num="0103">The discard shading processor <b>740</b> may perform the early depth test and does not update a depth value of a depth buffer.</p>
<p id="p-0105" num="0104">The pixel shading processor <b>750</b> may perform an early depth test updating a depth value to selectively discard the pixels and use the pixel shader to process the pixels. That is, part of the input pixels may be discarded by the early depth test. The remaining pixels may be determined to have a final color by the pixel shader, and the pixels having the determined color may be output to the color blending unit <b>760</b>.</p>
<p id="p-0106" num="0105">The discard shader may correspond to a part associated with the discard instruction among the entire pixel shader to process an input pixel, and the pixel shader may correspond to another part excluding the part corresponding to the discard shader.</p>
<p id="p-0107" num="0106">When the entire pixel shader processing an input pixel does not include the discard instruction, the input pixel may be input directly to the pixel shading processor <b>750</b> by the discard determination unit <b>730</b> instead of going through the discard shading processor <b>740</b>.</p>
<p id="p-0108" num="0107">The depth value of the depth buffer may be updated by the pixel shading processor <b>750</b>, and the updated depth value may be effective for a pixel on which the early depth tests are performed by the discard shading processor <b>740</b> and the pixel shading processor <b>750</b>. In other words, a pixel with a higher depth value may be discarded by the early depth test. Updating the depth value of the depth buffer may be performed after determining whether an input pixel is discarded by the discard instruction.</p>
<p id="p-0109" num="0108">Further, the depth buffer may be updated before color of a pixel is calculated and other pixels may be compared using parallel pipeline processing based on an updated depth value. Accordingly, efficiency of the early depth test may be improved, and the parallel processing performance of the rendering pipeline unit <b>710</b> may be enhanced. Moreover, operation times of the 3D rendering apparatus <b>700</b> may be reduced, and a smaller memory bandwidth may be used in the 3D rendering apparatus <b>700</b>.</p>
<p id="p-0110" num="0109">The pixel shader used by the pixel shading processor <b>750</b> may not include a discard instruction. Thus, the problems because of the early depth test described above with reference to <figref idref="DRAWINGS">FIG. 6</figref> may not occur. Therefore, a pixel processed by the shader not including the discard instruction may be discarded by the general early depth test of the pixel shading processor <b>750</b> because the pixel does not go through the discard shading processor <b>740</b>.</p>
<p id="p-0111" num="0110">The discard shading processor <b>740</b> may include a first depth tester <b>742</b> and a discard shader unit <b>744</b>.</p>
<p id="p-0112" num="0111">The first depth tester <b>742</b> may perform an early depth test on input pixels to selectively discard input pixels. The first depth tester <b>742</b> may not change the depth value of the depth buffer. In other words, the first depth tester <b>742</b> may maintain the depth value of the depth buffer corresponding to input pixels.</p>
<p id="p-0113" num="0112">The discard shader unit <b>744</b> may process a discard instruction on input pixels to selectively discard input pixels.</p>
<p id="p-0114" num="0113">The pixel shading processor <b>750</b> may include a second depth tester <b>752</b> and a pixel shader unit <b>754</b>.</p>
<p id="p-0115" num="0114">The second depth tester <b>752</b> may perform a depth test on input pixels to selectively discard input pixels. The second depth tester <b>752</b> may update a depth value of the depth buffer corresponding to an input pixel to a depth value of the input pixel when the input pixel passes though the depth test.</p>
<p id="p-0116" num="0115">The pixel shader unit <b>754</b> may use a pixel shader to process pixels not discarded by the second depth tester <b>752</b>. Pixels may be selectively discarded by the first depth tester <b>742</b>, the discard shader unit <b>744</b>, and the second depth tester <b>752</b> before the pixels are processed by the pixel shader unit <b>754</b>. Accordingly, a number of the pixels to be processed by the pixel shader unit <b>754</b> may be reduced. Further, operation times by the pixel shader unit <b>754</b> and a memory bandwidth used by the pixel shader unit <b>754</b> may be reduced. Generally, since the pixel shader unit <b>754</b> represents a bottleneck of the 3D rendering apparatus <b>700</b>, improvement in performance of the pixel shader unit <b>754</b> may bring about an improvement in overall performance of the 3D rendering apparatus <b>700</b> and a decrease in power consumption.</p>
<p id="p-0117" num="0116">In order to efficiently process pixels, pixels may be divided into pixels going through the discard shading processor <b>740</b> and pixels directly input to the pixel shading processor <b>750</b>, and general pixel shader code to process the pixels are divided into code corresponding to the discard instruction and code not corresponding thereto.</p>
<p id="p-0118" num="0117">A programmer programming the general pixel shader code may separately program discard shader code corresponding to the discard instruction and modified pixel shader code not corresponding thereto.</p>
<p id="p-0119" num="0118">The compiler unit <b>770</b> may divide the general pixel shader code with respect to pixels into the discard shader code and the modified pixel shader code. The compiler unit <b>770</b> may compile the discard shader code to generate a discard shader, and may compile the modified pixel shader code to generate a pixel shader. The operations may be transparently performed by the programmer.</p>
<p id="p-0120" num="0119">The discard shader code may correspond to discard instruction code and previous code to the discard instruction among the general pixel shader codes, and the pixel shader code may correspond to subsequent code to the discard instruction among the general pixel shader code.</p>
<p id="p-0121" num="0120">In order to prevent redundant calculations of the discard shader and the pixel shader, a result of an operation by the discard shader is transmitted to the pixel shader.</p>
<p id="p-0122" num="0121">The result of the operation, i.e., information or attributes about pixels, may be transmitted from the discard shader code to the pixel shader code by a varying parameter of the discard shader code. As the varying parameter is added to the discard shader, operation times of the 3D rendering apparatus <b>700</b> may be reduced. The attributes of the pixels may include positional values of pixels or normal values of pixels.</p>
<p id="p-0123" num="0122">Functions of the above components <b>710</b> to <b>780</b> may be performed by a single controller (not shown). The controller may be a single processor or a multi-processor. The above components <b>710</b> to <b>780</b> may be services, processes, threads, or modules performed by the controller.</p>
<p id="p-0124" num="0123"><figref idref="DRAWINGS">FIG. 8</figref> illustrates generation of code of a compiler according to example embodiments.</p>
<p id="p-0125" num="0124">The compiler unit <b>770</b> may generate discard pixel shader code <b>820</b> and modified pixel shader code <b>830</b> based on original pixel shader code <b>810</b>.</p>
<p id="p-0126" num="0125">The compiler unit <b>770</b> may analyze the original pixel shader code <b>810</b> and divide the original pixel shader code <b>810</b> based on an inside discard instruction to generate code <b>820</b> and <b>830</b>.</p>
<p id="p-0127" num="0126">The original pixel shader code <b>810</b> may provide a shader which calculates a color value of only pixels in a circle with respect to pixels generated based on a rectangle and discards pixels outside the circle.</p>
<p id="p-0128" num="0127">The discard pixel shader code <b>820</b> may provide a shader which discards the pixels outside the circle, and the modified pixel shader code <b>830</b> may provide a shader which calculates color of the pixels in the circle.</p>
<p id="p-0129" num="0128">(4&#x2212;&#x3c0;)r<sup>2 </sup>pixels per rectangle may be discarded early by the discard pixel shader code <b>820</b>. Pixel shading by the modified pixel shader code <b>830</b> may not be performed on the discarded pixels. Thus, operation times of the 3D rendering apparatus <b>700</b> may be reduced, and a smaller data bandwidth may be used in the 3D rendering apparatus <b>700</b>.</p>
<p id="p-0130" num="0129">A result of an operation by a discard pixel shader, for example, information about pixels may be transmitted to a pixel shader by a new varying parameter. Transmission of the operation result using the varying parameter prevents redundant calculations and may minimize an overhead as a result of the use of two shaders.</p>
<p id="p-0131" num="0130">Thus, the discard pixel shader code <b>820</b> and the modified pixel shader code <b>830</b> may include a varying parameter declaration unit <b>840</b>. The discard pixel shader code <b>820</b> may include a part <b>850</b> to set a varying parameter value, and the modified pixel shader code <b>830</b> may include a part <b>860</b> to extract a varying parameter value.</p>
<p id="p-0132" num="0131">Unnecessary variables may need not be loaded to a memory, and as a result, a smaller memory bandwidth may be used in the 3D rendering apparatus <b>700</b>.</p>
<p id="p-0133" num="0132"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating a 3D rendering process according to example embodiments.</p>
<p id="p-0134" num="0133">In <b>910</b>, rasterization may be performed on input pixels.</p>
<p id="p-0135" num="0134">In <b>920</b> to determine discarding, it may be determined whether the pixels are targets for a discard shading process in <b>930</b> to <b>960</b>. When the pixels are targets for the discard shading process in <b>930</b> to <b>960</b>, the discard shading process may be performed in <b>920</b>. When the pixels are different from targets for the discard shading process in <b>930</b> to <b>960</b>, a pixel shading process in <b>970</b> to <b>982</b> may be performed.</p>
<p id="p-0136" num="0135">A discard shader may correspond to a part associated with a discard instruction among the entire pixel shader to process pixels. A pixel shader may correspond to another part among the entire pixel shader excluding the part corresponding to the discard shader.</p>
<p id="p-0137" num="0136">When the pixel shader processing pixels includes the discard instruction, the discard shading process in <b>930</b> to <b>960</b> may be performed after the determination of discarding in <b>920</b>. When the pixel shader does not include the discard instruction, the pixel shading process in <b>970</b> to <b>982</b> may be performed.</p>
<p id="p-0138" num="0137">The discard shading process in <b>930</b> to <b>960</b> may perform a process represented by discard shader code, and the pixel shading process in <b>970</b> to <b>982</b> may perform a process represented by pixel shader code.</p>
<p id="p-0139" num="0138">The discard shader code may correspond to discard instruction code and previous code to the discard instruction among the entire pixel shader code with respect to pixels, and the pixel shader code may correspond to subsequent code to the discard instruction among the entire pixel shader code.</p>
<p id="p-0140" num="0139">In the discard shading process in <b>930</b> to <b>960</b>, an early depth test maintaining a depth value may be performed, and a process by the discard shader may be performed to selectively discard pixels.</p>
<p id="p-0141" num="0140">In <b>930</b>, position and depth data of pixels may be patched.</p>
<p id="p-0142" num="0141">Next, in a first depth test in <b>932</b>, a depth test may be performed on the pixels. When the pixels pass the depth test, i.e., when a depth value of the pixels is greater than a value in a depth buffer, <b>940</b> may be performed. When the pixels do not pass the depth test, a pixel discarding process may be performed in <b>960</b>. Accordingly, in the first depth test in <b>932</b>, the depth test may be performed on the pixels to selectively discard pixels.</p>
<p id="p-0143" num="0142">Because the first depth test in <b>932</b> is performed before a discard shading in <b>942</b> to <b>950</b>, the depth test in the first depth test in <b>932</b> may be an early depth test.</p>
<p id="p-0144" num="0143">The first depth test in <b>932</b> may not include updating a depth value of the depth buffer. Thus, in the first depth test in <b>932</b>, a depth value of the depth buffer corresponding to a pixel may be maintained.</p>
<p id="p-0145" num="0144">In a first varying data patch in <b>940</b>, varying data of the pixels may be patched. In the first varying data patch in <b>940</b>, information about the pixels may be extracted based on a varying parameter of the discard shader code.</p>
<p id="p-0146" num="0145">In the discard shading in <b>942</b> to <b>950</b>, pixels not discarded by a first depth tester may be processed by the discard shader and are selectively discarded by processing the discard instruction on the pixels.</p>
<p id="p-0147" num="0146">In <b>942</b>, the discard shading may be performed on the pixels.</p>
<p id="p-0148" num="0147">In <b>950</b>, it may be determined whether the pixels are discarded. When the pixels are discarded, <b>960</b> may be performed. When the pixels are not discarded, a pixel shading process may be performed in <b>970</b> to <b>972</b>.</p>
<p id="p-0149" num="0148">In the pixel shading process in <b>970</b> to <b>972</b>, an early depth test to update a depth value may be performed to selectively discard pixels, and the pixel shader may be used to process the pixels. The pixels not discarded in the discard shading process in <b>930</b> to <b>960</b> may be processed in the pixel shading process in <b>970</b> to <b>972</b>.</p>
<p id="p-0150" num="0149">In <b>970</b>, position and depth data of the pixels may be patched.</p>
<p id="p-0151" num="0150">Next, in a second depth test in <b>972</b> and <b>974</b>, a depth test may be performed on the pixels to selectively discard pixels.</p>
<p id="p-0152" num="0151">In <b>972</b>, the depth test may be performed on the pixels. When the pixels pass the depth test, i.e., when a depth value of the pixels is greater than a value in a depth buffer, <b>974</b> may be performed. When the pixels do not pass the depth test, the pixel discarding process may be performed in <b>960</b>.</p>
<p id="p-0153" num="0152">The depth value of the depth buffer may be updated in <b>974</b> to a depth value of a pixel passing the depth test. The update is immediately effective in the first depth test in <b>932</b> and the second depth test in <b>972</b> and <b>974</b>, which are subsequently performed.</p>
<p id="p-0154" num="0153">The second depth test in <b>972</b> and <b>974</b> may be performed before a pixel shading in <b>982</b> and thus, the depth test in the second depth test in <b>972</b> and <b>974</b> is an early depth test.</p>
<p id="p-0155" num="0154">In a second varying data patch in <b>980</b>, varying data of the pixels may be patched. In the second varying data patch in <b>980</b>, information about the pixels may be extracted based on a varying parameter of the pixel shader code.</p>
<p id="p-0156" num="0155">In the pixel shading in <b>982</b>, pixels not discarded by the second depth test in <b>972</b> and <b>974</b> may be processed by the pixel shader.</p>
<p id="p-0157" num="0156">In a color blending in <b>990</b>, color blending may be performed on the pixels.</p>
<p id="p-0158" num="0157">In <b>992</b>, a color value of the pixels may be written in a frame buffer.</p>
<p id="p-0159" num="0158">Technical concepts according to example embodiments described above with reference to <figref idref="DRAWINGS">FIGS. 1 to 8</figref> may be applied to the present embodiments. Thus, detailed descriptions thereof are omitted for clarity and conciseness.</p>
<p id="p-0160" num="0159"><figref idref="DRAWINGS">FIG. 10</figref> illustrates a result of a 3D rendering process according to example embodiments.</p>
<p id="p-0161" num="0160"><figref idref="DRAWINGS">FIG. 10</figref> illustrates an image <b>1010</b> only processed by the pixel shading processor <b>740</b> not including the discard instruction, an image <b>1020</b> processed by the discard shading processor <b>750</b> including the discard instruction, and an image <b>1030</b> which is a combination of the two images <b>1010</b> and <b>1020</b>.</p>
<p id="p-0162" num="0161">The above-described embodiments may be recorded in non-transitory computer-readable media including program instructions to implement various operations embodied by a computer. The media may also include, alone or in combination with the program instructions, data files, data structures, and the like. The program instructions recorded on the media may be those specially designed and constructed for the purposes of the example embodiments, or they may be of the kind well-known and available to those having skill in the computer software arts. Examples of non-transitory computer-readable media include magnetic media such as hard disks, floppy disks, and magnetic tape; optical media such as CD ROM disks and DVDs; magneto-optical media such as optical disks; and hardware devices that are specially configured to store and perform program instructions, such as read-only memory (ROM), random access memory (RAM), flash memory, and the like. The computer-readable media may be a plurality of computer-readable storage devices in a distributed network, so that the program instructions are stored in the plurality of computer-readable storage devices and executed in a distributed fashion. The program instructions may be executed by one or more processors or processing devices. The computer-readable media may also be embodied in at least one application specific integrated circuit (ASIC) or Field Programmable Gate Array (FPGA). Examples of program instructions include both machine code, such as produced by a compiler, and files containing higher level code that may be executed by the computer using an interpreter. The described hardware devices may be configured to act as one or more software modules in order to perform the operations of the above-described embodiments, or vice versa.</p>
<p id="p-0163" num="0162">Although embodiments have been shown and described, it should be appreciated by those skilled in the art that changes may be made in these embodiments without departing from the principles and spirit of the disclosure, the scope of which is defined by the claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A three-dimensional (3D) rendering apparatus, comprising:
<claim-text>a discard shading processor that performs a first early depth test maintaining a depth value and processing a discard shader to selectively discard a pixel; and</claim-text>
<claim-text>a pixel shading processor that performs a second early depth test updating the depth value to selectively discard a remaining pixel, and using a pixel shader to process a second remaining pixel,</claim-text>
<claim-text>wherein the discard shading processor outputs the remaining pixel to the pixel shading processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The 3D rendering apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the discard shader corresponds to a part associated with a discard instruction, and the pixel shader corresponds to another part excluding the part corresponding to the discard shader.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The 3D rendering apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the discard shading processor comprises:
<claim-text>a first depth tester performing the first early depth test on the pixel to selectively discard the pixel; and</claim-text>
<claim-text>a discard shader unit processing the remaining pixel not discarded by the first depth tester using the discard shader and processing a discard instruction on the remaining pixel to selectively discard the pixel,</claim-text>
<claim-text>wherein the first depth tester maintains a depth value of a depth buffer corresponding to the pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The 3D rendering apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pixel shading processor comprises:
<claim-text>a second depth tester performing the second early depth test on the pixel to selectively discard the pixel; and</claim-text>
<claim-text>a pixel shader unit processing the remaining pixel not discarded by the second depth tester using the pixel shader,</claim-text>
<claim-text>wherein the second depth tester updates a depth value of a depth buffer corresponding to the remaining pixel to a depth value of the discarded pixel when the remaining pixel is discarded.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The 3D rendering apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a discard determination unit determining whether a second pixel is a target to be processed by the discard shading processor,
<claim-text>wherein the discard determination unit outputs the second pixel to the discard shading processor when the second pixel is the target to be processed by the discard shading processor, and outputs the second pixel to the pixel shading processor when the second pixel is different from the target to be processed by the discard shading processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The 3D rendering apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising:
<claim-text>a rasterizer unit performing rasterization on the pixel and outputting the pixel to the discard determination unit; and</claim-text>
<claim-text>a color blending unit receiving the second remaining pixel from the pixel shading processor and performing color blending on the pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The 3D rendering apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the discard determination unit outputs the pixel to the discard shading processor when the pixel shader to process the pixel comprises the discard instruction, and outputs the remaining pixel to the pixel shading processor when the pixel shader does not comprise the discard instruction.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The 3D rendering apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising a compiler unit dividing all pixel shader code with respect to the pixel into discard shader code and pixel shader code, compiling the discard shader code to generate the discard shader, and compiling the pixel shader code to generate the pixel shader,
<claim-text>wherein the discard shader code corresponds to discard instruction code and previous code to the discard instruction among the all pixel shader code, and the pixel shader code corresponds to subsequent code to the discard instruction among the all pixel shader code.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The 3D rendering apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein information about the pixel is transmitted from the discard shade code to the pixel shader code by a variable in the discard shader code.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The 3D rendering apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, a rasterizer unit performing rasterization on the pixel and outputting the pixel to the discard shading processor.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A three-dimensional (3D) rendering method, comprising:
<claim-text>a discard shading process performing, by at least one processor, a first early depth test maintaining a depth value and processing a discard shader to selectively discard a pixel; and</claim-text>
<claim-text>a pixel shading process performing, by the at least one processor, a second early depth test updating the depth value to selectively discard a remaining pixel, and using a pixel shader to process a second remaining pixel,</claim-text>
<claim-text>wherein the remaining pixel not discarded in the discard shading process is processed in the pixel shading process.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The 3D rendering method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the discard shader corresponds to a part associated with a discard instruction, and the pixel shader corresponds to another part, excluding the part corresponding to the discard shader.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The 3D rendering method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the discard shading process comprises:
<claim-text>a first depth testing performing the first early depth test on the pixel to selectively discard the pixel; and</claim-text>
<claim-text>a discard shading processing the remaining pixel not discarded by the first early depth test using the discard shader and processing a discard instruction on the remaining pixel to selectively discard the remaining pixel,</claim-text>
<claim-text>wherein the first depth testing maintains a depth value of a depth buffer corresponding to the remaining pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The 3D rendering method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the pixel shading processor comprises:
<claim-text>a second depth testing performing the second early depth test on the remaining pixel to selectively discard the remaining pixel; and</claim-text>
<claim-text>a pixel shading processing the second remaining pixel not discarded by the second early depth test using the pixel shader,</claim-text>
<claim-text>wherein the second depth testing updates a depth value of a depth buffer corresponding to the second remaining pixel to a depth value of the discarded pixel when the pixel is discarded.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The 3D rendering method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising a discard determining process to determine whether a second pixel is a target to be processed in the discard shading process, wherein the discard shading process is performed when the second pixel is the target to be processed in the discard shading process, and the pixel shading process is performed when the second pixel is different from the target to be processed in the discard shading process.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The 3D rendering method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising:
<claim-text>a rasterizing process performing rasterization on the pixel; and</claim-text>
<claim-text>a color blending process performing color blending on the second remaining pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The 3D rendering method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the discard shading process is performed after the discard determining process when the pixel shader to process the pixel comprises the discard instruction, and the pixel shading process is performed when the pixel shader does not comprise the discard instruction.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The 3D rendering method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the discard shading process performs a process represented by discard shader code, and the pixel shading process performs a process represented by pixel shader code,
<claim-text>wherein the discard shader code corresponds to discard instruction code and previous code to a discard instruction among all pixel shader code with respect to the pixel, and the pixel shader code corresponds to subsequent code to the discard instruction among the all pixel shader code.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The 3D rendering method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the discard shading process comprises a first varying data patching process extracting information about the pixel based on a variable in the discard shader code, and the pixel shading process comprises a second varying data patching process extracting information about the pixel based on a variable in the pixel shader code.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. At least one non-transitory computer-readable medium comprising computer readable instructions that control at least one processor to implement the three-dimensional (3D) rendering method of <claim-ref idref="CLM-00011">claim 11</claim-ref>. </claim-text>
</claim>
</claims>
</us-patent-grant>
