<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625888-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625888</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12841133</doc-number>
<date>20100721</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>469</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>34</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>66</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382164</main-classification>
<further-classification>382195</further-classification>
</classification-national>
<invention-title id="d2e53">Variable kernel size image matting</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5671294</doc-number>
<kind>A</kind>
<name>Rogers et al.</name>
<date>19970900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382228</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6130676</doc-number>
<kind>A</kind>
<name>Wise et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6134345</doc-number>
<kind>A</kind>
<name>Berman et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6226000</doc-number>
<kind>B1</kind>
<name>Richens et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6791573</doc-number>
<kind>B2</kind>
<name>Hamburg</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7280117</doc-number>
<kind>B2</kind>
<name>Fayan</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7400763</doc-number>
<kind>B2</kind>
<name>Hamburg</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7420590</doc-number>
<kind>B2</kind>
<name>Matusik et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7430339</doc-number>
<kind>B2</kind>
<name>Rother et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7627168</doc-number>
<kind>B2</kind>
<name>Hamburg</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7636128</doc-number>
<kind>B2</kind>
<name>Sun et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7692664</doc-number>
<kind>B2</kind>
<name>Weiss et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345592</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2002/0149686</doc-number>
<kind>A1</kind>
<name>Taubman</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348272</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2006/0029275</doc-number>
<kind>A1</kind>
<name>Li et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2006/0221248</doc-number>
<kind>A1</kind>
<name>McGuire et al.</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2007/0013813</doc-number>
<kind>A1</kind>
<name>Sun et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348587</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2007/0070226</doc-number>
<kind>A1</kind>
<name>Matusik et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2007/0165966</doc-number>
<kind>A1</kind>
<name>Weiss et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2007/0263119</doc-number>
<kind>A1</kind>
<name>Shum et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2008/0317388</doc-number>
<kind>A1</kind>
<name>Hamburg</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2009/0097728</doc-number>
<kind>A1</kind>
<name>Lee et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2009/0278859</doc-number>
<kind>A1</kind>
<name>Weiss et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2010/0030778</doc-number>
<kind>A1</kind>
<name>Liu et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  6</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2011/0038536</doc-number>
<kind>A1</kind>
<name>Gong</name>
<date>20110200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2011/0216976</doc-number>
<kind>A1</kind>
<name>Rother et al.</name>
<date>20110900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2011/0293247</doc-number>
<kind>A1</kind>
<name>Bhagavathy et al.</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2012/0008862</doc-number>
<kind>A1</kind>
<name>Das Gupta et al.</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382167</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2012/0020554</doc-number>
<kind>A1</kind>
<name>Sun et al.</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2012/0128070</doc-number>
<kind>A1</kind>
<name>Kim et al.</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524013</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>CN</country>
<doc-number>101536078</doc-number>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>CN</country>
<doc-number>101588459</doc-number>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00032">
<othercit>Office Action for U.S. Appl. No. 12/841,094, mailed on Feb. 3, 2012, Jian Sun, &#x201c;Interactive Image Matting&#x201d;, 9 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00033">
<othercit>Bai, et al., &#x201c;A Geodesic Framework for Fast Interactive Image and Video Segmentation and Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://webdocs.cs.ualberta.ca/&#x2dc;jag/papersVis2/07ICCV/data/papers/ICCV/094.pdf&#x3e;&#x3e;, IEEE International Conference on Computer Vision (ICCV), Rio De Janeiro, BR, 2007, pp. 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Borodajkewycz, &#x201c;Tomorrow's Photoshop Effects&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://forum.artoolkit.org/courses/Seminar/WS2009/Tomorrows<sub>&#x2014;</sub>PhotoShop<sub>&#x2014;</sub>Effects.pdf&#x3e;&#x3e;, Technische Universitat, Wien, Austria, Report at Seminar on Computer Graphics, 2009, pp. 1-18.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Bousseau, et al., &#x201c;User-Assisted Intrinsic Images&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://artis.imag.fr/Publications/2009/BPD09/intrinsic<sub>&#x2014;</sub>main.pdf&#x3e;&#x3e;, ACM, Transactions on Graphics (TOG), vol. 28, No. 5, Dec. 2009, pp. 1-10.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>Chang, et al., &#x201c;An Iterative Bayesian Approach for Digital Matting&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&#x26;arnumber=1699162&#x3e;&#x3e;, IEEE Computer Society, 18th International Conference on Pattern Recognition (ICPR), Hong Kong, vol. 2, 2006, pp. 122-125.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>Chuang, et al., &#x201c;A Bayesian Approach to Digital Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.2400&#x26;rep=rep1&#x26;type=pdf&#x3e;&#x3e;, IEEE Proceedings of Computer Vision and Pattern Recognition (CVPR), vol. II, Dec. 2001, pp. 264-271.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>Chuang, et al., &#x201c;Video Matting of Complex Scenes&#x201d;, ACM, Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques, Session: Images and Video, 2002, pp. 243-248.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>Crow, &#x201c;Summed-Area Tables for Texture Mapping&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.124.1904&#x26;rep=repl&#x26;type=pdf&#x3e;&#x3e;, ACM, Computer Graphics, vol. 18, No. 3, Jul. 1984, pp. 207-212.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>Elder, et al., &#x201c;Image Editing in the Contour Domain&#x201d;, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 23, Issue 3, Mar. 2001, pp. 291-296.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>Farbman, et al., &#x201c;Edge-Preserving Decompositions for Multi-Scale Tone and Detail Manipulation&#x201d;, retrieved don Apr. 21, 2010 at &#x3c;&#x3c;http://www.cs.huji.acil/&#x2dc;danix/epd/epd-small.pdf&#x3e;&#x3e;, ACM, International Conference on Computer Graphics and Interactive Techniques (CCGIT), Los Angeles, CA, vol. 27, No. 3, 2008, pp. 67-77.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00042">
<othercit>Fattal, et al., &#x201c;Edge-Based Image Coarsening&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://vis.berkeley.edu/papers/ebic/ebic<sub>&#x2014;</sub>manuscript.pdf&#x3e;&#x3e;, ACM, Transactions on Graphics (TOG) , vol. 29, No. 1, Dec. 2009, pp. 1-20.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>Fattal, et al., &#x201c;Gradient Domain High Dynamic Range Compression&#x201d;, ACM, Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques Session: Images and Video, 2002, pp. 249-256.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00044">
<othercit>Finlayson, et al., &#x201c;Removing Shadows From Images&#x201d;, Computer Vision&#x2014;ECCV 2002: 7th European Conference on Computer Vision, May 28-31, 2002, pp. 129-132.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00045">
<othercit>Zheng, et al., &#x201c;Learning Based Digital Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://zheng.vision.googlepages.com/matting<sub>&#x2014;</sub>iccv09<sub>&#x2014;</sub>Zheng.pdf&#x3e;&#x3e;, IEEE 20th International Conference on Computer Vision (ICCV), Kyoto, Japan, 2009, pp. 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00046">
<othercit>Grady, et al., &#x201c;Random Walks for Interactive Alpha-Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.5802&#x26;rep=rep1&#x26;type=pdf&#x3e;&#x3e;, Proceedings of Visualization Imaging and Image Processing (VIIP), Benidorm, Spain, 2005, pp. 423-429.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>Guan, et al., &#x201c;Easy Matting&#x2014;A Stroke Based Approach for Continuous Image Matting&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://www.cad.zju.edu.cn/home/chenwei/research/EG2006<sub>&#x2014;</sub>paper.pdf&#x3e;&#x3e;, The Eurographics Association and Blackwell Publishing, Proceedings of Eurographics, vol. 25, No. 3, 2006, pp. 567-576.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>Hasinoff, et al., &#x201c;Boundary matting for view synthesis&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://research.microsoft.com/pubs/64217/Hasinoff-CVIU06.pdf&#x3e;&#x3e;, Elsevier Science Inc., Computer Vision and Image Understanding, vol. 103, No. 1, 2006, pp. 22-32.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>He, et al., &#x201c;Fast Matting Using Large Kernel Matting Laplacian Matrices&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://research. microsoft.com/en-us/um/people/jiansun/papers/CVPR10<sub>&#x2014;</sub>FastMatting.pdf&#x3e;&#x3e;, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). San Francisco, CA, 2010, pp. 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00050">
<othercit>He, et al., &#x201c;Single Image Haze Removal Using Dark Channel Prior&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://research.microsoft.com/en-us/um/people/jiansun/papers/dehaze<sub>&#x2014;</sub>cvpr2009.pdf&#x3e;&#x3e;, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Miami, FL, 2009, pp. 1956-1963.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>Hillman, et al., &#x201c;Alpha Channel Estimation in High Resolution Images and Image Sequences&#x201d; Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, vol. 1, 2001, pp. I-1063-I-1068.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00052">
<othercit>Hsu, et al., &#x201c;Light Mixture Estimation for Spatially Varying White Balance&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://www. shaiavidan.org/papers/ime-sig2008-sm.pdf&#x3e;&#x3e;, ACM, International Conference on Computer Graphics and Interactive Techniques, Los Angeles, CA, vol. 27, No. 3, 2008, pp. 1-7.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00053">
<othercit>Levin, et al., &#x201c;A Closed Form Solution to Natural Image Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://www.wisdom. weizmann.ac.il/&#x2dc;levina/papers/Matting-Levin-Lischinski-Weiss-CVPR06.pdf&#x3e;&#x3e;, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), New York, NY, vol. 1, Jun. 2006, pp. 61-68.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>Levin, et al., &#x201c;Colonization using Optimization&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://www.wisdom.weizmann.ac.il/&#x2dc;levina/papers/colorization-siggraph04.pdf&#x3e;&#x3e;, ACM, Transactions on Graphics (TOG), vol. 23, No. 3, 2004, pp. 689-694.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>Liu, et al., &#x201c;Paint Selection&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://research.microsoft.com/en-us/um/people/jiansun/papers/paintselection<sub>&#x2014;</sub>siggraph09.pdf&#x3e;&#x3e;, ACM Transactions on Graphics (TOG), vol. 28, No. 3, Aug. 2009, pp. 1-7.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00056">
<othercit>Mitsunaga, et al., &#x201c;AutoKey: Human Assisted Key Extraction&#x201d;, ACM, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, 1995, pp. 265-272.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00057">
<othercit>Narasimhan, et al., &#x201c;Interactive Deweathering of an Image Using Physical Models&#x201d;, IEEE Workshop on Color and Photometric Methods in Computer Vision, In Conjunction with ICCV, Oct. 2003, 8 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00058">
<othercit>Perez, et al., &#x201c;Poisson Image Editing&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.6932&#x26;rep=repl&#x26;type=pdf&#x3e;&#x3e;, ACM, Transactions on Graphics (TOG), vol. 22, No. 3, 2003, pp. 313-318.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00059">
<othercit>Perona, et al., &#x201c;Scale-Space and Edge Detection Using Anisotropic Diffusion&#x201d;, UC Berkeley EECS Technical Reports, Dec. 20, 1988, Also, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 12, Issue 7, Jul. 1990, pp. 629-639, 41 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00060">
<othercit>Qian, et al., &#x201c;Video Background Replacement Without a Blue Screen&#x201d;, Proceedings 1999 International Conference on Image Processing, vol. 4, Oct. 24-28, 1999, pp. 143-146.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00061">
<othercit>Rhemann, et al., &#x201c;A Perceptually Motivated Online Benchmark for Image Matting&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://www.juew.org/publication/CVPR09<sub>&#x2014;</sub>evaluation<sub>&#x2014;</sub>final<sub>&#x2014;</sub>HQ.pdf&#x3e;&#x3e;, IEEE Proceedings on Computer Vision and Pattern Recognition (CVPR), 2009, pp. 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00062">
<othercit>Rhemann, et al., &#x201c;Alpha Matting Evaluation Website&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://www.alphamatting.com&#x3e;&#x3e;, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Jun. 2009, pp. 1-2.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00063">
<othercit>Rhemann, et al., &#x201c;High Resolution Matting via Interactive Trimap Segmentation&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://www.ims.tuwien.ac.at/media/documents/publications/RhemannRotherRavAchaSharpTR08.pdf&#x3e;&#x3e;, Technical Report TR-188-2-2008-04, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Alaska, Jun. 2008, pp. 1-12.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00064">
<othercit>Rhemann, et al., &#x201c;Improving Color Modeling for Alpha Matting&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://publik.tuwien.ac.at/files/PubDat<sub>&#x2014;</sub>169054.pdf&#x3e;&#x3e;, British Machine Vision Conference (BMVC), 2008, pp. 1-10.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00065">
<othercit>Ruzon, et al., &#x201c;Alpha Estimation in Natural Images&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://www.cs.duke.edu/&#x2dc;tomasi/ papers/ruzon/ruzonCvpr00.pdf&#x3e;&#x3e;, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, Jun. 2000, vol. 1, pp. 18-25.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00066">
<othercit>Saad, &#x201c;Iterative Methods for Sparse Linear Systems&#x201d;, Second Edition, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://www-users.cs.umn.edu/&#x2dc;saad/PS/iter1.pdf&#x3e;&#x3e;, CRC Press, Jan. 3, 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00067">
<othercit>Singaraju, et al., &#x201c;New Appearance Models for Natural Image Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://research.microsoft.com/pubs/80300/cvpr09-matting-newModels.pdf&#x3e;&#x3e;, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Miami, FL, Jun. 2009, pp. 659-666.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00068">
<othercit>Smith, et al., &#x201c;Blue Screen Matting&#x201d; , ACM, Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques, 1996, pp. 259-268.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00069">
<othercit>Sun, et al., &#x201c;Flash Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://vision.ai.uiuc.edu/&#x2dc;tankh/citations/nonphotorealistic<sub>&#x2014;</sub>camera<sub>&#x2014;</sub>siggraph2004/sun<sub>&#x2014;</sub>siggraph2006.pdf&#x3e;&#x3e;, ACM, Transactions on Graphics (TOG), vol. 25, No. 3, Jul. 2006, pp. 772-778.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00070">
<othercit>Sun, et al., &#x201c;Poisson Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.8258&#x26;rep=rep1&#x26;type=pdf&#x3e;&#x3e;, ACM Transactions on Graphics, vol. 23, No. 3, Jul. 2004, pp. 315-321.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00071">
<othercit>Szeliski, &#x201c;Locally Adapted Hierarchical Basis Preconditioning&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://research.microsoft.com/pubs/70280/tr-2006-38.pdf&#x3e;&#x3e;, ACM, Transactions on Graphics, International Conference on Computer Graphics and Interactive Techniques, vol. 25, No. 3, Aug. 2006, pp. 1135-1143.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00072">
<othercit>Wang, et al., &#x201c;An Iterative Optimization Approach for Unified Image Segmentation and Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://research.microsoft.com/en-us/um/people/cohen/iccv2005.pdf&#x3e;&#x3e;, IEEE Computer Society, Proceedings of the Tenth International Conference on Computer Vision (ICCV), vol. 2, 2005, pp. 936-943.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00073">
<othercit>Wang, et al, &#x201c;Image and Video Matting: A Survey&#x201d;, retrieved on Apr. 21, 2010 at &#x3c;&#x3c;http://www.nowpublishers.com/getpdf.aspx?doi=0600000019&#x26;product=CGV&#x3e;&#x3e;, Now Publishers Inc., Foundations and Trends in Computer Graphics and Vision, vol. 3, No. 2, 2007, pp. 97-175.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00074">
<othercit>Wang, et al., &#x201c;Interactive Video Cutout&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://juew.org/publication/VideoCutout2005.pdf&#x3e;&#x3e;, ACM, International Conference on Computer Graphics and Interactive Techniques, Los Angeles, CA, 2005, pp. 585-594.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00075">
<othercit>Wang, et al., &#x201c;Optimized Color Sampling for Robust Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://research.microsoft.com/en-us/um/people/cohen/robustmattingcvprfinal.pdf&#x3e;&#x3e;, IEEE Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR), Minneapolis, MN, Jun. 2007, pp. 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00076">
<othercit>Wang, et al., &#x201c;Soft Scissors : An Interactive Tool for Realtime High Quality Matting&#x201d;, retrieved on Apr. 20, 2010 at &#x3c;&#x3c;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.64.3777&#x26;rep=rep1&#x26;type=pdf&#x3e;&#x3e;, ACM, International Conference on Computer Graphics and Interactive Techniques, San Diego, CA, vol. 25, No. 3, 2007, pp. 1-6.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00077">
<othercit>The Chinese Office Action mailed Mar. 8, 2013 for Chinese patent application No. 201110216315.6, a counterpart foreign application of US patent No. 8,386,964, 18 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>17</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382164</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382195</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345592-593</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>12</number-of-drawing-sheets>
<number-of-figures>21</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120020554</doc-number>
<kind>A1</kind>
<date>20120126</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sun</last-name>
<first-name>Jian</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
<residence>
<country>CN</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>He</last-name>
<first-name>Kaiming</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
<residence>
<country>CN</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Sun</last-name>
<first-name>Jian</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>He</last-name>
<first-name>Kaiming</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Lee &#x26; Hayes, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Microsoft Corporation</orgname>
<role>02</role>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Abdi</last-name>
<first-name>Amara</first-name>
<department>2668</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Image matting is performed on an image having a specified foreground region, a background region and an unknown region by selecting a kernel size based on a size of the unknown region. The matting processing is performed using the selected kernel size to provide an alpha matte that distinguishes a foreground portion from a background portion in the unknown region. Further, in some implementations, a trimap of the image may be segmented and matting processing may be performed on each segment using a kernel size appropriate for that segment.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="116.59mm" wi="187.11mm" file="US08625888-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="204.22mm" wi="176.19mm" file="US08625888-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="206.33mm" wi="134.54mm" orientation="landscape" file="US08625888-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="284.40mm" wi="179.32mm" file="US08625888-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="178.65mm" wi="164.59mm" file="US08625888-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="232.92mm" wi="157.99mm" orientation="landscape" file="US08625888-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="257.47mm" wi="140.46mm" orientation="landscape" file="US08625888-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="274.24mm" wi="189.15mm" file="US08625888-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="276.35mm" wi="180.76mm" file="US08625888-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="254.59mm" wi="191.94mm" orientation="landscape" file="US08625888-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="262.72mm" wi="194.06mm" orientation="landscape" file="US08625888-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="246.21mm" wi="177.55mm" file="US08625888-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="249.34mm" wi="172.30mm" orientation="landscape" file="US08625888-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">In image composition, a composite image can be created by combining a portion of a first image with a portion of a second image. For example, a foreground portion of a first image, such as a person or thing, can be lifted from the first image and placed over a second image which serves as a new background in the composite image. In order to combine these image portions correctly an associated matte (e.g., an alpha matte) that contains the coverage information (e.g., the shape of one or more portions being composited) is used to distinguish between the image portions. This technique, referred to as &#x201c;image matting&#x201d; or just &#x201c;matting&#x201d;, is common in still image compositing, video special effects, computer vision and a variety of other graphics and image-manipulation applications.</p>
<p id="p-0003" num="0002">Well-known matting techniques include blue-screen or green-screen matting in which an alpha matte and foreground portion of an image can be readily separated from the background of the image because the background is a single user-controlled color. In contrast, for natural image matting in which the background is not a single color, the alpha matte, the foreground and the background are estimated and identified using statistical techniques. Further, natural image matting is an intrinsically under-constrained problem due to the number of unknowns in the matting equation. Consequently, separation of the alpha matte, the foreground and the background for a given image using conventional matting techniques can be quite computation intensive.</p>
<p id="p-0004" num="0003">Further, because image matting is an under-constrained problem, most existing approaches rely on a &#x201c;trimap&#x201d; provided with an image or generated from the image that identifies at least some of a definite foreground, a definite background and/or an unknown region. A sufficiently defined trimap can assist in achieving a quality matte by reducing the number of unknown elements. Further, when matting is performed interactively by a user using a user interface, the capability of providing instant feedback to the user can be helpful because the user is able to refine the trimap as the matte is rendered until a satisfactory result is obtained. For example, providing real time feedback to a user can significantly shorten the overall matting process time and reduce user effort since the user is able to quickly identify locations where touchups are desired. Also, a highly responsive system can provide a more fluid user experience and avoid user frustration. Unfortunately, most conventional high quality matting approaches are computationally expensive and unable to provide responses in real time.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0005" num="0004">This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key or essential features of the claimed subject matter; nor is it to be used for determining or limiting the scope of the claimed subject matter.</p>
<p id="p-0006" num="0005">Some implementations disclosed herein provide a fast and efficient method for image matting. Some implementations use relatively large kernels or windows during matting processing. These implementations may employ larger kernels to propagate matting information more quickly than smaller kernels and can improve the matte quality. To further reduce computation time, some implementations may also employ adaptive kernel sizes based on trimap segmentation.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0007" num="0006">The detailed description is set forth with reference to the accompanying drawing figures. In the figures, the left-most digit(s) of a reference number identifies the figure in which the reference number first appears. The use of the same reference numbers in different figures indicates similar or identical items or features.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example of a kernel according to some implementations herein.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a framework for image matting according to some implementations.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIGS. 3A-3C</figref> depict an example of image matting according to some implementations.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 4</figref> is a flow diagram of an example process for image matting according to some implementations.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 5</figref> is a graph illustrating examples of radius size relative to number of iterations to convergence according to some implementations.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram of a framework for image matting with trimap segmentation according to some implementations.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. 7A-7B</figref> illustrate an example of trimap segmentation according to some implementations.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 8</figref> is a flow diagram of an example process for trimap segmentation according to some implementations.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. 9A-9H</figref> illustrate the effect of local-global-local processing according to some implementations.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 10</figref> is a flow diagram of an example process for image matting with trimap segmentation and local-global-local processing according to some implementations.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 11</figref> is a block diagram of an example of a suitable computing system environment according to some implementations.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="h-0005" num="0000">Fast Image Matting</p>
<p id="p-0019" num="0018">The technologies described herein are generally directed towards image matting to enable separation of a foreground portion of an image from a background portion of the image. For example, a foreground object can be lifted or pulled from an input image and then placed over a background provided by another image. Implementations herein may be applied to natural image matting in which the background is difficult to distinguish from the foreground being extracted. For instance, some implementations may be applied when the boundary between the foreground and the background is a soft boundary, such as is produced when hair or other complex structures extend in the boundary region between portions of the image that are clearly the foreground and clearly the background. Further, some implementations herein for image matting may be employed in a variety of applications, such as image/video segmentation, layer extraction, new view synthesis, interactive image editing, and film making, to name a few.</p>
<p id="p-0020" num="0019">Since the matting problem is highly ill-posed, in some implementations, a trimap (or strokes) indicating definite foreground, definite background, and unknown regions may be provided by a user or an application. Efficiency is also a consideration for image matting, especially when applied to large multi-megapixel images produced by conventional digital cameras Implementations herein are able to quickly and efficiently infer the alpha matte in the unknown regions of an image, and are able to handle complex cases like hair. Some implementations can be applied to interactive image matting in which the matte is formed in real time as a user indicates regions of the trimap on a display.</p>
<p id="p-0021" num="0020">Some implementations herein provide a technique for high quality image matting using relatively large-kernel matting Laplacian matrices that is substantially faster than conventional techniques. A Laplacian matrix (sometimes referred to as an admittance matrix) is a matrix representation of affinity between pixels based on color. Some implementations are based on an efficient method to solve a linear system using a large kernel matting Laplacian. Kernel size refers to the size of the portion of the image being processed, i.e., comprising a number of pixels around a pixel of interest. According to some implementations herein, using a relatively large kernel size accelerates the constraint propagation, reduces the time of the linear solver for convergence, and improves the matting quality. To further speed-up the matting process and reduce computation time, some implementations employ a segmentation technique to decompose the trimap into sub-trimaps and to enable assigning an adaptive kernel size to each sub-trimap. Thus, the number of iterations can be fixed beforehand and the running time of the entire process can be essentially linear to the number of the unknown pixels. Testing has demonstrated that implementations herein may be 5 to 20 times faster than conventional techniques while achieving high matting quality. Implementations can also be useful for other applications employing the matting Laplacian, such as haze removal, spatially variant white balance, and intrinsic images.</p>
<p id="h-0006" num="0000">Large Kernel Matting Laplacian</p>
<p id="p-0022" num="0021">For a color image, the foreground F and the background B can be specified as color components together with an alpha channel matte &#x3b1;. For example, in the red, green, blue (RGB) color model, the image may be expressed as a matrix, as follows:</p>
<p id="p-0023" num="0022">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
  <mo>&#x2003;</mo>
  <mrow>
    <mo>{</mo>
    <mtable>
      <mtr>
        <mtd>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
        </mtd>
        <mtd>
          <mi>&#x3b1;</mi>
        </mtd>
        <mtd>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <msub>
            <mi>F</mi>
            <mi>r</mi>
          </msub>
        </mtd>
        <mtd>
          <msub>
            <mi>F</mi>
            <mi>g</mi>
          </msub>
        </mtd>
        <mtd>
          <msub>
            <mi>F</mi>
            <mi>b</mi>
          </msub>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <msub>
            <mi>B</mi>
            <mi>r</mi>
          </msub>
        </mtd>
        <mtd>
          <msub>
            <mi>B</mi>
            <mi>g</mi>
          </msub>
        </mtd>
        <mtd>
          <msub>
            <mi>B</mi>
            <mi>b</mi>
          </msub>
        </mtd>
      </mtr>
    </mtable>
    <mo>}</mo>
  </mrow>
</mrow>
</math>
</maths>
</p>
<p id="p-0024" num="0023">An alpha channel has various uses, including, for example, masking objects, making them transparent, or adding specific color instructions. In the {&#x3b1;, F, B} matrix, the alpha channel is a matte that distinguishes the foreground and background in an RGB image. As described herein, a user may construct such a matrix for an image through a process referred to as matting, which aims to find an appropriate &#x3b1; and F. For example, in the alpha matte, an alpha value of 1 typically indicates a foreground region and an alpha value of 0 typically indicates a background region.</p>
<p id="p-0025" num="0024">Image matting is inherently under-constrained because the matting equation has too many unknowns. Therefore, user interaction is often used to obtain a quality matte. For example, in natural image matting, a user may supply a trimap that partitions the image into three regions: &#x201c;definitely foreground&#x201d;, &#x201c;definitely background&#x201d; and &#x201c;unknown region&#x201d;. The unknown region is typically the boundary between the definite foreground and definite background. In some implementations, the user may identify definite foreground and/or definite background using various interfaces and input devices. For example, a user may use a mouse or other input device to make one or more strokes, scribbles or clicks on an image to indicate a foreground portion and/or a background portion of an image. Further, in some implementations, the trimap may be partially or entirely automatically generated. For example, a user may positively identify a part of a foreground and a part of a background, with a trimap being automatically generated based on this identification. In some implementations, the user may use the input device to positively identify the unknown region or boundary. In other implementations, a trimap may be automatically generated based on a previous image in a sequence of images, such through motion estimation. Other variations will also be apparent in light of the disclosure herein.</p>
<p id="p-0026" num="0025">For each pixel in an input image having a foreground color (F), a background color (B), and a foreground opacity (alpha matte &#x3b1;), the pixel's color I can be expressed as a convex or linear combination of the foreground and background colors as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>I=F&#x3b1;+B</i>(1&#x2212;&#x3b1;)&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0027" num="0026">The matting Laplacian matrix is an affinity matrix applicable to image matting. One assumption of Laplacian matting is the color line model, namely, the foreground (or background) colors in a local window lie on a single line in the RGB color space. That &#x3b1; is a linear transformation of I in the local window is proved by the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x3b1;<sub>i</sub><i>=a</i><sup>T</sup><i>I</i><sub>i</sub><i>b,&#x2200;i&#x3b5;&#x3c9;,</i>&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where i is a pixel index, I<sub>i </sub>and a are 3&#xd7;1 vectors, a<sup>T </sup>is the transpose of vector a, and a and b are assumed to be constant in the local window &#x3c9;, in which a=1/F&#x2212;B&#x2032;, and b=B/F&#x2212;B&#x2032;. Accordingly, a cost function J(&#x3b1;, a, b) can be defined to support the alpha obeying this model:
</p>
<p id="p-0028" num="0027">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>J</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>&#x3b1;</mi>
              <mo>,</mo>
              <mi>a</mi>
              <mo>,</mo>
              <mi>b</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <munder>
            <mo>&#x2211;</mo>
            <mrow>
              <mi>k</mi>
              <mo>&#x2208;</mo>
              <mi>I</mi>
            </mrow>
          </munder>
          <mo>&#x2062;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <munder>
                  <mo>&#x2211;</mo>
                  <mrow>
                    <mi>i</mi>
                    <mo>&#x2208;</mo>
                    <mstyle>
                      <mspace width="0.3em" height="0.3ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <msub>
                      <mi>&#x3c9;</mi>
                      <mi>k</mi>
                    </msub>
                  </mrow>
                </munder>
                <mo>&#x2062;</mo>
                <msup>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <msub>
                        <mi>&#x3b1;</mi>
                        <mi>i</mi>
                      </msub>
                      <mo>-</mo>
                      <mrow>
                        <msubsup>
                          <mi>a</mi>
                          <mi>k</mi>
                          <mi>T</mi>
                        </msubsup>
                        <mo>&#x2062;</mo>
                        <msub>
                          <mi>I</mi>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                      <mo>-</mo>
                      <msub>
                        <mi>b</mi>
                        <mi>k</mi>
                      </msub>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                  <mn>2</mn>
                </msup>
              </mrow>
              <mo>+</mo>
              <mrow>
                <mi>&#x25b;</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msubsup>
                  <mi>a</mi>
                  <mi>k</mi>
                  <mi>T</mi>
                </msubsup>
                <mo>&#x2062;</mo>
                <msub>
                  <mi>a</mi>
                  <mi>k</mi>
                </msub>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where &#x3c9;<sub>k </sub>is the window centered at pixel k, and &#x3b5; is a regularization parameter. By minimizing the cost function with respect to (a, b), a quadratic function of a can be obtained:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>J</i>(&#x3b1;)=&#x3b1;<sup>T</sup><i>L&#x3b1;.</i>&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0029" num="0028">Here &#x3b1; is denoted as an N&#xd7;1 vector, where N is the number of unknowns, and the matrix L is called the &#x201c;matting Laplacian&#x201d;. The Laplacian matrix L is an N&#xd7;N symmetric matrix whose (i, j) element may be expressed as:</p>
<p id="p-0030" num="0029">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>L</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>i</mi>
              <mo>,</mo>
              <mi>j</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <munder>
            <mo>&#x2211;</mo>
            <mrow>
              <mi>k</mi>
              <mo>|</mo>
              <mrow>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mi>i</mi>
                    <mo>,</mo>
                    <mi>j</mi>
                  </mrow>
                  <mo>)</mo>
                </mrow>
                <mo>&#x2208;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msub>
                  <mi>&#x3c9;</mi>
                  <mi>k</mi>
                </msub>
              </mrow>
            </mrow>
          </munder>
          <mo>&#x2062;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <msub>
                <mi>&#x3b4;</mi>
                <mi>ij</mi>
              </msub>
              <mo>-</mo>
              <mrow>
                <mfrac>
                  <mn>1</mn>
                  <mrow>
                    <mo>&#xf603;</mo>
                    <msub>
                      <mi>&#x3c9;</mi>
                      <mi>k</mi>
                    </msub>
                    <mo>&#xf604;</mo>
                  </mrow>
                </mfrac>
                <mo>&#x2062;</mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mn>1</mn>
                    <mo>+</mo>
                    <mrow>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>I</mi>
                              <mi>i</mi>
                            </msub>
                            <mo>-</mo>
                            <msub>
                              <mi>&#x3bc;</mi>
                              <mi>k</mi>
                            </msub>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mi>T</mi>
                      </msup>
                      <mo>&#x2062;</mo>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <munder>
                              <mo>&#x2211;</mo>
                              <mi>k</mi>
                            </munder>
                            <mo>&#x2062;</mo>
                            <mrow>
                              <mrow>
                                <mo>+</mo>
                                <mfrac>
                                  <mi>&#x25b;</mi>
                                  <mrow>
                                    <mo>&#xf603;</mo>
                                    <msub>
                                      <mi>&#x3c9;</mi>
                                      <mi>k</mi>
                                    </msub>
                                    <mo>&#xf604;</mo>
                                  </mrow>
                                </mfrac>
                              </mrow>
                              <mo>&#x2062;</mo>
                              <mi>U</mi>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mrow>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                      </msup>
                      <mo>&#x2062;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <msub>
                            <mi>I</mi>
                            <mi>j</mi>
                          </msub>
                          <mo>-</mo>
                          <msub>
                            <mi>&#x3bc;</mi>
                            <mi>k</mi>
                          </msub>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>5</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where i j is the Kronecker delta, &#x3bc;<sub>k </sub>and &#x3a3;<sub>k </sub>are the mean and covariance matrix, respectively, of the colors in window &#x3c9;<sub>k</sub>, |&#x3c9;<sub>k</sub>| is the number of pixels in the window &#x3c9;<sub>k</sub>, and U is a 3&#xd7;3 identity matrix.
</p>
<p id="p-0031" num="0030">Combining this cost function with the user-specified constraints (e.g., the trimap), the whole cost function may be defined as:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>E</i>(&#x3b1;)=&#x3b1;<sup>T</sup><i>L</i>&#x3b1;+&#x3bb;(&#x3b1;&#x2212;&#x3b2;)<sup>T</sup><i>D</i>(&#x3b1;&#x2212;&#x3b2;),&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where &#x3b2; is the trimap, D is a diagonal matrix whose elements are one for constraint pixels and zero otherwise, and &#x3bb;, is a large number to enforce a hard constraint for the known pixels. A data term specified by color sampling confidence or a sparsity prior can also be incorporated in some implementations. The cost function of equation (6) can be optimized by solving a sparse linear system:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>L+&#x3bb;D</i>)&#x3b1;=&#x3bb;D&#x3b2;.&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0032" num="0031">The techniques of haze removal, spatially variant white balance, and intrinsic images also involve this linear system. Given this linear system, implementations herein provide a matting component that uses an appropriate linear system solver to recover &#x3b1;, as described below. Non-iterative methods, such as LU (lower-upper) decomposition are typically not effective to handle this linear system in large scale due to the high memory cost. Further in conventional iterative methods, the information of the known pixels is propagated into the unknown region by iteratively multiplying the matrix. However, iterative methods are often time consuming, and another drawback of the iterative methods is that the time to carry out the computations is difficult to predict because the number of iterations depends on the number of unknowns, the image content, and the trimap shape. Thus, conventional iterative methods are typically not suitable for interactive image matting.</p>
<p id="p-0033" num="0032">Further, conventional methods usually use a small window or kernel because the matrix will be less sparse with a larger window. Conventional thought holds that solving a less sparse system takes more time. However, according to some implementations herein, this is not necessarily true. Thus, according to some implementations herein, solving a less sparse system takes fewer iterations to converge, with the only bottleneck being the increased computational burden in each iteration. Thus, implementations herein are able to greatly reduce the time for each iteration, so the image matting component may actually be faster when a larger window or kernel is used.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 1</figref> depicts a 21&#xd7;21 pixel kernel <b>100</b> for discussion purposes, having a pixel i located at its center. The kernel size of a matting Laplacian is defined as the number of the non-zero elements in a row of L. In equation (5), the window radius of the window &#x3c9; may be denoted by a &#x201c;radius&#x201d; r. Then the kernel size may be defined as (4r+1)<sup>2</sup>. As set forth in equation (5), the (i, j) element of L is non-zero only if (i, j)&#x3b5;&#x3c9;<sub>k</sub>. According to some implementations herein, as illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, when the radius of the window &#x3c9; is r, the radius of the kernel centered at i is 2r. Thus, kernel <b>100</b> includes a first window &#x3c9;<sub>i </sub>of radius r having pixel i located at its center and a second window &#x3c9;<sub>k </sub>having a pixel k located at its center. Both pixel i and pixel j are elements of window &#x3c9;<sub>i </sub>and pixel i and pixel k are elements of window &#x3c9;<sub>i</sub>. Thus, pixel i is influenced by pixel j, which is 2r from pixel i.</p>
<p id="p-0035" num="0034">Existing methods typically use r=1 (i.e., a 3&#xd7;3 pixel window) because L will become less sparse when r is larger, and both the memory and the time to solve the linear system increases tremendously. For example, in the case of the conjugate gradient (CG) method for solving a linear system, the CG solver iteratively multiplies the conjugate vector by the Laplacian matrix. (See, e.g., Y. Saad, &#x201c;Iterative methods for sparse linear systems,&#x201d; SIAM, 2003, page 178, for an example of a CG solver.) In each iteration, the matrix product Lp dominates the computation cost. Here p is the conjugate vector of the previous iteration. In the view of signal processing, the matrix product Lp is the response of a spatially variant filter L on p, whose ith element is:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>Lp</i>)<sub>i</sub>=&#x3a3;<sub>j</sub><i>L</i><sub>ij</sub><i>p</i><sub>j</sub>.&#x2003;&#x2003;(8)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0036" num="0035">Computing Lp using equations (5) and (8) involves spatially variant convolution, whose time and memory complexity is O(Nr<sup>2</sup>). This is not computationally affordable when r gets larger. However, according to implementations herein, in each iteration a pixel can influence another pixel that is 2r away. So the information is propagated according to 2r pixels. Consequently, the CG solver will converge in fewer iterations if the kernel size is larger.</p>
<p id="p-0037" num="0036">Implementations herein may employ an O(N) time process (that is independent of r) to compute the product Lp in each iteration. Because the process is independent of r, the process is in some aspects independent of window size or kernel size, and thus, it becomes more efficient to process large sized kernels. Further, instead of computing L's elements and the convolution explicitly, implementations herein calculate the product Lp as a whole using equations (9), (10) and (11), as set forth below. Thus, according to implementations herein, given a conjugate vector p, Lp can be calculated through the following three equations:</p>
<p id="p-0038" num="0037">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msubsup>
          <mi>a</mi>
          <mi>k</mi>
          <mo>*</mo>
        </msubsup>
        <mo>=</mo>
        <mrow>
          <msubsup>
            <mi>&#x394;</mi>
            <mi>k</mi>
            <mrow>
              <mo>-</mo>
              <mn>1</mn>
            </mrow>
          </msubsup>
          <mo>(</mo>
          <mrow>
            <mrow>
              <mfrac>
                <mn>1</mn>
                <mrow>
                  <mo>&#xf603;</mo>
                  <mi>&#x3c9;</mi>
                  <mo>&#xf604;</mo>
                </mrow>
              </mfrac>
              <mo>&#x2062;</mo>
              <mrow>
                <munder>
                  <mo>&#x2211;</mo>
                  <mrow>
                    <mi>i</mi>
                    <mo>&#x2208;</mo>
                    <msub>
                      <mi>&#x3c9;</mi>
                      <mi>k</mi>
                    </msub>
                  </mrow>
                </munder>
                <mo>&#x2062;</mo>
                <mrow>
                  <msub>
                    <mi>I</mi>
                    <mi>i</mi>
                  </msub>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mi>p</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
              </mrow>
            </mrow>
            <mo>-</mo>
            <mrow>
              <msub>
                <mi>&#x3bc;</mi>
                <mi>k</mi>
              </msub>
              <mo>&#x2062;</mo>
              <msub>
                <mover>
                  <mi>p</mi>
                  <mi>_</mi>
                </mover>
                <mi>k</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>9</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msubsup>
          <mi>b</mi>
          <mi>k</mi>
          <mo>*</mo>
        </msubsup>
        <mo>=</mo>
        <mrow>
          <msub>
            <mover>
              <mi>p</mi>
              <mi>_</mi>
            </mover>
            <mi>k</mi>
          </msub>
          <mo>-</mo>
          <mrow>
            <msubsup>
              <mi>a</mi>
              <mi>k</mi>
              <mrow>
                <mo>*</mo>
                <mi>T</mi>
              </mrow>
            </msubsup>
            <mo>&#x2062;</mo>
            <msub>
              <mi>&#x3bc;</mi>
              <mi>k</mi>
            </msub>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>10</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <msub>
            <mrow>
              <mo>(</mo>
              <mi>Lp</mi>
              <mo>)</mo>
            </mrow>
            <mi>i</mi>
          </msub>
          <mo>&#x2261;</mo>
          <msub>
            <mi>q</mi>
            <mi>i</mi>
          </msub>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mrow>
              <mo>&#xf603;</mo>
              <mi>&#x3c9;</mi>
              <mo>&#xf604;</mo>
            </mrow>
            <mo>&#x2062;</mo>
            <msub>
              <mi>p</mi>
              <mi>i</mi>
            </msub>
          </mrow>
          <mo>-</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <msup>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <munder>
                        <mo>&#x2211;</mo>
                        <mrow>
                          <mi>k</mi>
                          <mo>&#x2208;</mo>
                          <msub>
                            <mi>&#x3c9;</mi>
                            <mi>i</mi>
                          </msub>
                        </mrow>
                      </munder>
                      <mo>&#x2062;</mo>
                      <msubsup>
                        <mi>a</mi>
                        <mi>k</mi>
                        <mo>*</mo>
                      </msubsup>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                  <mi>T</mi>
                </msup>
                <mo>&#x2062;</mo>
                <msub>
                  <mi>I</mi>
                  <mi>i</mi>
                </msub>
              </mrow>
              <mo>+</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <munder>
                    <mo>&#x2211;</mo>
                    <mrow>
                      <mi>k</mi>
                      <mo>&#x2208;</mo>
                      <msub>
                        <mi>&#x3c9;</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                  </munder>
                  <mo>&#x2062;</mo>
                  <msubsup>
                    <mi>b</mi>
                    <mi>k</mi>
                    <mo>*</mo>
                  </msubsup>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>11</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where a<sub>k</sub>* is a 3&#xd7;1 vector for each pixel k, <o ostyle="single">p</o><sub>k </sub>is the mean of p in &#x3c9;<sub>k</sub>,
</p>
<p id="p-0039" num="0038">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mrow>
  <mrow>
    <msub>
      <mi>&#x394;</mi>
      <mi>k</mi>
    </msub>
    <mo>=</mo>
    <mrow>
      <munder>
        <mo>&#x2211;</mo>
        <mi>k</mi>
      </munder>
      <mo>&#x2062;</mo>
      <mrow>
        <mrow>
          <mo>+</mo>
          <mfrac>
            <mi>&#x25b;</mi>
            <mrow>
              <mo>&#xf603;</mo>
              <msub>
                <mi>&#x3c9;</mi>
                <mi>k</mi>
              </msub>
              <mo>&#xf604;</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>&#x2062;</mo>
        <mi>U</mi>
      </mrow>
    </mrow>
  </mrow>
  <mo>,</mo>
</mrow>
</math>
</maths>
<br/>
and (Lp)<sub>i </sub>is denoted as q<sub>i</sub>. As mentioned above, equations (9)-(11) are independent of the window radius r, and therefore are independent of window or kernel size. Accordingly, some implementations herein carry out image matting based on the value q, given by equations (9), (10) and (11), being equivalent to the value Lp in the equations (5) and (8) discussed above. The theorem and proof for this equivalence are set forth below.
</p>
<p id="p-0040" num="0039">Theorem: The value q given by equations (9), (10) and (11) is identical to the value Lp calculated by equation (5) and equation (8) set forth above.</p>
<p id="p-0041" num="0040">Proof: Written in matrix notation, from equation (9) there is an affine transform:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>a*=Ap,</i>&#x2003;&#x2003;(12)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where A is a coefficient matrix dependent on I. When equation (9) is combined with equation (10), it can be seen that b* is also p's affine transform: b*=Bp. Similarly, q is p's affine transform: q=Qp.
</p>
<p id="p-0042" num="0041">Consequently, in order to show q=Lp, it can be shown that &#x2202;q<sub>i</sub>/&#x2202;p<sub>j</sub>=L(i, j). Putting equation (10) into equation (11) and eliminating b, provides:</p>
<p id="p-0043" num="0042">
<maths id="MATH-US-00006" num="00006">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mrow>
            <mo>&#x2202;</mo>
            <msub>
              <mi>q</mi>
              <mi>i</mi>
            </msub>
          </mrow>
          <mrow>
            <mo>&#x2202;</mo>
            <msub>
              <mi>p</mi>
              <mi>j</mi>
            </msub>
          </mrow>
        </mfrac>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mrow>
              <mo>&#xf603;</mo>
              <mi>&#x3c9;</mi>
              <mo>&#xf604;</mo>
            </mrow>
            <mo>&#x2062;</mo>
            <msub>
              <mi>&#x3b4;</mi>
              <mi>ij</mi>
            </msub>
          </mrow>
          <mo>-</mo>
          <mrow>
            <munder>
              <mo>&#x2211;</mo>
              <mrow>
                <mi>k</mi>
                <mo>&#x2208;</mo>
                <msub>
                  <mi>&#x3c9;</mi>
                  <mi>i</mi>
                </msub>
              </mrow>
            </munder>
            <mo>&#x2062;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mfrac>
                  <mrow>
                    <mo>&#x2202;</mo>
                    <msub>
                      <mover>
                        <mi>p</mi>
                        <mi>_</mi>
                      </mover>
                      <mi>k</mi>
                    </msub>
                  </mrow>
                  <mrow>
                    <mo>&#x2202;</mo>
                    <msub>
                      <mi>p</mi>
                      <mi>j</mi>
                    </msub>
                  </mrow>
                </mfrac>
                <mo>+</mo>
                <mrow>
                  <mfrac>
                    <mrow>
                      <mo>&#x2202;</mo>
                      <msubsup>
                        <mi>a</mi>
                        <mi>k</mi>
                        <mrow>
                          <mo>*</mo>
                          <mi>T</mi>
                        </mrow>
                      </msubsup>
                    </mrow>
                    <mrow>
                      <mo>&#x2202;</mo>
                      <msub>
                        <mi>p</mi>
                        <mi>j</mi>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo>&#x2062;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <msub>
                        <mi>I</mi>
                        <mi>i</mi>
                      </msub>
                      <mo>-</mo>
                      <msub>
                        <mi>&#x3bc;</mi>
                        <mi>k</mi>
                      </msub>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>13</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
which provides:
</p>
<p id="p-0044" num="0043">
<maths id="MATH-US-00007" num="00007">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mrow>
            <mo>&#x2202;</mo>
            <msub>
              <mover>
                <mi>p</mi>
                <mi>_</mi>
              </mover>
              <mi>k</mi>
            </msub>
          </mrow>
          <mrow>
            <mo>&#x2202;</mo>
            <msub>
              <mi>p</mi>
              <mi>j</mi>
            </msub>
          </mrow>
        </mfrac>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mfrac>
              <mn>1</mn>
              <mrow>
                <mo>&#xf603;</mo>
                <mi>&#x3c9;</mi>
                <mo>&#xf604;</mo>
              </mrow>
            </mfrac>
            <mo>&#x2062;</mo>
            <mrow>
              <munder>
                <mo>&#x2211;</mo>
                <mrow>
                  <mi>n</mi>
                  <mo>&#x2208;</mo>
                  <msub>
                    <mi>&#x3c9;</mi>
                    <mi>k</mi>
                  </msub>
                </mrow>
              </munder>
              <mo>&#x2062;</mo>
              <mfrac>
                <mrow>
                  <mo>&#x2202;</mo>
                  <msub>
                    <mi>p</mi>
                    <mi>n</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mo>&#x2202;</mo>
                  <msub>
                    <mi>p</mi>
                    <mi>j</mi>
                  </msub>
                </mrow>
              </mfrac>
            </mrow>
          </mrow>
          <mo>=</mo>
          <mrow>
            <mrow>
              <mfrac>
                <mn>1</mn>
                <mrow>
                  <mo>&#xf603;</mo>
                  <mi>&#x3c9;</mi>
                  <mo>&#xf604;</mo>
                </mrow>
              </mfrac>
              <mo>&#x2062;</mo>
              <msub>
                <mi>&#x3b4;</mi>
                <mrow>
                  <mi>j</mi>
                  <mo>&#x2208;</mo>
                  <msub>
                    <mi>&#x3c9;</mi>
                    <mi>k</mi>
                  </msub>
                </mrow>
              </msub>
            </mrow>
            <mo>=</mo>
            <mrow>
              <mfrac>
                <mn>1</mn>
                <mrow>
                  <mo>&#xf603;</mo>
                  <mi>&#x3c9;</mi>
                  <mo>&#xf604;</mo>
                </mrow>
              </mfrac>
              <mo>&#x2062;</mo>
              <msub>
                <mi>&#x3b4;</mi>
                <mrow>
                  <mi>k</mi>
                  <mo>&#x2208;</mo>
                  <msub>
                    <mi>&#x3c9;</mi>
                    <mi>j</mi>
                  </msub>
                </mrow>
              </msub>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>14</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where &#x3b4;<sub>j</sub>&#x3b5;&#x3c9;<sub>k </sub>is 1 if j&#x3b5;&#x3c9;<sub>k</sub>, and is 0 otherwise. Additionally, equation (9) provides:
</p>
<p id="p-0045" num="0044">
<maths id="MATH-US-00008" num="00008">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mtable>
        <mtr>
          <mtd>
            <mrow>
              <mfrac>
                <mrow>
                  <mo>&#x2202;</mo>
                  <msub>
                    <mi>a</mi>
                    <mi>k</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mo>&#x2202;</mo>
                  <msub>
                    <mi>p</mi>
                    <mi>j</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mo>=</mo>
              <mrow>
                <msubsup>
                  <mi>&#x394;</mi>
                  <mi>k</mi>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </msubsup>
                <mo>(</mo>
                <mrow>
                  <mrow>
                    <mfrac>
                      <mn>1</mn>
                      <mrow>
                        <mo>&#xf603;</mo>
                        <mi>&#x3c9;</mi>
                        <mo>&#xf604;</mo>
                      </mrow>
                    </mfrac>
                    <mo>&#x2062;</mo>
                    <mrow>
                      <munder>
                        <mo>&#x2211;</mo>
                        <mrow>
                          <mi>i</mi>
                          <mo>&#x2208;</mo>
                          <msub>
                            <mi>&#x3c9;</mi>
                            <mi>k</mi>
                          </msub>
                        </mrow>
                      </munder>
                      <mo>&#x2062;</mo>
                      <mrow>
                        <mfrac>
                          <mrow>
                            <mo>&#x2202;</mo>
                            <msub>
                              <mi>p</mi>
                              <mi>i</mi>
                            </msub>
                          </mrow>
                          <mrow>
                            <mo>&#x2202;</mo>
                            <msub>
                              <mi>p</mi>
                              <mi>j</mi>
                            </msub>
                          </mrow>
                        </mfrac>
                        <mo>&#x2062;</mo>
                        <msub>
                          <mi>I</mi>
                          <mi>i</mi>
                        </msub>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>-</mo>
                  <mrow>
                    <mfrac>
                      <mrow>
                        <mo>&#x2202;</mo>
                        <msub>
                          <mover>
                            <mi>p</mi>
                            <mi>_</mi>
                          </mover>
                          <mi>k</mi>
                        </msub>
                      </mrow>
                      <mrow>
                        <mo>&#x2202;</mo>
                        <msub>
                          <mi>p</mi>
                          <mi>j</mi>
                        </msub>
                      </mrow>
                    </mfrac>
                    <mo>&#x2062;</mo>
                    <msub>
                      <mi>&#x3bc;</mi>
                      <mi>k</mi>
                    </msub>
                  </mrow>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mrow>
              <mo>=</mo>
              <mrow>
                <mrow>
                  <msubsup>
                    <mi>&#x394;</mi>
                    <mi>k</mi>
                    <mrow>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </msubsup>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mrow>
                        <mfrac>
                          <mn>1</mn>
                          <mrow>
                            <mo>&#xf603;</mo>
                            <mi>&#x3c9;</mi>
                            <mo>&#xf604;</mo>
                          </mrow>
                        </mfrac>
                        <mo>&#x2062;</mo>
                        <msub>
                          <mi>I</mi>
                          <mi>j</mi>
                        </msub>
                      </mrow>
                      <mo>-</mo>
                      <mrow>
                        <mfrac>
                          <mn>1</mn>
                          <mrow>
                            <mo>&#xf603;</mo>
                            <mi>&#x3c9;</mi>
                            <mo>&#xf604;</mo>
                          </mrow>
                        </mfrac>
                        <mo>&#x2062;</mo>
                        <msub>
                          <mi>&#x3bc;</mi>
                          <mi>k</mi>
                        </msub>
                      </mrow>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&#x2062;</mo>
                <mrow>
                  <msub>
                    <mi>&#x3b4;</mi>
                    <mrow>
                      <mi>k</mi>
                      <mo>&#x2208;</mo>
                      <msub>
                        <mi>&#x3c9;</mi>
                        <mi>j</mi>
                      </msub>
                    </mrow>
                  </msub>
                  <mo>.</mo>
                </mrow>
              </mrow>
            </mrow>
          </mtd>
        </mtr>
      </mtable>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>15</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
Putting equation (14) and equation (15) into equation (13) provides:
</p>
<p id="p-0046" num="0045">
<maths id="MATH-US-00009" num="00009">
<math overflow="scroll">
<mrow>
  <mfrac>
    <mrow>
      <mo>&#x2202;</mo>
      <msub>
        <mi>q</mi>
        <mi>i</mi>
      </msub>
    </mrow>
    <mrow>
      <mo>&#x2202;</mo>
      <msub>
        <mi>p</mi>
        <mi>j</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mrow>
    <mrow>
      <mrow>
        <mo>&#xf603;</mo>
        <mi>&#x3c9;</mi>
        <mo>&#xf604;</mo>
      </mrow>
      <mo>&#x2062;</mo>
      <msub>
        <mi>&#x3b4;</mi>
        <mi>ij</mi>
      </msub>
    </mrow>
    <mo>-</mo>
    <mrow>
      <mfrac>
        <mn>1</mn>
        <mrow>
          <mo>&#xf603;</mo>
          <mi>&#x3c9;</mi>
          <mo>&#xf604;</mo>
        </mrow>
      </mfrac>
      <mo>&#x2062;</mo>
      <mrow>
        <munder>
          <mo>&#x2211;</mo>
          <mrow>
            <mrow>
              <mi>k</mi>
              <mo>&#x2208;</mo>
              <msub>
                <mi>&#x3c9;</mi>
                <mi>i</mi>
              </msub>
            </mrow>
            <mo>,</mo>
            <mrow>
              <mi>k</mi>
              <mo>&#x2208;</mo>
              <msub>
                <mi>&#x3c9;</mi>
                <mi>j</mi>
              </msub>
            </mrow>
          </mrow>
        </munder>
        <mo>&#x2062;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mn>1</mn>
            <mo>+</mo>
            <mrow>
              <msup>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <msub>
                      <mi>I</mi>
                      <mi>j</mi>
                    </msub>
                    <mo>-</mo>
                    <msub>
                      <mi>&#x3bc;</mi>
                      <mi>k</mi>
                    </msub>
                  </mrow>
                  <mo>)</mo>
                </mrow>
                <mi>T</mi>
              </msup>
              <mo>&#x2062;</mo>
              <mrow>
                <msubsup>
                  <mi>&#x394;</mi>
                  <mi>k</mi>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </msubsup>
                <mo>&#x2061;</mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <msub>
                      <mi>I</mi>
                      <mi>i</mi>
                    </msub>
                    <mo>-</mo>
                    <msub>
                      <mi>&#x3bc;</mi>
                      <mi>k</mi>
                    </msub>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
    </mrow>
  </mrow>
</mrow>
</math>
</maths>
<br/>
which is exactly L(i, j) in equation (5).
</p>
<p id="p-0047" num="0046">The process herein also has intuitive interpretations: Equations (9) and (10) are linear regression solutions and the regression model may be expressed as p<sub>i</sub>&#x2248;a<sub>k</sub>*<sup>T</sup>I<sub>i</sub>+b<sub>k</sub>*, &#x2200;i&#x3b5;&#x3c9;<sub>k</sub>. Further, equation (11) can be rewritten as:</p>
<p id="p-0048" num="0047">
<maths id="MATH-US-00010" num="00010">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mrow>
            <mo>(</mo>
            <mi>Lp</mi>
            <mo>)</mo>
          </mrow>
          <mi>i</mi>
        </msub>
        <mo>=</mo>
        <mrow>
          <munder>
            <mo>&#x2211;</mo>
            <mrow>
              <mi>k</mi>
              <mo>&#x2208;</mo>
              <msub>
                <mi>&#x3c9;</mi>
                <mi>i</mi>
              </msub>
            </mrow>
          </munder>
          <mo>&#x2062;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <msub>
                <mi>p</mi>
                <mi>i</mi>
              </msub>
              <mo>-</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mrow>
                    <msubsup>
                      <mi>a</mi>
                      <mi>k</mi>
                      <mrow>
                        <mo>*</mo>
                        <mi>T</mi>
                      </mrow>
                    </msubsup>
                    <mo>&#x2062;</mo>
                    <msub>
                      <mi>I</mi>
                      <mi>i</mi>
                    </msub>
                  </mrow>
                  <mo>+</mo>
                  <msubsup>
                    <mi>b</mi>
                    <mi>k</mi>
                    <mo>*</mo>
                  </msubsup>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>16</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where, for any pixel I<sub>i</sub>, the term (p<sub>i</sub>&#x2212;(a<sub>k</sub>*<sup>T</sup>I<sub>i</sub>+b<sub>k</sub>*)) is the error between p<sub>i </sub>and its linear prediction. As I<sub>i </sub>is involved in all the regression processes satisfying k&#x3b5;&#x3c9;<sub>i</sub>, equation (16) is the sum of errors in all windows around i.
</p>
<p id="p-0049" num="0048">All the summations in (9) and (11) can be very efficiently computed using an integral image technique (see, e.g., Crow, F. C., &#x201c;Summed-area tables for texture mapping,&#x201d; SIGGRAPH, 1984). Using the integral image, the sum of any window can be obtained in constant time (e.g., four operations). For example, once a summed area table has been computed for an image, any rectangle can be evaluated in constant time with just four array references. Therefore, the time complexity for computing Lp in each iteration is O(N&#x2032;)&#x2248;O(N), where N&#x2032; is the size of the bounding box of the unknown region. Consequently, it may be seen that the time complexity is also independent of the kernel size.</p>
<p id="h-0007" num="0000">Example Framework</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of a framework <b>200</b> for image matting according to some implementations herein. The framework <b>200</b> receives an input image <b>202</b> for processing. As an example, the input image <b>202</b> may have one or more foreground objects that a user would like to pull from the input image <b>202</b>, such as for placing over a background of another image (not shown), or the like. The input image <b>202</b> may be used to generate a trimap <b>204</b> that is provided to a variable kernel size matting component <b>206</b>. For example, in some implementations, a user may generate the trimap from the image interactively, such as by using a mouse and a user interface (not shown in <figref idref="DRAWINGS">FIG. 2</figref>) to designate a definite foreground region, a definite background region, and a boundary or unknown region. In other implementations, the trimap may be generated automatically or partially automatically based on user input. In other implementations, the trimap may be generated in advance, such as by the user, by an application, or the like. For example, in the case of a series of video images the trimap may be generated automatically by an application, such as based on motion estimation from a previous frame, and so forth.</p>
<p id="p-0051" num="0050">The trimap and the input image are provided to the variable kernel size matting component <b>206</b> to process the image using equations (9), (10) and (11), as described above, to produce an alpha matter and/or composite image <b>208</b>. Thus, for each pixel i in the unknown region, the variable kernel size matting component <b>206</b> determines the value q<sub>i </sub>based on a conjugate vector p of a previous iteration. As mentioned above, because the computation is independent of the window radius r and the kernel size, relatively large kernel sizes (e.g., 5&#xd7;5 pixels or larger) may be used for processing each pixel, thereby achieving a high quality matte with a shorter computation time that conventional techniques.</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIGS. 3A-3C</figref> depict an example of an input image <b>300</b> illustrating matting processing according to the framework of <figref idref="DRAWINGS">FIG. 2</figref>. As depicted in <figref idref="DRAWINGS">FIG. 3A</figref>, the input image <b>300</b> includes two dolls <b>302</b>, <b>304</b> as foreground objects on a natural background <b>306</b>. The dolls <b>302</b>, <b>304</b> include hair <b>308</b>, <b>310</b> that can be difficult to distinguish from the background <b>306</b>. <figref idref="DRAWINGS">FIG. 3B</figref> is a trimap <b>312</b> corresponding to <figref idref="DRAWINGS">FIG. 3A</figref>, including definite foreground regions <b>314</b>, <b>316</b>, definite background regions <b>318</b> and a boundary or unknown region <b>320</b>. A mentioned above, in some implementations the trimap may be generated interactively by a user, such as with a mouse or other input device. In other implementations, the trimap <b>312</b> may be generated automatically or semi-automatically, or generated in advance of receiving the input image <b>300</b>. <figref idref="DRAWINGS">FIG. 3C</figref> depicts the alpha channel or alpha matte <b>322</b> extracted from input image <b>300</b> using an implementation of the matting process herein based on equations (9), (10) and (11) described above, that is independent of kernel size and window radius r. The process has clearly defined the details of the unknown region <b>320</b> of the trimap as either background <b>318</b> or foreground <b>314</b>, <b>316</b>, including the hair structure <b>308</b>, <b>310</b>.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 4</figref> depicts a flow diagram of an example process <b>400</b> for image matting according to some implementations herein. In the flow diagram, the operations are summarized in individual blocks. The operations may be performed in hardware, or as processor-executable instructions (software or firmware) that may be executed by one or more processors. Further, the process <b>400</b> may, but need not necessarily, be implemented using the framework of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0054" num="0053">At block <b>402</b>, an input image is received for processing. For example, the matting components and processing described herein may be part of a computer program application or software package such as an image processing application, a photograph editing application, a presentation application, a word processing application, a video editing application, or the like.</p>
<p id="p-0055" num="0054">At block <b>404</b>, a trimap corresponding to the input image is received or generated for the image. For example, as described above with reference to <figref idref="DRAWINGS">FIG. 3</figref>, the trimap identifies definite foreground areas, definite background areas, and an unknown boundary area.</p>
<p id="p-0056" num="0055">At block <b>406</b>, matting processing of the image is performed based on equations (9), (10) and (11) described above in a manner that is independent of the kernel size and window radius used during the processing. Thus, instead of computing the elements of the matting Laplacian L and the convolution explicitly, the product Lp is calculated as a whole using equations (9)-(11). Further, because the process is independent of kernel size a relatively large kernel size can be efficiently employed during the processing, thereby reducing the number of iterations carried out and increasing the speed of the overall process. The limits on the kernel size are discussed below and are based on maintaining the linearity of the system, rather than processing time, or the like.</p>
<p id="p-0057" num="0056">At block <b>408</b>, the alpha matte is generated as output. The alpha matte clearly indicates which parts of the input image are part of the selected foreground or part of the background. The alpha matte may be used for various applications, such as for transferring the selected foreground to a different background image to create composite image or for other purposes.</p>
<p id="p-0058" num="0057">The above framework and process for image matting described herein may be implemented in a number of different environments and situations. Further, while several examples are described herein for explanation purposes, the disclosure is not limited to the specific examples, and can be extended to additional environments, applications and settings. For example, the matting processing herein may be used for other applications, such as haze removal, spatially variant white balance, intrinsic imaging, and the like.</p>
<p id="h-0008" num="0000">Kernel Size</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 5</figref> depicts a graph demonstrating the effect of different kernel sizes during processing on the same image according to implementations of the process described herein. As illustrated in <figref idref="DRAWINGS">FIG. 5</figref>, it may be seen that the solver converges much faster in the larger kernel cases. In this example, when the window radius r=1 the linear solver takes 519 iterations to converge, while when the window radius r=20, the solver only takes 44 iterations to converge, with the number of iterations for r=10 and r=5 also being substantially less than for r=1. Further, the running time (not shown in <figref idref="DRAWINGS">FIG. 5</figref>) is also substantially less for r=20 (e.g., 0.090 sec.) than for r=1 (e.g., 1.07 sec.), while the resulting mattes were visually almost identical. Consequently, by employing the above process, the running time of the linear solver can be substantially reduced when a relatively large kernel is used since the linear solver converges in fewer iterations. Further, as comparison with conventional techniques, the running time of a brute force CG solver using equations (5) and (8) for r=1 was found to be 0.95 sec. and for r=20 was found to be 22 sec.</p>
<p id="p-0060" num="0059">A large kernel having a radius greater than r=1 can also improve the quality of the resulting matte because a large window may cover disconnected regions of the foreground/background. This property is particularly favored when the foreground object has holes through which portions of the background are visible. In such a case, when the radius is r=1, the radius may be too small to cover the known background and the holes. Thus, implementations herein can obtain a quality matte by using a larger window size, e.g., r=20. Further, the large kernel process herein may typically be more appropriate for high-resolution images. For example, a small window may not be sufficient to describe the fine lines or structures in an image, such as hairs, feathers, fuzz, etc., which can result in the loss of such fine structures. However, a large window enables collection of more color samples, and thereby achieves a higher quality result. Further, a larger window kernel also enables coverage of more known pixels near the boundary of unknowns and thereby provides more stable constraints. However, a drawback of a large kernel is that when the foreground/background is complicated, a larger window leads to a higher probability of breaking the color line assumption upon which equations (9)-(11) are based (i.e., equation (1)). For instance, if a window is so large that the window covers more than one color cluster of the background, the colors will not lie in the same line. Thus, an upper bound of the kernel size is limited based on maintaining linearity of the colors in the kernel. Consequently, the matte will not be as accurate as using a smaller window and may include artifacts. In practice, when creating a trimap, a user will create a wide band of unknowns near a fuzzy object or an object with holes, as it is difficult to provide a precise boundary, while, on the other hand, the band of unknowns created near a solid boundary tends to be relatively narrow. Further, the use of high-resolution images may also result in a wider band of unknowns. Accordingly, using a larger kernel enables efficient propagation of constraints in a wide band. However, for a narrow band, a smaller kernel may be favored to avoid breaking the color line assumption. To achieve this goal of using smaller kernels for narrower bands of unknowns and larger kernels for wider bands, implementations herein adaptively set the kernel size based on a trimap segmentation technique, as described below.</p>
<p id="h-0009" num="0000">Example Framework with Trimap Segmentation</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 6</figref> depicts an example of a framework <b>600</b> for image matting with trimap segmentation according to some implementations herein. The framework <b>600</b> receives an input image <b>602</b> for processing. As an example, the input image <b>602</b> may have one or more foreground objects that a user would like to pull from the input image <b>602</b>, such as for placing over a background of another image (not shown), or the like. The input image <b>602</b> may be used to generate a trimap <b>604</b> or the trimap <b>604</b> may be received with the input image <b>602</b>. For example, in some implementations, a user may generate the trimap interactively, such as by using a mouse and a user interface (not shown in <figref idref="DRAWINGS">FIG. 6</figref>) to designate a definite foreground region, a definite background region, and a boundary or unknown region. In other implementations, the trimap may be generated automatically or partially automatically based on user input. Further, the trimap <b>604</b> may be generated in advance, such as by the user, by an application, or the like.</p>
<p id="p-0062" num="0061">The trimap <b>604</b> may be provided to a trimap segmentation component <b>606</b>. Trimap segmentation component <b>606</b> performs segmentation of the trimap <b>604</b> to divide the trimap into smaller regions or segments to produce a segmented trimap <b>608</b>. Through segmentation of the trimap, each segment can be processed individually using an optimal kernel size during the matting processing, as is described additionally below. The segmented trimap <b>608</b> and the input image <b>602</b> are provided to a matting component <b>610</b> to process the image to produce an alpha matte and/or composite image <b>612</b>.</p>
<p id="p-0063" num="0062">Matting component <b>610</b> may include a variable kernel size matting component <b>614</b> to perform the matting processing to separate the alpha matte from the background, as described above, based on formulas (9)-(11). In some implementations, variable kernel size matting component <b>614</b> corresponds to variable kernel size matting component <b>206</b> discussed above. Each segment in the segmented trimap may be processed using an optimal kernel size determined for the segment. As mentioned above, because the matting computation itself is independent of the kernel size, relatively large kernel sizes (e.g., 5&#xd7;5 pixels or larger) may be used for processing each segment, thereby achieving a high quality matte with a shorter computation time that conventional techniques. Further, through trimap segmentation, the kernel size can be optimized to maintain linearity within each kernel.</p>
<p id="p-0064" num="0063">Matting component <b>610</b> may further include a local processing component <b>616</b> and a global processing component <b>618</b>. Local processing component <b>616</b> and global processing component <b>618</b> may be provided to address artifacts and seams that may otherwise occur in the alpha matte due to the segmentation of the trimap. Thus, as is described additionally below, according to some implementations, the matte may be calculated during a first local pass for each segment using local processing component <b>616</b>. Global processing component <b>618</b> may then be used to refine the matte during a global pass that solves the unknowns based on the entire trimap to remove transitions between segments. Finally, the local processing component <b>616</b> may be employed again to further refine the matte during a second local pass that performs additional processing on each of the segments of the segmented trimap. Other variations will also be apparent in light of the disclosure herein.</p>
<p id="h-0010" num="0000">Trimap Segmentation</p>
<p id="p-0065" num="0064">According to some implementations herein, trimap segmentation may further improve both the quality and efficiency of the image matting. Trimap segmentation enables different window or kernel sizes to be used in different regions. Thus, trimap segmentation reduces a large linear system into a set of smaller linear systems and thereby further reduces the running time for solving the entire system.</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. 7A</figref> illustrates an example input image <b>700</b>, while <figref idref="DRAWINGS">FIG. 7B</figref> illustrates a corresponding trimap <b>702</b> for image <b>700</b>. For a given trimap, implementations herein first calculate the unknown region's barycenter (x<sub>x</sub>, y<sub>c</sub>), x variance</p>
<p id="p-0067" num="0066">
<maths id="MATH-US-00011" num="00011">
<math overflow="scroll">
<mrow>
  <mrow>
    <msubsup>
      <mi>&#x3c3;</mi>
      <mi>x</mi>
      <mn>2</mn>
    </msubsup>
    <mo>=</mo>
    <mrow>
      <mfrac>
        <mn>1</mn>
        <mi>n</mi>
      </mfrac>
      <mo>&#x2062;</mo>
      <mrow>
        <munder>
          <mo>&#x2211;</mo>
          <mi>U</mi>
        </munder>
        <mo>&#x2062;</mo>
        <msup>
          <mrow>
            <mo>(</mo>
            <mrow>
              <msub>
                <mi>x</mi>
                <mi>c</mi>
              </msub>
              <mo>-</mo>
              <mi>x</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
          <mn>2</mn>
        </msup>
      </mrow>
    </mrow>
  </mrow>
  <mo>,</mo>
</mrow>
</math>
</maths>
<br/>
and y variance
</p>
<p id="p-0068" num="0067">
<maths id="MATH-US-00012" num="00012">
<math overflow="scroll">
<mrow>
  <mrow>
    <msubsup>
      <mi>&#x3c3;</mi>
      <mi>y</mi>
      <mn>2</mn>
    </msubsup>
    <mo>=</mo>
    <mrow>
      <mfrac>
        <mn>1</mn>
        <mi>n</mi>
      </mfrac>
      <mo>&#x2062;</mo>
      <mrow>
        <munder>
          <mo>&#x2211;</mo>
          <mi>U</mi>
        </munder>
        <mo>&#x2062;</mo>
        <msup>
          <mrow>
            <mo>(</mo>
            <mrow>
              <msub>
                <mi>y</mi>
                <mi>c</mi>
              </msub>
              <mo>-</mo>
              <mi>y</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
          <mn>2</mn>
        </msup>
      </mrow>
    </mrow>
  </mrow>
  <mo>,</mo>
</mrow>
</math>
</maths>
<br/>
where U is the set of unknown pixels, and n is the size of U. Then a line that passes through (x<sub>c</sub>, y<sub>c</sub>) is used to divide the trimap into two areas. This line is perpendicular to the axis (either x or y) having a larger variance. For instance, in the illustrated example of <figref idref="DRAWINGS">FIG. 7B</figref>, the line <b>704</b> divides the trimap into two areas, these two areas are then divided into two more areas, by lines <b>706</b> and <b>708</b>, respectively, each of those areas may be further divided into two more areas, and so forth, to divide the trimap <b>702</b> into a plurality of segments <b>710</b>. Each segment <b>710</b> contains a portion of the unknown region and at least one of definite foreground region and definite background region. In some implementations, the trimap may be recursively divided and a two-dimensional tree data structure may be built accordingly. For example, in the tree data structure, the entire trimap serves as the root area and each time an area is subdivided into two sub-areas, two branches are added to the tree. Such a tree may be referred to as a binary space partitioning (BSP) tree or a two-dimensional k-dimensional (2D KD) tree. The tree data structure may be traversed for managing matting processing of the various segments of the trimap.
</p>
<p id="p-0069" num="0068">The conditions for stopping the recursive subdivision of the trimap may be determined as follows. If a subdivided area of the image covers enough foreground and background constraints, a reasonably good matte can be obtained by considering just this subdivided area of the image independently. Therefore, it is desirable for the segments to be small, while still having as many of segments as possible having both definite foreground (F) and definite background (B) constraints in addition to the unknown (U) region. Consequently, according to implementations herein, the recursive division of the trimap may be stopped when at least one of the following conditions is satisfied: (a) the segment only has F and U elements; (b) the segment only has B and U elements; (c) if the segment is divided, one of the segment's children will have only F and U elements, and the other child will have only B and U elements; or (d) The segment's minimum width or minimum height would be smaller than a predetermined threshold. Empirical data has shown 32 pixels to be a suitable threshold, although other suitable thresholds may also be used. It may be further noted that these conditions generally result in segmentation of the trimap such that the bandwidth of the unknowns in each segment is generally uniform.</p>
<p id="p-0070" num="0069">According to some implementations, when the trimap has been segmented, the linear system in each segment can be solved as described above based on equations (9)-(11). The integral image is calculated in a bounding box of the unknowns in each segment. Implementations herein first solve the segments that satisfy the above conditions (c) or (d), as these segments directly contain both F and B constraints. Then, other segments (i.e., those segments that have only F and U, or only B and U) are solved, such as by using an inverse Breadth-First Search order on the tree data structure, i.e., in which the deeper leaves in the binary tree have a higher priority. Further, because these remaining segments do not contain one of an F or B constraint, implementations herein use an already-solved matte of a neighboring segment as boundary conditions. The inverse Breadth-First Search order ensures that at least one of the neighboring segments has already been solved, although other methods may also be used for determining an order to solve the various segments.</p>
<p id="p-0071" num="0070">In addition, implementations herein adapt the kernel size used to solve each segment to the bandwidth of the unknowns in that segment. For example, for each segment, let (w, h) be the width and height of U's bounding box (i.e., a rectangle of a minimum size that encompasses all the unknown pixels in the particular segment). Implementations herein approximate the width of the band by w<sub>b</sub>=n/max(w,h). Implementations herein set the window radius r=w<sub>b</sub>/&#x3b7;, where &#x3b7; is a factor that may be determined empirically. For example, experiments with implementations herein have shown suitable values for &#x3b7; to range from 2 to 20, depending on desired window size. Intuitively, the propagation will influence the other side of the band in &#x3b7;/2 iterations (noting that the kernel radius is 2r). Therefore, the number of iterations for convergence is in the order of &#x3b7;, and can be fixed beforehand. For example, if the bandwidth of the unknown region of a first segment is approximately 50 pixels, i.e., w<sub>b</sub>=50, then using a factor &#x3b7; of 3, the window radius r=50/3 or 17 for processing the first segment (i.e., a kernel size of 69&#xd7;69 pixels). On the other hand, when the bandwidth of a second segment is approximately 30 pixels, then the window radius r=10 for that segment (i.e., a kernel size of 41&#xd7;41 pixels). Thus, implementations herein are able to assign a kernel size that is suitable for the particular segment for maintaining both a linear system and for achieving optimal processing speed. Consequently, the propagation speed is adaptive to the bandwidth of the unknown region in a particular segment. Further, the same number of iterations is able to provide high quality mattes for two bands of unknowns of different width.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 8</figref> depicts a flow diagram of an example process <b>800</b> for trimap segmentation according to some implementations herein. In the flow diagram, the operations are summarized in individual blocks. The operations may be performed in hardware, or as processor-executable instructions (software or firmware) that may be executed by one or more processors. Further, the process <b>800</b> may, but need not necessarily, be implemented using the framework of <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0073" num="0072">At block <b>802</b>, a trimap of an image is received identifying a definite foreground portion F, a definite background portion B and a boundary or unknown portion U.</p>
<p id="p-0074" num="0073">At block <b>804</b>, the process selects an area of the trimap for processing. For example, when the trimap is first received the entire trimap is the area that is processed, whereas, subsequently, subdivided areas of the trimap are the areas selected for processing.</p>
<p id="p-0075" num="0074">At block <b>806</b>, the barycenter, x variance, and y variance are calculated for the unknown portion U of the selected area.</p>
<p id="p-0076" num="0075">At block <b>808</b>, the area may be segmented at the barycenter along a line perpendicular to the axis having the larger variance.</p>
<p id="p-0077" num="0076">At block <b>810</b>, the two new segments created by segmenting the selected area are added to the tree data structure representing the trimap segmentation. As mentioned above, the tree data structure may be a BSP or 2D KD tree.</p>
<p id="p-0078" num="0077">At block <b>812</b>, the two new segmented areas are examined based upon specified conditions to determine whether to perform further segmentation on one or both of the segmented areas. Thus for each of the new segmented areas, the process determines whether at least one of the four following conditions has been met.</p>
<p id="p-0079" num="0078">At block <b>814</b>, the process determines whether the segmented area has only foreground F and unknown U elements.</p>
<p id="p-0080" num="0079">At block <b>816</b>, the process determines whether the segmented area has only background B and unknown U elements.</p>
<p id="p-0081" num="0080">At block <b>818</b>, the process determines whether, if the segmented area is divided, one of the children will have only foreground F and unknown U elements while the other child will have only background B and unknown U elements.</p>
<p id="p-0082" num="0081">At block <b>820</b>, the process determines whether the segmented area's width or height is below a predetermined threshold. As mentioned above, and this predetermined threshold may be determined experimentally. Implementations herein have shown that the threshold may be between 25 and 40 pixels, such as for example 32 pixels, although other threshold values may also be used.</p>
<p id="p-0083" num="0082">At block <b>822</b>, the process determines whether one or more of the above conditions have been met. If not, then the process returns to block <b>806</b> to process the area for which none of the conditions have been met. On the other hand, if at least one of the conditions is met for both of the newly segmented areas, then no further segmentations of these areas is desired and the process moves to block <b>824</b>.</p>
<p id="p-0084" num="0083">At block <b>824</b>, the process determines whether all of the areas in the trimap have been processed. When all of the areas in the trimap have been segmented, the segmented trimap is ready for image matting processing.</p>
<p id="h-0011" num="0000">Local-Global-Local Processing</p>
<p id="p-0085" num="0084">To prevent the result from being overly locally determined, some implementations herein employ a local-global-local (LGL) scheme. Under this LGL scheme, following the trimap segmentation technique described above, a first local pass is performed which quickly solves the matte for each segment in the segmented trimap. Next a global pass is performed over the entire unsegmented trimap, and then a second local pass is performed over the segmented trimap to further refine the alpha matte.</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIGS. 9A-9H</figref> depict an example of the execution and effect of the local-global-local processing scheme. <figref idref="DRAWINGS">FIG. 9A</figref> depicts a trimap <b>900</b> corresponding to the trimap <b>312</b> of <figref idref="DRAWINGS">FIG. 3B</figref>. The trimap <b>900</b> has been segmented using the trimap segmentation technique described above. Initially, a first local pass of the image is performed for each segment in the trimap <b>900</b> to generate an alpha matte <b>902</b>, as depicted in <figref idref="DRAWINGS">FIG. 9C</figref>. For example, if &#x3b7;=3, then the matting component is able to quickly propagate initial matting information. Further, some implementations herein may empirically fix the number of iterations in the first local pass. For example, experiments have shown that 10 iterations is a suitable number of iterations for the first local pass sufficient to obtain a good initial alpha matte <b>902</b>.</p>
<p id="p-0087" num="0086">However, because the segments are processed individually to a certain extent, noticeable seams may exist on segment boundaries. <figref idref="DRAWINGS">FIG. 9B</figref> represents an enlarged region <b>904</b> of a segment boundary line <b>906</b> between a first segment <b>908</b> and a second segment <b>910</b>. <figref idref="DRAWINGS">FIG. 9D</figref> represents an enlarged region <b>912</b> of alpha matte <b>902</b> corresponding to the location of enlarged region <b>904</b> of <figref idref="DRAWINGS">FIGS. 9A-9B</figref>. Close examination of the corresponding alpha matte <b>902</b> at the enlarged region <b>912</b> in area <b>914</b> reveals a noticeable transition between the two segments <b>908</b>, <b>910</b> at the location of the segment boundary line <b>906</b>.</p>
<p id="p-0088" num="0087">Using the above-obtained alpha matte <b>902</b> as an initial guess, some implementations herein next optimize the whole linear system globally. Accordingly, for the global matting process, in some implementations, the window radius r is set to be min(w, h)/50 where w and h are the image's width and height in pixels, and 50 is an empirically determined value, although other suitable values may also be used. Further, the number of iterations to be carried out is fixed on a low number, such as five. This global processing produces a second alpha matte <b>916</b>, as illustrated in <figref idref="DRAWINGS">FIG. 9E</figref>. As demonstrated by the enlarged area <b>918</b>, of <figref idref="DRAWINGS">FIG. 9F</figref>, the noticeable transition between the segments is eliminated by the global processing.</p>
<p id="p-0089" num="0088">However, the kernel size used in the global processing may be too large for some local regions. Thus, because of the large kernel size, the alpha matte <b>916</b> may include artifacts or be missing some details due to the failure of the color line assumption. Consequently a second local processing pass may be executed to further refine the alpha matte <b>916</b> using the segmented trimap <b>900</b>. As an example, in the second local pass, &#x3b7; may be larger than in the earlier passes, such as &#x3b7;=15 and the number of iterations permitted may also be larger, such as 20 iterations. Experiments have shown that more iterations than 20 improve the result very little. Additionally, because &#x3b7; is larger (i.e., 15 as opposed to 3), the window and kernel size is much smaller in the second local pass than in the first local pass so as to ensure that the color line model is maintained. This suppresses the occurrence of artifacts due to the large window size used in previous two steps, and can produce a third alpha matte <b>920</b>, as illustrated in <figref idref="DRAWINGS">FIG. 9G</figref>. <figref idref="DRAWINGS">FIG. 9H</figref> depicts an enlarged portion <b>922</b> of alpha matte <b>920</b>, showing that artifacts are eliminated and some details <b>924</b> are improved.</p>
<p id="h-0012" num="0000">Time Complexity</p>
<p id="p-0090" num="0089">The running time of implementations herein may be substantially linear to the image size thereby providing predictable performance and processing time based on image size. For example, if N&#x2032; is denoted as the total area of all the bounding boxes of the unknowns in all segments, then the time complexity of the local steps is O(N&#x2032;) when the time for calculating Lp in each iteration is O(N&#x2032;) and the iteration number is fixed. For the same reason, the time complexity of the global step is O(M), where M is the size of the bounding box of the whole unknown region. Experiments have shown that the time for the global step is much less than that of the local steps due to the fewer number of iterations. Consequently, the total time complexity is essentially O(N&#x2032;). Therefore, as N&#x2032; is slightly larger than the number of unknowns N, the running time is almost linear to N. Accordingly, after the trimap is segmented, the time can be predicted based in the number of unknown pixels N before running the linear solver.</p>
<p id="h-0013" num="0000">Example Matting Process with Trimap Segmentation</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 10</figref> depicts a flow diagram of an example of a matting process <b>1000</b> with trimap segmentation according to some implementations herein. In the flow diagram, the operations are summarized in individual blocks. The operations may be performed in hardware, or as processor-executable instructions (software or firmware) that may be executed by one or more processors. Further, the process <b>1000</b> may, but need not necessarily, be implemented using the framework of <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0092" num="0091">At block <b>1002</b>, an input image is received for processing. For example, in some implementations, a high-resolution image having a foreground object on a natural background is received for pulling the foreground object and an alpha matte from the background of the image.</p>
<p id="p-0093" num="0092">At block <b>1004</b>, a trimap is received and/or generated for the input image. For example, in some implementations, a user may interactively assist in generation of the trimap using a user interface and an input device, such as a mouse. In other implementations, the trimap may be pre-generated by a user or an application, or provided by other methods.</p>
<p id="p-0094" num="0093">At block <b>1006</b>, the trimap is segmented as described above with reference to <figref idref="DRAWINGS">FIG. 8</figref>. For example, the trimap is segmented and a corresponding tree data structure is generated to enable traversal of the trimap segments during matting processing of the individual segments. Other methods of performing matting processing of the individual segments may also be used.</p>
<p id="p-0095" num="0094">At block <b>1008</b>, a first local matting processing pass is performed based on the segmented trimap. For example, this local pass may be a quick processing of the image using a low number of iterations and larger kernel sizes to obtain a first alpha matte.</p>
<p id="p-0096" num="0095">At block <b>1010</b>, a global matting processing pass is performed on the image based on the trimap without considering the segmentation. For example, the global pass may also be performed using a large kernel size and a relatively small number of iterations to refine the first alpha matte by removing transition areas between segments to obtain a second alpha matte.</p>
<p id="p-0097" num="0096">At block <b>1012</b>, a second local matting processing pass is performed based on the segmented trimap to further refine the second alpha matte. The second local pass may be performed using a smaller kernel size and a larger number of iterations than the first local pass for refining the second alpha matte to obtain a third alpha matte.</p>
<p id="p-0098" num="0097">At block <b>1014</b>, the third alpha matte is output, and may be used for further image processing. For example, the third alpha matte may be used to place the corresponding foreground object over a new background to create a composite image, or the like.</p>
<p id="h-0014" num="0000">Computing System Environment</p>
<p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. 11</figref> illustrates an example configuration of a suitable computing system environment <b>1100</b> according to some implementations herein. The computing system environment <b>1100</b> may include at least one processor <b>1102</b>, a memory <b>1104</b>, communication interfaces <b>1106</b>, a display device <b>1108</b>, input/output (I/O) devices <b>1110</b>, and one or more mass storage devices <b>1112</b>, all able to communicate through a system bus <b>1114</b> or other suitable connection.</p>
<p id="p-0100" num="0099">The processor <b>1102</b> may be a single processing unit or a number of processing units, all of which may include single or multiple computing units or multiple cores. The processor <b>1102</b> can be implemented as one or more microprocessors, microcomputers, microcontrollers, digital signal processors, central processing units, state machines, logic circuitries, and/or any devices that manipulate signals based on operational instructions. Among other capabilities, the processor <b>1102</b> can be configured to fetch and execute computer-readable instructions or processor-accessible instructions stored in the memory <b>1104</b>, mass storage devices <b>1112</b>, or other computer-readable storage media.</p>
<p id="p-0101" num="0100">Memory <b>1104</b> and mass storage devices <b>1112</b> are examples of computer-readable storage media for storing instructions which are executed by the processor <b>1102</b> to perform the various functions described above. For example, memory <b>1104</b> may generally include both volatile memory and non-volatile memory (e.g., RAM, ROM, or the like). Further, mass storage devices <b>1112</b> may generally include hard disk drives, solid-state drives, removable media, including external and removable drives, memory cards, Flash memory, floppy disks, optical disks (e.g., CD, DVD), storage arrays, storage area networks, network attached storage, or the like, or any combination thereof. Both memory <b>1104</b> and mass storage devices <b>1112</b> may be collectively referred to as memory or computer-readable storage media herein. Memory <b>1104</b> is capable of storing computer-readable, processor-executable program instructions as computer program code that can be executed on the processor <b>1102</b> as a particular machine configured for carrying out the operations and functions described in the implementations herein. Memory <b>1104</b> may include the trimap segmentation component <b>606</b> and the matting component <b>610</b> having the variable kernel size matting component <b>614</b>, the local processing component <b>616</b>, and the global processing component <b>618</b>, which can be executed on the processor <b>1102</b> for implementing the functions described herein. In some implementations, memory <b>1104</b> may include a user interface component <b>1116</b> for generating a user interface <b>1118</b> on display device <b>1108</b>. User interface <b>1118</b> may enable a user to interactively use matting component <b>610</b> for pulling a matte from an image. For example, the user may use a mouse or other input device <b>1110</b> to interact with an image such as for generating a trimap of the image being processed. In some implementations, matting component <b>610</b> and trimap segmentation component <b>606</b> may be part of an application (not shown), or the like, such as any of an image processing application, a photo editing application, a presentation generating application, a word processing application, or any other suitable application. Further in other implementations, matting component <b>610</b> and trimap segmentation component <b>606</b> are separate components not included in an application, and/or may be part of an operating system (not shown).</p>
<p id="p-0102" num="0101">The computing system environment <b>1100</b> can also include one or more communication interfaces <b>1106</b> for exchanging data with other devices, such as via a network, direct connection, or the like, as discussed above. The communication interfaces <b>1106</b> can facilitate communications within a wide variety of networks and protocol types, including wired networks (e.g., LAN, cable, etc.) and wireless networks (e.g., WLAN, cellular, satellite, etc.), the Internet and the like.</p>
<p id="p-0103" num="0102">The display device <b>1108</b>, such as a monitor, display, or screen, may be included in some implementations for displaying the user interface <b>1118</b> and/or an input image to a user. I/O devices <b>1110</b> may include devices that receive various inputs from a user and provide various outputs to the user, such as a keyboard, remote controller, a mouse, a camera, audio devices, and so forth.</p>
<p id="p-0104" num="0103">The example environments, systems and computing devices described herein are merely examples suitable for some implementations and are not intended to suggest any limitation as to the scope of use or functionality of the environments, architectures and frameworks that can implement the processes, components and features described herein. Thus, implementations herein are operational with numerous environments or applications, and may be implemented in general purpose and special-purpose computing systems, or other devices having processing capability.</p>
<p id="p-0105" num="0104">Additionally, the components, frameworks and processes herein can be employed in many different environments and situations. Generally, any of the functions described with reference to the figures can be implemented using software, hardware (e.g., fixed logic circuitry) or a combination of these implementations. The term &#x201c;module,&#x201d; &#x201c;mechanism&#x201d; or &#x201c;component&#x201d; as used herein generally represents software, hardware, or a combination of software and hardware that can be configured to implement prescribed functions. For instance, in the case of a software implementation, the term &#x201c;module,&#x201d; &#x201c;mechanism&#x201d; or &#x201c;component&#x201d; can represent program code (and/or declarative-type instructions) that performs specified tasks or operations when executed on a processing device or devices (e.g., CPUs or processors). The program code can be stored in one or more computer-readable memory devices or other computer-readable storage devices. Thus, the processes, components and modules described herein may be implemented by a computer program product.</p>
<p id="p-0106" num="0105">Although illustrated in <figref idref="DRAWINGS">FIG. 11</figref> as being stored in memory <b>1104</b> of computing system environment <b>1100</b>, matting component <b>610</b>, trimap segmentation component <b>606</b>, or portions thereof, may be implemented using any form of computer-readable media that is accessible by computing system environment <b>1100</b>. Computer-readable media may include, for example, computer storage media and communications media.</p>
<p id="p-0107" num="0106">Computer storage media includes volatile and non-volatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to store information for access by a computing device.</p>
<p id="p-0108" num="0107">In contrast, communication media may embody computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave, or other transport mechanism.</p>
<p id="p-0109" num="0108">Furthermore, this disclosure provides various example implementations, as described and as illustrated in the drawings. However, this disclosure is not limited to the implementations described and illustrated herein, but can extend to other implementations, as would be known or as would become known to those skilled in the art. Reference in the specification to &#x201c;one implementation,&#x201d; &#x201c;this implementation,&#x201d; &#x201c;these implementations&#x201d; or &#x201c;some implementations&#x201d; means that a particular feature, structure, or characteristic described is included in at least one implementation, and the appearances of these phrases in various places in the specification are not necessarily all referring to the same implementation.</p>
<heading id="h-0015" level="1">CONCLUSION</heading>
<p id="p-0110" num="0109">Implementations herein provide fast and efficient image matting. Further, implementations enable matting processing using relatively large or optimized kernel sizes. Employing larger and optimized kernels leads to fewer iterations to converge, enabling the focus to be on reducing the time in each iteration, and can also provide mattes of improved quality.</p>
<p id="p-0111" num="0110">Although the subject matter has been described in language specific to structural features and/or methodological acts, the subject matter defined in the appended claims is not limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims. This disclosure is intended to cover any and all adaptations or variations of the disclosed implementations, and the following claims should not be construed to be limited to the specific implementations disclosed in the specification. Instead, the scope of this document is to be determined entirely by the following claims, along with the full range of equivalents to which such claims are entitled.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08625888-20140107-M00001.NB">
<img id="EMI-M00001" he="12.02mm" wi="76.20mm" file="US08625888-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08625888-20140107-M00002.NB">
<img id="EMI-M00002" he="8.81mm" wi="76.20mm" file="US08625888-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08625888-20140107-M00003.NB">
<img id="EMI-M00003" he="9.57mm" wi="76.20mm" file="US08625888-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US08625888-20140107-M00004.NB">
<img id="EMI-M00004" he="23.28mm" wi="76.20mm" file="US08625888-20140107-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US08625888-20140107-M00005.NB">
<img id="EMI-M00005" he="7.45mm" wi="76.20mm" file="US08625888-20140107-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00006" nb-file="US08625888-20140107-M00006.NB">
<img id="EMI-M00006" he="9.91mm" wi="76.20mm" file="US08625888-20140107-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00007" nb-file="US08625888-20140107-M00007.NB">
<img id="EMI-M00007" he="8.47mm" wi="76.20mm" file="US08625888-20140107-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00008" nb-file="US08625888-20140107-M00008.NB">
<img id="EMI-M00008" he="15.49mm" wi="76.20mm" file="US08625888-20140107-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00009" nb-file="US08625888-20140107-M00009.NB">
<img id="EMI-M00009" he="8.47mm" wi="76.20mm" file="US08625888-20140107-M00009.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00010" nb-file="US08625888-20140107-M00010.NB">
<img id="EMI-M00010" he="7.45mm" wi="76.20mm" file="US08625888-20140107-M00010.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00011" nb-file="US08625888-20140107-M00011.NB">
<img id="EMI-M00011" he="7.79mm" wi="76.20mm" file="US08625888-20140107-M00011.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00012" nb-file="US08625888-20140107-M00012.NB">
<img id="EMI-M00012" he="7.79mm" wi="76.20mm" file="US08625888-20140107-M00012.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>receiving a trimap of an image that specifies a foreground region, a background region and an unknown region for the image;</claim-text>
<claim-text>segmenting the trimap into a plurality of segments, each segment including a portion of the unknown region and at least one of a portion of the foreground region or a portion of the background region;</claim-text>
<claim-text>solving, by a processor, the portion of the unknown region in each segment in a first local pass to provide a first alpha matte that distinguishes a foreground region from a background region in the portion of the unknown region;</claim-text>
<claim-text>solving, by the processor, the unknown region for the entire image as a linear system to refine the first alpha matte to obtain a second alpha matte; and</claim-text>
<claim-text>refining the second alpha matte to obtain a third alpha matte by solving the portion of the unknown region in each segment wherein the solving for each segment employs a kernel size based on a size of the unknown region of the segment that is smaller than a kernel size used in the first local pass.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising segmenting the trimap by:
<claim-text>calculating a barycenter of unknown elements for a selected area; and</claim-text>
<claim-text>segmenting the selected area along a line perpendicular to one of an x axis or a y axis having a larger variance of the unknown elements.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising performing segmentation of the selected area of the trimap until at least one of the following conditions is met:
<claim-text>the selected area contains only foreground and unknown elements;</claim-text>
<claim-text>the selected area contains only background and unknown elements;</claim-text>
<claim-text>if the selected area is divided, one of the subdivided areas would only have foreground and unknown elements, and another of the subdivided areas would only have background and unknown elements; or</claim-text>
<claim-text>a width or height of the selected area is below a predetermined threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein an upper bound of the kernel size is limited based on maintaining linearity of the colors in the kernel.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein solving the portion of the unknown region for each segment comprises employing a relatively larger kernel size when a size of the portion of the unknown region in the segment is relatively wide and employing a relatively smaller kernel size when the size of the portion of the unknown region in the segment is relatively narrow.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A method comprising:
<claim-text>receiving a trimap of an image, the trimap specifying a foreground region, a background region and an unknown region;</claim-text>
<claim-text>segmenting the trimap into a plurality of segments, the segmenting comprising:
<claim-text>calculating a barycenter of unknown elements for a selected area; and</claim-text>
<claim-text>segmenting the selected area along a line perpendicular to one of an x axis or a y axis having a larger variance of the unknown elements;</claim-text>
</claim-text>
<claim-text>selecting a kernel size for performing matting processing; and</claim-text>
<claim-text>performing the matting processing using the selected kernel size to provide an alpha matte that distinguishes a foreground portion from a background portion in the unknown region, wherein the matting processing includes calculating a product of a conjugate vector and a Laplacian matrix as a whole based on an integral image technique.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein selecting the kernel size comprises specifying a window radius for the matting processing.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the matting processing is time independent of the selected kernel size.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:
<claim-text>selecting a kernel size for each segment based on the size of the unknown region in each segment, wherein larger kernel sizes are selected for larger unknown regions and smaller kernel sizes are selected for smaller unknown regions.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein performing the matting processing using the selected kernel size comprises performing the matting processing for each segment using the kernel size selected for that segment based on the size of the unknown region in that segment.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising performing a second matting processing of the image as a whole to smooth transition areas between segments in the alpha matte.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the trimap is segmented based on one of a binary space partitioning tree segmentation method or a two-dimensional KD tree based segmentation method.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein, the kernel size is selected relative to a size of the unknown region.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A system comprising:
<claim-text>a processor in communication with computer-readable storage media;</claim-text>
<claim-text>a trimap segmentation component, maintained in the computer-readable storage media and executed on the processor, to receive a trimap of an image that defines a specified foreground region, a background region and the unknown region, the trimap segmentation component segmenting the trimap into a plurality of segments, each segment including a portion of the unknown region; and</claim-text>
<claim-text>a matting component to solve the unknown region of the image by solving the portion of the unknown region of each segment to provide an alpha matte that distinguishes foreground elements from background elements in the unknown region, wherein the matting component includes a local processing component that performs a first pass of the image by solving, for each segment, the portion of the unknown region of each segment using a window having a radius selected based on a size of the portion of the unknown region of each segment.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein:
<claim-text>the matting component further includes a global processing component that solves the unknown region of the entire image; and</claim-text>
<claim-text>the local processing component subsequently performs a second pass of the image based on the segmentation to solve the portion of the unknown region of each segment based on the results of the global processing component.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the second pass performed by the local processing component is performed using a smaller window radius and/or more iterations for each segment than during the first pass by the local processing component.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein
<claim-text>the matting component first solves one or more first segments having a portion of the foreground region, a portion of the background region and a portion of the unknown region, and subsequently solves one or more second segments having a portion of the unknown region and only one of a portion of the foreground region or a portion of the background region; and</claim-text>
<claim-text>the one or more second segments are solved using an adjacent previously-solved segment. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
