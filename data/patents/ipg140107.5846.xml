<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626954-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626954</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12200658</doc-number>
<date>20080828</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>412</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709249</main-classification>
<further-classification>370401</further-classification>
<further-classification>709230</further-classification>
</classification-national>
<invention-title id="d2e53">Application-aware M:N hot redundancy for DPI-based application engines</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5008805</doc-number>
<kind>A</kind>
<name>Fiebig et al.</name>
<date>19910400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>700 79</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5664090</doc-number>
<kind>A</kind>
<name>Seki et al.</name>
<date>19970900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 15</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6195760</doc-number>
<kind>B1</kind>
<name>Chung et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6266781</doc-number>
<kind>B1</kind>
<name>Chung et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6711606</doc-number>
<kind>B1</kind>
<name>Leymann et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709203</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7583665</doc-number>
<kind>B1</kind>
<name>Duncan et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370389</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7711712</doc-number>
<kind>B2</kind>
<name>Kano</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707674</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2004/0139128</doc-number>
<kind>A1</kind>
<name>Becker et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2004/0205206</doc-number>
<kind>A1</kind>
<name>Naik et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709230</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2005/0060418</doc-number>
<kind>A1</kind>
<name>Sorokopud</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709230</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0198247</doc-number>
<kind>A1</kind>
<name>Perry et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709223</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2006/0173870</doc-number>
<kind>A1</kind>
<name>Erdmenger et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2007/0058629</doc-number>
<kind>A1</kind>
<name>Luft</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370390</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2007/0300234</doc-number>
<kind>A1</kind>
<name>Dekel et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>719313</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2008/0010487</doc-number>
<kind>A1</kind>
<name>Dekel et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2008/0016389</doc-number>
<kind>A1</kind>
<name>Talaugon et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2008/0019264</doc-number>
<kind>A1</kind>
<name>Lafleur et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370217</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2008/0028009</doc-number>
<kind>A1</kind>
<name>Ngo</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2008/0209146</doc-number>
<kind>A1</kind>
<name>Imazu et al.</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711162</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2008/0225850</doc-number>
<kind>A1</kind>
<name>Oran et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2008/0262991</doc-number>
<kind>A1</kind>
<name>Kapoor et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 20</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2008/0267628</doc-number>
<kind>A1</kind>
<name>Li et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>398 79</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2009/0003349</doc-number>
<kind>A1</kind>
<name>Havemann et al.</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2009/0063893</doc-number>
<kind>A1</kind>
<name>Bagepalli et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2009/0086651</doc-number>
<kind>A1</kind>
<name>Luft et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370253</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2009/0219813</doc-number>
<kind>A1</kind>
<name>Dolganow et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2009/0252148</doc-number>
<kind>A1</kind>
<name>Dolganow et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370351</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2009/0285225</doc-number>
<kind>A1</kind>
<name>Dahod</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370401</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2009/0296613</doc-number>
<kind>A1</kind>
<name>Kahn et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370310</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2009/0296700</doc-number>
<kind>A1</kind>
<name>Stevens et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370389</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2009/0300153</doc-number>
<kind>A1</kind>
<name>Ray et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709223</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2009/0316698</doc-number>
<kind>A1</kind>
<name>Menten</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2010/0054142</doc-number>
<kind>A1</kind>
<name>Moiso et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370252</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2010/0182918</doc-number>
<kind>A1</kind>
<name>Clevy et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370252</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>2010/0226369</doc-number>
<kind>A9</kind>
<name>Havemann et al.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>2010/0250733</doc-number>
<kind>A1</kind>
<name>Turanyi et al.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>22</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709249</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100057940</doc-number>
<kind>A1</kind>
<date>20100304</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Dolganow</last-name>
<first-name>Andrew</first-name>
<address>
<city>Kanata</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Morin</last-name>
<first-name>Steven Edward</first-name>
<address>
<city>Ottawa</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Dolganow</last-name>
<first-name>Andrew</first-name>
<address>
<city>Kanata</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Morin</last-name>
<first-name>Steven Edward</first-name>
<address>
<city>Ottawa</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Kramer &#x26; Amado, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Alcatel Lucent</orgname>
<role>03</role>
<address>
<city>Paris</city>
<country>FR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Algibhah</last-name>
<first-name>Hamza</first-name>
<department>2448</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A packet processing system for providing application-aware hot redundancy and a related card and methods are disclosed. The system may include a plurality of active devices, each including a processor configured to perform deep packet inspection to identify an application associated with an active flow, and a redundancy block configured to determine whether the application requires hot redundancy and, if so, to forward a message from which state information may be derived. The system may also include at least one protecting device in communication with each of the active devices and configured to receive the message regarding the active flow from the active device, derive state information from the message, and resume packet forwarding operations for the active flow upon failure of a respective active device of the plurality of active devices.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="94.06mm" wi="122.43mm" file="US08626954-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="174.41mm" wi="146.56mm" file="US08626954-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="214.29mm" wi="152.74mm" file="US08626954-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="222.76mm" wi="153.75mm" file="US08626954-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="200.58mm" wi="156.13mm" file="US08626954-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="233.60mm" wi="134.11mm" file="US08626954-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="141.14mm" wi="122.34mm" file="US08626954-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="195.50mm" wi="151.89mm" file="US08626954-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">This invention relates generally to providing a redundancy scheme for deep packet inspection engines.</p>
<p id="p-0004" num="0003">2. Description of Related Art</p>
<p id="p-0005" num="0004">Telecommunication service providers often advertise the reliability of their services by listing the percentage of time per year that their equipment provides full service. For example, many service providers guarantee &#x201c;6-nines&#x201d; availability, which translates to around thirty seconds of system downtime per year. In order to ensure high levels of customer satisfaction and retention, it is imperative that service providers adhere to the guaranteed level of service.</p>
<p id="p-0006" num="0005">Given the stringent requirements faced by service providers, equipment manufacturers strive to produce reliable hardware and software that minimize system downtime. However, because a typical service provider simultaneously operates thousands of pieces of equipment, hardware and software failure are inevitable. In an attempt to minimize the effect of such failures on service availability, service providers frequently utilize redundancy schemes, whereby a backup piece of equipment may be quickly activated upon failure of a primary piece of equipment.</p>
<p id="p-0007" num="0006">Service providers use several variations of a redundancy scheme, depending on cost restraints, availability requirements, and a number of other factors. In a 1+1 redundancy scheme, one piece of redundant equipment is provided for each piece of active equipment. This scheme maximizes reliability, such that the system may reliably handle failure of multiple devices at once. Alternatively, to allow for cost savings at the expense of reliability, a service provider may utilize one redundant device for each set of N active devices. A compromise between the 1+1 and 1:N redundancy scheme may be reached by utilizing N redundant devices for every M active devices, where N is less than M.</p>
<p id="p-0008" num="0007">Regardless of the redundancy scheme selected, the service provider must also determine whether to use hot redundancy, warm redundancy, or a combination thereof. In a hot redundant system, the redundant device maintains configuration data, equipment availability, and state information. Accordingly, in the event of failure of the active device, the redundant device is ready to immediately resume operation with no service outage. In contrast, a redundant device implementing warm redundancy stores configuration data and equipment availability, but does not store state information. Accordingly, upon failure of the active device, the warm redundant device may resume operation without having to boot-up, but must learn state information, thereby introducing a slight impact on the provided service.</p>
<p id="p-0009" num="0008">As is apparent from the above description, redundancy schemes are complex and require a significant amount of planning, configuration, and maintenance for successful implementation. With the ever-increasing complexity of network infrastructures, redundancy schemes are experiencing a corresponding increase in complexity. This increase in complexity is well-illustrated by the problem of providing redundancy for deep packet inspection (DPI) devices.</p>
<p id="p-0010" num="0009">DPI devices are increasingly deployed in telecommunications networks. These devices examine packets in a particular flow and identify an application associated with the flow. Using information about the application identified by the DPI device, service providers may, inter alia, increase the quality of service and more fairly bill customers based on their network usage. Thus, although DPI engines provide significant benefits to service providers, they also introduce significant expenses and complexities in high availability systems for which redundancy is required.</p>
<p id="p-0011" num="0010">Current redundancy schemes fail to minimize the costs associated with a high-availability scheme when DPI devices are used by the service provider. In particular, a conventional approach to high-availability mandates 1+1 hot redundancy, such that the service provider needs to purchase a backup DPI device for each primary DPI device and must modify its network such that both devices always process the entirety of the traffic to learn and maintain state information. This is very costly, given the complexity of DPI devices, especially given that, in many situations, only a subset of applications is important enough to require hot redundant support. Thus, current solutions fail to effectively provide redundancy for the DPI-based application engines in an efficient, cost-effective manner.</p>
<p id="p-0012" num="0011">Accordingly, there is a need for a redundancy scheme for DPI-based application engines that eliminates the need for 1+1 hot redundancy. In particular, there is a need for an M:N redundancy scheme, where N is less than or equal to M, that maximizes efficiency in providing redundancy by considering application information known by the DPI engine. Additionally, there is a need for a M:N redundancy scheme with a reduced complexity of implementation.</p>
<p id="p-0013" num="0012">The problems described above are illustrative of those that are addressed by the various exemplary embodiments and are not intended to be exhaustive or limiting of the possible problems addressed or solved. Furthermore, the foregoing objects and advantages of the invention are merely illustrative and are not intended to be exhaustive or limiting of the possible advantages that can be realized. Thus, these and other objects and advantages of the various exemplary embodiments will be apparent from the description herein or can be learned from practicing the various exemplary embodiments, both as embodied herein or as modified in view of any variation that may be apparent to those skilled in the art. Accordingly, the present invention resides in the novel methods, arrangements, combinations, and improvements herein shown and described in various exemplary embodiments.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0014" num="0013">In light of the present need for an efficient redundancy mechanism for DPI-based application engines, a brief summary of various exemplary embodiments is presented. Some simplifications and omissions maybe made in the following summary, which is intended to highlight and introduce some aspects of the various exemplary embodiments, but not to limit the scope of the invention. Detailed descriptions of a preferred exemplary embodiment adequate to allow those of ordinary skill in the art to make and use the inventive concepts will follow in later sections.</p>
<p id="p-0015" num="0014">Various exemplary embodiments rely on the application awareness of a DPI engine to more efficiently provide a redundancy scheme. In particular, by examining packets forwarded through a network device, a DPI engine identifies the application associated with each flow. Based on the identified application, the device determines whether to provide redundancy for the particular user and its flow and what type of redundancy to provide. For example, the device may provide hot redundancy only for high priority or long duration applications, such as video, telecommunications, and Voice Over Internet Protocol (VoIP). In contrast, the card may determine that it is not worth the additional expense to provide hot redundancy for short duration flows, such as email or web browsing.</p>
<p id="p-0016" num="0015">By efficiently implementing a redundancy scheme, various exemplary embodiments reduce costs and minimize complexity, while maintaining high performance. Furthermore, by providing hot redundancy based on application-level policies, various exemplary embodiments enable a service provider to not only reduce costs, but also to effectively provide a guaranteed quality of service or charge differently on a per-application basis, even in the event of hardware or software failure.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0017" num="0016">In order to better understand various exemplary embodiments, reference is made to the accompanying drawings, wherein:</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram of an exemplary system used to implement a redundancy scheme for DPI-based application engines;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic diagram of an exemplary card used in the system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a timing diagram illustrating the transition from an active DPI card to a protecting DPI card upon hardware or software failure;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart of a first exemplary embodiment of a method implementing a redundancy scheme on an active card;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart of a first exemplary embodiment of a method implementing a redundancy scheme on a protecting card;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> are flow charts of a second exemplary embodiment of a method implementing a redundancy scheme on an active card; and</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7</figref> is a flow chart of a second exemplary embodiment of a method implementing a redundancy scheme on a protecting card.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS OF THE INVENTION</heading>
<p id="p-0025" num="0024">Referring now to the drawings, in which like numerals refer to like components or steps, there are disclosed broad aspects of various exemplary embodiments.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram of an exemplary system <b>100</b> used to implement a redundancy scheme for DPI-based application engines. In various exemplary embodiments, system <b>100</b> includes first active card <b>110</b>, second active card <b>120</b>, Nth active card <b>130</b>, and protecting card <b>140</b>. It should be apparent that, although system <b>100</b> is illustrated as including three active cards <b>110</b>, <b>120</b>, <b>130</b>, system <b>100</b> may include N active cards, where N is a positive integer. Thus, system <b>100</b> implements a 1:N redundancy scheme.</p>
<p id="p-0027" num="0026">It should also be apparent that, although system <b>100</b> is illustrated using active and protecting cards, the cards may represent other devices including, but not limited to, DPI-capable processors on one or multiple cards, DPI-capable processing cores inside a single processor, DPI-based network elements such as standalone DPI devices, and similar devices that will be apparent to those of skill in the art. Thus, in the following description, it should be apparent that any of these devices may be substituted for the active and protecting cards.</p>
<p id="p-0028" num="0027">In various exemplary embodiments, active cards <b>110</b>, <b>120</b>, <b>130</b> are line cards used to receive, process, and forward data packets over one or more communication links. It should be apparent, however, that active cards <b>110</b>, <b>120</b>, <b>130</b> may be any network devices for which a redundancy scheme is desired. Thus, in various exemplary embodiments, each of the active cards <b>110</b>, <b>120</b>, <b>130</b> is an input-output module (IOM), media dependent adapter (MDA), or any other component for which redundancy is desirable. Each of the active cards <b>110</b>, <b>120</b>, <b>130</b> may be installed in a separate slot of a telecommunications switch or other piece of equipment. Active cards <b>110</b>, <b>120</b>, <b>130</b> each implement a redundancy scheme according to the processing described further below with reference to <figref idref="DRAWINGS">FIG. 4</figref> or <figref idref="DRAWINGS">FIGS. 6A and 6B</figref>.</p>
<p id="p-0029" num="0028">In various exemplary embodiments, protecting card <b>140</b> is an additional line card or telecommunication device used to support high availability of system <b>100</b>. In particular, protecting card <b>140</b> serves as a redundant or backup card such that protecting card <b>140</b> resumes packet processing and forwarding upon failure of one or more active cards <b>110</b>, <b>120</b>, <b>130</b>. Accordingly, protecting card <b>140</b> may implement a redundancy scheme according to the processing described further below with reference to <figref idref="DRAWINGS">FIG. 5</figref> or <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0030" num="0029">Although illustrated as implementing a 1:N redundancy scheme, it should be apparent that system <b>100</b> may include any number of active cards and any number of protecting cards. Thus, system <b>100</b> may implement an M:N redundancy scheme, where N is an integer less than or equal to M. For example, system <b>100</b> could include two protecting cards and four active cards, such that system <b>100</b> implements a 4:2 redundancy scheme. Other variations on the redundancy schemes described herein will be apparent to those of ordinary skill in the art.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic diagram of an exemplary card <b>200</b> used in system <b>100</b> of <figref idref="DRAWINGS">FIG. 1</figref>. In various exemplary embodiments, card <b>200</b> includes DPI processor <b>210</b>, redundancy block <b>220</b>, state information <b>230</b>, and application block <b>240</b>. It should be apparent that, for the purpose of simplicity, only the components used for providing redundancy functionality are illustrated as separate blocks and a 1 to 1 mapping is used from DPI processor <b>210</b> to the rest of the redundancy providing blocks <b>220</b>, <b>230</b>, <b>240</b>. It should therefore be apparent that card <b>200</b> may also include known components, such as an interface for receiving packets, an interface for forwarding packets, and one or more additional processors or storage media. Furthermore, some of the redundancy-providing components <b>220</b>, <b>230</b>, <b>240</b> may serve more than one DPI processor.</p>
<p id="p-0032" num="0031">In various exemplary embodiments, DPI processor <b>210</b> is a microprocessor or executable software configured to examine any combination of information in layers 2 through 7 of the Open Systems Interconnection (OSI) model. Thus, in various exemplary embodiments, DPI processor <b>210</b> performs a &#x201c;deep&#x201d; analysis of one or more packets in order to identify an application associated with the packets. For example, DPI processor <b>210</b> may analyze a packet to determine whether the packet relates to email, streaming video, web browsing, peer-to-peer transfer, VoIP, teleconferencing, or any other application of interest to the service provider. In various exemplary embodiments, the analysis performed by DPI processor <b>210</b> includes at least one of signature and pattern matching, stateful monitoring, behavioral analysis, and statistical analysis.</p>
<p id="p-0033" num="0032">In various exemplary embodiments, redundancy block <b>220</b> comprises hardware, software, or a combination thereof that executes the functionality required to implement redundancy in card <b>200</b>. Thus, redundancy block <b>220</b> may be a set of instructions encoded on a computer-readable storage medium and configured for execution by a processor. Alternatively, redundancy block <b>220</b> may comprise a processor, Field Programmable Gate Array (FPGA), or any other hardware mechanism that may be pre-configured to execute a set of instructions. Furthermore, redundancy block <b>220</b> may be configured to allow communication of information between active cards <b>110</b>, <b>120</b>, <b>130</b> and protecting card <b>140</b>.</p>
<p id="p-0034" num="0033">When card <b>200</b> corresponds to an active card <b>110</b>, <b>120</b>, <b>130</b>, redundancy block <b>220</b> may implement a redundancy scheme described further below with reference to <figref idref="DRAWINGS">FIG. 4</figref> or <figref idref="DRAWINGS">FIGS. 6A and 6B</figref>. In addition, redundancy block <b>220</b> may be configured to exchange messages with protecting card <b>140</b>, such that protecting card <b>140</b> is aware when failure has occurred on active card <b>110</b>, <b>120</b>, <b>130</b> and may resume operations of active card <b>110</b>, <b>120</b>, <b>130</b>. Conversely, when card <b>200</b> corresponds to protecting card <b>140</b>, redundancy block <b>220</b> may implement a redundancy scheme described further below with reference to <figref idref="DRAWINGS">FIG. 5</figref> or <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0035" num="0034">In various exemplary embodiments, state information <b>230</b> stores data regarding the flows currently managed by the particular card <b>200</b>. Accordingly, state information <b>230</b> may include data necessary to forward packets associated with a flow, including Internet Protocol (IP) 5-tuple information, application identifiers, policy information, user identification, etc. State information may also include application information identifying the application associated with each flow and application policy information. State information <b>230</b> may be stored on a computer-readable storage medium contained in or otherwise accessible to card <b>200</b>.</p>
<p id="p-0036" num="0035">When card <b>200</b> is an active card <b>110</b>, <b>120</b>, <b>130</b>, state information <b>230</b> may maintain data regarding all current flows. Alternatively, when card <b>200</b> corresponds to protecting card <b>140</b>, state information <b>230</b> may maintain data only for flows for which hot redundancy is desired, Thus, as described in further detail below, protecting card <b>140</b> may provide hot redundancy for select applications for multiple active cards <b>110</b>, <b>120</b>, <b>130</b>, while providing warm or no redundancy for all other applications. Upon failure of active card <b>110</b>, <b>120</b>, <b>130</b>, protecting card <b>140</b> may therefore immediately restore packet processing and forwarding for the selected applications.</p>
<p id="p-0037" num="0036">In various exemplary embodiments, application block <b>240</b> implements application-specific processing based on the application identified by DPI processor <b>210</b>. For example, application block <b>240</b> may mark packets based on a required Quality of Service, drop packets, collect statistics, and manage billing. Application block <b>240</b> maybe a set of instructions encoded on a computer-readable storage medium and configured for execution by a processor. Alternatively, application block <b>240</b> may comprise a processor, Field Programmable Gate Array (FPGA), or any other hardware mechanism that may be pre-configured to execute a set of instructions.</p>
<p id="p-0038" num="0037">It should be apparent that, although described above as distinct components, DPI processor <b>210</b>, redundancy block <b>220</b>, state information <b>230</b>, and application block <b>240</b> may be merged into fewer modules. Alternatively, the functions performed by one or more of the components <b>210</b>, <b>220</b>, <b>230</b>, <b>240</b> may be separated into multiple components, such that card <b>200</b> includes additional components. Alternative arrangements of the functionality of card <b>200</b> will be apparent to those of ordinary skill in the art.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 3</figref> is a timing diagram <b>300</b> illustrating the transition from an active DPI card <b>110</b>, <b>120</b>, <b>130</b> to a protecting DPI <b>140</b> card upon hardware or software failure. Timing diagram <b>300</b> includes a horizontal axis indicating time and a vertical axis indicating whether processing is performed on the active or protecting card.</p>
<p id="p-0040" num="0039">As shown in exemplary timing diagram <b>300</b>, an application flow <b>310</b> begins at time t<b>0</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> initiates processing. At time t<b>1</b>, the DPI engine contained in active card <b>110</b>, <b>120</b>, <b>130</b> performs processing to identify the application associated with the flow <b>310</b>.</p>
<p id="p-0041" num="0040">At time t<b>2</b>, failure occurs on active card <b>110</b>, <b>120</b>, <b>130</b>, and protecting card <b>140</b> takes over activity and resumes processing previously performed by the active card. Thus, at time t<b>2</b>, protecting card <b>140</b> retrieves state information regarding flow <b>310</b> from its state information block <b>230</b>, then begins forwarding traffic associated with each of the flows for which hot redundancy was provided. All other flows may bypass protecting card <b>140</b>, such that these flows are processed without application awareness.</p>
<p id="p-0042" num="0041">Alternatively, protecting card <b>140</b> may provide warm redundancy for the flows not supported by hot redundancy with an option to preempt the warm redundant flows upon congestion of the protecting card. In the event that multiple protecting cards fail at the same time, protecting card <b>140</b> may drop support of the warm redundant flows, thereby enabling protecting card <b>140</b> to provide hot redundancy for more than failed active card at the same time. For example, protecting card <b>140</b> may determine a priority for each warm redundant flow based on at least one of the flow duration, application type, and customer associated with the flow, then drop the lowest priority flows when necessary. Thus, in these situations, the protecting card always provides hot redundancy, while providing warm redundancy as a &#x201c;best-effort&#x201d; service pending resource availability on protecting card <b>140</b>.</p>
<p id="p-0043" num="0042">In either case, processing of flow <b>310</b> continues on protecting card <b>140</b> until flow <b>310</b> ends at time t<b>3</b> or until the functionality of active card <b>140</b> is restored.</p>
<p id="p-0044" num="0043">As should be apparent from the description above, in order to implement hot redundancy, protecting card <b>140</b> must be aware of the application associated with flow <b>310</b> at the time of failure. Accordingly, some mechanism is required to allow protecting card <b>140</b> to learn application information regarding flows for which hot redundancy is required for particular user. <figref idref="DRAWINGS">FIGS. 4-7</figref> illustrate several exemplary embodiments of methods used to enable protecting card <b>140</b> to discover the application associated with flow <b>310</b>.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart of a first exemplary embodiment of a method <b>400</b> implementing a redundancy scheme on an active card <b>110</b>, <b>120</b>, <b>130</b>. As described in further detail below, in this embodiment, active card <b>110</b>, <b>120</b>, <b>130</b> duplicates at least a portion of the received packets to protecting card <b>140</b>.</p>
<p id="p-0046" num="0045">Method <b>400</b> starts in step <b>410</b> and proceeds to step <b>420</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> receives information about applications. In particular, active card <b>110</b>, <b>120</b>, <b>130</b> receives information that maybe used to identify applications and an indication whether hot redundancy is required for the corresponding application. Active card <b>110</b>, <b>120</b>, <b>130</b> may receive this information directly via a user configuration process. For example, the user may access a software interface to specify the values or enter the values into a configuration file. Alternatively, active card <b>110</b>, <b>120</b>, <b>130</b> may receive the application information from a pre-configured file or hardware interface on the card. It should be apparent, however, that any method of specifying application information may be used, provided that active card <b>110</b>, <b>120</b>, <b>130</b> has access to this information.</p>
<p id="p-0047" num="0046">Furthermore, the information specified in step <b>410</b> may be specified based on the criticality of the particular application, the importance of user participating (e.g. whether the user is the source or destination of a packet), or the average duration of the flow for a particular type of application. For example, the service provider may specify that hot redundancy should be supported for video, VoIP, and teleconferencing, as these flows typically last longer than the Internet average of around thirty seconds, such that hot redundancy is particularly beneficial. In contrast, hot redundancy may not be desired for short duration flows such as email and web browsing, as it may be more efficient to allow the DPI to re-learn the state for those flows or treat them without recognizing the application until they complete. It should therefore be apparent that the information specifying hot-redundant applications is dynamic, advantageously allowing the service provider or other entity to support hot redundancy based on customized preferences.</p>
<p id="p-0048" num="0047">After receiving information about applications of interest in step <b>420</b>, exemplary method <b>400</b> proceeds to step <b>430</b>, where the active card <b>110</b>, <b>120</b>, <b>130</b> receives a packet associated with a flow. Exemplary method <b>400</b> then proceeds to decision step <b>440</b>, where the active card <b>110</b>, <b>120</b>, <b>130</b> determines whether the application associated with the flow has been identified.</p>
<p id="p-0049" num="0048">When, in decision step <b>440</b>, the active card <b>110</b>, <b>120</b>, <b>130</b> determines that the application is unknown, active card <b>110</b>, <b>120</b>, <b>130</b> is unaware whether hot redundancy will be required for the flow. Thus, method <b>400</b> proceeds to step <b>460</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> duplicates the packet to protecting card <b>140</b>, such that protecting card <b>140</b> will have information sufficient to identify the flow should hot redundancy be required.</p>
<p id="p-0050" num="0049">Alternatively, when, in decision step <b>440</b>, the active card <b>110</b>, <b>120</b>, <b>130</b> determines that the application is known, exemplary method <b>400</b> proceeds to decision step <b>450</b>, where it is determined whether hot redundancy is required for the particular application. This decision may be made by retrieving the information received in step <b>420</b> and determining whether hot redundancy is required for the application associated with the flow.</p>
<p id="p-0051" num="0050">When, in decision step <b>450</b>, it is determined that hot redundancy is required for the flow, exemplary method <b>400</b> proceeds to step <b>466</b>. In step <b>460</b>, active card <b>110</b>, <b>120</b>, <b>130</b> duplicates the packet to protecting card <b>140</b>. Accordingly, in various exemplary embodiments, step <b>460</b> enables protecting card <b>140</b> to remain hot redundant, as all packets of a hot redundant flow are also sent to protecting card <b>140</b>. Furthermore, because all packets are sent to protecting card <b>140</b>, hot redundancy may also be provided for statistical or billing purposes.</p>
<p id="p-0052" num="0051">As an alternative to duplicating all packets in step <b>460</b>, active card <b>110</b>, <b>120</b>, <b>130</b> may only duplicate enough packets to enable protecting card <b>140</b> to identify the application associated with the flow. Thus, in various exemplary embodiments, step <b>460</b> is only executed until protecting card <b>140</b> has enough information to establish state information, thereby allowing protecting card <b>140</b> to immediately resume processing in the event of failure on active card <b>110</b>, <b>120</b>, <b>130</b>.</p>
<p id="p-0053" num="0052">In contrast, when, in decision step <b>450</b>, it is determined that hot redundancy is not required for the application associated with the current flow, exemplary method <b>450</b> proceeds to optional step <b>470</b>. In step <b>470</b>, active card <b>110</b>, <b>120</b>, <b>130</b> sends an end of flow indicator to protecting card <b>140</b>. The end of flow indicator may be a packet or other message in a format known by protecting card <b>140</b>. As described further below with reference to <figref idref="DRAWINGS">FIG. 5</figref>, the end of flow indicator enables protecting card <b>140</b> to clear information regarding the current flow from its memory. It should be apparent that this step may be performed for only the first packet received after the application is identified, such that a clean-up operation is performed by protecting card <b>140</b> only once.</p>
<p id="p-0054" num="0053">After active-card <b>110</b>, <b>120</b>, <b>130</b> sends the duplicate packet in step <b>460</b> or an end of flow indicator in step <b>470</b>, exemplary method <b>400</b> proceeds to step <b>480</b>. In step <b>480</b>, active card <b>110</b>, <b>120</b>, <b>130</b> performs normal packet processing. In particular, active card <b>110</b>, <b>120</b>, <b>130</b> may identify the application associated with the flow using deep packet inspection, as described above with reference to DPI processor <b>210</b> of <figref idref="DRAWINGS">FIG. 2</figref>. In addition, active card <b>110</b>, <b>120</b>, <b>130</b> may select a forwarding policy based on the identified application, apply the policy, gather statistics, or perform any other operation. Other typical packet processing operations performed by active card <b>110</b>, <b>120</b>, <b>130</b> will be apparent to those of ordinary skill in the art. Exemplary method <b>400</b> then proceeds to step <b>490</b>, where exemplary method <b>400</b> stops.</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart of a first exemplary embodiment of a method <b>500</b> implementing a redundancy scheme on a protecting card <b>140</b>. In various exemplary embodiments, method <b>500</b> is executed in parallel on a protecting card <b>140</b> to process duplicate packets received from an active card <b>110</b>, <b>120</b>, <b>130</b> executing method <b>400</b>, described above with reference to <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0056" num="0055">Exemplary method <b>500</b> starts in step <b>510</b> and proceeds to step <b>520</b>, where protecting card <b>140</b> receives a duplicated packet from active card <b>110</b>, <b>120</b>, <b>130</b>. Exemplary method <b>500</b> then proceeds to decision step <b>530</b>, where protecting card <b>140</b> determines whether the application associated with the flow is known.</p>
<p id="p-0057" num="0056">When in decision step <b>530</b>, protecting card <b>140</b> determines that the application associated with the flow is known, exemplary method <b>500</b> proceeds to decision step <b>540</b>. In decision step <b>540</b>, protecting card <b>140</b> determines whether the packet received from the active card <b>110</b>, <b>120</b>, <b>130</b> is an end of flow indicator. When, in decision step <b>540</b>, it is determined that the packet indicates the end of a flow, exemplary method <b>500</b> proceeds to step <b>560</b>, where protecting card <b>140</b> performs a clean-up operation. More specifically, protecting card <b>140</b> may remove state information and any other information stored regarding the flow, thereby freeing up any memory used to provide redundancy for the flow. After performing the clean-up operation, exemplary method <b>500</b> proceeds to step <b>580</b>, where exemplary method <b>500</b> stops. Alternatively, when it is determined in decision step <b>540</b> that the packet is not an end of flow indicator, exemplary method <b>500</b> proceeds to step <b>570</b>, described in further detail below.</p>
<p id="p-0058" num="0057">Returning to decision step <b>530</b>, when it is determined that the application associated with the flow is not known, exemplary method <b>500</b> proceeds to step <b>550</b>. In step <b>550</b>, protecting card <b>140</b> performs processing necessary to establish state information for the flow. In particular, protecting card <b>140</b> may identify the flow using the packet's IP 5-tuple, which may include a source IP address, destination IP address, source port, destination port, and protocol. Protecting card <b>140</b> may also identify the application by performing DPI processing, described in further detail above with reference to DPI processor <b>210</b> of <figref idref="DRAWINGS">FIG. 2</figref>. In addition, protecting card <b>140</b> may select a policy based on current state information, collect statistics, or perform any other operations related to the state of the application flow. Exemplary method <b>500</b> then proceeds to step <b>570</b>.</p>
<p id="p-0059" num="0058">In step <b>570</b>, protecting card <b>140</b> continues normal processing of the packet. Thus, protecting card <b>140</b> may drop the packet, provide on-the-fly redundancy, or perform any other operations required to implement redundancy. Exemplary method <b>500</b> then proceeds to step <b>580</b>, where exemplary method <b>500</b> stops.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> are flow charts of a second exemplary embodiment of a method <b>600</b> implementing a redundancy scheme on an active card <b>110</b>, <b>120</b>, <b>130</b>. It should be apparent that method <b>600</b> may be executed by an active card <b>110</b>, <b>120</b>, <b>130</b> as an alternative to the processing of method <b>400</b>, described above with reference to <figref idref="DRAWINGS">FIG. 4</figref>. Thus, as described in further detail below, rather than duplicating entire packets, active card <b>110</b>, <b>120</b>, <b>130</b> sends messages containing updates regarding particular flows. It should be apparent that this method of redundancy may therefore reduce the bandwidth required between active cards <b>110</b>, <b>120</b>, <b>130</b> and protecting card <b>140</b>.</p>
<p id="p-0061" num="0060">As illustrated in <figref idref="DRAWINGS">FIG. 6A</figref>, exemplary method <b>600</b> starts in step <b>605</b> and proceeds to step <b>610</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> receives information about applications. In particular, active card <b>110</b>, <b>120</b>, <b>130</b> receives information that may be used to identify applications and an indication whether hot redundancy is required for the corresponding application. Active card <b>110</b>, <b>120</b>, <b>130</b> may receive this information directly via a user configuration process. For example, the user may run a software interface to specify the values or enter the values into a configuration file. Alternatively, active card <b>110</b>, <b>120</b>, <b>130</b> may receive the application information from a pre-configured file or hardware interface on the card. It should be apparent, however, that any method of specifying application information may be used, provided that active card <b>110</b>, <b>120</b>, <b>130</b> has access to this information.</p>
<p id="p-0062" num="0061">After receiving information about applications of interest in step <b>610</b>, exemplary method <b>600</b> proceeds to step <b>615</b>, where the active card <b>110</b>, <b>120</b>, <b>130</b> receives a packet associated with a flow. Exemplary method <b>600</b> then proceeds to decision step <b>620</b>, where the active card <b>110</b>, <b>120</b>, <b>130</b> determines whether the application associated with the flow is already known. This decision may be included for efficiency, as active card <b>110</b>, <b>120</b>, <b>130</b> may have already identified the application associated with the flow using packets that were previously received on active card <b>110</b>, <b>120</b>, <b>130</b>.</p>
<p id="p-0063" num="0062">When, in decision step <b>620</b>, it is determined that the application is known, exemplary method <b>600</b> proceeds to decision step <b>650</b>, described further below with reference to <figref idref="DRAWINGS">FIG. 6B</figref>. On the other hand, when it is determined in decision step <b>620</b> that the application is not yet known, exemplary method <b>600</b> proceeds to step <b>625</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> attempts to identify the application associated with the flow. Thus, active card <b>110</b>, <b>120</b>, <b>130</b> may perform DPI processing to identify the application, as described in further detail above with reference to DPI processor <b>210</b> of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0064" num="0063">Exemplary method <b>600</b> then proceeds to decision step <b>630</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> determines whether the application associated with the flow was successfully identified. When it is determined that the application has not been identified, exemplary method <b>600</b> proceeds to decision step <b>650</b>, described further below with reference to <figref idref="DRAWINGS">FIG. 6B</figref>.</p>
<p id="p-0065" num="0064">Alternatively, when it is determined in decision step <b>630</b> that the application has been identified, exemplary method <b>600</b> proceeds to step <b>635</b>. In step <b>635</b>, active card <b>110</b>, <b>120</b>, <b>130</b> establishes state information based on the processing performed in step <b>625</b>. In particular, active card <b>110</b>, <b>120</b>, <b>130</b> may identify the flow using the packet's IP 5-tuple, which may include a source IP address, destination IP address, source port, destination port, and protocol. Active card <b>110</b>, <b>120</b>, <b>130</b> may also generate an identifier for the application based on the DPI processing. In addition, active card <b>110</b>, <b>120</b>, <b>130</b> may select a policy based on current state information. Exemplary method <b>600</b> then proceeds to decision step <b>640</b>.</p>
<p id="p-0066" num="0065">In decision step <b>640</b>, active card <b>110</b>, <b>120</b>, <b>130</b> determines whether hot redundancy is required for the particular application associated with the flow. This decision may be made by accessing the information received in step <b>610</b> and determining whether hot redundancy is required for the particular application for the particular user. When, in decision step <b>640</b>, it is determined that hot redundancy is not required for the flow, exemplary method <b>600</b> proceeds to decision step <b>650</b>, described further below with reference to <figref idref="DRAWINGS">FIG. 6B</figref>.</p>
<p id="p-0067" num="0066">Alternatively, when it is determined in decision step <b>640</b> that hot redundancy is required, exemplary method <b>600</b> proceeds to step <b>645</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> propagates state information to protecting card <b>140</b>. In particular, active card <b>110</b>, <b>120</b>, <b>130</b> may use a message to send any combination of the state information established in step <b>635</b> to protecting card <b>140</b>. The protecting card <b>140</b> then processes the message in accordance with method <b>700</b>, described further below with reference to <figref idref="DRAWINGS">FIG. 7</figref>. Message formats suitable for sending state information from active card <b>110</b>, <b>120</b>, <b>130</b> to protecting card <b>140</b> will be apparent to those of skill in the art. After sending the message to protecting card <b>140</b>, exemplary method <b>600</b> proceeds to step <b>650</b>.</p>
<p id="p-0068" num="0067">Referring now to <figref idref="DRAWINGS">FIG. 6B</figref>, in decision step <b>650</b>, active card <b>110</b>, <b>120</b>, <b>130</b> determines whether the packet previously received in step <b>615</b> is the last packet in the flow. When, in decision step <b>650</b>, it is determined that the packet is the last packet in the flow, exemplary method <b>600</b> proceeds to step <b>655</b>, where active card <b>110</b>, <b>120</b>, <b>130</b> sends a last packet message to protecting card <b>140</b>. Again, message formats suitable for sending the last packet indication will be apparent to those of skill in the art. After sending the last packet message, exemplary method <b>600</b> proceeds to step <b>660</b>. Alternatively, when it is determined in decision step <b>650</b> that the packet is not the last packet in the flow, exemplary method <b>600</b> proceeds directly to step <b>660</b> without forwarding a last packet indication.</p>
<p id="p-0069" num="0068">In step <b>660</b>, active card <b>110</b>, <b>120</b>, <b>130</b> performs normal packet processing. In particular, active card <b>110</b>, <b>120</b>, <b>130</b> may select application-specific policies, gather statistics, drop or forward the packet, or perform any other operation. Other packet processing operations performed by active card <b>110</b>, <b>120</b>, <b>130</b> will be apparent to those of ordinary skill in the art. Exemplary method <b>600</b> then proceeds to step <b>665</b>, where exemplary method <b>600</b> stops.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 7</figref> is a flow chart of a second exemplary embodiment of a method <b>700</b> implementing a redundancy scheme on a protecting card <b>140</b>. It should be apparent that method <b>700</b> may be executed by a protecting card <b>140</b> as an alternative to the processing of method <b>500</b>, described above with reference to <figref idref="DRAWINGS">FIG. 5</figref>. In various exemplary embodiments, method <b>700</b> is executed in parallel on a protecting card <b>140</b> to process messages received from an active card <b>110</b>, <b>120</b>, <b>130</b> executing the processing of method <b>600</b>, described above with reference to <figref idref="DRAWINGS">FIGS. 6A and 6B</figref>.</p>
<p id="p-0071" num="0070">Exemplary method <b>700</b> starts in step <b>710</b> and proceeds to step <b>720</b>, where a protecting card <b>140</b> receives a message from the active card <b>110</b>, <b>120</b>, <b>130</b>. Exemplary method <b>700</b> then proceeds to decision step <b>730</b>, where protecting card <b>140</b> determines whether the message is a last packet indication.</p>
<p id="p-0072" num="0071">When, in decision step <b>730</b>, protecting card <b>140</b> determines that the message is a last packet indication, exemplary method <b>700</b> proceeds to step <b>740</b>, where protecting card <b>140</b> performs a clean-up operation. More specifically, protecting card <b>140</b> may remove state information and any other information stored regarding the flow, thereby freeing up any memory used to provide redundancy for the flow. Exemplary method <b>700</b> then proceeds to step <b>760</b>.</p>
<p id="p-0073" num="0072">Alternatively, when it is determined in decision step <b>730</b> that the message is not a last packet indication, protecting card <b>140</b> deduces that the message includes state information for a hot redundant flow. Accordingly, exemplary method <b>700</b> proceeds to step <b>750</b>, where protecting card <b>140</b> extracts and stores state information based on the content of the message received from active card <b>110</b>, <b>120</b>, <b>130</b>. In particular, protecting card <b>140</b> may extract flow-identifying information, such as an IP 5-tuple, or an application identifier. Protecting card <b>140</b> may also extract a policy for the flow from the message received from the active card <b>110</b>, <b>120</b>, <b>130</b>. Alternatively, protecting card <b>140</b> may itself derive a policy based on the state information included in the message. Exemplary method then proceeds to step <b>760</b>.</p>
<p id="p-0074" num="0073">In step <b>760</b>, protecting card <b>140</b> continues receiving messages from active card <b>110</b>, <b>120</b>, <b>130</b>. Exemplary method <b>700</b> then proceeds to step <b>770</b>, where exemplary method <b>700</b> stops.</p>
<p id="p-0075" num="0074">It should be apparent from the foregoing description of the redundancy schemes depicted in <figref idref="DRAWINGS">FIGS. 4-7</figref> that protecting card <b>140</b> may quickly resume operations upon failure of an active card <b>110</b>, <b>120</b>, <b>130</b>. In particular, active cards <b>110</b>, <b>120</b>, <b>130</b> and protecting card <b>140</b> interact to provide hot redundancy for selected applications. Accordingly, a fast transition occurs for flows associated with these applications when protecting card <b>140</b> detects failure of an active card <b>110</b>, <b>120</b>, <b>130</b>.</p>
<p id="p-0076" num="0075">Thus, according to the foregoing, various exemplary embodiments provide hot redundancy schemes for DPI engines that optimize efficiency using application information. By providing redundancy only for selected applications, various exemplary embodiments allow 1 for N or M for N hot redundancy, such that a single engine may protect multiple active engines. This scheme therefore enables a service provider to decrease costs, while still providing reliable, high availability services.</p>
<p id="p-0077" num="0076">Although the various exemplary embodiments have been described in detail with particular reference to certain exemplary aspects thereof, it should be understood that the invention is capable of other embodiments and its details are capable of modifications in various obvious respects. As is readily apparent to those skilled in the art, variations and modifications can be affected while remaining within the spirit and scope of the invention. Accordingly, the foregoing disclosure, description, and figures are for illustrative purposes only and do not in any way limit the invention, which is defined only by the claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A packet processing system for providing application-aware hot redundancy, the system comprising:
<claim-text>a plurality of active devices, each of the plurality of active devices comprising:
<claim-text>a receiving interface configured to receive a packet belonging to an active flow,</claim-text>
<claim-text>a processor configured to perform deep packet inspection to identify an application associated with the active flow,</claim-text>
<claim-text>a forwarding interface configured to forward the packet belonging to the active flow according to a forwarding policy, and</claim-text>
<claim-text>a redundancy block configured to determine whether the application requires hot redundancy and, if so, to transmit a message from which state information associated with the active flow may be derived; and</claim-text>
</claim-text>
<claim-text>at least one protecting device providing redundancy for the plurality of active devices, wherein the protecting device is in communication with each of the active devices and is configured to:
<claim-text>receive the message regarding the active flow from a respective active device of the plurality of active devices,</claim-text>
<claim-text>derive state information from the message, and</claim-text>
<claim-text>resume packet forwarding operations for the active flow using the state information upon failure of the respective active device.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The packet processing system for providing application-aware hot redundancy according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the message transmitted by the redundancy block of the respective active device is a duplicate of a packet belonging to the active flow.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The packet processing system for providing application-aware hot redundancy according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the message transmitted by the redundancy block of the active device includes state information predetermined by the redundancy block of the respective active device.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The packet processing system for providing application-aware hot redundancy according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the applications for which hot redundancy is required are specified by a service provider based on at least one of an average duration of flows associated with each application and a criticality of each application.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The packet processing system for providing application-aware hot redundancy according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the state information includes at least one of an Internet protocol 5-tuple, an application identifier, and application policy information.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A card for supporting application-aware hot redundancy in a packet processing system, the card comprising:
<claim-text>a receiving interface configured to receive an incoming packet belonging to an active flow;</claim-text>
<claim-text>a processor configured to perform deep packet inspection to identify an application associated with the active flow;</claim-text>
<claim-text>a forwarding interface configured to forward the incoming packet belonging to the active flow according to a forwarding policy; and</claim-text>
<claim-text>a redundancy block configured to:
<claim-text>determine whether the application requires hot redundancy and, if so, to transmit a message to a protecting device, the message including sufficient information from which state information associated with the active flow is derived by the protecting device, and</claim-text>
<claim-text>communicate with the protecting device, such that the protecting device resumes packet forwarding operations for the active flow using the state information upon failure of the card.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The card for supporting application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the message transmitted by the redundancy block is a duplicate of a packet belonging to the active flow.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The card for supporting application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the message transmitted by the redundancy block includes state information predetermined by the redundancy block.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The card for supporting application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the applications for which hot redundancy is required are specified by a service provider based on at least one of an average duration of flows associated with each application and a criticality of each application.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A method for providing application-aware hot redundancy in a packet processing system, the method comprising:
<claim-text>receiving redundancy information indicating applications for which hot redundancy is required;</claim-text>
<claim-text>receiving an incoming packet on an active device, the incoming packet belonging to an active flow;</claim-text>
<claim-text>performing deep packet inspection (DPI) to identify an application associated with the active flow;</claim-text>
<claim-text>determining whether hot redundancy is required for the active flow using the identified application and the redundancy information;</claim-text>
<claim-text>forwarding the incoming packet according to a forwarding policy; and</claim-text>
<claim-text>duplicating the incoming packet to a protecting device when it is determined that hot redundancy is required.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the step of duplicating the incoming packet is executed only when the protecting device requires additional information to identify the application associated with the active flow.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:
<claim-text>sending an end of flow indicator to the protecting device when it is determined that hot redundancy is not required for the active flow; and</claim-text>
<claim-text>in response to receipt of the end of flow indicator on the protecting device, performing a clean-up operation on the protecting device to remove information regarding the active flow from memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:
<claim-text>receiving the packet on the protecting device; and</claim-text>
<claim-text>establishing state information for the active flow on the protecting device when it is determined that the application associated with the active flow is not yet known.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising:
<claim-text>when the active device fails, utilizing the state information to resume packet forwarding operations for the active flow on the protecting device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:
<claim-text>providing warm redundancy on the protecting device as a best effort service when multiple active devices fail simultaneously, such that the protecting device provides hot redundancy for all flows that require hot redundancy.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising:
<claim-text>dropping warm redundant flows according to a priority associated with each flow, the priority for each flow determined by considering at least one of a duration of the flow, the application associated with the flow, and a customer associated with the flow.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A method for providing application-aware hot redundancy in a packet processing system, the method comprising:
<claim-text>receiving redundancy information indicating applications for which hot redundancy is to be provided;</claim-text>
<claim-text>receiving an incoming packet on an active device, the incoming packet belonging to an active flow;</claim-text>
<claim-text>performing deep packet inspection (DPI) to identify state information associated with the active flow, the state information identifying an application associated with the flow;</claim-text>
<claim-text>determining whether hot redundancy is required for the active flow using the identified application and the redundancy information;</claim-text>
<claim-text>transmitting a message to a protecting device when it is determined that hot redundancy is required, the message including the state information; and</claim-text>
<claim-text>forwarding the incoming packet according to a forwarding policy.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, the method further comprising:
<claim-text>transmitting a last packet indication to the protecting device when it is determined that the incoming packet is the last packet in the active flow; and</claim-text>
<claim-text>in response to receipt of the last packet indication on the protecting device, performing a clean-up operation on the protecting device to remove information regarding the active flow from memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, the method further comprising:
<claim-text>receiving the message on the protecting device;</claim-text>
<claim-text>extracting the state information from the message;</claim-text>
<claim-text>storing the state information on the protecting device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising:
<claim-text>when the active device fails, utilizing the state information to resume packet forwarding operations for the active flow on the protecting device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising:
<claim-text>providing warm redundancy on the protecting device as a best effort service when multiple active devices fail simultaneously, such that the protecting device provides hot redundancy for all flows that require hot redundancy.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method for providing application-aware hot redundancy in a packet processing system according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising:
<claim-text>dropping warm redundant flows according to a priority associated with each flow, the priority for each flow determined by considering at least one of a duration of the flow, the application associated with the flow, and a customer associated with the flow.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
