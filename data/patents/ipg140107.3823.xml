<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624890-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624890</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12375031</doc-number>
<date>20070726</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="regional">
<country>EP</country>
<doc-number>06118162</doc-number>
<date>20060731</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>952</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345419</main-classification>
<further-classification>345440</further-classification>
</classification-national>
<invention-title id="d2e71">Method, apparatus and computer-readable medium for creating a preset map for the visualization of an image dataset</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5305204</doc-number>
<kind>A</kind>
<name>Ohhashi</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382131</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5542003</doc-number>
<kind>A</kind>
<name>Wofford</name>
<date>19960700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6236751</doc-number>
<kind>B1</kind>
<name>Farrell</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6690371</doc-number>
<kind>B1</kind>
<name>Okerlund et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345424</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7277567</doc-number>
<kind>B2</kind>
<name>Miyamoto et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2003/0144589</doc-number>
<kind>A1</kind>
<name>Roell</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600410</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2003/0169254</doc-number>
<kind>A1</kind>
<name>Ditt et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2004/0017370</doc-number>
<kind>A1</kind>
<name>Miyamoto et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>EP</country>
<doc-number>0283255</doc-number>
<kind>A2</kind>
<date>19880900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>EP</country>
<doc-number>0409206</doc-number>
<kind>A2</kind>
<date>19910100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>63298279</doc-number>
<kind>A</kind>
<date>19881200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2004057411</doc-number>
<kind>A</kind>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>WO</country>
<doc-number>2005073921</doc-number>
<kind>A2</kind>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>WO</country>
<doc-number>2006048802</doc-number>
<kind>A2</kind>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Laszlo G. Nyul et al, On Standardizing the MR Image Intensity Scale, 1999, Magnetic Resonance in Medicine.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Nyul L G et al: &#x201c;On standardizing the MR image intensity scale&#x201d; Magnetic Resonance in Medicine, Wiley USA, vol. 42, No. 6, Dec. 1999, pp. 1072-1081, XP002505239 ISSN: 0740-3194.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Joe Kniss, et al; Multidimensional Transfer Functions for Interactive Volume Rendering, IEEE Transactions on Visualization and Computer Graphics, vol. 8, No. 3, Jul.-Sep. 2002, pp. 270-285.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Guy M Nicoletti; Optimal Generation of Transfer Functions for Direct Volume Rendering, 2003 IEEE, Proc. 35th Souteastern Symposium on System Theory, Mar. 2003, pp. 367-371.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>Guy M Nicoletti; Volume Visualization: Advances in Transfer and Opacity Function Generation for Interactive Direct Volume Rendering, 2004 IEEE, Proc. Thirty-Sixth Southeastern Symposium on System Theory, 2004, pp. 1-5.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>Jani AB, et al; Accuracy of Object Depiction and Opacity Transfer Function optimization in CT Volume-rendering images, J. Comput Assist Tomogr, May-Jun. 1998; 22(3):459-470.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>22</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345424</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090256838</doc-number>
<kind>A1</kind>
<date>20091015</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>De Bliek</last-name>
<first-name>Hubrecht Lambertus Tjalling</first-name>
<address>
<city>Eindhoven</city>
<country>NL</country>
</address>
</addressbook>
<residence>
<country>NL</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Visser</last-name>
<first-name>Cornelis Pieter</first-name>
<address>
<city>Eindhoven</city>
<country>NL</country>
</address>
</addressbook>
<residence>
<country>NL</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>De Bliek</last-name>
<first-name>Hubrecht Lambertus Tjalling</first-name>
<address>
<city>Eindhoven</city>
<country>NL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Visser</last-name>
<first-name>Cornelis Pieter</first-name>
<address>
<city>Eindhoven</city>
<country>NL</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Koninklijke Philips N.V.</orgname>
<role>03</role>
<address>
<city>Eindhoven</city>
<country>NL</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Xiao</last-name>
<first-name>Ke</first-name>
<department>2677</department>
</primary-examiner>
<assistant-examiner>
<last-name>Zhai</last-name>
<first-name>Kyle</first-name>
</assistant-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/IB2007/052970</doc-number>
<kind>00</kind>
<date>20070726</date>
</document-id>
<us-371c124-date>
<date>20090126</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2008/015620</doc-number>
<kind>A </kind>
<date>20080207</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method for creating a preset map for the visualization of an image dataset is provided. The method comprises dynamically adapting the preset map based on image dataset properties resulting in an adapted preset map. The method may be used for identifying the gray value similarity between the volume that the preset was created for and the volume to which the preset is supplied. This similarity measure is used to adapt the preset. As a result comparable 3D images, including structure and color, are created. An apparatus and a computer-readable medium are also provided.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="246.38mm" wi="185.59mm" file="US08624890-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="241.22mm" wi="150.88mm" file="US08624890-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="121.50mm" wi="161.80mm" file="US08624890-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="243.84mm" wi="182.88mm" file="US08624890-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="245.36mm" wi="191.60mm" file="US08624890-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="252.05mm" wi="178.22mm" file="US08624890-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="249.43mm" wi="175.60mm" file="US08624890-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">This invention pertains in general to the field of image analysis. More particularly the invention relates 3-D volume visualization for displaying structures present in a scanned volume, e.g. from Computed Tomography (CT), Magnetic Resonance Imaging (MRI) and Ultrasound Imaging (US).</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">3D volume visualization is an accepted technique to display structures present in a scanned volume, e.g. from CT, MRI or US. This visualization technique needs a color and an opacity map as input. The opacity map defines the structure to be visualized and the color map defines the coloring of the structure. Manual definition of the color and opacity map is not straightforward. To work around this problem presets are defined for the color and opacity maps. However, a preset is defined for a volume with specific voxel values. The result of a preset becomes invalid when applied to a volume containing a structure with different voxel values.</p>
<p id="p-0004" num="0003">In viewing applications 3D visualization techniques are used to view the content of the volume data. To create an appealing 3D visualization a color map and an opacity map are defined. However, it is not straightforward to create these maps. Often a user can choose from preset color and opacity maps instead of having to perform this laborious task.</p>
<p id="p-0005" num="0004">The Philips ViewForum workstation offers the possibility to create 3D visualizations from a volume scan (CT or MR). The user may create 3D visualizations with help of the so-called surface shaded direct volume rendering algorithm. With this rendering technique it is possible to create realistic images from the volume scan. Dependent upon the values present in the color and opacity maps different structures, present in the volume scan, may be visualized.</p>
<p id="p-0006" num="0005">On the Philips ViewForum workstation the user may choose from a wide range of defined presets for the color and opacity maps. These presets are created and tested on a limited number of volume scans and tuned to visualize certain structures.</p>
<p id="p-0007" num="0006">Currently the presets are static. This means that the contents of the color and opacity map are passed directly to the rendering algorithm. This means that when a preset is developed on a certain volume scan to visualize a certain structure, it is not guaranteed that this presets results in comparable 3D visualizations when supplied to other volume scans.</p>
<p id="p-0008" num="0007">Hence, an improved method, apparatus, and computer-readable medium would be advantageous, allowing for increased flexibility, cost-effectiveness, and visualization resolution.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">Accordingly, the present invention preferably seeks to mitigate, alleviate or eliminate one or more of the above-identified deficiencies in the art and disadvantages singly or in any combination and solves at least the above-mentioned problems by providing a method, apparatus and a computer-readable medium, according to the appended patent claims.</p>
<p id="p-0010" num="0009">According to one aspect of the invention, a method for creating a preset map for the visualization of an image dataset is provided. The method comprises dynamically adapting the preset map based on image dataset properties resulting in an adapted preset map.</p>
<p id="p-0011" num="0010">According to another aspect of the invention, an apparatus for creating a preset map for the visualization of an image dataset is provided. The apparatus comprises a unit for dynamically adapting the preset map based on image dataset properties resulting in an adapted preset map.</p>
<p id="p-0012" num="0011">According to yet another aspect of the invention, a computer-readable medium is provided. The computer-readable medium has embodied thereon a computer program for processing by a computer for creating a preset map for the visualization of an image dataset. The computer program comprises a code segment for dynamically adapting the preset map based on image dataset properties resulting in an adapted preset map.</p>
<p id="p-0013" num="0012">When using the method according to some embodiments 3D visualizations of the same structure, created from different volume scans will result in comparable images, in regards of color and transparency.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013">These and other aspects, features and advantages of which the invention is capable of will be apparent and elucidated from the following description of embodiments of the present invention, reference being made to the accompanying drawings, in which</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> is a flow chart showing a method according to an embodiment;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2</figref> is a chart showing a preset map according to an embodiment;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 3</figref> is an illustration showing a practical implementation of the method according to an embodiment;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic view of an apparatus according to an embodiment; and</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic view of a computer-readable medium according to an embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DESCRIPTION OF EMBODIMENTS</heading>
<p id="p-0020" num="0019">The present invention provides a method that may be used for identifying the gray value similarity between the volume that the preset was created for and the volume to which the preset is supplied. This similarity measure is used to tune the preset. As a result comparable 3D images, including structure and color, are created.</p>
<p id="p-0021" num="0020">The following description focuses on embodiments of the present invention applicable to applications that use visualization parameter presets for the display of volume rendered images (image datasets). Examples of the visualization parameter presets are the color map and the opacity map.</p>
<p id="p-0022" num="0021">The basic idea of the invention is to tune or adapt the preset values in a preset map corresponding to a first volume scan (3D or multi-dimensional image dataset) to the current specific volume scan before passing the preset values to a rendering algorithm for 3D visualization.</p>
<p id="p-0023" num="0022">In an embodiment method for creating a preset map for the visualization of an image dataset is provided. The preset map may e.g. be a color map or an opacity map. The method comprises dynamically adapting the preset map based on image dataset properties resulting in an adapted preset map.</p>
<p id="p-0024" num="0023">In an embodiment of the invention, according to <figref idref="DRAWINGS">FIG. 1</figref>, the dynamically adapting of the preset map comprises:</p>
<p id="p-0025" num="0024">retrieving 11 a first image dataset,</p>
<p id="p-0026" num="0025">retrieving 12 a preset map corresponding to the first image dataset,</p>
<p id="p-0027" num="0026">deriving 13 first image dataset properties from the first image dataset,</p>
<p id="p-0028" num="0027">storing 14 the first image dataset properties together with the preset map in a first preset map,</p>
<p id="p-0029" num="0028">retrieving 15 a second image dataset,</p>
<p id="p-0030" num="0029">retrieving 16 the first preset map,</p>
<p id="p-0031" num="0030">deriving 17 image dataset properties in the second image dataset corresponding to the image dataset properties of the first image dataset, and</p>
<p id="p-0032" num="0031">adapting 18 the first preset map, based on the first image dataset properties and second image dataset properties, creating an adapted preset map.</p>
<p id="p-0033" num="0032">This embodiment may be used for each new (second, third, etc.) image dataset that is to be analyzed describing a similar structure to that of the first image dataset. The great advantage of this embodiment is that the preset map for the new image dataset will be adapted based on image dataset properties from the preset map but adapted for the image dataset properties in the new image dataset and thus the result of the eventual 3D visualization will be greatly improved.</p>
<p id="p-0034" num="0033">In an embodiment the method further comprises rendering 19 a 3D visualization based on the adapted preset map to be showed on a display.</p>
<p id="p-0035" num="0034">In an embodiment the image dataset properties may be the position of local maxima/minima present in the histogram of the image dataset. Using the method according to an embodiment it is thus possible to compare image datasets and utilize the difference between similar positions of the first image dataset and the new image dataset to modify the preset map.</p>
<p id="p-0036" num="0035">In an embodiment the image dataset properties may be the positions of slope angles present in the histogram of the image dataset. A slope angle is the angle the graph makes with respect to the histogram's horizontal axis (e.g. the position of the maximum slope angle). The minimum/maximum graph value positions and e.g. the positions of the minimum/maximum slope angles may be used to describe the histogram.</p>
<p id="p-0037" num="0036">In an embodiment the image dataset properties may be and a combination of position of local maxima/minima and position of slope angles.</p>
<p id="p-0038" num="0037">In an embodiment the image dataset properties may be the first derivative of an interpolated histogram of the image dataset.</p>
<p id="p-0039" num="0038">The image dataset properties may be derived from the entire image dataset or from a defined volume of interest comprised in the image dataset or from a structure in the image dataset.</p>
<p id="p-0040" num="0039">In an embodiment the preset maps are defined for a color or opacity map.</p>
<p id="p-0041" num="0040">In an embodiment of the invention the image dataset is 3D or higher-dimensional image dataset describing one or more volume scans, e.g. created by Computed Tomography, Magnetic Resonance Imaging or Ultrasound Imaging.</p>
<p id="p-0042" num="0041">There are several ways of determining whether the new image dataset comprises similar structures to that of the first image dataset. The method according to some embodiments functions satisfactory when there is a correlation between the first image dataset for which first image dataset parameters are derived and the new image dataset for which corresponding image parameters are derived. Different Computer Vision and Image Analysis techniques may be used to correlate structures located in the first image dataset to structures in the new image dataset. A commonly known technique to identify a structure in an image dataset is segmentation that may be performed on the first and new image datasets. Comparing the similarity between histograms of segmented structures is much easier then comparing histograms of entire volumes. If the segmentation is performed manually the person segmenting the structure must ensure that the structure is segmented correctly. In many cases the segmentation may be performed automatically, e.g. by a computer program.</p>
<p id="p-0043" num="0042">The parameters of the preset map may be different for the type of visual presentation. In an embodiment, according to <figref idref="DRAWINGS">FIG. 2</figref>, the parameters of the preset map, first preset map, and adapted preset map are Level and Width. These parameters describe the global properties of the preset map. <figref idref="DRAWINGS">FIG. 2</figref> illustrates an opacity map containing the following values (0.0, 0.2), (100.0, 0.2), (200.0, 0.5), (300.0, 1.0), (500.0, 1.0). Width is defined as the difference between the last and the first changing map values with reference to the y-axis. Thus the Width of this opacity map equals 300.0&#x2212;100.0=200.0. The Level is defined as the center position between the first and the last changing preset map values. Accordingly the Level is positioned at 200.0 for the given opacity map. The Level and Width values may also be used to position and scale the entire preset map, meaning that if the adapted Level value calculated from the new image dataset (histogram) turns out to be 100.0 then the entire map will shift 100 to the left. If the Width value changes then the map values will be stretched or shrunk (scaled) in the direction of x-axis. It should be noted that this is a specific embodiment in which the found histogram properties are applied to the entire map. In other embodiments it is naturally also possible to apply the found image dataset (histogram) properties more local to the preset map, i.e. local scale at multiple found image dataset (histogram) positions, instead of global scale. This means that several Level and Width location based parameters may be used in the preset map for different locations found in the histogram of the image dataset.</p>
<p id="p-0044" num="0043">The adapted preset map(s) may be created with the purpose to visualize a certain structure present in the image dataset. From the image dataset, properties of this structure are derived and stored together with the preset map using the method according to an embodiment. By using the method according to some embodiments 3D visualizations of the same structure, created from different image datasets will result in comparable images, in regards of color and transparency.</p>
<p id="p-0045" num="0044">In an embodiment the first preset map is only calculated once and may be applied to several new image datasets. In this way steps <b>11</b>-<b>14</b> is performed once, and <b>15</b>-<b>18</b> and optionally step <b>19</b> are performed for each of the new image datasets.</p>
<p id="p-0046" num="0045">In an embodiment, according to <figref idref="DRAWINGS">FIG. 3</figref>, the method according to an embodiment is practically implemented for the visualization of a heart present in an MRI image dataset. The heart consists of two distinguishable structures, namely soft tissue and blood pool. Thus in this embodiment the properties derived from the image datasets are the gray value locations of these structures in histograms of the image datasets. Prior to deriving these image dataset properties the image dataset of the heart may be segmented. In <figref idref="DRAWINGS">FIG. 3</figref><i>a </i>three histograms A, B, C from three different image datasets, e.g. originating from different hospitals, illustrate the two distinguishable parts of the heart. In these histograms the two peaks P<b>1</b>, P<b>1</b>&#x2032;, P<b>1</b>&#x2033; and P<b>2</b>, P<b>2</b>&#x2032;, P<b>2</b>&#x2033;, respectively represent the two distinguishable structures. Using the method according to some embodiments the first preset map is created based on the first histogram presented in <figref idref="DRAWINGS">FIG. 3</figref><i>a </i>and the first image dataset properties, e.g. the two peak values P<b>1</b> and P<b>2</b>. When this first preset map is applied to the other two image datasets then the first preset map may be adapted in the following manner. Firstly, the first preset map comprising the preset map and the image dataset properties, peak values P<b>1</b> and P<b>2</b>, is retrieved (step <b>12</b> in <figref idref="DRAWINGS">FIG. 1</figref>). Then (step <b>13</b> in <figref idref="DRAWINGS">FIG. 1</figref>) the intensity level <b>311</b> and width <b>312</b> for the preset map are determined, as well as new peak values P<b>1</b>&#x2032; and P<b>2</b>&#x2032; for the new image dataset, and moreover new intensity level values (Level&#x2032;) <b>321</b>, <b>331</b> and width values (Width&#x2032;) <b>322</b>, <b>332</b> are calculated, e.g. by using the following equations which does not require great computation capacity:</p>
<p id="p-0047" num="0046">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
  <mrow>
    <mrow>
      <msup>
        <mi>Level</mi>
        <mi>&#x2032;</mi>
      </msup>
      <mo>=</mo>
      <mrow>
        <mrow>
          <mi>P</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <msup>
            <mn>1</mn>
            <mi>&#x2032;</mi>
          </msup>
        </mrow>
        <mo>+</mo>
        <mrow>
          <mfrac>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>Level</mi>
                <mo>-</mo>
                <mrow>
                  <mi>P</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <mn>1</mn>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <mi>P</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <mn>2</mn>
                </mrow>
                <mo>-</mo>
                <mrow>
                  <mi>P</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <mn>1</mn>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mfrac>
          <mo>*</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <mi>P</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msup>
                  <mn>2</mn>
                  <mi>&#x2032;</mi>
                </msup>
              </mrow>
              <mo>-</mo>
              <mrow>
                <mi>P</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msup>
                  <mn>1</mn>
                  <mi>&#x2032;</mi>
                </msup>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mrow>
    <mo>,</mo>
    <mstyle>
      <mtext>
</mtext>
    </mstyle>
    <mo>&#x2062;</mo>
    <mi>and</mi>
  </mrow>
</math>
</maths>
<maths id="MATH-US-00001-2" num="00001.2">
<math overflow="scroll">
  <mrow>
    <msup>
      <mi>Width</mi>
      <mi>&#x2032;</mi>
    </msup>
    <mo>=</mo>
    <mrow>
      <mfrac>
        <mi>Width</mi>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mrow>
              <mi>P</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <mn>2</mn>
            </mrow>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>-</mo>
            <mrow>
              <mi>P</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <mn>1</mn>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mfrac>
      <mo>*</mo>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mrow>
            <mi>P</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <msup>
              <mn>2</mn>
              <mi>&#x2032;</mi>
            </msup>
          </mrow>
          <mo>-</mo>
          <mrow>
            <mi>P</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <msup>
              <mn>1</mn>
              <mi>&#x2032;</mi>
            </msup>
          </mrow>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mrow>
  </mrow>
</math>
</maths>
</p>
<p id="p-0048" num="0047">The last step, namely the adapting step <b>23</b>, illustrated by <figref idref="DRAWINGS">FIG. 3</figref><i>b</i>, involves creating the adapted preset <b>34</b> map by aligning (see <figref idref="DRAWINGS">FIG. 2</figref>) the first preset map to the new image dataset by means of the new Level&#x2032; values <b>321</b>, <b>331</b> and Width&#x2032; values <b>322</b>, <b>332</b>. As the method in this embodiment utilizes the histograms of the image datasets the resulting adapted preset map may be referred to as a histogram driven preset. It should be noted that the preset map <b>31</b>, i.e. original preset map without image properties included, applied to histogram C in <figref idref="DRAWINGS">FIG. 3</figref><i>b</i>, which would be the approach according to prior art, might result in an almost empty 3D image. This illustrates the great advantage of some embodiments of the invention over prior art.</p>
<p id="p-0049" num="0048">The present invention provides a method that identifies image dataset properties for a first image dataset to create a first preset map comprising the preset map and the first image dataset properties. Furthermore the present invention provides a way to adapt the first preset map to a new image dataset to improve 3D visualization.</p>
<p id="p-0050" num="0049">In an embodiment an apparatus (<b>40</b>) for creating a preset map for the visualization of an image dataset is provided. The apparatus comprises a unit for dynamically adapting the preset map based on image dataset properties resulting in an adapted preset map.</p>
<p id="p-0051" num="0050">In an embodiment, according to <figref idref="DRAWINGS">FIG. 4</figref>, the unit for dynamically adapting of the apparatus (<b>40</b>) further comprises a first retrieving unit <b>41</b> for retrieving a first image dataset and a second retrieving unit <b>42</b> for retrieving the preset map. Moreover the apparatus comprises a first deriving unit <b>43</b> for deriving first image dataset properties from the first image dataset, and a storing unit <b>44</b> for storing the first image dataset properties together with the preset map in a first preset map. The apparatus further comprises a third retrieving unit <b>45</b> for retrieving a new image dataset, and a fourth retrieving unit <b>46</b> for retrieving the first preset map. Moreover the apparatus comprises a second deriving unit <b>47</b> for deriving second image dataset properties from the first image dataset, and an adapting unit <b>48</b> for adapting the first preset map, based on first image dataset properties and second image dataset properties, creating an adapted preset map.</p>
<p id="p-0052" num="0051">In an embodiment the first, second, third and fourth retrieving unit is integrated into only one retrieving unit.</p>
<p id="p-0053" num="0052">In an embodiment the first and second deriving unit is integrated into only one deriving unit.</p>
<p id="p-0054" num="0053">In an embodiment of the invention the apparatus <b>40</b> further comprises a render unit <b>491</b> for rendering a 3D visualization of the second image dataset based on the adapted preset map.</p>
<p id="p-0055" num="0054">In an embodiment the apparatus further comprises a display unit <b>492</b> for displaying the rendered 3D visualization to a user.</p>
<p id="p-0056" num="0055">The retrieving unit(s), deriving unit(s), storing unit, optimization unit, and render unit may be any unit normally used for such tasks, e.g. a hardware, such as a processor with a memory. The processor could be any of variety of processors, such as Intel or AMD processors, CPUs, microprocessors, Programmable Intelligent Computer (PIC) microcontrollers, Digital Signal Processors (DSP), etc. However, the scope of the invention is not limited to these specific processors. The memory may be any memory capable of storing information, such as Random Access Memories (RAM) such as, Double Density RAM (DDR, DDR2), Single Density RAM (SDRAM), Static RAM (SRAM), Dynamic RAM (DRAM), Video RAM (VRAM), etc. The memory may also be a FLASH memory such as a USB, Compact Flash, SmartMedia, MMC memory, MemoryStick, SD Card, MiniSD, MicroSD, xD Card, TransFlash, and MicroDrive memory etc. However, the scope of the invention is not limited to these specific memories.</p>
<p id="p-0057" num="0056">In an embodiment the apparatus <b>40</b> is comprised in a medical workstation or medical system, such as a Computed Tomography (CT) system, Magnetic Resonance Imaging (MRI) System or Ultrasound Imaging (US) system.</p>
<p id="p-0058" num="0057">In an embodiment a computer-readable medium (<b>50</b>) having embodied thereon a computer program for processing by a computer for creating a preset map for the visualization of an image dataset is provided. The computer program comprises a code segment for dynamically adapting the preset map based on image dataset properties resulting in an adapted preset map.</p>
<p id="p-0059" num="0058">In an embodiment, according to <figref idref="DRAWINGS">FIG. 5</figref>, the code segment further comprises code segments for performing the method according to some embodiments. The computer program comprises a first retrieving code segment <b>51</b> for retrieving the first image dataset. Furthermore the computer program comprises a second retrieving code segment <b>52</b> for retrieving the preset map. Moreover the computer program comprises a first deriving code segment <b>53</b> for deriving first image dataset properties from the first image dataset, and a storing code segment <b>54</b> for storing the first image dataset properties together with the preset map in a first preset map. The computer program has furthermore a third retrieving code segment <b>55</b> for retrieving a new image dataset and a fourth retrieving code segment <b>56</b> for retrieving the first preset map. Moreover the computer program comprises a second deriving code segment <b>57</b> for deriving second image dataset properties from the first image dataset, and an optimization code segment <b>58</b> for adapting the first preset map, based on first image dataset properties and second image dataset properties, creating an adapted preset map. In an embodiment the computer program further comprises a render code segment <b>591</b> for rendering a 3D visualization of the second image dataset based on the adapted preset map. This 3D visualization maybe created with help of a shaded volume render algorithm or any other algorithm that uses a preset map to help visualize structures of interest.</p>
<p id="p-0060" num="0059">In an embodiment the computer program further comprises a display code segment <b>592</b> for displaying the rendered 3D visualization to a user. The user may select a preset from a preset list comprising several presets. This preset list may already display small versions of the presets when applied to the new image dataset.</p>
<p id="p-0061" num="0060">In another embodiment the computer-readable medium comprises code segments arranged, when run by an apparatus having computer processing properties, for performing all of the method steps defined in any one of the embodiments.</p>
<p id="p-0062" num="0061">Applications and use of the above-described embodiments according to the invention are various and include all exemplary fields that may benefit from using preset maps with image dataset properties to individualize 3D visualization for image datasets comprising the same structure of interest.</p>
<p id="p-0063" num="0062">The invention may be implemented in any suitable form including hardware, software, firmware or any combination of these. However, preferably, the invention is implemented as computer software running on one or more data processors and/or digital signal processors. The elements and components of an embodiment of the invention may be physically, functionally and logically implemented in any suitable way. Indeed, the functionality may be implemented in a single unit, in a plurality of units or as part of other functional units. As such, the invention may be implemented in a single unit, or may be physically and functionally distributed between different units and processors.</p>
<p id="p-0064" num="0063">Although the present invention has been described above with reference to specific embodiments, it is not intended to be limited to the specific form set forth herein. Rather, the invention is limited only by the accompanying claims and, other embodiments than the specific above are equally possible within the scope of these appended claims. In the claims, the term &#x201c;comprises/comprising&#x201d; does not exclude the presence of other elements or steps. Furthermore, although individually listed, a plurality of means, elements or method steps may be implemented by e.g. a single unit or processor. Additionally, although individual features may be included in different claims, these may possibly advantageously be combined, and the inclusion in different claims does not imply that a combination of features is not feasible and/or advantageous. In addition, singular references do not exclude a plurality. The terms &#x201c;a&#x201d;, &#x201c;an&#x201d;, &#x201c;first&#x201d;, &#x201c;second&#x201d; etc do not preclude a plurality. Reference signs in the claims are provided merely as a clarifying example and shall not be construed as limiting the scope of the claims in any way.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001 MATH-US-00001-2" nb-file="US08624890-20140107-M00001.NB">
<img id="EMI-M00001" he="17.27mm" wi="76.20mm" file="US08624890-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002 MATH-US-00002-2" nb-file="US08624890-20140107-M00002.NB">
<img id="EMI-M00002" he="17.27mm" wi="76.20mm" file="US08624890-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for creating a preset map for visualization of an image dataset, comprising:
<claim-text>dynamically adapting, by a processor, said preset map based on image dataset properties resulting in an adapted preset map, the dynamically adapting comprising the steps of:
<claim-text>(i) retrieving a first image dataset,</claim-text>
<claim-text>(ii) retrieving said preset map corresponding to said first image dataset,</claim-text>
<claim-text>(iii) deriving a first set of image dataset properties from said first image dataset, and</claim-text>
<claim-text>(iv) storing said first set of image dataset properties together with said preset map in a first preset map</claim-text>
</claim-text>
<claim-text>retrieving, by the processor, said first preset map,</claim-text>
<claim-text>retrieving, by the processor, a second image dataset,</claim-text>
<claim-text>deriving, by the processor, a second set of image dataset properties, corresponding to said first set of image dataset properties in said first image dataset, from said second image dataset, and</claim-text>
<claim-text>adapting, by the processor, said first preset map, based on said first set of image dataset properties and said second set of image dataset properties, resulting in said adapted preset map for said second image dataset.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said preset map is defined for a color map or opacity map.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image dataset is a 2D, 3D or higher dimensional medical image dataset.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said first or second image dataset properties are position of local maxima/minima within said first or second image dataset.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said first or second image dataset properties are positions of slope angles within said first or second image dataset.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said first or second image dataset properties are a combination of position of local maxima/minima and positions of slope angles within said first or second image dataset.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising deriving said first set of image parameters and said second set of image parameters from the entire first image dataset and second image dataset, respectively, or from a defined volume of interest comprised in said first image dataset and said second image dataset, respectively.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A method according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein said deriving first image dataset parameters comprises: determining at least two first peak values P<b>1</b> and P<b>2</b> in said first image dataset, determining an intensity level value (Level) and a width value (Width) for said preset map, and said deriving second image dataset parameters comprises: determining at least two second peak values P<b>1</b>&#x2032; and P<b>2</b>&#x2032; in said second image dataset, and calculating a second intensity level value (Level&#x2032;) and a second width value (Width&#x2032;).</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said calculating comprises solving the equations:</claim-text>
<claim-text>
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
  <mrow>
    <mrow>
      <msup>
        <mi>Level</mi>
        <mi>&#x2032;</mi>
      </msup>
      <mo>=</mo>
      <mrow>
        <mrow>
          <mi>P</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <msup>
            <mn>1</mn>
            <mi>&#x2032;</mi>
          </msup>
        </mrow>
        <mo>+</mo>
        <mrow>
          <mfrac>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>Level</mi>
                <mo>-</mo>
                <mrow>
                  <mi>P</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <mn>1</mn>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <mi>P</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <mn>2</mn>
                </mrow>
                <mo>-</mo>
                <mrow>
                  <mi>P</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <mn>1</mn>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mfrac>
          <mo>*</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <mi>P</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msup>
                  <mn>2</mn>
                  <mi>&#x2032;</mi>
                </msup>
              </mrow>
              <mo>-</mo>
              <mrow>
                <mi>P</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msup>
                  <mn>1</mn>
                  <mi>&#x2032;</mi>
                </msup>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mrow>
    <mo>,</mo>
    <mstyle>
      <mtext>
</mtext>
    </mstyle>
    <mo>&#x2062;</mo>
    <mi>and</mi>
  </mrow>
</math>
</maths>
<maths id="MATH-US-00002-2" num="00002.2">
<math overflow="scroll">
  <mrow>
    <msup>
      <mi>Width</mi>
      <mi>&#x2032;</mi>
    </msup>
    <mo>=</mo>
    <mrow>
      <mfrac>
        <mi>Width</mi>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mrow>
              <mi>P</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <mn>2</mn>
            </mrow>
            <mo>-</mo>
            <mrow>
              <mi>P</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <mn>1</mn>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mfrac>
      <mo>*</mo>
      <mrow>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mrow>
              <mi>P</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msup>
                <mn>2</mn>
                <mi>&#x2032;</mi>
              </msup>
            </mrow>
            <mo>-</mo>
            <mrow>
              <mi>P</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msup>
                <mn>1</mn>
                <mi>&#x2032;</mi>
              </msup>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mo>.</mo>
      </mrow>
    </mrow>
  </mrow>
</math>
</maths>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said adapting said first preset map comprises aligning said first preset map to said second image dataset by means of said second intensity level value (Level&#x2032;) and width value (Width&#x2032;).</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising rendering said second image dataset based on said adapted preset map for 3D visualization.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image dataset properties are gray value locations of a structure in a histogram of said second image dataset.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. An apparatus for creating a preset map for visualization of an image dataset, comprising:
<claim-text>a hardware unit for dynamically adapting said preset map based on image dataset properties resulting in an adapted preset map, the unit comprising:
<claim-text>(i) a first retrieving unit for retrieving a first image dataset,</claim-text>
<claim-text>(ii) a second retrieving unit for retrieving a preset map corresponding to said first image dataset,</claim-text>
<claim-text>(iii) a first deriving unit for deriving a first set of image dataset properties from said first image dataset, and</claim-text>
<claim-text>(iv) a storing unit for storing said first set of image dataset properties together with said preset map in a first preset map</claim-text>
</claim-text>
<claim-text>a third retrieving hardware unit for retrieving said first preset map,</claim-text>
<claim-text>a fourth retrieving hardware unit for retrieving a second image dataset,</claim-text>
<claim-text>a second deriving hardware unit for deriving a second set of image dataset properties, corresponding to said first set of image dataset properties in said first image dataset, from said second image dataset, and</claim-text>
<claim-text>an adapting hardware unit for adapting said first preset map, based on said first set of image dataset properties and said second set of image dataset properties, resulting in an adapted preset map for said second image dataset.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein said first. second, third, and fourth retrieving hardware units are integrated into one retrieving unit.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein said first and second deriving units are integrated.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising a render unit for rendering a 3D visualization of said second image dataset based on said adapted preset map.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising a display unit for displaying said rendered 3D visualization to a user.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein said apparatus is comprised in a medical workstation.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A non-transitory computer-readable medium having embodied thereon a computer program for processing by a computer for creating a preset map for visualization of an image dataset, said computer program comprising a code segment for:
<claim-text>dynamically adapting said preset map based on image dataset properties resulting in an adapted preset map;</claim-text>
<claim-text>a first retrieving code segment for retrieving a first image dataset;</claim-text>
<claim-text>a second retrieving code segment for retrieving a preset map corresponding to said first image dataset;</claim-text>
<claim-text>a first deriving code segment for deriving a first set of image dataset properties from said first image dataset;</claim-text>
<claim-text>a storing code segment for storing said first set of image dataset properties together with said preset map in a first preset map;</claim-text>
<claim-text>a third retrieving code segment for retrieving said first preset map;</claim-text>
<claim-text>a fourth retrieving code segment for retrieving a second image dataset;</claim-text>
<claim-text>a second deriving code segment for deriving a second set of image dataset properties, corresponding to said first set of image dataset properties in said first image dataset, from said second image dataset; and</claim-text>
<claim-text>an adapting code segment for adapting said first preset map, based on said first set of image dataset properties and said second set of image dataset properties, resulting in creating an adapted preset map for said second image dataset.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the computer program further comprises a render code segment for rendering a 3D visualization of the second image dataset based on the adapted preset map.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising a display code segment for displaying the rendered 3D visualization to a user.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00019">claim 19</claim-ref> comprising code segments executable by a processor for performing a method for creating a preset map for visualization of an image dataset, said method comprising dynamically adapting said preset map based on image dataset properties resulting in an adapted preset map. </claim-text>
</claim>
</claims>
</us-patent-grant>
