<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627358-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627358</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12856906</doc-number>
<date>20100816</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>157</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>62</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>10</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>025</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>445</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>13</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>725 35</main-classification>
<further-classification>725 32</further-classification>
<further-classification>725 34</further-classification>
<further-classification>725 60</further-classification>
<further-classification>725 61</further-classification>
<further-classification>382100</further-classification>
<further-classification>382224</further-classification>
</classification-national>
<invention-title id="d2e53">Location-based movie identification systems and methods</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2003/0095681</doc-number>
<kind>A1</kind>
<name>Burg et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2008/0015983</doc-number>
<kind>A1</kind>
<name>Spikes</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 40</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2008/0271072</doc-number>
<kind>A1</kind>
<name>Rothschild et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 35</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2009/0112815</doc-number>
<kind>A1</kind>
<name>Antognini et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2009/0320070</doc-number>
<kind>A1</kind>
<name>Inoguchi</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 40</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2010/0241514</doc-number>
<kind>A1</kind>
<name>Ofek et al.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 1458</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2011/0255738</doc-number>
<kind>A1</kind>
<name>Gao et al.</name>
<date>20111000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382103</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00008">
<othercit>Image Analysis, http://en.wikipedia.orgiwiki/Image<sub>&#x2014;</sub>analysis, Aug. 17, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>9</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>725 35</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kessenger</last-name>
<first-name>Erika Nelson</first-name>
<address>
<city>Denver</city>
<state>CO</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Pollock</last-name>
<first-name>Bruce</first-name>
<address>
<city>Omaha</city>
<state>NE</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kessenger</last-name>
<first-name>Erika Nelson</first-name>
<address>
<city>Denver</city>
<state>CO</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Pollock</last-name>
<first-name>Bruce</first-name>
<address>
<city>Omaha</city>
<state>NE</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>West Corporation</orgname>
<role>02</role>
<address>
<city>Omaha</city>
<state>NE</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Shepard</last-name>
<first-name>Justin</first-name>
<department>2424</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The illustrative embodiments described herein provide systems and methods for movie identification based on a location. In the embodiment, a method includes locating a mobile communication device associated with a user to form location data, accessing a location database to determine a geographic location of the mobile communication device based on the location data, and identifying a set of movies related to the geographic location by accessing a movie database. Each of the set of movies in the movie database is associated with one or more respective geographic locations. The method also includes presenting a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device. In another embodiment, the method may also validate an object photographed by a camera of the mobile communication device, and use the recognized object to identify the set of movies.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="160.27mm" wi="217.59mm" file="US08627358-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="226.99mm" wi="171.03mm" orientation="landscape" file="US08627358-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="231.99mm" wi="190.75mm" orientation="landscape" file="US08627358-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="208.53mm" wi="171.03mm" orientation="landscape" file="US08627358-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="204.64mm" wi="174.58mm" file="US08627358-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="222.42mm" wi="183.56mm" file="US08627358-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="218.78mm" wi="156.21mm" file="US08627358-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="211.16mm" wi="140.04mm" file="US08627358-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="232.33mm" wi="171.37mm" file="US08627358-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="198.37mm" wi="161.46mm" file="US08627358-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates generally to systems and methods for identifying movies. More particularly, the present invention relates to identifying movies at least partially based on a location of a user.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">The ever-increasing catalog of movies can present challenges for viewers in selecting a movie according to his or her preferences. While movies can often be found or identified according to static criteria, such as title, genre, actor, or actress, current systems or applications may not allow viewers to select a movie based on some types of criteria. For example, current systems are limited in that they may not allow people to find movies that contain, or otherwise relate, to the current location of a device, such as a cellular phone, used by that person. Current systems may also be unable to identify and deliver a listing of movies to a viewer based on a picture captured by the viewer's cellular phone camera. The failure of current systems to conveniently identify movies based on a location may lead moviegoers with no way to find movies for potential viewing based on located-related criteria.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0006" num="0005">The illustrative embodiments described herein are directed to a data processing system and, in particular, to systems and methods for movie identification based on a location. In the embodiment, a method includes locating a mobile communication device associated with a user to form location data, accessing a location database to determine a geographic location of the mobile communication device based on the location data, and identifying a set of movies related to the geographic location by accessing a movie database. Each of the set of movies in the movie database is associated with one or more respective geographic locations. The method also includes presenting a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device.</p>
<p id="p-0007" num="0006">In another embodiment, a method includes receiving an image captured by a camera of a mobile communication device. The mobile communication device is associated with a user, and the image at least partially contains an object. The method includes identifying the object contained in the image and accessing a movie database to identify a set of movies associated with the object. The movie database includes a plurality of movies associated with a respective set of objects. The method includes presenting a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device.</p>
<p id="p-0008" num="0007">In another embodiment, a location-based movie identification system includes a movie identification application at least partially implemented by a mobile communication device. The movie identification application includes a location identification module to determine a geographic location of the mobile communication device, and a movie identification engine to identify a set of movies associated with the geographic location. The movie identification engine includes a movie results module to initiate a movie results interface on a graphical user interface of the mobile communication device. The movie results interface lists a set of movie results corresponding to the set of movies.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic, pictorial representation of a location-based movie identification system according to an illustrative embodiment;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic, block diagram of a location-based movie identification system according to an illustrative embodiment;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic, pictorial representation of a movie results interface displayable to a user according to an illustrative embodiment;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart of a location-based movie identification process according to an illustrative embodiment;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart of a process for managing promotions and transactions in a location-based movie identification system according to an illustrative embodiment;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart of a location-based movie identification process according to another illustrative embodiment;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart of an illustrative embodiment of a sub-process for the step of identifying an object that is shown in <figref idref="DRAWINGS">FIG. 6</figref>;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart of a location-based movie identification process according to another illustrative embodiment; and</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 9</figref> is a schematic, block diagram of a data processing system in which the illustrative embodiments may be implemented.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0018" num="0017">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, an illustrative embodiment of a location-based movie identification system <b>100</b> includes a mobile communication device <b>102</b> on which a movie identification application <b>104</b> is implemented. The mobile communication device <b>102</b> is in communication with a movie identification hub <b>106</b>, which includes a server <b>108</b>. The movie identification hub <b>106</b> may also include a storage device <b>110</b> on which data supporting the functionality of the movie identification application <b>104</b> may be stored. The storage device <b>110</b>, though shown at the movie identification hub <b>106</b>, may also be located in the mobile communication device <b>102</b>. A user <b>112</b> of the mobile communication device <b>102</b> may interface with the movie identification application <b>104</b> to retrieve or view a set of movies that relate to the current location of the user <b>112</b>. Unless otherwise indicated, as used herein, &#x201c;or&#x201d; does not require mutual exclusivity. As used herein, the term &#x201c;set&#x201d; encompasses a quantity of one or more.</p>
<p id="p-0019" num="0018">In one embodiment, the location-based movie identification system <b>100</b> locates the mobile communication device <b>102</b>, and identifies location data that indicates the mobile communication device's location. For example, the movie identification application <b>104</b> may have, or communicate with, a global positioning system or other similar location technology (e.g., WiFi, cell identification (Cell ID), observed time difference of arrival (OTDOA), enhanced observed time difference (E-OTD), network multipath analysis and assisted global positioning system (A-GPS), etc.) to determine the global positioning system coordinates that reflect the location of the mobile communication device <b>102</b>. Using the location data, the movie identification application <b>104</b> may access the storage device <b>110</b> to determine the geographic location of the mobile communication device <b>102</b>. The storage device <b>110</b> may include a location database <b>113</b> that includes many different locations around the world that are indexed with any type of location data, such as global positioning system coordinates. By way of specific illustration, the movie identification application <b>104</b>, after determining the global positioning system coordinates of the mobile communication device <b>102</b>, may use these coordinates when accessing the location database <b>113</b> to search for and identify the geographic location of the mobile communication device <b>102</b> as being at or near Liberty Island, New York, N.Y. 10004. In this specific example, the global positioning system coordinates indicate that the mobile communication device <b>102</b> is located on Liberty Island.</p>
<p id="p-0020" num="0019">Once the geographic location of the mobile communication device <b>102</b> is determined, the movie identification application <b>104</b> may access a movie database <b>114</b> in the storage device <b>110</b>. The movie database <b>114</b> may include any number of movies, as well as data about those movies. In one embodiment, each movie in the movie database <b>114</b> is associated with one or more geographic locations that relate to the respective movie. For example, movies that contain, have dialogue about, or otherwise relate to Liberty Island or New York City may be associated with these geographic locations, such as in the form of geotags or other metadata. Using the geographic locations that are associated with the movies in the movie database <b>114</b>, the movie identification application <b>104</b> may search for and identify the movies in the movie database <b>114</b> that are associated with the geographic location of the mobile communication device <b>102</b>. The movies that are identified may then be presented as search results, or in any other form, to the user <b>112</b> of the mobile communication device <b>102</b> by displaying the movie search results on the graphical user interface <b>116</b> of the mobile communication device <b>102</b>.</p>
<p id="p-0021" num="0020">Another embodiment of the location-based movie identification system <b>100</b> utilizes a camera on the mobile communication device <b>102</b> in order to identify the movies relating to an object <b>118</b> in an image <b>120</b> captured by the camera. In this embodiment, the movie identification application <b>104</b> may receive the image <b>120</b> that is captured by the camera. The movie identification application <b>104</b> may then identify the object <b>118</b> that is at least partially contained in the image <b>120</b>. Recognition of the object <b>118</b> that is contained in the image <b>120</b> may be performed using any of a variety of techniques, such as image analysis or other methods described in further detail below. The movie identification application <b>104</b> may then access the movie database <b>114</b> to identify movies that are associated with the object <b>118</b> contained in the image <b>120</b>. The movies in the movie database <b>114</b> may each be tagged, or otherwise associated with, one or more objects that relate to the movie. For example, objects that appear in, relate to the plot of, are talked about in, or otherwise relate to a movie in the movie database <b>114</b> may be associated with that movie. In identifying the movies that are associated with the object <b>118</b>, the movie identification application <b>104</b> may search for and identify the object <b>118</b> in the movie database <b>114</b>, and then identify the movies that are associated with that object <b>118</b>. The movies that are identified by the movie identification application <b>104</b> may then be presented on the graphical user interface <b>116</b> of the mobile communication device <b>102</b> so that they can be viewed by the user <b>112</b>. As explained in further detail below, the user <b>112</b> may be presented with an option to purchase or view any of the movies that are listed on the graphical user interface <b>116</b> by the movie identification application <b>104</b>.</p>
<p id="p-0022" num="0021">While <figref idref="DRAWINGS">FIG. 1</figref> shows the movie identification application <b>104</b> to be located or implemented in the mobile communication device <b>102</b>, the movie identification application <b>104</b> may also be implemented elsewhere, such as on the server <b>108</b>. In another embodiment, the movie identification hub <b>106</b>, including the storage device <b>102</b> containing the location database <b>113</b> and the movie database <b>114</b>, may be located or implemented in the mobile communication device <b>102</b> along with the movie identification application <b>104</b>. Indeed, the movie identification application <b>104</b> and movie identification hub <b>106</b>, including any combination of functionality thereof, may be distributed across the location-based movie identification system <b>100</b> in a variety of ways.</p>
<p id="p-0023" num="0022">The mobile communication device <b>102</b> may be any device capable of communicating with other devices and interfacing with the user <b>112</b>. For example, the mobile communication device <b>102</b> may be a cellular phone (e.g., a smart phone), a walkie talkie, a computer (e.g., a laptop, netbook, tablet computer, or minicomputer), a personal digital assistant, a digital music player, a digital reader, a portable gaming device, a web browsing device, a media player, or any other electronic device that is mobile and capable of communicating data with other devices.</p>
<p id="p-0024" num="0023">The techniques, technologies, or media by which the components of the location-based movie identification system <b>100</b> intercommunicate are numerous. For example, the location-based movie identification system <b>100</b>, or any portion thereof, may be part of a personal area network (PAN), a local area network (LAN), a campus area network (CAN), a metropolitan area network (MAP), or any other network type. Also, data communication between any two of the elements in the location-based movie identification system <b>100</b> may be direct or indirect. Data communication medium <b>124</b> between the base station <b>126</b> and the movie identification hub <b>106</b> may be any medium through which data can be communicated. For example, the data communication medium <b>124</b> may be wired or wireless data connections, and may utilize a virtual private network (VPN), multi-protocol label switching (MPLS), the Internet, or any other data communication media. Wireless communication between the mobile communication device <b>102</b> and the base station <b>126</b> may utilize any wireless standard for communicating data, such as CDMA (e.g., cdmaOne or CDMA2000), GSM, 3G, 4G, Edge, an over-the-air network, Bluetooth, etc. Any of the transactions occurring in the location-based movie identification system <b>100</b> may be performed using secure SSL transactions.</p>
<p id="p-0025" num="0024">In one example, the location-based movie identification system <b>100</b> may utilize the Internet, with the data communication medium <b>124</b> representing a worldwide collection of networks and gateways that use the Transmission Control Protocol/Internet Protocol (TCP/IP) suite of protocols to communicate with one another. At the heart of the Internet is a backbone of high-speed data communication lines between major nodes or host computers, consisting of thousands of commercial, governmental, educational, and other computer systems that route data and messages. <figref idref="DRAWINGS">FIG. 1</figref> is intended as an example, and not as an architectural limitation for the different illustrative embodiments.</p>
<p id="p-0026" num="0025">Referring to <figref idref="DRAWINGS">FIGS. 2 and 3</figref>, an illustrative embodiment of the location-based movie identification system <b>200</b> includes the movie identification application <b>204</b> implemented on the mobile communication device <b>202</b>, the movie identification hub <b>206</b> in communication with the mobile communication device <b>202</b>, and non-limiting examples of the elements that may be included in the mobile communication device <b>202</b> and movie identification hub <b>206</b> to implement the location-based movie identification system <b>200</b>. Elements of <figref idref="DRAWINGS">FIG. 2</figref> that are analogous to elements in <figref idref="DRAWINGS">FIG. 1</figref> have been shown by indexing the reference numerals by 100. All or a portion of the elements of the movie identification application <b>204</b> or the movie identification hub <b>206</b> may be implemented on the mobile communication device <b>202</b>, a server, such as the server <b>108</b> in <figref idref="DRAWINGS">FIG. 1</figref>, a combination of these devices, or any other device that is in communication with the user <b>212</b>. Thus, for example, the movie identification application <b>202</b> may be fully or partially implemented by the mobile communication device <b>202</b>.</p>
<p id="p-0027" num="0026">The user <b>212</b> may use the movie identification application <b>204</b> to retrieve information about movies pertaining to his or her location. The user <b>212</b> may activate this retrieval process by, for example, pressing a button instructing the movie identification application <b>204</b> to find movies relating to the current location of his or her mobile communication device <b>202</b>. In one embodiment, the movie identification application <b>204</b> includes a location identification module <b>228</b> that determines a geographic location of the mobile communication device <b>202</b>. In one example, the location identification module <b>228</b> determines location data, such as global positioning system coordinates, that indicate the location of the mobile communication device <b>202</b>. Other location-based technologies or services may also be used to determine the location data for the mobile communication device <b>202</b>, such as WiFi, Cell ID, OTDOA, E-OTD, A-GPS, etc. The location identification module <b>228</b> may then access the location database <b>213</b> to identify the geographic location of the mobile communication device <b>202</b> based on the location data. The location database <b>213</b> contains multiple locations, such as zip codes, cities, states, neighborhoods, streets, bodies of water, which are associated with respective location data that is matchable with the location data of the mobile communication device <b>202</b>. For example, the location data for mobile communication device <b>202</b>, as determined by the location identification module <b>228</b>, may be the global positioning system coordinates of 40.689167, &#x2dc;74.044444. These global positioning system coordinates may be stored in the location database <b>213</b> and associated with the geographic location of Liberty Island in New York, N.Y. 10004. Thus, when the location identification module <b>228</b> uses these global positioning system coordinates to find the geographic location of the mobile communication device <b>202</b>, the location identification module <b>228</b> identifies these global positioning system coordinates in the location database <b>213</b> and then identifies the location associated with these coordinate (i.e., Liberty Island), thus determining the geographic location of the mobile communication device <b>202</b>.</p>
<p id="p-0028" num="0027">In an alternate embodiment, the location identification module <b>228</b> may identify the geographic location of the user <b>212</b> based on a user's manual entry of his or her location. For example, the user <b>212</b> may manually input his or her current or other location on the mobile communication device <b>202</b>.</p>
<p id="p-0029" num="0028">After the location identification module <b>228</b> determines the geographic location of the mobile communication device <b>202</b>, a movie identification engine <b>230</b> may then identify a set of movies containing, or otherwise related, to this geographic location by accessing the movie database <b>214</b>. The movie database <b>214</b> may contain multiple entries corresponding to any number of respective movies <b>232</b>, each of which may be associated with one or more geographic locations relating to the respective movie. For example, each movie <b>232</b> in the movie database <b>214</b> may have one or more geotags <b>234</b> that identify locations that are contained, or otherwise related to, in the movie. The geotags <b>234</b> may be any data that indicates a location, such as an address, any political, geographic, or naturally-occurring unit, boundary, or location, global positioning system coordinates, or any combination thereof. By way of example, if the location identification module <b>228</b> determines that the mobile communication device <b>202</b> is located at Liberty Island, New York, N.Y. 10004, the movie identification engine <b>230</b> may search for and identify any geotags <b>234</b> that match this geographic location. The movie identification engine <b>230</b> may then identify the movies that have the geotags matching the geographic location of the mobile communication device <b>202</b> (e.g., liberty Island).</p>
<p id="p-0030" num="0029">Once the movies associated with the geographic location of the mobile communication device <b>202</b> are identified by the movie identification engine <b>230</b>, a movie results module <b>235</b> displays a set of movie results corresponding to the identified movies on the graphical user interface <b>216</b> of the mobile communication device <b>202</b>. As shown in <figref idref="DRAWINGS">FIG. 3</figref>, the movie results may be displayed on the graphical user interface <b>216</b> using a movie results interface <b>236</b>. The movie results interface <b>236</b> lists the movies that relate to the geographic location of the mobile communication device <b>202</b>, as determined by the location identification module <b>228</b>. The movie results interface <b>236</b> also lists the geographic location of the mobile communication device <b>202</b> for the user's reference. In the example of <figref idref="DRAWINGS">FIG. 3</figref>, the geographic location of the mobile communication device <b>202</b> is Liberty Island, New York, N.Y. 10004. Additional details regarding the movie results interface <b>236</b> are provided below.</p>
<p id="p-0031" num="0030">In other illustrative embodiments, the location-based movie identification system <b>200</b> may use the object <b>218</b> located at or near the user <b>212</b> to identify movies for presentation to the user <b>212</b>. The object <b>218</b> may be identified by an object identification module <b>238</b> in the movie identification application <b>204</b>. There are numerous ways in which the object identification module <b>238</b> may determine the object <b>218</b>. In one embodiment, the object identification module <b>238</b> may identify the object <b>218</b> at or near the user <b>212</b> based on the geographic location of the mobile communication device <b>202</b>, as determined by the location identification module <b>228</b>. In this embodiment, each of the locations in the location database <b>213</b> may be associated with one or more objects <b>240</b>. For example, each of the objects <b>240</b> may be linked to, or otherwise associated with, respective locations in the location database <b>213</b> at which those objects <b>240</b> are located. For example, the object Statue of Liberty may be associated with the location Liberty Island, New York, N.Y. 10004. In identifying the object <b>218</b>, the object identification module <b>238</b> may compare the geographic location of the mobile communication device <b>202</b> to locations contained in the location database <b>213</b>. When the geographic location is found in the location database <b>213</b>, the one or more objects <b>240</b> associated with those locations may be identified as the object <b>218</b>. In one embodiment, the identification of the object <b>218</b> by the object identification module <b>238</b>, as described above, may be triggered by, or otherwise in response to, the capturing of an image of the object <b>218</b> by the camera <b>240</b>. The object identification module <b>238</b> may or may not need to use the image in order to determine any objects contained in the image, depending on the particular embodiment. For example, the object identification module <b>238</b> may identify the object <b>218</b> in the location database <b>213</b> using the geographic location of the mobile communication device <b>202</b> and without reference to the image taken by the camera <b>240</b>.</p>
<p id="p-0032" num="0031">In another embodiment, the object identification module <b>238</b> may identify the object <b>218</b> contained in the image captured by the camera <b>240</b> using image analysis. In this embodiment, the object identification module <b>238</b>, in conjunction with an image processor <b>242</b>, uses image analysis techniques such as object-based image analysis (OPIA), or other techniques or applications capable of recognizing objects within an image. The object identification module <b>238</b> may then attempt to find a match between the object recognized using image analysis and the objects <b>240</b> in the location database <b>213</b> to confirm the accuracy of the image analysis.</p>
<p id="p-0033" num="0032">In another illustrative embodiment, after the object <b>218</b> is identified by the object identification module <b>238</b> by analyzing the image captured by the camera <b>240</b>, the geographic location of the mobile communication device <b>202</b> may be determined based on the object <b>218</b>. For example, if the user <b>212</b> captures an image of the Statue of Liberty, the location identification module <b>228</b> may determine the location of the mobile communication device <b>202</b> by searching for and identifying the geographic location of the Statue of Liberty. In this specific non-limiting example, the location identification module <b>228</b> identifies the geographic location of the mobile communication device <b>202</b> as being Liberty Island, New York, N.Y. 10004. One example of how the geographic location may be determined based on the object <b>218</b> is by the location identification module <b>228</b> accessing the location database <b>213</b> to search for the object <b>218</b> identified by the object identification module <b>238</b>. The location identification module <b>228</b> may, for example, search for and identify the Statue of Liberty as one of the objects <b>240</b> in the location database <b>213</b>, and then identify the location linked to, or associated with, the Statue of Liberty.</p>
<p id="p-0034" num="0033">In another embodiment, the location identification module <b>228</b> may identify the location of the mobile communication device <b>202</b>, and then the object identification module <b>238</b> may validate the object <b>218</b> captured in the image using object recognition technology to confirm a match. In particular, after the location identification module <b>228</b> identifies the location of the mobile communication device <b>202</b> (e.g., Liberty Island, NY), the object identification module <b>238</b> may identify, or otherwise recognize, the object <b>218</b> (e.g., Statue of Liberty) and validate the location of the object <b>218</b> relative to the identified location of the mobile communication device <b>202</b>. For example, if the location identification module <b>228</b> identifies Dallas, Tex. as the location of the mobile communication device <b>202</b>, but the object identification module <b>238</b> identifies the Statue of Liberty as the object <b>218</b> contained in the image captured by the camera <b>240</b>, then the movie identification application <b>204</b> may determine that an error has occurred with regard to identifying the object <b>218</b> or the location of the mobile communication device <b>202</b> since the Statute of Liberty is not located in Dallas, Tex. In another embodiment, the movie identification application <b>204</b> may compare the object <b>218</b> identified by the object identification module <b>238</b> with the location identified by the location identification module <b>228</b> to determine a level, or degree, of confidence that the correct object <b>218</b> or location has been identified. Also, user proximity to the object <b>218</b> may be used to determine a level of confidence that, in turn, determines whether it is necessary to perform an object identification lookup (e.g., look up the object <b>218</b> in the location database <b>213</b>) or object recognition. For example, the closer the identified location is to the object <b>218</b>, the higher the confidence that the user <b>212</b> is looking at, or otherwise near, the object <b>218</b>. Thus, once the movie identification application <b>204</b> determines a proximity between the mobile communication device <b>202</b> and a known object, such as one of the objects <b>240</b> in the location database <b>213</b>, the movie identification application <b>204</b> may use this proximity to determine a confidence level that indicates, or is otherwise associated with, the likelihood that the mobile communication device <b>202</b> is near the object in the location database <b>213</b>.</p>
<p id="p-0035" num="0034">In another embodiment, the object identification module <b>238</b> may identify the object <b>218</b> based on a user's manual entry of the object <b>218</b>. For example, the user <b>212</b> may manually input the name of the object <b>218</b> (e.g., Taj Mahal) on the mobile communication device <b>202</b>.</p>
<p id="p-0036" num="0035">After either or both of the geographic location of the mobile communication device <b>202</b> or the object <b>218</b> is identified by the location identification module <b>228</b> or the object identification module <b>238</b>, respectively, the movie identification engine <b>230</b> may identify a set of movies for presentation to the user <b>212</b> based on either or both of the geographic location or the object <b>218</b>. As described above, one or more movies may be identified in the movie database <b>214</b> using geographic location data, such as geotags <b>234</b>, that is associated with the movies <b>232</b>. Each of the movies <b>232</b> in the movie database <b>214</b> may also be tagged, or otherwise associated with, one or more objects that are contained in, or otherwise related to, the respective movie. Once the object <b>218</b> is determined by the object identification module <b>238</b>, the movie identification engine <b>230</b> may search for the object tags in the movie database <b>214</b> to find the movies associated with those objects.</p>
<p id="p-0037" num="0036">The identification of movies by the movie identification engine <b>230</b> may also be based on user preferences <b>244</b> of the user <b>212</b>, which are stored in a user profile <b>245</b> of the user <b>212</b>. For example, the user preferences <b>244</b> may include a preference for a particular genre of movie, such as comedy or horror, or a particular date range for movies that the user <b>212</b> is interested in. When identifying movies, the movie identification engine <b>230</b> may take into account these user preferences <b>244</b> in addition to the object <b>218</b> and/or the geographic location of the mobile communication device <b>202</b>. By way of non-limiting example, if the object <b>218</b> is identified as the Golden Gate Bridge and the user preferences <b>244</b> indicate that the user <b>212</b> prefers comedies, the movie identification engine <b>230</b> will identify movies in the movie database <b>214</b> that relate to the Golden Gate Bridge and are comedies.</p>
<p id="p-0038" num="0037">After the movies associated with the geographic location of the mobile communication device <b>202</b> or the object <b>218</b> are identified by the movie identification engine <b>230</b>, a listing of the movie results corresponding to the identified movies may be presented to the user <b>212</b> on the graphical user interface <b>216</b>. These movie results may be listed in the movie results interface <b>236</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>, which may also show the object <b>218</b> identified by the object identification module <b>238</b> or the geographic location identified by the location identification module <b>228</b>. In the non-limiting example shown in <figref idref="DRAWINGS">FIG. 3</figref>, four movies related to the Statue of Liberty are listed in the movie results interface <b>236</b>. These movies may be sorted, such as by name, date, rating, or relevance to the object <b>218</b>, by selecting a sort option <b>246</b></p>
<p id="p-0039" num="0038">In one embodiment, the movie identification engine <b>230</b> includes a promotional content module <b>248</b> that delivers one or more promotions <b>250</b> to the user <b>212</b> in conjunction with the movie results delivered by the movie results module <b>235</b>. The promotion <b>250</b> may be an advertisement, coupon, notice, etc. In one embodiment, the promotion <b>250</b> selected for display in the movie results interface <b>236</b> may be based on the geographic location of the mobile communication device <b>202</b> as determined by the location identification module <b>228</b>, or the object <b>218</b> at or near the user <b>212</b> as determined by the object identification module <b>238</b>. Thus, the promotional content module <b>248</b> may select promotions that are most relevant to the user <b>212</b> based on his or her location. In another embodiment, the promotional content module <b>248</b> may identify the promotion <b>250</b> based on the movies identified by the movie identification engine <b>230</b>, such as promotions for memorabilia for a particular movie or for products or services associated with a particular genre of movie.</p>
<p id="p-0040" num="0039">The movie identification application <b>204</b> may also include a transaction engine <b>252</b> that conducts a movie purchase transaction for the user <b>212</b> when the user <b>212</b> selects to purchase one of the movies identified by the movie identification engine <b>230</b>. As shown in the movie results interface <b>236</b> in <figref idref="DRAWINGS">FIG. 3</figref>, the user <b>212</b> may select to purchase an identified movie by selecting a purchase option <b>254</b> next to a respective movie. After a movie purchase is made, the user <b>212</b> may be provided an option to view the movie on the graphical user interface <b>216</b>. A customer account database <b>256</b> at the movie identification hub <b>206</b>, which may include financial, purchase, or other account-related information for the user <b>212</b>, may be updated when the user <b>212</b> purchases a movie using the transaction engine <b>252</b>. In another embodiment, the data in the customer account database <b>256</b> may be included in the user profile <b>245</b>.</p>
<p id="p-0041" num="0040">In another embodiment, the user <b>212</b> may be provided with additional options with respect to each movie identified by the movie identification engine <b>230</b>. For example, the movie results interface <b>236</b> may provide the user <b>212</b> an option to view a movie synopsis of each of the listed movies, or view detailed rating information (e.g., community, public, etc. ratings).</p>
<p id="p-0042" num="0041">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, an illustrative embodiment of a location-based movie identification process, which may be implemented by the location-based movie identification system <b>100</b> or <b>200</b> in <figref idref="DRAWINGS">FIG. 1</figref> or <b>2</b>, includes locating a mobile communication device associated with a user to form location data (step <b>301</b>). The process accesses the location database to determine the geographic location of the mobile communication device based on the location data (step <b>303</b>). The process determines whether the geographic location is found (step <b>305</b>).</p>
<p id="p-0043" num="0042">If the process determines that the geographic location is not found, the process returns to step <b>301</b>. Returning to step <b>305</b>, if the process determines that the geographic location is found, the process identifies a set of movies related to the geographic location by accessing the movie database (step <b>307</b>). The process presents a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device (step <b>309</b>).</p>
<p id="p-0044" num="0043">Referring to <figref idref="DRAWINGS">FIG. 5</figref>, an illustrative embodiment of a process for managing promotions and transactions in a location-based movie identification system, such as the location-based movie identification system <b>100</b> or <b>200</b> in <figref idref="DRAWINGS">FIG. 1</figref> or <b>2</b>, includes presenting a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device (step <b>401</b>). The process presents a set of promotions on the graphical user interface of the mobile communication device (step <b>403</b>). The process determines whether a user selection to purchase one of the set of movies presented on the mobile communication device is received (step <b>405</b>). If the process determines that a user selection to purchase one of the set of movies presented on the mobile communication device is not received, the process terminates.</p>
<p id="p-0045" num="0044">If the process determines that a user selection to purchase one of the set of movies presented on the mobile communication device is received, the process initiates a purchase transaction for the movie selected by the user (step <b>407</b>). The process determines whether to display the movie on the graphical user interface, such as by user selection (step <b>409</b>). If the process determines not to display the movie on the graphical user interface, the process terminates. If the process determines to display the movie on the graphical user interface, the process displays the movie on the graphical user interface (step <b>411</b>).</p>
<p id="p-0046" num="0045">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, an illustrative embodiment of a location-based movie identification process, which may be implemented by the location-based movie identification system <b>100</b> or <b>200</b> in <figref idref="DRAWINGS">FIG. 1</figref> or <b>2</b>, includes receiving an image of an object captured by a camera of a mobile communication device (step <b>501</b>). The process identifies the object contained in the image (step <b>503</b>). The process determines whether the object is identified (step <b>505</b>). If the process determines that the object is not identified, the process informs the user that no results are found (step <b>507</b>).</p>
<p id="p-0047" num="0046">If the process determines that the object is identified, the process accesses a movie database to identify a set of movies associated with the object (step <b>509</b>). The process presents a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device (step <b>511</b>).</p>
<p id="p-0048" num="0047">Referring to <figref idref="DRAWINGS">FIG. 7</figref>, an illustrative embodiment of the step <b>503</b> identifying the object contained in the image shown in <figref idref="DRAWINGS">FIG. 6</figref> includes determining a geographic location of the mobile communication device (step <b>601</b>). The process searches a location database for the geographic location (step <b>603</b>). The process determines whether a geographic location is found (step <b>605</b>). If the process determines that the geographic location is not found, the process returns to step <b>601</b>.</p>
<p id="p-0049" num="0048">If the process determines that the geographic location is found, the process identifies a geographic location in the location database (step <b>607</b>). The process identifies the object located at the geographic location identified in the location database (step <b>609</b>).</p>
<p id="p-0050" num="0049">Referring to <figref idref="DRAWINGS">FIG. 8</figref>, an illustrative embodiment of a location-based movie identification process, which may be implemented by the location-based movie identification system <b>100</b> or <b>200</b> in <figref idref="DRAWINGS">FIG. 1</figref> or <b>2</b>, includes locating a mobile communication device associated with a user to form location data (step <b>701</b>). The process accesses a location database to determine the geographic location of the mobile communication device based on the location data (step <b>703</b>). The process determines whether the geographic location is found (step <b>705</b>). If the process determines that the geographic location is not found, the process returns to step <b>701</b>.</p>
<p id="p-0051" num="0050">If the process determines that the geographic location is found, the process receives an image of an object captured by a camera of the mobile communication device (step <b>707</b>). The process identifies the object contained in the image using the geographic location of the mobile communication device (step <b>709</b>). The process receives a set of user preferences of the user of the mobile communication device (step <b>711</b>).</p>
<p id="p-0052" num="0051">The process accesses a movie database to identify a set of movies related to the geographic location or the object based on the user preferences (step <b>713</b>). The process presents a set of movie results corresponding to the set of movies on the graphical user interface of the mobile communication device (step <b>715</b>).</p>
<p id="p-0053" num="0052">The flowcharts and block diagrams in the different depicted embodiments illustrate the architecture, functionality, and operation of some possible implementations of apparatus, methods and computer program products. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified function or functions. In some alternative implementations, the function or functions noted in the block may occur out of the order noted in the Figures. For example, in some cases, two blocks shown in succession may be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved.</p>
<p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIG. 9</figref>, a block diagram of a computing device <b>802</b> is shown in which illustrative embodiments may be implemented. The computing device <b>802</b> may be the mobile communication device <b>102</b> or <b>202</b> described in <figref idref="DRAWINGS">FIG. 1</figref> or <b>2</b>, respectively. The computing device <b>802</b> may be the computing device on which the movie identification application <b>104</b> or <b>204</b> in <figref idref="DRAWINGS">FIG. 1</figref> or <b>2</b> is implemented. Computer-usable program code or instructions implementing the processes used in the illustrative embodiments may be located on the computing device <b>802</b>. The computing device <b>802</b> includes a communications fabric <b>803</b>, which provides communications between a processor unit <b>805</b>, a memory <b>807</b>, a persistent storage <b>809</b>, a communications unit <b>811</b>, an input/output (I/O) unit <b>813</b>, and a display <b>815</b>.</p>
<p id="p-0055" num="0054">The processor unit <b>805</b> serves to execute instructions for software that may be loaded into the memory <b>807</b>. The processor unit <b>805</b> may be a set of one or more processors or may be a multi-processor core, depending on the particular implementation. Further, the processor unit <b>805</b> may be implemented using one or more heterogeneous processor systems in which a main processor is present with secondary processors on a single chip. As another illustrative example, the processor unit <b>805</b> may be a symmetric multi-processor system containing multiple processors of the same type.</p>
<p id="p-0056" num="0055">The memory <b>807</b>, in these examples, may be, for example, a random access memory or any other suitable volatile or non-volatile storage device. The persistent storage <b>809</b> may take various forms depending on the particular implementation. For example, the persistent storage <b>809</b> may contain one or more components or devices. For example, the persistent storage <b>809</b> may be a hard drive, a flash memory, a rewritable optical disk, a rewritable magnetic tape, or some combination of the above. The media used by the persistent storage <b>809</b> also may be removable. For example, a removable hard drive may be used for the persistent storage <b>809</b>.</p>
<p id="p-0057" num="0056">The communications unit <b>811</b>, in these examples, provides for communications with other data processing systems or communication devices. In these examples, the communications unit <b>811</b> may be a network interface card. The communications unit <b>811</b> may provide communications through the use of either or both physical and wireless communication links.</p>
<p id="p-0058" num="0057">The input/output unit <b>813</b> allows for the input and output of data with other devices that may be connected to the computing device <b>802</b>. For example, the input/output unit <b>813</b> may provide a connection for user input through a keyboard and mouse. Further, the input/output unit <b>813</b> may send output to a processing device. In the case in which the computing device <b>802</b> is a cellular phone, the input/output unit <b>813</b> may also allow devices to be connected to the cellular phone, such as microphones, headsets, and controllers. The display <b>815</b> provides a mechanism to display information to a user, such as a graphical user interface. The display <b>815</b> may be used to display the text messages described in the illustrative embodiments.</p>
<p id="p-0059" num="0058">Instructions for the operating system and applications or programs are located on the persistent storage <b>809</b>. These instructions may be loaded into the memory <b>807</b> for execution by the processor unit <b>805</b>. The processes of the different embodiments may be performed by the processor unit <b>805</b> using computer-implemented instructions, which may be located in a memory, such as the memory <b>807</b>. These instructions are referred to as program code, computer-usable program code, or computer-readable program code that may be read and executed by a processor in the processor unit <b>805</b>. The program code in the different embodiments may be embodied on different physical or tangible computer-readable media, such as the memory <b>807</b> or the persistent storage <b>809</b>.</p>
<p id="p-0060" num="0059">Program code <b>817</b> is located in a functional form on a computer-readable media <b>819</b> and may be loaded onto or transferred to the computing device <b>802</b> for execution by the processor unit <b>805</b>. The program code <b>817</b> and the computer-readable media <b>819</b> form computer program product <b>821</b> in these examples. In one embodiment, the computer program product <b>821</b> is the movie identification application <b>104</b> or <b>204</b> described in <figref idref="DRAWINGS">FIG. 1</figref> or <b>2</b>, respectively. In this embodiment, the program code <b>817</b> may include computer-usable program code capable of locating a mobile communication device associated with a user to form location data, accessing a location database to determine a geographic location of the mobile communication device based on the location data, and identifying a set of movies related to the geographic location by accessing a movie database. Each of the set of movies in the movie database is associated with one or more respective geographic locations. The program code <b>817</b> may also include computer-usable program code capable of presenting a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device.</p>
<p id="p-0061" num="0060">In another embodiment, the program code <b>817</b> may include computer-usable program code capable of receiving an image captured by a camera of a mobile communication device. The mobile communication device is associated with a user, and the image at least partially contains an object. The program code <b>817</b> may also include computer-usable program code capable of identifying the object contained in the image and accessing a movie database to identify a set of movies associated with the object. The movie database includes a plurality of movies associated with a respective set of objects. The program code <b>817</b> may also include computer-usable program code capable of presenting a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device. Any combination of the above-mentioned computer-usable program code may be implemented in the program code <b>817</b>, and any functions of the illustrative embodiments may be implemented in the program code <b>817</b>.</p>
<p id="p-0062" num="0061">In one example, the computer-readable media <b>819</b> may be in a tangible form, such as, for example, an optical or magnetic disc that is inserted or placed into a drive or other device that is part of the persistent storage <b>809</b> for transfer onto a storage device, such as a hard drive that is part of the persistent storage <b>809</b>. In a tangible form, the computer-readable media <b>819</b> also may take the form of a persistent storage, such as a hard drive or a flash memory that is connected to the computing device <b>802</b>. The tangible form of the computer-readable media <b>819</b> is also referred to as computer recordable storage media.</p>
<p id="p-0063" num="0062">Alternatively, the program code <b>817</b> may be transferred to the computing device <b>802</b> from the computer-readable media <b>819</b> through a communication link to the communications unit <b>811</b> or through a connection to the input/output unit <b>813</b>. The communication link or the connection may be physical or wireless in the illustrative examples. The computer-readable media <b>819</b> also may take the form of non-tangible media, such as communication links or wireless transmissions containing the program code <b>817</b>.</p>
<p id="p-0064" num="0063">The different components illustrated for the computing device <b>802</b> are not meant to provide architectural limitations to the manner in which different embodiments may be implemented. The different illustrative embodiments may be implemented in a data processing system including components in addition to or in place of those illustrated for computing device <b>802</b>. Other components shown in <figref idref="DRAWINGS">FIG. 9</figref> can be varied from the illustrative examples shown.</p>
<p id="p-0065" num="0064">As one example, a storage device in the computing device <b>802</b> is any hardware apparatus that may store data. The memory <b>807</b>, the persistent storage <b>809</b>, and the computer-readable media <b>819</b> are examples of storage devices in a tangible form.</p>
<p id="p-0066" num="0065">In another example, a bus system may be used to implement the communications fabric <b>803</b> and may be comprised of one or more buses, such as a system bus or an input/output bus. Of course, the bus system may be implemented using any suitable type of architecture that provides for a transfer of data between different components or devices attached to the bus system. Additionally, the communications unit <b>811</b> may include one or more devices used to transmit and receive data, such as a modem or a network adapter. Further, a memory may be, for example, the memory <b>807</b> or a cache such as found in an interface and memory controller hub that may be present in the communications fabric <b>803</b>.</p>
<p id="p-0067" num="0066">The principles of the present invention can take the form of an entirely hardware embodiment, an entirely software embodiment, or an embodiment containing both hardware and software elements. In one embodiment, the invention is implemented in software, which includes but is not limited to, firmware, resident software, microcode, and other computer readable code.</p>
<p id="p-0068" num="0067">Furthermore, the principles of the present invention can take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description, a computer-usable or computer readable medium can be any tangible apparatus that can contain, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device.</p>
<p id="p-0069" num="0068">The previous detailed description is of a small number of embodiments for implementing the invention and is not intended to be limiting in scope. One of skill in this art will immediately envisage the methods and variations used to implement this invention in other areas than those described in detail. The following claims set forth a number of the embodiments of the invention disclosed with greater particularity.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for movie identification based on a location, the method comprising:
<claim-text>locating a mobile communication device associated with a user to form location data;</claim-text>
<claim-text>accessing a location database to determine a geographic location of the mobile communication device based on the location data;</claim-text>
<claim-text>identifying a set of movies related to the geographic location by accessing a movie database, each of the set of movies in the movie database associated with one or more respective geographic locations; and</claim-text>
<claim-text>presenting a set of movie results corresponding to the set of movies on a graphical user interface of the mobile communication device, wherein</claim-text>
<claim-text>the identifying of the set of movies comprises identifying the set of movies that include an object contained in an image captured by a camera.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>receiving the captured image from a camera of the mobile communication device, the image at least partially containing the object; and</claim-text>
<claim-text>identifying the object contained in the image using the geographic location of the mobile communication device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>receiving the image captured by the camera of the mobile communication device, the image at least partially containing the object;</claim-text>
<claim-text>identifying a direction at which the camera of the mobile communication device is pointed when the image is captured; and</claim-text>
<claim-text>identifying the object contained in the image using the geographic location of the mobile communication device and the direction of the camera.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the location database comprises a plurality of locations and a plurality of objects, each of the plurality of objects corresponding to at least one of the plurality of locations;
<claim-text>wherein accessing the location database to determine the geographic location of the mobile communication device comprising accessing the location database to identify an object at or near the mobile communication device based on the geographic location of the mobile communication device; and</claim-text>
<claim-text>wherein identifying the set of movies related to the geographic location comprises identifying the set of movies related to the object at or near the mobile communication device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the location data comprises global positioning system coordinates associated with a position of the mobile communication device.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>receiving a set of user preferences from the user, the set of user preferences comprising movie preferences of the user, wherein identifying the set of movies comprises identifying the set of movies using the set of user preferences.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>receiving a user selection to purchase at least one of the set of movies presented on the mobile communication device; and</claim-text>
<claim-text>initiating a purchase transaction for the at least one movie selected by the user.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein presenting the set of movie results corresponding to the set of movies on the graphical user interface comprises presenting a set of promotions on the graphical user interface of the mobile communication device, the set of promotions associated with at least one of the set of movies or the geographic location of the mobile communication device.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method for movie identification based on a location, the method comprising:
<claim-text>receiving an image captured by a camera of a mobile communication device, the mobile communication device associated with a user, the image at least partially containing an object;</claim-text>
<claim-text>identifying the object contained in the image;</claim-text>
<claim-text>accessing a movie database to identify a set of movies that include the object, the movie database comprising a plurality of movies associated with a respective set of objects; and</claim-text>
<claim-text>presenting a set of movie results corresponding to the set of movies comprising the object on a graphical user interface of the mobile communication device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein identifying the object contained in the image comprises:
<claim-text>determining a geographic location of the mobile communication device;</claim-text>
<claim-text>searching a location database for the geographic location, the location database comprising a plurality of locations and a plurality of objects, each of the plurality of objects located in at least one of the plurality of locations; and</claim-text>
<claim-text>identifying the geographic location in the location database; and</claim-text>
<claim-text>identifying the object located at the geographic location identified in the location database.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the movie database comprises a plurality of movies, each of the plurality of movies tagged with one or more objects related to the respective movie; and
<claim-text>wherein accessing the movie database to identify the set of movies associated with the object comprises identifying the set of movies tagged with the object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein identifying the object contained in the image comprises recognizing the object using image analysis.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising:
<claim-text>identifying a geographic location of the mobile communication device based on the object contained in the image, wherein accessing the movie database to identify the set of movies comprises accessing the movie database to identify the set of movies associated with the geographic location.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A location-based movie identification system comprising:
<claim-text>a movie identification application at least partially implemented by a mobile communication device, the movie identification application comprising:
<claim-text>a location identification module configured to determine a geographic location of the mobile communication device; and</claim-text>
<claim-text>a movie identification engine configured to identify a set of movies associated with the geographic location, the movie identification engine comprising a movie results module configured to initiate a movie results interface on a graphical user interface of the mobile communication device, the movie results interface configured to list a set of movie results corresponding to the set of movies, wherein</claim-text>
<claim-text>the movie identification engine is further configured to identify the set of movies that include an object contained in an image captured by a camera.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The location-based movie identification system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>a location database configured to store a plurality of locations,</claim-text>
<claim-text>wherein the location identification module is further configured to access the location database to determine the geographic location of the mobile communication device using location data associated with the mobile communication device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The location-based movie identification system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>a movie database comprising a plurality of movies, each of the plurality of movies associated with a respective set of geotags,</claim-text>
<claim-text>wherein the movie identification engine is further configured to access the movie database to identify the set of movies using the geotags.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The location-based movie identification system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>a mobile communication device comprising the camera configured to capture the image at least partially containing the object,</claim-text>
<claim-text>wherein the movie identification application further comprises an object identification module configured to recognize the object at least partially contained in the image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The location-based movie identification system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>a location database comprising a plurality of locations and a plurality of objects, each of the plurality of objects corresponding to at least one of the plurality of locations,</claim-text>
<claim-text>wherein the movie identification application further comprises an object identification module configured to access the location database to identify an object corresponding to the geographic location of the mobile communication device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The location-based movie identification system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>a mobile communication device comprising the camera configured to capture the image at least partially containing the object,</claim-text>
<claim-text>wherein the movie identification application further comprises an object identification module configured to identify the object using the geographic location of mobile communication device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The location-based movie identification system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>a transaction engine configured to conduct a movie purchase transaction for a user of the mobile communication device when the user selects to purchase one of the set of movies. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
