<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627049-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627049</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11383465</doc-number>
<date>20060515</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1299</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>11</main-group>
<subgroup>30</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>712227</main-classification>
</classification-national>
<invention-title id="d2e53">Real-time prioritization of stall or event information</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5657253</doc-number>
<kind>A</kind>
<name>Dreyer et al.</name>
<date>19970800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702186</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5751945</doc-number>
<kind>A</kind>
<name>Levine et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 47</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5768152</doc-number>
<kind>A</kind>
<name>Battaline et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702186</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6112318</doc-number>
<kind>A</kind>
<name>Jouppi et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 47</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6134676</doc-number>
<kind>A</kind>
<name>VanHuben et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 39</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6170032</doc-number>
<kind>B1</kind>
<name>Izzard</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710244</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2001/0039488</doc-number>
<kind>A1</kind>
<name>Swoboda</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703 17</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2001/0047253</doc-number>
<kind>A1</kind>
<name>Swoboda</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703 26</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2003/0229823</doc-number>
<kind>A1</kind>
<name>Swaine et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 25</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2005/0034026</doc-number>
<kind>A1</kind>
<name>Swaine et al.</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 43</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0102460</doc-number>
<kind>A1</kind>
<name>Wahler</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710269</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>&#x201c;MM74HC148 8-3 Line Priority Encoder&#x201d; Fairchild Semiconductor 1987/2001.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>CoreSight v1.0 Architecture Specification&#x2014;ARM, Sep. 2004.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
</us-references-cited>
<number-of-claims>2</number-of-claims>
<us-exemplary-claim>2</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>714 47</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60681427</doc-number>
<date>20050516</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60681551</doc-number>
<date>20050516</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060259664</doc-number>
<kind>A1</kind>
<date>20061116</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sohm</last-name>
<first-name>Oliver P.</first-name>
<address>
<city>Toronto</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Sohm</last-name>
<first-name>Oliver P.</first-name>
<address>
<city>Toronto</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Marshall, Jr.</last-name>
<first-name>Robert D.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Brady</last-name>
<first-name>W. James</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="03" rep-type="attorney">
<addressbook>
<last-name>Telecky, Jr.</last-name>
<first-name>Frederick J.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Texas Instruments Incorporated</orgname>
<role>02</role>
<address>
<city>Dallas</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Vicary</last-name>
<first-name>Keith</first-name>
<department>2183</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Disclosed herein is a system and method for executing a series of instructions on a circuit. The system comprises an encoder that receives event data corresponding to the executed instructions. The encoder groups the event data into one or more groups and outputs the highest priority event for each such group.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="112.95mm" wi="180.93mm" file="US08627049-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="269.49mm" wi="197.61mm" file="US08627049-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="271.86mm" wi="200.74mm" file="US08627049-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="251.63mm" wi="166.88mm" file="US08627049-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="248.07mm" wi="162.64mm" file="US08627049-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="249.68mm" wi="159.09mm" file="US08627049-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims the benefit of U.S. Provisional Application Ser. No. 60/681,551, filed May 16, 2005, titled &#x201c;Emulation/Debugging with Real-Time System Control,&#x201d; and U.S. Provisional Application Ser. No. 60/681,427, filed May 16, 2005, titled &#x201c;Debugging Software-Controlled Cache Coherence,&#x201d; both of which are incorporated by reference herein as if reproduced in full below.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0003" num="0002">This application also may contain subject matter that may relate to the following commonly assigned co-pending applications incorporated herein by reference: &#x201c;Real-Time Monitoring, Alignment, and Translation of CPU Stalls or Events,&#x201d; Ser. No. 11/383,361, filed May 15, 2006, &#x201c;Event and Stall Selection,&#x201d; Ser. No. 11/383,389, filed May 15, 2006, &#x201c;Watermark Counter With Reload Register,&#x201d; Ser. No. 11/383,464, filed May 15, 2006, &#x201c;Method of Translating System Events Into Signals For Activity Monitoring,&#x201d; Ser. No. 11/383,466, filed May 15, 2006, &#x201c;System and Methods For Stall Monitoring,&#x201d; Ser. No. 11/383,472, filed May 15, 2006, &#x201c;Monitoring of Memory and External Events,&#x201d; Ser. No. 11/383,473, filed May 15, 2006, &#x201c;Event-Generating Instructions,&#x201d; Ser. No. 11/383,433, filed May 15, 2006, and &#x201c;Selectively Embedding Event-Generating Instructions,&#x201d; Ser. No. 11/383,438, filed May 15, 2006.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">Integrated circuits are ubiquitous in society and can be found in a wide array of electronic products. Regardless of the type of electronic product, most consumers have come to expect greater functionality when each successive generation of electronic products are made available because successive generations of integrated circuits offer greater functionality such as faster memory or microprocessor speed. Moreover, successive generations of integrated circuits that are capable of offering greater functionality are often available relatively quickly. For example, Moore's law, which is based on empirical observations, predicts that the speed of these integrated circuits doubles every eighteen months. As a result, integrated circuits with faster microprocessors and memory are often available for use in the latest electronic products every eighteen months.</p>
<p id="p-0005" num="0004">Although successive generations of integrated circuits with greater functionality and features may be available every eighteen months, this does not mean that they can then be quickly incorporated into the latest electronic products. In fact, one major hurdle in bringing electronic products to market is ensuring that the integrated circuits, with their increased features and functionality, perform as desired. Generally speaking, ensuring that the integrated circuits will perform their intended functions when incorporated into an electronic product is called &#x201c;debugging&#x201d; the electronic product. Also, determining the performance, resource utilization, and execution of the integrated circuit is often referred to as &#x201c;profiling&#x201d;. Profiling is used to modify code execution on the integrated circuit so as to change the behavior of the integrated circuit as desired. The amount of time that debugging and profiling takes varies based on the complexity of the electronic product. One risk associated with the process of debugging and profiling is that it delays the product from being introduced into the market.</p>
<p id="p-0006" num="0005">To prevent delaying the electronic product because of delay from debugging and profiling the integrated circuits, software based simulators that model the behavior of the integrated circuit are often developed so that debugging and profiling can begin before the integrated circuit is actually available. While these simulators may have been adequate in debugging and profiling previous generations of integrated circuits, such simulators are increasingly unable to accurately model the intricacies of newer generations of integrated circuits. Further, attempting to develop a more complex simulator that copes with the intricacies of integrated circuits with cache memory takes time and is usually not an option because of the preferred short time-to-market of electronic products. Unfortunately, a simulator's inability to effectively model integrated circuits results in the integrated circuits being employed in the electronic products without being debugged and profiled fully to make the integrated circuit behave as desired.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0007" num="0006">Disclosed herein is a system and method for executing a series of instructions on a circuit. An encoder receives event data corresponding to the executed instructions, wherein the encoder groups the event data into one or more groups and outputs the highest priority event for each group.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007">For a detailed description of exemplary embodiments of the invention, reference will now be made to the accompanying drawings in which:</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> depicts an exemplary debugging and profiling system in accordance with a preferred embodiment of the invention;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> depicts an embodiment of circuitry where code is being debugged and profiled using a trace;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref> depicts a preferred embodiment of circuitry where code is being debugged and profiled using a trace;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 4</figref> depicts an example of an implementation of an event encoder;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 5</figref> depicts a preferred implementation of a priority encoder;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 6</figref> depicts the inputs and outputs of a logical group <b>500</b>;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 7A</figref> depicts an implementation of any of the groups shown in <figref idref="DRAWINGS">FIG. 5</figref> for prioritizing the input events;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 7B</figref> depicts an example of the operation of <figref idref="DRAWINGS">FIG. 7A</figref>; and</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 7C</figref> depicts an example of the operation of <figref idref="DRAWINGS">FIG. 7A</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> depicts an exemplary debugging and profiling system <b>100</b> including a host computer <b>105</b> coupled to a target device <b>110</b> through a connection <b>115</b>. A user may debug and profile the operation of the target device <b>110</b> by operating the host computer <b>105</b>. The target device <b>110</b> may be debugged and profiled in order for the operation of the target device <b>110</b> to perform as desired (for example, in an optimal manner) with circuitry <b>145</b>. To this end, the host computer <b>105</b> may include an input device <b>120</b>, such as a keyboard or mouse, as well as an output device <b>125</b>, such as a monitor or printer. Both the input device <b>120</b> and the output device <b>125</b> couple to a central processing unit <b>130</b> (CPU) that is capable of receiving commands from a user and executing software <b>135</b> accordingly. Software <b>135</b> interacts with the target <b>110</b> and may allow the debugging and profiling of applications that are being executed on the target <b>110</b>.</p>
<p id="p-0019" num="0018">Connection <b>115</b> couples the host computer <b>105</b> and the target device <b>110</b> and may be a wireless, hard-wired, or optical connection. Interfaces <b>140</b>A and <b>140</b>B may be used to interpret data from or communicate data to connection <b>115</b> respectively according to any suitable data communication method. Connection <b>150</b> provides outputs from the circuitry <b>145</b> to interface <b>140</b>B. As such, software <b>135</b> on host computer <b>105</b> communicates instructions to be implemented by circuitry <b>145</b> through interfaces <b>140</b>A and <b>140</b>B across connection <b>115</b>. The results of how circuitry <b>145</b> implements the instructions is output through connection <b>150</b> and communicated back to host computer <b>105</b>. These results are analyzed on host computer <b>105</b> and the instructions are modified so as to debug and profile applications to be executed on target <b>110</b> by circuitry <b>145</b>.</p>
<p id="p-0020" num="0019">Connection <b>150</b> may be a wireless, hard-wired, or optical connection. In the case of a hard-wired connection, connection <b>150</b> is preferably implemented in accordance with any suitable protocol such as a Joint Testing Action Group (JTAG) type of connection. Additionally, hard-wired connections may include a real time data exchange (RTDX) type of connection developed by Texas instruments, Inc. Briefly put, RTDX gives system developers continuous real-time visibility into the applications that are being implemented on the circuitry <b>145</b> instead of having to force the application to stop, via a breakpoint, in order to see the details of the application implementation. Both the circuitry <b>145</b> and the interface <b>140</b>B may include interfacing circuitry to facilitate the implementation of JTAG, RTDX, or other interfacing standards.</p>
<p id="p-0021" num="0020">The target <b>110</b> preferably includes the circuitry <b>145</b> executing code that is actively being debugged and profiled. In some embodiments, the target <b>110</b> may be a test fixture that accommodates the circuitry <b>145</b> when code being executed by the circuitry <b>145</b> is being debugged and profiled. The debugging and profiling may be completed prior to widespread deployment of the circuitry <b>145</b>. For example, if the circuitry <b>145</b> is eventually used in cell phones, then the executable code may be designed using the target <b>110</b>.</p>
<p id="p-0022" num="0021">The circuitry <b>145</b> may include a single integrated circuit or multiple integrated circuits that will be implemented as part of an electronic device. For example, the circuitry <b>145</b> may include multi-chip modules comprising multiple separate integrated circuits that are encapsulated within the same packaging. Regardless of whether the circuitry <b>145</b> is implemented as a single-chip or multiple-chip module, the circuitry <b>145</b> may eventually be incorporated into an electronic device such as a cellular telephone, a portable gaming console, network routing equipment, etc.</p>
<p id="p-0023" num="0022">Debugging and profiling the executable firmware code on the target <b>110</b> using breakpoints to see the details of the code execution is an intrusive process and affects the operation and performance of the code being executed on circuitry <b>145</b>. As such, a true understanding of the operation and performance of the code execution on circuitry <b>145</b> is not gained through the use of breakpoints.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 2</figref> depicts an embodiment of circuitry <b>145</b> where code is being debugged and profiled using a trace on circuitry <b>145</b> to monitor events. Circuitry <b>145</b> includes a processor <b>200</b> which executes the code. Through the operation of the processor <b>200</b> many events <b>205</b> may occur that are significant for debugging and profiling the code being executed by the processor <b>200</b>. The term &#x201c;events&#x201d; or &#x201c;event data&#x201d; herein is being used broadly to describe any type of stall in which processor <b>200</b> is forced to wait before it can complete executing an instruction, such as a CPU stall or cache stall; any type of memory event, such as a read hit or read miss; and any other occurrences which may be useful for debugging and profiling the code being executed on circuitry <b>145</b>. The internal trace memory <b>210</b> records the events <b>205</b> as event data and outputs the event data through connection <b>150</b> to computer <b>105</b>. This enables a user of the computer <b>105</b> to see how the execution of the code is being implemented on circuitry <b>145</b>.</p>
<p id="p-0025" num="0024">As successive generations of processors are developed with faster speeds, the number of events occurring on a processor such as processor <b>200</b> similarly increases, however, the bandwidth between computer <b>105</b> and circuitry <b>145</b> through connection <b>150</b> is limited. The amount of event data <b>205</b> recorded using a trace may exceed the bandwidth of connection <b>150</b>. As such, for this solution to be implemented a trace may only be run for a very limited amount of time so as to not fill up internal trace memory <b>210</b>. This situation is analogous to a sink that drains much less water than the faucet is putting into the sink. In order to prevent the sink from overflowing the faucet may only be turned on for a limited amount of time. This solution of only running the trace for a very short time may not be preferable since it would give a very limited view of the execution of the code on circuitry <b>145</b>. Alternatively, internal trace memory <b>210</b> may be very large so as to accommodate the large amount of event data. This may not be preferable either, since trace memory <b>210</b> would then take up a large area on circuitry <b>145</b> and consume more power.</p>
<p id="p-0026" num="0025">As such, intelligent ways of reducing the amount of event data without losing any or much information are desirable. <figref idref="DRAWINGS">FIG. 3</figref> discloses another embodiment of circuitry <b>145</b> where code is being debugged and profiled using a trace on circuitry <b>145</b> to monitor events. Circuitry <b>145</b> includes a processor core <b>300</b> which executes the code. Processor <b>300</b> interacts with memory controller <b>320</b> in order to input data and instructions from various levels of a memory subsystem and output data manipulated according to the instructions. The memory subsystem may include an L1 cache memory <b>305</b>, which may be divided into a program portion of L1 cache and a data portion of L1 cache; an L2 cache memory <b>310</b>, which may be larger and slower than the L1 cache memory; and an external memory <b>315</b>, which may be a random access memory (RAM), or any other suitable external storage. Through executing the code, stalls may occur in the processor core <b>300</b> wherein stall signals indicating that these stalls occurred are output from processor core <b>300</b> to event encoder <b>340</b> through connection <b>325</b>. Stalls occur when the processor core <b>300</b> is forced to wait before it can complete executing an instruction. Stalls can occur for a wide variety of reasons, for example if the processor core <b>300</b> has to wait while a data element is being fetched or if the processor core <b>300</b> has to wait while an area in cache is being freed up to write the result of an instruction.</p>
<p id="p-0027" num="0026">Memory controller <b>320</b> outputs memory events <b>330</b> to event encoder <b>340</b>. Memory events can also occur for a wide variety of reasons, for example a read hit on the L1 cache <b>305</b> or a read miss on the L1 cache <b>305</b>. Note that certain memory events <b>330</b> may also cause a stall, but not all memory events cause a stall. For example a read miss on the L1 cache <b>305</b> will also cause a stall until the data that is needed is forwarded to the L1 cache <b>305</b>. A read hit is an example of a memory event that would not cause a stall.</p>
<p id="p-0028" num="0027">External events <b>335</b> may also be input to event encoder <b>340</b>. External events <b>335</b> may include interrupt routines executed on processor core <b>300</b> for interacting with external devices. Monitoring these external events enables a user of computer <b>105</b> for example to determine the real-time deadlines for executing the interrupt routines. Event encoder <b>340</b> combines and/or selectively outputs the various event data to computer <b>105</b> through connection <b>150</b>. The encoded event data that is sent to computer <b>105</b> is decoded and interpreted in order to enable a user on computer <b>105</b> to debug and profile the execution of code on circuitry <b>145</b>. Related application U.S. Ser. No. 11/383,466, filed May 15, 2006, &#x201c;Method of Translating System Events into Signals for Activity Monitoring&#x201d;, by Swoboda et al. details an exemplary process for decoding the event data on computer <b>105</b>. The content of the above referenced application is herein incorporated by reference in its entirety.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 4</figref> depicts an example of an implementation of event encoder <b>340</b>. Event encoder <b>340</b> includes alignment blocks <b>400</b> and <b>405</b>, a stall priority encoder <b>410</b>, an event translator <b>415</b>, a selector <b>420</b>, and a data encoder <b>425</b>. In the embodiment of <figref idref="DRAWINGS">FIG. 4</figref>, alignment blocks <b>400</b> and <b>405</b> are used for aligning an event to the instruction where the event occurred. Such alignment enables a causal relationship to be determined between code execution and the stalls or events of interest. Priority encoder <b>410</b> is used to prioritize groups of stalls for cases where multiple stalls occur simultaneously. In at least one embodiment, only the stall with the highest priority in a particular group is output. Translator <b>415</b> is used to group events with common characteristics. Selector <b>420</b> selects one of the output from priority encoder <b>410</b>, the output from translator <b>415</b>, or the external event <b>335</b> input to be provided to encoder <b>425</b>. Encoder <b>425</b> combines or compresses the data selected by selector <b>420</b>. For example, encoder <b>425</b> may include one or more counters to count a number of events occurring within a particular time period. Related application U.S. Ser. No. 11/383,464, filed May 15, 2006, &#x201c;Watermark Counter with Reload Register&#x201d;, by Swoboda et al. details one such counter implementation. The content of the above referenced application is herein incorporated by reference in its entirety. Encoder <b>425</b> may also include standard bit reduction techniques such as Huffman Coding, or any other suitable bit reduction method. Related application U.S. Ser. No. 11/383,361, filed May 15, 2006, &#x201c;Real-Time Monitoring, Alignment, and Translation of CPU Stalls or Events&#x201d;, by Sohm et al. details an implementation of alignment blocks <b>400</b> or <b>405</b>. The content of the above referenced application is herein incorporated by reference in its entirety.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 5</figref> depicts an implementation of priority encoder <b>410</b>. In particular, for priority encoder <b>410</b>, the aligned stalls are organized into different logical groups <b>500</b> depending on the type of stall in order to set priorities for which stall to output if multiple stalls occur simultaneously. Some logical groups may include stalls caused by architectural delays (e.g., CPU architectural stalls), memory access conflicts (e.g., L1 cache stalls indicating a snoop conflict), memory access delays (e.g., L1 cache stalls indicating cache line fills), memory access ordering (e.g., L1 cache stalls indicating a write buffer flush on a read miss), or logical groups may be organized by any other category or algorithm. The logical groups may be mutually exclusive groups of stall or overlapping groups of stalls. Each logical group would output only one signal so as to communicate the highest priority event of that group. By grouping signals with common characteristics, the most important signal causing an event or stall may be identified and given precedence over any other stall or event occurring simultaneously. This gives added clarity to a developer by showing the root cause of a stall or event. By only outputting the highest priority event or stall for each logical group, less bandwidth is needed to communicate the event information that might otherwise be needed. In addition to bandwidth reduction benefits, by prioritizing the stalls, more meaning may be extracted from the stall signals.</p>
<p id="p-0031" num="0030">For example, if a read miss occurs then the dirty line in cache may be evicted and replaced with the desired data. This dirty line in cache is referred to as a victim and may be written back to a higher level in memory. As such, two stalls occur simultaneously. One stall indicating a read miss and another stall indicating a victim write-back. If both of these stall types are grouped together and the victim write-back stall is given a higher priority then each of these stalls will be seen as separate stalls. In particular, first the victim write-back stall would be asserted until the dirty line in cache is written back to a higher level in memory. If the victim write-back stall is being monitored then a determination can be made as to the efficiency of a victim write-back. When the victim write-back stall is no longer asserted the read miss stall would become visible until the data needed is written in the dirty line in cache. As such, instead of a read miss stall indicating the entire duration of the victim write-back and the time to fill the line in cache, by prioritizing the stalls the read miss gains a new meaning. In particular, the read miss stall indicates the duration of time to fill the line in cache, or a line fill stall. As such, by prioritizing groups of stalls new meaning and detail may be provided for each stall signal.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 6</figref> depicts the inputs and outputs from a logical group <b>500</b> of priority encoder <b>340</b> in the example above with a victim write-back stall and a read stall occurring simultaneously. As shown in <figref idref="DRAWINGS">FIG. 6</figref>, both stalls are initially asserted on the input of a logical group <b>500</b>. At time <b>6</b>-<b>1</b> the victim write-back stall is no longer asserted and only the read miss stall remains asserted. If the victim write-back stall is given higher priority than the read miss stall then initially the output of the logical group <b>500</b> is asserted for the victim write-back stall. Note that the read miss stall is masked at the output since it has a lower priority and only the highest priority stall signal is output at any one time. As such, at time <b>6</b>-<b>1</b> the victim write-back stall is no longer asserted a line fill stall is determined to be the highest priority stall signal and as such is output from the logical group <b>500</b>. Note that as described in the example above, the read miss stall takes on new meaning to indicate a line fill stall. Since only the highest priority event is asserted at the output of each logical group <b>500</b>, then any other lower priority events are not double-counted.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 7A</figref> depicts a priority encoder implementation of any logical group <b>500</b>. <figref idref="DRAWINGS">FIG. 7A</figref> includes a series of logic blocks <b>700</b> where the output from one block is provided as an input to the next. The logic block <b>700</b> at the top has the highest priority and the logic block <b>700</b> at the bottom has the lowest priority. Each logic block <b>700</b> outputs a logical combination of inputs such that if multiple events occur simultaneously, only the highest priority event is visible on the output. In a preferred embodiment, each logic block <b>700</b> includes two AND gates <b>705</b> and <b>710</b> as well as an inverter <b>715</b>. An AND gate produces a logical ANDing of the inputs to the AND gate. An inverter produces a logical inversion of the input to the inverter. In particular, a logical &#x201c;1&#x201d; value is input to both AND gates <b>705</b> and <b>710</b> of the first logic block <b>700</b>. AND gate <b>705</b> also receives an input from the highest priority event signal. The highest priority event signal indicates whether or not the highest priority event has occurred. A logical &#x201c;1&#x201d; would be input to AND gate <b>705</b> if the event occurred and a logical &#x201c;0&#x201d; would be input to AND gate <b>705</b> if the event did not occur. As such, the first logic block <b>700</b> will output a value of &#x201c;0&#x201d; if the input from the highest priority event signal is &#x201c;0&#x201d; since the logical ANDing of a &#x201c;0&#x201d; and a &#x201c;1&#x201d; produces a &#x201c;0&#x201d;. Logic block <b>700</b> would produce a value of &#x201c;1&#x201d; if the input from the highest priority event signal is &#x201c;1&#x201d; since the logical ANDing of a &#x201c;1&#x201d; and a &#x201c;1&#x201d; produces a &#x201c;1&#x201d;. An inverter <b>715</b> inverts whatever signal is output from AND gate <b>705</b> and inputs the result as another input to AND gate <b>710</b>. The output from AND gate <b>710</b> from the first logic block <b>700</b> is fed into the inputs of AND gates <b>705</b> and <b>710</b> for the next logic block <b>700</b>. Each successive logic block <b>700</b> receives one input from the next lowest priority event signal and another input from the output of AND gate <b>710</b> from the previous logic block <b>700</b>. For the lowest priority event signal a simple AND gate <b>720</b> is used to logically AND the values from the lowest priority event signal and the output of AND gate <b>710</b> from the previous logic block <b>700</b>. <figref idref="DRAWINGS">FIGS. 7B and 7C</figref> illustrate the operation of the operation of the priority encoder.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 7B</figref> depicts the operation of the priority encoder where the highest priority event is occurring simultaneously with third priority event. As illustrated, AND gate <b>705</b> produces a &#x201c;1&#x201d; output because of the two &#x201c;1&#x201d; inputs. Inverter <b>715</b> inverts the &#x201c;1&#x201d; output from AND gate <b>705</b> to produce a &#x201c;0&#x201d; input for AND gate <b>710</b>, therefore AND gate <b>710</b> produces a &#x201c;0&#x201d; output to the second logic block <b>700</b>. Both AND gates <b>705</b> and <b>710</b> for the second logic block receive the &#x201c;0&#x201d; input and therefore in turn produce a &#x201c;0&#x201d; output. The &#x201c;0&#x201d; output from AND gate <b>710</b> in the second logic block is input to the third logic block. Similarly, Both AND gates <b>705</b> and <b>710</b> for the third logic block receive the &#x201c;0&#x201d; input and therefore in turn produce a &#x201c;0&#x201d; output. Note that even though a &#x201c;1&#x201d; is input from the third priority event signal, the logical ANDing of a &#x201c;0&#x201d; and a &#x201c;1&#x201d; produces a &#x201c;0&#x201d;. As such, the event occurring on the third priority event signal is masked by the higher priority event occurring on the highest priority event signal. The &#x201c;0&#x201d; output from AND gate <b>710</b> in the third logic block is fed into AND gate <b>720</b> to also produce a &#x201c;0&#x201d; output.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 7C</figref> depicts the operation of the priority encoder where the second priority event is occurring simultaneously with third priority event. As illustrated, AND gate <b>705</b> produces a &#x201c;0&#x201d; output because of the &#x201c;0&#x201d; input from the highest priority event signal. Inverter <b>715</b> inverts the &#x201c;0&#x201d; output from AND gate <b>705</b> to produce a &#x201c;1&#x201d; input for AND gate <b>710</b>, therefore AND gate <b>710</b> produces a &#x201c;1&#x201d; output to the second logic block <b>700</b>. Both AND gates <b>705</b> and <b>710</b> for the second logic block receive the &#x201c;1&#x201d; input. AND gate <b>705</b> for the second logic block <b>700</b> produces a &#x201c;1&#x201d; output because of the two &#x201c;1&#x201d; inputs. Inverter <b>715</b> for the second logic block <b>700</b> inverts the &#x201c;1&#x201d; output from AND gate <b>705</b> to produce a &#x201c;0&#x201d; input for AND gate <b>710</b> of the second logic block <b>700</b>, therefore AND gate <b>710</b> produces a &#x201c;0&#x201d; output to the third logic block <b>700</b>. The &#x201c;0&#x201d; output from AND gate <b>710</b> in the second logic block is input to the third logic block. Both AND gates <b>705</b> and <b>710</b> for the third logic block receive the &#x201c;0&#x201d; input and therefore in turn produce a &#x201c;0&#x201d; output. Note that even though a &#x201c;1&#x201d; is input from the third priority event signal, the logical ANDing of a &#x201c;0&#x201d; and a &#x201c;1&#x201d; produces a &#x201c;0&#x201d;. As such, the event occurring on the third priority event signal is masked by the higher priority event occurring on the second priority event signal. The &#x201c;0&#x201d; output from AND gate <b>710</b> in the third logic block is fed into AND gate <b>720</b> to also produce a &#x201c;0&#x201d; output. As such, the priority encoder only outputs the highest priority event if multiple events in a group occur simultaneously. Since only the highest priority event is asserted then any other lower priority events are not double-counted.</p>
<p id="p-0036" num="0035">Disclosed above is a system and method of tracing a group of processor events in real-time in order to enable a programmer to debug and profile the operation and execution of code on the processor. The events are fed into an event encoder where they are grouped together and prioritized where the highest priority event for each group is output.</p>
<p id="p-0037" num="0036">While various system and method embodiments have been shown and described herein, it should be understood that the disclosed systems and methods may be embodied in many other specific forms without departing from the spirit or scope of the invention. The present examples are to be considered as illustrative and not restrictive. The intention is not to be limited to the details given herein, but may be modified within the scope of the appended claims along with their full scope of equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system comprising:
<claim-text>a circuit configured to execute a series of instructions, said circuit including a cache memory, said cache memory generating a cache miss stall triggered upon a read miss into said cache memory and a corresponding victim eviction stall triggered if said cache miss stall causes a writeback of a dirty cache entry to be replaced with new data in said cache memory; and</claim-text>
<claim-text>an encoder configured to receive event data corresponding to the executed series of instructions, said event data describes at least processor stalls including said cache miss stall and said victim eviction stall, said encoder grouping the received event data into a plurality of groups, outputting a highest priority event for each group as prioritized event data and providing said highest priority event of each group to a computer external to said system, said encoder grouping said cache miss stall and said corresponding victim eviction stall into one of said plurality of groups and assigning a lower priority to said cache miss stall than to said corresponding victim eviction stall.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A method comprising:
<claim-text>executing a series of instructions in a target device; and</claim-text>
<claim-text>encoding event data corresponding to the executed series of instructions, said event data describing at least processor stalls including a cache miss stall triggered upon a read miss into a cache memory and a corresponding victim eviction stall triggered if said cache miss stall causes a writeback of a dirty cache entry to be replaced with new data in the cache memory;</claim-text>
<claim-text>said encoding step including grouping event data into a plurality of groups and outputting a highest priority event for each group as prioritized event data;</claim-text>
<claim-text>said encoding step further including grouping said cache miss stall and said corresponding victim eviction stall into one of said plurality of groups and assigning a higher priority to said corresponding victim eviction stall than to said cache miss stall; and</claim-text>
<claim-text>transmitting said highest priority event of each group to a computer external to said target device. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
