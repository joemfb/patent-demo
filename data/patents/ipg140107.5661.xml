<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626762-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626762</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12732511</doc-number>
<date>20100326</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2009-0086507</doc-number>
<date>20090914</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>319</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>30</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>048</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>707736</main-classification>
<further-classification>707796</further-classification>
<further-classification>707805</further-classification>
<further-classification>707E1703</further-classification>
<further-classification>715838</further-classification>
<further-classification>715848</further-classification>
</classification-national>
<invention-title id="d2e71">Display apparatus and method of providing a user interface</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6121969</doc-number>
<kind>A</kind>
<name>Jain et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715850</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6281898</doc-number>
<kind>B1</kind>
<name>Nikolovska et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6356971</doc-number>
<kind>B1</kind>
<name>Katz et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710301</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7046230</doc-number>
<kind>B2</kind>
<name>Zadesky et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7479949</doc-number>
<kind>B2</kind>
<name>Jobs et al.</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7698658</doc-number>
<kind>B2</kind>
<name>Ohwa et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>8493408</doc-number>
<kind>B2</kind>
<name>Williamson et al.</name>
<date>20130700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345629</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2005/0210410</doc-number>
<kind>A1</kind>
<name>Ohwa et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2011/0154196</doc-number>
<kind>A1</kind>
<name>Icho et al.</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715702</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>10-260671</doc-number>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>KR</country>
<doc-number>112006004447</doc-number>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>KR</country>
<doc-number>1020090043752</doc-number>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Apple Inc., &#x201c;iPod touch User Guide&#x201d; manual, pp. 1-122, 2008.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Apple Inc., &#x201c;iPhone User Guide for iPhone OS 3.1 Software&#x201d; manual, 2009, pp. 1-217.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Christoffer Bjorkskog et al., &#x201c;Mobile Implementation of a Web 3D Carousel With Touch Input&#x201d;, MobileHCI'09 Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services, 2009, pp. 1-4.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Su Lee Hyeon and A Sung Jeong, &#x201c;Method for providing User Interface and display apparatus applying the same&#x201d;, Sep. 14, 2009, The Korean Intellectual Property Office (KR), application No. 10-2009-0086507.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Korean Office Action dated Sep. 30, 2013 issued in KR Application 10-2009-0086507.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>24</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>707722</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707736</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707802</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707796</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707804</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707805</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715838</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715848</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>22</number-of-drawing-sheets>
<number-of-figures>25</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110066627</doc-number>
<kind>A1</kind>
<date>20110317</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Seung</last-name>
<first-name>Jung-ah</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yoo</last-name>
<first-name>Yun-ji</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Seung</last-name>
<first-name>Jung-ah</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Yoo</last-name>
<first-name>Yun-ji</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Stanzione &#x26; Kim, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>SAMSUNG Electronics Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lewis</last-name>
<first-name>Cheryl</first-name>
<department>2155</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method of providing a user interface (UI) and a display apparatus having the same. In a method for providing a UI, a display apparatus receives an manipulation for two or more axis directions, and searches for one of a plurality of images by applying two or more different classification standards according to the directions of the received input manipulation. Therefore, the user may easily search for a desired image using one or more classification standards.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="203.20mm" wi="153.84mm" file="US08626762-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="143.51mm" wi="156.97mm" file="US08626762-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="230.04mm" wi="168.57mm" file="US08626762-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="128.78mm" wi="85.26mm" file="US08626762-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="182.03mm" wi="171.70mm" file="US08626762-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="119.04mm" wi="158.75mm" file="US08626762-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="137.75mm" wi="169.16mm" file="US08626762-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="135.81mm" wi="174.67mm" file="US08626762-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="139.02mm" wi="182.63mm" file="US08626762-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="130.05mm" wi="185.84mm" file="US08626762-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="141.65mm" wi="171.62mm" file="US08626762-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="136.48mm" wi="174.07mm" file="US08626762-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="167.89mm" wi="172.21mm" file="US08626762-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="133.27mm" wi="172.04mm" file="US08626762-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="142.16mm" wi="171.53mm" file="US08626762-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="134.45mm" wi="177.46mm" file="US08626762-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="163.41mm" wi="169.25mm" file="US08626762-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="138.94mm" wi="174.07mm" file="US08626762-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="219.79mm" wi="143.51mm" file="US08626762-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="228.09mm" wi="139.02mm" file="US08626762-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="223.01mm" wi="158.24mm" file="US08626762-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="117.26mm" wi="124.97mm" file="US08626762-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="228.09mm" wi="173.65mm" file="US08626762-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims priority under 35 U.S.C. &#xa7;119(a) from Korean Patent Application No. 10-2009-0086507, filed on Sep. 14, 2009, in the Korean Intellectual Property Office, the disclosure of which is incorporated herein by reference in its entirety.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present general inventive concept relates to a method of providing a user interface (UI), and a display apparatus adopting the same. More particularly, the present general inventive concept relates to a method of providing a UI to search for a desired image from among stored images, and a display apparatus adopting the same.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">As technology has been developing, the storage capability of display apparatuses has enhanced. Accordingly, a user may store a large number of images in a display apparatus.</p>
<p id="p-0007" num="0006">If a large number of images are stored in a display apparatus, it takes a long time to search for a desired image. Even after the user searches for a desired image, the user typically searches other images stored in the display apparatus through many procedures in order to find another desired image related to the found image.</p>
<p id="p-0008" num="0007">In particular, since most display apparatuses are designed to search for an image based on a single classification standard, the user generally views images arranged according to the single classification standard and selects a desired image. In order to change the classification standard, the user typically must perform a separate operation of changing settings of a display apparatus, causing inconvenience to the user.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0009" num="0008">Users of display apparatus wish to search for images with greater ease and convenience. Therefore, there is a need for a method of providing a UI to received user input to easily search for an image with a plurality of classification standards.</p>
<p id="p-0010" num="0009">The present general inventive concept provides a method of providing a user interface (UI) in which a manipulation for two or more axis directions is input and two or more classification standards are applied according to the direction in which the manipulation is input so that one of the images may be found, and a display apparatus adopting the same.</p>
<p id="p-0011" num="0010">Additional aspects and utilities of the present general inventive concept will be set forth in part in the description which follows and, in part, will be obvious from the description, or may be learned by practice of the general inventive concept.</p>
<p id="p-0012" num="0011">The foregoing and/or other features and utilities of the present general inventive concept may be achieved by providing a method of providing a user interface (UI), the method including receiving an input manipulation for two or more axis directions, and searching for one of a plurality of images by applying two or more different classification standards according to the directions of the received input manipulation.</p>
<p id="p-0013" num="0012">The two or more axis directions may include a first axis direction, a second axis direction, and a third axis direction, the two or more classification standards may include a first classification standard, a second classification standard, and a third classification standard, and the searching for one of the plurality of images may include searching for an image according to the first classification standard when the received input manipulation is in the first axis direction, searching for an image according to the second classification standard when the received input manipulation is in the second axis direction, and searching for an image according to the third classification standard when the received input manipulation is in the third axis direction.</p>
<p id="p-0014" num="0013">On a display, the first axis direction may be a horizontal direction, the second axis direction may be a vertical direction, and the third axis direction may be a diagonal direction.</p>
<p id="p-0015" num="0014">The first classification standard, the second classification standard, and the third classification standard each may correspond to one of time, person, place, color, event, and type of scene.</p>
<p id="p-0016" num="0015">The received input manipulation may be a short stroke or a long stroke, and the searching for the image according to the first classification standard may include searching for a previous image or a subsequent image according to the first classification standard when the short stroke of the received input manipulation is in the first axis direction, and searching for an image in a different category according to the first classification standard when the long stroke of the received input manipulation is in the first axis direction.</p>
<p id="p-0017" num="0016">The received input manipulation may be a short stroke or a long stroke, and the searching for the image according to the second classification standard may include searching for a previous image or a subsequent image according to the second classification standard when the short stroke of the received input manipulation is in the second axis direction, and searching for an image in a different category according to the second classification standard when the long stroke of the received input manipulation is in the second axis direction.</p>
<p id="p-0018" num="0017">If a currently searched image changes, the plurality of images may be rearranged according to the first, second and third classification standard according to the changed image.</p>
<p id="p-0019" num="0018">The method may further include displaying thumbnails of images classified according to the first classification standard in an x-axis direction in a 3-dimensional space of a display, displaying thumbnails of images classified according to the second classification standard in an y-axis direction in the 3-dimensional space of the display, and displaying thumbnails of images classified according to the third classification standard in a z-axis direction in the 3-dimensional space of the display.</p>
<p id="p-0020" num="0019">The method may further include displaying only a currently searched image on a display from among the plurality of images to be searched.</p>
<p id="p-0021" num="0020">Exemplary embodiments of the present general inventive concept may also be achieved by providing a display apparatus including a storage unit to store a plurality of images, a manipulation unit to receive an input manipulation in two or more axis directions, and a control unit to searching for one of the plurality of images by applying two or more different classification standards according to the received input manipulation.</p>
<p id="p-0022" num="0021">The two or more axis directions may include a first axis direction, a second axis direction, and a third axis direction, the two or more classification standards may include a first classification standard, a second classification standard, and a third classification standard, and the control unit may search for an image according to the first classification standard when the received input manipulation is in the first axis direction, the control unit may search for an image according to the second classification standard when the received input manipulation is in the second axis direction, and the control unit may search for an image according to the third classification standard when the received manipulation is in the third axis direction.</p>
<p id="p-0023" num="0022">On a display, the first axis direction may be a horizontal direction, the second axis direction may be a vertical direction, and the third axis direction may be a diagonal direction.</p>
<p id="p-0024" num="0023">The first classification standard, the second classification standard, and the third classification standard each may correspond to one of time, person, place, color, event, and type of scene.</p>
<p id="p-0025" num="0024">The received input manipulation may be a short stroke or a long stroke, and the control unit may search for a previous image or a subsequent image according to the first classification standard when the short stroke of the received input manipulation is in the first axis direction, and the control unit may search for an image in a different category according to the first classification standard when the long stroke of the received input manipulation is in the first axis direction.</p>
<p id="p-0026" num="0025">The received input manipulation may be a short stroke or a long stroke, and the control unit may search for a previous image or a subsequent image according to the second classification standard when the short stroke of the received input manipulation is in the second axis direction, and the control unit may search for an image in a different category according to the second classification standard when the long stroke of the received input manipulation is in the second axis direction.</p>
<p id="p-0027" num="0026">When a currently searched image changes, the control unit may rearrange the plurality of images according to the first, second and third classification standard according to the changed image.</p>
<p id="p-0028" num="0027">The control unit may display thumbnails of images classified according to the first classification standard in an x-axis direction in a 3-dimensional space of a display, the control unit may display thumbnails of images classified according to the second classification standard in an y-axis direction in the 3-dimensional space of the display, and the control unit may display thumbnails of images classified according to the third classification standard in a z-axis direction in the 3-dimensional space of the display.</p>
<p id="p-0029" num="0028">The control unit may display only a currently searched image on a display from among the plurality of images to be searched.</p>
<p id="p-0030" num="0029">Exemplary embodiments of the present general inventive concept may also be achieved by providing a method of providing a user interface (UI), the method including displaying thumbnails of images classified according to a first classification standard in a first axis direction in a 3-dimensional space of a display, displaying thumbnails of images classified according to a second classification standard in a second axis direction in the 3-dimensional space of the display, and displaying thumbnails of images classified according to a third classification standard in a third axis direction in the 3-dimensional space of the display.</p>
<p id="p-0031" num="0030">Exemplary embodiments of the present general inventive concept may be achieved by providing a method of providing a user interface (UI), the method including searching for content according to a first classification standard when an input manipulation in a first axis direction is received, searching for content according to a second classification standard when an input manipulation in a second axis direction is received, and searching for content according to a third classification standard when an input manipulation in a third axis direction is received.</p>
<p id="p-0032" num="0031">The content may be music, the first classification standard may be a genre, the second classification standard may be a singer, and the third classification standard may be an album.</p>
<p id="p-0033" num="0032">Exemplary embodiments of the present general inventive concept also include a method of searching for stored content with a graphical user interface of a display apparatus, the method including receiving an input manipulation from the graphical user interface of the display apparatus in a plurality of axis directions to select a classification of the content to be searched, and searching for stored content in a storage unit of a display apparatus according to the received input manipulation.</p>
<p id="p-0034" num="0033">The method may also include receiving a selection a type of the stored content with the graphical user interface of the display apparatus.</p>
<p id="p-0035" num="0034">The method may also include where each axis of the plurality of axis directions is a different classification of the content.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0036" num="0035">These and/or other features and utilities of the present general inventive concept will become apparent and more readily appreciated from the following description of the embodiments, taken in conjunction with the accompanying drawings of which:</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 1</figref> is a detailed block diagram illustrating a configuration of a camera according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart illustrating a method of providing a UI according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> illustrate arranged images according to classification standards corresponding to three axis directions according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a screen displaying an image search menu in a thumbnail view mode according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIGS. 5A and 5B</figref> illustrate that a short stroke to the right is received as input according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> illustrate that a long stroke to the right is received as input according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. 7A and 7B</figref> illustrate that a short stroke downwards is received as input according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. 8A and 8B</figref> illustrate that a long stroke downwards is received as input according to an exemplary embodiment of the present general inventive concept;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIGS. 9A and 9B</figref> illustrate that a short stroke in a diagonal down direction is received as input according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIGS. 10A and 10B</figref> illustrate that a long stroke in a diagonal down direction is received as input according to an exemplary embodiment of the present general inventive concept;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. 11A to 11F</figref> illustrate a process of operating an image search menu in a single view mode according to exemplary embodiments of the present general inventive concept;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 12</figref> illustrates a screen displaying a history of displayed images according to exemplary embodiments of the present general inventive concept; and</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 13</figref> illustrates that a plurality of music files in an MP3 player are arranged in three axis directions according to exemplary embodiments of the present general inventive concept.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE EMBODIMENTS</heading>
<p id="p-0050" num="0049">Reference will now be made in detail to the present embodiments of the present general inventive concept, examples of which are illustrated in the accompanying drawings, wherein like reference numerals refer to like elements throughout. The embodiments are described below in order to explain the present general inventive concept by referring to the figures.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 1</figref> is a detailed block diagram illustrating a configuration of a camera <b>100</b> according to an exemplary embodiment of the present general inventive concept. As illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, the camera <b>100</b> may include a lens unit <b>110</b>, an image pickup device <b>120</b>, an image processing unit <b>130</b>, an image output unit <b>140</b>, a display <b>150</b>, a codec <b>160</b>, a storage unit <b>165</b>, a manipulation unit <b>170</b>, a Global Positioning System (GPS) <b>180</b>, a face recognition unit <b>185</b>, and a control unit <b>190</b>.</p>
<p id="p-0052" num="0051">The lens unit <b>110</b> can focus light from a subject onto an image pickup area.</p>
<p id="p-0053" num="0052">The image pickup device <b>120</b> can convert light entering via a lens into an electric signal and can process the electric signal. That is, the image pickup device can capture the image of the subject. The image pickup device <b>120</b> may include pixels and an analog-to-digital (AD) converter. One or more pixels may output an analog image signal, and the AD converter can convert the analog image signal into a digital image signal.</p>
<p id="p-0054" num="0053">The image processing unit <b>130</b> can process an image signal input from the image pickup device <b>120</b>, and can transmit the processed image signal to the image output unit <b>140</b> to display a captured image. For example, the image processing unit <b>103</b> can sharpen, correct the white balance, remove and/or minimize motion blur, change and/or modify the color space, and/or compress the captured image. The image processing unit <b>130</b> can process an image signal input from the control unit <b>190</b>, and can transmit the processed image signal to the image output unit <b>140</b> to display a stored image or an image search menu.</p>
<p id="p-0055" num="0054">The image search menu includes a graphical user interface (GUI) to receive a selection from a user of a desired image from among the images stored in the storage unit <b>165</b>. The image search menu may be in one of a thumbnail view mode and a single view mode.</p>
<p id="p-0056" num="0055">In the thumbnail view mode, the image search menu can display thumbnails for a plurality of images in a 3-dimensional space in the x-axis, y-axis, and z-axis directions. The thumbnails displayed in the x-axis, y-axis, and z-axis directions are thumbnails for images arranged according to one or more classification standards. The classification standard indicates a standard to classify an image. More specifically, the classification standard may be, for example, one of time, person, place, color, event, and type of scene. For example, in an image search menu, thumbnails for images arranged according to a classification standard related to time (that is, arranged according to time at which images are captured) may be displayed in the x-axis direction, thumbnails for images arranged according to a classification standard related to person (that is, arranged according to person who is captured in a photograph) may be displayed in the y-axis direction, and thumbnails for images arranged according to classification standard related to place (that is, arranged according to place in which images are captured) may be displayed in the z-axis direction.</p>
<p id="p-0057" num="0056">In the single view mode, the image search menu can display a currently searched image from among the images to be searched.</p>
<p id="p-0058" num="0057">The image processing unit <b>130</b> can transmit an image signal processed to display such an image search menu to the image output unit <b>140</b>.</p>
<p id="p-0059" num="0058">The image processing unit <b>130</b> can output a processed image signal to the codec <b>160</b> so as to store a captured image. More specifically, the image processing unit <b>130</b> can convert a format of an image signal output by the image pickup device <b>120</b>, and can perform digital zooming, auto white balance (AWB), auto focus (AF), auto exposure (AE), and the like so as to adjust scale of the image.</p>
<p id="p-0060" num="0059">The image processing unit <b>130</b> can receive and process an image stored in the storage unit <b>165</b> using the codec <b>160</b>, and can output the processed image to the image output unit <b>140</b>.</p>
<p id="p-0061" num="0060">The image output unit <b>140</b> can output an image signal received from the image processing unit <b>130</b> to the internal display <b>150</b> or an external output terminal. A display device, a digital projector, a computer, a personal digital assistant (PDA), and/or any other suitable device may be connected to the external output terminal to receive the image from the image processing unit <b>130</b> to be displayed.</p>
<p id="p-0062" num="0061">The display <b>150</b> can display a captured image or an image search menu. The display <b>150</b> may display the image search menu in the thumbnail view mode or the single view mode, or any other suitable view mode to carry out the exemplary embodiments of the present general inventive concept.</p>
<p id="p-0063" num="0062">The codec <b>160</b> can encode an image received from the image processing unit <b>130</b> and transmit the encoded image to the storage unit <b>165</b>. The codec <b>160</b> can decode an image stored in the storage unit <b>190</b> and can transmit the decoded image to the image processing unit <b>130</b>.</p>
<p id="p-0064" num="0063">That is, when a captured image is stored in the storage unit <b>190</b>, the codec <b>160</b> can encode the image, and when a stored image is output to the image processing unit <b>130</b>, the codec <b>160</b> can decode the image.</p>
<p id="p-0065" num="0064">The storage unit <b>165</b> can store an image captured by the image pickup unit <b>120</b> in a compressed format, and can store information regarding the time at which the image is captured and information regarding the place in which the image is captured. The place information is generated can based on position information obtained by the GPS <b>180</b>, which may include at least one set of GPS coordinates of the place in which the image is captured, an address, and the name of the place.</p>
<p id="p-0066" num="0065">The storage unit <b>165</b> may be a flash memory, a hard disk, or the like.</p>
<p id="p-0067" num="0066">The manipulation unit <b>170</b> can receive a user command. More specifically, the manipulation unit <b>170</b> can receive a user command related to two or more axis directions (for example, a horizontal direction, a vertical direction, and a diagonal direction) such as the two or more axis directions illustrated in <figref idref="DRAWINGS">FIG. 3A</figref>.</p>
<p id="p-0068" num="0067">The manipulation unit <b>170</b> may be implemented as buttons on the surface of the camera <b>100</b>, or as a touch screen <b>175</b> capable of recognizing touch by the user on the display <b>150</b>.</p>
<p id="p-0069" num="0068">The GPS <b>180</b> can detect coordinate information of a current position using a satellite. The control unit <b>190</b> can match the coordinate information with a captured image.</p>
<p id="p-0070" num="0069">The face recognition unit <b>185</b> can recognize a human face from a captured image. More specifically, to recognize a human face, the face recognition unit <b>185</b> can detect a face from an image, and can recognize features of the face. The face recognition unit <b>185</b> can detect a face from an image by detecting an area including a face from an image. The face recognition unit <b>185</b> can recognize features of a face by differentiating the face from other faces.</p>
<p id="p-0071" num="0070">Detection of a face can be by a face area based on color, detection of an eye area based on at least one edge, normalization of the face area, and verification of the face area according to a support vector machine (SVM).</p>
<p id="p-0072" num="0071">Detection of a face area based on color can be performed by detecting a face from an input image using information regarding color of human skin. More specifically, to extract a face area, a skin filter can be generated using YCbCr information of the input image. That is, a skin-color area can be extracted from the input image.</p>
<p id="p-0073" num="0072">An eye area can be detected according to detected edges of an eye area using brightness. Generally, an eye area can be detected using edges and brightness, but there is a possibility that an error may occur due to hair style, eye glasses, and/or sunglasses.</p>
<p id="p-0074" num="0073">The face area can be normalized using the detected eye area. Using the SVM, the normalized face area can be verified. If a SVM face area detection device is used, the possibility of a wrong face area is detected is reduced to less than 1%.</p>
<p id="p-0075" num="0074">The face recognition unit <b>185</b> can detect a face from an image.</p>
<p id="p-0076" num="0075">There are at least two exemplary methods of recognizing features of face: a holistic approach and an analytic approach.</p>
<p id="p-0077" num="0076">The holistic approach can recognize a face by considering features of at least a portion of or the entire area of a face pattern, which includes an Eigenface method and a template matching-based method.</p>
<p id="p-0078" num="0077">The analytic approach can recognize a face by extracting geometrical features of face. An advantage of the analytic approach is fast recognition and minimized memory usage, but it may have decreased accuracy (e.g., in comparison with the accuracy of the holistic approach) in selecting and extracting features of a face.</p>
<p id="p-0079" num="0078">Recognizing features of face may include the following operations. The face recognition unit <b>185</b> can receive an image including a face, and can extract features of face such as eyes, nose, mouth, and the like. The face recognition unit <b>185</b> can perform at least one adjustment if the face is rotated or illuminated. The face recognition unit <b>185</b> can extract features of face from the image and can detect the face from the image.</p>
<p id="p-0080" num="0079">That is, the face recognition unit <b>185</b> can detect the overall pattern of a face from an image and can recognize features of a face using the detected face pattern. By at least these operations, the face recognition unit <b>185</b> can perform face recognition.</p>
<p id="p-0081" num="0080">The control unit <b>190</b> can control the operation of the camera <b>100</b>. The control unit <b>190</b> can search for one of the plurality of images by, for example, applying two or more different classification standards according to a direction received as manipulation input from the user.</p>
<p id="p-0082" num="0081">More specifically, if a manipulation input in a first axis direction is received, the control unit <b>190</b> can search for an image according to a first classification standard, if a manipulation input in a second axis direction is received, the control unit <b>190</b> can search for an image according to a second classification standard, and if a manipulation input in a third axis direction is received, the control unit <b>190</b> can search for an image according to a third classification standard.</p>
<p id="p-0083" num="0082">On the display screen, the first axis direction may be a horizontal direction, the second axis direction may be a vertical direction, and the third axis direction may be a diagonal direction.</p>
<p id="p-0084" num="0083">The first, second and third classification standard each may correspond to one of time, person, place, color, event, and type of scene, as illustrated, for example, in <figref idref="DRAWINGS">FIG. 3A</figref>.</p>
<p id="p-0085" num="0084">If a classification standard is time, the control unit <b>190</b> can arrange the images in chronological order or reverse chronological order. If a classification standard is person, the control unit <b>190</b> can arrange the images so that images having the same face recognized by the face recognition unit <b>185</b> are arranged together. If a classification standard is place, the control unit <b>190</b> can arrange the images so that images having the same place information detected by the GPS <b>180</b> and/or tagged by the camera <b>100</b> or a user to indicate place information are arranged together. If a classification standard is color, the control unit <b>190</b> can detect color information of the images and can arrange the images so that images having similar one or more colors are arranged together. For example, images that have a predetermined percentage of a preselected color may be arranged together, or image having a predetermined ratio of colors may be arranged together. If a classification standard is event, the control unit <b>190</b> can arrange the images so that images having the same event input by the user can be arranged together. For example, a user may selectively tag and/or identify one or more photos with one or more event tags, and the images can be arranged by their respective event tags. If a classification standard is type of scene, the control unit <b>190</b> can arrange the images so that images having the same type of scene can be arranged together.</p>
<p id="p-0086" num="0085">The type of scene can include a type of subject included in an image, for example, a landscape, a person, and a night view.</p>
<p id="p-0087" num="0086">If a short stroke is input in the first axis direction, the control unit <b>190</b> can search for a previous image or a subsequent image according to the first classification standard and can control the display <b>150</b> to display the selected image on the screen.</p>
<p id="p-0088" num="0087">If a long stroke is input in the first axis direction, the control unit <b>190</b> can search for an image in a previous category or a subsequent category according to the first classification standard and can control the display <b>150</b> to display the selected image on the screen.</p>
<p id="p-0089" num="0088">A stroke can indicate that a touch of the display screen has been received from a user, that touch has been maintained with movement at a certain distance, and that the touch input received from the user has ceased. A short stroke can indicate a received user touch to the screen, that touch has been maintained with movement at less than a threshold distance, and that touch input receive from a user has ceased. A long stroke indicates that that a user touch to the screen has been received, that touch has been maintained with movement received from a user that is greater than a threshold distance, and touch input receive from a user has ceased. The threshold distance can indicate a touched distance that determines whether a stroke is long or short.</p>
<p id="p-0090" num="0089">The category can indicate a group of images divided according to one or more classification standards. For example, if a classification standard is person, images related to the same person can be a single category, if a classification standard is time, images related to the same date can be a single category, if a classification standard is place, images related to the same place can be a single category, if a classification standard is color, images related to the same color can be a single category, if a classification standard is event, images related to the same event can be a single category, and if a classification standard is type of scene, images related to the same scene can be a single category.</p>
<p id="p-0091" num="0090">For example, when the first classification standard is person, if a short stroke is input in the first axis direction, the control unit <b>190</b> can search for a previous image or a subsequent image that is related to a person in a currently searched image. If a long stroke is input in the first axis direction, the control unit <b>190</b> can search for an image related to a previous person or a subsequent person who is different from a person in a currently searched image.</p>
<p id="p-0092" num="0091">If a short stroke is input in the second axis direction, the control unit <b>190</b> can search for a previous image or a subsequent image according to the second classification standard and can control the display <b>150</b> to display the selected image on the screen.</p>
<p id="p-0093" num="0092">If a long stroke is input in the second axis direction, the control unit <b>190</b> can search for an image in a previous category or a subsequent category according to the second classification standard and can control the display <b>150</b> to display the selected image on the screen.</p>
<p id="p-0094" num="0093">If a short stroke is input in the third axis direction, the control unit <b>190</b> can search for a previous image or a subsequent image according to the third classification standard and can control the display <b>150</b> to display the selected image on the screen.</p>
<p id="p-0095" num="0094">If a long stroke is input in the third axis direction, the control unit <b>190</b> can search for an image in a previous category or a subsequent category according to the third classification standard and can control the display <b>150</b> to display the selected image on the screen.</p>
<p id="p-0096" num="0095">If a currently searched image changes, the control unit <b>190</b> can rearrange the images according to the first, second and third classification standard according to the currently searched image. That is, the control unit <b>190</b> can rearrange the images according to the first, second and third classification standard according to a currently searched image.</p>
<p id="p-0097" num="0096">The control unit <b>190</b> may control an image search menu to be displayed in the thumbnail view mode. In other words, the control unit <b>190</b> can display thumbnails of images divided according to the first classification standard in the x-axis direction, can display thumbnails of images divided according to the second classification standard in the y-axis direction, and can display thumbnails of images divided according to the third classification standard in the z-axis direction in a 3-dimensional space of the display screen.</p>
<p id="p-0098" num="0097">The control unit <b>190</b> may control an image search menu to be displayed in the single view mode. In other words, the control unit <b>190</b> can display a currently searched image from among the images on the display screen.</p>
<p id="p-0099" num="0098">The control unit <b>190</b> can apply a different classification standard according to the at least three touch directions of received manipulation input to search for an image. Accordingly, the user can easily search for a desired image using one or more classification standards.</p>
<p id="p-0100" num="0099">Hereinafter, a method of providing a UI to search for an image using three axis directions is described with reference to <figref idref="DRAWINGS">FIG. 2</figref>. <figref idref="DRAWINGS">FIG. 2</figref> is a flow chart illustrating a method of providing a UI according to exemplary embodiments of the present general inventive concept.</p>
<p id="p-0101" num="0100">In operation S<b>210</b>, the camera <b>100</b> can display a currently searched image on the screen. More specifically, the camera <b>100</b> can display a currently searched image on an image search menu.</p>
<p id="p-0102" num="0101">The image search menu can indicate a graphical user interface (GUI) which is provided to receive a selection from a user of a desired image from among the images stored in the storage unit <b>165</b>. The image search menu may be in one of the thumbnail view mode and the single view mode.</p>
<p id="p-0103" num="0102">In the thumbnail view mode, the image search menu can display thumbnails for a plurality of images in a 3-dimensional space in x-axis, y-axis, and z-axis directions. The thumbnails displayed in x-axis, y-axis, and z-axis directions can be thumbnails of images arranged according to one or more different classification standards. The classification standard indicates a standard to classify an image. More specifically, the classification standard may be one of time, person, place, color, event, and type of scene. For example, in an image search menu, thumbnails for images arranged according to a classification standard related to time (that is, arranged according to time in which images are captured) may be displayed in the x-axis direction, thumbnails for images arranged according to a classification standard related to person (that is, arranged according to person who is captured in a photograph) may be displayed in the y-axis direction, and thumbnails for images arranged according to classification standard related to place (that is, arranged according to place in which images are captured) may be displayed in the z-axis direction.</p>
<p id="p-0104" num="0103">In the single view mode, the image search menu can display a currently searched image from among the images to be searched.</p>
<p id="p-0105" num="0104">In operation S<b>220</b>, the camera <b>100</b> can arrange the images according to the first, second and third classification standard based on the currently searched image. That is, the camera <b>100</b> can rearrange the images according to the first, second and third classification standard according to a currently searched image.</p>
<p id="p-0106" num="0105">In operation S<b>230</b>, the camera <b>100</b> can determine whether or not a manipulation in the first axis direction has been received from a user. In operation S<b>230</b>-Y, if an input manipulation in the first axis direction has been received, the camera <b>100</b> can search for an image according to the first classification standard in operation S<b>235</b>, and can display a currently searched image on the display screen in operation S<b>210</b>.</p>
<p id="p-0107" num="0106">More specifically, if a short stroke input in the first axis direction is received, the camera <b>100</b> can search for a previous image or a subsequent image according to the first classification standard. If a long stroke input in the first axis direction is received, the camera <b>100</b> can search for an image in a previous category or a subsequent category according to the first classification standard.</p>
<p id="p-0108" num="0107">For example, if the first axis direction is a horizontal direction and the first classification standard is time, and if a short stroke input to the right is received, the camera <b>100</b> can search for a subsequent image according to the order of the time in which an image was captured. If a long stroke input to the right is received, the camera <b>100</b> can search for an image (that is, an image in a subsequent time category) which was captured on the next date of the date on which the currently searched image was captured according to the order of the time in which an image was captured.</p>
<p id="p-0109" num="0108">In operation S<b>240</b>, the camera <b>100</b> can determine whether or not an input manipulation in the second axis direction is received from a user. In operation S<b>240</b>-Y, if an input manipulation in the second axis direction is received, the camera <b>100</b> can search for an image according to the second classification standard in operation S<b>245</b>, and can display a currently searched image on the screen in operation S<b>210</b>.</p>
<p id="p-0110" num="0109">More specifically, if a short stroke input in the second axis direction is received, the camera <b>100</b> can search for a previous image or a subsequent image according to the second classification standard. If a long stroke input in the second axis direction is received, the camera <b>100</b> can search for an image in a previous category or a subsequent category according to the second classification standard.</p>
<p id="p-0111" num="0110">For example, if the second axis direction is a vertical direction and the second classification standard is place, and if a short stroke upwards is received as input, the camera <b>100</b> can search for a subsequent image according to the order of the place in which an image was captured. If a long stroke upwards is received as input, the camera <b>100</b> can search for an image (that is, an image in a subsequent place category) which was captured in a place which is different from the place in which the currently searched image was captured according to the order of the place in which an image was captured.</p>
<p id="p-0112" num="0111">In operation S<b>250</b>, the camera <b>100</b> can determine whether or not an input manipulation in the third axis direction is received. In operation S<b>250</b>-Y, if an input manipulation in the third axis direction is received, the camera <b>100</b> can search for an image according to the third classification standard in operation S<b>255</b>, and can display a currently searched image on the display screen in operation S<b>210</b>.</p>
<p id="p-0113" num="0112">More specifically, if a short stroke input in the third axis direction is received, the camera <b>100</b> can search for a previous image or a subsequent image according to the third classification standard. If a long stroke input in the third axis direction is received, the camera <b>100</b> can search for an image in a previous category or a subsequent category according to the third classification standard.</p>
<p id="p-0114" num="0113">For example, if the third axis direction is a diagonal direction (that is, a left downward direction and a right upward direction) and the third classification standard is person, and if a short stroke input in a right upward direction is received, the camera <b>100</b> can search for a subsequent image according to the order of a person included in an image. If a long stroke input in a right upward direction is received, the camera <b>100</b> can search for an image (that is, an image in a subsequent person category) including a person which is different from a person included in the currently searched image according to the order of a person included in an image.</p>
<p id="p-0115" num="0114">When the user inputs a manipulation diagonally, the camera <b>100</b> may recognize the diagonal direction as a horizontal direction or a vertical direction. To minimize and/or prevent a directional mis-recognition, the camera <b>100</b> may recognize a diagonal manipulation using a manipulation which is different from a horizontal manipulation and a vertical manipulation. For example, the camera <b>100</b> may recognize a vertical manipulation or a horizontal manipulation from a received stroke, and may recognize a diagonal manipulation from a received multi-touch stroke. That is, the camera <b>100</b> may recognize a vertical manipulation or a horizontal manipulation from a received stroke, and may recognize a diagonal manipulation from a selected button and a received stroke.</p>
<p id="p-0116" num="0115">In operation S<b>260</b>-Y, if another manipulation input is received, the camera <b>100</b> can perform a function in operation S<b>265</b> that corresponds to the received input manipulation.</p>
<p id="p-0117" num="0116">The camera <b>100</b> can search for an image by applying a different classification standard according to the at least three touch directions of input manipulation that may be received, so an image can be searched for with one or more classification standards.</p>
<p id="p-0118" num="0117">Hereinafter, operation of the camera <b>100</b> is described according to a received input (e.g., a touch by the user) with reference to <figref idref="DRAWINGS">FIGS. 3A to 12</figref>.</p>
<p id="p-0119" num="0118"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> illustrate that images are arranged according to classification standards corresponding to three axis directions according to exemplary embodiments of the present general inventive concept.</p>
<p id="p-0120" num="0119"><figref idref="DRAWINGS">FIG. 3A</figref> illustrates coordinates which may be used to arrange images. As illustrated in <figref idref="DRAWINGS">FIG. 3A</figref>, the camera <b>100</b> can assign the x-axis with a classification standard related to time, assign the y-axis with a classification standard related to place, and assign the z-axis with a classification standard related to person.</p>
<p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. 3B</figref> illustrates that images can be arranged in the x, y and z axis in a 3-dimensional space according to classification standards related to at least time, place, and person. As illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>, the camera <b>100</b> can arrange stored images along the x, y and z axis in a 3-dimensional space according to classification standards related to time, place, and person, as illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>.</p>
<p id="p-0122" num="0121">Referring to <figref idref="DRAWINGS">FIG. 3B</figref>, example images from September 9 until September 11 can be arranged along the x-axis according to time basis, images related to amusement park and home can be arranged along the y-axis according to place basis, and images related to mother, myself, and friend can be arranged along the z-axis according to person basis. In <figref idref="DRAWINGS">FIG. 3B</figref>, a currently searched image <b>300</b> can be, for example, related to September 10 according to time, to amusement part based on place, and to myself based on person.</p>
<p id="p-0123" num="0122">When images are arranged as illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>, if a short stroke input to the left (in the direction of &#x2212;x) is received, the camera <b>100</b> can search for a subsequent image (that is, a first image <b>310</b>) according to the order of the time in which an image was captured. If a long stroke input to the left is received, the camera <b>100</b> can search for an image (that is, a second image <b>311</b>) which was captured on the next date (September 11) of the date (September 10) on which the currently searched image <b>300</b> was captured according to the order of the time in which an image was captured (that is, searches for an image in a different time category).</p>
<p id="p-0124" num="0123">When images are arranged as illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>, if a short stroke input to the right (in the direction of +x) is received, the camera <b>100</b> can search for a previous image (that is, a third image <b>315</b>) according to the order of the time in which an image was captured. If a long stroke is input to the right, the camera <b>100</b> can search for an image (that is, a fourth image <b>320</b>) which was captured on the previous date (September 9) of the date (September 10) on which the currently searched image <b>300</b> was captured according to the order of the time in which an image was captured (that is, searches for an image in a different time category).</p>
<p id="p-0125" num="0124">When images are arranged as illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>, if a short stroke input downwards (in the direction of &#x2212;y) is received, the camera <b>100</b> can search for a subsequent image (that is, a fifth image <b>320</b>) according to the order of the place (e.g., location) in which an image was captured. If a long stroke input downwards is received, the camera <b>100</b> can search for an image (not illustrated) which was captured in a place which is different from the place (e.g., amusement park) in which the currently searched image <b>300</b> was captured according to the order of the place in which an image was captured (that is, searches for an image in a different place category).</p>
<p id="p-0126" num="0125">When images are arranged as illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>, if a short stroke input upwards (in the direction of +y) is received, the camera <b>100</b> can search for a previous image (that is, a sixth image <b>325</b>) according to the order of the place in which an image was captured. If a long stroke input upwards is received, the camera <b>100</b> can search for an image (that is, the sixth image <b>325</b>) which was captured in a place which is different from the place (amusement park) in which the currently searched image <b>300</b> was captured according to the order of the place in which an image was captured (that is, searches for an image in a different place category).</p>
<p id="p-0127" num="0126">When images are arranged as illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>, if a short stroke input in the left downward direction (in the direction of &#x2212;z) is received, the camera <b>100</b> can search for a subsequent image (that is, a seventh image <b>330</b>) according to the order of a person included in an image. If a long stroke input in the left downward direction is received, the camera <b>100</b> can search for an image (that is, an eighth image <b>331</b>) including a person (e.g., friend) which is different from a person (e.g., myself) included in the currently searched image <b>300</b> according to the order of a person included in an image (that is, searches for an image in a different person category).</p>
<p id="p-0128" num="0127">When images are arranged as illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>, if a short stroke input in the right upward direction (in the direction of +z) is received, the camera <b>100</b> can search for a previous image (that is, a ninth image <b>335</b>) according to the order of a person included in an image. If a long stroke input in the right upward direction is received, the camera <b>100</b> can sarch for an image (that is, the ninth image <b>335</b>) including a previous person (e.g., mother) which is different from a person (e.g., myself) included in the currently searched image <b>300</b> according to the order of a person included in an image (that is, searches for an image in a different person category).</p>
<p id="p-0129" num="0128">The camera <b>100</b> can search for an image based on one or more different classification standards according to the direction of a stroke.</p>
<p id="p-0130" num="0129"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a screen displaying an image search menu in the thumbnail view mode according to exemplary embodiments of the present general inventive concept. As illustrated in <figref idref="DRAWINGS">FIG. 4</figref>, the camera <b>100</b> displays an image search menu in the thumbnail view mode in a 3-dimensional space. Referring to <figref idref="DRAWINGS">FIG. 4</figref>, in the thumbnail view mode, stored images are arranged and displayed according to the classification standards of time, place, and person in the x-axis, y-axis, and z-axis of a 3-dimensional space (e.g., as illustrated in <figref idref="DRAWINGS">FIGS. 3A-3B</figref>).</p>
<p id="p-0131" num="0130">The image search menu in the thumbnail view mode can receive an input a stroke from a user and search for an image according to one or more classification standards (e.g., a selected classification).</p>
<p id="p-0132" num="0131"><figref idref="DRAWINGS">FIGS. 5A and 5B</figref> illustrate that a short stroke input to the right is received according to exemplary embodiments of the present general inventive concept. If a stroke input horizontally is received, the camera <b>100</b> can search for an image according to a classification standard related to time.</p>
<p id="p-0133" num="0132">As illustrated in <figref idref="DRAWINGS">FIG. 5A</figref>, a currently searched image <b>500</b> was captured at 7:12 pm on Oct. 12, 2009. If the user inputs a short stroke to the right as illustrated by the directional arrow in <figref idref="DRAWINGS">FIG. 5A</figref>, a previous image is searched as illustrated in <figref idref="DRAWINGS">FIG. 5B</figref>. A currently searched image <b>510</b> illustrated in <figref idref="DRAWINGS">FIG. 5B</figref> was captured at 7:10 pm.</p>
<p id="p-0134" num="0133"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> illustrate that a long stroke input to the right is received according to exemplary embodiments of the present general inventive concept. If a stroke input horizontally is received, the camera <b>100</b> can search for an image according to a classification standard related to time.</p>
<p id="p-0135" num="0134"><figref idref="DRAWINGS">FIG. 6A</figref> illustrates that a currently searched image <b>600</b> was captured at 7:12 pm on Oct. 12, 2009. If a long stroke to the right is received from the user as in <figref idref="DRAWINGS">FIG. 6A</figref>, an image which was captured on a previous date can be searched, as illustrated in <figref idref="DRAWINGS">FIG. 6B</figref>. Therefore, a currently searched image <b>610</b> illustrated in <figref idref="DRAWINGS">FIG. 6B</figref> was captured on Oct. 11, 2009.</p>
<p id="p-0136" num="0135"><figref idref="DRAWINGS">FIGS. 7A and 7B</figref> illustrate that a short stroke input downwards is received according to exemplary embodiments of the present general inventive concept. If a stroke input vertically is received, the camera <b>100</b> can search for an image according to a classification standard related to place.</p>
<p id="p-0137" num="0136"><figref idref="DRAWINGS">FIG. 7A</figref> illustrates that a currently searched image <b>700</b> was captured in Washington (i.e., a place). If a short stroke downwards is received from the user as illustrated by the directional arrow in <figref idref="DRAWINGS">FIG. 7A</figref>, a previous image is searched, as illustrated in <figref idref="DRAWINGS">FIG. 7B</figref>. A currently searched image <b>710</b> in <figref idref="DRAWINGS">FIG. 7B</figref> can be a previous image which was captured in Washington.</p>
<p id="p-0138" num="0137"><figref idref="DRAWINGS">FIGS. 8A and 8B</figref> illustrate that a long stroke input downwards (e.g., as illustrated by the directional arrow illustrated in <figref idref="DRAWINGS">FIG. 8A</figref>) is received according to exemplary embodiments of the present general inventive concept. If a stroke is input vertically, the camera <b>100</b> can search for an image according to a classification standard related to place.</p>
<p id="p-0139" num="0138"><figref idref="DRAWINGS">FIG. 8A</figref> illustrates that a currently searched image <b>800</b> was captured in Washington. If a long stroke downwards is received as input from a user as illustrated in <figref idref="DRAWINGS">FIG. 8A</figref>, an image of a previous place is searched, as illustrated in <figref idref="DRAWINGS">FIG. 8B</figref>. A currently searched image <b>810</b> as illustrated in <figref idref="DRAWINGS">FIG. 8B</figref> is an image which was captured in Seoul.</p>
<p id="p-0140" num="0139"><figref idref="DRAWINGS">FIGS. 9A and 9B</figref> illustrate that a short stroke input is received in a diagonal down direction (e.g. as illustrated by the directional arrow in <figref idref="DRAWINGS">FIG. 9A</figref>) according to exemplary embodiments of the present general inventive concept. If a stroke is input diagonally (in the right upwards direction or in the left downward direction), the camera <b>100</b> can search for an image according to a classification standard related to person.</p>
<p id="p-0141" num="0140">In <figref idref="DRAWINGS">FIG. 9A</figref>, a currently searched image <b>900</b> includes a person (e.g., person &#x201c;SH.L&#x201d;). If a short stroke input in the left downward direction is received as illustrated in <figref idref="DRAWINGS">FIG. 9A</figref> (e.g., as illustrated by the directional arrow), a previous image of the person &#x201c;SH.L&#x201d; is searched, as illustrated in <figref idref="DRAWINGS">FIG. 9B</figref>. Therefore, a currently searched image <b>910</b> in <figref idref="DRAWINGS">FIG. 9B</figref> is a previous image including the person &#x201c;SH.L.&#x201d;</p>
<p id="p-0142" num="0141"><figref idref="DRAWINGS">FIGS. 10A and 10B</figref> illustrate that a long stroke input is received in a diagonal down direction (e.g., as illustrated by the directional arrow in <figref idref="DRAWINGS">FIG. 10A</figref>) according to exemplary embodiments of the present general inventive concept. If a stroke input diagonally is received (e.g., in the right upwards direction or in the left downward direction as illustrated in <figref idref="DRAWINGS">FIG. 8A</figref>), the camera <b>100</b> can search for an image according to a classification standard related to person.</p>
<p id="p-0143" num="0142"><figref idref="DRAWINGS">FIG. 10A</figref> illustrates a currently searched image <b>1000</b> includes a person &#x201c;SH.L&#x201d;. If a long stroke input in the left downward direction is received as in <figref idref="DRAWINGS">FIG. 10A</figref>, an image of a different person can be searched, as illustrated in <figref idref="DRAWINGS">FIG. 10B</figref>. A currently searched image <b>1010</b> illustrated in <figref idref="DRAWINGS">FIG. 10B</figref> can be an image including a person &#x201c;HS.J.&#x201d;</p>
<p id="p-0144" num="0143">As described above, the camera <b>100</b> can search for an image using an image search menu in the thumbnail view mode by applying one or more different classification standards according to the direction of stroke received as input from a user. That is, the user can search for an image according to one or more classification standards by inputting a direction of a stroke.</p>
<p id="p-0145" num="0144"><figref idref="DRAWINGS">FIGS. 11A to 11F</figref> illustrate a process of operating an image search menu in the single view mode according to exemplary embodiments of the present general inventive concept. As illustrated in <figref idref="DRAWINGS">FIGS. 11A to 11F</figref>, the camera <b>100</b> can search for an image using an image search menu in the single view mode by applying one or more different classification standards according to the direction of a received input stroke.</p>
<p id="p-0146" num="0145">Referring to <figref idref="DRAWINGS">FIG. 11A</figref>, when executing an image search menu in the single view mode, the camera <b>100</b> can display a currently searched image on the screen. For example, as illustrated in <figref idref="DRAWINGS">FIG. 11A</figref>, a place in which the image was captured can be identified in the display screen (e.g., the image of <figref idref="DRAWINGS">FIG. 11</figref> was captured in &#x201c;Place 1&#x201d;).</p>
<p id="p-0147" num="0146">If a vertically input stroke is received, the camera <b>100</b> can search for an image according to a classification standard related to place. If a long stroke downwards is received from the user as illustrated by the direction arrow in <figref idref="DRAWINGS">FIG. 11A</figref>, an image which was captured in a different place (that is, an image in a different place category) can be searched, as illustrated in <figref idref="DRAWINGS">FIG. 11B</figref>. A currently searched image in <figref idref="DRAWINGS">FIG. 11B</figref> can be an image captured in &#x201c;Place 2.&#x201d;</p>
<p id="p-0148" num="0147">As illustrated in <figref idref="DRAWINGS">FIG. 11B</figref>, the image was captured at 2:00 pm. If a horizontal input stroke is received from a user, the camera <b>100</b> can search for an image according to a classification standard related to time.</p>
<p id="p-0149" num="0148">If a short input stroke to the right (e.g,. as illustrated by the directional arrow) is received from the user as in <figref idref="DRAWINGS">FIG. 11B</figref>, an image which is prior to the image illustrated in <figref idref="DRAWINGS">FIG. 11B</figref> is searched as in <figref idref="DRAWINGS">FIG. 11C</figref>. A currently searched image in <figref idref="DRAWINGS">FIG. 11C</figref> can be an image captured, for example, at 1:10 pm.</p>
<p id="p-0150" num="0149">The image illustrated in <figref idref="DRAWINGS">FIG. 11C</figref> includes &#x201c;Person 1.&#x201d; If a stroke is input diagonally as illustrated by the directional arrow in <figref idref="DRAWINGS">FIG. 11C</figref>, the camera <b>100</b> can search for an image according to a classification standard related to person.</p>
<p id="p-0151" num="0150">If a short stroke is received from a user in the left downward direction as in <figref idref="DRAWINGS">FIG. 11C</figref>, a previous image of the same person can be searched as illustrated in <figref idref="DRAWINGS">FIG. 11D</figref>. A currently searched image in <figref idref="DRAWINGS">FIG. 11D</figref> can be an image related to &#x201c;Person 1.&#x201d;</p>
<p id="p-0152" num="0151">If a long stroke input in the left downward direction is received as illustrated by the directional arrow in <figref idref="DRAWINGS">FIG. 11D</figref> is received from a user, a previous image of a different person (that is, an image in a different person category) can be searched as illustrated in <figref idref="DRAWINGS">FIG. 11E</figref>. A currently searched image in <figref idref="DRAWINGS">FIG. 11E</figref> can be an image related to &#x201c;Person 2.&#x201d;</p>
<p id="p-0153" num="0152">If a selection of a back button <b>1100</b> is received, the camera <b>100</b> can display a previously displayed image. If a selection of the back button <b>1100</b> is received as illustrated in <figref idref="DRAWINGS">FIG. 11E</figref>, the camera <b>100</b> can display a previously displayed image on the screen as illustrated in <figref idref="DRAWINGS">FIG. 11F</figref>.</p>
<p id="p-0154" num="0153"><figref idref="DRAWINGS">FIG. 12</figref> illustrates a screen displaying a history <b>1200</b> of displayed images according to exemplary embodiments of the present general inventive concept. As illustrated in <figref idref="DRAWINGS">FIG. 12</figref>, the camera <b>100</b> may display the history <b>1200</b> of images which have been searched on the display screen. Accordingly, the user can identify which images have been searched at a glance.</p>
<p id="p-0155" num="0154">As described above, the camera <b>100</b> can search for an image using an image search menu in the single view mode by applying different classification standards according to the direction of the received input stroke. A desired image can be searched for according to one or more classification standards by receiving an input of the direction of stroke differently in the image search menu in the single view mode.</p>
<p id="p-0156" num="0155">In exemplary embodiments of the present general inventive concept, the display apparatus can be, for example, included with the camera <b>100</b>. The display apparatus may include any suitable device to search for and to display a desired (e.g., selected image, searched for image, etc.) image from among a plurality of images. For example, the display apparatus may be a television, a mobile phone, an MP3 player, a personal digital assistant (PDA), an electronic photo frame, and a notebook computer to display an image, or a camera, or any other suitable device to carry out the exemplary embodiments of the present general inventive concept.</p>
<p id="p-0157" num="0156">In exemplary embodiments of the present general inventive concept, content can include images as illustrated in <figref idref="DRAWINGS">FIGS. 1-12</figref> as described above, but the present general inventive concept may include other types of content such as music, movies, text, and so on.</p>
<p id="p-0158" num="0157">For example, exemplary embodiments in which the display apparatus is an MP3 player and content is music files is described with reference to <figref idref="DRAWINGS">FIG. 13</figref>, which illustrates that a plurality of music files in the MP3 player are arranged in three axis directions.</p>
<p id="p-0159" num="0158">If the display apparatus is an MP3 player, content to be searched may be music. For example, a first classification standard, a second classification standard, and a third classification standard may be related to genre, singer, and album, respectively. The MP3 player may arrange stored music files according to one or more classification standards related to genre, singer, and album along the x-axis, the y-axis, and the z-axis in a 3-dimensional space, as illustrated in <figref idref="DRAWINGS">FIG. 13</figref>.</p>
<p id="p-0160" num="0159">Referring to <figref idref="DRAWINGS">FIG. 13</figref>, music files such as Genre 1, Genre 2, and Genre 3 can be arranged along the x-axis according to a classification standard related to, for example, a genre of music (e.g., classical, jazz, electronic, world, rock, etc.). Music files such as Singer 1, Singer 2, and Singer 3 can be arranged along the y-axis according to a classification standard related to a singer. Music files such as Album 1, Album 2, and Album 3 are arranged along the z-axis according to a classification standard related to an album. <figref idref="DRAWINGS">FIG. 13</figref> illustrates a currently searched music file <b>1300</b> that can be related to Genre 1, Singer 1, and Album 1.</p>
<p id="p-0161" num="0160">If music files are arranged as illustrated in <figref idref="DRAWINGS">FIG. 13</figref>, and if a short stroke input to the left (in the direction of &#x2212;x) is received, the MP3 player can search for a subsequent music file (that is, a first music file <b>1310</b>) according to the order of the genre of music. If a long stroke input to the left is received, the MP3 player can search for a music file (that is, a second music file <b>1311</b>) of the genre (e.g., Genre 2) which is different from the genre (e.g., Genre 1) of the currently searched music file <b>1300</b> according to the order of the genre of music (that is, searches for a music file in a different genre category).</p>
<p id="p-0162" num="0161">If a short stroke input to the right (in the direction of +x) is received, the MP3 player can search for a previous music file (that is, a third music file <b>1315</b>) according to the order of the genre of music. If a long stroke input to the right is received, the MP3 player can search for a music file (that is, a fourth music file <b>1316</b>) of the genre (Genre 3) which is different from the genre (Genre 1) of the currently searched music file <b>1300</b> according to the order of the genre of music (that is, searches for a music file in a different genre category).</p>
<p id="p-0163" num="0162">If music files are arranged as illustrated in <figref idref="DRAWINGS">FIG. 13</figref>, and if a short stroke input downwards (in the direction of &#x2212;y) is received, the MP3 player can search for a subsequent music file (that is, a fifth music file <b>1325</b>) according to the order of singer of music. If a long input stroke input downwards is received, the MP3 player can search for a music file (that is, the fifth music file <b>1325</b>) of the singer (Singer 2) which can be different from the singer (Singer 1) of the currently searched music file <b>1300</b> according to the order of singer of music (that is, searches for a music file in a different singer category).</p>
<p id="p-0164" num="0163">If a short stroke input upwards (in the direction of +y) is received, the MP3 player can search for a subsequent music file (that is, a sixth music file <b>1320</b>) according to the order of singers of music. If a long stroke input upwards is received, the MP3 player searches for a music file (that is, a seventh music file <b>1321</b>) of the singer (e.g., Singer 3) which is different from the singer (e.g., Singer 1) of the currently searched music file <b>1300</b> according to the order of music singers (that is, searches for a music file in a different singer category).</p>
<p id="p-0165" num="0164">If music files are arranged as illustrated in <figref idref="DRAWINGS">FIG. 13</figref>, and if a short stroke input in the left downward direction (in the direction of &#x2212;z) is received, the MP3 player can search for a subsequent music file (that is, an eighth music file <b>1335</b>) according to the order of album of music. If a long stroke input in the left downward direction is received, the MP3 player can search for a music file (that is, the ninth music file <b>1336</b>) of the album (e.g., Album 2) which can be different from the album (e.g., Album 1) of the currently searched music file <b>1300</b> according to the order of album of music (that is, searches for a music file in a different album category).</p>
<p id="p-0166" num="0165">If a short stroke input in the right upward direction (in the direction of +z) is received, the MP3 player can search for a previous music file (that is, a tenth music file <b>1330</b>) according to the order of album of music. If a long stroke input in the right upward direction is received, the MP3 player can search for a music file (that is, an eleventh music file <b>1331</b>) of the album (Album 3) which can be different from the album (Album 1) of the currently searched music file <b>1300</b> according to the order of album of music (that is, searches for a music file in a different album category).</p>
<p id="p-0167" num="0166">As described above, the MP3 player can search for a music file of a different classification standard according to the direction of the stroke.</p>
<p id="p-0168" num="0167">Exemplary embodiments of the present general inventive concept may be applied when a display apparatus is an MP3 player and content is music.</p>
<p id="p-0169" num="0168">As can be appreciated from the exemplary embodiments of the present general inventive concept, a method of providing a user interface (UI) in which a manipulation for two or more axis directions is input and two or more classification standards are applied according to the direction in which the operation is input so that one of the images may be found, and a display apparatus adopting the same are provided. The user may easily search for a desired image using diverse classification standards.</p>
<p id="p-0170" num="0169">In particular, a classification standard may be changed by receiving a changed direction of touch input to search for a desired image with one or more classification standards with greater ease.</p>
<p id="p-0171" num="0170">Although various embodiments of the present general inventive concept have been illustrated and described, it will be appreciated by those skilled in the art that changes may be made in these embodiments without departing from the principles and spirit of the general inventive concept, the scope of which is defined in the appended claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of providing a user interface (UI), the method comprising:
<claim-text>receiving an input manipulation in one of first and second axis directions; and</claim-text>
<claim-text>searching for one of a plurality of images according to a first classification criteria to categorize images when the received input manipulation is in the first axis direction and searching for one of a plurality of images according to a second classification criteria to categorize images when the received input manipulation is in the second axis direction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the receiving comprises receiving an input manipulation in one of the first, the second, and a third axis directions, and the searching for one of the plurality of images comprises:
<claim-text>searching for an image according to a third classification criteria to categorize images when the received input manipulation is in the third axis direction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein on a display, the first axis direction is a horizontal direction, the second axis direction is a vertical direction, and the third axis direction is a diagonal direction.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the first classification criteria to categorize images, the second classification criteria to categorize images, and the third classification criteria to categorize images each correspond to one of time, person, place, color, event, and type of scene.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the received input manipulation is a short stroke or a long stroke, and
<claim-text>the searching for the image according to the first classification standard comprises:</claim-text>
<claim-text>searching for a previous image or a subsequent image according to the first classification criteria to categorize images when the short stroke of the received input manipulation is in the first axis direction; and</claim-text>
<claim-text>searching for an image in a different category according to the first classification criteria to categorize images when the long stroke of the received input manipulation is in the first axis direction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the received input manipulation is a short stroke or a long stroke, and
<claim-text>the searching for the image according to the second classification standard comprises:</claim-text>
<claim-text>searching for a previous image or a subsequent image according to the second classification criteria to categorize images when the short stroke of the received input manipulation is in the second axis direction; and</claim-text>
<claim-text>searching for an image in a different category according to the second classification criteria to categorize images when the long stroke of the received input manipulation is in the second axis direction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein when a currently searched image changes, the plurality of images are rearranged according to the first, second and third classification criteria to categorize images according to the changed image.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:
<claim-text>displaying thumbnails of images classified according to the first classification criteria to categorize images in an x-axis direction in a 3-dimensional space of a display;</claim-text>
<claim-text>displaying thumbnails of images classified according to the second classification criteria to categorize images in an y-axis direction in the 3-dimensional space of the display; and</claim-text>
<claim-text>displaying thumbnails of images classified according to the third classification criteria to categorize images in a z-axis direction in the 3-dimensional space of the display.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:
<claim-text>displaying only a currently searched image on a display from among the plurality of images to be searched.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A display apparatus, comprising:
<claim-text>a storage unit to store a plurality of images;</claim-text>
<claim-text>a manipulation unit to receive an input manipulation in one of a first and a second axis directions; and</claim-text>
<claim-text>a control unit to search for one of the plurality of images according to a first classification criteria to categorize images when the received input manipulation is in the first axis direction and to search for one of the plurality of images according to a second classification criteria to categorize images when the received input manipulation is in the second axis direction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The display apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the manipulation unit receives an input manipulation in one of the first, the second, and a third axis directions, and the control unit searches for one of the plurality of images according to the third classification criteria to categorize images when the received manipulation input is in the third axis direction.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The display apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein on a display, the first axis direction is a horizontal direction, the second axis direction is a vertical direction, and the third axis direction is a diagonal direction.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The display apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the first classification criteria to categorize images, the second classification criteria to categorize images, and the third classification criteria to categorize images each correspond to one of time, person, place, color, event, and type of scene.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The display apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the received input manipulation is a short stroke or a long stroke, and the control unit searches for a previous image or a subsequent image according to the first classification criteria to categorize images when the short stroke of the received input manipulation is in the first axis direction, and the control unit searches for an image in a different category according to the first classification criteria to categorize images when the long stroke of the received input manipulation is in the first axis direction.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The display apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the received input manipulation is a short stroke or a long stroke, and
<claim-text>the control unit searches for a previous image or a subsequent image according to the second classification criteria to categorize images when the short stroke of the received input manipulation is in the second axis direction, and the control unit searches for an image in a different category according to the second classification criteria to categorize images when the long stroke of the received input manipulation is in the second axis direction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The display apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein when a currently searched image changes, the control unit rearranges the plurality of images according to the first, second and third classification criteria to categorize images according to the changed image.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The display apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the control unit displays thumbnails of images classified according to the first classification criteria to categorize images in an x-axis direction in a 3-dimensional space of a display, the control unit displays thumbnails of images classified according to the second classification standard in an y-axis direction in the 3-dimensional space of the display, and the control unit displays thumbnails of images classified according to the third classification criteria to categorize images in a z-axis direction in the 3-dimensional space of the display.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The display apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the control unit displays only a currently searched image on a display from among the plurality of images to be searched.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A method of providing a user interface (UI), the method comprising:
<claim-text>displaying thumbnails of images classified according to a first classification criteria to categorize images in a first axis direction in a 3-dimensional space of a display;</claim-text>
<claim-text>displaying thumbnails of images classified according to a second classification criteria to categorize images in a second axis direction in the 3-dimensional space of the display; and</claim-text>
<claim-text>displaying thumbnails of images classified according to a third classification criteria to categorize images in a third axis direction in the 3-dimensional space of the display.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A method of providing a user interface (UI), the method comprising:
<claim-text>searching for content according to a first classification criteria to categorize images when an input manipulation in a first axis direction is received;</claim-text>
<claim-text>searching for content according to a second classification criteria to categorize images when an input manipulation in a second axis direction is received; and</claim-text>
<claim-text>searching for content according to a third classification criteria to categorize images when an input manipulation in a third axis direction is received.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the content is music, the first classification criteria to categorize images is a genre, the second classification criteria to categorize images is a singer, and the third classification criteria to categorize images is an album.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. A method of searching for stored content with a graphical user interface of a display apparatus, the method comprising:
<claim-text>receiving an input manipulation from the graphical user interface of the display apparatus in a plurality of axis directions to select a classification criteria to categorize images of the content to be searched; and</claim-text>
<claim-text>searching for stored content in a storage unit of a display apparatus according to the received input manipulation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising:
<claim-text>receiving a selection a type of the stored content with the graphical user interface of the display apparatus.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein each axis of the plurality of axis directions is a different classification criteria to categorize images of the content.</claim-text>
</claim>
</claims>
</us-patent-grant>
