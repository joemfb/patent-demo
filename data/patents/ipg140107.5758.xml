<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626862-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626862</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10979281</doc-number>
<date>20041102</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1046</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709207</main-classification>
<further-classification>709204</further-classification>
<further-classification>709205</further-classification>
<further-classification>709206</further-classification>
<further-classification>709217</further-classification>
<further-classification>715201</further-classification>
<further-classification>715700</further-classification>
<further-classification>715751</further-classification>
<further-classification>715752</further-classification>
<further-classification>715753</further-classification>
<further-classification>715758</further-classification>
<further-classification>715780</further-classification>
<further-classification>379 9323</further-classification>
</classification-national>
<invention-title id="d2e53">Identifying people and available communication modes</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5793365</doc-number>
<kind>A</kind>
<name>Tang et al.</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715758</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6049796</doc-number>
<kind>A</kind>
<name>Siitonen et al.</name>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707711</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6360252</doc-number>
<kind>B1</kind>
<name>Rudy et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709206</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6807562</doc-number>
<kind>B1</kind>
<name>Pennock et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7007239</doc-number>
<kind>B1</kind>
<name>Hawkins et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715780</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7050553</doc-number>
<kind>B2</kind>
<name>Chang et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 9315</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7162256</doc-number>
<kind>B2</kind>
<name>Seligmann et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4554566</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7218919</doc-number>
<kind>B2</kind>
<name>Vaananen</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4554121</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7240093</doc-number>
<kind>B1</kind>
<name>Danieli et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709205</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7243078</doc-number>
<kind>B1</kind>
<name>Lewis-Hawkins</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705  729</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7275215</doc-number>
<kind>B2</kind>
<name>Werndorfer et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715752</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7334021</doc-number>
<kind>B1</kind>
<name>Fletcher</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709206</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>7433921</doc-number>
<kind>B2</kind>
<name>Ludwig et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>7653879</doc-number>
<kind>B1</kind>
<name>Sareen et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715752</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>RE42476</doc-number>
<kind>E</kind>
<name>Vaananen</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4554121</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2002/0002069</doc-number>
<kind>A1</kind>
<name>Keronen et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2002/0032567</doc-number>
<kind>A1</kind>
<name>Lindholm et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704246</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2002/0056000</doc-number>
<kind>A1</kind>
<name>Albert Coussement</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2002/0178270</doc-number>
<kind>A1</kind>
<name>Riordan</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2003/0233129</doc-number>
<kind>A1</kind>
<name>Matos</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>607  5</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2004/0014456</doc-number>
<kind>A1</kind>
<name>Vnnen</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455413</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2004/0024822</doc-number>
<kind>A1</kind>
<name>Werndorfer et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709206</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2004/0051726</doc-number>
<kind>A1</kind>
<name>Martyn</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345700</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2004/0107255</doc-number>
<kind>A1</kind>
<name>Ludwig et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2004/0199582</doc-number>
<kind>A1</kind>
<name>Kucharewski et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2004/0203610</doc-number>
<kind>A1</kind>
<name>Deeds</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4554121</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2005/0050150</doc-number>
<kind>A1</kind>
<name>Dinkin</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709207</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2005/0108207</doc-number>
<kind>A1</kind>
<name>Thuerk</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2005/0111638</doc-number>
<kind>A1</kind>
<name>Chang et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 9315</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2005/0125496</doc-number>
<kind>A1</kind>
<name>Thuerk</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2005/0198321</doc-number>
<kind>A1</kind>
<name>Blohm</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709228</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2007/0198944</doc-number>
<kind>A1</kind>
<name>Viswanathan et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715778</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2011/0202867</doc-number>
<kind>A1</kind>
<name>Viswanathan et al.</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715781</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Drew Robb, &#x201c;Getting Messaging Together&#x201d;, www.computerworld.com, (Jan. 29, 2001) (6 pages).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Web page titled, &#x201c;MSN&#xae; Messenger for Windows&#xae;; MSN Messenger lets you see when your friends are online and exchange instant messages with them&#x201d;, http://messenger.msn.com, (Printed from the Internet on Mar. 28, 2003) (2 pages).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>Web page titled, &#x201c;MSN&#xae; Messenger for Windows&#xae;; MSN Messenger's great features are easy to use and just one click away&#x201d;, http://messenger.msn.com, (Printed from the Internet on Mar. 28, 2003) (2 pages).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>Web page titled, &#x201c;MSN&#xae; Messenger for Windows&#xae;; Stay in touch with Microsoft&#xae; .NET Alerts!&#x201d;, http://messenger.msn.com, (Printed from the Internet on Mar. 28, 2003) (2 pages).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>Alcatel Technology Brief, &#x201c;Extending the PC environment with more than a soft phone&#x201d; (3 pages).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>U.S. Appl. No. 10/728,374, Reply Brief, filed Aug. 24, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>U.S. Appl. No. 10/728,374, Examiner's Answer mailed Jun. 24, 2009, in Response to Appeal Brief filed Mar. 16, 2009 appealing from the Office Action mailed Oct. 31, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>U.S. Appl. No. 10/728,374, Appeal Brief filed Mar. 16, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00042">
<othercit>U.S. Appl. No. 10/728,374, Office Action mailed Oct. 31, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>U.S. Appl. No. 10/728,374, Response to Notification of Non-Compliant Appeal Brief, filed Jul. 29, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00044">
<othercit>U.S. Appl. No. 10/728,374, Appeal Brief, filed Jun. 17, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00045">
<othercit>U.S. Appl. No. 10/728,374, Advisory Action mailed Feb. 4, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00046">
<othercit>U.S. Appl. No. 10/728,374, Reply to Office Action mailed Nov. 16, 2007, filed Jan. 16, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>U.S. Appl. No. 10/728,374,Office Action mailed Nov. 16, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>U.S. Appl. No. 10/728,374, Reply to Office Action mailed Mar. 2, 2007, filed Sep. 4, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>U.S. Appl. No. 10/728,374,Office Action mailed Mar. 2, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00050">
<othercit>U.S. Appl. No. 10/952,034, Office Action mailed Jul. 22, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>U.S. Appl. No. 10/952,034, Reply to Office Action mailed Jan. 6, 2010, filed May 5, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00052">
<othercit>U.S. Appl. No. 10/952,034, Office Action mailed Jan. 6, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00053">
<othercit>U.S. Appl. No. 10/952,034, Reply to Office Action mailed Mar. 6, 2009, filed Aug. 24, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>U.S. Appl. No. 10/952,034, Office Action mailed Mar. 6, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>U.S. Appl. No. 10/952,034, Supplemental Appeal Brief, filed Oct. 17, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00056">
<othercit>U.S. Appl. No. 10/952,034, Appeal Brief filed Sep. 16, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00057">
<othercit>U.S. Appl. No. 10/952,034, Advisory Action mailed Feb. 4, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00058">
<othercit>U.S. Appl. No. 10/952,034, Reply to Office Action mailed Nov. 16, 2007, Reply filed Jan. 16, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00059">
<othercit>U.S. Appl. No. 10/952,034, Office Action mailed Nov. 16, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00060">
<othercit>U.S. Appl. No. 10/952,034, Reply to Office Action mailed Mar. 6, 2007, Reply filed Sep. 6, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00061">
<othercit>U.S. Appl. No. 10/952,034, Office Action mailed Mar. 6, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>31</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709228</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709204-207</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709217</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715201</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715700</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715751-753</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715758</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715780</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379 9323</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10952034</doc-number>
<date>20040928</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10979281</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10728374</doc-number>
<date>20031204</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10952034</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050125498</doc-number>
<kind>A1</kind>
<date>20050609</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Frank</last-name>
<first-name>Randall</first-name>
<address>
<city>Weston</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Prusinoski</last-name>
<first-name>Scott J.</first-name>
<address>
<city>Brighton</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Vujjini</last-name>
<first-name>Vijay</first-name>
<address>
<city>Malden</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Frank</last-name>
<first-name>Randall</first-name>
<address>
<city>Weston</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Prusinoski</last-name>
<first-name>Scott J.</first-name>
<address>
<city>Brighton</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Vujjini</last-name>
<first-name>Vijay</first-name>
<address>
<city>Malden</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Fish &#x26; Richardson P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>FMR LLC</orgname>
<role>02</role>
<address>
<city>Boston</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Boutah</last-name>
<first-name>Alina N</first-name>
<department>2443</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system that includes a computer device and a user interface. The user interface is configured to enable a user to interact with a person using one of at least two of voice conversation, voice-video conversation, graphic text-based conversation, fax, and electronic mail. The interactions can include the following. Creating a rule to cause the computer device to automatically perform an action based on a request to converse with the user. Viewing an automatically generated listing of a set of persons, the listing comprising a name, presence information, and communication modes available for the user to communicate with the person from the set of persons. Selecting the person from the set of persons. Selecting a communication mode from the communication modes available to communicate with the person, and retrieving information about a person using an identifying characteristic of the person, where the identifying characteristic is selected by the user from a display. Communicating with the person.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="189.74mm" wi="198.63mm" file="US08626862-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="225.98mm" wi="171.11mm" file="US08626862-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="237.74mm" wi="200.58mm" file="US08626862-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="235.63mm" wi="161.80mm" file="US08626862-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="210.23mm" wi="189.23mm" file="US08626862-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="222.84mm" wi="197.61mm" file="US08626862-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="217.25mm" wi="209.13mm" file="US08626862-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="212.17mm" wi="157.82mm" file="US08626862-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="250.87mm" wi="195.92mm" file="US08626862-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="207.52mm" wi="190.92mm" file="US08626862-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="235.29mm" wi="192.19mm" file="US08626862-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 10/952,034, filed on Sep. 28, 2004, which is a continuation of U.S. application Ser. No. 10/728,374, filed on Dec. 4, 2003, now pending.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">TECHNICAL FIELD</heading>
<p id="p-0003" num="0002">This invention generally relates to integrating multiple communication modes.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">New communication technologies are becoming available on computers. These technologies, primarily based on high speed processors, good connections to high speed data transmission on Ethernet and Internet, and fast rendering of graphics, enable new modes of personal communication on computers such as voice conversation, voice with video conversation, graphic text-based conversation, and electronic mail (e-mail). An example of voice conversation mode of personal communication on computers is Voice delivered over Internet Protocol (VoIP) while an example of graphic text-based conversation mode is Instant Messaging (IM).</p>
<p id="p-0005" num="0004">VoIP is a term used in Internet Protocol (IP) telephony for a set of facilities for managing the delivery of voice information using the Internet Protocol (IP). In general, this means sending voice information in digital form in discrete packets rather than in the traditional circuit-committed protocols of the public switched telephone network (PSTN). VoIP has generally been implemented for personal communication on computers using voice conversation mode as a replacement for physical telephones. In some examples, the graphical user interface (GUI) created as this replacement has been designed with a keypad designed to emulate the keypad of a physical telephone. Thus, the user must click on different numbers on the GUI keypad to make a phone call.</p>
<p id="p-0006" num="0005">IM provides the ability to easily determine whether a chosen friend or co-worker is connected to the Internet and, if they are, to exchange messages with them. IM differs from ordinary e-mail in the immediacy of the message exchange and also makes a continued exchange simpler than sending e-mail back and forth. These message exchanges are graphic text-based. In order for IM to work, both users (who must subscribe to the service) must be online at the same time, and the intended recipient must be willing to accept instant messages. If the IM software is set to accept instant messages, the IM software alerts the recipient with a distinctive sound, generates a window that indicates that an incoming message has arrived, and allows the recipient to accept or reject the incoming message or a window containing the incoming message.</p>
<p id="p-0007" num="0006">Under most conditions, IM is truly &#x201c;instant.&#x201d; Even during peak Internet usage periods, the delay is rarely more than a second or two. Little or no delay makes it possible for two people to have a real-time online conversation by sending instant messages back and forth to each other.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0008" num="0007">In general, in one aspect, there is a method that includes receiving from a first person a request to converse with a second person using any one of two or more selectable communication modes, and in response to the received request, automatically performing an action determined by a rule created by the second person.</p>
<p id="p-0009" num="0008">Implementations may include one or more other features. The rule is created by the second person using a user interface on a computing device. The method further includes selecting the rule from a set of one or more rules based on a condition statement of the rule. The method further includes selecting the rule based on the one of two or more communication modes. The method further includes selecting the rule based on an identity of the first person. The method further includes selecting the rule based on a current status of the second person. The method further includes determining an electronic document associated with the first person and retrieving the electronic document if the second person indicates a desire to view the document. In some cases, the method further includes displaying the electronic document to the second person. In other cases, the method further includes retrieving the electronic document from an e-mail storage module, wherein the electronic document is an e-mail message. In still other cases, the method further includes retrieving a calendar of the second person from a calendar storage module, wherein the electronic document is the calendar.</p>
<p id="p-0010" num="0009">Implementations may include one or more other features. Automatically performing the action further includes enabling the first person to leave a message if the current status of the second person is that the second person is unavailable to converse. Automatically performing the action further includes forwarding the request to converse to a third person if a current status of the second person is that the second person is unavailable to converse and the third person is available to converse. The one of two or more communication modes includes a voice conversation communication mode, in some cases, the voice conversation communication mode includes Voice over Internet Protocol (VoIP). The one of two or more communication modes includes a voice/video conversation communication mode. The one of two or more communication modes includes a graphic text-based conversation communications mode, in some cases, the graphic text-based conversation communication mode includes Instant Messaging.</p>
<p id="p-0011" num="0010">In general, in another aspect, there is a system that includes a computing device that includes a transceiver configured to receive a request to converse with a user of the computing device, and an integration module configured to interact with at least two of voice conversation software, voice-video conversation software, graphic text-based conversation software, fax software, and electronic mail software, and to automatically perform an action determined by a rule created by the user based on the received request.</p>
<p id="p-0012" num="0011">Implementations may include one or more other features. The integration module includes a microphone and a speaker. The integration module includes a user interface hook to detect when the user is interacting with the computing device. The integration module includes a user interface that enables the user to specify the action. The system further includes a network. The system further includes a second computing device configured to send the request to converse. The system further includes a telephone configured to send the request to converse. The network includes a switched local area network. The transceiver is further configured to receive a request to converse via the switched local area network. The switched local area network is configured to connect the computing device to an internet. The switched local area network is configured to connect the computing device to an intranet. The switched local area network is configured to connect to an internet protocol/public switched telephone network gateway, in some cases, the network further includes a second switched local area network. In such cases, the second computing device can send the request to converse via the second switched local area network. In some cases, the network further includes a telephone system and a public switched telephone network configured to enable the telephone to send the request to converse to the computing device.</p>
<p id="p-0013" num="0012">In general, in one aspect, there is a method that includes providing to a first person a listing of a set of persons, the listing comprising a name, presence information, and two or more communication modes available to communicate with each person. The method also includes enabling the first person to select a second person from the set of persons, and enabling the first person to select a communication mode from the communication modes available to communicate with the second person.</p>
<p id="p-0014" num="0013">Implementations may include one or more other features. The method further includes retrieving one or more first letters of a name of the second person, matching the one or more first letters of the name to names of a second set of persons, and presenting the second set of persons to the first person. In some cases, the method further includes enabling the first person to select the second person from the second set of persons. The method further includes enabling the first person to communicate with the second person using the selected communication mode by interfacing with a computer program. The method further includes enabling the first person to communicate with the second person by voice. In some cases, communication by voice uses Voice over Internet Protocol (VoIP). The method further includes enabling the first person to communicate with the second person by voice and video. The method further includes enabling the first person to communicate with the second person by text-based conversation. In some cases, the text-based conversation includes Instant Messaging. The method further includes enabling the first person to communicate with the second person via an e-mail message. The communication modes include at least two of a voice conversation mode, an e-mail mode, a graphic text-based conversation mode, and an voice/video conversation mode. The presence information includes an indicator indicating that the second person is (i) logged into a computer, (ii) at work but not logged into the computer, or (iii) out of the office. The listing further includes status information comprising an indicator indicating that the second person is currently engaged in conversation with a third person. In some cases, the indicator indicates that the second person is currently engaged in conversation using one of a voice conversation mode, a voice/video conversation mode, and a graphic text-based conversation mode. The method further includes querying a database for information about the set of persons.</p>
<p id="p-0015" num="0014">In general, in another aspect, there is a system that includes a user interface module configured to generate a listing of a set of persons, the listing comprising a name, presence information, and communication modes available to communicate with each person. The user interface module is also configured to enable a user to select a person from the set of persons, and enable the user to select a communication mode from the communication modes available to communicate with the selected person.</p>
<p id="p-0016" num="0015">Implementations may include one or more other features. The user interface is further configured to interface with a computer program providing at least one of the communication modes. The user interface is further configured to interface with a computer program providing at least a portion of the presence information. The system further includes a database including information about the set of persons. The user interface module further includes a user interface hook to detect when the user is interacting with the computing device.</p>
<p id="p-0017" num="0016">In general, in another aspect, there is a communication integration environment that includes an integration module configured to interact with at least two of voice conversation software, voice-video conversation software, graphic text-based conversation software, fax software, and electronic mail software, and to automatically perform an action determined by a rule created by the user based on the received request. The environment also includes a user interface module configured to generate a listing of a set of persons, the listing comprising a name, presence information, and communication modes available to communicate with each person. The user interface module is also configured to enable a user to select a person from the set of persons, and enable the user to select a communication mode from the communication modes available to communicate with the selected person.</p>
<p id="p-0018" num="0017">In general, in another aspect, there is a system that includes a computer device, a user interface that is configured to enable a user to interact with a person using one of at least two of voice conversation, voice-video conversation, graphic text-based conversation, fax, and electronic mail; wherein the interaction includes the following. Creating a rule to cause the computer device to automatically perform an action based on a request to converse with the user. Viewing an automatically generated listing of a set of persons, the listing comprising a name, presence information, and communication modes available for the user to communicate with the person from the set of persons. Selecting the person from the set of persons. Selecting a communication mode from the communication modes available to communicate with the person. Retrieving information about a person using an identifying characteristic of the person, and the identifying characteristic being selected by the user from a display. Communicating with the person.</p>
<p id="p-0019" num="0018">In general, in another aspect, there is a method that includes enabling a first person to select an identifying characteristic of a second person in a display provided by a first computer program, automatically retrieving, using a second computer program, information about the second person using the identifying characteristic of the second person and a type of the characteristic, and enabling the first person to select from the communication modes available to contact the second person.</p>
<p id="p-0020" num="0019">Implementations may include one or more other features. Retrieving further includes determining the type of characteristic. The method further includes determining the communication modes available to communicate with the second person based on the identifying characteristic of the second person. The method further includes determining the communication modes available to communicate with the second person based on the type of characteristic. The method further includes enabling the first person to communicate with the second person using the selected communication mode. In some cases, enabling the first person to communicate with the second person further includes interfacing with a third computer program. The method further includes determining a communication mode identifier associated with the second person for at least one of the communication modes available to contact the second person. The communication modes include at least two of a voice conversation mode, an e-mail mode, a graphic text-based conversation mode, and an voice/video conversation mode. The method further includes displaying at least one of a name associated with the second person, presence information associated with the second person, and status information associated with the second person. The presence information includes an indicator indicating that the second person is (i) logged into a computer, (ii) at work but not logged into a computer, (iii) out of the office. The status information includes an indicator indicating that the second person is currently engaged in conversation with another person. In some cases, the indicator indicates that the second person is currently engaged in conversation using one of voice conversation mode, voice/video conversation mode, and graphic text-based conversation mode.</p>
<p id="p-0021" num="0020">Implementations may include one or more other features. The method further includes enabling the first person to communicate with the second person by voice. Communication by voice uses Voice over Internet Protocol (VoIP). The method further includes enabling the first person to communicate with the second person by voice and video. The method further includes enabling the first person to communicate with the second person by text-based conversation. In some cases, the text-based conversation uses Instant Messaging. The method further includes enabling the first person to communicate with the second person via an e-mail message. Enabling the first person to select an identifying characteristic of the second person further includes highlighting the identifying characteristic. The identifying characteristic includes a name of the second person. The identifying characteristic includes a telephone number of the second person. The method further includes performing optical character recognition on an image of the identifying characteristic. The identifying characteristic includes an image of the second person.</p>
<p id="p-0022" num="0021">In general, in another aspect, there is a system that includes a retrieval module configured to automatically retrieve information about a first person using an identifying characteristic of the first person, and the identifying characteristic being selected by a second person from a display, and a selection module configured to enable the second person to select from communication modes available to communicate with the first person.</p>
<p id="p-0023" num="0022">Implementations may include one or more other features. The system further includes a network. The selection module is further configured to interface with a computer program to provide the second person with one of the communication modes available to communicate with the first person. The system further includes a display module to display at least one of a name associated with the first person, presence information associated with the first person, and status information associated with the first person. In some cases, the presence information includes an indicator indicating that the first person is (i) logged into a computer, (ii) at work but not logged into a computer, (iii) out of the office. In other cases, the status information includes an indicator indicating that the first person is currently engaged in conversation with another person. In these cases, the indicator can indicate that the first person is currently engaged in conversation using one of voice conversation mode, voice/video conversation mode, and graphic text-based conversation mode. The selection module includes a user interface hook to detect when the user is interacting with the computing device.</p>
<p id="p-0024" num="0023">In general, in another aspect, there is a system that includes a computer device and a user interface. The user interface is configured to enable a user to interact with a person using one of at least two of voice conversation, voice-video conversation, graphic text-based conversation, fax, and electronic mail. The interaction includes the following. Creating a rule to cause the computer device to automatically perform an action based on a request to converse with the user; viewing an automatically generated listing of a set of persons, the listing comprising a name, presence information, and communication modes available for the user to communicate with the person from the set of persons. Selecting the person from the set of persons. Selecting a communication mode from the communication modes available to communicate with the person; retrieving information about a person using an identifying characteristic of the person, where the identifying characteristic is selected by the user from a display. Communicating with the person.</p>
<p id="p-0025" num="0024">In general, in another aspect there is a computer program product residing on a computer storage readable medium, the computer program product comprising executable instruction that cause a processor to perform one or more of the methods described above.</p>
<p id="p-0026" num="0025">These and other embodiments may have one or more of the following advantages.</p>
<p id="p-0027" num="0026">Multiple modes of personal communication on computers are integrated together with a contact list and user's preferences to improve the user's communication with others. The communication is improved by enabling the user to specify the identity of another person using convenient techniques, view presence information about the other person, and then specify the desired mode of communication with the other person by simply selecting the desired mode from the integrated multiple modes. The communication is also improved by enabling the user to set up rules that determine how incoming requests for communication with the user are automatically handled.</p>
<p id="p-0028" num="0027">In a corporate environment, integrating the multiple modes of personal communication on computers enables the user's entire computer-based communication environment to follow the user from a computer in an office to another computer in another office. This can allow office communication equipment, such as a phone and a desktop computer, to remain at one physical location and the employee's communication environment to follow that employee, reappearing when the employee logs into another computer in another office.</p>
<p id="p-0029" num="0028">The details of one or more examples are set forth in the accompanying drawings and the description below.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">DESCRIPTION OF DRAWINGS</heading>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 1</figref> is a view of a communication system environment.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 2</figref> is a view of a computer.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 3</figref> is a view of a user interface to integrate multiple modes of personal communication on a computer.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 3A</figref> is a view of a user interface for voice conversation mode of personal communication.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 4</figref> is a view of an Internet web browser with the text of a telephone number highlighted.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 4A</figref> is view of a user interface for voice conversation mode of personal communication after highlighting a telephone number in the web browser of <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 5</figref> is a view of a user interface of a rules assistant with a rule.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 6</figref> is a view of a user interface for voice conversation mode of personal communication enabling a user to bring up documents associated with the caller.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 7</figref> is a view of components of communication integration software.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 8</figref> is a view of another communication system.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0040" num="0039">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, communication system <b>10</b> includes voice-enabled computer <b>14</b>, network <b>16</b>, voice-enabled computer <b>24</b>, telephone <b>28</b>, and voice-enabled computer <b>30</b>. Computers <b>14</b>, <b>24</b>, and <b>30</b> are computing devices that can include, for example, desktop computers and/or handheld computers. Computer <b>14</b>, computer <b>24</b>, and computer <b>30</b> operate according to instructions in integration software <b>32</b>. Integration software <b>32</b> integrates multiple modes of personal communication on each computer and provides an interface to a user <b>12</b> using a single graphical user interface (GUI). Examples of the multiple modes of personal communication can include voice conversation (e.g., VoIP), voice-video conversation, graphic text-based conversation (e.g., IM), or other forms of graphic text-based communication such as fax or electronic mail (e-mail). User <b>12</b> uses voice-enabled computer <b>14</b> to communicate with users <b>22</b> and <b>26</b> via network <b>16</b>. User <b>22</b> uses voice-enabled computer <b>24</b> while user <b>26</b> uses telephone <b>28</b>. Computer <b>14</b> has access to server <b>18</b> that is connected to database <b>20</b>. User <b>12</b> communicates using one or more of the multiple modes of personal communication on computer <b>14</b>. Database <b>20</b> stores the communication preferences of user <b>22</b> and the identities as well as communication addresses of users <b>22</b> and <b>26</b>. Although database <b>22</b> is a separate entity in the illustrated example, database <b>22</b> or portions of database <b>22</b> can be distributed and/or included on a computing device, such as <b>14</b>, <b>24</b>, and/or <b>30</b>.</p>
<p id="p-0041" num="0040">In system <b>10</b>, voice conversation mode of personal communication via computer <b>24</b>, in addition to other modes of personal communication, is controlled by instructions executed by computer <b>14</b> and components of these modes of personal communication are represented by data in database <b>20</b>. Thus, these components can be manipulated, stored, categorized, accessed, and moved around network <b>16</b> like any other form of data. For example, integration software <b>32</b> enables user <b>12</b> to set instructions to forward or store a voice message using the same user interface as forwarding an e-mail message. These instructions and the components of the modes of personal communication are stored in database <b>20</b>. User <b>12</b> may also log into computer <b>30</b> and have access to the same information on computer <b>30</b> from database <b>20</b> as by logging into computer <b>14</b>. In corporate environments, for example, users can move around between different locations providing computers such as computer <b>14</b> and computer <b>30</b>. These different locations can include, for example, user <b>12</b>'s permanent office, user <b>12</b>'s colleague's office, a conference room over wireless LAN connection, an airport lounge with a Virtual Private Network (VPN) connection to user <b>12</b>'s employer, and user <b>12</b>'s home office with a VPN connection to server <b>18</b>. No matter where user <b>12</b> is logged in using computer <b>14</b>, <b>24</b>, or <b>30</b>, accessibility and control over these multiple modes of personal communication on computers are available to user <b>12</b>.</p>
<p id="p-0042" num="0041">If user <b>12</b> is logged in at computers <b>14</b> and <b>30</b> concurrently and user <b>22</b> sends a request to converse to user <b>12</b>, then computers <b>14</b> and <b>30</b> can both indicate the arrival of the request for conversation. If user <b>12</b> does not answer at either computer <b>14</b> or <b>30</b>, then, based on the instructions of user <b>12</b>, integration software <b>32</b> can deliver a message from user <b>22</b> to a mailbox stored in database <b>20</b>, accessible at either computer <b>14</b> or <b>30</b>.</p>
<p id="p-0043" num="0042">When either user <b>22</b> or user <b>26</b> sends a request for conversation to user <b>12</b> and user <b>12</b> is logged in on computer <b>14</b>, integration software <b>32</b> on computer <b>14</b> detects the identity of either user <b>22</b> or user <b>26</b>. A request to converse can include, for example, an incoming phone call using VoIP or an incoming instant message. When the request is for voice conversation, integration software <b>32</b> on computer <b>14</b> detects the identity based on, for example, the automatic number identification (ANI) information provided with the telephone call by matching the ANI with the requester's identity in database <b>20</b>. Other requests for conversation can directly contain the identity of the requesting user.</p>
<p id="p-0044" num="0043">When either user <b>22</b> or user <b>26</b> sends a request for conversation to user <b>12</b> and user <b>12</b> is logged in on computer <b>14</b>, computer <b>14</b> can use the identity of the requesting user to search different contact and address lists in database <b>20</b> and display as much information about the incoming call and user <b>22</b> or <b>26</b> as computer <b>14</b> is able to retrieve from database <b>20</b>. Such information can include, for example, user <b>22</b>'s or <b>26</b>'s organization, title, and/or photo. Based on a simple action by user <b>12</b> using a GUI, integration software <b>32</b> on computer <b>14</b> can also retrieve associated documents, such as recent e-mail correspondence to or from user <b>22</b> or <b>26</b>, stored in database <b>20</b> so that this recent correspondence is available during conversation. In another example, integration software <b>32</b> on computer <b>14</b> can also retrieve calendar information for user <b>22</b> or <b>26</b> in database <b>20</b> so that the availability of user <b>22</b> or <b>26</b> is available during the conversation based on a simple action by user <b>12</b>. This GUI is described in greater detail below.</p>
<p id="p-0045" num="0044">When user <b>12</b> goes on vacation, user <b>12</b> can use integration software <b>32</b> to set a vacation message (once) in a computer desktop environment setting to store the message in database <b>20</b>, and integration software <b>32</b> can configure all of the communication modes available to user <b>12</b> based on that single vacation message.</p>
<p id="p-0046" num="0045">Using integration software <b>32</b>, user <b>12</b> can manage communication distribution groups (e.g., groups in the Global Address List) in one place and communicate with these groups using any of the multiple modes of personal communication.</p>
<p id="p-0047" num="0046">While preparing to send an e-mail to a list including users <b>22</b> and <b>26</b>, user <b>12</b> decides to include voice annotation associated with the e-mail. Because integration software <b>32</b> coordinates with the various modes of personal communication, user <b>12</b> can include the voice annotation in the e-mail, or user <b>12</b> can initiate an immediate synchronous phone connection to all users in the list including users <b>22</b> and <b>26</b>.</p>
<p id="p-0048" num="0047">A set of rules defined by user <b>12</b> does a portion of the integration of multiple modes of personal communication on a computer for user <b>12</b>. User <b>12</b> uses a rules assistant in the form of a GUI to specify these rules, as discussed in greater detail below. Using this rules assistant, user <b>12</b> can specify actions computer <b>14</b> should take when certain events such as an incoming request to converse, from user <b>22</b> to user <b>12</b>, arrives at computer <b>14</b>. The condition statements of these rules specify the parameters of events. These parameters include, for example, the identity of user <b>22</b> (the sender), the mode of conversation used, a date and time range, and the current status of user <b>12</b> (the recipient). In an illustrative example, conditions of a particular rule include receipt of a voice call and user <b>12</b> is out of the office. In defining a rule for this example, user <b>12</b> can specify actions such as send the voice call to voice mail, disconnect the voice call, or forward the voice call to some other user.</p>
<p id="p-0049" num="0048">Referring to <figref idref="DRAWINGS">FIG. 2</figref>, computer <b>14</b> includes monitor <b>58</b>, processor <b>60</b>, and storage medium <b>62</b>. Processor <b>60</b> executes instructions stored in storage medium <b>62</b> while monitor <b>58</b> displays graphical output from processor <b>60</b>. Storage medium <b>62</b> stores operating system <b>64</b>, network software <b>66</b>, and applications. Applications include integration software <b>32</b> that integrates multiple communication modes for user <b>12</b> on computer <b>14</b>. Applications also include Internet browser software <b>70</b>, calendar software <b>72</b>, e-mail software <b>74</b>, VoIP software <b>76</b>, IM software <b>80</b>, and voice/video communication software <b>82</b>. Computer <b>14</b> also includes one or more speakers <b>84</b>, microphone <b>86</b>, and camera <b>88</b>. VoIP software <b>76</b> uses speaker <b>84</b> to transmit speech from user <b>22</b> or user <b>26</b> to user <b>12</b> while VoIP software <b>76</b> uses microphone <b>86</b> to record speech from user <b>12</b>. Voice/video communication software <b>82</b> uses speaker <b>84</b> and microphone <b>86</b> in a similar way as VoIP software and also uses camera <b>88</b> to record video of user <b>12</b>.</p>
<p id="p-0050" num="0049">One example of Internet browser software <b>70</b> is available as Internet Explorer&#xae; from Microsoft Corporation of Redmond, Wash. One example of calendar software <b>72</b> is available as Outlook&#xae; software from Microsoft Corporation of Redmond, Wash. One example of e-mail software <b>74</b> is also available as Outlook&#xae; software from Microsoft Corporation of Redmond, Wash. One example of VoIP software <b>76</b> is available as WinRTP&#xae; as source code from Vovida.org and another example as Telephony Application Programmer's Interface&#xae; (TAPI) software from Microsoft Corporation of Redmond, Wash. One example of voice/video communication software <b>82</b> is available as Eyeball Chat&#xae; from Eyeball Networks of Vancouver, BC, Canada.</p>
<p id="p-0051" num="0050">Integration software <b>32</b> incorporates a rules assistant function to enable user <b>12</b> to setup rules determining how incoming communication is handled. Integration software <b>32</b> also interacts with Application Programmer's Interfaces (APIs) in software <b>70</b>, <b>72</b>, <b>74</b>, <b>76</b>, <b>80</b>, and <b>82</b> to integrate multiple communication modes for user <b>12</b> on computer <b>14</b>. This integration includes reading electronic information stored by software <b>70</b>, <b>72</b>, <b>74</b>, <b>76</b>, <b>80</b>, and <b>82</b> and launching the execution of components of software <b>70</b>, <b>72</b>, <b>74</b>, <b>76</b>, <b>80</b>, and <b>82</b>. Examples of this integration are discussed in greater detail below.</p>
<p id="p-0052" num="0051">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, integration software <b>32</b> provides a Graphical User Interface (GUI) <b>102</b> that provides a person-centric interface that enables user <b>12</b> to contact user <b>28</b> from a list of known persons using multiple communication modes via computer <b>14</b>. In the illustrated example, these modes include a voice conversation mode, facilitated by VoIP software <b>76</b>, and graphic text-based conversation mode, facilitated by IM software <b>80</b>, as well as e-mail communication mode, facilitated by e-mail software <b>74</b>. GUI <b>102</b> includes area <b>112</b> with available communication modes. Area <b>112</b> includes button <b>128</b> (to specify VoIP communication), button <b>130</b> (to specify e-mail), and button <b>132</b> (to specify IM communication).</p>
<p id="p-0053" num="0052">GUI <b>102</b> also presents the name <b>104</b> of user <b>12</b> and a list of contacts <b>106</b>. For each contact in list <b>106</b> in GUI <b>102</b>, when user <b>12</b> selects that particular contact, the buttons <b>112</b> representing communication modes that are available for communication with that contact selected from list <b>106</b> are activated, while buttons <b>112</b> representing communication modes that are not available for communication with that contact selected from list <b>106</b> are deactivated. Thus, GUI <b>102</b> provides user <b>12</b>, in a single interface, with a list of communication modes that are available to communicate with a selected contact from list <b>106</b>, even though applications providing that mode of communication are independent of GUI <b>102</b>. In GUI <b>102</b>, icons <b>114</b> and <b>115</b> show different IM providers that are available for a contact. Icon <b>118</b> shows whether the contact is currently using a phone, and name <b>120</b> of the contact is color coded to reflect calendar information of the contact in list <b>106</b>. In an example that uses Outlook&#xae; as calendar software <b>72</b>, GUI <b>102</b> can perform the color-coding of the names according to the Outlook&#xae; status of an individual and uses the same color-coding as found in Outlook&#xae;. In that case, blue means busy, purple means out of office, and light blue means tentative. Area <b>122</b> provides one way for user <b>12</b> to specify the identity of user <b>22</b> to contact by typing in the name or telephone number of user <b>22</b>. Areas <b>124</b> and <b>126</b> present auxiliary information to user <b>22</b> such as weather, stock market conditions, and news.</p>
<p id="p-0054" num="0053">To communicate with user <b>22</b> or user <b>26</b>, user <b>12</b> first identifies user <b>22</b> or user <b>26</b> using GUI <b>102</b>. User <b>12</b> does this by clicking on a name in list <b>106</b> or typing in an identifier in area <b>122</b>. This identifier enables user <b>12</b> to identify a person not in list <b>106</b> but who is in database <b>20</b>. This identifier may be a name of a person in one or more databases <b>20</b>, where the name can be a nickname or user name, or a telephone number in database <b>20</b> with a match to a person. This identifier can also be a string of alphabetic characters of the beginning of the name of a person in database <b>20</b>. In general, if the identifier does not uniquely identify a person in database <b>20</b>, a sublist of persons is presented to the user and the user can select a person from this sublist. Otherwise, if the person is uniquely identified, integration software <b>32</b> initiates the communication process with the identified person. Before identifying which person to communicate with, user <b>12</b> can check the presence information of persons in list <b>106</b>.</p>
<p id="p-0055" num="0054">The icons <b>114</b> and <b>115</b> of a person standing or running indicate support for different IM services managed by IM software <b>80</b>. For example, the running person icon is representative of the AOL&#xae; IM service, the person standing is a Fidelity One contact. Other examples include icons of a Y for Yahoo&#xae;, a flower for ICQ&#xae;, and a pawn looking icon for MSN Messenger&#xae;. Icons <b>114</b> and <b>115</b> are shaded, representing the state of the user in relation of the user's IM usage. Green means that the user is currently engaged in an IM conversation, red means the user is away from the office, blue means do not disturb the person, gray means the user is at work but not logged into the computer, and white means the user has no presence information. The phone icon <b>118</b> means that Brian Falvey is currently speaking on a VoIP phone. The shading of name <b>120</b> indicates the office calendar status of user <b>12</b>. GUI <b>102</b> interacts with calendar software <b>72</b> to determine the calendar status of user <b>12</b>. For example, Outlook&#xae; software allows user <b>102</b> to set his or her current status at any given time as free, tentative, busy, or out of the office.</p>
<p id="p-0056" num="0055">Once user <b>12</b> has identified a person to communicate with, user <b>12</b> can choose a mode of communication in area <b>112</b>. If user <b>12</b> wishes to converse with user <b>22</b>, user <b>12</b> can click on button <b>128</b> for voice conversation mode of personal communication using VoIP software <b>76</b> or click on button <b>132</b> for graphic text-based conversation in the form of IM using IM software <b>80</b>. Otherwise, user <b>12</b> can initiate graphic text-based communication in the form of e-mail using e-mail software <b>74</b> by clicking on button <b>130</b>. In other examples, other buttons enable user <b>12</b> to choose other modes of personal communication not illustrated, such as voice/video conversation using voice/video software <b>82</b>.</p>
<p id="p-0057" num="0056">Referring to <figref idref="DRAWINGS">FIG. 3A</figref>, integration software <b>32</b> responds to user <b>12</b> clicking on button <b>128</b> by retrieving a telephone number and other information for a contact specified by user <b>12</b> in database <b>20</b>. Integration software <b>32</b> then launches the execution of VoIP software <b>76</b> that presents GUI <b>200</b> to user <b>12</b>. GUI <b>200</b> shows information about the VoIP call. Information for GUI <b>200</b> is gathered from database <b>20</b>. GUI <b>200</b> includes name <b>202</b> of user <b>22</b> or user <b>26</b> with whom user <b>12</b> wishes to communicate. GUI <b>200</b> also includes telephone number <b>204</b> of user <b>22</b> or user <b>26</b>. Additional information about user <b>22</b> or user <b>26</b> includes title <b>206</b> and company <b>208</b>. Because integration software <b>32</b> integrates multiples modes of communication, integration software <b>32</b> can display other information about user <b>22</b> obtained from database <b>20</b> or through other applications (e.g., <b>72</b>, <b>74</b>, <b>76</b>, <b>80</b>, and <b>82</b>) that have access to information about user <b>22</b>. Status <b>210</b> indicates the status of the VoIP call. This status can be, for example, &#x201c;Dialing&#x201d; or &#x201c;Connected&#x201d;. Button <b>212</b> enables user <b>12</b> to end the conversation. Control <b>214</b> enables user <b>12</b> to change the volume for microphone <b>86</b> while control <b>216</b> enables user <b>12</b> to change the volume control for computer speaker <b>84</b>.</p>
<p id="p-0058" num="0057">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, Internet browser software <b>70</b> provides GUI <b>300</b>. Integration software <b>32</b>, running in the background of Internet browser software <b>70</b> or some other software with a text GUI, coordinates with Internet browser software <b>70</b> and the other software to enable user <b>12</b> to communicate with user <b>22</b> or user <b>26</b> regardless of the software generating a display. For example, user <b>12</b> selects text <b>302</b> of a telephone number in GUI <b>300</b> generated by software <b>70</b>. After selecting text <b>302</b>, user <b>12</b> hits a &#x201c;hot&#x201d; key combination, such as CTRL D, that is programmed using the rules assistant. Integration software <b>32</b>, running in the background of Internet browser software <b>70</b>, detects the event of the &#x201c;hot&#x201d; key combination and reads the selected text. Integration software <b>32</b> determines that the type of the selected text is a number and determines that, because the format of the number is 3 digits, hyphen, 3 digits, hyphen, four digits, the number is a telephone number. Integration software <b>32</b> launches the execution of VoIP software <b>76</b> that brings up GUI <b>410</b>, as shown in <figref idref="DRAWINGS">FIG. 4A</figref>, and passes the telephone number, converted from the selected text, to VoIP software <b>76</b>. GUI <b>410</b> enables user <b>12</b> to call via VoIP the number selected in text <b>302</b>. The same number appears in box <b>412</b>.</p>
<p id="p-0059" num="0058">In the previous example, because the chosen text was determined to be a phone number, integration software <b>32</b> automatically selected the communication mode of voice conversation. The selected text is not, however, always in the form of a phone number. In other examples, this selected text can be another identifying characteristic of a contact in database <b>20</b>. In addition to a phone number, other identifying characteristics can include, for example ASCII characters representing the name of a contact or an image associated with a contact, such as scanned in text or a graphical image.</p>
<p id="p-0060" num="0059">In one example where the identify characteristic is ASCII characters representing the name of a contact, user <b>12</b> selects text containing the name of a contact in database <b>20</b> and hits the &#x201c;hot&#x201d; key combination. Integration software <b>32</b>, running in the background of Internet browser software <b>70</b> or other software, detects the event of the &#x201c;hot&#x201d; key combination and reads the selected text. Integration software <b>32</b> determines that the selected text includes alphabetic text, that the type of the text is a name, and that the name is an identifying characteristic of a contact in database <b>20</b>. Integration software <b>32</b> matches the name to the contact in database <b>20</b>. Integration software <b>32</b> provides GUI <b>102</b> to user <b>12</b> with the contact selected and enables user <b>12</b> to select the mode of communication in area <b>112</b>. In the case where user <b>12</b> selects voice conversation mode, using button <b>128</b>, integration software <b>32</b> launches the execution of VoIP software <b>76</b> and passes the telephone number for the contact, retrieved from database <b>20</b>, to VoIP software <b>76</b>.</p>
<p id="p-0061" num="0060">In another example where the text is in a scanned image, user <b>12</b> selects the applicable portion of the image in Internet browser software <b>70</b> or some other software and hits the correct &#x201c;hot&#x201d; key combination. This graphic image contains text of an identifying characteristic such as a name of a contact in database <b>20</b>. If the text is numeric, then the text represents a telephone number that can be matched to a name of the contact in database <b>20</b>. If the text is alphabetic, then the type of text is a name that is possibly known as a contact in database <b>20</b>. Integration software <b>32</b> performs optical character recognition to convert the image to ASCII text and to determine the identifying characteristic such as a name or telephone number. Integration software <b>32</b> compares the ASCII identifying characteristic with data in database <b>20</b> to determine a match. Integration software <b>32</b> provides GUI <b>102</b> to user <b>12</b> with the contact selected and enables user <b>12</b> to select the mode of personal communication in area <b>112</b> as in the previous examples.</p>
<p id="p-0062" num="0061">In another example, user <b>12</b> selects a graphic image in Internet browser software <b>70</b> or some other software and hits the correct &#x201c;hot&#x201d; key combination. This graphic image contains an identifying characteristic, such as a image of the face of a contact in database <b>20</b>. After determining that the graphic image does not represent numeric or alphabetic characters, integration software <b>32</b> determines that the type of image is an image of the face of a contact in database <b>20</b>. Integration software <b>32</b>, performs image pattern recognition to identify the contact in database <b>20</b>. Integration software <b>32</b>, provides GUI <b>102</b> to user <b>12</b> with the contact selected and enables user <b>12</b> to select the mode of communication in area <b>112</b> as in the previous examples. Software for such facial image pattern recognition is available, for example, from SeeStorm USA of Encinitas, Calif. Referring to <figref idref="DRAWINGS">FIG. 5</figref>, integration software <b>32</b> includes GUI <b>500</b> to enable user <b>12</b> to bring up all e-mails from user <b>22</b> when user <b>22</b> requests a voice conversation with user <b>12</b> and user <b>12</b> is in the office. In operation, upon receiving the request to converse from user <b>22</b>, GUI <b>500</b> appears and user <b>22</b> can indicate a desire to view the e-mails by selecting menu item <b>502</b>. When user <b>12</b> selects menu item <b>502</b>, integration software <b>32</b> brings up stored e-mails from user <b>22</b> for assisting user <b>12</b> in conversation with user <b>22</b>. Integration software <b>32</b> can retrieve these stored e-mails from database <b>20</b> and/or e-mail software <b>74</b>. Integration software <b>32</b> displays the stored e-mails using e-mail software <b>74</b>.</p>
<p id="p-0063" num="0062">In another example, a similar GUI enables user <b>22</b> to bring up calendar information for user <b>22</b> so that the availability of user <b>22</b> is visible to user <b>12</b> during the conversation. Integration software <b>32</b> can retrieve this calendar information from database <b>20</b> and/or calendar software <b>72</b>. Integration software <b>32</b> displays this calendar information through interaction with calendar software <b>72</b>.</p>
<p id="p-0064" num="0063">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, GUI <b>540</b> shows an example of a rule created by user <b>12</b> using the rules assistant. In the illustrated example, GUI <b>540</b> enables user <b>12</b> to program a rule when another user (e.g., user <b>22</b>) wants to initiate conversation with user <b>12</b> via voice. In this case, user <b>12</b> names the rule in box <b>542</b> as &#x201c;In Meeting&#x201d;. User <b>12</b> can set the conditions for the rule in area <b>544</b> and the actions for the rule in area <b>546</b>. In area <b>544</b>, user <b>12</b> can set the condition for the status of user <b>12</b> by clicking on box <b>545</b> and selecting from pull down menu <b>548</b>. In this case, user <b>12</b> clicks on box <b>546</b> and selects the status &#x201c;In a Meeting&#x201d;. Other status conditions in pull down menu <b>548</b> include &#x201c;On Vacation&#x201d;, &#x201c;Sick&#x201d;, &#x201c;At Work On Computer&#x201d;, and &#x201c;At Work but Not On Computer&#x201d;. User <b>12</b> also can set the date and time range when the rule applies. The date range is from date in box <b>550</b> to date in box <b>552</b>. User <b>12</b> can specify the condition for the name of user <b>22</b> who requests conversation with user <b>12</b> in box <b>554</b>. Lastly, for this example, GUI <b>540</b> provides four possible actions in area <b>546</b> to be automatically performed by computer <b>14</b> if user <b>22</b> initiates a voice call to user <b>12</b> and the conditions specified in area <b>544</b> are true. By selecting box <b>556</b>, user <b>12</b> specifies that computer <b>14</b> sends the call directly to voice mail. By selecting box <b>558</b>, user <b>12</b> specifies that computer <b>14</b> disconnects the call. By selecting box <b>560</b>, user <b>12</b> specifies that computer <b>14</b> forwards the call to wherever user <b>12</b> is currently located. By selecting box <b>562</b>, user <b>12</b> specifies that computer <b>14</b> forwards the call to another user listed in database <b>20</b>.</p>
<p id="p-0065" num="0064">Referring to <figref idref="DRAWINGS">FIG. 7</figref>, Fidelity One software <b>602</b> is an example of integration software <b>32</b> for the Windows&#xae; operating system. Fidelity One software <b>602</b> interacts with WinRTP software <b>606</b> and TAPI Control software <b>608</b> to provide VoIP services to user <b>12</b>. The Real-Time Transport Protocol (RTP) is an Internet protocol standard that specifies a way for programs to manage the real-time transmission of multimedia data over either unicast or multicast network services. WinRTP is a Component Object Model (COM) component that can originate RTP media from a microphone and terminate RTP media on a speaker. That is, WinRTP encodes and decodes RTP packets. WinRTP consists of two independent parts. One part has the ability to capture the user's voice using microphone <b>86</b>, encode the user's voice, and send the voice as an RTP stream to a configurable destination. The other part listens for an RTP stream from the network, extracts the audio from the RTP stream, and plays the extracted audio using speaker <b>84</b>. COM is the fundamental &#x201c;object model&#x201d; on which ActiveX Controls and OLE are built. COM allows an object to expose its functionality to other components and to host applications. COM defines both how the object exposes itself and how this exposure works across processes and across networks. COM also defines the object's life cycle. This makes WinRTP easy to use using any programming language like C, C++, or Java (using J/Direct).</p>
<p id="p-0066" num="0065">TAPI (Telephony Application Program Interface) software <b>608</b> is a standard program interface that lets a computer communicate over telephones or video phones to people or phone-connected resources elsewhere in the world.</p>
<p id="p-0067" num="0066">Integration software <b>32</b> also links to Easy Message&#xae; (EM) Control software <b>604</b> to use different IM services. EM is a unified instant messenger that provides support for IM providers such as ICQ&#xae;, MSN&#xae;, Yahoo&#xae;, and AOL&#xae; at the same time.</p>
<p id="p-0068" num="0067">Keyboard hook <b>610</b> is used in trapping keyboard messages to achieve high speed dialing. The idle User Interface (UI) hook <b>612</b> is used to detect when a user is at their keyboard by trapping all mouse and keyboard messages in Windows&#xae; to set presence status for IM.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 8</figref> shows communication system <b>732</b>. System <b>732</b> includes a network <b>734</b> which can be the Internet or a corporate intranet. System <b>732</b> also includes a Public Switched Telephone Network (PSTN) <b>736</b>. PSTN <b>736</b> can include, for example, a portion of the world's collection of interconnected voice-oriented public telephone networks, both commercial and government-owned. Voice-enabled computers <b>14</b>, <b>738</b>, and <b>740</b> are connected to a switched Local Area Network (LAN) <b>742</b>. Server <b>18</b> is also connected to LAN <b>742</b>. Voice-enabled computer <b>24</b> connects to network <b>734</b> via LAN <b>744</b>. LAN <b>744</b> also connects computer <b>24</b> to PSTN <b>736</b> via IP/PSTN Gateway <b>746</b>. LAN <b>742</b> connects computers <b>14</b>, <b>738</b>, and <b>740</b> to PSTN <b>736</b> via IP/PSTN Gateway <b>748</b>. Telephone <b>28</b> connects to PSTN <b>736</b> via private branch exchange (PBX) <b>750</b>. PBX <b>750</b> is a telephone system within an enterprise that switches calls between enterprise users on local lines while allowing users to share a certain number of external phone lines. Telephone <b>28</b> can also be connected to network <b>734</b> via PBX <b>50</b> and IP/PSTN Gateway <b>752</b>.</p>
<p id="p-0070" num="0069">System <b>732</b> allows flexibility in handling voice and data communication between users <b>12</b>, <b>22</b>, and <b>26</b>. For conversation modes of communication, system <b>732</b> separates data of the conversations into Internet Protocol (IP) packets and sends those packets via networks such as LANs and the Internet. For conversations using continuous streams of information, such as voice conversation and voice/video conversation modes of communication, PSTN <b>736</b> can be used in combination with network <b>734</b> via gateways <b>746</b>, <b>748</b>, and <b>752</b>. For example, one communication path for voice conversation mode of communication between users on computers <b>14</b> and <b>24</b> is from computer <b>14</b> to LAN <b>742</b> to IP/PSTN Gateway <b>748</b> to PSTN <b>736</b> to IP/PSTN Gateway <b>744</b> to LAN <b>744</b> to computer <b>24</b>. Another communication path for voice conversation mode between users on computer <b>14</b> and telephone <b>28</b> can be from computer <b>14</b> to LAN <b>742</b> to IP/PSTN <b>748</b> to PSTN <b>736</b> to PBX <b>750</b> to telephone <b>28</b>. For modes of communication other than voice conversation and the voice component of voice/video conversation, system <b>732</b> transmits data via LANs <b>742</b> and <b>744</b> or network <b>734</b>, for example, without going through PSTN <b>736</b>.</p>
<p id="p-0071" num="0070">A number of embodiments of the invention have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the invention. Accordingly, other embodiments are within the scope of the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>accessing, by one or more computers of a first person, information for a graphical user interface that when rendered by the one or more computers displays an identifying characteristic associated with a second person's contact information;</claim-text>
<claim-text>detecting, by the one or more computers, the first's person selection of a hotkey combination that specifies that the first user has selected textual information in the graphical user interface;</claim-text>
<claim-text>identifying, based on detection of the hotkey combination, that the selected textual information is the identifying characteristic displayed in the graphical user interface;</claim-text>
<claim-text>determining, by the one or more computers, a type of the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination, with the type of the identifying characteristic comprising one or more of a telephone number for the second person, a name of the second person, and an image associated with the second person;</claim-text>
<claim-text>determining, based on the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination and the type of the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination, contact information for the second person; and</claim-text>
<claim-text>launching a communication mode, with the communication mode using the contact information for the second person to establish a communication with the second person.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising determining communication modes available to communicate with the second person based on the identifying characteristic of the second person.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising determining communication modes available to communicate with the second person based on the type of characteristic.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising enabling the first person to communicate with the second person using the launched communication mode.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the graphical user interface comprises a first graphical user interface and wherein enabling the first person to communicate with the second person further comprises:
<claim-text>generating by the one or more computers a second graphical user interface that when rendered on a display device renders visual representations for plural modes of communication with the visual representations when selected, launching a third interface that can be used by the first person to initiate the communication.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising determining a communication mode identifier associated with the second person for at least a communication mode available to contact the second person.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the communication mode comprise at least one of a voice conversation mode, an e-mail mode, a graphic text-based conversation mode, and an voice/video conversation mode.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the graphical user interface comprises a first graphical user interface and wherein the method further comprises:
<claim-text>generating information for a second graphical user interface that when rendered on a display devices renders a visual representation of at least one of a name associated with the second person, presence information associated with the second person, and status information associated with the second person.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the presence information comprises an indicator indicating that the second person is one or more of logged into a computer, at work but not logged into a computer, and out of the office.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the status information comprises an indicator indicating that the second person is currently engaged in conversation with another person.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein the indicator indicates that the second person is currently engaged in conversation using one of voice conversation mode, voice/video conversation mode, and graphic text-based conversation mode.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising enabling the first person to communicate with the second person by voice.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein communication by voice uses Voice over Internet Protocol (VoIP).</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising enabling the first person to communicate with the second person by voice and video.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising enabling the first person to communicate with the second person by text-based conversation.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the text-based conversation uses Instant Messaging.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising enabling the first person to communicate with the second person via an e-mail message.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the selected textual information comprises highlighted textual information.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the identifying characteristic comprises a name of the second person.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising:
<claim-text>determining, by the one or more computers, that the identifying characteristic includes a telephone number of the second person;</claim-text>
<claim-text>launching VoIP software that when executed displays on a display a graphical user interface through which the first person initiates a telephonic communication with the second person;</claim-text>
<claim-text>passing, by the one or more computers, the telephone number to the VoIP software; and</claim-text>
<claim-text>establishing the telephonic communication between the first person and the second person using the VoIP software.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising performing optical character recognition on an image of the identifying characteristic.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the identifying characteristic comprises an image of the second person.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. A computer system comprising:
<claim-text>a processor; and</claim-text>
<claim-text>a computer readable hardware storage device storing a computer program product, the computer program product comprising instructions for causing the processor to:
<claim-text>access information for a graphical user interface that when rendered on a display device displays an identifying characteristic associated with a second person's contact information;</claim-text>
<claim-text>detect a first's person selection of a hotkey combination that specifies that the first user has selected textual information in the graphical user interface;</claim-text>
<claim-text>identify, based on detection of the hotkey combination, that the selected textual information is the identifying characteristic displayed in the graphical user interface;</claim-text>
<claim-text>determine a type of the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination, with the type of the identifying characteristic comprising one or more of a telephone number for the second person, a name of the second person, and an image associated with the second person;</claim-text>
<claim-text>determine, based on the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination and the type of the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination, contact information for the second person; and</claim-text>
<claim-text>launch a communication mode, with the communication mode using the contact information for the second person to establish a communication with the second person.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The system of <claim-ref idref="CLM-00023">claim 23</claim-ref> further comprising a network.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The system of <claim-ref idref="CLM-00023">claim 23</claim-ref> wherein the computer program product further comprises instructions for causing the processor to:
<claim-text>provide the second person with information indicative of a communication mode available to communicate with the first person.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The system of <claim-ref idref="CLM-00023">claim 23</claim-ref> wherein the graphical user interface comprises a first graphical user interface and wherein the computer program product further comprises instructions for causing the processor to:
<claim-text>generate information for a second graphical user interface that when rendered on a display devices renders a visual representation of at least one of a name associated with the first person, presence information associated with the first person, and status information associated with the first person.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The system of <claim-ref idref="CLM-00026">claim 26</claim-ref> wherein the presence information comprises an indicator indicating that the first person is one or more of logged into a computer, at work but not logged into a computer, and out of the office.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The system of <claim-ref idref="CLM-00026">claim 26</claim-ref> wherein the status information comprises an indicator indicating that the first person is currently engaged in conversation with another person.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The system of <claim-ref idref="CLM-00028">claim 28</claim-ref> wherein the indicator indicates that the first person is currently engaged in conversation using one of voice conversation mode, voice/video conversation mode, and graphic text-based conversation mode.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The system of <claim-ref idref="CLM-00023">claim 23</claim-ref> wherein the computer program product further comprises instructions for causing the processor to:
<claim-text>detect when one or more of the first user and the second user is interacting with a computing device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. A computer program product stored on a computer readable hardware storage device, the computer program product comprising instructions for causing a processor device to:
<claim-text>access information for a graphical user interface that when rendered on a display device displays an identifying characteristic associated with a second person's contact information;</claim-text>
<claim-text>detect a first's person selection of a hotkey combination that specifies that the first user has selected textual information in the graphical user interface;</claim-text>
<claim-text>identify, based on detection of the hotkey combination, that the selected textual information is the identifying characteristic displayed in the graphical user interface;</claim-text>
<claim-text>determine a type of the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination, with the type of the identifying characteristic comprising one or more of a telephone number for the second person, a name of the second person, and an image associated with the second person;</claim-text>
<claim-text>determine, based on the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination and the type of the identifying characteristic that is selected in the graphical user interface and that is identified by the selection of the hotkey combination, contact information for the second person; and</claim-text>
<claim-text>launch a communication mode, with the communication mode using the contact information for the second person to establish a communication with the second person. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
