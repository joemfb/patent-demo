<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625890-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625890</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13317374</doc-number>
<date>20111017</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>150</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382165</main-classification>
<further-classification>382173</further-classification>
</classification-national>
<invention-title id="d2e53">Stylizing geographic features in photographic images based on image content</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5214757</doc-number>
<kind>A</kind>
<name>Mauney et al.</name>
<date>19930500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715751</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5323317</doc-number>
<kind>A</kind>
<name>Hampton et al.</name>
<date>19940600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5761385</doc-number>
<kind>A</kind>
<name>Quinn</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 20</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5988853</doc-number>
<kind>A</kind>
<name>Kim et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>700 90</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7313402</doc-number>
<kind>B1</kind>
<name>Rahman</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4554561</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2002/0161767</doc-number>
<kind>A1</kind>
<name>Shapiro et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  9</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2005/0089219</doc-number>
<kind>A1</kind>
<name>Zhang</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382167</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2008/0195314</doc-number>
<kind>A1</kind>
<name>Green</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701211</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2008/0284791</doc-number>
<kind>A1</kind>
<name>Bressan et al.</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345589</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2011/0055253</doc-number>
<kind>A1</kind>
<name>Yoo et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707769</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2012/0110008</doc-number>
<kind>A1</kind>
<name>Pieper</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707769</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Adabala, N., et al., &#x201c;Computer aided generation of stylized maps,&#x201d; <i>Comp. Anim. Virtual Worlds </i>18:133-140, John Wiley &#x26; Sons, Ltd., United States (2007).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Vailaya, A., et al., &#x201c;On Image Classification: City Images VS. Landscapes,&#x201d; <i>Pattern Recognition </i>31(12):1921-1935, Pattern Recognition Society: Elsevier Science Ltd., Great Britain (1998).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Wikipedia, &#x201c;Adobe Photoshop,&#x201d; 7 pages, edited on Oct. 9, 2011, accessed from http://en.wikipedia.org/wiki/w.index/php?title=Photoshop&#x26;oldid=454696951, on May 23, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Wikipedia, &#x201c;Digital image processing,&#x201d; 4 pages, edited on Oct. 10, 2011, accessed from http://en.wikipedia.org/wiki/index,php?title=Digital<sub>&#x2014;</sub>image<sub>&#x2014;</sub>processing&#x26;oldid=454838118, on May 23, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Wikipedia, &#x201c;Image processing,&#x201d; 3 pages, edited on Oct. 8, 2011, accessed from http://en.wikipedia.org/wiki/index,php?title=Image<sub>&#x2014;</sub>processing&#x26;oldid=454580959, on May 23, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382165</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382173</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Brenner</last-name>
<first-name>Claus</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Brenner</last-name>
<first-name>Claus</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sterne, Kessler, Goldstein &#x26; Fox PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Google Inc.</orgname>
<role>02</role>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Wu</last-name>
<first-name>Jingge</first-name>
<department>2665</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Embodiments use the content of photographic images to stylize geographic features in the photographic images. In an embodiment, a computer-implemented method stylizes geographic features in a photographic image. In the method, a plurality of pixel regions in the photographic image are identified. For respective pixel regions, a plurality of attributes of image content within the pixel region of the photographic image are identified using the image content, and a geographic content type of the pixel region is determined using a classifier trained to recognize the geographic content type based on the plurality of attributes. Finally, at least one of the plurality of pixel regions of the photographic image are altered based on the respective determined geographic content type to stylize a geographic feature illustrated in the photographic image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="159.00mm" wi="232.33mm" file="US08625890-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="234.44mm" wi="162.48mm" orientation="landscape" file="US08625890-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="225.98mm" wi="166.54mm" file="US08625890-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="223.10mm" wi="161.21mm" file="US08625890-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="222.50mm" wi="161.54mm" orientation="landscape" file="US08625890-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="222.17mm" wi="165.02mm" orientation="landscape" file="US08625890-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="219.88mm" wi="160.53mm" orientation="landscape" file="US08625890-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">1. Field</p>
<p id="p-0003" num="0002">This disclosure generally relates to stylizing geographic features in images.</p>
<p id="p-0004" num="0003">2. Related Art</p>
<p id="p-0005" num="0004">To stylize maps, cartographers enhance the representation of some geographic features, while deemphasizing others. Moreover, in some cases, cartographers simplify geometries to make maps easier to read while still conveying essential information to a user. For example, maps that are generally available from online mapping services, such as GOOGLE Maps and MICROSOFT BING Maps, typically depict the road network, while omitting other geographic features. Further, the depiction of the roads may not be to scale and, depending on zoom level, may omit minor roads to simplify the image.</p>
<p id="p-0006" num="0005">Some online mapping services also display aerial photographic images. The aerial images may be overlaid with other information, such as street network, or point labels such as business locations. However, aerial images contain a lot of information. They contain colors, regions, and lines, to form complex patterns that can and may distract the user from any additional information that is superimposed.</p>
<p id="p-0007" num="0006">Moreover, image processing tools exist for modifying images, such as photographic images. For example, an ADOBE PHOTOSHOP tool allows for selective brightening or dimming of image content. However, manual intervention is normally needed to select manually the regions to be modified.</p>
<heading id="h-0002" level="1">BRIEF SUMMARY</heading>
<p id="p-0008" num="0007">Embodiments use the content of photographic images to stylize geographic features in the photographic images. In an embodiment, a computer-implemented method stylizes geographic features in a photographic image. In the method, a plurality of pixel regions in the photographic image are identified. For respective pixel regions, a plurality of attributes of image content within the pixel region of the photographic image are identified using the image content, and a geographic content type of the pixel region is determined using a classifier trained to recognize the geographic content type based on the plurality of attributes. Finally, at least one of the plurality of pixel regions of the photographic image are altered based on the respective determined geographic content type to stylize a geographic feature illustrated in the photographic image.</p>
<p id="p-0009" num="0008">System, method, and computer program product embodiments are also disclosed.</p>
<p id="p-0010" num="0009">Further embodiments, features, and advantages of the invention, as well as the structure and operation of the various embodiments of the invention are described in detail below with reference to accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading>
<p id="p-0011" num="0010">The accompanying drawings, which are incorporated herein and form a part of the specification, illustrate the present invention and, together with the description, further serve to explain the principles of the invention and to enable a person skilled in the pertinent art to make and use the invention.</p>
<p id="p-0012" num="0011">The patent or application file contains at least one drawing executed in color. Copies of this patent or patent application with color drawing(s) will be provided by the Office upon request and payment of necessary fee.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating a system for stylizing geographic features in aerial photographic images, according to an embodiment.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating a system for generating a content type mask for a geographic photographic image that can be used to stylize an image, according to a further embodiment.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart illustrating a method for stylizing geographic features in aerial photographic images, according to an embodiment.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 4</figref> is an aerial photographic image.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 5</figref> shows the aerial photographic image of <figref idref="DRAWINGS">FIG. 4</figref> that has been stylized to emphasize buildings and trees.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 6</figref> shows the aerial photographic image of <figref idref="DRAWINGS">FIG. 4</figref> that has been stylized to emphasize roads.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0019" num="0018">The drawing in which an element first appears is typically indicated by the leftmost digit or digits in the corresponding reference number. In the drawings, like reference numbers may indicate identical or functionally similar elements.</p>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF EMBODIMENTS</heading>
<p id="p-0020" num="0019">Embodiments relate to stylizing aerial photographic images to emphasize or deemphasize geographic features. In an embodiment, a photographic image may be divided into regions having similar characteristics. For example, the photographic image may be divided into regions having similar color bands, such as red green and blue color bands. Those regions are each analyzed to determine attributes. For example, the regions may be analyzed to determine the degree to which the red, green, and blue colors are represented in each region. Similarly, a magnitude of infrared light detected within the region may be determined. Further, stereo matching may be used to determine an altitude of the region in the photographic image. Based on these attributes, a content type of the region may be determined. Finally, the content type is used to alter the region of the photographic image to stylize a geographic feature having the content type. Altering the region may involve brightening, dimming, color modifying, or blurring to emphasize or deemphasize the geographic feature.</p>
<p id="p-0021" num="0020">In the detailed description of embodiments that follows, references to &#x201c;one embodiment&#x201d;, &#x201c;an embodiment&#x201d;, &#x201c;an example embodiment&#x201d;, etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily include the particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Further, when a particular feature, structure, or characteristic is described in connection with an embodiment, it is submitted that it is within the knowledge of one skilled in the art to effect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described.</p>
<p id="h-0005" num="0000">System</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating a system <b>100</b> for stylizing geographic features in aerial photographic images, according to an embodiment. System <b>100</b> includes an aerial image database <b>102</b>, a processing pipeline server <b>110</b>, and a stylized image database <b>150</b>. Processing pipeline server <b>110</b> includes an image region module <b>112</b>, a region attribute module <b>120</b>, a classifier module <b>140</b>, and an image alteration module <b>144</b>.</p>
<p id="p-0023" num="0022">In an example operation, image region module <b>112</b> retrieves an image from aerial image database <b>102</b>. Image region module <b>112</b> identifies a plurality of pixel regions <b>114</b> in the retrieved image. Region attribute module <b>120</b> analyzes each pixel region <b>114</b> to determine a variety of attributes associated with pixel region <b>114</b>. The attributes shown in <figref idref="DRAWINGS">FIG. 1</figref> include color magnitudes <b>130</b>, Normalized Difference Vegetation Index (NDVI) signal <b>132</b>, and a normalized altitude value <b>134</b>. Based on these signals, classifier module <b>140</b> determines a geographic content type for the pixel region. In one embodiment, region attribute module <b>120</b> and classifier module <b>140</b> may repeatedly or in parallel analyze each pixel region <b>114</b> determine a respective geographic content type <b>142</b>. Based on the respective content types <b>142</b>, image alteration module <b>144</b> determines a stylized version of the retrieved image and stores the stylized image in stylized image database <b>150</b>. Each of these modules and their functionality are described in greater detail below.</p>
<p id="p-0024" num="0023">Aerial image database <b>102</b> stores aerial photographic images. The images may be taken from an airplane or satellite, may have an oblique or nadir perspective of Earth images, and may be orthorectified, for example, to be displayed with map data. The images may have been stitched together from a variety of images covering overlapping geographic regions. For each image, the photographic image data may include light information for each pixel in the image. The light information may include not only traditional red, green, and blue light magnitudes, but also a light magnitude for infrared signals detected at that pixel. Moreover, each image may have corresponding panchromatic (i.e., black and white) image data.</p>
<p id="p-0025" num="0024">From aerial image database <b>102</b>, image region module <b>112</b> may retrieve a digital photographic image. In the photographic image, image region module <b>112</b> identifies a plurality of pixel regions <b>114</b>. The pixel regions may have similar characteristics. For example, each pixel region may have pixels that generally fall in a narrow color range. A variety of image segmentation techniques may be used to partition the image into regions. The image segmentation algorithm may try to detect edges between the various regions. In one example embodiment, to detect the edges, color or intensity values for the various pixels may be placed in a histogram and the histogram may be analyzed for peaks and valleys. In this way, the image may be divided into image regions, and the image regions may be analyzed holistically.</p>
<p id="p-0026" num="0025">By analyzing a region with plurality of pixels together, the category type determinations may be less sensitive to noise between individual pixels. However, in an alternative embodiment, image region module <b>112</b> may simply divide the image into individual pixels, and each of pixel regions <b>114</b> may consist of only one pixel from the retrieved image.</p>
<p id="p-0027" num="0026">For each of the respective pixel regions <b>114</b>, region attribute module <b>120</b> identifies a plurality of attributes of image content within the pixel region. Based on the image attributes, classifier module <b>140</b> determines a geographic content type <b>142</b> associated with the respective pixel region <b>114</b>.</p>
<p id="p-0028" num="0027">To determine image attributes for the image region, region attribute module <b>120</b> includes various submodules that each determine a different type of attribute for the region. In particular, region attribute module <b>120</b> includes a color module <b>122</b>, an IR module <b>124</b>, and an altitude determination module <b>126</b>. Each of these subcomponents is described below.</p>
<p id="p-0029" num="0028">Color module <b>122</b> determines color magnitudes <b>130</b> for the pixel region. Each color magnitude <b>130</b> may be a magnitude corresponding to the strength or relative strength of light at a particular wavelength within the pixel region. For example, color magnitudes <b>130</b> may include a red magnitude, a green magnitude, and a blue magnitude. The respective magnitudes may be determined, for example, by averaging the magnitudes of each pixel in a pixel region.</p>
<p id="p-0030" num="0029">Similar to color module <b>122</b>, IR module <b>124</b> determines an IR magnitude of infrared signals captured for the pixel region of the photographic image. In one embodiment, IR module <b>124</b> may use the IR magnitude to determine a Normalized Difference Vegetation Index (NDVI) for the pixel region. The NDVI may be a value representing the likelihood that the pixel region represents live green vegetation. The likelihood that the pixel region represents vegetation may increase as the IR magnitude increases and may decrease as the red color magnitude increases. Accordingly, the NDVI may be calculated using the following formula: NDVI=(I&#x2212;R)/(I+R), where I represents the magnitude of infrared signals in the pixel region and R represents the magnitude of red signals in pixel region. In an example, if the end NDVI exceeds 0.2 the region may very likely contain vegetation.</p>
<p id="p-0031" num="0030">Altitude determination module <b>126</b> determines an altitude value representing the altitude of the geographic area represented in the pixel region. In an embodiment, altitude determination module <b>126</b> may determine an altitude value for each respective pixel in the pixel region of the photographic image.</p>
<p id="p-0032" num="0031">To determine the altitude for respective pixels, multiple overlapping aerial images taken from different perspectives may be used. For example, a stereo matching algorithm may be used to correlate different features from two images and triangulate their position relative the cameras. Other algorithms may be used, such as plane matching and dense stereo matching. Other algorithms may be used, which compute a dense stereo matching, i.e., produce one altitude for every pixel of the aerial image. This may use methods like plane sweep stereo. To determine the altitude, panchromatic (black-and-white) image data may be used. Altitude determination module <b>126</b> may average the altitude values for the respective pixels in the pixel region to determine an altitude value for the entire pixel region.</p>
<p id="p-0033" num="0032">Moreover, altitude determination module <b>126</b> may normalize the altitude value determined for the pixel region against an altitude value for the geographic region to determine a normalized altitude value <b>134</b>. In an example, the altitude value for the pixel region may be normalized by simply subtracting an altitude value representing the ground of the geographic region. In this way, by normalizing the value, the altitude value may represent a relative height of the pixel region and may become more probative of whether the pixel region represents an above-ground structure, such as a building or tree.</p>
<p id="p-0034" num="0033">Once attributes of the pixel region, including color magnitudes <b>130</b>, NDVI signal <b>132</b>, and normalized altitude value <b>134</b>, are determined, the attributes may be used by classifier module <b>140</b> to determine a geographic content type <b>142</b> of the pixel region. Classifier module <b>140</b> uses a classifier trained to recognize the geographic content type based on the plurality of attributes using a smaller subset of images. Classifier module <b>140</b> may use any one of a number of different types of classification algorithms, such as k-means clustering, artificial neural network, or statistical classification. To use classifier module <b>140</b>, the classification algorithm may first need to be manually trained. Manual training may involve a user identifying geographic content types within images. After manually training a small percentage of the images, classifier module <b>140</b> can then be used to determine automatically geographic content types for the remaining images.</p>
<p id="p-0035" num="0034">In an embodiment, classifier module <b>140</b> may map each pixel region <b>114</b> into one of four possible geographic content types&#x2014;&#x201c;building,&#x201d; &#x201c;ground,&#x201d; &#x201c;tree,&#x201d; and &#x201c;grass.&#x201d; With these content types, classifier module <b>140</b> may utilize some relatively simple heuristics to determine the geographic content type for each imagery region. For example, if the altitude value <b>134</b> exceeds a first threshold value, the geographic content type may be either &#x201c;building&#x201d; or &#x201c;tree&#x201d; depending on whether the NDVI signal <b>132</b> exceeds a second threshold value. If the altitude value <b>134</b> does not exceed the first threshold value, the geographic content type may be either &#x201c;ground&#x201d; or &#x201c;grass&#x201d; again depending on whether the NDVI signal <b>132</b> exceeds the second threshold.</p>
<p id="p-0036" num="0035">Once a geographic content type <b>142</b> is determined for each of the pixel regions <b>114</b>, image alteration module <b>144</b> alters the pixel regions of the photographic image based on the respective determined geographic content type <b>114</b> to stylize a geographic feature illustrated in the photographic image. In a first example, all pixel regions having a particular geographic content type may be brightened, and all pixel regions not having the particular geographic content type may be darkened. This may serve to emphasize the geographic features within the pixel regions having the particular geographic content type. In an embodiment, when stylizing the photographic image, image alteration module <b>144</b> may blend the edges of the respective pixel regions. The stylization may be done using predefined settings or may be set or adjusted by a user using stylization controls.</p>
<p id="p-0037" num="0036">In a second example, all pixel regions not having a particular geographic content type may be blurred, and all pixel regions having the particular geographic content type may be sharpened. This may create a sense that the pixel regions not having the particular geographic content type are out of focus. In this way, the user's attention may be drawn to the geographic features in the image regions having the particular geographic content type.</p>
<p id="p-0038" num="0037">In the third example, in pixel regions having a particular content type, the colors may be simplified. For example, an average color of all pixel regions having a particular geographic content type may be determined, and every pixel in a pixel region having the particular geographic content type may be set to the average color. In this way, potentially distracting details of the geographic image may be removed.</p>
<p id="p-0039" num="0038">Similarly, image alteration module <b>144</b> may otherwise alter the colors in the pixel regions based on the respective geographic content type. For example, buildings may be made more reddish and vegetation may be made more greenish.</p>
<p id="p-0040" num="0039">Once image alteration module <b>144</b> has altered pixel regions of the aerial image according to their respective geographic content type, image alteration module <b>144</b> may store the altered image into stylized image database <b>150</b>. Stylized image database <b>150</b> may be available to a mapping service, and a stylized image stored in database <b>150</b> may be served to users in response to a request. Additional use cases of stylized images, including the creation of the content type mask, are described with respect to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating a system <b>200</b> for generating a content type mask for a geographic photographic image that can be used to stylize an image, according to a further embodiment. Similar to system <b>100</b> and <figref idref="DRAWINGS">FIG. 1</figref>, system <b>200</b> includes a processing pipeline server <b>110</b> and a classifier module <b>140</b> that generates geographic content types <b>142</b> corresponding to respective pixel regions of the aerial photographic image. In <figref idref="DRAWINGS">FIG. 2</figref>, processing pipeline server <b>110</b> further includes an image mask module <b>260</b> coupled to an image and mask database <b>262</b>.</p>
<p id="p-0042" num="0041">In <figref idref="DRAWINGS">FIG. 1</figref>, image alteration module <b>144</b> is shown on processing pipeline server <b>110</b>. However, in system <b>200</b> in <figref idref="DRAWINGS">FIG. 2</figref>, image alteration module <b>144</b> resides on a client <b>274</b>. Client <b>274</b> may communicate with a web server <b>270</b> via one or more networks <b>272</b>. In another example not shown, the image alteration module may reside on the web server <b>270</b> and may be accessible to client <b>274</b> via one or more web services.</p>
<p id="p-0043" num="0042">In general, system <b>200</b> may operate as follows. As described above with respect to <figref idref="DRAWINGS">FIG. 1</figref>, classifier module <b>140</b> may generate geographic content types <b>142</b> specifying a content type for respective pixel regions in an aerial image. Based on the geographic content types <b>142</b>, image mask module <b>260</b> may generate an image mask that maps pixels of the aerial image to corresponding content types. Image mask module <b>260</b> may store the content type mask associated with the aerial image in image mask database <b>262</b>. In response to requests from client <b>274</b>, web server <b>270</b> may retrieve both the aerial image and a content type mask from image and mask database <b>262</b>. Web server <b>270</b> may then send the image and mask back to client <b>274</b>. On client <b>274</b>, image alteration module <b>144</b> may stylize geographic features in the aerial image using the content type mask. Each of these modules and their operation are described in greater detail below.</p>
<p id="p-0044" num="0043">Image mask module <b>260</b> determines a content type mask that maps each pixel in the photographic image to a corresponding geographic content type determined by the classifier module <b>140</b>. As mentioned above, the geographic content types <b>142</b> each specify a content type for pixel region in the aerial image. To determine the mask, image mask module <b>260</b> may set a value for each pixel in the aerial image. More specifically, for each pixel in the aerial image, image mask module <b>260</b> may determine which pixel region the pixel resides in and which geographic content type <b>142</b> corresponds to that pixel region. The determined content type may be set to that pixel location in the mask.</p>
<p id="p-0045" num="0044">As mentioned above, in an embodiment there may be four geographic content types&#x2014;ground, building, grass, and tree. In that embodiment, the mask may allocate two bits for each pixel in the aerial image. In this way, the content mask may not consume very much space.</p>
<p id="p-0046" num="0045">Once determined by image mask module <b>260</b>, image mask module <b>260</b> stores the content mask along with the aerial image in image and mask database <b>262</b>.</p>
<p id="p-0047" num="0046">Web server <b>270</b> may provide a mapping service accessible via one or more networks <b>272</b>. When a client, such as client <b>274</b>, requests an aerial image, web server <b>270</b> may retrieve both the aerial image and the content type mask associated with the aerial image and send both back to the client.</p>
<p id="p-0048" num="0047">When the client, such as client <b>274</b>, receives the aerial image in the content type mask from web server <b>270</b>, image alteration module <b>144</b> alters portions of the aerial image based on the content type mask. In this way, image alteration module <b>144</b> can stylize geographic features in the aerial image on the client side. When the user takes an action that involves stylizing a geographic feature, image alteration module <b>144</b> may use the content type mask to determine what type of geographic information resides at each pixel in the aerial image. Using that information, image alteration module <b>144</b> may emphasize geographic features in the aerial image that are likely to be of interest and deemphasize geographic features in aerial image that are not likely to be of interest.</p>
<p id="p-0049" num="0048">In a first example, the user may search for addresses or points of interest, such as businesses, within the aerial image. In that example, areas having a &#x201c;building&#x201d; content type may be brightened, and areas having a &#x201c;road&#x201d; or other content type may be dimmed or darkened. Moreover, using information in the content type mask, client <b>274</b> may position labels for the businesses in areas of the aerial image that are not designated as having a &#x201c;building&#x201d; content type. In this way, the labels are less likely to obscure buildings that may be of interest. Further, if the text of the labels are white, they may be more readable when placed on the darker areas of the image.</p>
<p id="p-0050" num="0049">In a second example, a user may request routing directions, such as driving directions. In that example, roads are likely to be of more interest than other features displayed in the aerial image. For that reason, areas having a &#x201c;road&#x201d; content type in a content type mask may be brightened, and areas having other content types (such as buildings and trees) may be dimmed.</p>
<p id="p-0051" num="0050">In a third example, image alteration module <b>144</b> may alter specific pixel regions, as opposed to altering all pixel regions having a particular content type. When the user hovers the mouse across a building, for example, the building may be brightened while other areas of the aerial image may be dimmed. To alter the specific pixel region, image alteration module <b>144</b> may identify a region of contiguous pixels having the same content type in the content type mask. Then, image alteration module <b>144</b> may alter that region.</p>
<p id="p-0052" num="0051">Each of processing pipeline server <b>110</b>, web server <b>270</b>, and client <b>274</b> may be implemented on any computing device. Such computing device can include, but is not limited to, a personal computer, mobile device such as a mobile phone, workstation, embedded system, game console, television, set-top box, or any other computing device. Further, a computing device can include, but is not limited to, a device having a processor and memory for executing and storing instructions. Software may include one or more applications and an operating system. Hardware can include, but is not limited to, a processor, memory and graphical user interface display. The computing device may also have multiple processors and multiple shared or separate memory components. For example, the computing device may be a clustered computing environment or server farm.</p>
<p id="p-0053" num="0052">Each of image region module <b>112</b>, region attribute module <b>120</b>, color module <b>122</b>, IR module <b>124</b>, altitude determination module <b>126</b>, classifier module <b>140</b>, image alteration module <b>144</b>, and image mask module <b>260</b> may be implemented in hardware, software, firmware, or any combination thereof.</p>
<p id="p-0054" num="0053">Each of aerial image database <b>102</b>, stylized image database <b>150</b>, and image mask database <b>262</b> may be any type of structured memory, including a persistent memory. In examples, each database may be implemented as a relational database. It may be also implemented as part of a distributed storage system (e.g., &#x201c;stored in the cloud&#x201d;), which is not a relational database.</p>
<p id="h-0006" num="0000">Method</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart illustrating a method <b>300</b> for stylizing geographic features in aerial photographic images, according to an embodiment. In embodiments, method <b>300</b> may be used in operation of systems <b>100</b> and <b>200</b> in <figref idref="DRAWINGS">FIGS. 1 and 2</figref>.</p>
<p id="p-0056" num="0055">Method <b>300</b> begins by identifying a plurality of pixel regions of an aerial image at step <b>302</b>. The pixel regions may each include areas the of the aerial image having similar characteristics, such as color.</p>
<p id="p-0057" num="0056">After the pixel regions are identified, steps <b>304</b> and <b>306</b> are repeated for each of the respective pixel regions, as illustrated by decision block <b>308</b>. While <figref idref="DRAWINGS">FIG. 3</figref> illustrates sequential operation of steps <b>304</b> and <b>306</b>, the skilled artisan would recognize that steps <b>304</b> and <b>306</b> may occur in parallel for each of the respective pixel regions.</p>
<p id="p-0058" num="0057">At step <b>304</b>, a plurality of attributes of image content within the pixel region are identified using the image content. The attributes may include a color magnitude for respective colors in the region. Similarly, the attributes may include a magnitude of infrared light captured in the region, or a calculated NDVI signal indicating a likelihood that the region illustrates vegetation. Finally, the attributes may include a relative height of objects in the region. The height may be relative to a height in the aerial image as a whole.</p>
<p id="p-0059" num="0058">At step <b>306</b>, a geographic content type of the pixel region is determined using a classifier trained to recognize the geographic content type based on the plurality of attributes.</p>
<p id="p-0060" num="0059">Once the geographic content type for each of the respective pixel regions is determined, the images are altered based on the content type to stylize geographic features within the image at step <b>310</b>. In a first embodiment, the altering may include inserting highlighting into the photographic image to emphasize a particular pixel region. In a second embodiment, the altering may include determining an average color of all pixel regions having a particular geographic content type and setting every pixel in a pixel region having the particular geographic content type to the determined average color. In a third embodiment, the altering may include brightening or dimming regions of a content type mask having a particular geographic content type. Finally, in a fourth embodiment, the altering may include blurring or sharpening regions having a particular geographic content type.</p>
<p id="p-0061" num="0060">The altering of step <b>310</b> may involve altering the original file. Alternatively, the altering may be applied when the original image file is rendered by the client. In that embodiment, the defined style effects may be pre-defined so that when the image is rendered for display, the client applies the pre-defined style without altering the original image</p>
<p id="p-0062" num="0061">Method <b>300</b> may for example, be performed by a computing device executing a program of instructions tangibly embodied in a non-transitory computer-readable medium.</p>
<p id="p-0063" num="0062">In this way, method <b>300</b> enables stylization of geographic features within an aerial photographic image. Examples of stylizing an aerial image are illustrated in <figref idref="DRAWINGS">FIGS. 4-6</figref> below.</p>
<p id="h-0007" num="0000">Example Images</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 4</figref> shows an aerial photographic image <b>400</b>. Image <b>400</b> may be taken from for example an aircraft or satellite. Image <b>400</b> shows an urban area from a nadir perspective. Image <b>400</b> includes much detail that may be unnecessary and distracting to a user. For example, image <b>400</b> includes trees, buildings, and roads.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 5</figref> shows a modified image <b>500</b>. Modified image <b>500</b> has been determined from the aerial photographic image <b>400</b> in <figref idref="DRAWINGS">FIG. 4</figref> and has been stylized to emphasize buildings and trees in accordance with an embodiment. In image <b>500</b>, trees have been made greener, roads have been made darker, and buildings have been made brighter.</p>
<p id="p-0066" num="0065">Similarly, <figref idref="DRAWINGS">FIG. 6</figref> shows a modified image <b>600</b>. Modified image <b>600</b> has been determined from the aerial photographic image <b>400</b> in <figref idref="DRAWINGS">FIG. 4</figref> and has been stylized to emphasize roads in accordance with an embodiment. In image <b>600</b>, buildings have been made darker.</p>
<p id="h-0008" num="0000">Additional Advantages</p>
<p id="p-0067" num="0066">Some embodiments may have additional advantages not specifically enumerated above. First, geographic content types are computed by pixel operations only. No feature extraction, object detection, or modeling are necessary. Thus, production of the enhanced aerial images is much cheaper than the production of maps.</p>
<p id="p-0068" num="0067">Second, in a conventional map, errors (such as building footprints with incorrect shapes) may be easy to discover and may be disturbing to a user. However, in the proposed enhanced images, those errors may be easier to oversee. Thus, embodiments may be more forgiving and may require less quality assurance resources in production.</p>
<p id="p-0069" num="0068">Third, in contrast to conventional maps, no manual editing may be required to stylize aerial images according to embodiments.</p>
<p id="p-0070" num="0069">Fourth and finally, detected regions may be used as &#x201c;proxies&#x201d; to the real geometry. In other words, regions, which are just connected sets of identically classified pixels, are used as a substitute for exactly mapped regions, which are not available since it is too expensive to obtain them. For example, if the desired behavior is to &#x201c;brighten&#x201d; a building when the mouse pointer hovers over it, building footprint information would normally be needed to determine when the mouse is over the building and which pixels are to be highlighted. However, according to embodiments using just connected pixel regions, the same effect may be achieved without needing an exact building footprint.</p>
<p id="p-0071" num="0070">The Summary and Abstract sections may set forth one or more but not all exemplary embodiments of the present invention as contemplated by the inventor(s), and thus, are not intended to limit the present invention and the appended claims in any way.</p>
<p id="p-0072" num="0071">The present invention has been described above with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof. The boundaries of these functional building blocks have been arbitrarily defined herein for the convenience of the description. Alternate boundaries can be defined so long as the specified functions and relationships thereof are appropriately performed.</p>
<p id="p-0073" num="0072">The foregoing description of the specific embodiments will so fully reveal the general nature of the invention that others can, by applying knowledge within the skill of the art, readily modify and/or adapt for various applications such specific embodiments, without undue experimentation, without departing from the general concept of the present invention. Therefore, such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed embodiments, based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation, such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance.</p>
<p id="p-0074" num="0073">The breadth and scope of the present invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer-implemented method for stylizing geographic features in a photographic image, comprising:
<claim-text>(a) identifying a plurality of pixel regions in the photographic image;</claim-text>
<claim-text>for each pixel region in the plurality of pixel regions:</claim-text>
<claim-text>(b) identifying a plurality of attributes of image content within the pixel region of the photographic image using the image content, the identifying (b) comprising determining altitude values for respective pixels in the pixel region of the photographic image;</claim-text>
<claim-text>(c) normalizing the altitude values for respective pixels in the pixel region against an altitude value representing an altitude of the ground in a geographic region illustrated in the photographic image;</claim-text>
<claim-text>(d) determining a geographic content type of the pixel region using a classifier trained to recognize the geographic content type based on the plurality of attributes, the determining (d) comprising determining whether the geographic content type is a man-made structure based, at least in part, on the normalized altitude values for respective pixels, wherein a likelihood of the geographic content type being determined to be a man-made structure increases as the normalized altitude value increases; and</claim-text>
<claim-text>(e) altering at least one of the plurality of pixel regions of the photographic image based on the respective determined geographic content type to stylize a geographic feature illustrated in the photographic image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the identifying (b) further comprises determining a color magnitude of each of a plurality of colors illustrated within the pixel region of the photographic image, and
<claim-text>wherein the determining (d) comprises determining the geographic content type based, at least in part, on each color magnitude identified in (b).</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the identifying (b) further comprises determining an IR magnitude of infrared signals captured for the pixel region of the photographic image, and
<claim-text>wherein the determining (d) further comprises determining whether the geographic content type is vegetation based, at least in part on, on the IR magnitude and a color magnitude of a red color within the pixel region identified in (b), wherein a likelihood of the geographic content type being determined to be vegetation increases as the IR magnitude increases, and the likelihood decreases as the red magnitude increases.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>(f) determining a content type mask that maps each pixel in the photographic image to a corresponding geographic content type determined in (d), and</claim-text>
<claim-text>wherein altering (e) comprises altering the at least one pixel region based on the content type mask determined in (f).</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein altering (e) comprises inserting highlighting into the photographic image to emphasize a particular pixel region.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein altering (e) comprises altering the photographic image such that all pixel regions having a particular geographic content type are brightened relative to all pixel regions not having the particular geographic content type.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein altering (e) comprises altering the photographic image such that all pixel regions not having a particular geographic content type are blurred relative to all pixel regions having the particular geographic content type.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein altering (e) comprises:
<claim-text>(i) determining an average color of all pixel regions having a particular geographic content type; and</claim-text>
<claim-text>(ii) setting every pixel in a pixel region having the particular geographic content type to the average color determined in (i).</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining (d) comprises selecting the geographic content type from the group consisting of roads, buildings, grass, and trees.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A computer-implemented system for stylizing geographic features in a photographic image, comprising:
<claim-text>an image region module that identifies a plurality of pixel regions in the photographic image;</claim-text>
<claim-text>a region attribute module that, for each pixel region in the plurality of pixel regions, identifies a plurality of attributes of image content within the pixel region of the photographic image based on content within the pixel region, wherein the region attribute module comprises an altitude determination module that, for the respective pixel regions:
<claim-text>(i) determines an altitude value for respective pixels in the pixel region of the photographic image, and</claim-text>
<claim-text>(ii) normalizes the altitude values for respective pixels in the pixel region against an altitude value representing an altitude of the ground in the geographic region illustrated in the photographic image;</claim-text>
</claim-text>
<claim-text>a classifier module trained to recognize the geographic content type based on the plurality of attributes, wherein the classifier module determines a geographic content type for each of the respective pixel regions using a classifier, and wherein the classifier module determines whether the geographic content type is a man-made structure based, at least in part, on the normalized altitude values for respective pixels determined by the altitude determination module, wherein a likelihood of the geographic content type being determined to be a man-made structure increases as the normalized altitude value increases; and</claim-text>
<claim-text>an image alteration module that alters at least one of the plurality of pixel regions of the photographic image based on the respective determined geographic content type to stylize a geographic feature illustrated in the photographic image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the region attribute module determines a color magnitude of each of a plurality of colors illustrated within the pixel region of the photographic image, and
<claim-text>wherein the classifier module determines the geographic content type based, at east in part, on each color magnitude determined by the region attribute module.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the region attribute module determines an IR magnitude of infrared signals captured for the pixel region of the photographic image, and
<claim-text>wherein the classifier module determines whether the geographic content type is vegetation based, at least in, part on, on the IR magnitude and a color magnitude of a red color within the respective pixel region, wherein a likelihood of the geographic content type being determined to be vegetation increases as the IR magnitude increases, and the likelihood decreases as the red magnitude increases.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:
<claim-text>an image mask module that determines a content type mask that maps each pixel in the photographic image to a corresponding geographic content type determined by the classifier module, and</claim-text>
<claim-text>wherein the image alteration module alters the at least one pixel region based on the content type mask.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein image alteration module inserts highlighting into the photographic image to emphasize a particular pixel region.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein image alteration module alters the photographic image such that all pixel regions having a particular geographic content type are brightened relative to all pixel regions not having the particular geographic content type.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the image alteration, module alters the photographic image such that all pixel regions not having a particular geographic content type are blurred relative to all pixel regions having the particular geographic content type.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein image alteration module:
<claim-text>(i) determines an average color of all pixel regions having a particular geographic content type, and</claim-text>
<claim-text>(ii) sets every pixel in a region having the particular geographic content type to the average color.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein classifier module selects the geographic content type from the group consisting of roads, buildings, grass, and trees.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A computer-implemented system for stylizing geographic features in a photographic image, comprising:
<claim-text>a server configured to:</claim-text>
<claim-text>(i) identify a plurality of pixel regions in the photographic image, for each pixel region in the plurality of pixel regions:</claim-text>
<claim-text>(ii) identify a plurality of attributes of image content within the pixel region of the photographic image based on image content within the pixel region, the plurality of attributes including altitude values for respective pixels in the pixel region of the photographic image,</claim-text>
<claim-text>(iii) normalize the altitude values for respective pixels in the pixel region against an altitude value representing an altitude of the ground in a geographic region illustrated in the photographic image;</claim-text>
<claim-text>(iv) determine whether a geographic content type of the pixel region is a man-made structure using a classifier trained to recognize the geographic content type based on the plurality of attributes including the normalized altitude values for respective pixels such that a likelihood of the geographic content type being determined to be a man-made structure increases as the normalized altitude value increases,</claim-text>
<claim-text>(v) alter at least one of the plurality of pixel regions of the photographic image based on the respective determined geographic content type to stylize a geographic feature illustrated in the photographic image, and</claim-text>
<claim-text>(vi) provide the altered image over a network in response to a request;</claim-text>
<claim-text>a client configured to receive the altered image from the server via the network and display the image as a map.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A nontransitory program storage device embodying a program of instructions executable by at least one machine to perform a method for stylizing geographic features in a photographic image, said method comprising:
<claim-text>(a) identifying a plurality of pixel regions in the photographic image, for each pixel region in the plurality of pixel regions:</claim-text>
<claim-text>(b) identifying a plurality of attributes of image content within the pixel region of the photographic image based on image content within the pixel region, the plurality of attributes including altitude values for respective pixels in the pixel region of the photographic image,</claim-text>
<claim-text>(c) normalizing the altitude values for respective pixels in the pixel region against an altitude value representing an altitude of the ground in a geographic region illustrated in the photographic image;</claim-text>
<claim-text>(d) determining whether a geographic content type of the pixel region is a man-made structure using a classifier trained to recognize the geographic content type based on the plurality of attributes including the normalized altitude values for respective, pixels such that a likelihood of the geographic content type being determined to be a man-made structure increases as the normalized altitude value increases; and</claim-text>
<claim-text>(e) altering at least one of the plurality of pixel regions of the photographic image based on the respective determined geographic content type to stylize a geographic feature illustrated in the photographic image.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
