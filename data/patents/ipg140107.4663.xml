<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625751-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625751</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13186876</doc-number>
<date>20110720</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>85</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>11</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>379 8813</main-classification>
<further-classification>37914206</further-classification>
</classification-national>
<invention-title id="d2e55">System and method of audible caller identification via a multimedia device</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4899358</doc-number>
<kind>A</kind>
<name>Blakley</name>
<date>19900200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5805677</doc-number>
<kind>A</kind>
<name>Ferry et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 9335</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5875232</doc-number>
<kind>A</kind>
<name>Wolf</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 8819</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5875239</doc-number>
<kind>A</kind>
<name>Koralewski et al.</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37914215</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5907604</doc-number>
<kind>A</kind>
<name>Hsu</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6038443</doc-number>
<kind>A</kind>
<name>Luneau</name>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6154531</doc-number>
<kind>A</kind>
<name>Clapper</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6178232</doc-number>
<kind>B1</kind>
<name>Latter et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6233325</doc-number>
<kind>B1</kind>
<name>Frech et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6292210</doc-number>
<kind>B1</kind>
<name>Gerszberg et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6493020</doc-number>
<kind>B1</kind>
<name>Stevenson et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6535594</doc-number>
<kind>B1</kind>
<name>Reeves-Nobles et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6735295</doc-number>
<kind>B1</kind>
<name>Brennan et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6738615</doc-number>
<kind>B1</kind>
<name>Chow et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6816469</doc-number>
<kind>B1</kind>
<name>Kung et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>7039698</doc-number>
<kind>B2</kind>
<name>Slemmer et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>7075919</doc-number>
<kind>B1</kind>
<name>Wendt et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>7103167</doc-number>
<kind>B2</kind>
<name>Brahm et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>7113586</doc-number>
<kind>B2</kind>
<name>Silver</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>7388949</doc-number>
<kind>B2</kind>
<name>Contractor et al.</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>7421067</doc-number>
<kind>B2</kind>
<name>Dewing et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 8812</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>7904067</doc-number>
<kind>B1</kind>
<name>Tiwari et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455415</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>8068591</doc-number>
<kind>B2</kind>
<name>Soo et al.</name>
<date>20111100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37914201</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2002/0171552</doc-number>
<kind>A1</kind>
<name>Tate</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2002/0181694</doc-number>
<kind>A1</kind>
<name>Mani</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2002/0184346</doc-number>
<kind>A1</kind>
<name>Mani</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2003/0190024</doc-number>
<kind>A1</kind>
<name>Ju</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2005/0010573</doc-number>
<kind>A1</kind>
<name>Garg</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2005/0070261</doc-number>
<kind>A1</kind>
<name>Belmont et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2007/0279247</doc-number>
<kind>A1</kind>
<name>Rye et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34082572</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>EP</country>
<doc-number>1505814</doc-number>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>EP</country>
<doc-number>1739936</doc-number>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>WO</country>
<doc-number>2006038586</doc-number>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>International Search Report and Written Opinion for International Patent No. PCT/US2007/018835, mailed on Dec. 14, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Voice Announce Caller ID TD-CLVoice, www.harriscomm.com, Sep. 12, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>379 8813- 8814</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37914206</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11590649</doc-number>
<date>02001031</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8009812</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13186876</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110274255</doc-number>
<kind>A1</kind>
<date>20111110</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Bruce</last-name>
<first-name>Les</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Brandt</last-name>
<first-name>Jeffrey L.</first-name>
<address>
<city>Cedar Park</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sullivan</last-name>
<first-name>Marc A.</first-name>
<address>
<city>Austin</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Hubscher</last-name>
<first-name>Mark B.</first-name>
<address>
<city>San Antonio</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Bruce</last-name>
<first-name>Les</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Brandt</last-name>
<first-name>Jeffrey L.</first-name>
<address>
<city>Cedar Park</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Sullivan</last-name>
<first-name>Marc A.</first-name>
<address>
<city>Austin</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Hubscher</last-name>
<first-name>Mark B.</first-name>
<address>
<city>San Antonio</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Toler Law Group, PC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>AT&#x26;T Intellectual Property I, L.P.</orgname>
<role>02</role>
<address>
<city>Atlanta</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Sing</last-name>
<first-name>Simon</first-name>
<department>2653</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method is disclosed that receives an incoming call at an electronic device, where the incoming call includes caller identification information. Further, the method determines whether a personal address book stored remotely from the electronic device includes an entry associated with the caller identification information. Additionally, an audio alert associated with the entry is inserted into a multimedia data stream, where the audio alert is determined based at least in part on the entry.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="208.96mm" wi="157.56mm" file="US08625751-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="230.38mm" wi="161.63mm" file="US08625751-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="231.31mm" wi="180.26mm" file="US08625751-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="215.90mm" wi="163.24mm" file="US08625751-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="217.34mm" wi="155.02mm" file="US08625751-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="214.12mm" wi="177.29mm" file="US08625751-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="215.56mm" wi="220.05mm" file="US08625751-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="215.90mm" wi="170.26mm" file="US08625751-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="215.90mm" wi="258.74mm" file="US08625751-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="215.65mm" wi="143.76mm" file="US08625751-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CLAIM OF PRIORITY</heading>
<p id="p-0002" num="0001">The present application is a continuation of and claims priority from U.S. patent application Ser. No. 11/590,649 filed on Oct. 31, 2006, the content of which is expressly incorporated herein by reference in its entirely.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE DISCLOSURE</heading>
<p id="p-0003" num="0002">The present disclosure is generally related to systems and methods of audible caller identification via a multimedia device.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">In general, caller identification devices are commercially available as assistive technologies for visually impaired individuals, for example, to provide an audible announcement of caller identification information. Such caller identification devices may be coupled to a telephone line to receive an incoming call and may include an audio output to produce an audible announcement of the caller identification information. However, such caller identification devices may not allow user customization. Additionally, such caller identification devices may be separate from other electronic devices that are already within a particular home. For example, if a user is focused on listening to an audio output of a particular electronic device, such as a television, the user may not hear an audio announcement of a caller identification provided by a separate caller identification device.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a particular illustrative embodiment of a system to provide an audio alert related to an incoming call with a multimedia data stream;</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a second particular alternative illustrative embodiment of a system to provide an audio alert related to an incoming call with a multimedia data stream;</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a third particular illustrative embodiment of a system to provide an audio alert related to an incoming call with a multimedia data stream;</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of a particular illustrative embodiment of a network system to provide an audio alert related to an incoming call via customer premises equipment;</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram of a particular illustrative embodiment of a user interface to receive user input to configure an electronic device to provide an audio alert;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 6</figref> is a flow diagram of a particular illustrative embodiment of a method of providing an audio alert related to an incoming call with a multimedia data stream for playback via a multimedia device;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 7</figref> is a flow diagram of a particular illustrative embodiment of a method of determining an audio alert associated with an incoming call;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 8</figref> is a flow diagram of a particular illustrative embodiment of a method of generating, at a network device, an audio alert related to an incoming call to customer premises equipment (CPE); and</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 9</figref> is a block diagram that is representative of a general computer system that may be used to provide an audio alert related to an incoming call.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013">In a particular illustrative embodiment, a method includes receiving an incoming call at an electronic device, where the incoming call includes caller identification information. The method further includes determining whether a personal address book stored remotely from the electronic device includes an entry associated with the caller identification information. Additionally, the method includes inserting an audio alert associated with the entry into a multimedia data stream, where the audio alert is determined based at least in part on the entry.</p>
<p id="p-0015" num="0014">In another particular embodiment, an electronic device includes an input, a memory, and a processor. The input receives caller identification information associated with a telephone call. The memory is coupled to the input and stores processor executable instructions. The processor is coupled to the input and to the memory. The processor determines whether a personal address book stored remotely from the electronic device includes an entry associated with the caller identification information. Additionally, the processor inserts an audio alert associated with the entry into a multimedia data stream, where the audio alert is determined based on the entry.</p>
<p id="p-0016" num="0015">In yet another particular embodiment, a non-transitory processor-readable medium including processor-executable instructions that, when executed by a processor, cause the processor to generate a graphical user interface. The graphical user interface is configured to enable a user associated with an electronic device to select a first personal address book stored remotely from the electronic device. A first audio alert associated with an entry of the first personal address book is inserted into a multimedia data stream that is received by the electronic device in response to an incoming call received at the electronic device.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a particular embodiment of a system <b>100</b> to provide an audio alert related to an incoming call with a multimedia data stream. The system <b>100</b> includes an electronic device <b>102</b> coupled to a network <b>104</b> via a first communications link <b>106</b>, which may include a digital subscriber line (DSL) or other broadband Internet connection (such as, for example, a Voice over Internet Protocol connection), a wireless connection, a plain old telephone service (POTS) connection, or another type of connection. The network <b>104</b> may receive an incoming call that is intended for a user associated with the electronic device <b>102</b>. For example, the incoming call may be received from a caller <b>108</b> via a second communications link <b>110</b>. In an illustrative embodiment, the second communications link <b>110</b> may be an Internet protocol link (such as a Voice over Internet Protocol connection), a wireless connection, a plain old telephone service (POTS) connection, or another type of connection. The network <b>104</b> may direct the incoming call from the caller <b>108</b> to the electronic device <b>102</b>. The electronic device <b>102</b> includes a network interface <b>116</b>, a processor <b>118</b>, a multimedia device interface <b>120</b>, a text-to-speech converter <b>122</b>, and a memory <b>124</b>. The electronic device <b>102</b> may be coupled to a multimedia device <b>112</b> via a communications link <b>114</b>, which may be a cable link, a wireless link, or another type of communications link.</p>
<p id="p-0018" num="0017">In a particular illustrative embodiment, the electronic device <b>102</b> may include a network interface <b>116</b> that is responsive to the network <b>104</b> to receive an incoming call including caller identification information, such as a name and a telephone number associated with the caller <b>108</b>. The processor <b>118</b> may utilize the caller identification information to produce an audio alert via the text-to-speech converter <b>122</b>. The processor <b>118</b> may insert the audio alert and the caller identification information into a multimedia data stream for audio playback and for display at the multimedia device <b>112</b>. In a particular embodiment, the caller identification information may be displayed within a pop up window <b>126</b> within the display area <b>128</b> of the multimedia device <b>112</b>. Additionally, the audio alert may be output as an audible sound <b>130</b> via speakers associated with the multimedia device <b>112</b>. The speakers may be integral with or coupled to the multimedia device <b>112</b>.</p>
<p id="p-0019" num="0018">In another particular embodiment, a user may configure the electronic device <b>102</b> to store an audio alert in the memory <b>124</b>. The user may associate the audio alert with a phone number associated with a particular caller, with a name of the particular caller, or with any combination thereof. In response to receiving an incoming call from the network <b>104</b>, the processor <b>118</b> may search the memory <b>124</b> to identify an audio alert related to the caller identification information associated with the incoming call. If no match is found, the processor <b>118</b> may utilize the text-to-speech converter <b>122</b> to generate an audio alert based on the caller identification information. If a match is found, the processor <b>118</b> may insert the identified audio alert into the multimedia data stream along with caller information stored in the memory, such as information stored in a personal address book.</p>
<p id="p-0020" num="0019">For example, in a particular illustrative embodiment, the caller <b>108</b> may be named Bob Smith. Caller identification information related to the caller <b>108</b> may be received from the network <b>104</b> (e.g. a caller name &#x201c;Bob Smith&#x201d; and a phone number &#x201c;512-555-5555&#x201d;). The processor <b>118</b> may receive the caller identification information from the network <b>104</b> via the network interface <b>116</b> and may search the memory <b>124</b> for stored caller information related to the caller identification information. If a match is identified but the caller information is not associated with an audio alert, the processor <b>118</b> may utilize the text-to-speech converter <b>122</b> to convert the identified caller information into an audio alert. For example, if the memory <b>124</b> includes a personal address book, a name or alias within the personal address book that is related to the caller identification information may be converted from text to speech to provide an audio alert. The processor <b>118</b> may then provide the audio alert to the multimedia device <b>112</b> for playback as an audible sound <b>130</b> via speakers associated with the multimedia device <b>112</b>. In a particular embodiment, the processor <b>118</b> inserts the audio alert and at least a portion of the identified caller information into a multimedia data stream, which is transmitted to the multimedia device <b>112</b> via the multimedia device interface <b>120</b>.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a second particular alternative embodiment of a system <b>200</b> to provide an audio alert related to an incoming call via a multimedia device. The system <b>200</b> includes a customer premises <b>202</b> having an electronic device <b>204</b>, such as a set-top box device, which is coupled to a multimedia device <b>112</b> via a connection <b>114</b>. In a particular embodiment, the electronic device <b>204</b> may be coupled to a public switched telephone network (PSTN) <b>206</b> via a communications link <b>208</b>, such as a plain old telephone service (POTS) connection, a wireless communications link, or another type of communications link. The electronic device <b>204</b> may include a multimedia device interface <b>120</b>, a processor with text-to-speech converter capability <b>210</b>, a first personal address book (PAB) with audio data <b>212</b>, a network interface <b>214</b>, and a home network interface <b>216</b>. The home network interface <b>216</b> may communicate with a computing device, such as a portable computer <b>220</b> via a home network <b>218</b>. The portable computer <b>220</b> may include a second PAB with audio data <b>222</b>. The home network <b>218</b> may be wired or wireless. The electronic device <b>204</b> may be coupled to a wide area network, such as the public Internet <b>228</b>, via a dial-up connection, a wireless connection, or a broadband connection. The electronic device <b>204</b> may be adapted to communicate with an Internet service provider (ISP) <b>226</b> via the Internet <b>228</b> to access, for example, a third PAB with audio data <b>230</b>.</p>
<p id="p-0022" num="0021">In general, the PSTN <b>206</b> may include a line information database (LIDB) <b>224</b>. In a particular illustrative embodiment, the PSTN <b>206</b> may also include a fourth PAB with audio data <b>232</b>. Additionally, the PSTN <b>206</b> may be coupled to a call control center <b>234</b>, which may include a fifth PAB with audio data <b>236</b>.</p>
<p id="p-0023" num="0022">A PAB with audio data may be stored in one or more different devices and at one or more locations, such as at a server of the PSTN <b>206</b> (e.g., the fourth PAB with audio data <b>232</b>), at a server of the call control center <b>234</b> (e.g., the fifth PAB with audio data <b>236</b>), at an Internet Service Provider <b>226</b> (e.g., the third PAB with audio data <b>230</b>), at a computing device <b>220</b> coupled to the home network <b>218</b> (e.g., the second PAB with audio data <b>222</b>), within the electronic device <b>204</b> (e.g., the first PAB with audio data <b>212</b>), or any combination thereof. A user may configure the electronic device <b>204</b> to access the one or more PABs with audio data <b>212</b>, <b>222</b>, <b>230</b>, <b>232</b>, and <b>236</b> in a particular order via a user interface, such as the particular illustrative non-limiting embodiment of a user interface shown in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0024" num="0023">In general, the PABs with audio data <b>212</b>, <b>222</b>, <b>230</b>, <b>232</b>, and <b>236</b> may each include one or more records, where each record includes a phone number and an associated alias or name. One or more of the records of the PABs with audio data <b>212</b>, <b>222</b>, <b>230</b>, <b>232</b>, and <b>236</b> may include an associated audio alert. For example, a user may configure the PAB with audio data <b>212</b> to associate a fog horn sound with a particular phone number, such that whenever an incoming call is received from the particular phone number, the fog horn sound plays as the audio alert on the multimedia display device. Alternatively, a user may configure the PAB with audio data <b>212</b> to associate a nickname with a particular phone number. The processor with text-to-speech capability <b>210</b> may convert the nickname and the associated phone number to produce the audio alert. In a particular embodiment, the PABs with audio data <b>212</b>, <b>222</b>, <b>230</b>, <b>232</b>, and <b>236</b> may include entries or records having audio alert data and entries or records that do not include audio data.</p>
<p id="p-0025" num="0024">In a particular embodiment, a user may utilize the portable computer <b>220</b> to create a PAB with audio data <b>222</b> and/or to synchronize the PAB with audio data <b>222</b> with the PAB with audio data <b>212</b> of the electronic device <b>204</b>. The processor with text-to-speech capability <b>210</b> may be configured by the user to retrieve data from at least one of the PABs with audio data <b>212</b>, <b>222</b>, <b>230</b>, <b>232</b>, and <b>236</b> in a particular order. In another embodiment, the processor <b>210</b> may be configured to provide a user interface responsive to a remote control device <b>240</b> associated with the electronic device <b>204</b> via an input <b>242</b>, such as an infrared or other remote control interface.</p>
<p id="p-0026" num="0025">In an exemplary embodiment, when a caller, such as the caller <b>108</b> in <figref idref="DRAWINGS">FIG. 1</figref>, dials a phone number associated with a user, the call is received by the PSTN <b>206</b>, which uses the calling number of the caller to search the LIDB <b>224</b> to identify a billing name associated with the calling number. The PSTN <b>206</b> may include logic to provide the calling number or the calling number and a billing name to the electronic device <b>204</b> via the POTS connection <b>208</b>. It should be understood that customers may subscribe to caller ID services from the PSTN <b>102</b> or they may choose not to subscribe. Additionally, there may be tiers within the caller ID services such as calling number only, billing name and calling number, and so on. The caller identification information provided by the PSTN <b>206</b> may be used by the processor with text-to-speech converter capability <b>210</b> to identify or to generate an audio alert associated with the caller identification information and to insert the audio alert into a multimedia data stream.</p>
<p id="p-0027" num="0026">In a particular illustrative embodiment, the electronic device <b>204</b> may receive an incoming telephone call with caller identification information via the POTS connection <b>208</b>. The electronic device <b>204</b> may determine if the PAB <b>212</b> includes a call entry related to the caller identification information. If the PAB <b>212</b> does not have a related entry, the electronic device <b>204</b> may search the PAB <b>222</b> via the home network <b>218</b>. If no related entry is identified, the electronic device <b>204</b> may search one or more of the other PABs <b>230</b>, <b>232</b> and <b>236</b>. The particular search order may be configured by the user via a user interface.</p>
<p id="p-0028" num="0027">In another particular illustrative embodiment, the electronic device <b>204</b> may receive an incoming telephone call with caller identification information via the POTS connection <b>208</b>. The electronic device <b>204</b> may determine if the PAB <b>212</b> includes a call entry related to the caller identification information. If the PAB <b>212</b> does have a related entry, the electronic device <b>204</b> may determine if the related entry includes an audio alert. If no audio alert is found, the electronic device <b>204</b> may utilize the processor with text-to-speech converter function <b>210</b> to convert text from the related entry of the PAB <b>212</b> into speech to produce an audio alert, which may be sent to the display device <b>112</b> along with the text from the related entry to provide a visual pop up caller identification alert together with audible announcement (alert) associated with the incoming call. While this particular example describes conversion from text of the PAB <b>212</b> to produce an audio alert, it should be understood that the processor with text-to-speech converter function <b>210</b> may convert text from any of the PABs <b>212</b>, <b>222</b>, <b>230</b>, <b>232</b>, and <b>236</b> or from the caller identification information received with the incoming call to produce an audio alert.</p>
<p id="p-0029" num="0028">In a particular illustrative embodiment, the processor with text-to-speech converter capability <b>210</b> may be adapted to adjust a volume level of the multimedia data stream, of the audio alert, or both, to create a volume differential between the multimedia data stream and the audio alert. In a particular embodiment, the audio alert may be played at a first volume level that is greater than a second volume level of the multimedia data stream. In another particular embodiment, the second volume level of the multimedia data stream may be reduced to a lower level and the first volume level of the audio alert may be played at a normal volume level.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a third particular embodiment of a system <b>300</b> to provide an audio alert associated with an incoming call. The system <b>300</b> may include an electronic device <b>102</b> that may be coupled to the network <b>104</b> via a network connection <b>106</b>. The electronic device <b>102</b> may be coupled to a multimedia device <b>302</b> via a communication link <b>304</b>. The electronic device <b>102</b> may include a network interface <b>116</b>, a processor <b>118</b>, a text-to-speech converter <b>122</b>, and a memory <b>124</b>, and a multimedia device interface <b>306</b>. The memory <b>124</b> may include a personal address book (PAB) <b>308</b> including a caller entry with audio data <b>310</b>. The electronic device <b>102</b> may also include other interfaces <b>312</b>, such as a Universal Serial Bus (USB) interface, an infrared interface, a wired or wireless network interface, other types of interfaces, or any combination thereof. The other interfaces <b>312</b> may, for example, be utilized to receive user inputs.</p>
<p id="p-0031" num="0030">In a particular embodiment, the electronic device <b>102</b> receives an incoming call including caller identification information from the network <b>104</b> via the communications link <b>106</b>. The network interface <b>116</b> provides the caller identification information to the processor <b>118</b>. The processor <b>118</b> may access the memory <b>124</b> to search the PAB <b>308</b> to identify a caller entry that is related to the caller identification information. If no caller entry is identified, the processor <b>118</b> may utilize the text-to-speech converter <b>122</b> to generate an audio alert based on the caller identification information. The processor <b>118</b> may provide the audio alert and at least a portion of the caller identification information to the multimedia device <b>302</b> via the multimedia device interface <b>306</b> and the communications link <b>304</b>. In a particular embodiment, the processor <b>118</b> may insert the audio alert and the caller information into a multimedia data stream and may provide the multimedia data stream with the inserted audio alert and caller information to the multimedia device <b>302</b> via the communications link <b>304</b> and the multimedia device interface <b>306</b>.</p>
<p id="p-0032" num="0031">For example, the electronic device <b>102</b> may provide the audio alert to the multimedia device <b>302</b> for playback via a speaker associated with the multimedia device <b>302</b>. Additionally, the multimedia device <b>302</b> may display the portion of the caller identification information in a pop up window, such as the pop up display <b>126</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>. The pop up caller identification information may be displayed on top of video data being displayed, and the audible sound may be rendered at a volume level that is greater than the volume of the sound associated with the video data.</p>
<p id="p-0033" num="0032">In a particular embodiment, the multimedia device may be a television, a portable computer (such as the portable computer <b>220</b> shown in <figref idref="DRAWINGS">FIG. 2</figref>), a handheld device (such as a personal digital assistant), or another device adapted to display video data and to reproduce audio data (either via speakers or via headphones).</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of a particular embodiment of a system <b>400</b> to produce an audio alert related to an incoming call to customer premises equipment <b>404</b>. The system <b>400</b> may include the network systems <b>402</b> coupled to the customer premises equipment (CPE) <b>404</b> via a network <b>406</b>, which may be an Internet protocol network, a public switched telephone network, a wireless network, or another type of network. The CPE <b>404</b> may be coupled to a multimedia device <b>408</b> to display caller identification information and to playback an audio alert related to the caller identification information. The multimedia device <b>408</b> may be a computing device, such as a device including a video display and sound outputs (such as speakers or speaker connections), a television, or another device adapted to display video data and to reproduce audio data. The network systems <b>402</b> may include a network interface <b>410</b>, a processor <b>412</b>, a text-to-speech converter <b>414</b>, and a memory <b>416</b>. The memory <b>416</b> may include a personal address book <b>418</b> including a caller entry with audio data <b>420</b>.</p>
<p id="p-0035" num="0034">In a particular embodiment, the CPE <b>404</b> may receive an incoming call notification including caller identification information. The CPE <b>404</b> may transmit the caller identification information to the network systems <b>402</b> to request an audio alert. The network interface <b>410</b> may receive the caller identification information and may provide it to the processor <b>412</b>.</p>
<p id="p-0036" num="0035">In a particular embodiment, the processor <b>412</b> may convert the caller identification information into an audio alert via the text-to-speech converter <b>414</b> and may provide the generated audio alert to the CPE <b>404</b> for playback via the multimedia device <b>408</b>. In another particular embodiment, the processor <b>412</b> may search the personal address book <b>418</b> to identify a particular caller entry that is related to the caller identification information. If no entry is identified, the processor <b>412</b> may convert the caller identification information into an audio alert using the text-to-speech converter <b>414</b>. If an entry is identified but the identified entry does not include associated audio data, the processor <b>412</b> may convert information from the identified caller entry into an audio alert using the text-to-speech converter <b>414</b>. If the identified entry includes associated audio data, the processor <b>412</b> may utilize the audio data as an audio alert. The processor <b>412</b> may then provide the audio alert to the CPE <b>404</b> for playback via a speaker of the multimedia device <b>408</b>. In a particular illustrative embodiment, the processor <b>412</b> may also provide the caller information from the identified entry for display on the multimedia device <b>408</b>.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram of a particular illustrative embodiment of a user interface <b>500</b> to configure an electronic device to provide an audio alert. The user interface <b>500</b> includes a graphical user interface window <b>502</b>, which includes personal address book information <b>504</b>. The personal address book information <b>504</b> includes a list of personal address books <b>506</b> and an associated search order list <b>508</b>. The graphical user interface window <b>502</b> includes selectable indicators, including an add new personal address book (PAB) button <b>512</b>, an edit PAB button <b>514</b>, a delete PAB button <b>516</b>, and an edit search order button <b>518</b>. The local PAB identifier <b>510</b> of the list of PABs <b>506</b> is selected.</p>
<p id="p-0038" num="0037">The graphical user interface window <b>502</b> can also include the caller information <b>520</b> associated with the selected local PAB <b>510</b>. The caller information <b>520</b> includes a list of names <b>522</b>, a list of associated phone numbers <b>524</b> and a list of associated audio alerts <b>526</b>. The caller information <b>520</b> may include an add new entry button <b>528</b>, an edit button <b>530</b>, a delete button <b>532</b>, and an import audio alert button <b>534</b>. The graphical user interface window <b>502</b> may also include a cancel button <b>536</b> and a save button <b>538</b> to cancel or save any changes to a particular entry within a list.</p>
<p id="p-0039" num="0038">In a particular embodiment, a user may add a personal address book to the list of personal address books <b>506</b> by selecting the add new button <b>512</b>. A user may edit or delete a selected PAB, such as the selected PAB <b>510</b> by selecting the edit PAB button <b>514</b> or the delete PAB button <b>516</b>. A user may change an order in which the processor searches one or more of the PABs by selecting the edit search order button <b>518</b>.</p>
<p id="p-0040" num="0039">In a particular embodiment, when the local PAB <b>510</b> is selected, the interface <b>500</b> displays the data contained in the selected PAB <b>510</b> in the caller information <b>520</b>. A user may select an add new entry button <b>528</b> to add another name to the caller information list <b>522</b> and a number to the associated number list <b>524</b>. A user may select an existing name within the list <b>522</b> and select the edit button <b>530</b> or the delete button <b>532</b> to edit or delete the caller entry. Additionally, a user may select the import audio alert button <b>534</b> to import or record an audio alert and to associate the imported or recorded audio alert with the selected caller entry in the list of names <b>522</b>. Finally, a user may save any changes by selecting the save button <b>538</b> or cancel any changes by selecting the cancel button <b>536</b>.</p>
<p id="p-0041" num="0040">It should be understood that the user selectable buttons <b>512</b>, <b>514</b>, <b>516</b>, <b>518</b>, <b>528</b>, <b>530</b>, <b>532</b>, <b>534</b>, <b>536</b>, and <b>538</b> may be presented as links, text items, icons, or another user selectable object. Additionally, the configuration interface may be arranged differently. For example, in a particular illustrative, non-limiting embodiment, the list of PABs <b>506</b> may be presented within a first window, and the list of names <b>522</b> may be presented in a second window when a user selects the edit PAB button <b>514</b>.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 6</figref> is a flow diagram of a particular illustrative embodiment of a method of providing an audio alert related to an incoming call via a multimedia device. An incoming call including caller identification information is received at an input responsive to a network, at <b>600</b>. A text-to-speech converter converts the caller identification information into audio data, at <b>602</b>. An audio alert is generated that is related to the audio data, at <b>604</b>. Display information that is related to the caller identification information is generated, at <b>606</b>. For example, a processor may include a portion of the caller identification information such as the phone number, and may insert, for example, a nickname or other information such as introductory language. In a particular embodiment, the processor may insert the caller identification information into the multimedia data stream, including an additional phrase, such as &#x201c;The incoming call is from . . . &#x201d; The audio alert and the display information associated with the incoming call are inserted into a multimedia data stream for audio playback and display via a multimedia device, at <b>608</b>.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 7</figref> is a flow diagram of a particular illustrative embodiment of a method of determining an audio alert associated with an incoming call. An incoming call including caller identification (CID) information is received at an input responsive to a network, at <b>700</b>. The system determines whether the CID information matches stored caller data, at <b>702</b>. If the CID information does not match, the method advances to <b>704</b>, and the system determines whether the CID information includes an audio alert. If the CID information includes an audio alert, the audio alert and display information associated with the incoming call are inserted into a multimedia data stream for audio playback and display via a multimedia device, at <b>706</b>. If not, the method advances to <b>712</b>, and the CID information is converted into an audio alert. The audio alert and display information associated with the incoming call are inserted into a multimedia data stream for audio playback and display via a multimedia device, at <b>706</b>.</p>
<p id="p-0044" num="0043">Returning to <b>702</b>, if the CID information matches stored caller data, the processor retrieves the stored caller data, at <b>708</b>. The processor determines whether the stored caller data includes an audio alert, at <b>710</b>. If the stored caller data and the CID information do not include an audio alert, the method advances to <b>712</b>, and the CID information or the stored caller is converted into an audio alert. The audio alert and display information associated with the incoming call are inserted into a multimedia data stream for audio playback and display via a multimedia device, at <b>706</b>.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 8</figref> is a flow diagram of a particular illustrative embodiment of a method of generating an audio alert at a network device. Caller identification information associated with a call to a user device is received at an input responsive to a network, at <b>800</b>. An audio alert related to the caller identification information is generated, at <b>802</b>. Display information related to the caller identification information is generated, at <b>804</b>. The audio alert and the display information are transmitted to a user device via the network, at <b>806</b>. In general, the user device may be an electronic device, such as the electronic device <b>102</b> shown in <figref idref="DRAWINGS">FIGS. 1 and 3</figref>, the electronic device <b>204</b> in <figref idref="DRAWINGS">FIG. 2</figref>, or the electronic device <b>404</b> in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0046" num="0045">Referring to <figref idref="DRAWINGS">FIG. 9</figref>, an illustrative embodiment of a general computer system is shown and is designated <b>900</b>. The computer system <b>900</b> can include a set of instructions that can be executed to cause the computer system <b>900</b> to perform any one or more of the methods or computer based functions disclosed herein. The computer system <b>900</b> may operate as a standalone device or may be connected, e.g., using a network, to other computer systems or peripheral devices, such as the multimedia devices, the portable computing devices, the networks, the servers, the network systems, and other devices illustrated in <figref idref="DRAWINGS">FIGS. 1-4</figref>.</p>
<p id="p-0047" num="0046">In a networked deployment, the computer system may operate in the capacity of a server or as a client user computer in a server-client user network environment, or as a peer computer system in a peer-to-peer (or distributed) network environment. The computer system <b>900</b> can also be implemented as or incorporated into various devices, such as a personal computer (PC), a tablet PC, a set-top box (STB), a personal digital assistant (PDA), a mobile device, a palmtop computer, a laptop computer, a desktop computer, a communications device, a wireless telephone, a land-line telephone, a control system, a camera, a scanner, a facsimile machine, a printer, a pager, a personal trusted device, a web appliance, a network router, switch or bridge, or any other machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. In a particular embodiment, the computer system <b>900</b> can be implemented using electronic devices that provide voice, video or data communication. Further, while a single computer system <b>900</b> is illustrated, the term &#x201c;system&#x201d; shall also be taken to include any collection of systems or sub-systems that individually or jointly execute a set, or multiple sets, of instructions to perform one or more computer functions.</p>
<p id="p-0048" num="0047">As illustrated in <figref idref="DRAWINGS">FIG. 9</figref>, the computer system <b>900</b> may include a processor <b>902</b>, e.g., a central processing unit (CPU), a graphics processing unit (GPU), or both. Moreover, the computer system <b>900</b> can include a main memory <b>904</b> and a static memory <b>906</b> that can communicate with each other via a bus <b>908</b>. As shown, the computer system <b>900</b> may further include a video display unit <b>910</b>, such as a liquid crystal display (LCD), an organic light emitting diode (OLED), a flat panel display, a solid state display, or a cathode ray tube (CRT). Additionally, the computer system <b>900</b> may include an input device <b>912</b>, such as a keyboard, and a cursor control device <b>914</b>, such as a mouse. The computer system <b>900</b> can also include a disk drive unit <b>916</b>, a signal generation device <b>918</b>, such as a speaker or remote control, and a network interface device <b>920</b>.</p>
<p id="p-0049" num="0048">In a particular embodiment, as depicted in <figref idref="DRAWINGS">FIG. 9</figref>, the disk drive unit <b>916</b> may include a computer-readable medium <b>922</b> in which one or more sets of instructions <b>924</b>, e.g., software, can be embedded. Further, the instructions <b>924</b> may embody one or more of the methods or logic as described herein. Additionally, the instructions <b>924</b> may embody one or more user interfaces for configuring the methods and logic as described herein. In a particular embodiment, the instructions <b>924</b> may reside completely, or at least partially, within the main memory <b>904</b>, the static memory <b>906</b>, and/or within the processor <b>902</b> during execution by the computer system <b>900</b>. The main memory <b>904</b> and the processor <b>902</b> also may include computer-readable media.</p>
<p id="p-0050" num="0049">In an alternative embodiment, dedicated hardware implementations, such as application specific integrated circuits, programmable logic arrays and other hardware devices, can be constructed to implement one or more of the methods described herein. Applications that may include the apparatus and systems of various embodiments can broadly include a variety of electronic and computer systems. One or more embodiments described herein may implement functions using two or more specific interconnected hardware modules or devices with related control and data signals that can be communicated between and through the modules, or as portions of an application-specific integrated circuit. Accordingly, the present system encompasses software, firmware, and hardware implementations.</p>
<p id="p-0051" num="0050">In accordance with various embodiments of the present disclosure, the methods described herein may be implemented by software programs executable by a computer system. Further, in an exemplary, non-limited embodiment, implementations can include distributed processing, component/object distributed processing, and parallel processing. Alternatively, virtual computer system processing can be constructed to implement one or more of the methods or functionality as described herein.</p>
<p id="p-0052" num="0051">The present disclosure contemplates a computer-readable medium that includes instructions <b>924</b> or receives and executes instructions <b>924</b> responsive to a propagated signal, so that a device connected to a network <b>926</b> can communicate voice, video or data over the network <b>926</b>. Further, the instructions <b>924</b> may be transmitted or received over the network <b>926</b> via the network interface device <b>920</b>.</p>
<p id="p-0053" num="0052">While the computer-readable medium is shown to be a single medium, the term &#x201c;computer-readable medium&#x201d; includes a single medium or multiple media, such as a centralized or distributed database, and/or associated caches and servers that store one or more sets of instructions. The term &#x201c;computer-readable medium&#x201d; shall also include any medium that is capable of storing, encoding or carrying a set of instructions for execution by a processor or that cause a computer system to perform any one or more of the methods or operations disclosed herein.</p>
<p id="p-0054" num="0053">In a particular non-limiting, exemplary embodiment, the computer-readable medium can include a solid-state memory such as a memory card or other package that houses one or more non-volatile read-only memories. Further, the computer-readable medium can be a random access memory or other volatile re-writable memory. Additionally, the computer-readable medium can include a magneto-optical or optical medium, such as a disk or tapes or other storage device to capture carrier wave signals such as a signal communicated over a transmission medium. A digital file attachment to an e-mail or other self-contained information archive or set of archives may be considered a distribution medium that is equivalent to a tangible storage medium. Accordingly, the disclosure is considered to include any one or more of a computer-readable medium or a distribution medium and other equivalents and successor media, in which data or instructions may be stored.</p>
<p id="p-0055" num="0054">Although the present specification describes components and functions that may be implemented in particular embodiments with reference to particular standards and protocols, the disclosure is not limited to such standards and protocols. For example, standards for Internet and other packet switched network transmission (e.g., TCP/IP, UDP/IP, HTML, HTTP) represent examples of the state of the art. Such standards are periodically superseded by faster or more efficient equivalents having essentially the same functions. Accordingly, replacement standards and protocols having the same or similar functions as those disclosed herein are considered equivalents thereof.</p>
<p id="p-0056" num="0055">The illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure, such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Additionally, the illustrations are merely representational and may not be drawn to scale. Certain proportions within the illustrations may be exaggerated, while other proportions may be minimized Accordingly, the disclosure and the figures are to be regarded as illustrative rather than restrictive.</p>
<p id="p-0057" num="0056">One or more embodiments of the disclosure may be referred to herein, individually and/or collectively, by the term &#x201c;invention&#x201d; merely for convenience and without intending to voluntarily limit the scope of this application to any particular invention or inventive concept. Moreover, although specific embodiments have been illustrated and described herein, it should be appreciated that any subsequent arrangement designed to achieve the same or similar purpose may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all subsequent adaptations or variations of various embodiments. Combinations of the above embodiments, and other embodiments not specifically described herein, will be apparent to those of skill in the art upon reviewing the description.</p>
<p id="p-0058" num="0057">The Abstract of the Disclosure is provided to comply with 37 C.F.R. &#xa7;1.72(b) and is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description, various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments. Thus, the following claims are incorporated into the Detailed Description, with each claim standing on its own as defining separately claimed subject matter.</p>
<p id="p-0059" num="0058">The above-disclosed subject matter is to be considered illustrative, and not restrictive, and the appended claims are intended to cover all such modifications, enhancements, and other embodiments, which fall within the true spirit and scope of the present disclosure. Thus, to the maximum extent allowed by law, the scope of the present disclosure is to be determined by the broadest permissible interpretation of the following claims and their equivalents, and shall not be restricted or limited by the foregoing detailed description.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>receiving an incoming call at an electronic device, wherein the incoming call includes caller identification information;</claim-text>
<claim-text>determining whether a first personal address book stored remotely from the electronic device includes an entry associated with the caller identification information; and</claim-text>
<claim-text>inserting a first audio alert associated with the entry into a multimedia data stream in response to a determination that the entry is included in the first personal address book, wherein the first audio alert is determined based at least in part on the entry, and wherein the first audio alert is generated by the electronic device in response to retrieving the entry.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising generating the first audio alert based at least in part on caller information included in the entry.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising accessing the first personal address book stored at a first device.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising inserting display information associated with the entry into the multimedia data stream in response to the determination that the entry is included in the first personal address book.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising generating a second audio alert based on at least a portion of the caller identification information.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the second audio alert is generated in response to a determination that the personal address book does not include the entry associated with the caller identification information.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the second audio alert is generated by the electronic device in response to retrieving the entry.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining whether the first personal address book is accessible in response to the incoming call.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising identifying the first personal address book based on a list of personal address books that defines an order of access of the personal address books.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising accessing a second personal address book based on a determination that the first personal address book does not include the entry associated with the caller identification information, the second personal address book identified based on the list of personal address books and wherein the second personal address book follows the first personal address book in the order of access.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising inserting a second audio alert based on at least a portion of the caller identification information into the multimedia data stream in response to a determination that each address book included in the list of personal address books is inaccessible.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An electronic device comprising:
<claim-text>an input to receive caller identification information associated with a call;</claim-text>
<claim-text>a memory coupled to the input, the memory to store processor executable instructions; and</claim-text>
<claim-text>a processor coupled to the input and to the memory, the processor configured to execute the processor executable instructions to:</claim-text>
<claim-text>determine whether a personal address book stored remotely from the electronic device includes an entry associated with the caller identification information; and</claim-text>
<claim-text>insert an audio alert associated with the entry into a multimedia data stream, wherein the audio alert is determined based on the entry.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The electronic device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising receiving the audio alert at the electronic device via a network.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The electronic device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the network includes a wireless network.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The electronic device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising creating a volume differential between a first sound volume and a second sound volume, wherein the first sound volume is associated with the audio alert and the second sound volume is associated with the multimedia data stream.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The electronic device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the electronic device includes a set-top box.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The electronic device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the electronic device is located at a head end of a multimedia distribution system.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A non-transitory processor-readable medium comprising processor-executable instructions that, when executed by a processor, cause the processor to:
<claim-text>generate a graphical user interface configured to enable a user associated with an electronic device to select a first personal address book stored remotely from the electronic device, wherein a first audio alert associated with an entry of the first personal address book is inserted into a multimedia data stream that is received by the electronic device in response to an incoming call received at the electronic device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The non-transitory processor-readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the graphical user interface is further configured to enable the user to define a list of personal address books and an order of access of the personal address books, wherein the list of personal address books includes the first personal address book.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The non-transitory processor-readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the processor is included in the electronic device. </claim-text>
</claim>
</claims>
</us-patent-grant>
