<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625857-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625857</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13151888</doc-number>
<date>20110602</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2008-311460</doc-number>
<date>20081205</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>146</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382112</main-classification>
<further-classification>358  328</further-classification>
</classification-national>
<invention-title id="d2e71">Image processing method and image processing apparatus</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5684885</doc-number>
<kind>A</kind>
<name>Cass et al.</name>
<date>19971100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5987272</doc-number>
<kind>A</kind>
<name>Maeda et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-national><country>US</country><main-classification>399 58</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2005/0116029</doc-number>
<kind>A1</kind>
<name>Miki et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-national><country>US</country><main-classification>235380</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2005/0134622</doc-number>
<kind>A1</kind>
<name>Yamaguchi et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-national><country>US</country><main-classification>347 15</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2007/0177216</doc-number>
<kind>A1</kind>
<name>Miki et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-national><country>US</country><main-classification>358  326</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0223780</doc-number>
<kind>A1</kind>
<name>Yamaguchi et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-national><country>US</country><main-classification>382100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>11-168616</doc-number>
<kind>A</kind>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-cpc-text>H04N 1/387</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>2001-148755</doc-number>
<kind>A</kind>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-cpc-text>H04N 1/00</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>2002-283598</doc-number>
<kind>A</kind>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-cpc-text>B41J 2/325</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2005-178367</doc-number>
<kind>A</kind>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-cpc-text>B42D 15/10</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>2007-060527</doc-number>
<kind>A</kind>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-cpc-text>H04N 1/387</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2007-203516</doc-number>
<kind>A</kind>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-cpc-text>B41J 2/325</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>WO</country>
<doc-number>WO 2005/094058</doc-number>
<kind>A1</kind>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-cpc-text>H04N 1/387</classification-cpc-text>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>European Search Report dated Jul. 31, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>International Search Report for PCT/JP2008/072722, dated Jan. 27, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>18</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382100</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382112</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  328</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713176</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>19</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>PCT/JP2008/072722</doc-number>
<date>20081208</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13151888</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120027264</doc-number>
<kind>A1</kind>
<date>20120202</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yamaguchi</last-name>
<first-name>Takashi</first-name>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Miki</last-name>
<first-name>Takeo</first-name>
<address>
<city>Machida</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Miyazaki</last-name>
<first-name>Kenji</first-name>
<address>
<city>Komae</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Yamaguchi</last-name>
<first-name>Takashi</first-name>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Miki</last-name>
<first-name>Takeo</first-name>
<address>
<city>Machida</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Miyazaki</last-name>
<first-name>Kenji</first-name>
<address>
<city>Komae</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Pillsbury Winthrop Shaw Pittman, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Kabushiki Kaisha Toshiba</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Johns</last-name>
<first-name>Andrew W</first-name>
<department>2665</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">According to one embodiment, an image processing method for inspecting an image includes creating synthetic image information in which information is synthesized with main image information in a visible state which the human eyes perceive in an invisible state which is hard to perceive with the human eyes, printing the synthetic image information onto a medium, acquiring an image printed on the medium as an inspection image information, extracting information embedded in the main image information from the inspection image acquired, and determining a fault in the image printed on the medium based on an extraction result of information.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="126.49mm" wi="192.36mm" file="US08625857-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="263.99mm" wi="171.96mm" file="US08625857-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="199.31mm" wi="143.00mm" file="US08625857-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.19mm" wi="148.34mm" file="US08625857-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="247.99mm" wi="134.62mm" file="US08625857-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="225.13mm" wi="164.34mm" orientation="landscape" file="US08625857-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="200.83mm" wi="157.48mm" file="US08625857-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="207.69mm" wi="155.19mm" orientation="landscape" file="US08625857-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="218.36mm" wi="162.81mm" file="US08625857-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="225.13mm" wi="163.58mm" file="US08625857-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="234.53mm" wi="175.60mm" file="US08625857-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="260.35mm" wi="173.23mm" file="US08625857-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This is a Continuation Application of PCT Application No. PCT/JP2008/072722, filed Dec. 8, 2008, which was published under PCT Article 21 (2) in English.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0003" num="0002">This application is based upon and claims the benefit of priority from Japanese Patent Application No. 2008-311460, filed Dec. 5, 2008, the entire contents of which are incorporated herein by reference.</p>
<heading id="h-0002" level="1">FIELD</heading>
<p id="p-0004" num="0003">Embodiments described herein relate generally to an image processing method and an image processing apparatus.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0005" num="0004">Conventionally, the thermal transfer recording method using a thermal head is likely to be affected by dust or dirt adhering between an image receiving layer and an ink ribbon or between the thermal head and the ink ribbon. That is, the thermal transfer recording method sometimes may suffer from any image fault such as slip-out of a particular color and inability of securing a particular color due to the dust or the like. Such an image fault is inspected by human naked eyes after transfer/recording to a recording medium is completed. Further, if the fault in an image is remarkable, that recording medium is abandoned as a defective product and then a new recording medium is made again.</p>
<p id="p-0006" num="0005">Further, as a method for forming an image on a personal authentication recording medium such as the ID card, intermediate transfer recording method is available. The intermediate transfer recording method is an image forming method for transferring an image formed on an intermediate transfer body (intermediate recording medium) to a final recording medium such as an IC card. According to the intermediate transfer recording method, for example, a thermal head is heated corresponding to image information so as to record (transfer) ink on an ink ribbon to a transparent intermediate transfer body and an image formed on the intermediate transfer body is transferred to a recording medium such as an ID card. According to the intermediate transfer recording method, an image is formed on the intermediate transfer body having a specialized image receiving layer, different from the method for forming directly on the recording medium. Thus, the intermediate transfer recording method is less affected by the status of a transfer surface on a recording medium so as to form a stable image.</p>
<p id="p-0007" num="0006">On the other hand, to prevent forgery or falsification, often a recording medium such as an IC chip incorporated card (IC card) or brochure (IC brochure) is used as a personal authentication recording medium. The recording medium containing the IC chip is an expensive recording medium. Abandonment of such an expensive recording medium for the reason of the image fault increases an economic loss.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing schematically a configuration example of an image processing apparatus according to a first embodiment.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart for explaining schematically a flow of processing in the image processing apparatus according to the first embodiment.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram showing an example of an ID card as a print object.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. 4A and 4B</figref> are diagrams showing an example of identification information.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart for explaining a flow of processing as synthetic image creation processing.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram for explaining an example of expansion processing of identification image information.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram showing an example of synthetic image information in a real space area.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram showing an example of synthetic image information in the frequency area.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram showing an example of distribution of identification image information.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram showing schematically an example of the configuration of an image processing apparatus according to a second embodiment.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 11</figref> is a flow chart for explaining schematically a flow of processing in the image processing apparatus according to the second embodiment.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 12</figref> is a block diagram showing schematically an example of the configuration of the image processing apparatus according to a third embodiment.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 13</figref> is a flow chart for explaining schematically a flow of processing in the image processing apparatus according to the third embodiment.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. 14A and 14B</figref> are diagrams showing an example of key information.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram showing an example of digital watermark embedding processing using superimposes processing.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 16</figref> is a block diagram showing schematically an example of the configuration of the image processing apparatus according to a fourth embodiment.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 17</figref> is a flow chart for explaining schematically a flow of processing in the image processing apparatus according to the fourth embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0025" num="0024">In general, according to one embodiment, an image processing method for inspecting an image includes creating synthetic image information in which information is synthesized with main image information in a visible state which the human eyes perceive in an invisible state which is hard to perceive with the human eyes, printing the synthetic image information onto a medium, acquiring an image printed on the medium as an inspection image information, extracting information embedded in the main image information from the inspection image acquired, and determining a fault in the image printed on the medium based on an extraction result of information.</p>
<p id="p-0026" num="0025">First, the first embodiment will be described.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing schematically an example of the configuration of the image processing apparatus according to the first embodiment.</p>
<p id="p-0028" num="0027">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, an image processing apparatus <b>100</b> includes a main image acquisition portion <b>101</b>, an identification information acquisition portion <b>102</b>, a synthesizing portion <b>103</b>, a print portion <b>104</b>, an inspection image input portion <b>106</b>, an identification information extracting portion <b>107</b>, a fault determining portion <b>108</b> and a display portion <b>109</b>. Each of these portions is a function which is achieved when a control portion (not shown) executes a control program.</p>
<p id="p-0029" num="0028">The main image acquisition portion <b>101</b> acquires information of a main image (main image) to be recorded in a recording medium. For example, the main image acquisition portion <b>101</b> is achieved when the control portion controls an interface for image input. As the main image information which the main image acquisition portion <b>101</b> intends to acquire, a face image for certification to be printed on the recording medium is expected.</p>
<p id="p-0030" num="0029">The identification information acquisition portion <b>102</b> acquires identification information to be buried into the main image information. For example, the identification information acquisition portion <b>102</b> is achieved when the control portion controls the interface for identification information input. The identification information acquired by the identification information acquisition portion <b>102</b> is information which is used for detecting a fault of print in a processing (fault determining processing) described later.</p>
<p id="p-0031" num="0030">The synthesizing portion <b>103</b> creates synthetic image information by synthesizing the main image information and the identification information. For example, the synthesizing portion <b>103</b> is achieved by control portion's executing a program for image processing (image synthesizing processing) using a memory for memorizing image information. The synthesizing portion <b>103</b> is assumed to create synthetic image information in which identification information acquired by the identification information acquisition portion <b>102</b> is embedded in the main image information acquired by the main image acquisition portion <b>101</b> in a state not easy for human eyes to perceive (in an invisible state). In the meantime, in the first embodiment, a case where the creation method for the synthetic image information acquired by frequency conversion using Fourier transformation is applied to the synthesizing portion <b>103</b> will be described. As the creation method for the synthetic image by the synthesizing portion <b>103</b>, various creation methods are available. For example, a method for creating the synthetic image information by color difference modulation and superimpose processing described in the third embodiment can be applied to the synthesizing portion <b>103</b>.</p>
<p id="p-0032" num="0031">The print portion <b>104</b> records (prints) synthetic image information created by the synthesizing portion <b>103</b> on a recording medium (medium). That is, the print portion <b>104</b> creates a printed material <b>105</b> by recording (printing) the synthetic image information on the recording medium. For example, the print portion <b>104</b> is achieved by control portion's controlling the printer for image formation. As the printer of the print portion <b>104</b>, for example, a thermal transfer type printer is assumed. The printer of the print portion <b>104</b> described in the first embodiment is not restricted to the thermal transfer type but various printing type printers can be applied.</p>
<p id="p-0033" num="0032">The inspection image input portion <b>106</b> inputs image information printed on the printed material <b>105</b>. That is, the inspection image input portion <b>106</b> inputs an image of a face of a recording medium to which the synthetic image information is printed by the print portion <b>104</b> as the inspection image information. For example, the inspection image input portion <b>106</b> is achieved by control portion's controlling a scanner for reading the image information optically. In this case, the inspection image input portion <b>106</b> reads an image recorded on the printed material <b>105</b> optically and transforms the read image information to digital image information (inspection image information). The inspection image input portion <b>106</b> reads an inspection image from the printed material <b>105</b> at a reading resolution about twice or three times the resolution for the main image information. For example, if the resolution of the main image information is 300 dpi, the reading resolution for the inspection image by the inspection image input portion <b>106</b> needs to be 600 to 1200 dpi. In the meantime, the inspection image input portion <b>106</b> may be an interface for acquiring image information of the printed material <b>105</b> read by a scanner as an external device.</p>
<p id="p-0034" num="0033">The identification information extracting portion <b>107</b> extracts identification information from the inspection image information inputted by the inspection image input portion <b>106</b>. For example, the identification information extracting portion <b>107</b> is achieved by control portion's executing a program for identification information extraction using the memory for image storage. The aforementioned inspection image information includes a print result (synthetic image information after print) of synthetic image information in which the identification information is embedded in the main image information in an invisible state. The identification information extracting portion <b>107</b> extracts identification information by extracting a specific frequency component from the inspection image information. In this case, the specific frequency component depends on the identification information. Thus, the identification information which can be extracted as the specific frequency component is used.</p>
<p id="p-0035" num="0034">The fault determining portion <b>108</b> determines any fault of an image. For example, the fault determining portion <b>108</b> is achieved by control portion's executing a program for fault determination. The fault determining portion <b>108</b> determines whether or not any fault exists in the inspection image information, based on the information which the identification information extracting portion <b>107</b> extracts as the identification information from the inspection image information. That is, principally, if the synthetic image information is printed normally on the printed material <b>105</b>, the identification information extracting portion <b>107</b> extracts the identification information accurately from the inspection image information obtained from the printed material <b>105</b>. Contrary to this, unless the synthetic image information is printed normally on the printed material <b>105</b> (that is, any fault exists in print), the identification information extracting portion <b>107</b> cannot extract the identification information accurately from the inspection image information obtained from the printed material <b>105</b>. Therefore, the fault determining portion <b>108</b> determines whether or not any fault exists in the inspection image information by determining whether or not the identification information extracting portion <b>107</b> extracts the identification information normally, taking account of statistical error at each processing.</p>
<p id="p-0036" num="0035">The display portion <b>109</b> displays a result of the processing on a display unit. For example, the display portion <b>109</b> is achieved by control portion's controlling the display unit which displays images. The display portion <b>109</b> displays a result of determination about presence or absence of any fault by the fault determining portion <b>108</b> on the display unit.</p>
<p id="p-0037" num="0036">Next, a flow of processing in the image processing apparatus <b>100</b> having the above-described structure will be described schematically.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart for explaining schematically a flow of the processing in the image processing apparatus <b>100</b> according to the first embodiment.</p>
<p id="p-0039" num="0038">First, the image processing apparatus <b>100</b> acquires the main image information by means of the main image acquisition portion <b>101</b> as main image information input processing (S<b>111</b>). The main image acquisition portion <b>101</b> supplies the acquired main image information to the synthesizing portion <b>103</b>. The image processing apparatus <b>100</b> acquires identification information by means of the identification information acquisition portion <b>102</b> as identification information input processing (S<b>112</b>). The identification information acquisition portion <b>102</b> supplies the acquired identification information to the synthesizing portion <b>103</b>. That is, the main image information and the identification information are inputted to the synthesizing portion <b>103</b>. When the main image information and the identification information are supplied, the synthesizing portion <b>103</b> carries out synthetic image creation processing of generating synthetic image information by embedding the identification information in the main image information in an invisible state (S<b>113</b>). If the synthetic image information is created by the synthesizing portion <b>103</b>, the print portion <b>104</b> carries out print processing of printing created synthetic image information on a recording medium (S<b>114</b>). This print processing is a processing for creating the printed material <b>105</b> based on the synthetic image information.</p>
<p id="p-0040" num="0039">When the print portion <b>104</b> which prints the synthetic image information is created, the image processing apparatus <b>100</b> carries out a processing of inspecting an image printed on the printed material (S<b>115</b> to S<b>118</b>). First, the inspection image input portion <b>106</b> carries out an inspection image input processing of inputting an image printed on the printed material <b>105</b> as an inspection image (S<b>115</b>). If the inspection image is inputted by the inspection image input portion <b>106</b>, the identification information extracting portion <b>107</b> carries out an identification information extracting processing of extracting the identification information from the inputted inspection image (S<b>116</b>). For example, the identification information extracting portion <b>107</b> extracts a frequency component from the inspection image as the identification information. Based on a result of extraction of the identification information by the identification information extracting portion <b>107</b>, the fault determining portion <b>108</b> carries out a fault determining processing of determining any fault in the inspection image (S<b>117</b>). A result of the determination on the fault by the fault determining portion <b>108</b> is reported to the display portion <b>109</b>. Consequently, the display portion <b>109</b> carries out a display processing of displaying information indicating a fault in the inspection image on the display unit (S<b>118</b>).</p>
<p id="p-0041" num="0040">Next, an example of the printed material <b>105</b> will be described.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram showing an example of an ID card <b>131</b> as the printed material <b>105</b>.</p>
<p id="p-0043" num="0042">A personal authentication face image <b>132</b> is printed on the ID card <b>131</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>. The face image <b>132</b> is a color multicolor image. The aforementioned face image <b>132</b> is presented by printing synthetic image information created by the image processing apparatus <b>100</b> onto a recording medium. Thus, the identification information is embedded in the face image <b>132</b> as the synthetic image information to be printed to the ID card <b>131</b>.</p>
<p id="p-0044" num="0043">In other words, the face image <b>132</b> printed on the ID card <b>131</b> is an image which is an inspection object for any fault in the print processing. That is, the inspection image input portion <b>106</b> inputs the inspection image by reading the ID card <b>131</b>. If respective pixels of the face image <b>132</b> as the synthetic image information are printed normally in the print processing to the ID card <b>131</b>, the identification information extracting portion <b>107</b> extracts the identification information normally. Contrary to this, if any fault exists in print of the respective pixels of the face image <b>132</b> as the synthetic image information, the identification information extracting portion <b>107</b> cannot extract identification information in a complete state. Thus, the fault determining portion <b>108</b> determines any fault in the face image <b>132</b> contained in an inspection image obtained from the ID card <b>131</b>, based on a result of the extraction of the identification information by the identification information extracting portion <b>107</b>.</p>
<p id="p-0045" num="0044">If it is determined that a fault exceeding a predetermined standard exists, that ID card <b>131</b> is taken as an object for procedure for reissue. If no fault exists or it is determined that the fault is below the predetermined standard, the ID card <b>131</b> can be used as it is. The standard for determining whether or not the card should be reissued may be set appropriately corresponding to an operating style. For example, as the standard for determining whether or not the ID card should be reissued, it is permissible to make a setting in which a fault in an image on the background of the face image for personal authentication is permitted while a fault in an image in an area other than the background (face portion) should not be permitted.</p>
<p id="p-0046" num="0045">Next, identification information will be described.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. 4A and 4B</figref> are diagrams showing an example of the identification information. <figref idref="DRAWINGS">FIG. 4A</figref> expresses the identification information by binary number of 16 digits. <figref idref="DRAWINGS">FIG. 4B</figref> shows binary image obtained by transforming &#x201c;0&#x201d; of the identification information shown in <figref idref="DRAWINGS">FIG. 4A</figref> to white pixel and transforming &#x201c;1&#x201d; to black pixel. In other words, <figref idref="DRAWINGS">FIG. 4B</figref> shows identification image information obtained by transforming the identification information into binary image. That is, the identification information shown in <figref idref="DRAWINGS">FIG. 4A</figref> and the identification image information shown in <figref idref="DRAWINGS">FIG. 4B</figref> indicate the same information. The example shown in <figref idref="DRAWINGS">FIG. 4B</figref> assumes to create identification image information by transforming the binary number to binary image. The identification image information may be any information as long as it is extracted by the identification information extracting processing. For example, the identification image information may use a geometric pattern image generated directly. Further, as the identification information, a predetermined value may be used or the identification information may be generated from pseudo random number. Further, to obtain the identification information, a specific word (for example, information relating to personal authentication) may be transformed to binary number, for example, by transformation to ASCII code.</p>
<p id="p-0048" num="0047">Next, synthetic image creation processing by the synthesizing portion <b>103</b> will be described.</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart for explaining a flow of a processing as the synthetic image creation processing.</p>
<p id="p-0050" num="0049">First, the synthesizing portion <b>103</b> carries out a frequency analysis processing (main image analysis processing) for the main image information (S<b>121</b>). The synthesizing portion <b>103</b> carries out FFT (discrete Fourier transform) processing on the main image information supplied from the main image acquisition portion <b>101</b> as an main image analysis processing. According to the FFT processing, the main image information is transformed from a real space area to a frequency area. When the main image information is transformed to the frequency area, the synthesizing portion <b>103</b> carries out an extension processing (extension processing of the identification information) on the identification image information supplied from the identification information acquisition portion <b>102</b> (S<b>122</b>). The extension processing is a processing of extending the identification image information corresponding to the image area of the main image information.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram for explaining an example of the extension processing of the identification image information.</p>
<p id="p-0052" num="0051">In the example shown in <figref idref="DRAWINGS">FIG. 6</figref>, a small area <b>162</b> of the identification image information of a smaller size than the size of the main image information <b>161</b> is regarded as individual tile. In this case, the extension processing arranges and places the small areas <b>162</b> of the identification image information regarded as the tile uniformly and cyclically in an area of the same size as the image area of the main image information <b>161</b>. The entire identification image information group arranged in the area of the same size as the main image information <b>161</b> turns to be the extended identification image information <b>163</b>. The extension processing shown in <figref idref="DRAWINGS">FIG. 6</figref> is carried out to match the size of the main image information with the size of the identification image information in a real space. However if the size of the main image information is not matched with the size of the identification image information in the real space, as the extension processing, the frequency side may be changed so that the image sizes in the real space are matched in the frequency area.</p>
<p id="p-0053" num="0052">When the identification information is extended to match with the size of the main image information, the synthesizing portion <b>103</b> carries out a frequency analysis processing (analysis processing of the identification information) on the extended identification image information (extended identification image information) (S<b>123</b>). The synthesizing portion <b>103</b> carries out FFT (discrete Fourier transform) processing on the extended identification image information as an analysis processing of the identification information. By such a FFT processing, the identification image information is transformed from the real space area to the frequency area.</p>
<p id="p-0054" num="0053">When the identification image information is transformed to the frequency area, the synthesizing portion <b>103</b> carries out a processing (synthesizing processing) of synthesizing the main image information with the identification image information (S<b>124</b>). The aforementioned synthesizing processing is a processing of summing up the main image information transformed to the frequency area and the identification image information transformed to the frequency area. Consequently, the synthesizing processing creates synthetic image information of the frequency area.</p>
<p id="p-0055" num="0054">Generally, in the FFT (Fourier transform) processing, linearity is established. For the reason, it comes that two kinds of the functions summed up in the frequency area are summed up in a real space. That is, it means that the main image information and the extended identification image information are summed up (synthesized) in the real space area in the synthetic processing.</p>
<p id="p-0056" num="0055">When the synthetic image information of the frequency area is created by the synthetic processing, the synthesizing portion <b>103</b> carries out a processing (area transformation processing) of transforming the synthetic image information of the frequency area to the synthetic image information of the real space (S<b>125</b>). The area transformation processing is a processing of transforming the frequency area to the real space area. For example, the synthesizing portion <b>103</b> carries out I-FFT processing (inverse discrete Fourier transform processing) on the synthetic image information in the frequency area. I-FFT processing (inverse discrete Fourier transform processing) is a processing of transforming an image in the frequency area to an image in the real space. Thus, the synthesizing portion <b>103</b> transforms the synthetic image information in the frequency area to the synthetic image information in the real space area by the above-described area transformation processing.</p>
<p id="p-0057" num="0056">Here, it is assumed that the main image information is src (x, y), the extended identification image information is id (x, y), the synthetic image information is dst (x, y), the FFT processing result of the main image information is SRC (fx, fy), the FFT processing result of the extended identification image information is ID (fx, fy) and the FFT processing result of the synthetic image information is DST (fx, fy). In this case, it can be considered that each processing shown in <figref idref="DRAWINGS">FIG. 5</figref> corresponds to each arithmetic operation expressed in (A-1) to (A-4) described below.</p>
<p id="p-0058" num="0057">Frequency analysis processing to the main image information of S<b>121</b> (main image analysis processing):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>src</i>(<i>x,y</i>)&#x2192;[FFT processing]&#x2192;<i>SRC</i>(<i>fx,fy</i>)&#x2003;&#x2003;(A-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0059" num="0058">Frequency analysis processing to the identification image information of S<b>123</b> (identification information analysis processing):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>id</i>(<i>x,y</i>)&#x2192;[FFT processing]&#x2192;<i>ID</i>(<i>fx,fy</i>)&#x2003;&#x2003;(A-2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0060" num="0059">Synthetic processing between the main image information and the extended identification image information in the frequency area of S<b>124</b>:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>SRC</i>(<i>fx,fy</i>)+<i>ID</i>(<i>fx,fy</i>)=<i>DST</i>(<i>fx,fy</i>)&#x2003;&#x2003;(A-3)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0061" num="0060">Transformation processing from the frequency area to the real space area of S<b>125</b>:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DST</i>(<i>fx,fy</i>)&#x2192;[<i>I&#x2212;FFT </i>processing(inverse transform)]&#x2192;<i>dst</i>(<i>x,y</i>)&#x2003;&#x2003;(A-4)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0062" num="0061">(x, y) are coordinates of the real space area and (fx, fy) are coordinates of the frequency area.</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram showing an example of the synthetic image information in the real space area. <figref idref="DRAWINGS">FIG. 8</figref> is a diagram showing an example of the synthetic image information in the frequency area. These synthetic image information pieces can be expressed in following equations (B-1) and (B-2) if the above-described equations are used. That is, the synthetic image information in the real space area shown in <figref idref="DRAWINGS">FIG. 7</figref> can be expressed in an equation (B-1) and the synthetic image information in the frequency area shown in <figref idref="DRAWINGS">FIG. 8</figref> can be expressed in an equation (B-2).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>dst</i>(<i>x,y</i>)=<i>src</i>(<i>x,y</i>)+<i>id</i>(<i>x,y</i>)&#x2003;&#x2003;(B-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DST</i>(<i>fx,fy</i>)=<i>SRC</i>(<i>fx,fy</i>)+<i>ID</i>(<i>fx,fy</i>)&#x2003;&#x2003;(B-2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0064" num="0063">Next, the identification information extraction processing will be described in detail.</p>
<p id="p-0065" num="0064">The identification information extracting portion <b>107</b> extracts the identification image information from the inspection image which is an image read from the printed material <b>105</b> as an identification information extraction processing corresponding to the S<b>116</b>. As a method for extracting the identification image information from the inspection image in the identification information extracting portion <b>107</b>, the frequency filter may be used. In this case, the identification information extracting portion <b>107</b> calculates the coefficient of a frequency filter corresponding to the identification image information in following (1) to (4). In the meantime, the calculation of the coefficient may be carried out preliminarily so as to store its result or it may be executed before the extraction processing or each time of the extraction processing.</p>
<p id="h-0006" num="0000">(1) Expanding/contracting the size of the identification image information based on the resolution of the inspection image</p>
<p id="h-0007" num="0000">(2) Distributing in the frequency area by Fourier transform</p>
<p id="h-0008" num="0000">(3) Adjusting the passage area of a filter by referring to distributed values</p>
<p id="h-0009" num="0000">(4) Adopting a value obtained by executing Fourier inverse transform to an adjusted value as the coefficient of the frequency filter</p>
<p id="p-0066" num="0065">The coefficient of the frequency filter is used to extract the frequency component of the identification image information. Here, the identification information extracting portion <b>107</b> executes a convolution integral indicated in an equation (C-1) in order to extract a frequency component Ik (x, y) of the identification image information from the inspection image I (x, y) using a frequency filter coefficient g (u, v). Where u, v are variables for integral.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Ik</i>(<i>x,y</i>)=&#x3a3;&#x3a3;(<i>g</i>(<i>u,v</i>)&#xb7;<i>I</i>(<i>x&#x2212;u,y&#x2212;v</i>))&#x2003;&#x2003;(C-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0067" num="0066">For the identification information extracting portion <b>107</b>, the method for extracting a specific space frequency component which is a frequency component of the identification image information is not limited to the above-mentioned method using the spatial frequency filter. For example, the identification information extracting portion <b>107</b> may use a method of extracting the frequency component of the identification image information by mapping after the mapping is carried out to another space temporarily using the Fourier transform or wavelet transform.</p>
<p id="p-0068" num="0067">The identification image information is reformed from the frequency component of the identification image information extracted by the identification information extracting portion <b>107</b>. That is, in the reformation processing for the identification image information from the extracted frequency component, binarization processing is carried out to an obtained extraction result using a predetermined threshold Th. Consequently, a binary image indicating a distribution of the frequency component of the extracted identification image information can be reformed. That is, if all the frequency components of the identification image information embedded in the synthetic image information is extracted normally, the binary image in which the original identification image information is reformed in a complete condition by the above-described reformation processing can be obtained.</p>
<p id="p-0069" num="0068">Next, the fault determining processing will be described in detail.</p>
<p id="p-0070" num="0069">The fault determining portion <b>108</b> determines a fault in the inspection image as a fault determining processing corresponding to the S<b>117</b>. The identification information extracting portion <b>107</b> obtains the binary image which indicates a distribution of the identification image information in the entire main image area of the inspection image as a result of the identification information extraction processing. In this case, the fault determining portion <b>108</b> is supplied with the binary image which indicates the distribution of the identification image information extracted from the inspection image.</p>
<p id="p-0071" num="0070">The identification image information is distributed uniformly and cyclically in the entire main image (synthetic image) area of the inspection image. Here, it is assumed that the distribution of the identification image information in the main image (synthetic image) area is set preliminarily. The inspection image is an image data obtained by reading, by a scanner, a recording medium on which the synthetic image information having the identification information embedded in the main image information is printed. Therefore, if the print processing is terminated normally, the distribution of the identification image information in the main image (synthetic image) area of the inspection image becomes equal to the distribution of the identification image information in the created synthetic image information (main image information).</p>
<p id="p-0072" num="0071">The fault determining portion <b>108</b> divides the entire main image area of the inspection image to smaller areas and determines whether or not the distribution of the identification image information in the small area is disturbed. For example, the size of the small area is preferred to be the same as the size of the identification image information as shown in <figref idref="DRAWINGS">FIG. 4B</figref> or larger than that. That is, the fault determining portion <b>108</b> determines that a small area in which the disturbance of the distribution of the identification image information is over the predetermined threshold is a region having the image fault. That is, if a disturbance over the predetermined threshold or any fault exists, the fault determining portion <b>108</b> determines that any fault exists in that inspection image. The fault determining portion <b>108</b> determines that a small area in which the disturbance of the distribution of the identification image information is below the predetermined threshold is an area in which the identification image information is embedded normally. That is, if the disturbance of the distribution of the identification information in all the small areas is below the threshold, the fault determining portion <b>108</b> determines that no fault exists in the inspection image.</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram showing an example of the distribution of the identification image information.</p>
<p id="p-0074" num="0073">The entire image area shown in <figref idref="DRAWINGS">FIG. 9</figref> is an extended identification image information area <b>191</b>. Each small area shown in <figref idref="DRAWINGS">FIG. 9</figref> indicates a state in which the identification image information is extracted. A small area <b>192</b> with shaded portion in the distribution example shown in <figref idref="DRAWINGS">FIG. 9</figref> is an area in which the distribution of the identification image information is not disturbed. Small areas <b>193</b><i>a, b </i>having dots in the distribution example shown in <figref idref="DRAWINGS">FIG. 9</figref> are areas in which the distribution of the identification image information is disturbed. In this case, the fault determining portion <b>108</b> determines that the small areas <b>193</b><i>a</i>, <b>193</b><i>b </i>are areas in which the distribution of the identification image information is disturbed, that is, areas having any image fault.</p>
<p id="p-0075" num="0074">As described above, the image processing apparatus <b>100</b> of the first embodiment can detect image faults such as missing of a color or color unevenness accurately based on a result of the extraction of the identification image information in the invisible state embedded in the main image information in a visible state.</p>
<p id="p-0076" num="0075">In the meantime, the first embodiment assumes a method of transforming the main image information and the identification image information to the frequency area as the synthetic image creation processing and then, synthesizing images converted to the frequency area. However, the above-described synthetic image creation processing is not limited to this. For example, as the synthetic image creation processing, a method of overwriting the identification image information with a color which the human being cannot perceives easily, for example, the identification image information onto the main image information directly with a yellow may be adopted. In this case, the identification information extracting portion may carry out a processing of extracting the identification image information written in yellow. With such a processing, it is considered that the same effect as the above-described embodiment can be obtained.</p>
<p id="p-0077" num="0076">Next, the second embodiment will be described.</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram showing schematically an example of the configuration of an image processing apparatus <b>200</b> according to the second embodiment.</p>
<p id="p-0079" num="0078">As shown in <figref idref="DRAWINGS">FIG. 10</figref>, the image processing apparatus <b>200</b> includes a main image acquisition portion <b>201</b>, an identification information acquisition portion <b>202</b>, a synthesizing portion <b>203</b>, a print portion <b>204</b>, an inspection image input portion <b>206</b>, an identification information extracting portion <b>207</b>, and a fault determining portion <b>208</b>. These respective portions are realized by control portion's (not shown) executing a control program. The main image acquisition portion <b>201</b>, the identification information acquisition portion <b>202</b>, the synthesizing portion <b>203</b>, the inspection image input portion <b>206</b>, the identification information extracting portion <b>207</b>, and the fault determining portion <b>208</b> can be realized with those having the same functions as the main image acquisition portion <b>101</b>, the identification information acquisition portion <b>102</b>, the synthesizing portion <b>103</b>, the identification information extracting portion <b>107</b> and the fault determining portion <b>108</b>. For the reason, a detailed description of the main image acquisition portion <b>201</b>, the identification information acquisition portion <b>202</b>, the synthesizing portion <b>203</b>, the inspection image input portion <b>206</b>, the identification information extracting portion <b>207</b> and the fault determining portion <b>208</b> is omitted.</p>
<p id="p-0080" num="0079">The print portion <b>204</b> has a print control portion <b>211</b>, an image forming portion <b>212</b> and a transfer portion <b>213</b>. The print control portion <b>211</b> controls each portion in the print portion <b>204</b>. The print control portion <b>211</b> controls an operation of the image forming portion <b>212</b> or the transfer portion <b>213</b> corresponding to a signal from outside.</p>
<p id="p-0081" num="0080">The image forming portion <b>212</b> forms an image on an intermediate transfer body (medium) <b>215</b>. In the image processing apparatus <b>200</b> of the second embodiment, the image forming portion <b>212</b> forms a synthetic image information created by the synthesizing portion <b>203</b> by synthesizing the main image information with the identification information on the intermediate transfer body <b>215</b>. The intermediate transfer body <b>215</b> has a specialized image receiving layer in which an image is formed by the image forming portion <b>212</b>. The transfer portion <b>213</b> transfers an image formed on the intermediate transfer body <b>215</b> to a recording medium. That is, the intermediate transfer body <b>215</b> is a medium which holds an image to be transferred to a recording medium which is created as the printed material <b>205</b>.</p>
<p id="p-0082" num="0081">The above-described image recording method in the print portion <b>204</b> is generally called intermediate transfer recording method. Generally, the intermediate transfer recording method stabilizes an image to be recorded in the recording medium as compared with a method of forming an image directly on a (final) recording medium. Because the intermediate transfer recording method forms an image on the intermediate transfer medium <b>215</b> having a specialized image receiving layer, the image is stabilized regardless of a transfer surface of the (final) recording medium.</p>
<p id="p-0083" num="0082">In the image processing apparatus <b>200</b>, the inspection image input portion <b>206</b> inputs an image formed on the intermediate transfer body <b>215</b> within the print portion <b>204</b> as an inspection image. The basic structure of the inspection image input portion <b>206</b> is the same as the inspection image input portion <b>106</b>. That is, the inspection image input portion <b>206</b> is realized by control portion's controlling a scanner for reading an image formed on the intermediate transfer body <b>215</b>. Further, the inspection image input portion <b>206</b> reads an inspection image from the intermediate transfer body <b>215</b> at a resolution about twice or three times the resolution for the main image information.</p>
<p id="p-0084" num="0083">The identification information extracting portion <b>207</b> extracts the identification information from the inspection image (image formed on the intermediate transfer body <b>215</b>) inputted by the inspection image input portion <b>206</b>. The fault determining portion <b>208</b> determines whether or not any fault exists in the inspection image (image formed on the intermediate transfer body <b>215</b>) based on a result of the extraction of the identification information by the identification information extracting portion <b>207</b>. The fault determining portion <b>208</b> supplies a result of the fault determination to the print control portion <b>211</b> in the print portion <b>204</b>.</p>
<p id="p-0085" num="0084">Next, a flow of processing in the image processing apparatus <b>200</b> having the above-described structure will be described schematically.</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. 11</figref> is a flow chart for explaining a flow of the processing in the image processing apparatus <b>200</b> according to the second embodiment schematically. The respective processing which the image processing apparatus <b>200</b> executes as shown in <figref idref="DRAWINGS">FIG. 11</figref> includes the same processing which the image processing apparatus <b>100</b> executes. The respective processing of S<b>211</b>-S<b>213</b> and S<b>216</b>-S<b>217</b> shown in <figref idref="DRAWINGS">FIG. 11</figref> are similar processing to S<b>111</b>-S<b>113</b> and S<b>116</b>-S<b>117</b>. Thus, a detailed description of the respective processing of the S<b>211</b>-S<b>213</b> and S<b>216</b>-S<b>217</b> is omitted.</p>
<p id="p-0087" num="0086">The image processing apparatus <b>200</b> acquires the main image information by means of the main image acquisition portion <b>201</b> as main image information input processing (S<b>211</b>). The image processing apparatus <b>200</b> acquires the identification information by means of the identification information acquisition portion <b>102</b> as an identification information input processing (S<b>212</b>). The synthesizing portion <b>203</b> carries out a synthetic image creation processing of generating the synthetic image information by embedding the identification information in an invisible state in the main image information (S<b>213</b>). The synthetic image information created by the synthesizing portion <b>203</b> is supplied to the print portion <b>204</b>. In the print portion <b>204</b>, the print control portion <b>211</b> stores the synthetic image information in a memory (not shown).</p>
<p id="p-0088" num="0087">The print control portion <b>211</b> carries out the image forming processing of forming the synthetic image information on the intermediate transfer body <b>215</b> (S<b>214</b>). When a synthetic image is formed on the intermediate transfer body <b>215</b>, the image processing apparatus <b>200</b> executes a processing of inspecting an image formed on the intermediate transfer body <b>215</b> (S<b>215</b>-S<b>217</b>). First, the inspection image input portion <b>206</b> carries out an inspection image input processing of inputting an image formed on the intermediate transfer body <b>215</b> as an inspection image (S<b>215</b>). When the inspection image is inputted by the inspection image input portion <b>206</b>, the identification information extracting portion <b>207</b> carries out an identification information extraction processing of extracting the identification information from the inputted inspection image (S<b>216</b>). As described in the first embodiment, the identification information extracting portion <b>207</b> extracts a frequency component as the identification information from the inspection image. Based on a result of the extraction of the identification information by the identification information extracting portion <b>207</b>, the fault determining portion <b>208</b> carries out a fault determining processing of determining a fault in the inspection image (S<b>217</b>). A result of the determination for the fault by the fault determining portion <b>208</b> is reported to the print control portion <b>211</b> in the print portion <b>204</b>.</p>
<p id="p-0089" num="0088">When a fault determination result is received from the fault determining portion <b>208</b>, the print control portion <b>211</b> determines whether or not an image formed on the intermediate transfer body <b>215</b> is to be transferred to a recording medium (S<b>218</b>). As for this determination, whether or not an image is transferred to the recording medium is determined depending on whether or not any fault is detected in the image (inspection image) formed on the intermediate transfer body <b>215</b>. Unless any fault is detected from the image formed on the intermediate transfer body <b>215</b>, the print control portion <b>211</b> determines that the image formed on the intermediate transfer body <b>215</b> is transferred to the recording medium (S<b>218</b>, YES).</p>
<p id="p-0090" num="0089">If it is determined that the image formed on the intermediate transfer body <b>215</b> is transferred to the recording medium (S<b>218</b>, YES), the print control portion <b>211</b> transfers an image formed on the intermediate transfer body <b>215</b> by the transfer portion <b>213</b> to the recording medium (S<b>219</b>). Consequently, the print portion <b>204</b> creates the printed material <b>205</b> to which the image formed on the intermediate transfer body <b>215</b> is transferred.</p>
<p id="p-0091" num="0090">If the fault determining portion <b>208</b> detects any fault from the image formed on the intermediate transfer body <b>215</b>, the print control portion <b>211</b> determines that the image formed on the intermediate transfer body <b>215</b> is not transferred to the recording medium (S<b>218</b>, NO). If it is determined that the image formed on the intermediate transfer body <b>215</b> is not transferred to the recording medium (S<b>218</b>, NO), the print control portion <b>211</b> executes the image formation processing of forming the synthetic image information created by the synthesizing portion <b>103</b> on the intermediate transfer body <b>215</b>. In this case, the print control portion <b>211</b> abandons the image formed on the intermediate transfer body <b>215</b> and executes the processing from the S<b>214</b> again.</p>
<p id="p-0092" num="0091">According to the second embodiment, as described above, any image fault such as missing of a color is judged on the image formed on the intermediate transfer body on a stage before the final printing onto the recording medium. If a fault exists on the image formed on the intermediate transfer body as a result of this fault determination, the image formed on the intermediate transfer body is abandoned and the image formation processing is carried out to the intermediate transfer body again. As a result, a fault in the image formed on the intermediate transfer body can be detected accurately. Further, if a fault in the image formed on the intermediate transfer body is detected, the transfer of the image to the final recording medium is blocked. Thus, the transfer of the image having the fault to the final recording medium can be prevented. Consequently, wasteful abandonment of a final recording medium (for example, recording medium incorporating an IC chip) is eliminated, thereby reducing an economic loss.</p>
<p id="p-0093" num="0092">As the image recording method, thermal transfer recording method using a thermal head is available. The thermal transfer recording method is affected easily by dust or dirt adhering between the image receiving layer and an ink ribbon or between the thermal head and the ink ribbon. If the thermal transfer recording method is affected by dust and dirt, a possibility that an image fault such as missing of color, in which a desired color cannot be obtained, is raised. Therefore, the image processing apparatus which adopts the thermal transfer recording method at its print portion can improve the quality and processing efficiency by the above-described image fault inspection.</p>
<p id="p-0094" num="0093">Next, the third embodiment will be described.</p>
<p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. 12</figref> is a block diagram showing schematically an example of the configuration of an image processing apparatus <b>300</b> according to the third embodiment.</p>
<p id="p-0096" num="0095">As shown in <figref idref="DRAWINGS">FIG. 12</figref>, the image processing apparatus <b>300</b> includes a main image acquisition portion <b>301</b>, an auxiliary information acquisition portion <b>302</b>, a key information acquisition portion <b>309</b>, a synthesizing portion <b>303</b>, a print portion <b>304</b>, an inspection image input portion <b>306</b>, a carrier extracting portion <b>307</b> and a fault determining portion <b>308</b>. These respective portions are realized by control portion's (not shown) executing a control program. The main image acquisition portion <b>301</b>, the print portion <b>304</b>, the inspection image input portion <b>306</b>, and the fault determining portion <b>308</b> can be realized with those having the same functions as the main image acquisition portion <b>201</b>, the print portion <b>204</b>, the inspection image input portion <b>206</b> and the fault determining portion <b>208</b>. For the reason, a detailed description of the print portion <b>304</b>, the inspection image input portion <b>306</b> and the fault determining portion <b>308</b> is omitted.</p>
<p id="p-0097" num="0096">The auxiliary information acquisition portion <b>302</b> acquires auxiliary information to be embedded in the main image information. For example, the auxiliary information acquisition portion <b>302</b> is realized by the control portion's controlling an interface for the auxiliary information input. The auxiliary information acquired by the auxiliary information acquisition portion <b>302</b> is information for raising the security performance of the main image information. The auxiliary information is information which is a fundamental for digital watermarking which is to be embedded in the main image information. The auxiliary information may be memorized preliminarily in a memory (not shown) in the image processing apparatus <b>300</b> or may be supplied to the image processing apparatus <b>300</b> from an external unit.</p>
<p id="p-0098" num="0097">The key information acquisition portion <b>309</b> acquires key information for use in embedding the auxiliary information in the main image information. For example, the key information acquisition portion <b>309</b> is realized by the control portion's controlling an interface for key information input. In the meantime, the key information may be memorized preliminarily in a memory (not shown) in the image processing apparatus <b>300</b> or may be supplied to the image processing apparatus <b>300</b> from an external unit. The key information acquired by the key information acquisition portion <b>309</b> is used for embedding the auxiliary information in the main image information and further, for recovering the auxiliary information from the synthetic image information.</p>
<p id="p-0099" num="0098">The synthesizing portion <b>303</b> creates the synthetic image information in which the auxiliary information in an invisible state is embedded in the main image information in the visible state using the key information. That is, in the synthetic image information, only the main image information can be made visible. For example, the synthesizing portion <b>303</b> is realized by the control portion's executing a program for image processing (image synthesizing processing) using a memory for memorizing the image information. The synthesizing portion <b>303</b> creates the synthetic image information according to the digital watermarking method making use of human visual feature to color difference. This digital watermarking method will be described later.</p>
<p id="p-0100" num="0099">The print portion <b>304</b> has the same structure as the print portion <b>204</b>. The print portion <b>304</b> has a print control portion <b>311</b>, an image forming portion <b>312</b>, a transfer portion <b>313</b> and an intermediate transfer body <b>315</b>. The print control portion <b>311</b>, the image forming portion <b>312</b>, the transfer portion <b>313</b> and the intermediate transfer body <b>315</b> have the same functions as the print control portion <b>211</b>, the image forming portion <b>212</b>, the transfer portion <b>213</b> and the intermediate transfer body <b>215</b>. That is, the print control portion <b>311</b> controls the operation of each portion in the print portion <b>304</b>. The image forming portion <b>312</b> forms an image such as synthetic image information on the intermediate transfer body <b>315</b>. The transfer portion <b>313</b> transfers the image formed on the intermediate transfer body <b>315</b> to a recording medium.</p>
<p id="p-0101" num="0100">The inspection image input portion <b>306</b> has the same structure as the inspection image input portion <b>206</b>. That is, the inspection image input portion <b>306</b> inputs an image formed on the intermediate transfer body <b>315</b> in the print portion <b>304</b> as an inspection image.</p>
<p id="p-0102" num="0101">The carrier extracting portion <b>307</b> extracts a digital watermarking carrier signal from the inspection image (image formed on the intermediate transfer body <b>215</b>) inputted by the inspection image input portion <b>306</b>. The carrier extracting portion <b>307</b> extracts a digital watermarking carrier signal from the aforementioned inspection image using the key information used upon creating the synthetic image information.</p>
<p id="p-0103" num="0102">The fault determining portion <b>308</b> determines whether or not any fault exists in the inspection image (image formed on the intermediate transfer body <b>315</b>) based on a result of the extraction of the carrier signal in the carrier extracting portion <b>307</b>. The fault determining portion <b>308</b> supplies a result of the fault determination to the print control portion <b>311</b> in the print portion <b>304</b>.</p>
<p id="p-0104" num="0103">The carrier signal is information which indicates the auxiliary information embedded in the main image information. Thus, if the carrier signal is extracted from the inspection image normally, the auxiliary information embedded in the main image information is restored to a complete condition. In other words, any inspection image by which the auxiliary information cannot be restored to a complete condition can be judged to be in a state having a fault which disables the complete carrier signal from being detected.</p>
<p id="p-0105" num="0104">Next, a flow of the processing in the image processing apparatus <b>300</b> having the above-described structure will be described schematically.</p>
<p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. 13</figref> is a flow chart for explaining a flow of the processing in the image processing apparatus <b>300</b> according to the third embodiment schematically. In the meantime, the respective processing which the image processing apparatus <b>300</b> execute as shown in <figref idref="DRAWINGS">FIG. 13</figref> include the same processing as those that the image processing apparatus <b>100</b> or the image processing apparatus <b>200</b> executes. The respective processing of S<b>310</b>, S<b>314</b>-S<b>315</b> and S<b>318</b>-S<b>319</b> shown in <figref idref="DRAWINGS">FIG. 13</figref> are similar processing to S<b>210</b>, S<b>214</b>-S<b>215</b> and S<b>218</b>-S<b>219</b>. Thus, a detailed description of the respective processing of the S<b>310</b>, S<b>314</b>-S<b>315</b> and S<b>318</b>-S<b>319</b> is omitted.</p>
<p id="p-0107" num="0106">First, the image processing apparatus <b>300</b> acquires the main image information by means of the main image acquisition portion <b>301</b> as a main image information input processing (S<b>310</b>). The image processing apparatus <b>300</b> acquires the auxiliary information by means of the auxiliary information acquisition portion <b>302</b> as an auxiliary information input processing (S<b>311</b>). Further, the image processing apparatus <b>300</b> acquires the key information by means of the key information acquisition portion <b>309</b> as a key information input processing (S<b>312</b>). The auxiliary information and the key information are supplied to the synthesizing portion <b>303</b> together with the main image information.</p>
<p id="p-0108" num="0107">The synthesizing portion <b>303</b> carries out a synthetic image creation processing of creating the synthetic image information by embedding the auxiliary information in the invisible state into the main image information in the visible state using the key information (S<b>313</b>). The synthetic image information created by the synthesizing portion <b>303</b> is supplied to the print portion <b>304</b>. In the print portion <b>304</b>, the print control portion <b>311</b> stores the synthetic image information in a memory (not shown).</p>
<p id="p-0109" num="0108">The print control portion <b>311</b> carries out an image forming processing of forming the synthetic image information on the intermediate transfer body <b>315</b> (S<b>314</b>). If a synthetic image is formed on the intermediate transfer body <b>315</b>, the image processing apparatus <b>300</b> carries out a processing of inspecting an image formed on the intermediate transfer body <b>315</b> (S<b>315</b> to S<b>317</b>). First, the inspection image input portion <b>306</b> carried out an inspection image input processing of inputting an image formed on the intermediate transfer body <b>315</b> as an inspection image (S<b>315</b>). If the inspection image is inputted by the inspection image input portion <b>306</b>, the carrier extracting portion <b>307</b> carries out a carrier extraction processing of extracting a digital watermarking carrier signal from the inspection image using the key information obtained from the key information acquisition portion <b>309</b> (S<b>316</b>). The carrier signal extracted by the carrier extracting portion <b>307</b> is information which indicates the auxiliary information embedded in the main image information. Based on a result of the extraction of the identification information by the carrier extracting portion <b>307</b>, the fault determining portion <b>308</b> carries out a fault determining processing of determining a fault in the inspection image (S<b>317</b>). A result of the determination for the fault by the fault determining portion <b>308</b> is reported to the print control portion <b>311</b> in the print portion <b>304</b>.</p>
<p id="p-0110" num="0109">When the result of the fault determination is received from the fault determining portion <b>308</b>, the print control portion <b>311</b> determines whether or not the image formed on the intermediate transfer body <b>315</b> should be transferred to the recording medium (S<b>318</b>). For example, the print control portion <b>311</b> determines whether or not the image formed on the intermediate transfer body <b>315</b> should be transferred to the recording medium depending on whether or not any fault is detected from the image formed on the intermediate transfer body <b>315</b>.</p>
<p id="p-0111" num="0110">If any fault is detected from the image formed on the intermediate transfer body <b>315</b>, that is, it is determined that the image formed on the intermediate transfer body <b>315</b> should be transferred to the recording medium (S<b>318</b>, YES), the print control portion <b>311</b> transfers the image formed on the intermediate transfer body <b>315</b> to the recording medium by means of the transfer portion <b>313</b> (S<b>319</b>). Consequently, the print portion <b>304</b> creates the printed material <b>305</b> by transferring the synthetic image formed on the intermediate transfer body <b>315</b>.</p>
<p id="p-0112" num="0111">If a fault is detected from an image formed on the intermediate transfer body <b>315</b>, that is, it is determined that the image formed on the intermediate transfer body <b>315</b> is not transferred to the recording medium (S<b>318</b>, NO), the print control portion <b>311</b> executes an image formation processing of forming the synthetic image information created by the synthesizing portion <b>303</b> on the intermediate transfer body <b>315</b>. In this case, the print control portion <b>311</b> abandons the image formed on the intermediate transfer body <b>315</b> and executes the processing from the S<b>314</b> again.</p>
<p id="p-0113" num="0112">The above-mentioned image processing apparatus <b>300</b> creates the printed material <b>305</b> to which the synthetic image information, in which the auxiliary information in the invisible state is embedded in the main image information in the visible state, is printed. That is, when the synthetic image information is printed on the recording medium, the auxiliary information is in the invisible state. Thus, the printed material <b>105</b> created by the image processing apparatus <b>100</b> and the printed material <b>305</b> created by the image processing apparatus <b>300</b> are apparently the same. For example, the image processing apparatus <b>300</b> can create the same one as the printed material <b>131</b> shown in <figref idref="DRAWINGS">FIG. 3</figref> in terms of the apparent structure.</p>
<p id="p-0114" num="0113">The image processing apparatus <b>300</b> of the third embodiment can use personal control information such as ID number, name, birth date, expiration date as the auxiliary information in order to improve the security performance. The printed material <b>305</b> which uses the personal identification information as the auxiliary information relates the auxiliary information which is restored from the synthetic image information such as the face image with the personal control information. Consequently, it is difficult to modify or forge part of the ID certificate, thereby intensifying the security performance.</p>
<p id="p-0115" num="0114">Next, the key information will be described in detail.</p>
<p id="p-0116" num="0115"><figref idref="DRAWINGS">FIGS. 14A and 14B</figref> are diagrams showing an example of the key information.</p>
<p id="p-0117" num="0116"><figref idref="DRAWINGS">FIG. 14A</figref> is a diagram which expresses the key information with binary number of 16 digits. <figref idref="DRAWINGS">FIG. 14B</figref> is a binary image as a result of transforming &#x201c;0&#x201d; of the key information shown in <figref idref="DRAWINGS">FIG. 14A</figref> to white pixels and &#x201c;1&#x201d; to black pixels. In other words, <figref idref="DRAWINGS">FIG. 14B</figref> shows the key image information obtained by transforming the key information to the binary image. Essentially speaking, the key information shown in <figref idref="DRAWINGS">FIG. 14A</figref> and the key image information shown in <figref idref="DRAWINGS">FIG. 14B</figref> indicate the same information. An example shown in <figref idref="DRAWINGS">FIG. 14B</figref> assumes creation of the identification image information by transforming the binary number to the binary image. However, the key image information is not limited to the binary number transformed to the binary image. For example, the key image information can use a geometric pattern image directly generated. As the key information, a predetermined value may be used or it may be generated from a pseudo random number. Further, to obtain the key information, a specific word (for example, information relating to personal authentication) may be transformed to binary number, for example, by transformation to ASCII code.</p>
<p id="p-0118" num="0117">Next, the digital watermark embedding processing of the synthesizing portion <b>303</b> will be described.</p>
<p id="p-0119" num="0118">The digital watermark embedding processing using the color difference and superimpose processing can be applied to the synthesizing portion <b>303</b>. An example of the digital watermark embedding processing using the color difference and superimpose processing has been disclosed in, for example, Jpn. Pat. Appln. KOKAI Publication No. 11-168616.</p>
<p id="p-0120" num="0119">The digital watermark embedding processing using the color difference and superimpose processing uses following characteristics.</p>
<p id="h-0010" num="0000">(1) Using the Human Visual Feature</p>
<p id="p-0121" num="0120">As the image frequency rises, tone identification performance drops.</p>
<p id="p-0122" num="0121">Color difference information is harder to distinguish than brightness information.</p>
<p id="h-0011" num="0000">(2) Using the Relation of Physical Complementary Color</p>
<p id="p-0123" num="0122">For example, in case of additive color mixing, red+cyan look achromatic color (white).</p>
<p id="h-0012" num="0000">(3) Adopting the relation of complementary color and color difference information to high frequency carrier pattern image (color difference modulation processing)</p>
<p id="p-0124" num="0123">That is, red and cyan are in the relationship of complementary colors. For the reason, if red and cyan are adjacent to each other, they are hard to distinguish with the human eyes so that they look achromatic color. If red rich pixels and cyan rich pixels are arranged repeatedly by using the high frequency carrier pattern image, differences of these fine color difference cannot be distinguished with the human eyes. As a result, the amount of color difference is determined to zero as a result of plus-minus with the human visual feature.</p>
<p id="p-0125" num="0124">The digital watermark embedding processing using the color difference and superimpose processing as described above enables the auxiliary information to be embedded in the main image information in the invisible state without inducing deterioration of the quality.</p>
<p id="p-0126" num="0125"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram showing an example of the digital watermark embedding processing using the superimpose processing.</p>
<p id="p-0127" num="0126">Next, the color difference modulation processing in the digital watermark embedding processing will be described.</p>
<p id="p-0128" num="0127">The color difference modulation processing is a processing of creating the embedded information. That is, the embedded information is created by executing color difference modulation processing on the key image information created from the key information.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>KEY(<i>x,y</i>)=in case of white pixel&#x2192;<i>EMD</i>(<i>x,y</i>)&#x2212;<i>R=+&#x394;CD&#x2212;R</i>&#x2003;&#x2003;(D-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>EMD</i>(<i>x,y</i>)&#x2212;<i>G=&#x2212;&#x394;CD&#x2212;G</i>&#x2003;&#x2003;(D-2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>EMD</i>(<i>x,y</i>)&#x2212;<i>B=&#x2212;&#x394;CD&#x2212;B</i>&#x2003;&#x2003;(D-3)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>KEY(<i>x,y</i>)=in case of black pixel&#x2192;<i>EMD</i>(<i>x,y</i>)&#x2212;<i>R=&#x2212;&#x394;CD&#x2212;R</i>&#x2003;&#x2003;(D-4)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>EMD</i>(<i>x,y</i>)&#x2212;<i>G=+&#x394;CD&#x2212;G</i>&#x2003;&#x2003;(D-5)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>EMD</i>(<i>x,y</i>)&#x2212;<i>B=+&#x394;CD&#x2212;B</i>&#x2003;&#x2003;(D-6)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
KEY (x, y): key image information
<br/>
EMD (x, y): embedded information (result of color difference modulation processing)
<br/>
&#x394;CD: amount of color difference
</p>
<p id="p-0129" num="0128">As a result of the above-described color difference modulation processing, a portion corresponding to the white pixel in the key image information turns R-rich (red component rich) and a portion corresponding to the black pixel turns C-rich (cyan component rich). Red and cyan are in the relationship of physical complementary colors. Thus, if both of them are summed up, achromatic color is produced. Thus, by setting the pixel pitch to a high resolution (about 300 dpi or more) exceeding a range which the human eyes can perceive, the embedded information which is a result of the color difference modulation processing disables red and cyan to be distinguished with the naked eyes, so that achromatic color (gray) is produced. In the color difference modulation processing, by using this feature, the key information pattern can be replaced with the achromatic color information apparently. In the meantime, the above-mentioned equation executes such a color difference modulation that the key image information turns to cyan component rich in case of white pixel and red component rich in case of black pixel. However, such a relation is relative. Thus, there is no problem principally even if the cyan component rich and the red component rich are reversed.</p>
<p id="p-0130" num="0129">Next, the superimpose processing in the digital watermark embedding processing will be described.</p>
<p id="p-0131" num="0130">The superimpose processing is a processing of superimposing the embedded information obtained by the color difference modulation processing on the main image information. The main image information, embedded information (for superimpose) and synthetic image information on coordinates (x, y) of an image are defined as follows.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>main image information: <i>SRC&#x2212;C</i>(<i>x,y</i>) . . . corresponds to 351 of FIG. 15&#x2003;&#x2003;(E-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>embedded information(for superimpose):<i>EMD&#x2212;C</i>(<i>x,y</i>) . . . corresponds to 352 of FIG. 15&#x2003;&#x2003;(E-2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>synthetic image information:<i>DES&#x2212;C</i>(<i>x,y</i>) . . . corresponds to 353 of FIG. 15&#x2003;&#x2003;(E-3)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
x, y are coordinate values of an image (the coordinate sizes are assumed to be the same)
<br/>
C={R (red), G (green), B (blue)}, which indicates a plain
<br/>
In case of 24 bit color arithmetic operation, each value is an integer value of 0 to 255.
<br/>
The superimpose processing on the coordinates (x, y) is expressed in following equations (F-1) to (F-3).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DES&#x2212;R</i>(<i>x,y</i>)=<i>SRC&#x2212;R</i>(<i>x,y</i>)+<i>EMD&#x2212;R</i>(<i>x,y</i>)&#x2003;&#x2003;(F-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DES&#x2212;G</i>(<i>x,y</i>)=<i>SRC&#x2212;G</i>(<i>x,y</i>)+<i>EMD&#x2212;G</i>(<i>x,y</i>)&#x2003;&#x2003;(F-2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DES&#x2212;B</i>(<i>x,y</i>)=<i>SRC&#x2212;B</i>(<i>x,y</i>)+<i>EMD&#x2212;B</i>(<i>x,y</i>)&#x2003;&#x2003;(F-3)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0132" num="0131">Next, the carrier extraction processing will be described in detail.</p>
<p id="p-0133" num="0132">The carrier extracting portion <b>307</b> extracts a frequency component (digital watermarking carrier signal) of the key image information indicating the auxiliary information from the inspection image as a carrier extraction processing corresponding to the S<b>316</b>. As a method for extracting the carrier signal from the inspection image in the carrier extracting portion <b>307</b>, the frequency filter may be used. In this case, the carrier extracting portion <b>307</b> calculates the coefficient of the frequency filter corresponding to the digital watermarking carrier signal in (1) to (4). In the meantime, the calculation of the coefficient may be carried out preliminarily to store its result or it may be executed before the extraction processing or it may be carried out each time.</p>
<p id="h-0013" num="0000">(1) Expanding/contracting the size of the key image information based on the resolution of the inspection image</p>
<p id="h-0014" num="0000">(2) Distributing in the frequency area by Fourier transform</p>
<p id="h-0015" num="0000">(3) Adjusting the passage area of a filter by referring to distributed values</p>
<p id="h-0016" num="0000">(4) Adopting a value obtained by executing Fourier inverse transform to an adjusted value as the coefficient of the frequency filter</p>
<p id="p-0134" num="0133">The coefficient of the frequency filter is used to extract the frequency component of the key image information. Here, the carrier extracting portion <b>307</b> executes a convolution integral indicated in an equation (G-1) in order to extract a frequency component Ik (x, y) of the key image information from the inspection image I (x, y) using a frequency filter coefficient g (u, v). Where u, v are variables for integral.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Ik</i>(<i>x,y</i>)=&#x3a3;&#x3a3;(<i>g</i>(<i>u,v</i>)&#xb7;<i>I</i>(<i>x&#x2212;u,y&#x2212;v</i>))&#x2003;&#x2003;(G-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0135" num="0134">For the carrier extracting portion <b>307</b>, the method for extracting a specific space frequency component which is a frequency component of a key image information is not limited to the above-mentioned method using the spatial frequency filter. For example, the carrier extracting portion <b>307</b> may use a method of extracting the frequency component of the key image information by mapping after the mapping is carried out to another space temporarily using the Fourier transform or wavelet transform.</p>
<p id="p-0136" num="0135">Further, the key image information is reformed from the digital watermarking carrier signal extracted by the carrier extracting portion <b>307</b>.</p>
<p id="p-0137" num="0136">That is, the processing of reforming the key image information from the extracted frequency component carries out binarization processing using a predetermined threshold Th to an obtained extraction result. Consequently, a binary image indicating a distribution of the frequency component of the extracted key image information can be reformed. That is, if all the frequency components of the key image information embedded in the synthetic image information are extracted normally, the binary image in which the original key image information is reformed in a complete state is obtained by the above-described reformation processing.</p>
<p id="p-0138" num="0137">The threshold to the digital watermarking carrier signal is affected easily by the value of the main image information if it is a fixed value. Thus, an adaptive type binarization processing of changing the threshold with surrounding values by providing a reference area (for example, 3&#xd7;3 pixels) for an attention pixel is preferred.</p>
<p id="p-0139" num="0138">Next, the fault determining processing will be described in detail.</p>
<p id="p-0140" num="0139">The fault determining portion <b>308</b> determines a fault in the inspection image as a fault determining processing corresponding to the S<b>317</b>. The carrier extracting portion <b>307</b> obtains a binary image indicating a distribution of the digital watermarking carrier signal in the entire main image area of the inspection image as a result of the carrier extraction processing. Here, it is assumed that the digital watermarking carrier signal is substantially the same as the key image information. In this case, the distribution of the digital watermarking carrier signal (key image information) is known preliminarily and the carrier signals are distributed cyclically in the entire main image (synthetic image) area of the inspection image. It is assumed that the distribution of the digital watermarking carrier signal (key image information) is set preliminarily.</p>
<p id="p-0141" num="0140">The inspection image is an image data obtained by reading, by a scanner, a recording medium containing the printed synthetic image information in which the auxiliary information (digital watermarking body) is embedded in the main image information in the invisible state using the key image information (digital watermarking carrier). Thus, if the print processing is carried out normally, the distribution of the digital watermarking carrier signal in the main image (synthetic image) area of the inspection image and the distribution of the digital watermarking carrier signal in the created synthetic image information (main image information) are equal to each other.</p>
<p id="p-0142" num="0141">For example, the fault determining portion <b>308</b> divides the entire main image area of the inspection image to smaller areas and confirms whether or not the distribution of the digital watermarking carrier signal is disturbed in each small area. The size of the small area is preferred to be equal to or larger than the size of the key image information shown in <figref idref="DRAWINGS">FIG. 14B</figref>. The fault determining portion <b>308</b> determines a small area in which the disturbance of the distribution of the digital watermarking carrier signal is over a predetermined threshold to be an area having an image fault. That is, if a disturbance over the predetermined threshold or a missing exits, the fault determining portion <b>308</b> determines that a fault exists in the inspection image. Further, the fault determining portion <b>308</b> determines that the small area in which the disturbance of the distribution of the digital watermarking carrier signal is below the predetermined threshold is an area in which the digital watermarking carrier signal is embedded normally. That is, if the disturbance of the distribution of the digital watermarking carrier signal in all the small areas is below the predetermined threshold, the fault determining portion <b>308</b> determines that no fault exists in the inspection image.</p>
<p id="p-0143" num="0142">Consequently, as regards a result of the print of the synthetic image information in which the auxiliary image information is embedded in the invisible state in the main image information in the visible state using the key image information, the image processing apparatus <b>300</b> of the third embodiment can detect an image fault such as missing of color and color unevenness at a high accuracy. Because the image fault can be detected with respect to the synthetic image information formed on the intermediate transfer body, an image having a fault is prevented from being transferred to the recording medium such as an IC card. Consequently, wasteful abandonment of a recording medium such as an IC card is eliminated, thereby reducing an economic loss.</p>
<p id="p-0144" num="0143">Next, the fourth embodiment of the present invention will be described.</p>
<p id="p-0145" num="0144"><figref idref="DRAWINGS">FIG. 16</figref> is a block diagram showing schematically an example of the configuration of an image processing apparatus <b>400</b> according to a fourth embodiment.</p>
<p id="p-0146" num="0145">As shown in <figref idref="DRAWINGS">FIG. 16</figref>, the image processing apparatus <b>400</b> includes a main image acquisition portion <b>401</b>, an auxiliary information acquisition portion <b>402</b>, a key information acquisition portion <b>409</b>, a synthesizing portion <b>403</b>, a print portion <b>404</b>, an inspection image input portion <b>406</b>, a carrier extracting portion <b>407</b>, a fault candidate extracting portion <b>408</b> and a fault determining portion <b>410</b>. These respective portions are realized by control portion's (not shown) executing a control program. The main image acquisition portion <b>401</b>, the auxiliary information acquisition portion <b>402</b>, the key information acquisition portion <b>409</b>, the synthesizing portion <b>403</b>, the print portion <b>404</b>, the inspection image input portion <b>406</b>, and the carrier extracting portion <b>407</b> are realized by those having the same functions as the main image acquisition portion <b>301</b>, the auxiliary information acquisition portion <b>302</b>, the key information acquisition portion <b>309</b>, the synthesizing portion <b>303</b>, the print portion <b>304</b>, the inspection image input portion <b>306</b> and the carrier extracting portion <b>307</b>. For the reason, a detailed description of the main image acquisition portion <b>401</b>, the auxiliary information acquisition portion <b>402</b>, the key information acquisition portion <b>409</b>, the synthesizing portion <b>403</b>, the print portion <b>404</b>, the inspection image input portion <b>406</b> and the carrier extracting portion <b>407</b> is omitted.</p>
<p id="p-0147" num="0146">The fault candidate extracting portion <b>408</b> extracts a fault candidate in the inspection image inputted by the inspection image input portion <b>406</b> based on a result of the extraction of the digital watermarking carrier signal by the carrier extracting portion <b>407</b>. The fault candidate extracting portion <b>408</b> can be realized by the same processing as the fault determining processing described in the third embodiment. For example, as described in the third embodiment, the carrier extracting portion <b>407</b> divides the entire area of the inspection image to small areas and extracts the digital watermarking carrier signal. In this case, the fault candidate extracting portion <b>408</b> determines, by comparing with a predetermined threshold, whether or not the distribution of the digital watermarking carrier signal in each small area is disturbed. Consequently, the fault candidate extracting portion <b>408</b> extracts a small area in which the disturbance of the distribution of the carrier signal is over the predetermined threshold as a fault candidate having a possibility of the image fault.</p>
<p id="p-0148" num="0147">The fault determining portion <b>410</b> determines whether or not the fault candidate extracted by the fault candidate extracting portion <b>408</b> is an image fault. As shown in <figref idref="DRAWINGS">FIG. 16</figref>, the fault determining portion <b>410</b> includes a comparison image creating portion <b>421</b>, a position information calculating portion <b>422</b>, a reference image creating portion <b>423</b> and a determining portion <b>424</b>.</p>
<p id="p-0149" num="0148">The comparison image creating portion <b>421</b> creates an area of the fault candidate in the inspection image as comparison image information. That is, the comparison image creating portion <b>421</b> cuts out an area of the fault candidate in the inspection image information as the comparison image information based on the position of the fault candidate extracted by the fault candidate extracting portion <b>408</b>.</p>
<p id="p-0150" num="0149">The position information calculating portion <b>422</b> calculates a position information corresponding to the position of a fault candidate in the synthetic image information based on the position of the fault candidate extracted by the fault candidate extracting portion <b>408</b>.</p>
<p id="p-0151" num="0150">The synthetic image information is image information in a state before printed. The inspection image is image information obtained by fetching an image formed physically on the intermediate transfer body <b>415</b> electronically with a scanner. Thus, in actual operations, it is considered that often, the synthetic image information and inspection image are different in terms of the resolution. For example, here it is assumed that the resolution of the synthetic image information is 300 dpi and the resolution of the inspection image is 1200 dpi. If the resolution of the synthetic image information is different from the resolution of the inspection image, the position information calculating portion <b>422</b> executes resolution transformation.</p>
<p id="p-0152" num="0151">The reference image creating portion <b>423</b> creates an area corresponding to the area of a fault candidate in the image information (synthetic image information) in a state before the image is formed on the intermediate transfer body <b>415</b> as the reference image information. Based on the position information of the fault candidate in the main image information calculated by the position information calculating portion <b>422</b>, the area of the fault candidate in the main image information is cut out as the comparison image information.</p>
<p id="p-0153" num="0152">The determining portion <b>424</b> determines whether or not the fault candidate extracted by the fault candidate extracting portion <b>408</b> is a fault. The determining portion <b>424</b> determines whether or not the fault candidate is a fault by comparing a comparison image information created by the comparison image creating portion <b>421</b> with the reference image information created by the reference image creating portion <b>423</b>. Here, as described above, it is assumed that the resolutions of the comparison image information and the reference image information meet each other and the positions of respective pixels also meet.</p>
<p id="p-0154" num="0153">Next, the determining processing for the fault in the determining portion <b>424</b> will be described.</p>
<p id="p-0155" num="0154">The determining portion <b>424</b> determines whether or not the fault candidate is a fault in a following procedure.</p>
<p id="h-0017" num="0000">(1) The determining portion <b>424</b> transforms the RGB values of the pixels which constitute the comparison image information and the pixels which constitute the reference image information to L value, a value and b value.</p>
<p id="p-0156" num="0155">(2) The determining portion <b>424</b> matches the pixels of the comparison image information with the pixels of the reference image information. The determining portion <b>424</b> calculates a color difference &#x2220;Ei (i=1 to n) of a corresponding pixel. The determining portion <b>424</b> regards the L value, a value and b value of a pixel i of the comparison image information as Lci, aci and bci, and the L value, a value and b value of a pixel i of the reference image information as Lbi, abi and bbi. In this case, the determining portion <b>424</b> calculates the &#x2220;Ei according to a following equation (H-1).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x2220;<i>Ei</i>=(&#x2220;<i>Ldi</i>2+&#x2220;<i>adi</i>2+&#x2220;<i>bdi</i>2)(1/2)&#x2003;&#x2003;(H-1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Based on the color differences of the respective pixels, the determining portion <b>424</b> calculates a color difference &#x2220;E between the entire comparison image information and the entire reference image information according to a following equation (H-2).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x2220;<i>E</i>=(1/<i>n</i>)&#x3a3;<i>n</i>&#x2220;(<i>Ei</i>)&#x2003;&#x2003;(H-2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0157" num="0156">where &#x2220;Ldi<b>2</b>, &#x2220;adi<b>2</b>, &#x2220;bdi<b>2</b> are differences on the L, a, b axes between the pixel i of the comparison image information and the pixel i of the reference image information.</p>
<p id="h-0018" num="0000">(3) The determining portion <b>424</b> calculates standard deviations &#x3c3;B, &#x3c3;C of the L value, a value and b value of each pixel of the comparison image information and each pixel of the reference image information.</p>
<p id="h-0019" num="0000">(4) The determining portion <b>424</b> calculates a degree of separation d between the inspection image and synthetic image according to a following equation (H-3).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>d=&#x394;E</i>/(&#x3c3;<i>B+&#x3c3;C</i>)&#x2003;&#x2003;(H-3)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
(5) If the degree of separation is over a predetermined threshold, the determining portion <b>424</b> determines that it is an image fault and if below the threshold, the determining portion <b>424</b> determines that it is not an image fault.
</p>
<p id="p-0158" num="0157">Next, a flow of the processing in the image processing apparatus <b>400</b> having the above described structure will be described schematically.</p>
<p id="p-0159" num="0158"><figref idref="DRAWINGS">FIG. 17</figref> is a flow chart for explaining a flow of the processing in the image processing apparatus <b>400</b> according to a fourth embodiment schematically. In the meantime, the processing which the image processing apparatus <b>400</b> executes as shown in <figref idref="DRAWINGS">FIG. 17</figref> include the same processing as those that the image processing apparatus <b>100</b>, the image processing apparatus <b>200</b> and the image processing apparatus <b>300</b> execute. For example, the processing of S<b>410</b> to S<b>416</b> and S<b>422</b> to S<b>423</b> as shown in <figref idref="DRAWINGS">FIG. 16</figref> are similar processing to those of S<b>310</b> to S<b>316</b> and S<b>318</b> to S<b>319</b> shown in <figref idref="DRAWINGS">FIG. 13</figref>. Thus, a detailed description of the processing of S<b>410</b> to S<b>416</b> and S<b>422</b> to S<b>423</b> is omitted.</p>
<p id="p-0160" num="0159">That is, the image processing apparatus <b>400</b> acquires the main image information by means of the main image acquisition portion <b>401</b> as the main image information input processing (S<b>410</b>). The image processing apparatus <b>400</b> acquires the auxiliary information by means of the auxiliary information acquisition portion <b>402</b> as the auxiliary information input processing (S<b>411</b>). Further, the image processing apparatus <b>400</b> acquires the key information by means of the key information acquisition portion <b>409</b> as the key information input processing (S<b>412</b>). The auxiliary information and the key information are supplied to the synthesizing portion <b>403</b> together with the main image information.</p>
<p id="p-0161" num="0160">The synthesizing portion <b>403</b> carries out a synthetic image creation processing of creating the synthetic image information by embedding the auxiliary information in the invisible state into the main image information in the visible state using the key information (S<b>413</b>). The synthetic image information created by the synthesizing portion <b>403</b> is supplied to the print portion <b>404</b>. In the print portion <b>404</b>, the print control portion <b>411</b> stores the synthetic image information in a memory (not shown).</p>
<p id="p-0162" num="0161">The print control portion <b>411</b> carries out the image formation processing of forming the synthetic image information on the intermediate transfer body <b>415</b> (S<b>414</b>). When the synthetic image is formed on the intermediate transfer body <b>415</b>, the image processing apparatus <b>400</b> carries out a processing of inspecting an image formed on the intermediate transfer body <b>415</b> (S<b>415</b> to S<b>421</b>). First, the inspection image input portion <b>406</b> carries out an inspection image input processing of inputting the image formed on the intermediate transfer body <b>415</b> as the inspection image (S<b>415</b>). When the inspection image is inputted by the inspection image input portion <b>406</b>, the carrier extracting portion <b>407</b> carries out a carrier extraction processing of extracting a digital watermarking carrier signal from the inspection image using the key information obtained from the key information acquisition portion <b>409</b> (S<b>416</b>). For example, as described above, the carrier extracting portion <b>407</b> divides the entire area of the inspection image in smaller areas and extracts the digital watermarking carrier signal.</p>
<p id="p-0163" num="0162">Based on an extraction result of the digital watermarking carrier signal by the carrier extracting portion <b>407</b>, the fault candidate extracting portion <b>408</b> extracts a fault candidate in the inspection image (S<b>417</b>). Here, the fault candidate extracting portion <b>408</b> extracts a small area in which the distribution of the digital watermarking carrier signal in the inspection image is disturbed more than a predetermined threshold, as a fault candidate having a possibility of the image fault. If the fault candidate in the inspection image is extracted, the fault determining portion <b>410</b> determines whether or not the extracted fault candidate is a fault of the image (S<b>418</b> to S<b>421</b>).</p>
<p id="p-0164" num="0163">That is, the comparison image creating portion <b>421</b> cuts out an area of the fault candidate in the inspection image information as the comparison image information based on the position of the fault candidate extracted by the fault candidate extracting portion <b>408</b> (S<b>418</b>). The position information calculating portion <b>422</b> calculates position information corresponding to the position of the fault candidate in the synthetic image information, based on the position of the fault candidate extracted by the fault candidate extracting portion <b>408</b> (S<b>419</b>). In the meantime, the position information calculating portion <b>422</b> carries out resolution transformation for matching the resolution of the inspection image information with that of the synthetic image information. The reference image creating portion <b>423</b> cuts out an area corresponding to the area of the fault candidate in the synthetic image information as the reference image information, based on the position information of the fault candidate in the synthetic image information calculated by the position information calculating portion <b>422</b> (S<b>420</b>).</p>
<p id="p-0165" num="0164">The determining portion <b>424</b> determines whether or not the fault candidate should be adopted as the image fault by comparing the comparison image information created by the comparison image creating portion <b>421</b> with the reference image information created by the reference image creating portion <b>423</b> (S<b>421</b>). For example, the determining portion <b>424</b> determines whether or not the image is a fault according to the above-described fault determining procedure. The determining portion <b>424</b> reports a fault determination result to the print control portion <b>411</b>.</p>
<p id="p-0166" num="0165">If it is determined that no fault exists in the image formed on the intermediate transfer body <b>415</b>, the print control portion <b>411</b> determines that the image formed on the intermediate transfer body <b>415</b> should be transferred to a recording medium (S<b>422</b>, YES). In this case, the print control portion <b>411</b> transfers the image formed on the intermediate transfer body <b>315</b> to the recording medium by means of the transfer portion <b>413</b> (S<b>423</b>). Consequently, the print portion <b>404</b> creates the printed material <b>405</b> to which the synthetic image formed on the intermediate transfer body <b>415</b> is transferred.</p>
<p id="p-0167" num="0166">If it is determined that a fault exists in the image formed on the intermediate transfer body <b>415</b>, it is determined that the image formed on the intermediate transfer body <b>415</b> is not to be transferred to the recording medium (S<b>422</b>, NO). In this case, the print control portion <b>411</b> carries out an image formation processing of forming the synthetic image information created by the synthesizing portion <b>403</b> on the intermediate transfer body <b>415</b>. In this case, the print control portion <b>411</b> abandons the image formed on the intermediate transfer body <b>415</b> and executes the processing from the S<b>414</b> again.</p>
<p id="p-0168" num="0167">The image processing apparatus <b>400</b> of the fourth embodiment extracts an area of the fault candidate in the inspection image obtained by reading the intermediate transfer body in which the synthetic image information is formed, and compares the comparison image information which is an area of the fault candidate in the inspection image with the reference image information which is an area corresponding to the area of the fault candidate in the synthetic image information, so as to judge a fault in the inspection image. Consequently, whether or not the area extracted as a fault from the inspection image is an image having a fault such as missing of color or color unevenness can be determined at a high accuracy. Because the fault of the image formed on the intermediate transfer body can be judged, the fault image is prevented from being transferred to a recording medium such as an IC card. As a result, wasteful abandonment of a recording medium such as an IC card is eliminated, thereby reducing an economic loss.</p>
<p id="p-0169" num="0168">While certain embodiments have been described, these embodiments have been presented by way of example only, and are not intended to limit the scope of the inventions. Indeed, the novel embodiments described herein may be embodied in a variety of other forms; furthermore, various omissions, substitutions and changes in the form of the embodiments described herein may be made without departing from the spirit of the inventions. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of the inventions.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing method for inspecting an image, comprising:
<claim-text>creating synthetic image information having a specific frequency in which information is synthesized with main image information;</claim-text>
<claim-text>printing the synthetic image information onto a medium;</claim-text>
<claim-text>acquiring an image printed on the medium as inspection image information;</claim-text>
<claim-text>extracting a distribution of the specific frequency component from the inspection image acquired; and</claim-text>
<claim-text>determining a fault in the image printed on the medium based on the distribution of the specific frequency component extracted from the inspection image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the distribution of the specific frequency component is extracted for each small area having a size larger than the cycle of the frequency in the inspection image, and
<claim-text>the fault in the image printed on the medium is determined in the unit of the small area in the inspection image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the synthetic image information is created by embedding auxiliary information into the main image information in an invisible state using key information,
<claim-text>the information that is extracted from the inspection image is the specific frequency component of the key information from the inspection image, and</claim-text>
<claim-text>the fault in the image printed on the medium is determined based on the distribution of the specific frequency component of the key information extracted from the inspection image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The image processing method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the synthetic image information is embedded in the information as an achromatic color in the main image information by performing color difference modulation on the key image information created using a group of two complementary colors on the key information.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image processing method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the synthetic image information is created by embedding auxiliary information in the invisible state into the main image information by using a digital watermarking carrier signal based on the key information,
<claim-text>the information that is extracted from the inspection image is based on the digital watermarking carrier signal, and</claim-text>
<claim-text>the fault in the image printed on the medium is determined based on the distribution of the digital watermarking carrier signal extracted from the inspection image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The image processing method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the information that is extracted from the inspection image is the digital watermarking carrier signal for each small area having a size larger than the cycle of the digital watermarking carrier signal in the inspection image, and
<claim-text>the fault in the image printed on the medium is determined in the unit of the small area in the inspection image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The image processing method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the determining comprises extracting an area of a fault candidate from each small area in the inspection image; and
<claim-text>determining whether or not the extracted area of the fault candidate is an image fault based on a predetermined condition.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The image processing method according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the determining includes comparing image information in the inspection image corresponding to the extracted area of the fault candidate with image information in the synthetic image information corresponding to the extracted area of the fault candidate to determine whether or not any image fault exists.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The image processing method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the synthetic image information is printed on an intermediate transfer body as the medium, and the inspection image information is acquired from the intermediate transfer body, the image processing method further comprising:
<claim-text>transferring the image printed on the intermediate transfer body to a recording medium, if it is determined that no fault exists in the image printed on the intermediate transfer body, and</claim-text>
<claim-text>abandoning the image printed on the intermediate transfer body and printing the synthetic image information on the intermediate transfer body again, if it is determined that a fault exists in the image printed on the intermediate transfer body.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An image processing apparatus, comprising:
<claim-text>a synthesizing unit configured to create synthetic image information having a specific frequency in which information is synthesized with main image information;</claim-text>
<claim-text>a printing device configured to print the synthetic image information created by the synthesizing unit onto a medium;</claim-text>
<claim-text>an inspection image input unit configured to acquire an image printed on the medium by the printer as an inspection image information;</claim-text>
<claim-text>an information extracting unit configured to extract a distribution of the specific frequency component from the inspection image acquired by the inspection image input unit; and</claim-text>
<claim-text>a fault determining unit configured to determine a fault in the image printed on the medium based on the distribution of the specific frequency component extracted from the inspection image by the information extracting unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The image processing apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the information extracting unit extracts the distribution of the specific frequency for each small area having a size larger than the cycle of the frequency in the inspection image, and
<claim-text>the fault determining unit determines a fault in the unit of a small area in the inspection image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The image processing apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the synthesizing unit creates the synthetic image information by embedding auxiliary information into the main image information in an invisible state using key information,
<claim-text>the information extracting unit extracts the specific frequency component of the key information from the inspection image, and</claim-text>
<claim-text>the fault determining unit determines the fault in the image printed on the medium based on the distribution of the specific frequency component of the key information extracted from the inspection image by the information extracting unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The image processing apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the synthesizing unit embeds the information as an achromatic color in the main image information by performing color difference modulation on the key image information created by using a group of two complementary colors on the key image information.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The image processing apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the synthesizing unit creates synthetic image information by embedding auxiliary information in the invisible state into the main image information by using a digital watermarking carrier signal based on the key information;
<claim-text>the information extracting unit extracts the digital watermarking carrier signal from the inspection image; and</claim-text>
<claim-text>the fault determining unit determines a fault in the image printed on the medium based on the distribution of the digital watermarking carrier signal extracted from the inspection image by the information extracting unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The image processing apparatus according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the information extracting unit extracts the digital watermarking carrier signal for each small area having a size larger than the cycle of the digital watermarking carrier signal in the inspection image; and
<claim-text>the fault determining unit determines a fault in the unit of the small area in the inspection image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The image processing apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the fault determining unit comprises a candidate extracting unit to extract an area of a fault candidate from each small area in the inspection image; and
<claim-text>a determining unit to determine whether or not the extracted area of the fault candidate is an image fault, based on a predetermined condition.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The image processing apparatus according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the determining unit compares image information in the inspection image corresponding to the extracted area of the fault candidate with image information in the synthetic image information corresponding to the extracted area of the fault candidate to determine whether or not any image fault exists.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The image processing apparatus according to any one of <claim-ref idref="CLM-00010">claims 10</claim-ref>, or <claim-ref idref="CLM-00011">11</claim-ref> to <b>17</b>, wherein the printer prints the synthetic image information created by the synthesizing unit on an intermediate transfer body as the medium, and the inspection image input unit acquires an image formed on the intermediate transfer body by the printer as inspection image information, the image processing apparatus further comprising:
<claim-text>a transfer unit configured to transfer the image printed on the intermediate transfer body to a recording medium, if it is determined that no fault exists in the image printed on the intermediate transfer body by the fault determining unit; and</claim-text>
<claim-text>a print control unit configured to abandon the image printed on the intermediate transfer body and print the synthetic image information on the intermediate transfer body again, if it is determined that a fault exists in the image printed on the intermediate transfer body by the fault determining unit. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
