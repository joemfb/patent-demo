<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626939-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626939</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11400952</doc-number>
<date>20060410</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>GB</country>
<doc-number>0508946.1</doc-number>
<date>20050430</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1704</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709231</main-classification>
<further-classification>379 8814</further-classification>
<further-classification>704270</further-classification>
</classification-national>
<invention-title id="d2e71">Method and apparatus for streaming data</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5016226</doc-number>
<kind>A</kind>
<name>Hiwada et al.</name>
<date>19910500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>36523317</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5583652</doc-number>
<kind>A</kind>
<name>Ware</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386 75</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5864678</doc-number>
<kind>A</kind>
<name>Riddle</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709235</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5890203</doc-number>
<kind>A</kind>
<name>Aoki</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711111</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5928330</doc-number>
<kind>A</kind>
<name>Goetz et al.</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6112239</doc-number>
<kind>A</kind>
<name>Kenner et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6138164</doc-number>
<kind>A</kind>
<name>Kobata et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6466909</doc-number>
<kind>B1</kind>
<name>Didcock</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704260</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6502139</doc-number>
<kind>B1</kind>
<name>Birk et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709233</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6557026</doc-number>
<kind>B1</kind>
<name>Stephens, Jr.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709203</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6618820</doc-number>
<kind>B1</kind>
<name>Krum</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 13</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6766407</doc-number>
<kind>B1</kind>
<name>Lisitsa et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
<classification-national><country>US</country><main-classification>710316</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6839768</doc-number>
<kind>B2</kind>
<name>Ma et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709235</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>7197557</doc-number>
<kind>B1</kind>
<name>Asar et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>7337231</doc-number>
<kind>B1</kind>
<name>Li</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>7430609</doc-number>
<kind>B2</kind>
<name>Brown et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2002/0083173</doc-number>
<kind>A1</kind>
<name>Musoll et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2002/0095683</doc-number>
<kind>A1</kind>
<name>Watanabe</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 90</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2003/0055910</doc-number>
<kind>A1</kind>
<name>Amini et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709214</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2003/0093543</doc-number>
<kind>A1</kind>
<name>Cheung et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2003/0163478</doc-number>
<kind>A1</kind>
<name>Kirkland</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707102</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2004/0039834</doc-number>
<kind>A1</kind>
<name>Saunders et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2004/0044783</doc-number>
<kind>A1</kind>
<name>Nordberg</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2004/0250273</doc-number>
<kind>A1</kind>
<name>Swix et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 25</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2006/0092938</doc-number>
<kind>A1</kind>
<name>Gentrix</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370390</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2006/0146185</doc-number>
<kind>A1</kind>
<name>Chen</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3484101</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>EP</country>
<doc-number>1182875</doc-number>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Taal et al, &#x201c;Adaptive End-to-End Optimization of Mobile Video Streaming Using QoS Negotiation&#x201d;, May 31, 2002.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>Beggs et al, &#x201c;Designing Web Audio&#x201d;, Jan. 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>Kim et al, &#x201c;TCP-friendly Internet Video Streaming employing Variable Frame-rate Encoding and Interpolation&#x201d;, Mar. 20, 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>18</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709231-235</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709201-202</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709204</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709217</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709219</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709226</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709229</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379 8813- 8814</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379 8315</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379 8324</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37910013</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379908</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704  1</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704258</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704262</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704270-278</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060248214</doc-number>
<kind>A1</kind>
<date>20061102</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Jackson</last-name>
<first-name>Callum Peter</first-name>
<address>
<city>Fareham</city>
<country>GB</country>
</address>
</addressbook>
<residence>
<country>GB</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Smith</last-name>
<first-name>Nanami</first-name>
<address>
<city>Southhampton</city>
<country>GB</country>
</address>
</addressbook>
<residence>
<country>GB</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Jackson</last-name>
<first-name>Callum Peter</first-name>
<address>
<city>Fareham</city>
<country>GB</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Smith</last-name>
<first-name>Nanami</first-name>
<address>
<city>Southhampton</city>
<country>GB</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>GRASSO PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Grasso</last-name>
<first-name>Fred</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Najjar</last-name>
<first-name>Saleh</first-name>
<department>2492</department>
</primary-examiner>
<assistant-examiner>
<last-name>Shepperd</last-name>
<first-name>Eric W</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Method and apparatus for negotiation of streaming data, suitable for application in an environment wherein a server generates and serves large, continuous amounts of speech data to a client in real time. A method of controlling the play out of a generated data stream from a data stream player includes estimating a time for generating the data stream; estimating a time for playing the data stream; generating a data stream using a data stream generation resource, for output by the data stream player; and alerting the stream player if the remaining generation time is less than the play time. The server may calculate what it can do, given knowledge of the network, and send a message to guarantee a level of service. A &#x201c;can start play&#x201d; message may be sent to client when the client can reliably start playing the signal.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="214.55mm" wi="106.17mm" file="US08626939-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="177.29mm" wi="116.42mm" file="US08626939-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="225.81mm" wi="111.25mm" file="US08626939-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="195.66mm" wi="103.63mm" file="US08626939-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="181.44mm" wi="165.61mm" file="US08626939-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The invention relates to a method and apparatus for streaming data, and in particular the invention relates to a method and apparatus in a server that generates and serves large, continuous amounts of speech data to a client in real time.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">A server receives a request for real time processing from a client. This request requires the server to carry out continuous processing while providing blocks of processed data to the client. Data blocks are streamed from the server to the client, which plays these data blocks continuously.</p>
<p id="p-0004" num="0003">In a problem-free scenario, server-side processing is capable of providing blocks continuously to the client. Depending on the data that is being streamed, a client might be set up to buffer none, all, or a specified number of data blocks before allowing play to take place.</p>
<p id="p-0005" num="0004">A server is expected to experience times under stress; for example, when bandwidth is low or CPU usage is high. This is likely to impact the server's ability to process and stream data continuously. To some extent buffering provides a solution to this problem. However, a static client side buffer does not take the server's current workload or network bandwidth into consideration.</p>
<p id="p-0006" num="0005">The outcome, with regard to the client-side, can be variable. Two likely scenarios follow. In the first, the client stores additional data, effectively waiting for all requested data to arrive before commencing play. The implication for the client end user is that they must wait an undesirable length of time between requesting and receiving play of data. In the second scenario, inadequate data is stored by the client, and buffer under-run occurs. Consequently, the end user experiences interruptions in play.</p>
<p id="p-0007" num="0006">Sizing a text-to-speech (TTS) system is not trivial. If the size of the TTS data transmission is calculated incorrectly, several problems can occur. With the client system under stress, the quality of the TTS is greatly reduced. If the TTS server is under stress, then the TTS can be played to the caller in bits, which would seem unnatural. If the client system (typically an interactive voice response system) detects under-run, then the whole prompt could be replayed. In all cases the caller suffers a negative experience of the system and is less likely to use the system in the future.</p>
<p id="p-0008" num="0007">U.S. Pat. No. 6,766,407, &#x201c;Intelligent streaming framework,&#x201d; describes a streaming framework manager that coordinates elements of a streaming solution based on the analysis of the properties of a particular connection. The patent does not consider the streaming generator workload.</p>
<p id="p-0009" num="0008">U.S. Pat. No. 6,112,239, &#x201c;System and method for server-side optimization of data delivery on a distributed computer network,&#x201d; involves server-side optimization and network performance information. This patent is concerned with redirecting data to various delivery sites and servers, in accordance with network information.</p>
<p id="p-0010" num="0009">EP patent publication 1182875, &#x201c;Streaming method and corresponding system,&#x201d; is described in terms of negotiation driven by the client capacities rather than from the server, but involves optimization to avoid buffer underflow and overflow. Changes in transmission capacity are detected and reacted to. The client terminal is responsible for using transmission capacity to calculate an appropriate buffer level and delay, and consequently instructing the server to transmit at a particular rate. However, the server performance is not considered.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0011" num="0010">According to a first aspect of the present invention, there is provided a method of controlling the play out of a generated media data stream from a data stream player, comprising: estimating a generation time for generating the data stream; estimating a play time for the data stream; generating a data stream using a data stream generation resource, for output by the data stream player; and alerting the data stream player if the remaining generation time is not more than the play time (that is, the remaining generation time is equal to or less than the play time).</p>
<p id="p-0012" num="0011">In a preferred embodiment of the invention, the server calculates what it can do, given knowledge of the network, and sends a message to guarantee a level of service from a point in time onwards. A &#x201c;can start play&#x201d; message is sent to client at a point when the client can reliably start playing the signal. This embodiment of the invention takes into account the server's processing capabilities and takes responsibility for prioritizing processes to guarantee a level of service to the client.</p>
<p id="p-0013" num="0012">A preferred embodiment of the invention determines when sufficient audio has been sent and when the client should start playing. The controlling server-client communication is implemented within the protocol used to send the data, and this information should be available for use by client-side applications.</p>
<p id="p-0014" num="0013">In the specification, the difference between the play time of a data stream and the remaining generation time of the data stream is called the critical buffer point. The stream player is alerted when the critical buffer point is reached, that is when the critical buffer becomes zero.</p>
<p id="p-0015" num="0014">Advantageously, the rate of generation of the data stream is forced to be at the same rate or faster after the alert has been sent. It is more advantageous where each data stream has a priority and the priority is raised within the generation resource to maintain the rate after the alert has been sent.</p>
<p id="p-0016" num="0015">Preferably, the remaining generation time is obtained from the data stream generation resource each time it is compared to the play time. The remaining generation time can be estimated from the elapsed time from the original estimate of the generation time or more advantageously a new estimate of the generation time can be made after the original estimate. A new estimate of the generation time allows the changing work load of the generation resource to be taken into account.</p>
<p id="p-0017" num="0016">More preferably, the alert is sent from the server to the client. In a preferred embodiment, it is the server that calculates the difference between the generation and the play times since the generation time changes at the server and generation time updates are more easily obtained at the server. However, if the generation time was sent to the client, then the client could calculate the best time to start the play out of the data.</p>
<p id="p-0018" num="0017">The invention may be suitably applied when, for example, the media data stream is speech data and the generation resource is a text-to-speech engine. Although TTS is particularly susceptible to interruption since it must be played out at a constant rate, other types of generation engines could use this technique to reduce interruptions of the media stream, for example, video graphics requiring a constant rate output. The TTS engine keeps the TTS controller updated with the TTS generation time throughout the transmission of the TTS data stream.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0018">Embodiments of the invention will now be described, by means of example only, with reference to the accompanying drawings, in which:</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic client and server arrangement;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 2</figref> is a flow diagram of the server controller method;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 3</figref> is a flow diagram of a client controller method;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 4A</figref> is a graph of an example TTS server workload with respect to time; and</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 4B</figref> is a graph of the corresponding TTS generation and critical buffer points.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0025" num="0024">In <figref idref="DRAWINGS">FIG. 1</figref> there is shown a client <b>10</b> and server <b>12</b> arrangement according to a preferred embodiment. The server <b>12</b> comprises: a TTS controller <b>14</b>; a text-to-speech (TTS) engine <b>16</b>; and a priority engine <b>18</b>. The client <b>10</b> comprises: an audio player <b>20</b>; buffer controller <b>22</b>; and a buffer <b>24</b>.</p>
<p id="p-0026" num="0025">The TTS controller <b>14</b> processes TTS requests from one or more clients <b>10</b> and directs TTS transmissions from the TTS engine <b>16</b> using TTS controller method <b>200</b>.</p>
<p id="p-0027" num="0026">The TTS engine <b>16</b> generates a TTS data stream on request from a client <b>10</b>. As part of the initiation of the sending, the TTS engine <b>16</b> calculates the time taken to generate the TTS data stream (generation time) and the time taken to play the TTS data stream (play time).</p>
<p id="p-0028" num="0027">The priority engine <b>18</b> performs load balancing on the TTS engine <b>16</b> by controlling the assignment of TTS engine resource according to a priority of the data stream. Initially each data stream is assigned an average priority but this priority can be changed during the processing. If one data stream has a higher priority than other data streams then this one data stream will be processed faster than the other data streams. The priority engine <b>18</b> responds to the TTS controller <b>14</b> and adapts the assignment of TTS engine resource accordingly.</p>
<p id="p-0029" num="0028">The client buffer <b>24</b> receives a data stream from the server <b>12</b>, and stores it until the client audio player <b>20</b> requests the data for play out.</p>
<p id="p-0030" num="0029">The buffer controller <b>22</b> initiates the request for the data stream, in a simple case, after prompting by the user through an interface of the client audio player <b>20</b>. In a more complex case, a user interaction is controlled by an interactive voice response application and the application makes requests for the audio stream after certain user interactions.</p>
<p id="p-0031" num="0030">The client audio player <b>20</b> comprises an interface with an input and an output. The input takes user commands for selecting data streams or for engaging with an interactive voice application.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 2</figref> describes the TTS controller method <b>200</b> performed by the TTS controller <b>14</b>.</p>
<p id="p-0033" num="0032">Step <b>202</b> starts after the TTS request is received from the client. In step <b>202</b> the TTS controller <b>14</b> calculates the critical buffer point (CBP) by subtracting the play time of the TTS data stream from the TTS generation time. In a preferred embodiment, the TTS generation time is calculated taking account of the size of the text for conversion and the workload of the TTS engine. A further embodiment may also use the network workload in the calculation. Alternatively, the size of the text alone is a simple factor which gives a useful TTS generation time.</p>
<p id="p-0034" num="0033">Step <b>204</b> is the initiation of the sending of the TTS data stream from the TTS engine <b>16</b> to the client <b>10</b>. As the TTS data stream is generated and sent, the time taken to generate the TTS data stream changes as the loading of the TTS engine changes.</p>
<p id="p-0035" num="0034">In step <b>206</b>, a continuous loop is started, and a new CBP is recalculated based on the new TTS generation time. The TTS engine <b>16</b> keeps the TTS controller <b>14</b> updated with the TTS generation time throughout the transmission of the TTS data stream. In a preferred embodiment, the continuous recalculation of the CBP greatly improves the accuracy in high workload situations where the TTS generation time can vary from point to point. However, another useful embodiment may also include a CBP which is only calculated once.</p>
<p id="p-0036" num="0035">In step <b>208</b>, the CBP is checked to see if it is zero or less (i.e. the remaining generation time is equal to or less than the play out time) and loops back to step <b>206</b> until it is. During this loop the TTS data is being sent to the client buffer <b>24</b> and the remaining generation time is shrinking. Once the CBP has reached zero then the process moves on step <b>210</b>.</p>
<p id="p-0037" num="0036">In step <b>210</b>, the TTS controller <b>14</b> alerts the client <b>10</b> that the CBP has reached zero by sending a &#x2018;can play buffer&#x2019; message.</p>
<p id="p-0038" num="0037">In step <b>212</b>, the TTS controller <b>14</b> commits the TTS engine to the generation and delivery rate by instructing the priority engine to increase the priority of the data stream processing.</p>
<p id="p-0039" num="0038">Step <b>216</b> is the end of the control method, although as in step <b>214</b> the TTS engine can still be generating the TTS data stream and the client may still be playing out the data stream.</p>
<p id="p-0040" num="0039">The client buffer controller <b>22</b> uses client controller method <b>300</b> to process the TTS data stream.</p>
<p id="p-0041" num="0040">In step <b>302</b>, the buffer controller <b>22</b> requests TTS from the server <b>12</b>.</p>
<p id="p-0042" num="0041">In step <b>304</b>, the buffer controller <b>22</b> receives TTS data stream from the server.</p>
<p id="p-0043" num="0042">In step <b>306</b>, the buffer controller <b>22</b> waits until it is possible to start the play buffer.</p>
<p id="p-0044" num="0043">In optional step <b>308</b>, the buffer controller <b>22</b> waits to start the play buffer.</p>
<p id="p-0045" num="0044">In step <b>310</b>, the play buffer is played out while the TTS data stream is still received. Step <b>314</b> shows the end of the client controller method of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0046" num="0045">Below is an example of operation of the preferred embodiment for a text-to-speech data stream that takes 12 seconds to generate and 6 seconds to play out.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 4A</figref> is a graph of an example TTS server <b>12</b> workload verses time. Here, the server is able to process 0.5 seconds of audio every second for the first two seconds. After 2.0 seconds, because of a reduced workload, the TTS server <b>12</b> is able to process 0.75 seconds of audio every second. When the server <b>12</b> initially receives the TTS request, the TTS server <b>12</b> can only deliver 0.5 seconds of audio for every elapsed second. A critical point of 6.0 seconds is determined by subtracting the time to play the request (6.0 seconds) from the time to process the request (12.0 seconds). The server process schedules to send a &#x2018;can play buffer&#x2019; signal to the client after 6.0 seconds have elapsed.</p>
<p id="p-0048" num="0047">However, after 2.0 seconds of elapsed time, the server's load has decreased and now the system is able to deliver 0.75 seconds of audio for every elapsed second. A new critical buffer point determined by subtracting the time to play the request (6.0 seconds) from the time to process the request (5.0/0.75=6.67 seconds) to give 0.67 seconds or 2.67 seconds from the initial request being received (see <figref idref="DRAWINGS">FIG. 4B</figref>). The &#x2018;can play buffer&#x2019; message (START_PLAY in <figref idref="DRAWINGS">FIG. 4B</figref>) is sent after 2.67 seconds instead of 6.0 seconds.</p>
<p id="p-0049" num="0048">In summary, there is described a method, apparatus, and computer program product, which may include a computer readable medium, for negotiation of streaming data. In particular, it relates to a method and apparatus in a server that generates and serves large continuous amounts of speech data to a client in real time. According to one aspect there is provided a method of controlling the play out of a generated media data stream from a data stream player comprising: estimating a generation time for generating the data stream; estimating a play time for the data stream; generating a data stream using a data stream generation resource, for output by the data stream player; and alerting the stream player if the remaining generation time is substantial equal to or less than the play time. In a preferred embodiment, the server calculates what it can do, given knowledge of the network, and sends a message to guarantee a level of service from a pointon wards. A &#x201c;can start play&#x201d; message is sent to client at a point when the client can reliably start playing the signal. A preferred embodiment of the invention takes into account the server's processing capabilities and takes responsibility for prioritizing processes to guarantee a level of service to the client.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>We claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of controlling play out of a generated audio data stream from a client data stream player, the method comprising:
<claim-text>at a server, receiving a request, from a client data stream player, to generate an audio stream by converting textual data received from the client data stream player;</claim-text>
<claim-text>at the server, receiving, from a client, textual data to be generated by the server to an audio stream;</claim-text>
<claim-text>at the server, estimating a generation time for generating the audio stream;</claim-text>
<claim-text>at the server, estimating a time to play the generated audio stream at a data stream player;</claim-text>
<claim-text>at the server, generating the audio stream using data received from the client and a data stream generation resource, the audio stream for output by the client data stream player;</claim-text>
<claim-text>buffering at the client, the audio stream generated at the server,</claim-text>
<claim-text>waiting at the client for an alert from the server indicating that a remaining generation time is not more than a remaining play time;</claim-text>
<claim-text>sending an alert from the server to the client if remaining generation time for generating the audio stream using the data stream generation resource is not more than remaining play time; and</claim-text>
<claim-text>maintaining a rate of generation at an initial rate or faster after the alert has been sent,
<claim-text>wherein generating the audio stream has a priority and the priority is raised in order to maintain the rate of generation of the audio stream after the alert has been sent.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the remaining generation time is obtained from the data stream generation resource during the generation of the audio stream.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the alert is sent from the server to the client and wherein remaining generation time is calculated using size of text for conversion from the client and workload of a server text-to-speech engine.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the audio stream is speech only and the generation resource is a server text-to-speech engine.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein estimating the generation time includes considering the size of the textual data received from the client and considering the current workload of the data stream generation resource and determining if a critical buffer point is zero or less, the critical buffer point being determined by subtracting play time of voice data at a client media stream player from text-to-speech generation time by the data stream generation resource.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A system for controlling play out of a generated media data stream from a client data stream player, said system comprising:
<claim-text>a processor configured to estimate a generation time for generating a media data stream,
<claim-text>the processor executing instructions that cause the processor to calculate a critical buffer point for a buffer of a client data stream player, the critical buffer point representing a text-to-speech generation time minus a playtime of the speech at a client data stream player,</claim-text>
<claim-text>the processor also executing instructions that cause the processor to estimate a play time for the media data stream at a client data stream player;</claim-text>
</claim-text>
<claim-text>means for generating the media data stream using a data stream generation resource, for output by the client data stream player,
<claim-text>wherein the means for generating the media data stream is configured to convert text data received from the client to generate a media data stream consisting of audible speech,</claim-text>
<claim-text>wherein the means for generating is further configured to keep a controller updated with text-to-speech generation time throughout a transmission of a text-to-speech data stream;</claim-text>
</claim-text>
<claim-text>means for sending an alert to the client data stream player if remaining generation time for generating the media data stream using the data stream generation resource is not more than the play time by a client data stream player; and</claim-text>
<claim-text>means for maintaining the rate of generation of the media data stream at an initial rate or faster after an alert has been sent,
<claim-text>wherein the means for maintaining the rate of generation of the media data stream generation is configured to set a priority for generating the media data stream and to further raise the priority for generating the media data stream after the alert has been sent.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein remaining generation time is determined by the data stream generation resource during the generation of the media data stream and wherein remaining generation time is obtained each time from the data stream generation resource each time generation time is compared to play time by a client data stream player.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the means for sending an alert is in a server.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the means for generating the media data stream is configured to convert text to speech.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref> wherein the means for generating the media data stream is further configured to consider the size of the textual data received from a client and consider the means for generating.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A computer program product for controlling the play out of a generated media data stream from a data stream player, said computer program product comprising a non-transitory computer readable medium having computer readable program code tangibly embedded therein, the computer readable program code comprising:
<claim-text>computer readable program code configured to repeatedly estimate a remaining generation time for generating an audio voice stream from textual data received from a client;</claim-text>
<claim-text>computer readable program code configured to repeatedly estimate a play time at a client for playing a stream consisting of audio voice converted from the textual data received from the client;</claim-text>
<claim-text>computer readable program code configured to generate an audio voice stream using textual data received from a client and a data stream generation resource at a server, for output by a data stream player at the client;</claim-text>
<claim-text>computer readable program code configured to send an alert to the data stream player at the client if the remaining generation time is not more than the estimated play time at the client data stream player; and</claim-text>
<claim-text>computer readable program code configured to maintain the rate of generation of the audio voice stream at an initial rate or faster after the alert has been sent,
<claim-text>wherein the audio voice stream generation has a priority and the priority is raised to maintain the rate of generation of the audio voice stream after the alert has been sent.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The computer program product of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the remaining generation time of the audio voice stream is obtained from the data stream generation resource during the generation of the audio voice stream.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer program product of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the data stream generation resource is a text-to-speech engine.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The computer program product as in <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein the computer readable program code is further configured to consider the size of the textual data received from the client and consider the current workload of the data stream generation resource.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A system for controlling play out of a generated media data stream from a client data stream player, said system comprising:
<claim-text>a processor and memory, the memory storing instructions for execution on the processor, the instructions, which when executed by the processor, cause the processor to:
<claim-text>estimate a generation time for generating a media data stream;</claim-text>
<claim-text>estimate a play time at a client data stream player for a generated media data stream;</claim-text>
<claim-text>calculate a critical buffer point for a buffer of a client data stream player, the critical buffer point representing a text-to-speech generation time minus a playtime at the client data stream player;</claim-text>
<claim-text>generate the media data stream by converting text data received from a client to a media data stream consisting of audible speech;</claim-text>
<claim-text>send an alert to the client data stream player if remaining generation time for generating the media data stream is not more than the play time at the client data stream player;</claim-text>
<claim-text>maintain the rate of generation of the media data stream at an initial rate or faster after an alert has been sent; and</claim-text>
<claim-text>set a priority for generating the media data stream and later raise the priority for generating the media data stream after the alert has been sent.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein remaining generation time is determined during the generation of the media data stream and wherein remaining generation time is obtained each time generation time is compared to play time by a client data stream player.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the instructions, which when executed by the processor, further cause the processor to:
<claim-text>consider the size of textual data received from the client before sending the alert and consider the current workload of a data stream generation resource before sending the alert.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the instructions, when executed by the processor, further cause the processor to:
<claim-text>obtain remaining generation time of an audio voice stream from a data stream generation resource in communication with the processor during the generation of the audio voice stream. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
