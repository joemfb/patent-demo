<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624997-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624997</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13035785</doc-number>
<date>20110225</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>324</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>235</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>3</main-group>
<subgroup>14</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>3482291</main-classification>
<further-classification>3482301</further-classification>
<further-classification>348277</further-classification>
<further-classification>348297</further-classification>
<further-classification>3482211</further-classification>
</classification-national>
<invention-title id="d2e53">Alternative color image array and associated methods</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7479998</doc-number>
<kind>B2</kind>
<name>Mitsunaga et al.</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348273</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2004/0080652</doc-number>
<kind>A1</kind>
<name>Nonaka et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348312</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2004/0141075</doc-number>
<kind>A1</kind>
<name>Xu et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2006/0192873</doc-number>
<kind>A1</kind>
<name>Yaffe</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2007/0045681</doc-number>
<kind>A1</kind>
<name>Mauritzson et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0273785</doc-number>
<kind>A1</kind>
<name>Ogawa et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348362</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2007/0285526</doc-number>
<kind>A1</kind>
<name>Mann et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482221</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2009/0009623</doc-number>
<kind>A1</kind>
<name>Hoshino</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2009/0059048</doc-number>
<kind>A1</kind>
<name>Luo et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348308</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>WO</country>
<doc-number>2006049098</doc-number>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>Mase, Mitsuhito et al., &#x201c;A Wide Dynamic Range CMOS Image Sensor With Multiple Exposure-Time Signal Outputs and 12-Bit Column-Parallel Cyclic A/D Converters,&#x201d; IEEE Journal of Solid-State Circuits, vol. 40, No. 12, Dec. 2005 pp. 2787-2795.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Schrey, O. et al., &#x201c;A 1K&#xd7;1K High Dynamic Range CMOS Image Sensor With On-Chip Programmable Region of Interest Readout,&#x201d; Fraunhofer Institute of Microelectronic Circuits and Systems, Finkenstra.beta.e 61, D-47057 Duisburg, Germany, 4 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Yadid-Pecht, O. et al., &#x201c;Wide Intrascene Dynamic Range CMOS APS Using Dual Sampling,&#x201d; IEEE Transactions on Electron Devices, vol. 44, No. 10, Oct. 1997, pp. 1721-1723.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>European Search Report for Application No. 08252842.3 mailed on Nov. 24, 2008, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>File History of related European Patent Application Serial No. 08252842.3, dated Aug. 28, 2008 through Feb. 16, 2010, 136 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>3</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348273</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348277</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348280</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348276</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348281</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482221</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482201</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482211</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348362</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348297</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482291</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482301</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>PCT/US2010/049368</doc-number>
<date>20100917</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13035785</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61334886</doc-number>
<date>20100514</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110279705</doc-number>
<kind>A1</kind>
<date>20111117</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kuang</last-name>
<first-name>Jiangtao</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Wu</last-name>
<first-name>Donghui</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Shan</last-name>
<first-name>Jizhang</first-name>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kuang</last-name>
<first-name>Jiangtao</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Wu</last-name>
<first-name>Donghui</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Shan</last-name>
<first-name>Jizhang</first-name>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Lathrop &#x26; Gage LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>OmniVision Technologies, Inc.</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Tran</last-name>
<first-name>Nhan T</first-name>
<department>2664</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image sensor includes an array of light sensitive elements and a filter array. Each filter element is in optical communication with a respective light sensitive element. The image sensor receives filtered light having a repeating pattern. Light sensitive elements in at least two successive rows alternately receive light having a first color and a second color, and light sensitive elements in common columns of the successive rows alternately receive light having the first color and the second color. Light sensitive elements in at least two additional successive rows alternately receive light having a third and a fourth color, and light sensitive elements in common columns of the additional successive rows alternately receive light having the third color and the fourth color. Output values of pairs of sampled light sensitive elements receiving light of a common color and from successive rows are combined to generate a down-sampled image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="97.62mm" wi="156.55mm" file="US08624997-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="239.69mm" wi="157.99mm" file="US08624997-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="158.75mm" wi="113.37mm" file="US08624997-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="103.55mm" wi="156.63mm" file="US08624997-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="108.97mm" wi="165.52mm" file="US08624997-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="119.21mm" wi="166.88mm" file="US08624997-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="132.76mm" wi="172.97mm" file="US08624997-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="207.01mm" wi="157.99mm" file="US08624997-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="191.35mm" wi="168.23mm" file="US08624997-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="158.75mm" wi="130.64mm" file="US08624997-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="122.60mm" wi="160.70mm" file="US08624997-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation-in-part of International Application No. PCT/US2010/049368 filed Sep. 17, 2010, which claims priority to U.S. Patent Application Ser. No. 61/334,886, filed May 14, 2010, each of which are incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">CMOS image sensors are typically formed as an array of pixels, where each pixel includes a photodetector that transforms incident light photons into current signals. Each pixel may also include other known elements, such as a reset switch, a signal amplifier, and output circuits that operate to set the exposure time of the photodetector and perform a read out indicative of light photons incident thereon. Where incident light is too high for the set exposure time of the pixel, the photodetector typically saturates.</p>
<p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a prior art CMOS image sensor pixel array <b>100</b>. Pixel array <b>100</b> is configured for column parallel readout and has a plurality of columns, each having a pixel <b>102</b> for each of a plurality of rows. In column parallel readout architecture, for each row, one pixel <b>102</b> in each column is read out and processed simultaneously. That is, pixels <b>102</b> of Row <b>0</b> are read out in parallel, then pixels <b>102</b> of Row <b>1</b> are read out in parallel, then pixels <b>102</b> of Row <b>2</b> are read out in parallel, and so on, until Row M is read out. Pixels <b>102</b> within each column connect to a column readout line <b>105</b>, such that when a row is triggered for output, each pixel in that row outputs a signal to its associated column readout line <b>105</b>, while outputs of other pixels in the column remain inactive. Array <b>100</b> is shown with one sample and hold element <b>104</b> for each column read out line <b>105</b>. Sample and hold elements <b>104</b> and column read out lines <b>105</b> cooperate to provide a row-by-row read out of pixels <b>102</b>. A second stage amplifier <b>106</b> connects to each of the sample and hold elements <b>104</b>. All rows are typically output to form an image (also known as a frame).</p>
<p id="p-0005" num="0004">CMOS image sensors are often used in applications in which both very bright and very dark conditions are encountered. A variety of techniques have been developed to improve the response of CMOS image sensors in a variety of light conditions. For example, U.S. Patent Publication No. 2004/0141075, entitled &#x201c;Image Sensor Having Dual Automatic Exposure Control&#x201d;, by Xiangchen Xu et al., is assigned to Omnivision Technologies, Inc. and is hereby incorporated by reference. Xu teaches that the gain and exposure time can be adjusted over a sequence of frames to compensate for varying light conditions. An adjustment in exposure time is determined by analyzing one frame and then used to make an adjustment for a subsequent frame. While such approach controls exposure times over a series of frames to adjust for bright and dark conditions, it does not result in an increase in the dynamic range of the image sensor for a particular frame. As is well known in the field of image sensors, the dynamic range is the ratio of the largest detectable signal to the smallest, which for a CMOS image sensor is often defined by the ratio of the largest non-saturating signal to the standard deviation of the noise under dark conditions.</p>
<p id="p-0006" num="0005">U.S. Patent Publication No. 2009/0059048, entitled &#x201c;Image Sensor with High Dynamic Range in Down-Sampling Mode&#x201d;, by Xiaodong Luo et al, is also assigned to Omnivision Technologies, Inc. and is hereby incorporated by reference. Luo introduces a system and method to achieve a high dynamic range in a down-sampling operation mode by varying exposure times for different pixel rows and combining rows with different exposures, thus simultaneously reducing the vertical resolution and extending the dynamic range.</p>
<p id="p-0007" num="0006">In down-sampling, a binning process is used to combine data from two or more pixels to increase a signal to noise ratio (SNR), and a high dynamic range (HDR) combination process is used to combine data from two or more pixels to increase dynamic range. In the binning process, all rows have the same exposure time, while in the HDR combination process, rows of pixels can have different exposure times.</p>
<p id="p-0008" num="0007">A Bayer pattern, which is one of the most commonly used patterns for down-sampling, generates zigzag edges during both the HDR combination process and the binning process. Although corrective algorithms for these zigzag edges have been developed for use with the Bayer pattern, these corrective algorithms have certain disadvantages, such as reducing sharpness and resolution of output frames and increasing cost of image sensors. For example, a binning re-interpolation algorithm can partly smooth zigzag edges caused by the Bayer pattern, but with a sacrifice in sharpness and resolution of the resultant frame. Re-interpolation also becomes very expensive since more memory is necessary.</p>
<heading id="h-0003" level="1">BRIEF SUMMARY</heading>
<p id="p-0009" num="0008">The present disclosure presents a modified Bayer pattern as an alternative to the conventional Bayer pattern. The down-sampling problem of a zigzag effect resulting from binning or HDR combination of pixel values configured in a conventional Bayer pattern is solved by using a modified Bayer pattern. A sensor having pixels based upon the modified Bayer pattern outputs images with smooth edges without sacrificing sharpness or resolution. Image sensors based upon the modified Bayer pattern have less edge zigzag and have improved sharpness and resolution in generated images.</p>
<p id="p-0010" num="0009">In an embodiment, an image sensor includes an array of light sensitive elements and a filter array including a plurality of red, green, and blue filter elements. Each filter element is in optical communication with a respective light sensitive element. Each red filter element is configured to transmit only red colored light, each green filter element is configured to transmit only green colored light, and each blue filter element is configured to transmit only blue colored light. The filter array is arranged such that successive columns of the filter array have alternating first and second configurations. The first configuration is characterized by a repeating pattern of successive blue, green, red, and green filter elements, and the second configuration is characterized by a repeating pattern of successive green, blue, green, and red filter elements.</p>
<p id="p-0011" num="0010">In an embodiment, a method for down-sampling an image produced by an image sensor including an array of light sensitive elements includes filtering light incident on the image sensor. The light is filtered such that successive columns of the array of light sensitive elements alternately receive light having a first pattern and a second pattern. The first pattern is characterized by each four successive light sensitive elements in a column respectively receiving blue, green, red, and green colored light. The second pattern is characterized by each four successive light sensitive elements in a column respectively receiving green, blue, green, and red colored light. The method further includes sampling output values of the light sensitive elements and combining output values of pairs of light sensitive elements to generate a down-sampled image.</p>
<p id="p-0012" num="0011">In an embodiment, a method for down-sampling an image produced by an image sensor including an array of light sensitive elements includes filtering light incident on the image sensor. The light is filtered such that successive columns of the array of light sensitive elements alternately receive light having a first pattern and a second pattern. The first pattern is characterized by each four successive light sensitive elements in a column respectively receiving blue, green, red, and green colored light. The second pattern is characterized by each four successive light sensitive elements in a column respectively receiving green, blue, green, and red colored light. The method additionally includes sampling output values of the light sensitive elements such that light sensitive elements of successive rows alternately have long and short exposure times. The method further includes combining output values of pairs of light sensitive elements to generate a down-sampled image.</p>
<p id="p-0013" num="0012">In an embodiment, an image sensor has an array of light sensitive elements and a filter array including a plurality of first, second, third, and fourth filter elements, each filter element in optical communication with a respective light sensitive element. Each first filter element is configured to transmit light of a first color, each second filter element is configured to transmit light of a second color, each third filter element is configured to transmit light of a third color, and each fourth filter element is configured to transmit light of a fourth color. The filter array is configured to include a repeating pattern of filter elements characterized by: at least two successive rows of alternating first and second filter elements where common columns of the at least two successive rows also include alternating first and second filter elements, and at least two additional successive rows of alternating third and fourth filter elements where common columns of the at least two additional successive rows also include alternating third and fourth filter element elements.</p>
<p id="p-0014" num="0013">In an embodiment, a method down-samples an image produced by an image sensor including an array of light sensitive elements. Light incident on the image sensor is filtered such that the image sensor receives light having a repeating pattern characterized by: (a) light sensitive elements in at least two successive rows alternately receiving light having a first color and a second color, and light sensitive elements in common columns of the at least two successive rows alternately receiving light having the first color and the second color, and (b) light sensitive elements in at least two additional successive rows alternately receive light having a third and a fourth color, and light sensitive elements in common columns of the at least two additional successive rows alternately receiving light having the third color and the fourth color. Output values of the light sensitive elements are sampled, and output values of pairs of light sensitive elements receiving light of a common color and from successive rows of the array are combined to generate a down-sampled image.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> illustrates operation of a prior art image sensor.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating one exemplary modified Bayer pattern imaging system that supports down-sampling with both a high dynamic range combination and binning, according to an embodiment.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 3</figref> illustrates binning for a conventional Bayer pattern in a down-sampling mode.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 4</figref> illustrates binning for an exemplary modified Bayer pattern in a down-sampling mode, according to an embodiment.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 5</figref> illustrates prior art data selection between long exposure and short exposure for a conventional Bayer pattern in a down-sampling mode.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 6</figref> illustrates data selection among long exposure and short exposure for an exemplary modified Bayer pattern in a down-sampling mode, according to an embodiment.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 7</figref> shows a portion of a pixel array configured in a modified Bayer pattern illustrating exemplary connectivity for binning pixel data values to generate output data, according to an embodiment.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 8</figref> shows a portion of a pixel array configured in a modified Bayer pattern illustrating alternate exemplary connectivity for binning pixel data values to generate output data, according to an embodiment.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 9</figref> illustrates binning for an exemplary rotated modified Bayer pattern in a down-sampling mode, according to an embodiment.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram illustrating one exemplary rotated modified Bayer pattern image sensor that supports down-sampling with both a high dynamic range (HDR) combination and binning, according to an embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0025" num="0024">In the following description, the terms sensor array, pixel array, and image array may be used interchangeably to mean an array of photosensors.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating one exemplary modified Bayer pattern image sensor <b>200</b> that supports down-sampling with both a high dynamic range (HDR) combination and binning. Certain components are omitted for clarity of illustration. Image sensor <b>200</b> includes an image array <b>203</b> that has a plurality of light sensitive elements or photo-sensitive pixels <b>202</b> arranged as a plurality of rows and a plurality of columns and a filter array including a number of filter elements. Each filter element is in optical alignment with a respective pixel and is configured to allow light of only a certain color to pass through. The filter array conforms to a modified Bayer pattern defining the color sensitivity of each pixel <b>202</b>. That is, color of pixel sensors within image array <b>203</b> conform to the exemplary modified Bayer pattern sensor <b>400</b> of <figref idref="DRAWINGS">FIG. 4</figref>. Image sensor <b>200</b> may be implemented as a complementary metal-oxide-semiconductor (CMOS) image sensor where each pixel <b>202</b> includes a photodetector and associated circuitry that supports setting an exposure time and reading out pixel values.</p>
<p id="p-0027" num="0026">As shown, image array <b>203</b> has a column parallel readout architecture where, for each row, pixels <b>202</b> are read out simultaneously and processed in parallel. For each column, a readout line <b>205</b> connects, in parallel, to pixels <b>202</b> of that column and to a sample and hold (S/H) element <b>204</b>. Outputs of S/H elements <b>204</b> connect to a second stage amplifier <b>206</b>, which in turn connects to a processor <b>250</b>. Processor <b>250</b> processes signals (i.e., image sensor data) from amplifier <b>206</b> to generate an image. Processor <b>250</b> may be implemented as a digital signal processor having a local line memory.</p>
<p id="p-0028" num="0027">A row address decoder <b>208</b> and a column address decoder <b>210</b> operate to decode signals from a timing and control block <b>215</b> to address pixels <b>202</b>. Timing and control block <b>215</b> includes a first pre-charge address block <b>220</b>, a second pre-charge address block <b>225</b>, and a sampling address block <b>230</b>. The first pre-charge address block <b>220</b> may be set to a first pre-charge value, and the second pre-charge address block <b>225</b> may be set to a second pre-charge value. In one example of operation, sampling address <b>230</b> of timing and control block <b>215</b> selects a row, and a pre-charge is applied to pixels of that row from either the first pre-charge address block or the second pre-charge address block.</p>
<p id="p-0029" num="0028">In one embodiment, the first pre-charge address block <b>220</b> supports a full resolution mode with the same gain and exposure time setting for each row. The first pre-charge address block <b>220</b> also supports a down-sampling mode that reduces resolution and permits the same exposure time to be set for all the rows during binning to achieve high SNR. The first pre-charge address block <b>220</b> and the second pre-charge address block <b>225</b> cooperate to support a down-sampling mode that reduces resolution and permits different exposure times to be set for different rows during the HDR combination process to achieve high dynamic range. Additional pre-charge address blocks (not shown) may be included within timing and control block <b>215</b> to provide additional pre-charge values for additional down-sampling modes.</p>
<p id="p-0030" num="0029">The resolution of an image generated by processor <b>250</b> using data from image sensor <b>200</b> depends upon how the raw pixel data generated by photo-sensitive pixel elements is sampled and processed to generate pixels for the processed image. The term &#x201c;raw pixel data&#x201d; is used to distinguish data generated by image sensor <b>200</b> from the pixel data after the raw data has been sampled and performed additional signal processing by processor <b>250</b>. In particular, the raw pixel data received from image sensor <b>200</b> may be down-sampled to reduce the effective vertical resolution of the processed image. A variety of standard resolution formats are used in the image sensing art. For example, a 1.3 megapixel super extended graphics array (SXGA) format has 1280&#xd7;1024 pixels of resolution while a video graphics array (VGA) format has a resolution of 640&#xd7;480 pixels.</p>
<p id="p-0031" num="0030">In accordance with an embodiment, in a down-sampling mode, the vertical resolution of the raw pixel data is reduced by processor <b>250</b> to implement format conversion and simultaneously achieve a higher dynamic range. For example, when converting a 1.3 megapixel format into VGA, a down sampling mode may be selected that also provides a higher dynamic range. In this example, the down-sampling mode implements a 1:2 reduction in vertical resolution, and thus, since there is a simple geometric ratio of 1:2 in vertical resolution, down-sampling may combine data from two rows (e.g., Row <b>0</b> and Row <b>1</b>) of pixels <b>202</b>. In particular, processor <b>250</b> operates to combine raw pixel data values to generate pixel values in the final image. Where the first of the two rows being combined has a first pre-charge value (e.g., as set from the first pre-charge address block <b>220</b>) and the second of the two rows has a second pre-charge value (e.g., as set from the second pre-charge address block <b>225</b>), values resulting from two different exposure times controlled by the pre-charge values are processed by processor <b>250</b> to effectively increase the dynamic range of array <b>200</b>, as compared to the dynamic range when full resolution is used. In one example, even rows (e.g., Row <b>0</b>, Row <b>2</b>, Row <b>4</b>, . . . . Row M&#x2212;1) have a long exposure time and odd rows (e.g., Row <b>1</b>, Row <b>3</b>, Row <b>5</b>, . . . . Row M) have a short exposure time.</p>
<p id="p-0032" num="0031">As previously described, in one embodiment, processor <b>250</b> includes a local line memory to store and synchronize the processing of lines having either the same or different row exposure times. In particular, the local memory may be used to store sets of long exposure rows and short exposure rows sampled at different times to permit aligning and combining rows with either the same or different exposure times. In one embodiment, during down-sampling, processor <b>250</b> reads the memory and combines the raw pixel data of pixels that are neighbors along the vertical dimension that are of a compatible type and that have the same exposure time for the binning process. In another embodiment, during down-sampling, processor <b>250</b> reads the memory and selects the raw pixel data of pixels that are neighbors along the vertical dimension that are of a compatible type and that have the different exposure times for the HDR combination process.</p>
<p id="p-0033" num="0032">The exposure time of a pixel affects its output response. When a pixel is operated with a long exposure time, the pixel is very sensitive to received light, but tends to saturate at a low light level. In contrast, when the pixel is operated with a short exposure time, the pixel is less sensitive to light, and saturates at a higher light level as compared to operation with a short exposure time. Thus, by using different exposure times for rows that are down-sampled, a higher dynamic range is achieved as compared to down-sampling of rows with the same exposure time.</p>
<p id="p-0034" num="0033">Various extensions and modifications of the down-sampling mode with high dynamic range are contemplated. In a first scenario, any down-sampling mode with a 1:N reduction (where N is an integer value) in vertical resolution may be supported, such as 1:2, 1:3, 1:4 and so on. In this scenario, the exposure times of the rows are varied in an interleaved sequence of row exposure times that permits down-sampling to be achieved with increased dynamic range. For example, for down-sampling with a 1:3 reduction in vertical resolution, the three rows that are to be combined have a sequence of a long exposure time, medium exposure time, and short exposure time.</p>
<p id="p-0035" num="0034">In the HDR combination process, implemented within processor <b>250</b>, rows of pixels have different exposure times. By combining data from two or more pixels of rows having different exposure times, dynamic range may be increased. There are many ways of combining the data from long exposure pixels and short exposure pixels. In one way, data is selected from either the long exposure pixel or the short exposure pixel. In particular, data from pixels of long exposure time (L pixels) are selected by processor <b>250</b> where the L pixels are not saturated, and data from pixels of short exposure time (S pixels) are selected by processor <b>250</b> where the L pixels are saturated. Where the short exposure data is selected by processor <b>250</b>, the S pixel data is normalized to match the scale of long exposure pixels. For example,
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>data<sub>N</sub>=data<sub>O</sub>*(<i>L</i>_exposuretime/<i>S</i>_exposuretime)&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Where data<sub>N </sub>is the determined normalized pixel data value, data<sub>O </sub>is the original pixel data value, L_exposuretime represents the long exposure time, and S_exposuretime represents the exposure time of the selected pixel data value. If the pixel data value selected has the short exposure time, data<sub>N </sub>is normalized based upon the long exposure time as shown in Equation (1). If the pixel data value selected has the long exposure time, data<sub>N </sub>is the same as data<sub>O</sub>.
</p>
<p id="p-0036" num="0035">In one embodiment, when HDR combination is not required, all rows of pixels are configured to have the same exposure time. Binning of two rows having the same exposure time achieves a higher signal to noise ratio (SNR) in the down-sampling.</p>
<p id="p-0037" num="0036">Down-sampling modes that have higher dynamic range are also compatible with a variety of color filter array formats. In color sensing arrays in the art, a color filter array pattern is applied to an array of photosensors such that output from the photosensors creates a color image. The incoming light to each photosensor is filtered such that typically each photosensor in the pixel array records only one color, such as red, green or blue. In one embodiment, for a particular color filter array pattern, the row exposure times used in down-sampling are selected such that pixels having compatible filter types are combined during down-sampling.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 3</figref> illustrates prior art binning in a down-sampling mode for a Bayer pattern sensor <b>300</b>. Binning results <b>310</b> after down-sampling are shown in the right portion of <figref idref="DRAWINGS">FIG. 3</figref>. In Bayer pattern sensor <b>300</b>, a blue-green-blue-green (BGBG) row <b>315</b> of pixels is followed by a green-red-green-red (GRGR) row <b>320</b> of pixels. The Bayer pattern is a RGB filter pattern that is 50% green, 25% red, and 25% blue. In the Bayer pattern sensor, a blue-green row of pixels is followed by a green-red row of pixels. Other similar patterns include the CYGM filter array pattern (cyan, yellow, green, and magenta) formed of alternate rows of cyan-yellow and green-magenta, and a RGBE filter array pattern (red, green, blue, and emerald) having alternating rows of red-green and blue-emerald. Patterns may also include clear pixels, such a Red-Green-Blue-Clear (RGBC) and similarly, Red-Green-Blue-White (RGBW). As noted above, the problem with prior art sensor that utilize the Bayer pattern, is that significant zigzagging results during the binning process.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 4</figref> illustrates exemplary binning in a down-sampling mode for a modified Bayer pattern sensor <b>400</b>. Modified Bayer pattern sensor <b>400</b> may represent image array <b>203</b> of <figref idref="DRAWINGS">FIG. 2</figref>; a down sampling result <b>410</b> (the right portion of <figref idref="DRAWINGS">FIG. 4</figref>) illustrates binning results after down-sampling and has a conventional Bayer pattern as a result of binning. In the modified Bayer pattern sensor <b>400</b>, a blue-green row of pixels is followed by a green-blue row of pixels, which is followed by a red-green row of pixels, which is followed by a green-red row of pixels. Within the modified Bayer pattern sensor <b>400</b>, the rows of colors repeat every four rows. This novel pattern is modified from the Bayer pattern sensor <b>300</b> by inserting row GBGB <b>420</b> and row RGRG <b>430</b> between row BGBG <b>415</b> and row GRGR <b>435</b> that are equivalent to respective row BGBG <b>315</b> and row GRGR <b>320</b> of the Bayer pattern sensor <b>300</b>. Row GBGB <b>420</b> is formed by shifting elements G and B of row BGBG <b>415</b> to one column to either the right or to the left. Row RGRG <b>430</b> is formed by shifting elements G and R of row GRGR <b>435</b> to one column to either the right or the left.</p>
<p id="p-0040" num="0039">With the modified Bayer pattern sensor <b>400</b>, the rows have four color patterns that repeat every four rows: Blue-Green-Blue-Green (BGBG) <b>415</b>, Green-Blue-Green-Blue (GBGB) <b>420</b>, Red-Green-Red-Green (RGRG) <b>430</b>, and Green-Red-Green-Red (GRGR) <b>435</b>, and so on in repeating sequence. In this example all rows have the same exposure time. The repeating sequence is selected to be compatible with the modified Bayer pattern, which also repeats after every four rows. Binning of BGBG row <b>415</b> and GBGB row <b>420</b> generates a single BGBG row <b>425</b> after down-sampling in which the G combines data from the two green pixels of the two rows having the same exposure times, the B combines data from the two blue pixels of the two rows having the same exposure times, and so on. Similarly binning of RGRG row <b>430</b> and GRGR row <b>435</b> generates a single GRGR row <b>440</b> after down-sampling.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 5</figref> illustrates HDR combination in a down-sampling mode for a prior art Bayer filter pattern sensor <b>500</b>. Down-sampling from Bayer filter pattern sensor <b>500</b> gives down-sampling results <b>510</b> (in the right portion of <figref idref="DRAWINGS">FIG. 5</figref>). Within Bayer filter pattern sensor <b>500</b>, subscripts indicate whether the pixel is configured as either long (<sub>L</sub>) or short (<sub>S</sub>) exposure time rows. Every pair of two nearest rows having the same color pattern but different exposure times have pixel data combined during down-sampling to give down-sampling results <b>510</b>. GRGR row <b>525</b> results from selection between pixel values of GRGR row <b>515</b> and GRGR row <b>520</b>. Similarly BGBG row <b>540</b> results from pixel value selection between BGBG row <b>530</b> and BGBG row <b>535</b>. As noted above, the problem with prior art sensor that utilize the Bayer pattern, is that significant zigzagging results during the HDR combination process.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 6</figref> illustrates HDR combination in a down-sampling mode for a modified Bayer pattern sensor <b>600</b>. Modified Bayer filter pattern sensor <b>600</b> may represent a portion of image array <b>203</b> of <figref idref="DRAWINGS">FIG. 2</figref>; a down-sampling result <b>610</b> (shown in the right portion of <figref idref="DRAWINGS">FIG. 6</figref>) represents the result of down-sampling from modified Bayer filter pattern sensor <b>600</b>, and has a conventional Bayer pattern as a result of HDR combination. Within modified Bayer filter pattern sensor <b>600</b>, color sequences are similar to modified Bayer filter pattern sensor <b>400</b> of <figref idref="DRAWINGS">FIG. 4</figref>. Subscripts within each pixel indicate the configured exposure time as either long (<sub>L</sub>) or short (<sub>S</sub>). In the example of <figref idref="DRAWINGS">FIG. 6</figref>, row <b>615</b> has a long exposure time, row <b>620</b> has a short exposure time, row <b>630</b> has a long exposure time, and row <b>635</b> has a short exposure time. This sequence then repeats. The sequence is selected to be compatible with the modified Bayer pattern, which also repeats after every four rows. Adjacent rows of corresponding colors and different exposure times have pixel data combined during down-sampling. For example, a data selection of a long exposure time BGBG row <b>615</b> and a short exposure time GBGB row <b>620</b> to generate a single BGBG row <b>625</b> after down-sampling in which the G has selected data from the long and short exposure time pixel data (for the two green pixels from the rows with different exposure times), the R has selected data from long and short exposure time pixel data (for the two red pixels from the rows with different exposure times), and so on. Similarly one data is selected from a long exposure time RGRG row <b>630</b> and a short exposure time RGRG row <b>635</b> to generate a single GRGR row <b>640</b> after down-sampling.</p>
<p id="p-0043" num="0042">Other common filter patterns may also repeat after every four rows, such that the principles illustrated in <figref idref="DRAWINGS">FIGS. 4 and 6</figref> may be applied. For example, the CYGM pattern could be modified to have the following color pattern that repeats every four rows: cyan, yellow, cyan, yellow (row <b>1</b>); yellow, cyan, yellow, cyan (row <b>2</b>), green, magenta, green, magenta (row <b>3</b>); and magenta, green, magenta, green (row <b>4</b>). The RGBE, RGBC, and RGBW patterns could also be modified in similar manners, for example. Furthermore, it is anticipated that in alternate embodiments filter patterns are modified to repeat after more than four rows to achieve a reduction in vertical resolution larger than 1:2. For example, the Bayer pattern could be modified to have the following pattern that repeats every six row to achieve a 1:3 reduction in vertical resolution: blue, green, blue, green (row <b>1</b>); green, blue, green, blue (row <b>2</b>); blue, green, blue, green (row <b>3</b>); red, green, red green (row <b>4</b>); green, red, green, red (row <b>5</b>); and red, green, red, green (row <b>6</b>).</p>
<p id="p-0044" num="0043">Binning for the modified Bayer pattern (e.g., modified Bayer pattern sensors <b>400</b> and <b>600</b>) results in a uniform sampling and thereby minimizes zigzag edges, as compared to binning for conventional Bayer patterns. The HDR combination process also benefits from the modified Bayer pattern, and thus generates high quality images.</p>
<p id="p-0045" num="0044">In a normal mode (i.e., when not down-sampling), captured image quality from a sensor utilizing the modified Bayer pattern (e.g., sensor <b>200</b> configured with modified Bayer pattern sensor <b>400</b>) may not be as good as an image captured with a sensor configured with a conventional Bayer pattern. However, artifacts within the normal mode image captured from the sensor utilizing the modified Bayer pattern are minor compared to the zigzag problem, and these artifacts may be easily corrected by image processing algorithms.</p>
<p id="p-0046" num="0045">As previously discussed, image sensor <b>200</b> supports a full resolution (i.e., row-by-row) readout of pixel data in which each row has the same exposure time. In a preferred embodiment, image sensor <b>200</b> has two modes of operation; (1) a normal full resolution mode with dynamic range limited by photosensors within each pixel, and (2) a down-sampling mode that has reduced vertical resolution. In the down-sampling mode, binning achieves high SNR when HDR is not required, while HDR combination achieves a higher dynamic range when HDR is desired. A comparatively small amount of chip &#x2018;real estate&#x2019; is required for the additional functionality to provide the second pre-charge address block <b>225</b> and row independent exposure times for HDR combination. Only comparatively inexpensive modifications to processor <b>250</b> are required to implement the down-sampling mode with HDR combination. In essence &#x201c;spare lines&#x201d; are used during down-sampling to achieve a high dynamic range sensing mode at a very low marginal cost.</p>
<p id="p-0047" num="0046">Down-sampling schemes of the prior art typically emphasize reduction of noise and gain, and the exposure time of each row remains nominally the same. Prior art down-sampling either discards data from a portion of the lines or averages data across multiple rows. Thus, these prior art down-sampling approaches do not increase the dynamic range of resulting image.</p>
<p id="p-0048" num="0047">HDR combination may be implemented at least in part within the analog domain, such as using sample and hold registers or may be implemented in the digital domain, such as using analog to digital converters and software.</p>
<p id="p-0049" num="0048">Where processor <b>250</b> represents a digital signal processor, down-sampling, such as binning and HDR combination, may be implemented as machine readable instructions stored in memory accessible by the processor. At least part of the embodiments disclosed herein may relate to a computer storage product with a computer-readable medium having computer code thereon for performing various computer-implemented operations. Examples of computer-readable media include, but are not limited to: magnetic media such as hard disks, floppy disks, and magnetic tape; optical media such as CD-ROMs, DVDs and holographic devices; magneto-optical media; and hardware devices that are specially configured to store and execute program code, such as application-specific integrated circuits (&#x201c;ASICs&#x201d;), programmable logic devices (&#x201c;PLDs&#x201d;) and ROM and RAM devices. Examples of computer code include machine code, such as produced by a compiler, and files containing higher-level code that are executed by a computer using an interpreter. For example, an embodiment of the invention may be implemented using Java, C++, or other object-oriented programming language and development tools. Another embodiment of the invention may be implemented in hardwired circuitry in place of, or in combination with, machine-executable software instructions.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 7</figref> shows a portion <b>700</b> of a pixel array in modified Bayer pattern configuration illustrating exemplary connectivity for binning pixel data values to generate output data in a conventional Bayer pattern. Portion <b>700</b> may represent a portion of image array <b>203</b> of <figref idref="DRAWINGS">FIG. 2</figref>. Portion <b>700</b> includes sixteen pixels <b>202</b> divided into subgroups <b>710</b>A-D, each subgroup having four pixels. Portion <b>700</b> has four outputs <b>702</b>, <b>704</b>, <b>706</b>, and <b>708</b>. Output <b>702</b> combines data of two green pixels on a diagonal of subgroup <b>710</b>A. Similarly, output <b>704</b> combines data of two red pixels of subgroup <b>710</b>D, output <b>706</b> combines data of two green pixels of subgroup <b>710</b>C, and output <b>708</b> combines data of two blue pixels of subgroup <b>710</b>B. Outputs <b>708</b>, <b>702</b>, <b>706</b> and <b>704</b> thus generate two rows of two pixels arranged in a conventional Bayer pattern with a 2:1 reduction in vertical resolution and a 2:1 reduction in horizontal resolution.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 8</figref> shows a portion <b>800</b> of a pixel array in modified Bayer pattern configuration illustrating alternate exemplary connectivity for binning pixel data values to generate output data in a conventional Bayer pattern. Portion <b>800</b> may represent a portion of image array <b>203</b> of <figref idref="DRAWINGS">FIG. 2</figref>. Portion <b>800</b> has twenty four pixels that are divided into six subgroups <b>810</b>A-F of four pixels each. Each of subgroups <b>810</b>A-C has four pixels with BG on a first row and GB on a second row next to the first row, and each of subgroups <b>810</b>D-F has four pixels with RG on a first row and GR on a second row next to the first row. As illustrated in <figref idref="DRAWINGS">FIG. 8</figref>, outputs from each pair of pixels on a diagonal are combined, and then three pairs of the same color output are combined to generate green output <b>802</b>, red output <b>804</b>, green output <b>806</b>, and blue output <b>808</b>. Outputs <b>808</b>, <b>802</b>, <b>806</b> and <b>804</b> thus generate two rows of two pixels arranged in a conventional Bayer pattern with a 2:1 reduction in vertical resolution and a 3:1 reduction in horizontal resolution.</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 9</figref> is a block diagram illustrating one exemplary rotated modified Bayer pattern image sensor <b>900</b> that supports down-sampling with both a high dynamic range (HDR) combination and binning. Image sensor <b>900</b> is similar to image sensor <b>200</b> of <figref idref="DRAWINGS">FIG. 2</figref>, with the modified Bayer pattern of the filter array rotated by ninety degrees. Certain components are omitted for clarity of illustration. Image sensor <b>900</b> includes an image array <b>903</b> that has a plurality of light sensitive elements or photo-sensitive pixels <b>902</b> arranged as a plurality of rows and a plurality of columns and a filter array including a number of filter elements. Each filter element is in optical alignment with a respective pixel and is configured to allow light of only a certain color to pass through. The filter array conforms to a rotated modified Bayer pattern defining the color sensitivity of each pixel <b>902</b>. That is, color of pixel sensors within image array <b>903</b> conform to the exemplary rotated modified Bayer pattern sensor <b>1000</b> of <figref idref="DRAWINGS">FIG. 10</figref>. Image sensor <b>900</b> may be implemented as a complementary metal-oxide-semiconductor (CMOS) image sensor where each pixel <b>902</b> includes a photodetector and associated circuitry that supports setting an exposure time and reading out pixel values.</p>
<p id="p-0053" num="0052">As shown, image array <b>903</b> has a column parallel readout architecture where, for each row, pixels <b>902</b> are read out simultaneously and processed in parallel. For each column, a readout line <b>905</b> connects, in parallel, to pixels <b>902</b> of that column and to a sample and hold (S/H) element <b>904</b>. Outputs of S/H elements <b>904</b> connect to a second stage amplifier <b>906</b>, which in turn connects to a processor <b>950</b>. Processor <b>950</b> processes signals (i.e., image sensor data) from amplifier <b>906</b> to generate an image. Processor <b>950</b> may be implemented as a digital signal processor having a local line memory.</p>
<p id="p-0054" num="0053">A row address decoder <b>908</b> and a column address decoder <b>910</b> operate to decode signals from a timing and control block <b>915</b> to address pixels <b>902</b>. Timing and control block <b>915</b> includes a first pre-charge address block <b>920</b>, a second pre-charge address block <b>925</b>, and a sampling address block <b>930</b>. The first pre-charge address block <b>920</b> may be set to a first pre-charge value, and the second pre-charge address block <b>925</b> may be set to a second pre-charge value. In one example of operation, sampling address <b>930</b> of timing and control block <b>915</b> selects a row, and a pre-charge is applied to pixels of that row from either the first pre-charge address block or the second pre-charge address block.</p>
<p id="p-0055" num="0054">In one embodiment, the first pre-charge address block <b>920</b> supports a full resolution mode with the same gain and exposure time setting for each row. The first pre-charge address block <b>920</b> also supports a down-sampling mode that reduces resolution and permits the same exposure time to be set for all the rows during binning to achieve high SNR. The first pre-charge address block <b>920</b> and the second pre-charge address block <b>925</b> cooperate to support a down-sampling mode that reduces resolution and permits different exposure times to be set for different rows during the HDR combination process to achieve high dynamic range. Additional pre-charge address blocks (not shown) may be included within timing and control block <b>915</b> to provide additional pre-charge values for additional down-sampling modes.</p>
<p id="p-0056" num="0055">The resolution of an image generated by processor <b>950</b> using data from image sensor <b>900</b> depends upon how the raw pixel data generated by photo-sensitive pixel elements is sampled and processed to generate pixels for the processed image. The term &#x201c;raw pixel data&#x201d; is used to distinguish data generated by image sensor <b>900</b> from the pixel data after the raw data has been sampled and performed additional signal processing by processor <b>950</b>. In particular, the raw pixel data received from image sensor <b>900</b> may be down-sampled to reduce the effective vertical resolution of the processed image. A variety of standard resolution formats are used in the image sensing art. For example, a 1.3 megapixel super extended graphics array (SXGA) format has 1280&#xd7;924 pixels of resolution while a video graphics array (VGA) format has a resolution of 640&#xd7;480 pixels.</p>
<p id="p-0057" num="0056">In accordance with an embodiment, in a down-sampling mode, the vertical resolution of the raw pixel data is reduced by processor <b>950</b> to implement format conversion and simultaneously achieve a higher dynamic range. For example, when converting a 1.3 megapixel format into VGA, a down sampling mode may be selected that also provides a higher dynamic range. In this example, the down-sampling mode implements a 1:2 reduction in vertical resolution, and thus, since there is a simple geometric ratio of 1:2 in vertical resolution, down-sampling may combine data from two rows (e.g., Row <b>0</b> and Row <b>1</b>) of pixels <b>902</b>. In particular, processor <b>950</b> operates to combine raw pixel data values to generate pixel values in the final image. Where the first of the two rows being combined has a first pre-charge value (e.g., as set from the first pre-charge address block <b>920</b>) and the second of the two rows has a second pre-charge value (e.g., as set from the second pre-charge address block <b>925</b>), values resulting from two different exposure times controlled by the pre-charge values are processed by processor <b>950</b> to effectively increase the dynamic range of array <b>900</b>, as compared to the dynamic range when full resolution is used. In one example, even rows (e.g., Row <b>0</b>, Row <b>2</b>, Row <b>4</b>, . . . . Row M&#x2212;1) have a long exposure time and odd rows (e.g., Row <b>1</b>, Row <b>3</b>, Row <b>5</b>, . . . . Row M) have a short exposure time.</p>
<p id="p-0058" num="0057">As previously described, in one embodiment, processor <b>950</b> includes a local line memory to store and synchronize the processing of lines having either the same or different row exposure times. In particular, the local memory may be used to store sets of long exposure rows and short exposure rows sampled at different times to permit aligning and combining rows with either the same or different exposure times. In one embodiment, during down-sampling, processor <b>950</b> reads the memory and combines the raw pixel data of pixels that are neighbors along the vertical dimension that are of a compatible type and that have the same exposure time for the binning process. In another embodiment, during down-sampling, processor <b>950</b> reads the memory and selects the raw pixel data of pixels that are neighbors along the vertical dimension that are of a compatible type and that have the different exposure times for the HDR combination process.</p>
<p id="p-0059" num="0058">The exposure time of a pixel affects its output response. When a pixel is operated with a long exposure time, the pixel is very sensitive to received light, but tends to saturate at a low light level. In contrast, when the pixel is operated with a short exposure time, the pixel is less sensitive to light, and saturates at a higher light level as compared to operation with a short exposure time. Thus, by using different exposure times for rows that are down-sampled, a higher dynamic range is achieved as compared to down-sampling of rows with the same exposure time.</p>
<p id="p-0060" num="0059">Various extensions and modifications of the down-sampling mode with high dynamic range are contemplated. In a first scenario, any down-sampling mode with a 1:N reduction (where N is an integer value) in vertical resolution may be supported, such as 1:2, 1:3, 1:4 and so on. In this scenario, the exposure times of the rows are varied in an interleaved sequence of row exposure times that permits down-sampling to be achieved with increased dynamic range. For example, for down-sampling with a 1:3 reduction in vertical resolution, the three rows that are to be combined have a sequence of a long exposure time, medium exposure time, and short exposure time.</p>
<p id="p-0061" num="0060">In the HDR combination process, implemented within processor <b>950</b>, rows of pixels have different exposure times. By combining data from two or more pixels of rows having different exposure times, dynamic range may be increased. There are many ways of combining the data from long exposure pixels and short exposure pixels. In one way, data is selected from either the long exposure pixel or the short exposure pixel. In particular, data from pixels of long exposure time (L pixels) are selected by processor <b>950</b> where the L pixels are not saturated, and data from pixels of short exposure time (S pixels) are selected by processor <b>950</b> where the L pixels are saturated. Where the short exposure data is selected by processor <b>950</b>, the S pixel data is normalized to match the scale of long exposure pixels. For example,
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>data<sub>N</sub>=data<sub>O</sub>*(<i>L</i>_exposuretime/<i>S</i>_exposuretime)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Where data<sub>N </sub>is the determined normalized pixel data value, data<sub>O </sub>is the original pixel data value, L_exposuretime represents the long exposure time, and S_exposuretime represents the exposure time of the selected pixel data value. If the pixel data value selected has the short exposure time, data<sub>N </sub>is normalized based upon the long exposure time as shown in Equation (1). If the pixel data value selected has the long exposure time, data<sub>N </sub>is the same as data<sub>O</sub>.
</p>
<p id="p-0062" num="0061">In one embodiment, when HDR combination is not required, all rows of pixels are configured to have the same exposure time. Binning of two rows having the same exposure time achieves a higher signal to noise ratio (SNR) in the down-sampling.</p>
<p id="p-0063" num="0062">Down-sampling modes that have higher dynamic range are also compatible with a variety of color filter array formats. In color sensing arrays in the art, a color filter array pattern is applied to an array of photosensors such that output from the photosensors creates a color image. The incoming light to each photosensor is filtered such that typically each photosensor in the pixel array records only one color, such as red, green or blue. In one embodiment, for a particular color filter array pattern, the row exposure times used in down-sampling are selected such that pixels having compatible filter types are combined during down-sampling.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 10</figref> illustrates exemplary binning in a down-sampling mode for a rotated modified Bayer pattern sensor <b>1000</b>. Rotated modified Bayer pattern sensor <b>1000</b> may represent image array <b>903</b> of <figref idref="DRAWINGS">FIG. 9</figref>; a down sampling result <b>1010</b> (the right portion of <figref idref="DRAWINGS">FIG. 10</figref>) illustrates binning results after down-sampling and has a conventional Bayer pattern as a result of binning. In the rotated modified Bayer pattern sensor <b>1000</b>, a blue-green-red-green row <b>1015</b> of pixels is followed by a green-blue-green-red row <b>1020</b> of pixels, which is followed by a blue-green-red-green row <b>1030</b> of pixels, which is followed by a green-blue-green-red row <b>1035</b> of pixels. Within the rotated modified Bayer pattern sensor <b>1000</b>, the rows of colors repeat every two rows and the columns repeat every four columns The other modified Bayer patterns discussed above (e.g., modified CYGM, RGBE, RGBC, and RGBW) could also be rotated in a similar manner.</p>
<p id="p-0065" num="0064">With the rotated modified Bayer pattern sensor <b>1000</b>, the columns have four color patterns that repeat every four rows: Blue-Green-Blue-Green (BGBG) <b>1050</b>, Green-Blue-Green-Blue (GBGB) <b>1052</b>, Red-Green-Red-Green (RGRG) <b>1054</b>, and Green-Red-Green-Red (GRGR) <b>1056</b>, and so on in repeating sequence. In this example all rows have the same exposure time. The repeating sequence is selected to be compatible with the modified Bayer pattern, which also repeats after every four rows. Binning of BGBG row <b>1015</b> and GBGB row <b>1020</b> generates a single BGBG row <b>1025</b> after down-sampling in which the G combines data from the two green pixels of the two rows having the same exposure times, the B combines data from the two blue pixels of the two rows having the same exposure times, and so on. Similarly binning of RGRG row <b>1030</b> and GRGR row <b>1035</b> generates a single GRGR row <b>1040</b> after down-sampling. It should be noted that in this example, both horizontal and vertical down-sampling results.</p>
<p id="p-0066" num="0065">According to embodiments of the present invention, the modified Bayer filter pattern and rotated modified Bayer filter pattern may be used in, but is not limited to, high resolution sensors, and low noise and high sensitivity sensors for HD video. The use of higher resolution (than needed for a final image resolution) sensors (e.g., image sensor <b>200</b>, <figref idref="DRAWINGS">FIG. 2</figref> and image sensor <b>900</b>, <figref idref="DRAWINGS">FIG. 9</figref>) and the above described binning technique improves sharpness and resolution with minimized zigzag edges in the final image. Where an image sensor (e.g., image sensor <b>200</b>, <figref idref="DRAWINGS">FIG. 2</figref> and image sensor <b>900</b>, <figref idref="DRAWINGS">FIG. 9</figref>) also optionally implements down-sampling, such as binning and HDR combination to generate output, these sensors also benefit from use of the modified Bayer filter pattern and the rotated modified Bayer filter pattern for improved image quality.</p>
<p id="p-0067" num="0066">Other improvements may be realized through use of sensor <b>200</b> with a modified Bayer pattern sensor array (e.g., image array <b>203</b>) and image sensor <b>900</b> with a rotated modified Bayer pattern sensor array (e.g., image array <b>903</b>, <figref idref="DRAWINGS">FIG. 9</figref>), beyond the above described improvements in image quality. For example, cost may be reduced for system on a chip (SOC) image sensors. For sensors that output raw image data, an extra memory buffer may be required for Bayer pattern output. However, such raw image sensors may also share memory with other processing modules, such as defect pixel correction (DPC) and automatic white balance (AWB) processors.</p>
<p id="p-0068" num="0067">Having described several embodiments, it will be recognized by those skilled in the art that various modifications, alternative constructions, and equivalents may be used without departing from the spirit of the invention, for example, variations in sequence of steps and configuration and number of pixels, etc. Additionally, a number of well known processes and elements have not been described in order to avoid unnecessarily obscuring the present invention. Accordingly, the above description should not be taken as limiting the scope of the invention.</p>
<p id="p-0069" num="0068">It should thus be noted that the matter contained in the above description or shown in the accompanying drawings should be interpreted as illustrative and not in a limiting sense. The following claims are intended to cover generic and specific features described herein, as well as all statements of the scope of the present method and system, which, as a matter of language, might be the to fall there between.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for down-sampling an image produced by an image sensor including an array of light sensitive elements, comprising:
<claim-text>filtering light incident on the image sensor such that the image sensor receives light having a repeating pattern characterized by:</claim-text>
<claim-text>light sensitive elements in at least two successive columns alternately receiving light having a first color and a second color, and light sensitive elements in common rows of the at least two successive columns alternately receiving light having the first color and the second color, and</claim-text>
<claim-text>light sensitive elements in at least two additional successive columns alternately receive light having a third and a fourth color, and light sensitive elements in common rows of the at least two additional successive columns alternately receiving light having the third color and the fourth color;</claim-text>
<claim-text>sampling output values of the light sensitive elements;</claim-text>
<claim-text>combining output values of pairs of light sensitive elements receiving light of a common color and from successive rows of the array to generate a down-sampled image, the step of combining including, for each pair of light sensitive elements:
<claim-text>selecting a value from a light sensitive element of the pair having a long exposure time when the light sensitive element having a long exposure time has not saturated, and</claim-text>
<claim-text>selecting a value from a light sensitive element of the pair having a short exposure time when the light sensitive element having a long exposure time has saturated, the value being normalized to the value of the light sensitive element of the pair having the long exposure time; and</claim-text>
</claim-text>
<claim-text>configuring the light sensitive elements such that light sensitive elements of successive rows alternately have long and short exposure times, wherein the down-sampled image has increased dynamic range.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, the first and fourth colors being the color green, the second color being the color blue, and the third color being the color red.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A method for down-sampling an image produced by an image sensor including an array of light sensitive elements, comprising:
<claim-text>filtering light incident on the image sensor such that successive rows of the array of light sensitive elements alternately receive light having a first pattern and a second pattern, the first pattern characterized by each four successive light sensitive elements in a row respectively receiving blue, green, red, and green colored light, and the second pattern characterized by each four successive light sensitive elements in a row respectively receiving green, blue, green, and red colored light;</claim-text>
<claim-text>sampling output values of the light sensitive elements; and</claim-text>
<claim-text>combining output values of pairs of light sensitive elements receiving light of a common color and from successive rows of the array to generate a down-sampled image, the step of combining including, for each pair of light sensitive elements:
<claim-text>selecting a value from a light sensitive element of the pair having a long exposure time when the light sensitive element having a long exposure time has not saturated, and</claim-text>
<claim-text>selecting a value from a light sensitive element of the pair having a short exposure time when the light sensitive element having a long exposure time has saturated, the value being normalized to the value of the light sensitive element of the pair having the long exposure time; and,</claim-text>
</claim-text>
<claim-text>configuring the light sensitive elements such that light sensitive elements of successive rows alternately have long and short exposure times, wherein the down-samples image has an increased dynamic range. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
