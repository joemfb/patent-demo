<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622839-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622839</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12964225</doc-number>
<date>20101209</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>193</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>63</class>
<subclass>F</subclass>
<main-group>13</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>463 42</main-classification>
<further-classification>463  7</further-classification>
<further-classification>463  8</further-classification>
<further-classification>463  9</further-classification>
<further-classification>463 40</further-classification>
<further-classification>463 41</further-classification>
</classification-national>
<invention-title id="d2e53">Enhancing user experience by presenting past application usage</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2005/0054444</doc-number>
<kind>A1</kind>
<name>Okada</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 42</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2006/0287106</doc-number>
<kind>A1</kind>
<name>Jensen</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 42</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2007/0004507</doc-number>
<kind>A1</kind>
<name>Nakajima et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 29</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2007/0088862</doc-number>
<kind>A1</kind>
<name>Burkman et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710 16</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2007/0093293</doc-number>
<kind>A1</kind>
<name>Osnato</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 36</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0124791</doc-number>
<kind>A1</kind>
<name>Spechtler et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725133</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2008/0274798</doc-number>
<kind>A1</kind>
<name>Walker et al.</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 25</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2008/0280686</doc-number>
<kind>A1</kind>
<name>Dhupelia et al.</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 42</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2009/0270166</doc-number>
<kind>A1</kind>
<name>Thukral et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 25</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2010/0016073</doc-number>
<kind>A1</kind>
<name>Goldstein et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 29</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2010/0304860</doc-number>
<kind>A1</kind>
<name>Gault et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 31</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Planet Unreal, &#x201c;Unreal Tournament Game Guide&#x201d;, game released Nov. 1999 with earliest article comment on Sep. 6, 2007,IGN Entertainment, &#x3c;http://planetunreal.gamespy.com/View.php?view=UTGameInfo.Detail&#x26;id=28&#x26;game=6&#x3e;&#x3c;http://planetunreal.gamespy.com/View.php?view=UTGameInfo.Detail&#x26;id=l&#x26;game=6&#x3e;.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Unreal Tournament 1999, http://www.fingel.com/ut/, retrieved Jan. 25, 2013, 4 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>31</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>463  7-  9</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>McKenzie</last-name>
<first-name>Bruce J.</first-name>
<address>
<city>Murrieta</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Overton</last-name>
<first-name>Adam J.</first-name>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Fisher</last-name>
<first-name>Brian D.</first-name>
<address>
<city>Irvine</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Shepard</last-name>
<first-name>Isaac J.</first-name>
<address>
<city>Ladera Ranch</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>JnBaptiste</last-name>
<first-name>Eden Ashley</first-name>
<address>
<city>Orlando</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Zhang</last-name>
<first-name>Eric M.</first-name>
<address>
<city>Fremont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="007" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Jenks</last-name>
<first-name>Jason C.</first-name>
<address>
<city>Lynnwood</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="008" app-type="applicant" designation="us-only">
<addressbook>
<last-name>McCuller</last-name>
<first-name>Patrick G.</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>McKenzie</last-name>
<first-name>Bruce J.</first-name>
<address>
<city>Murrieta</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Overton</last-name>
<first-name>Adam J.</first-name>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Fisher</last-name>
<first-name>Brian D.</first-name>
<address>
<city>Irvine</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Shepard</last-name>
<first-name>Isaac J.</first-name>
<address>
<city>Ladera Ranch</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>JnBaptiste</last-name>
<first-name>Eden Ashley</first-name>
<address>
<city>Orlando</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Zhang</last-name>
<first-name>Eric M.</first-name>
<address>
<city>Fremont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="007" designation="us-only">
<addressbook>
<last-name>Jenks</last-name>
<first-name>Jason C.</first-name>
<address>
<city>Lynnwood</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="008" designation="us-only">
<addressbook>
<last-name>McCuller</last-name>
<first-name>Patrick G.</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Thomas | Horstemeyer, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Amazon Technologies, Inc.</orgname>
<role>02</role>
<address>
<city>Reno</city>
<state>NV</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Laneau</last-name>
<first-name>Ronald</first-name>
<department>3714</department>
</primary-examiner>
<assistant-examiner>
<last-name>Myhr</last-name>
<first-name>Justin</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Disclosed are various embodiments for enhancing the experience of a user with an application by presenting past usage of the application. An application is executed in a hosted environment in one or more computing devices. Multiple input commands are obtained from a client, and the input commands are provided to the application. A video signal generated by the application is encoded into real-time content, which is sent to the client. Recorded content from a library of recorded content is sent to the client. Each recorded content presents a past usage of the application.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="168.83mm" wi="170.60mm" file="US08622839-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="230.38mm" wi="170.94mm" file="US08622839-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="167.81mm" wi="175.01mm" file="US08622839-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="197.02mm" wi="171.62mm" file="US08622839-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="224.37mm" wi="153.08mm" file="US08622839-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="148.67mm" wi="170.94mm" file="US08622839-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">Video games and other computer-based games are often designed to be challenging. As an example, the execution of a complex move may be needed by a player to make it past a certain checkpoint in a game. Such a move may involve a rapid succession of input commands. The player may benefit from continued practice in order to execute the move. However, even with continued practice, the player may not be able to continue past the checkpoint.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0003" num="0002">Many aspects of the present disclosure can be better understood with reference to the following drawings. The components in the drawings are not necessarily to scale, emphasis instead being placed upon clearly illustrating the principles of the disclosure. Moreover, in the drawings, like reference numerals designate corresponding parts throughout the several views.</p>
<p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. 1</figref> is a drawing of a networked environment according to various embodiments of the present disclosure.</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIGS. 2 and 3</figref> are drawings of examples of user interfaces rendered by a client in the networked environment of <figref idref="DRAWINGS">FIG. 1</figref> according to various embodiments of the present disclosure.</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating one example of functionality implemented as portions of a server application executed in a computing device in the networked environment of <figref idref="DRAWINGS">FIG. 1</figref> according to various embodiments of the present disclosure.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic block diagram that provides one example illustration of a computing device employed in the networked environment of <figref idref="DRAWINGS">FIG. 1</figref> according to various embodiments of the present disclosure.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0003" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0008" num="0007">The present disclosure relates to enhancing the experience of a user with an application by presenting past usage of the application. The application may comprise, for example, a game application or some other type of application. In the case of a challenging video game, a user may get frustrated by not being able to complete an objective or to move on to the next level of the game. Although the user may talk with other players, consult references, or repeatedly practice gaming techniques, it may be most helpful to the user to see another player complete the objective or advance to the next level.</p>
<p id="p-0009" num="0008">Various embodiments of the present disclosure are configured to present multimedia showing past usage of an application in conjunction with the current usage of the application. Such multimedia may include, for example, videos of past usage, voiceovers by experienced users, textual annotations, and so on. The video and/or other media streams generated by an application executed in a hosted environment may be captured and stored for future reference by other users. Such stored application sessions may be indexed, annotated, and made available to users when appropriate. In the following discussion, a general description of the system and its components is provided, followed by a discussion of the operation of the same.</p>
<p id="p-0010" num="0009">With reference to <figref idref="DRAWINGS">FIG. 1</figref>, shown is a networked environment <b>100</b> according to various embodiments. The networked environment <b>100</b> includes one or more computing devices <b>103</b> in data communication with one or more clients <b>106</b> by way of a network <b>109</b>. The network <b>109</b> includes, for example, the Internet, intranets, extranets, wide area networks (WANs), local area networks (LANs), wired networks, wireless networks, or other suitable networks, etc., or any combination of two or more such networks.</p>
<p id="p-0011" num="0010">The computing device <b>103</b> may comprise, for example, a server computer or any other system providing computing capability. Alternatively, a plurality of computing devices <b>103</b> may be employed that are arranged, for example, in one or more server banks or computer banks or other arrangements. For example, a plurality of computing devices <b>103</b> together may comprise a cloud computing resource, a grid computing resource, and/or any other distributed computing arrangement. Such computing devices <b>103</b> may be located in a single installation or may be distributed among many different geographical locations. For purposes of convenience, the computing device <b>103</b> is referred to herein in the singular. Even though the computing device <b>103</b> is referred to in the singular, it is understood that a plurality of computing devices <b>103</b> may be employed in the various arrangements as described above.</p>
<p id="p-0012" num="0011">Various applications and/or other functionality may be executed in the computing device <b>103</b> according to various embodiments. Also, various data is stored in a data store <b>112</b> that is accessible to the computing device <b>103</b>. The data store <b>112</b> may be representative of a plurality of data stores <b>112</b> as can be appreciated. The data stored in the data store <b>112</b>, for example, is associated with the operation of the various applications and/or functional entities described below.</p>
<p id="p-0013" num="0012">The components executed on the computing device <b>103</b>, for example, include a server application <b>115</b>, a plurality of wrappers <b>118</b><i>a </i>. . . <b>118</b>N, a plurality of applications <b>119</b><i>a </i>. . . <b>119</b>N, a plurality of video encoders <b>120</b><i>a </i>. . . <b>120</b>N, and other applications, services, processes, systems, engines, or functionality not discussed in detail herein. The server application <b>115</b> may correspond to a game server application or another type of application session server. The server application <b>115</b> is executed to launch applications <b>119</b>, which are executed within the wrappers <b>118</b>. The server application <b>115</b> is also executed to obtain input data <b>122</b> from the clients <b>106</b> and provide the input data <b>122</b> to the respective wrapper <b>118</b>.</p>
<p id="p-0014" num="0013">The server application <b>115</b> is also executed to send output data <b>123</b> that is captured from the application <b>119</b> to the clients <b>106</b>. The server application <b>115</b> may communicate with the client <b>106</b> over various protocols such as, for example, hypertext transfer protocol (HTTP), simple object access protocol (SOAP), representational state transfer (REST), real-time transport protocol (RTP), real time streaming protocol (RTSP), real time messaging protocol (RTMP), user datagram protocol (UDP), transmission control protocol (TCP), and/or other protocols for communicating data over the network <b>109</b>. The server application <b>115</b> is configured to maintain application state information <b>124</b> associated with the executing applications <b>119</b>.</p>
<p id="p-0015" num="0014">The application <b>119</b> may correspond, for example, to a game or other types of applications. As non-limiting examples, the application <b>119</b> may correspond to a first-person shooter game, an action game, an adventure game, a party game, a role-playing game, a simulation game, a strategy game, a vehicle simulation game, and/or other types of games. The application <b>119</b> may be a game originally designed for execution in a general-purpose computing device or in a specialized video game device such as, for example, a video game console, a handheld game device, an arcade game device, etc. The applications <b>119</b> may also correspond to mobile phone applications, computer-aided design (CAD) applications, computer-aided manufacturing (CAM) applications, photo manipulation applications, video editing applications, office productivity applications, operating systems and associated applications, emulators for operating systems, architectures, and capabilities not present on a consumer device, and other applications and combinations of applications. Where game applications are mentioned in the following text, it is understood that game applications are merely examples of the many different types of applications <b>119</b>.</p>
<p id="p-0016" num="0015">The application <b>119</b> may expect to access one or more resources of the device on which it is executed. Such resources may correspond to display devices, input devices, or other devices. In some cases, the application <b>119</b> may request exclusive access to one or more of the resources, whereby no other applications may have access to the particular resources.</p>
<p id="p-0017" num="0016">The wrapper <b>118</b> corresponds to an application that provides a hosted, controlled, and/or virtualized environment for execution of the application <b>119</b>. In particular, the wrapper <b>118</b> may be configured to virtualize one or more of the resources that the application <b>119</b> expects to access. Such resources may include a keyboard, a mouse, a joystick, a video device, a sound device, etc. In this way, the wrapper <b>118</b> is able to provide input commands to the application <b>119</b> as if the wrapper <b>118</b> emulates a keyboard, a mouse, or another type of input device.</p>
<p id="p-0018" num="0017">Further, the wrapper <b>118</b> is able to obtain a video signal generated by the application <b>119</b> as if the wrapper <b>118</b> emulates a display device, an audio device, or another type of output device. The wrapper <b>118</b> is able to encode the video signal by way of a video encoder <b>120</b> into a media stream. The media stream may include an audio signal generated by the application <b>119</b> as well. To this end, the wrapper <b>118</b> may include various types of video encoders <b>120</b>, such as, for example, Moving Pictures Experts Group (MPEG) encoders, H.264 encoders, Flash&#xae; video encoders, etc. Such video encoders <b>120</b> may be selected according to factors such as, for example, data reduction, encoding quality, latency, etc. In some embodiments, the wrappers <b>118</b> may communicate directly with the clients <b>106</b> to obtain the input data <b>122</b> and to serve up the output data <b>123</b>.</p>
<p id="p-0019" num="0018">Different types of wrappers <b>118</b> may be provided for different applications <b>119</b> or classes of applications <b>119</b>. As non-limiting examples, different wrappers <b>118</b> may be provided for applications <b>119</b> using different application programming interfaces (APIs) such as OpenGL&#xae;, DirectX&#xae;, the Graphics Device Interface (GDI), and so on. Where the application <b>119</b> is configured for execution in a specialized video game device or another type of computing device, the wrapper <b>118</b> may include an emulation application that emulates the device or the software of the device.</p>
<p id="p-0020" num="0019">The application state information <b>124</b> that is maintained by the server application <b>115</b> includes various data relating to application sessions that are currently active. For example, the application state information <b>124</b> may track the users that are currently participating in the application session, status information associated with the users, security permissions associated with the application session (e.g., who can or cannot join), and so on. In some embodiments, some or all of the application state information <b>124</b> may be discarded when an application session ends.</p>
<p id="p-0021" num="0020">The data stored in the data store <b>112</b> includes, for example, applications <b>127</b>, video encoders <b>129</b>, wrappers <b>130</b>, saved state data <b>133</b>, user data <b>134</b>, recorded media streams <b>135</b>, annotations <b>136</b>, ratings <b>137</b>, and potentially other data. The applications <b>127</b> correspond to a library of different applications that are available to be launched as applications <b>119</b>. The applications <b>127</b> may correspond to executable code within the computing device <b>103</b>. Alternatively, the applications <b>127</b> may correspond to code that is executable within another type of device but is not executable within the computing device <b>103</b>. Such applications <b>127</b> may be referred to as &#x201c;binaries,&#x201d; read-only memory images (ROMs), and other terms. A particular application <b>127</b> may be executed as multiple instances of the applications <b>119</b> for multiple application sessions.</p>
<p id="p-0022" num="0021">The video encoders <b>129</b> correspond to the various types of video encoders <b>120</b> that may be employed in the computing device <b>103</b>. Some video encoders <b>129</b> may correspond to specific formats, such as, for example, H.264, MPEG-4, MPEG-2, and/or other formats. The wrappers <b>130</b> correspond to the executable code that implements the various types of wrappers <b>118</b>. The wrappers <b>130</b> are executable in the computing device <b>103</b> and may be executed as multiple instances of the wrappers <b>118</b> for multiple game sessions.</p>
<p id="p-0023" num="0022">The saved state data <b>133</b> corresponds to game states that have been saved by the applications <b>119</b>. Because the applications <b>119</b> are executed in a virtualized environment, the applications <b>119</b> may write state information to a virtual location, which is then mapped for storage in the data store <b>112</b> as the saved state data <b>133</b>. The saved state data <b>133</b> may correspond to data saved normally by the application <b>119</b> or may correspond to a memory image of the application <b>119</b> that may be resumed at any time. The user data <b>134</b> includes various data related to the users of the applications <b>119</b>, such as, for example, input command history for applications <b>119</b>, security credentials, application <b>119</b> preferences, billing information, a listing of other users that are permitted to join application sessions started by the user, and so on.</p>
<p id="p-0024" num="0023">The recorded media streams <b>135</b> correspond to a library of past media streams that have been recorded and stored in the data store <b>112</b>. In one embodiment, the recorded media streams <b>135</b> correspond to the data associated with portions of the media streams that are sent to clients <b>106</b>. In other embodiments, the recorded media streams <b>135</b> may be encoded using additional data reduction techniques, such as, for example, reducing the resolution of a video stream, encoding the parts of the media stream using a more aggressive data compression approach, and so on. In some embodiments, fingerprints that characterize the recorded media streams <b>135</b> may be stored along with the recorded media streams <b>135</b> for easy location and retrieval of relevant recorded media streams <b>135</b>.</p>
<p id="p-0025" num="0024">The annotations <b>136</b> correspond to annotations for the recorded media streams <b>135</b>. In one embodiment, the annotations <b>136</b> may include voiceovers by users to explain what is occurring in the recorded media streams <b>135</b>. In another embodiment, the annotations <b>136</b> may include textual descriptions to explain what is occurring in the recorded media streams <b>135</b>. In some embodiments, the annotations <b>136</b> may be provided in association with a media stream for a currently executing application <b>119</b> to provide helpful hints, tips, explanations, etc. to assist users in proceeding with the application <b>119</b>. Although annotations <b>136</b> may be provided by the user whose application <b>119</b> usage generated the recorded media stream <b>135</b>, annotations <b>136</b> may also be provided by other users as well.</p>
<p id="p-0026" num="0025">The ratings <b>137</b> include ratings and/or other feedback data regarding the recorded media streams <b>135</b> by users. There may be numerous recorded media streams <b>135</b> that depict a certain usage of an application <b>119</b>. Some of these recorded media streams <b>135</b> may depict better usage than others. For instance, where the application <b>119</b> is a game, one recorded media stream <b>135</b> may show poor game play of a level, while another recorded media stream <b>135</b> may show superior game play of the level. Although both recorded media streams <b>135</b> may depict completion of the same level, the one showing superior game play is likely to be preferred by users. To help distinguish among numerous recorded media streams <b>135</b>, ratings <b>137</b> from users may be collected that indicate user opinions regarding particular recorded media streams <b>135</b>. Accordingly, the recorded media streams <b>135</b> may be filtered according to the highest rating, ratings above a certain threshold, etc.</p>
<p id="p-0027" num="0026">The client <b>106</b> is representative of a plurality of client devices that may be coupled to the network <b>109</b>. The clients <b>106</b> may be geographically diverse. The client <b>106</b> may comprise, for example, a processor-based system such as a computer system. Such a computer system may be embodied in the form of a desktop computer, a laptop computer, personal digital assistants, cellular telephones, smartphones, set-top boxes, music players, web pads, tablet computer systems, game consoles, electronic book readers, or other devices with like capability.</p>
<p id="p-0028" num="0027">The client <b>106</b> may include a display <b>139</b>. The display <b>139</b> may comprise, for example, one or more devices such as cathode ray tubes (CRTs), liquid crystal display (LCD) screens, gas plasma-based flat panel displays, LCD projectors, or other types of display devices, etc. The client <b>106</b> may include one or more input devices <b>142</b>. The input devices <b>142</b> may comprise, for example, devices such as keyboards, mice, joysticks, accelerometers, light guns, game controllers, touch pads, touch sticks, push buttons, optical sensors, microphones, webcams, and/or any other devices that can provide user input. Additionally, various input devices <b>142</b> may incorporate haptic technologies in order to provide feedback to the user.</p>
<p id="p-0029" num="0028">The client <b>106</b> may be configured to execute various applications such as a client application <b>145</b> and/or other applications. The client application <b>145</b> is executed to allow a user to launch, join, play, or otherwise interact with an application <b>119</b> executed in the computing device <b>103</b>. To this end, the client application <b>145</b> is configured to capture input commands provided by the user through one or more of the input devices <b>142</b> and send this input over the network <b>109</b> to the computing device <b>103</b> as input data <b>122</b>.</p>
<p id="p-0030" num="0029">The client application <b>145</b> is also configured to obtain output data <b>123</b> over the network <b>109</b> from the computing device <b>103</b> and render a screen <b>148</b> on the display <b>139</b>. To this end, the client application <b>145</b> may include one or more video and audio players to play out a media stream generated by an application <b>119</b>. In one embodiment, the client application <b>145</b> comprises a plug-in within a browser application. The client <b>106</b> may be configured to execute applications beyond the client application <b>145</b> such as, for example, browser applications, email applications, instant message applications, and/or other applications.</p>
<p id="p-0031" num="0030">Next, a general description of the operation of the various components of the networked environment <b>100</b> is provided. To begin, a user at a client <b>106</b> sends a request to launch an application <b>119</b> to the server application <b>115</b>. The server application <b>115</b> obtains the corresponding application <b>127</b>, video encoder <b>129</b>, and wrapper <b>130</b> from the data store <b>112</b>. The server application <b>115</b> then launches the application <b>119</b> in the corresponding wrapper <b>118</b>. The server application <b>115</b> tracks the status of the application <b>119</b> within the application state information <b>124</b>.</p>
<p id="p-0032" num="0031">The wrapper <b>118</b> provides a virtualized environment for the application <b>119</b> that virtualizes one or more resources of the computing device <b>103</b>. Such resources may include exclusive resources, i.e., resources for which the application <b>119</b> requests exclusive access. For example, the application <b>119</b> may request full screen access from a video device, which is an exclusive resource because normally only one application can have full screen access. Furthermore, the wrapper may virtualize input devices such as, for example, keyboards, mice, etc. which may not actually be present in the computing device <b>103</b>. In various embodiments, the wrapper <b>118</b> may correspond to a virtual machine and/or the wrapper <b>118</b> may be executed within a virtual machine.</p>
<p id="p-0033" num="0032">The user at the client <b>106</b> enters input commands for the application <b>119</b> by use of the input devices <b>142</b> of the client <b>106</b>. As a non-limiting example, the user may depress a left mouse button. Accordingly, the client application <b>145</b> functions to encode the input command into a format that may be transmitted over the network <b>109</b> within the input data <b>122</b>. The server application <b>115</b> receives the input command and ultimately passes it to the wrapper <b>118</b>. The wrapper <b>118</b> then provides a left mouse button depression to the application <b>119</b> by way of a virtualized mouse.</p>
<p id="p-0034" num="0033">In some embodiments, different input commands may be presented to the application <b>119</b> from those that were generated by a client <b>106</b>. As a non-limiting example, if a user sends a mouse down command and the client application <b>145</b> loses focus, the wrapper <b>118</b> may be configured to send a mouse down command followed by a mouse up command. In various embodiments, the input commands may be relayed to the wrapper <b>118</b> as soon as possible, or the input commands may be queued by the wrapper <b>118</b> in an input queue and relayed to the application <b>119</b> sequentially from the queue according to another approach.</p>
<p id="p-0035" num="0034">Meanwhile, the graphical output of the application <b>119</b> is captured by the wrapper <b>118</b> and encoded into a media stream. Additionally, the audio output of the application <b>119</b> may be captured and multiplexed into the media stream. The media stream is transmitted by the server application <b>115</b> to the client <b>106</b> over the network <b>109</b> as the output data <b>123</b>. The client application <b>145</b> obtains the output data <b>123</b> and renders a screen <b>148</b> on the display <b>139</b>.</p>
<p id="p-0036" num="0035">Subsequently, other users may join the application <b>119</b> and participate like the first user. A user may start an application <b>119</b> at one client <b>106</b> and continue the application <b>119</b> at another client <b>106</b>. Furthermore, multiple users at diverse locations may participate in an application <b>119</b>. As a non-limiting example, an application <b>119</b> may have been developed to be executed in one device with multiple game controllers. Accordingly, the wrapper <b>118</b> may be configured to map input commands from one client <b>106</b> to a first virtual game controller and input commands from another client <b>106</b> to a second virtual game controller. As another non-limiting example, an application <b>119</b> may have been developed to be executed in one device, where one side of the keyboard controls the first player and the other side of the keyboard controls the second player. Accordingly, the wrapper <b>118</b> may be configured to map input commands from one client <b>106</b> to keys on one side of a virtual keyboard and input commands from another client <b>106</b> to keys on another side of the virtual keyboard.</p>
<p id="p-0037" num="0036">Various embodiments enable input generated through one type of input device <b>142</b> in a client <b>106</b> to be transformed by the wrapper <b>118</b> into input commands provided to the application <b>119</b> through an entirely different type of virtual input device. As a non-limiting example, input generated by an accelerometer in the client <b>106</b> may be translated by the wrapper <b>118</b> into input provided through a virtual mouse. Thus, completely different kinds of input devices <b>142</b> may be used in the application <b>119</b> that may not have been contemplated when the application <b>119</b> was implemented.</p>
<p id="p-0038" num="0037">Where the input devices <b>142</b> incorporate haptic technologies and devices, force feedback may be provided to the input devices <b>142</b> within the output data <b>123</b>. As a non-limiting example, a simulated automobile steering wheel may be programmed by force feedback to give the user a feel of the road. As a user makes a turn or accelerates, the steering wheel may resist the turn or slip out of control. As another non-limiting example, the temperature of the input device <b>142</b> may be configured to change according to force feedback. In one embodiment, force feedback generated from the input data <b>122</b> of one client <b>106</b> may be included in the output data <b>123</b> sent to another client <b>106</b>.</p>
<p id="p-0039" num="0038">Because the client <b>106</b> is decoupled from the hardware requirements of the application <b>119</b>, the application <b>119</b> may be used remotely through a diverse variety of clients <b>106</b> that are capable of streaming video with acceptable bandwidth and latency over a network <b>109</b>. For example, a game application <b>119</b> may be played on a client <b>106</b> that is a smartphone. Thus, the client <b>106</b> need not include expensive graphics hardware to perform the complex three-dimensional rendering that may be necessary to execute the application <b>119</b>. By contrast, the hardware of the computing device <b>103</b> may be upgraded, as needed, to meet the hardware requirements of the latest and most computationally intensive applications <b>119</b>. In various embodiments, the video signal in the media stream sent by the server application <b>115</b> may be scaled according to the bitrate and/or other characteristics of the connection between the computing device <b>103</b> and the client <b>106</b> over the network <b>109</b>.</p>
<p id="p-0040" num="0039">When a user is interacting with the application <b>119</b>, the user may become frustrated with completing specific tasks or meeting certain objectives of the application <b>119</b>. To this end, the user may enter an input command for help. In various embodiments, such a command may pause the execution of the application <b>119</b> and/or launch another user interface alongside the user interface of the application <b>119</b> as rendered in the client <b>106</b>. Alternatively, the user may enter a command that &#x201c;bookmarks&#x201d; the current application status for future reference in a help interface.</p>
<p id="p-0041" num="0040">In some cases, the user might not explicitly enter a command for help, but the server application <b>115</b> may automatically identify that the user is having difficulty. In one embodiment, the server application <b>115</b> examines the input command history for the user to determine if the user is stuck in the application <b>119</b>. As a non-limiting example, a user experiencing difficulty in a game may be repeatedly executing the same input commands to attempt to kill a &#x201c;boss&#x201d; in the game but be unsuccessful. As another non-limiting example, the user may be spending an excessive amount of time performing a task of the application <b>119</b>.</p>
<p id="p-0042" num="0041">Help may be provided to the user based on the experiences of other users when they have previously used the application <b>119</b>. Such help may be provided in the form of annotations <b>136</b> and/or walkthroughs in the application <b>119</b>. In various embodiments, a user interface may be provided for the user to select recorded content from a library that shows another user using the application <b>119</b> at or near the same point in the application <b>119</b>. The recorded content may include an input command history to show the user how to perform the moves, tasks, etc. depicted in the recorded content. In one embodiment, the user may be able to automatically provide input commands to the application <b>119</b> based on such an input command history in order to perform the moves, tasks, etc. As a non-limiting example, the recorded input commands may take control over the current game of a player in order to help the player get past a difficult checkpoint.</p>
<p id="p-0043" num="0042">In some cases, the recorded content may be identified from the recorded media streams <b>135</b> based on the graphical output of the application <b>119</b> by a fingerprinting technique that, for example, examines colors, contrast, etc. associated with the current video signal of the application <b>119</b> and compares them with the colors, contrast, etc. of portions of the recorded media streams <b>135</b> as represented in fingerprints stored with the recorded media streams <b>135</b>. In other words, with a positive fingerprint match, the backgrounds may be similar, the combinations of colors may be similar, and/or other quantifiable aspects of the recorded media streams <b>135</b> may be similar to the current video signal of the application <b>119</b>.</p>
<p id="p-0044" num="0043">Fingerprinting comparisons may also be done based on the audio signal generated by the application <b>119</b> and encoded audio signals in the recorded media streams <b>135</b>. For instance, a particular audio or music cue might uniquely identify a state in the application <b>119</b> that can be cross referenced with the recorded media streams <b>135</b>. Fingerprinting comparisons may also be performed based upon the order of input commands currently provided to the application <b>119</b> and the input command histories associated with the recorded media streams <b>135</b>.</p>
<p id="p-0045" num="0044">In addition to automated fingerprint identification of recorded media streams <b>135</b>, manual tagging may be employed. To illustrate, a user may be able to tag a current position in the media stream being generated by the application <b>119</b>. Such a tag may be used in indexing the portion of the media stream within the recorded media streams <b>135</b>. Other users may subsequently perform a search on the tags that describe the recorded media streams <b>135</b> in order to find recorded media streams <b>135</b> that are relevant.</p>
<p id="p-0046" num="0045">As a non-limiting example, the application <b>119</b> may correspond to a game such as Teenage Mutant Ninja Turtles&#xae; (TMNT) which was originally released by Konami Corporation as a coin-operated arcade game. For example, suppose that a user is playing the TMNT game at a client <b>106</b>, has selected the &#x201c;Donatello&#x201d; character, and is currently battling &#x201c;Bebop,&#x201d; the boss of stage <b>2</b>. The user may be getting repeatedly beaten up by &#x201c;Bebop&#x201d; and/or may be entering the same commands over and over. The server application <b>115</b> may then identify the user as having difficulty and then offer suggestions for help. Alternatively, the user may enter a hotkey to request help.</p>
<p id="p-0047" num="0046">In conjunction with the current game output, which may or may not be paused, a recorded video of another user as &#x201c;Donatello&#x201d; battling &#x201c;Bebop&#x201d; may be shown. The recorded video may be selected based on user-specified criteria, popularity, and/or appropriateness to the current position of the user in the TMNT game. The command sequences of the other user may also be shown. Accordingly, the user may watch the game play in the recorded video and learn the strategy for beating &#x201c;Bebop.&#x201d; In addition, a voiceover by the other user and/or textual help may be provided to describe what is going on in the recorded video.</p>
<p id="p-0048" num="0047">Various user interfaces (e.g., as shown in <figref idref="DRAWINGS">FIGS. 2 and 3</figref>) may be contemplated for selecting recorded media streams <b>135</b> and presenting them as recorded content in association with the real-time content generated from the application <b>119</b>. In the example of a game, a user may want to see a recorded media stream <b>135</b> based on achievements earned. An achievement corresponds to the completion of an objective that is not critical to completing the game, such as earning points, entering a hidden area, collecting gold coins, carrying a garden gnome from beginning to end in a game, etc.</p>
<p id="p-0049" num="0048">The assistance from other users may be provided also in the form of annotations <b>136</b> to the application <b>119</b>. Such annotations <b>136</b> may include voiceover explanations, written explanations, image explanations, etc. In various embodiments, the annotations <b>136</b> may be presented in connection with the recorded media stream <b>135</b> of the user who created the annotations <b>136</b>. In other embodiments, the annotations <b>136</b> may be presented while a user is using the application <b>119</b> at identifiable checkpoints. Various user interfaces may be contemplated for selecting and enabling the annotations <b>136</b>.</p>
<p id="p-0050" num="0049">In addition to providing help to users based on recorded media streams <b>135</b> and annotations <b>136</b>, the server application <b>115</b> may be configured to allow users to save their own recorded media streams <b>135</b> and create annotations <b>136</b>. To this end, the server application <b>115</b> may continuously record the real-time content media stream generated from the application <b>119</b> and allow users to select portions to be saved in the recorded media streams <b>135</b>. If space allows, the server application <b>115</b> may save all media streams automatically and later discard those that are not useful for other users. Alternatively, a user may issue start and stop commands to control when a media stream is being recorded and saved.</p>
<p id="p-0051" num="0050">Once a recorded media stream <b>135</b> is created, the server application <b>115</b> may allow the user to add metadata describing it. The server application <b>115</b> may also determine information regarding the recorded media stream <b>135</b> through an application programming interface (API) of the application <b>119</b> if available. Such information may include achievements earned, objectives completed, checkpoints passed, and so on. The user may also create and submit annotations <b>136</b> to be associated with the recorded media stream <b>135</b>. The user may specify certain checkpoints or times associated with the recorded media stream <b>135</b> at which certain annotations <b>136</b> are to be displayed. Further, the user may specify that visual annotations <b>136</b> be displayed in certain areas of the screen <b>148</b>.</p>
<p id="p-0052" num="0051">Turning now to <figref idref="DRAWINGS">FIG. 2</figref>, shown is one example of a user interface <b>200</b> rendered in the client <b>106</b> (<figref idref="DRAWINGS">FIG. 1</figref>) in the networked environment <b>100</b> (<figref idref="DRAWINGS">FIG. 1</figref>). Specifically, the user interface <b>200</b> shows a screen <b>148</b> (<figref idref="DRAWINGS">FIG. 1</figref>) associated with an application <b>119</b> (<figref idref="DRAWINGS">FIG. 1</figref>) that is a game. Although the example of a game is used in <figref idref="DRAWINGS">FIG. 2</figref>, it is understood that other types of applications <b>119</b> may be employed in embodiments of the present disclosure. The layout of the various elements of the user interface <b>200</b> as shown in <figref idref="DRAWINGS">FIG. 2</figref> is provided merely as an example and is not intended to be limiting.</p>
<p id="p-0053" num="0052">The top portion of the screen <b>148</b> shows a video stream <b>203</b> that is currently being generated from the application <b>119</b> by a video encoder <b>120</b> (<figref idref="DRAWINGS">FIG. 1</figref>). In the video stream <b>203</b>, the user at the client <b>106</b> is playing the game by moving a character around the world and sending other input commands to the application <b>119</b>. Rendered in association with the video stream <b>203</b> is an auxiliary video stream <b>206</b> that corresponds to a recorded media stream <b>135</b> (<figref idref="DRAWINGS">FIG. 1</figref>). The auxiliary video stream <b>206</b> shows past usage of the application <b>119</b> and, in particular, past game play of the game. The playback of the auxiliary video stream <b>206</b> may be controlled by way of a set of media controls <b>209</b>. It is noted that an auxiliary audio stream may also be played back in conjunction with the auxiliary video stream <b>206</b>.</p>
<p id="p-0054" num="0053">Descriptive text <b>212</b> may be provided to describe the auxiliary video stream <b>206</b>. In this example, the descriptive text <b>212</b> states &#x201c;Currently Viewing Completion of Level 3 by SpyMaster331.&#x201d; Thus, the descriptive text <b>212</b> may identify what is occurring in the auxiliary video stream <b>206</b> and the user who is controlling the application <b>119</b> as shown in the auxiliary video stream <b>206</b>. In other examples, the descriptive text <b>212</b> may provide textual help, tips, suggested command sequences, etc. to the user to complete objectives in the application <b>119</b>.</p>
<p id="p-0055" num="0054">Various options <b>215</b> may be provided to the user for controlling the auxiliary video stream <b>206</b>. Option <b>215</b><i>a </i>permits the user to view or browse other recorded sessions. To this end, another user interface may be loaded when option <b>215</b><i>a </i>is selected. Thumbnails and/or descriptions of various other recorded sessions may be shown to the user to facilitate a selection. Option <b>215</b><i>b </i>allows the user to maximize the current viewer. For example, selecting option <b>215</b><i>b </i>may permit the auxiliary video stream <b>206</b> to be resized larger to consume perhaps the entire screen <b>148</b> or the entire display <b>139</b> (<figref idref="DRAWINGS">FIG. 1</figref>). Option <b>215</b><i>c </i>allows the user to exit the recorded session viewer. When option <b>215</b><i>c </i>is selected, the video stream <b>203</b> may be maximized, and the user may return to playing the game instead of watching the auxiliary video stream <b>206</b>. It is understood that other types of options <b>215</b> may be provided, for example, to provide a rating <b>137</b> (<figref idref="DRAWINGS">FIG. 1</figref>) for the auxiliary video stream <b>206</b>, to enable or disable audio, to enable or disable textual help, and so on.</p>
<p id="p-0056" num="0055">Moving on to <figref idref="DRAWINGS">FIG. 3</figref>, shown is an example of a user interface <b>300</b> rendered in the client <b>106</b> (<figref idref="DRAWINGS">FIG. 1</figref>) in the networked environment <b>100</b> (<figref idref="DRAWINGS">FIG. 1</figref>). Specifically, the user interface <b>300</b> shows a screen <b>148</b> (<figref idref="DRAWINGS">FIG. 1</figref>) associated with an application <b>119</b> (<figref idref="DRAWINGS">FIG. 1</figref>) that is, in this example, a game. Although the example of a game is used in <figref idref="DRAWINGS">FIG. 3</figref>, it is understood that other types of applications <b>119</b> may be employed in embodiments of the present disclosure. The layout of the various elements of the user interface <b>300</b> as shown in <figref idref="DRAWINGS">FIG. 3</figref> is provided merely as an example and is not intended to be limiting.</p>
<p id="p-0057" num="0056">A title <b>303</b> of the user interface <b>300</b> describes the user interface as a &#x201c;Recorded Session Viewer for Spy Agent.&#x201d; The user interface <b>300</b> provides an interface for selecting various auxiliary media streams for presentation to the client <b>106</b>. In particular, the auxiliary media streams are related to the game &#x201c;Spy Agent.&#x201d; A search tool <b>306</b> is provided for a user to enter keywords for searching the various recorded media streams <b>135</b> (<figref idref="DRAWINGS">FIG. 1</figref>). The keywords may be matched against annotations <b>136</b> (<figref idref="DRAWINGS">FIG. 1</figref>), ratings <b>137</b> (<figref idref="DRAWINGS">FIG. 1</figref>), and/or other metadata that may be associated with recorded media streams <b>135</b>.</p>
<p id="p-0058" num="0057">Several thumbnails <b>309</b> are shown with representative images from the respective recorded media streams <b>135</b>. Descriptions <b>312</b> of the recorded media streams <b>135</b> are also provided in conjunction with the thumbnails <b>309</b>. The recorded media streams <b>135</b> that are initially highlighted in the user interface <b>300</b> may correspond to recorded media streams <b>135</b> that are superlative in various categories. For instance, the description <b>312</b><i>a </i>relates to a recorded media stream <b>135</b> that shows the &#x201c;Most Achievements&#x201d; for the game. The description <b>312</b><i>b </i>relates to a recorded media stream <b>135</b> that shows the &#x201c;Fastest Completion Time&#x201d; for the game. The description <b>312</b><i>c </i>relates to a recorded media stream <b>135</b> that shows the &#x201c;Highest Rated&#x201d; recorded media stream <b>135</b> for the game according to user ratings <b>137</b> for the game.</p>
<p id="p-0059" num="0058">Each of the descriptions <b>312</b> may include user interface components for launching the playback of the associated recorded media stream <b>135</b>, for example, as shown in <figref idref="DRAWINGS">FIG. 2</figref>. As a non-limiting example, a link is provided that is labeled &#x201c;View Recorded Session.&#x201d; Further, a link may be provided (&#x201c;See All&#x201d;) for a user to see other recorded media streams <b>135</b> in the particular category, e.g., most achievements, fastest completion time, highest rated, etc.</p>
<p id="p-0060" num="0059">Referring next to <figref idref="DRAWINGS">FIG. 4</figref>, shown is a flowchart that provides one example of the operation of a portion of the server application <b>115</b> according to various embodiments. It is understood that the flowchart of <figref idref="DRAWINGS">FIG. 4</figref> provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the server application <b>115</b> as described herein. As an alternative, the flowchart of <figref idref="DRAWINGS">FIG. 4</figref> may be viewed as depicting an example of steps of a method implemented in the computing device <b>103</b> (<figref idref="DRAWINGS">FIG. 1</figref>) according to one or more embodiments.</p>
<p id="p-0061" num="0060">Beginning with box <b>403</b>, the server application <b>115</b> obtains a request to launch an application <b>119</b> (<figref idref="DRAWINGS">FIG. 1</figref>) from a client <b>106</b> (<figref idref="DRAWINGS">FIG. 1</figref>). In box <b>406</b>, the server application <b>115</b> configures the video signal generated by the application <b>119</b> to be encoded by a video encoder <b>120</b> (<figref idref="DRAWINGS">FIG. 1</figref>) and to be sent to the client <b>106</b> as a media stream in the output data <b>123</b> (<figref idref="DRAWINGS">FIG. 1</figref>). In various embodiments, the media stream may include encoded audio signals generated by the application <b>119</b>, images, and/or other multimedia data. In box <b>409</b>, the server application <b>115</b> configures the application <b>119</b> to receive input commands from the client <b>106</b>. To this end, the input commands embodied in the input data <b>122</b> (<figref idref="DRAWINGS">FIG. 1</figref>) are configured to be provided to the application <b>119</b>.</p>
<p id="p-0062" num="0061">In box <b>412</b>, the application <b>119</b> is executed in the appropriate wrapper <b>118</b> (<figref idref="DRAWINGS">FIG. 1</figref>). The wrapper <b>118</b> provides a virtualized environment for execution of the application <b>119</b>. As such, the wrapper <b>118</b> virtualizes one or more input devices <b>142</b> (<figref idref="DRAWINGS">FIG. 1</figref>) and provides the input commands obtained from the client <b>106</b> to the application <b>119</b> by way of the virtualized input devices <b>142</b>.</p>
<p id="p-0063" num="0062">In box <b>415</b>, the server application <b>115</b> prepares a list of recorded sessions (i.e., recorded media streams <b>135</b> (<figref idref="DRAWINGS">FIG. 1</figref>)) that are relevant to the current application <b>119</b> and sends the list to the client <b>106</b>. For example, where the application <b>119</b> is a game, the list may include the recorded media streams <b>135</b> that show game play for the current level of the game. The current level, checkpoint, etc. may be determined with reference to the application state information <b>124</b> (<figref idref="DRAWINGS">FIG. 1</figref>). In one embodiment, frames from the video signal generated by the application <b>119</b> may be analyzed and compared with fingerprints of the recorded media streams <b>135</b> to determine the recorded media streams <b>135</b> that appear to show a similar usage for the application <b>119</b>.</p>
<p id="p-0064" num="0063">In box <b>418</b>, the server application <b>115</b> obtains a user selection of a recorded media stream <b>135</b> from the client <b>106</b>. Alternatively, the server application <b>115</b> may automatically determine a recorded media stream <b>135</b> that is most relevant to the current usage of the application <b>119</b>. For instance, the recorded media stream <b>135</b> from the list with the highest user rating may be selected. In box <b>421</b>, the selected recorded media stream <b>135</b> is sent to the client <b>106</b> for display in association with the current media stream of the application <b>119</b>. In one embodiment, the recorded media stream <b>135</b> is embedded within the current media stream of the application <b>119</b>. In another embodiment, the recorded media stream <b>135</b> is sent separately from the current media stream of the application <b>119</b>. As a non-limiting example, the recorded media stream <b>135</b> may be configured to be rendered in place of, adjacent to, overlaying, or otherwise in association with the current media stream of the application <b>119</b>. In another non-limiting example, the recorded media stream <b>135</b> is configured to be shown as a picture within a picture on the display <b>139</b>.</p>
<p id="p-0065" num="0064">In box <b>424</b>, the server application <b>115</b> determines whether the user at the client <b>106</b> is to provide a rating <b>137</b> (<figref idref="DRAWINGS">FIG. 1</figref>) for the recorded media stream <b>135</b>. If the user is to provide a rating <b>137</b>, the server application <b>115</b> proceeds to box <b>427</b> and obtains a rating <b>137</b> of the recorded media stream <b>135</b> from the client <b>106</b>. The server application <b>115</b> then associates the rating <b>137</b> with the particular recorded media stream <b>135</b>. As a non-limiting example, the user may click on a graphical icon showing a desired number of &#x201c;stars&#x201d; that are to be assigned to the recorded media stream <b>135</b> as a rating <b>137</b>. Further, the user may provide comments and/or other feedback as a rating <b>137</b>. The server application <b>115</b> then continues to box <b>430</b>. If the server application <b>115</b> determines in box <b>424</b> that no rating <b>137</b> is to be obtained, the server application <b>115</b> also proceeds to box <b>430</b>.</p>
<p id="p-0066" num="0065">Next, in box <b>430</b>, the server application <b>115</b> determines whether the current session (i.e., the media stream being generated from the application <b>119</b> and sent to the client <b>106</b>) is to be saved. If the current session is not to be saved, the portion of the server application <b>115</b> ends. Otherwise, if the current session is to be saved, the server application <b>115</b>, in box <b>433</b>, stores a portion of the media stream of the current session in the library of recorded media streams <b>135</b>. In one embodiment, the server application <b>115</b> may continuously store the media stream and then discard portions that are not later saved. A user interface may be provided for the user to select portions of the media stream to be saved. In another embodiment, the server application <b>115</b> may begin storing and saving the media stream only upon the command of a user.</p>
<p id="p-0067" num="0066">In box <b>436</b>, the server application <b>115</b> determines whether the session is to be annotated. If the session is not to be annotated, the portion of the server application <b>115</b> ends. Otherwise, if the session is to be annotated, the server application <b>115</b> proceeds to box <b>439</b> and obtains an annotation <b>136</b> (<figref idref="DRAWINGS">FIG. 1</figref>) from the client <b>106</b>. The annotation <b>136</b> is stored in the data store <b>112</b> (<figref idref="DRAWINGS">FIG. 1</figref>) and associated with the recorded media stream <b>135</b> generated from the session. It is understood that the annotation <b>136</b> may take many different forms, such as, for example, an audio voiceover, helpful text, and so on. In some embodiments, annotations <b>136</b> may also be presented to users in conjunction with a current media stream and not a recorded media stream <b>135</b>. Thereafter, the portion of the server application <b>115</b> ends.</p>
<p id="p-0068" num="0067">With reference to <figref idref="DRAWINGS">FIG. 5</figref>, shown is a schematic block diagram of the computing device <b>103</b> according to an embodiment of the present disclosure. The computing device <b>103</b> includes at least one processor circuit, for example, having a processor <b>503</b>, a memory <b>506</b>, and one or more graphics devices <b>507</b>, all of which are coupled to a local interface <b>509</b>. To this end, the computing device <b>103</b> may comprise, for example, at least one server computer or like device. The local interface <b>509</b> may comprise, for example, a data bus with an accompanying address/control bus or other bus structure as can be appreciated. The graphics devices <b>507</b> may correspond to high-performance graphics hardware, including one or more graphics processors <b>512</b>. The graphics devices <b>507</b> are configured to render graphics corresponding to the applications <b>119</b> executed in the computing device <b>103</b>.</p>
<p id="p-0069" num="0068">Stored in the memory <b>506</b> are both data and several components that are executable by the processor <b>503</b>. In particular, stored in the memory <b>506</b> and executable by the processor <b>503</b> are the server application <b>115</b>, the wrappers <b>118</b>, the applications <b>119</b>, the video encoders <b>120</b>, and potentially other applications. Also stored in the memory <b>506</b> may be a data store <b>112</b> and other data. In addition, an operating system may be stored in the memory <b>506</b> and executable by the processor <b>503</b>.</p>
<p id="p-0070" num="0069">It is understood that there may be other applications that are stored in the memory <b>506</b> and are executable by the processors <b>503</b> as can be appreciated. Where any component discussed herein is implemented in the form of software, any one of a number of programming languages may be employed such as, for example, C, C++, C#, Objective C, Java&#xae;, JavaScript&#xae;, Perl, PHP, Visual Basic&#xae;, Python&#xae;, Ruby, Delphi&#xae;, Flash&#xae;, or other programming languages.</p>
<p id="p-0071" num="0070">A number of software components are stored in the memory <b>506</b> and are executable by the processor <b>503</b>. In this respect, the term &#x201c;executable&#x201d; means a program file that is in a form that can ultimately be run by the processor <b>503</b>. Examples of executable programs may be, for example, a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory <b>506</b> and run by the processor <b>503</b>, source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory <b>506</b> and executed by the processor <b>503</b>, or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memory <b>506</b> to be executed by the processor <b>503</b>, etc. An executable program may be stored in any portion or component of the memory <b>506</b> including, for example, random access memory (RAM), read-only memory (ROM), hard drive, solid-state drive, USB flash drive, memory card, optical disc such as compact disc (CD) or digital versatile disc (DVD), floppy disk, magnetic tape, or other memory components.</p>
<p id="p-0072" num="0071">The memory <b>506</b> is defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus, the memory <b>506</b> may comprise, for example, random access memory (RAM), read-only memory (ROM), hard disk drives, solid-state drives, USB flash drives, memory cards accessed via a memory card reader, floppy disks accessed via an associated floppy disk drive, optical discs accessed via an optical disc drive, magnetic tapes accessed via an appropriate tape drive, and/or other memory components, or a combination of any two or more of these memory components. In addition, the RAM may comprise, for example, static random access memory (SRAM), dynamic random access memory (DRAM), or magnetic random access memory (MRAM) and other such devices. The ROM may comprise, for example, a programmable read-only memory (PROM), an erasable programmable read-only memory (EPROM), an electrically erasable programmable read-only memory (EEPROM), or other like memory device.</p>
<p id="p-0073" num="0072">Also, the processor <b>503</b> may represent multiple processors <b>503</b> and the memory <b>506</b> may represent multiple memories <b>506</b> that operate in parallel processing circuits, respectively. In such a case, the local interface <b>509</b> may be an appropriate network <b>109</b> (<figref idref="DRAWINGS">FIG. 1</figref>) that facilitates communication between any two of the multiple processors <b>503</b>, between any processor <b>503</b> and any of the memories <b>506</b>, or between any two of the memories <b>506</b>, etc. The local interface <b>509</b> may comprise additional systems designed to coordinate this communication, including, for example, performing load balancing. The processor <b>503</b> may be of electrical or of some other available construction.</p>
<p id="p-0074" num="0073">Although the server application <b>115</b>, the wrappers <b>118</b>, the applications <b>119</b>, the video encoders <b>120</b>, the client application <b>145</b> (<figref idref="DRAWINGS">FIG. 1</figref>), and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above, as an alternative the same may also be embodied in dedicated hardware or a combination of software/general purpose hardware and dedicated hardware. If embodied in dedicated hardware, each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include, but are not limited to, discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals, application specific integrated circuits having appropriate logic gates, or other components, etc. Such technologies are generally well known by those skilled in the art and, consequently, are not described in detail herein.</p>
<p id="p-0075" num="0074">The flowchart of <figref idref="DRAWINGS">FIG. 4</figref> shows the functionality and operation of an implementation of portions of the server application <b>115</b>. If embodied in software, each block may represent a module, segment, or portion of code that comprises program instructions to implement the specified logical function(s). The program instructions may be embodied in the form of source code that comprises human-readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor <b>503</b> in a computer system or other system. The machine code may be converted from the source code, etc. If embodied in hardware, each block may represent a circuit or a number of interconnected circuits to implement the specified logical function(s).</p>
<p id="p-0076" num="0075">Although the flowchart of <figref idref="DRAWINGS">FIG. 4</figref> shows a specific order of execution, it is understood that the order of execution may differ from that which is depicted. For example, the order of execution of two or more blocks may be scrambled relative to the order shown. Also, two or more blocks shown in succession in <figref idref="DRAWINGS">FIG. 4</figref> may be executed concurrently or with partial concurrence. Further, in some embodiments, one or more of the blocks shown in <figref idref="DRAWINGS">FIG. 4</figref> may be skipped or omitted. In addition, any number of counters, state variables, warning semaphores, or messages might be added to the logical flow described herein, for purposes of enhanced utility, accounting, performance measurement, or providing troubleshooting aids, etc. It is understood that all such variations are within the scope of the present disclosure.</p>
<p id="p-0077" num="0076">Also, any logic or application described herein, including the server application <b>115</b>, the wrappers <b>118</b>, the applications <b>119</b>, the video encoders <b>120</b>, and the client application <b>145</b>, that comprises software or code can be embodied in any non-transitory computer-readable medium for use by or in connection with an instruction execution system such as, for example, a processor <b>503</b> in a computer system or other system. In this sense, the logic may comprise, for example, statements including instructions and declarations that can be fetched from the computer-readable medium and executed by the instruction execution system. In the context of the present disclosure, a &#x201c;computer-readable medium&#x201d; can be any medium that can contain, store, or maintain the logic or application described herein for use by or in connection with the instruction execution system. The computer-readable medium can comprise any one of many physical media such as, for example, magnetic, optical, or semiconductor media. More specific examples of a suitable computer-readable medium would include, but are not limited to, magnetic tapes, magnetic floppy diskettes, magnetic hard drives, memory cards, solid-state drives, USB flash drives, or optical discs. Also, the computer-readable medium may be a random access memory (RAM) including, for example, static random access memory (SRAM) and dynamic random access memory (DRAM), or magnetic random access memory (MRAM). In addition, the computer-readable medium may be a read-only memory (ROM), a programmable read-only memory (PROM), an erasable programmable read-only memory (EPROM), an electrically erasable programmable read-only memory (EEPROM), or other type of memory device.</p>
<p id="p-0078" num="0077">It should be emphasized that the above-described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above-described embodiment(s) without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>Therefore, the following is claimed:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A non-transitory computer-readable medium embodying a program executable in a computing device, the program comprising:
<claim-text>code that executes a game application in a virtual environment in a cloud computing resource, the game application being selected from a library of game applications;</claim-text>
<claim-text>code that obtains a plurality of input commands from a client and provides the input commands to the game application through at least one virtual input device of the virtual environment;</claim-text>
<claim-text>code that obtains a video signal generated by the game application, encodes the video signal into a media stream, sends the media stream to the client, and records a portion of the media stream in a library of recorded media streams, an input command history associated with the portion of the media stream being recorded with the portion of the media stream, wherein the portion of the media stream is determined based at least in part on a checkpoint of the game application completed relative to the portion of the media stream;</claim-text>
<claim-text>code that obtains a selection by a user of a recorded media stream from the library of recorded media streams, the recorded media stream showing a past game play in the game application by another user; and</claim-text>
<claim-text>code that sends the recorded media stream to the client for rendering in the client in association with the media stream.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The non-transitory computer-readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the recorded media stream includes an annotation by the another user.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The non-transitory computer-readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the program further comprises code that obtains feedback from the user regarding the recorded media stream.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A system, comprising:
<claim-text>at least one computing device; and</claim-text>
<claim-text>a server application executable in the at least one computing device, the server application comprising:
<claim-text>logic that executes an application in a hosted environment in the at least one computing device;</claim-text>
<claim-text>logic that obtains a plurality of input commands from a client and provides the input commands to the application;</claim-text>
<claim-text>logic that obtains a video signal generated by the application, encodes the video signal into real-time content, and sends the real-time content to the client;</claim-text>
<claim-text>logic that records at least a portion of the real-time content and adds the at least a portion of the real-time content to a library of recorded content;</claim-text>
<claim-text>logic that selects recorded content from the library of recorded content based at least in part on at least one achievement completed in a past usage of the application shown in the recorded content, the past usage being previously recorded by the logic that records; and</claim-text>
</claim-text>
<claim-text>logic that sends the recorded content to the client.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the recorded content and the real-time content are sent together in a combined media stream to the client.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the real-time content is sent in a first media stream to the client, and the recorded content is sent in a second media stream to the client.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the recorded content is configured to be displayed in the client in association with the real-time content.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the recorded content is correlated with a current status of the application.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the recorded content includes an annotation provided by a user associated with the past usage presented in the recorded content.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the recorded content includes an annotation provided by a different user than a user associated with the past usage presented in the recorded content.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the server application further comprises logic that determines whether a user at the client is experiencing difficulty in the application, and the recorded content is sent to the client in response to determining that the user is experiencing difficulty in the application.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the logic that determines whether the user is experiencing difficulty in the application is configured to determine that the user is experiencing difficulty based at least in part on an input command history of the user.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the server application further comprises logic that selects the recorded content from the library of recorded content based at least in part on at least one user-specified criterion.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the at least a portion of the real-time content is added to the library in response to determining that the usage reflected in the at least a portion of the real-time content meets at least one criterion.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the server application further comprises logic that determines a subset of the library of recorded content that pertains to a current status of the application in response to obtaining a request from the client.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the logic that determines the subset of the library of recorded content is further configured to compare a fingerprint generated from the real-time content with a corresponding fingerprint associated with the recorded content.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the logic that determines the subset of the library of recorded content is further configured to perform a search against user-provided data that identifies recorded content in the library of recorded content.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the server application further comprises logic that facilitates a user selection of the recorded content from the library of recorded content.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the server application further comprises logic that collects user ratings regarding at least some of the recorded content in the library.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A system, comprising:
<claim-text>at least one computing device; and</claim-text>
<claim-text>a server application executable in the at least one computing device, the server application comprising:
<claim-text>logic that executes an application in a hosted environment in the at least one computing device;</claim-text>
<claim-text>logic that obtains a plurality of input commands from a client and provides the input commands to the application;</claim-text>
<claim-text>logic that obtains a video signal generated by the application, encodes the video signal into real-time content, and sends the real-time content to the client;</claim-text>
<claim-text>logic that records at least a portion of the real-time content and adds the at least a portion of the real-time content to a library of recorded content, wherein the at least a portion of the real-time content is determined based at least in part on a checkpoint of the application completed relative to the at least a portion of the real-time content; and</claim-text>
<claim-text>logic that sends recorded content from the library of recorded content to the client, wherein the recorded content presents a past usage of the application previously recorded by the logic that records.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the server application further comprises logic that selects the recorded content from the library of recorded content based at least in part on at least one achievement completed in the past usage shown in the recorded content.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. A method, comprising:
<claim-text>sending, in a client computing device, a plurality of input commands over a network to at least one computing device, wherein the input commands are to be provided to an application executed in a hosted environment in the at least one computing device; and</claim-text>
<claim-text>obtaining, in the client computing device, a media stream from the at least one computing device, the media stream presenting a current usage of the application, the media stream including recorded content that presents a past usage of the application, the recorded content being selected in the at least one computing device based at least in part on at least one achievement completed in the past usage shown in the recorded content.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the hosted environment comprises a virtualized environment.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising providing, in the client computing device, an annotation in conjunction with the media stream, wherein the annotation is based at least in part on the past usage of the application, and wherein the annotation includes a plurality of input commands obtained from the past usage of the application.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein at least some of the input commands are obtained from an input command history associated with the past usage of the application.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the application comprises a game application, the current usage corresponds to current game play, and the past usage corresponds to past game play.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the media stream encodes a video signal generated by the application.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the media stream includes a voiceover of a user whose past usage is presented in the recorded content.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising rendering, in the client computing device, a video signal of the recorded content on a display in association with a video signal in the media stream that is being generated by the application.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising rendering, in the client computing device, a user interface for selecting the recorded content from a library of recorded content.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising sending, in the client computing device, a request for a list of recorded content that is relevant to a current position in the application. </claim-text>
</claim>
</claims>
</us-patent-grant>
