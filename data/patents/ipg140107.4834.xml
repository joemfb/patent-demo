<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625927-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625927</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13283230</doc-number>
<date>20111027</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>132</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>64</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382278</main-classification>
</classification-national>
<invention-title id="d2e53">Image processing using image web</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6018592</doc-number>
<kind>A</kind>
<name>Shinagawa et al.</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6263088</doc-number>
<kind>B1</kind>
<name>Crabtree et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6347152</doc-number>
<kind>B1</kind>
<name>Shinagawa et al.</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6987520</doc-number>
<kind>B2</kind>
<name>Criminisi et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7088870</doc-number>
<kind>B2</kind>
<name>Perez et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7336851</doc-number>
<kind>B1</kind>
<name>Cote</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7760912</doc-number>
<kind>B2</kind>
<name>Dana et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7773099</doc-number>
<kind>B2</kind>
<name>Forlines et al.</name>
<date>20100800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7826683</doc-number>
<kind>B2</kind>
<name>Phillips</name>
<date>20101100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>8139850</doc-number>
<kind>B2</kind>
<name>Maxwell et al.</name>
<date>20120300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>8139867</doc-number>
<kind>B2</kind>
<name>Maxwell et al.</name>
<date>20120300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>8285055</doc-number>
<kind>B1</kind>
<name>Barnes et al.</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382195</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2003/0099406</doc-number>
<kind>A1</kind>
<name>Georgiev et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2004/0164996</doc-number>
<kind>A1</kind>
<name>Criminisi et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2005/0053131</doc-number>
<kind>A1</kind>
<name>Domke et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524001</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2005/0128210</doc-number>
<kind>A1</kind>
<name>Berger</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2005/0128211</doc-number>
<kind>A1</kind>
<name>Berger et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2005/0220348</doc-number>
<kind>A1</kind>
<name>Chiu et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2006/0120624</doc-number>
<kind>A1</kind>
<name>Jojic et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2006/0284874</doc-number>
<kind>A1</kind>
<name>Wilson</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2006/0285762</doc-number>
<kind>A1</kind>
<name>Sun et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2007/0025637</doc-number>
<kind>A1</kind>
<name>Setlur et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2008/0112642</doc-number>
<kind>A1</kind>
<name>Matsushita et al.</name>
<date>20080500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2008/0238942</doc-number>
<kind>A1</kind>
<name>Sun et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2008/0238945</doc-number>
<kind>A1</kind>
<name>Wakizaka</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2008/0292162</doc-number>
<kind>A1</kind>
<name>Gering et al.</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2009/0141992</doc-number>
<kind>A1</kind>
<name>Coulombe et al.</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2009/0180713</doc-number>
<kind>A1</kind>
<name>Bucha et al.</name>
<date>20090700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2010/0183242</doc-number>
<kind>A1</kind>
<name>Brand</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2010/0287511</doc-number>
<kind>A1</kind>
<name>Meier et al.</name>
<date>20101100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2010/0289817</doc-number>
<kind>A1</kind>
<name>Meier et al.</name>
<date>20101100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2010/0328352</doc-number>
<kind>A1</kind>
<name>Shamir et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2011/0182502</doc-number>
<kind>A1</kind>
<name>Liang</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Connelly Barnes, Eli Shechtman, Adam Finkelstein, and Dan B Goldman. 2009. PatchMatch: a randomized correspondence algorithm for structural image editing. ACM Trans. Graph. 28, 3, Article 24 (Jul. 2009).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Kokaram, Anil C., J. A. Stark, and William J. Fitzgerald. &#x201c;Enhancement and restoration of ancient manuscripts.&#x201d; Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series. vol. 1771. 1993.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>&#x2018;Web-Archive&#x2019; [online] &#x201c;Creative Commons,&#x201d; 2010, [retrieved on Jan. 26, 2012]. Retrieved from Internet: &#x3c;URL: http://web.archive.org/web/20100130095204/http:/creativecommons.org/&#x3e; . 3 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>&#x2018;Wikipedia&#x2019; [online] &#x201c;Java (programming language),&#x201d; 2002, [retrieved on Jan. 27, 2012]. Retrieved from the Internet: &#x3c;URL: http://en.wikipedia.org/w/index.php?title=Java<sub>&#x2014;</sub>(programming<sub>&#x2014;</sub>language)&#x26;oldid-550214&#x3e;. 7 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>&#x2018;Wikipedia&#x2019; [online]. &#x201c;OpenGL,&#x201d; Dec. 2004, [retrieved on Jan. 27, 2012]. Retrieved from the Internet: &#x3c;URL:http://en.wikipedia.org/w/index.php?title=OpenGL&#x26;oldid=9281664&#x3e;, 3 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>&#x201c;AutoCollage&#x201d; [online]. Microsoft Research 2008, [retrieved on Nov. 26, 2008]. Retrieved from he Internet: &#x3c;URL: http://research.microsoft.com/autocollage/&#x3e;.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>Agarwala, A., Dontcheva, M., Agrawala, M., Drucker, S., Colburn, A., Curless, B., Salesin, D., and Cohen, M., &#x201c;Interactive digital photomontage&#x201d;, <i>ACM Trans. Graph</i>. 23, 3, pp. 294-302, dated 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>Arya, S., Mount, D., Netanyahu, N., Silverman, R., and Wu, A., &#x201c;An optimal algorithm for approximate nearest neighbor searching in fixed dimensions&#x201d;, in <i>Proc. Fifth Symp. Discrete Algorithms </i>(<i>SODA</i>), pp. 573-582, dated 1994.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00042">
<othercit>Ashikhmin, M., &#x201c;Synthesizing natural textures&#x201d;, in <i>I3D '01 Proceedings of the 2001 symposium on Interactive 3D graphics</i>, ACM, New York, NY, USA, pp. 217-226, dated 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>Avidan, S., and Shamir, A., &#x201c;Seam carving for content-aware image resizing&#x201d;, in <i>ACM Trans. Graph</i>. 26, 3, 10, dated 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00044">
<othercit>Barnes, Connelly, Shechtman, Eli, Finkelstein, Adam and Goldman, Dan B., &#x201c;A Randomized Algorithm for Nearest Neighbor Fields&#x201d;, dated Sep. 8, 2008, p. 1-5.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00045">
<othercit>Barnes, et al., &#x201c;Supplementary Material for the Generalized PatchMatch Correspondence Algorithm&#x201d;, Downloaded from the internet at http://www.cs.princeton.edu/gfx/pubs/Barnes<sub>&#x2014;</sub>2010<sub>&#x2014;</sub>TGP/index.php Correspondence on Sep. 9, 2010, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00046">
<othercit>Barnes, et al., &#x201c;The Generalized PatchMatch Correspondence Algorithm&#x201d;, Downloaded from the internet at http://www.cs.princeton.edu/gfx/pubs/Barnes<sub>&#x2014;</sub>2010<sub>&#x2014;</sub>TGP/index.php on Sep. 9, 2010, 14 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>Bertalmio, M., Sapiro,G., Caselles, V., and Ballester, C., &#x201c;Image inpainting&#x201d;, in <i>SIGGRAPH </i>'00: <i>Proceedings of the 27</i><sup>th </sup><i>annual conference on computer graphics and interactive techniques</i>, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, pp. 417-424, dated 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>Boiman et al. &#x201c;In Defense of Nearest-Neighbor Based Image Classification.&#x201d; Academic Paper, The Weizmann Institute of Science, Jun. 2008, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>Bourdev and Brandt, &#x201c;Robust Object Detection Via Soft Cascade&#x201d; in <i>Proceedings from CVPR 2005, IEEE Computer Society</i>, pp. 2236-2243.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00050">
<othercit>Boykov, Y., Veksler, O., and Zabih, R., &#x201c;Fast approximate energy minimization via graph cuts&#x201d;, in <i>Pattern Analysis and Machine Intelligence, IEEE Transactions on </i>23, 11 (Nov.), pp. 1222-1239, dated 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>Buades, A., Coll, B., and Morel, J.M. 2005. A non-local algorithm for image denoising. In <i>Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on</i>, vol. 2, 60-65 vol. 2.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00052">
<othercit>Chen et al. &#x201c;Sketch2Photo: Internet Image Montage.&#x201d; ACM Transactions on Graphics (TOG)&#x2014;Proceedings of ACM SIGGRAPH Asia 2009, Dec. 2009, 10 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00053">
<othercit>Cho, T. S., Butman, M., Avidan, S., and Freeman, W., &#x201c;The patch transform and its applications to image editing&#x201d;, in <i>Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on </i>(<i>June</i>), pp. 1-8, dated 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>Criminisi, A., Perez, P., and Toyama, K. 2003. Object removal by exemplar-based inpainting. <i>Computer Vision and Pattern Recognition IEEE, Computer Society Conference on </i>2, 721.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>Criminisi, A., Perez, P., and Toyama, K., &#x201c;Region filling and object removal by exemplar-based image inpainting&#x201d;, in <i>IEEE Trans. Image Processing 13</i>, 9 (<i>September</i>),p. 1200-1212, dated 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00056">
<othercit>Dale et al. &#x201c;Image Restoration using Online Photo Collections.&#x201d; Proc. IEEE Conference on Computer Vision, Sep. 2009, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00057">
<othercit>Datar, Immorlica, Indyk, and Mirrokni, &#x201c;Locality-sensitive hashing scheme based on p-stable distributions&#x201d;, in <i>COMPGEOM: Annual ACM Symposium on Computational Geometry</i>, dated 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00058">
<othercit>Drori, I., Cohen-or, D., and Yeshurun, H., 2003. Fragment-based image completion. <i>ACM Transactions on Graphics </i>22, 303-312.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00059">
<othercit>Efros, A. A., and Freeman, W.T., &#x201c;Image quilting for texture synthesis and transfer&#x201d;, in <i>SIGGRAPH 2001, Computer Graphics Proceedings</i>, ACM Press/ACM SIGGRAPH, E. Fiume, Ed., pp. 341-346, dated 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00060">
<othercit>Efros, A. A., and Leung, T. K., &#x201c;Texture synthesis by non-parametric sampling&#x201d;, in <i>Computer Vision, IEEE International Conference on 2</i>, p. 1033, dated 1999.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00061">
<othercit>Eisemann et al. &#x201c;Photo Zoom: High Resolution from Unordered Image Collections.&#x201d; SIGGRAPH 2010, Los Angeles, California, May 2010, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00062">
<othercit>Fischler, M.A., and Bolles, R.C., 1981. Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. <i>Commun. ACM </i>24, 6, 381-395.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00063">
<othercit>Fitzgibbon, A., Wexler, Y., and Zisserman, A., 2003. Image-based rendering using image-based priors. In ICCV '03: <i>Proceedings of the Ninth IEEE International Conference on Computer Vision</i>, IEEE Computer Society, Washington, DC, USA 1176.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00064">
<othercit>Freeman, W. T., Pasztor, E. C., and Y, O. T. C., &#x201c;Learning low-level vision&#x201d;, in <i>International Journal of Computer Vision 40</i>, dated 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00065">
<othercit>Freeman, W., Jones, T., and Pasztor, E. 2002. Example-based super-resolution. <i>Computer Graphics and Applications, IEEE </i>22, 2(Mar./Apr.) 56-65.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00066">
<othercit>HaCohen et al. &#x201c;Image Upsampling via Texture Hallucination.&#x201d; IEEE International Conference on Computational Photography, Mar. 2010, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00067">
<othercit>Han et al. &#x201c;Multiscale Texture Synthesis.&#x201d; <i>ACM Transactions on Graphics</i>, vol. 27, No. 3, Aug. 2008, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00068">
<othercit>Hays and Efros. &#x201c;Scene Completion Using Millions of Photographs.&#x201d; SIGGRAPH 2007, San Diego, California, Aug. 2007, 7 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00069">
<othercit>Hertzmann, A., Jacobs, C. E., Oliver, N., Curless, B., and Salesin, D., &#x201c;Image analogies&#x201d;, in <i>SIGGRAPH</i>, pp. 327-340, dated 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00070">
<othercit>Johnson et al. &#x201c;CG2Real: Improving the Realism of Computer Generated Images Using a Large Collection of Photographs.&#x201d; <i>IEEE Transactions on Visualization and Computer Graphics</i>, vol. 17, No. 6, Sep. 2011, 13 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00071">
<othercit>Kaneva et al. &#x201c;Infinite Images: Creating and Exploring a Large Photorealistic Virtual Space.&#x201d; <i>Proceeding of the IEEE</i>, vol. 98, No. 8, Aug. 2010, 17 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00072">
<othercit>Kirkpatrick et al. &#x201c;Optimization by Simulated Annealing.&#x201d; <i>Science</i>, vol. 220, No. 4598, May 1983, 10 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00073">
<othercit>Komodakis, N., and Tziritas, G. 2007, Image completion using efficient belief propagation via priority scheduling and dynamic pruning. <i>IEEE Transactions on Image Processing </i>16, 11, 2649-2661.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00074">
<othercit>Kopf, J., Fu, C.-W., Cohen-Or, D., Deussen, O., Lischinski, D., and Wong, T.-T. 2007. Solid texture synthesis from 2d exemplars. <i>ACM Transactions on Graphics </i>(<i>Proceedings of SIGGRAPH 2007</i>) 26, 3, 2:1-2:9.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00075">
<othercit>Kumar, N., Zhang, L., and Nayar, S.K., &#x201c;What is a good nearest neighbors algorithm for finding similar patches in images?&#x201d;, in <i>European Conference on Computer Vision, II</i>: pp. 364-378, dated 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00076">
<othercit>Kwatra V., Schdl, A., Essa, I., Turk, G., and Bobick, A., &#x201c;Graphcut textures: Image and video synthesis using graph cuts&#x201d;, in <i>ACM Transactions on Graphics, SIGGRAPH 2003 </i>22, 3 (July), pp. 277-286, dated 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00077">
<othercit>Kwatra, V., Essa, I., Bobick, A., Kwatra N., &#x201c;Texture optimization for example-based synthesis&#x201d;, in <i>ACM Trans. Graph</i>., 24(3): pp. 795-802, dated 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00078">
<othercit>Lefebvre, S., and Hoppe, H., &#x201c;Parallel controllable texture synthesis&#x201d;, in <i>ACM Trans. Graph </i>24, 3, pp. 777-786, dated 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00079">
<othercit>Liang, L., Liu, C., Xu, Y.-Q., Guo, B., and Shum, H.-Y., &#x201c;Real-time texture synthesis by patch-based sampling&#x201d; in <i>ACM Trans. Graph</i>. 20, 3, pp. 127-150, dated 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00080">
<othercit>Lin, et al. &#x201c;Random Forests and Adaptive Nearest Neighbors&#x201d;, Technical Report No. 1055, Downloaded from the internet on Sep. 7, 2010 at www.stat.wise.edu/Department/techreports/tr1081.pdf; May 29, 2002, 31 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00081">
<othercit>Liu et al. &#x201c;Face Hallucination: Theory and Practice.&#x201d; <i>International Journal of Computer Vision </i>(<i>IJCV</i>), vol. 75, No. 1, Oct. 2007, 33 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00082">
<othercit>Liu, F., and Gleicher, M., &#x201c;Automatic image retargeting with fisheye-view warping&#x201d;, in <i>UIST, ACM, P. Baudisch, M. Czerwinski and D.R. Olsen, Eds</i>., pp. 153-162, dated 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00083">
<othercit>Liu, X., Mei, T., Hua, X.-S., Yang, B., and Zhou, H.-Q., &#x201c;Video Collage&#x201d;, in <i>MM</i>'07, pp. 461-462, dated 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00084">
<othercit>Lowe, D.G. &#x201c;Object Recognition from Local Scale-Invariant Features.&#x201d; Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference, Kerkyra, Greece, Sep. 1999, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00085">
<othercit>Mikolajczyk, K., and Matas, J. G., &#x201c;Improving descriptors for fast tree matching by optimal linear projection&#x201d;, in <i>International Conference on Computer Vision</i>, pp. 1-8, dated 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00086">
<othercit>Miranda et al. &#x201c;New Routes from Minimal Approximation Error to Principal Components.&#x201d; <i>Neural Processing Letters</i>, vol. 27, No. 3, Jun. 2008, 14 pages. .</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00087">
<othercit>Mount, D.M. and Arya, S. &#x201c;ANN: A library for approximate nearest neighbor searching&#x201d;, dated Oct. 28, 1997.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00088">
<othercit>Pandey et al. &#x201c;Nearest-Neighbor Caching for Content-Match Applications.&#x201d; International World Wide Web Conference Committee (IW3C2), Madrid, Spain, Apr. 2009, 10 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00089">
<othercit>Pavic, D., Schonefeld, V., and Kobbelt, L. 2006. Interactive image completion with perspective correction. <i>The Visual Computer </i>22 (Sep.), 671-681(11).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00090">
<othercit>Peterson, J. L. &#x201c;Computer Programs for Detecting and Correcting Spelling Errors.&#x201d; <i>Computing Practices: Communications of the ACM</i>, vol. 23, No. 12, Dec. 1980, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00091">
<othercit>Rong, G., and Tan, T.-S., &#x201c;Jump flooding in gpu with applications to voronoi diagram and distance transform&#x201d;, in <i>I3D '06: Proceedings of the 2006 symposium on Interactive 3D graphics and games</i>, ACM, New York, NY, USA, pp. 109-116, dated 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00092">
<othercit>Rother, C., Bordeaux, L., Hamadi, Y., and Blake, A., &#x201c;Autocollage&#x201d;, in <i>ACM Trans. Graph </i>25, 3, pp. 847-852, dated 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00093">
<othercit>Rother, C., Kumar, S., Kolmogorov, V., and Blake, A., &#x201c;Digital tapestry&#x201d;, in <i>IEEE Computer Vision and Pattern Recognition or CVPR, I</i>, pp. 589-596, dated 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00094">
<othercit>Rubinstein, M., Shamir, A., and Avidan, S., &#x201c;Improved seam carving for video retargeting&#x201d;, in <i>ACM Transactions on Graphics </i>(<i>SIGGRAPH</i>) 27, 3, dated 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00095">
<othercit>Setlur, V., Takagi, S., Raskar, R., Gleicher, M., and Gooch, B., &#x201c;Automatic image retargeting&#x201d;, in <i>MUM, ACM, M. Billinghurst, Ed., vol. 154 of ACM International Conference Proceeding Series</i>, pp. 59-68, dated 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00096">
<othercit>Shiratori, T., Matsushita, Y., Tang, X., and Kang, S. B., &#x201c;Video completion by motion field transfer&#x201d;, in <i>Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on 1 </i>(<i>Jun.</i>), pp. 411-418, dated Jun. 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00097">
<othercit>Simakov, D., Caspi, Y., Shechtman E., and Irani, M., &#x201c;Summarizing visual data using bidirectional similarity&#x201d;, in <i>Proc. IEEE Conference on Computer Vision and Pattern Recognition </i>(<i>CVPR</i>), pp. 1-8, dated 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00098">
<othercit>Snavely et al. &#x201c;Photo Tourism: Exploring Photo Collections in 3D.&#x201d; <i>ACM Transactions on Graphics </i>(<i>SIGGRAPH Proceedings</i>), vol. 25, No. 3, Jul. 2006, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00099">
<othercit>Sun, J., Yuan, L., Jia, J., and Shum, H.-Y. 2005. Image completion with structure propagation. In <i>SIGGRAPH '05:ACM SIGGRAPH 2005 Papers</i>, ACM, New York, NY, USA 861-868.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00100">
<othercit>Tong, X., Zhang, J., Liu, L., Wang, X., Guo, B., and Shum, H.-Y., &#x201c;Synthesis of bidirectional texture functions on arbitrary surfaces&#x201d;, in <i>ACM Transactions on Graphics 21</i>, 3 (<i>Jul.</i>), pp. 665-672, dated Jul. 2002.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00101">
<othercit>Tourapis, A. M., &#x201c;Enhanced predictive zonal search for single and multiple frame motion estimation&#x201d;, in <i>VCIP, SPIE, C. C. J. Kuo, Ed., vol. 4671 of Proceedings of SPIE</i>, pp. 1069-1079, dated 2002.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00102">
<othercit>Wang et al. &#x201c;Factoring Repeated Content Within and Among Images.&#x201d; <i>ACM Trans. on Graphics </i>(<i>SIGGRAPH</i>), vol. 27, No. 3, Aug. 2008, 10 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00103">
<othercit>Wang, T., Mei, T., Hua, X.&#x2014;S., Liu, X., and Zhou, H.-Q., &#x201c;Video collage: A novel presentation of video sequence&#x201d;, in <i>ICME, IEEE</i>, pp. 1479-1482, dated 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00104">
<othercit>Wang, Y.-S., Tai, C.-L., Sorkine, O., and Lee, T.-Y. 2008. Optimized scale-and-stretch for image resizing. In <i>siggraph asia '08: ACM SIGGRAPH Asia 2008 papers</i>, ACM, New York, NY, USA, 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00105">
<othercit>Webb, A. R. &#x201c;Chapter 6. Nonlinear Discriminant Analysis&#x2014;Projection Methods.&#x201d; <i>Statistical Pattern Recognition</i>, Jul. 2009, 22 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00106">
<othercit>Wei, L. Y., and Levoy, M., &#x201c;Fast texture synthesis using tree-structured vector quantization&#x201d;, in <i>SIGGraph-00</i>, pp. 479-488, dated 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00107">
<othercit>Wei, L.-Y., Han, J., Zhou, K., Bao, H., Guo, B., and Shum, H.-Y., &#x201c;Inverse texture synthesis&#x201d;, in <i>ACM Trans. Graph 27</i>, 3, pp. 1-9, dated 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00108">
<othercit>Wexler, Y., Shechtman, E., and Irani, M., &#x201c;Space-time completion of video&#x201d;, in <i>IEEE Trans. Pattern Analysis and Machine Intelligence 29</i>, 3, (<i>Mar.</i>), pp. 463-476, dated Mar. 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00109">
<othercit>Wexler, Y., Shechtman, E., and Irani, M., &#x201c;Space-time video completion&#x201d;, in <i>Computer Vision and Pattern Recognition, IEEE Computer Society Conference on 1</i>, pp. 120-127, dated 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00110">
<othercit>Wolf, L., Guttmann, M., and Cohen-Or, D., 2007. Non-homogeneous content-driven video-retargeting. In <i>Proceedings of the Eleventh IEEE International Conference on Computer Vision </i>(<i>ICCV-07</i>).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00111">
<othercit>Yianilos, P.N., &#x201c;Data structures and algorithms for nearest neighbor search in general metric spaces&#x201d;, in <i>SODA</i>, pp. 311-321, dated 1993.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00112">
<othercit>Baker, S. and Kanade, T. &#x201c;Limits on Super-Resolution and How to Break Them.&#x201d; <i>IEEE Transactions on Pattern Analysis and Machine Intelligience</i>, vol. 24, No. 9, Sep. 2002, 36 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00113">
<othercit>Bay et al. &#x201c;SURF; Speeded Up Robust Features.&#x201d; <i>Computer Vision and Image Understanding </i>(<i>CVIU</i>), vol. 110, No. 3, 2008, 14 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00114">
<othercit>Chang et al. &#x201c;Super-Resolution Through Neighbor Embedding.&#x201d; <i>Computer Vision and Pattern Recognition, 2004, CVPR 2004, Proceedings of the 2004 IEEE Computer Society Conference</i>, Jul. 2004, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00115">
<othercit>&#x2018;phpFlickr&#x2019; [online] &#x201c;phpFlickr version 3.1,&#x201d; Jan. 2011, [retrieved on Jan. 26, 2012]. Retrieved from the Internet: &#x3c;URL: http://phpflickr.com/&#x3e;. 4 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>21</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61408326</doc-number>
<date>20101029</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61407306</doc-number>
<date>20101027</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130163884</doc-number>
<kind>A1</kind>
<date>20130627</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Shechtman</last-name>
<first-name>Elya</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Goldman</last-name>
<first-name>Dan</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Finkelstein</last-name>
<first-name>Adam</first-name>
<address>
<city>Princeton</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Barnes</last-name>
<first-name>Connelly</first-name>
<address>
<city>Corvallis</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lewellen</last-name>
<first-name>Jacob</first-name>
<address>
<city>Bellevue</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Shechtman</last-name>
<first-name>Elya</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Goldman</last-name>
<first-name>Dan</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Finkelstein</last-name>
<first-name>Adam</first-name>
<address>
<city>Princeton</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Barnes</last-name>
<first-name>Connelly</first-name>
<address>
<city>Corvallis</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Lewellen</last-name>
<first-name>Jacob</first-name>
<address>
<city>Bellevue</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Wolfe-SBMC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Adobe Systems Incorporated</orgname>
<role>02</role>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Patel</last-name>
<first-name>Nirav G</first-name>
<department>2665</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A computer-implemented method for determining correspondence between images includes: receiving images in a computer system; performing iterations using the computer system to find respective mappings for each patch of pixels in the images to a patch in another one of the images such that the mappings have minimal patch distance, the iterations including at least: (i) evaluation of a nearby-pixel mapping in a current image, (ii) evaluation of a randomly selected mapping in the current image, and (iii) evaluation of a randomly selected mapping in another one of the images; and generating a mapping record that results from the iterations.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="113.62mm" wi="178.65mm" file="US08625927-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="245.45mm" wi="184.66mm" file="US08625927-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="254.08mm" wi="161.21mm" file="US08625927-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="245.45mm" wi="195.16mm" file="US08625927-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="240.20mm" wi="189.91mm" orientation="landscape" file="US08625927-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="135.38mm" wi="189.91mm" file="US08625927-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims priority from Provisional Application Ser. No. 61/408,326 filed Oct. 29, 2010, and entitled &#x201c;PatchWeb: An Extension of PatchMatch,&#x201d; and from Provisional Application Ser. No. 61/407,306 filed Oct. 27, 2010, and entitled &#x201c;PatchWeb: An Extension of PatchMatch,&#x201d; the contents of both of which are incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">This specification relates to image processing using an image web.</p>
<p id="p-0004" num="0003">Image likeness, such as a correspondence between regions of one or more images, can be defined in many different implementations that depend on such correspondences. For example, this can include algorithms for correspondence in computer vision, such as wide baseline stereo matching and motion tracking, and graphics algorithms for image summarization, image completion, synthesizing textures, images and video, and others.</p>
<p id="p-0005" num="0004">For example, a similarity score between images can be computed by a bidirectional similarity metric, which measures the distance from each patch in one image to the other image, and vice versa. A bidirectional similarity can be evaluated based on a patch distance metric. A bidirectional similarity computation can involve calculating nearest neighbor patches, which can be computationally demanding. Even with available approximation techniques, the bidirectional similarity calculation may not be quick enough for use in interactive applications for very large images. Moreover, approximation techniques may not be useable with certain distance metrics.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0006" num="0005">The invention relates to image processing using an image web.</p>
<p id="p-0007" num="0006">In a first aspect, a computer-implemented method for determining correspondence between images includes: receiving images in a computer system; performing iterations using the computer system to find respective mappings for each patch of pixels in the images to a patch in another one of the images such that the mappings have minimal patch distance, the iterations including at least: (i) evaluation of a nearby-pixel mapping in a current image, (ii) evaluation of a randomly selected mapping in the current image, and (iii) evaluation of a randomly selected mapping in another one of the images; and generating a mapping record that results from the iterations.</p>
<p id="p-0008" num="0007">In a second aspect, a computer program product is tangibly embodied in a non-transitory storage device and includes instructions that when executed by a processor perform a method comprising: receiving images in a computer system; performing iterations using the computer system to find respective mappings for each patch of pixels in the images to a patch in another one of the images such that the mappings have minimal patch distance, the iterations including at least: (i) evaluation of a nearby-pixel mapping in a current target image, and (ii) evaluation of a randomly selected mapping in another one of the images; and generating a mapping record that results from the iterations.</p>
<p id="p-0009" num="0008">In a third aspect, a system includes: a repository of images; and an image processing component that performs iterations to find respective mappings for each patch of pixels in the images to a patch in another one of the images such that the mappings have minimal patch distance, the iterations including at least: (i) evaluation of a nearby-pixel mapping in a current image, (ii) evaluation of a randomly selected mapping in the current image, and (iii) evaluation of a randomly selected mapping in another one of the images. The image processing component generates a mapping record based on the iterations.</p>
<p id="p-0010" num="0009">Implementations can include any or all of the following features. A first patch is currently mapped to a second patch, and the second patch is currently mapped to a third patch, the method further comprising determining whether the third patch has a smaller patch distance to the first patch than what the second patch has, and if so mapping the first patch to the third patch instead. A first patch is currently mapped to a second patch, and the second patch is currently mapped to a third patch, the method further comprising determining whether the first patch has a smaller patch distance to the second patch than what the third patch has, and if so mapping the second patch to the first patch instead.</p>
<p id="p-0011" num="0010">The method further comprises assigning groups of the images to each of multiple working sets, and providing each of multiple processes with at least one of the working sets, wherein each process uses the group of images in the respective working set. Assigning the group of images for at least one of the working sets comprises: finding a first subset of the group by choosing random locations in a first image and selecting the images to which the respective random locations are mapped; finding a second subset of the group by choosing random locations in the first image and selecting the images that are mapped to by locations to which the random locations are mapped; and finding a third subset of the group by choosing images at random. The method further comprises ejecting at least some of the images from the working set and replacing them with a new group from the received images, each image in the new group selected based on which of the first, second and third subsets included a corresponding ejected image.</p>
<p id="p-0012" num="0011">The mapping record has a specific sparsity with less than one mapping per pixel.</p>
<p id="p-0013" num="0012">The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1</figref> is an example block diagram of an image processing system.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 2</figref> shows an example of mapping between image regions in the image web of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. 3A-C</figref> show another example of mapping between image regions in the image web of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 4</figref> schematically shows an example of a system that performs synthesis using the image web of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 5</figref> is an example block diagram of a system that performs image processing.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 6</figref> shows an example implementation wherein iterations of propagation, randomized search and enrichment are performed.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 7</figref> schematically shows working sets for the image web of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0021" num="0020">Like reference numbers and designations in the various drawings indicate like elements.</p>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 1</figref> is an example block diagram of an image processing system <b>100</b>. The system <b>100</b> includes at least one image web <b>110</b> and an image analyzer <b>120</b>. The image web <b>110</b> comprises one or more offset files <b>130</b> and images <b>140</b>. The offset file <b>130</b> defines nearest neighbor relationships between patches in the images <b>140</b>. In some implementations, the offset file(s) <b>130</b> and images <b>140</b> are not separate files but rather are jointly stored as respective characteristics for each pixel. The image web <b>130</b> can be used in many vision and graphics implementations, such as by the image analyzer <b>120</b>. The image web <b>130</b> can be used for image completion, image enlargement or compression, object recognition, image analysis, image generation, image retargeting, morphing, image enhancement or image denoising, to name a few examples.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 2</figref> shows an example of mapping between image regions in the image web of <figref idref="DRAWINGS">FIG. 1</figref>. In this example, it is assumed that there are N number of images in the image web <b>110</b>. That is, the N images are here the same as the images <b>140</b>, and are numbered I<sub>1 </sub>through I<sub>N</sub>. Accordingly, an arbitrary image can be denoted by I<sub>i</sub>, where i=1 . . . N.</p>
<p id="p-0024" num="0023">The images <b>140</b> are here schematically illustrated as planes for clarity, but the images can have any suitable image format. The images <b>140</b> can be stored in a pixel-based format, and each of the images can include the same or a different number of pixels as any other one of the images. The images can use any suitable color model (e.g., the RGB color model) and can be stored in any suitable format (e.g., bitmap (BMP) format). Implementations can involve processing of data organized in two or three dimensions, and/or a video image, to name a few examples.</p>
<p id="p-0025" num="0024">For every image I<sub>k </sub>in the image web <b>110</b>, the offset file <b>130</b> (<figref idref="DRAWINGS">FIG. 1</figref>) defines a number of mappings <b>200</b> to one or more other images, or to the same image. Particularly, a mapping specifies, for each patch <b>210</b> in one of the images, at least one nearest neighbor patch in one or more of the images. Here, for example, the patch <b>210</b>A in the image I<sub>k </sub>has the mapping <b>200</b>A to a patch <b>210</b>B in the image I<sub>1</sub>. Similarly, the patch <b>210</b>C in the image I<sub>k </sub>has the mapping <b>200</b>B to a patch <b>210</b>D in the image I<sub>k-1</sub>. The patch <b>210</b>B in the image I<sub>k</sub>, moreover, has the mapping <b>200</b>C to a patch <b>210</b>E in the image I<sub>N</sub>.</p>
<p id="p-0026" num="0025">A patch is a region in an image, of fixed or varying shape. For example, patches could be defined as fixed-shape 5&#xd7;5 or 7&#xd7;7 rectangles. In some implementations, every patch in all of the images <b>140</b> has one of the mappings <b>200</b> to another patch which is located either on the same image or on another one of the images. In other implementations, the mappings <b>200</b> are sparser than one per patch. For clarity, only a few of the mappings <b>200</b> are illustrated here.</p>
<p id="p-0027" num="0026">The methods and techniques described herein can be used, for example, to provide one or more nearest neighbors for a patch within an image collection, and/or to use a resulting image web for one or more purposes. Some implementations are enhanced using acceleration techniques, such as an &#x201c;enrichment&#x201d; search strategy and/or a parallel algorithm for multi-core architectures.</p>
<p id="p-0028" num="0027">The image web <b>110</b> is generated by determining correspondence between a source image and a target image. The source and target images can be the same image or two separate images. That is, any of the images <b>140</b> (e.g., I<sub>k</sub>) can be considered the source image and any other of the images <b>140</b> can be considered the target image.</p>
<p id="p-0029" num="0028">In some implementations, one can search over a space of offsets into the target image. For example, a notation can be used such that a patch P in the source image (S) is defined as P=S(i,j), namely the patch in the image S having its upper left corner at column i and row j of the pixels in the image S. A patch T(k,l) in the target image (T) can be similarly defined.</p>
<p id="p-0030" num="0029">The correspondence can be quantified using a patch distance function that is applied to pairs of patches in the source and target images. Any distance function can be used. Some implementations can use common distance functions for natural images and/or other data sources including video and three-dimensional shapes, such as an L<sub>p</sub>, L<sub>1</sub>, or clamped L<sub>2</sub>, etc., or any other scalar function. If the patch distance function were applied for a given patch to all other patches among the images <b>140</b> (i.e., all possible pairings were evaluated, which can be considered a &#x201c;brute force&#x201d; approach), it could be determined for which one(s) of the other patches the patch distance function has a minimum. That is, the patch(es) with least patch distance to the current patch could be identified. In other implementations, however, a more efficient approach is used where not all possible pairings are evaluated. In any event, once the nearest neighbour has been found the mapping can be specified in terms of an offset between the current patch and the nearest neighbour.</p>
<p id="p-0031" num="0030">In some implementations, a bidirectional similarity measure can be used, for example one that finds good correspondences between image regions in both directions (e.g., from the patch S(i,j) to the patch T(k,l), and vice versa).</p>
<p id="p-0032" num="0031">An offset between patches S(i,j) and T(k,l) can be defined as (k&#x2212;i, l&#x2212;j). For example, if the two images S and T were identical, the best mapping from S to T when translation without warping is performed can be expressed as
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>arg min<sub>k,l</sub>(<i>D[S</i>(<i>i,j</i>),<i>T</i>(<i>k,l</i>)])=(<i>k&#x2212;i,l&#x2212;j</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0033" num="0032">for all (i,j) and (k,l), where D is the patch distance function being used.</p>
<p id="p-0034" num="0033">Here, the offset file <b>130</b> (<figref idref="DRAWINGS">FIG. 1</figref>) stores an estimate of all nearest-neighbor offsets. The offsets can be termed a nearest-neighbor field &#x192; such that.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x192;:R<sup>2</sup><img id="CUSTOM-CHARACTER-00001" he="2.79mm" wi="3.56mm" file="US08625927-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>R<sup>2</sup>.<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0035" num="0034">The nearest-neighbor field &#x192; can be improved using a randomized patch-matching algorithm that is performed for a predefined number of iterations or until convergence. Initial offsets for all patches are defined as a starting point, and in each iteration the algorithm seeks to improve every offset using at least two sets of candidates: propagation candidates and random-search candidates. The propagation candidates for offset &#x192;(x, y) are the known offsets above or to the left:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x192;(x&#x2212;1, y)+(1,0)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>and<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x192;(x, y&#x2212;1)+(0,1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0036" num="0035">where the plus symbols denote vector addition. That is, they are the right spatial neighbor of the current patch-space neighbor of the left spatial neighbor, and the upper spatial neighbor of the current patch-space neighbor of the bottom spatial neighbor.</p>
<p id="p-0037" num="0036">Generally, a propagation candidate that provides a smaller patch distance D should replace the current offset. On alternating iterations, propagation can instead be done in reverse scan order, such that offsets below and to the right are examined. For example, the propagation candidates can then be:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x192;(x+1,y)&#x2212;(1,0)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>and<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x192;(x,y+1)&#x2212;(0,1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0038" num="0037">where the minus symbols denote vector subtraction. As another example, the propagation step can be done twice per iteration so that the propagation is done in both directions (i.e., in scan order and reverse scan order) in each iteration.</p>
<p id="p-0039" num="0038">The random search can be done both among patches in the same image, or patches in the other images, or both. The random search can help prevent the evaluation of propagation candidates from ending up in a local minimum. The random-search candidates are sampled from an exponential distribution relative to the current offset (e.g., offsets located at an exponentially decreasing distance from the current offset in a random direction). The current offset is replaced if the random-search candidate has a smaller patch distance.</p>
<p id="p-0040" num="0039">For problems such as denoising, symmetry detection, and object and clone detection, to name just a few examples, one may wish to compute more than a single nearest neighbor for every (i,j) position. A patch matching algorithm can be created to collect k nearest neighbors for each patch.</p>
<p id="p-0041" num="0040">Multiple candidates can be found in various ways. Some implementations use an algorithm designed to find a single nearest-neighbor for each patch, such as the function &#x192; in the above example. For example, the k best matches found by the single-neighbor algorithm can be retained. As another example, the single-neighbor algorithm can be run k times, with each run constrained so that offsets cannot be equal to any of the previously chosen offsets.</p>
<p id="p-0042" num="0041">If multiple offset candidates are established for a patch in S, they can be registered in respective ones of multiple offset objects. For example, k offset objects can be used to store k offset candidates for each patch. In another implementation, a single multidimensional offset object can store all k candidates for each patch.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. 3A-C</figref> show another example of mapping between image regions in the image web of <figref idref="DRAWINGS">FIG. 1</figref>. In <figref idref="DRAWINGS">FIG. 3A</figref>, an image realm <b>300</b> includes an image A and a number of images B. A patch <b>302</b> is located in a region of the image A. The patch <b>302</b> is associated with one or more mappings <b>304</b> to another image region. The mappings <b>304</b> can be patch-to-patch mappings, similar to the ones described above.</p>
<p id="p-0044" num="0043">In some situations, the mapping <b>304</b> represents an initial guess of what image region(s) best correspond to the patch <b>302</b>, for example using the offsets mentioned above. For example, the other image region(s) can be located in an image B<sub>i</sub>, such as the region(s) represented by one or more patches <b>306</b>. The patch(es) <b>306</b> can include a rotated patch, a scaled patch, a non-rotated and non-scaled patch, or combinations thereof. A mapping can be improved in one or more iterations, for example as will now be described.</p>
<p id="p-0045" num="0044">In some implementations, a propagation phase can be carried out as schematically illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>. For example, assume that a patch <b>308</b> in the image A has been mapped to one or more patches <b>310</b> in a image B<sub>j</sub>, which is another image than B<sub>i </sub>in the previous example. These mapping(s) between patches <b>308</b> and <b>310</b> not being shown in the figure for clarity. Neighbors of the patch <b>308</b> can now be evaluated to determine what mappings they have, and whether any of these mappings can be applied to the patch <b>308</b> for a better result. For example, the algorithm can look at the offsets of neighboring or nearby patches, and use one of these offsets if it provides a better result. In some implementations, an algorithm can look at the four immediately adjacent pixels, or all pixels in a circular or square neighborhood of diameter 2 or 4, and/or any subset of the pixels within a fixed distance of the pixel at which propagation occurs, to name just a few examples.</p>
<p id="p-0046" num="0045">Here, for example, it may be determined that if one applies the mapping of a patch <b>312</b> to the patch <b>308</b>, then the patch <b>308</b> can be provided with a mapping <b>314</b> to a patch <b>316</b>, which has a better correspondence to the patch <b>308</b> than the earlier mapping to the patch <b>310</b>. The term propagation indicates that good mappings for one patch can be propagated to neighboring patches to improve their mappings. Thus, for example, if a local maximum of correspondence exists in mappings of a neighborhood around the patch <b>308</b>, it can be detected in the propagation phase.</p>
<p id="p-0047" num="0046">In implementations that identify k offsets as possible matches for a patch, these k offsets can all be taken into account in the propagation phase. In some implementations, the k offsets are ranked with regard to patch distance (e.g., as determined using any distance metric). For example, the offsets can be included in a max-heap. When a new candidate offset for an arbitrary patch (x,y) is identified in the propagation phase, it is compared to the &#x201c;worst&#x201d; offset in the max-heap (i.e., the one of the identified offsets having the greatest patch distance). If the candidate offset's patch distance is &#x201c;better&#x201d; than the worst offset (i.e., it has less patch distance), then the worst offset is removed from the max-heap and the candidate offset is added to the max-heap; else the candidate offset may be ignored.</p>
<p id="p-0048" num="0047">A perturbation such as a random-search phase can be used. The random search can be performed within one or more other images, for example as schematically illustrated in <figref idref="DRAWINGS">FIG. 3C</figref>, and/or within the same target image. First will be described an example of searching within a different image shown in <figref idref="DRAWINGS">FIG. 3C</figref>. Assume that the image B<sub>j </sub>is the current target image. Another one of the images, B<sub>k</sub>, can then be randomly selected and one or more of its patches can be evaluated. Any suitable randomizing function can be used.</p>
<p id="p-0049" num="0048">Here, a mapping <b>314</b>&#x2032; from the patch <b>308</b> to the image B<sub>k </sub>defines a starting point for the random search. For example, the patch in B<sub>k </sub>corresponding to the mapping <b>314</b>&#x2032; may have been randomly selected within the randomly chosen image B<sub>k</sub>, or it may be an already existing mapping (e.g., when multiple candidate target patches are identified for the same source patch in each iteration). Other ways of obtaining or choosing the initial mapping within the randomly chosen image can be used, including, but not limited to, using a default patch (e.g., the patch in the center of the image).</p>
<p id="p-0050" num="0049">Based on the mapping <b>314</b>&#x2032;, one or more randomly selected mappings can then be evaluated. For example, patches <b>318</b>A, <b>318</b>B and <b>318</b>C can be randomly selected in the image B<sub>k</sub>. In some implementations, the patches <b>318</b>A-C are selected to have gradually increasing or decreasing distance from the location of the original mapping target in the image B<sub>k</sub>. For example, a random distribution can be used that includes nearby locations (e.g., the patch <b>218</b>C) and locations further away (e.g., the patch <b>218</b>A), wherein the distribution places more weight in the distribution function on distances of nearby locations than would be obtained from uniform sampling.</p>
<p id="p-0051" num="0050">In some implementations, an algorithm can sample at uniform from the entire image with probability 1/2, and sample from a circle with small radius around the current mapping with probability 1/2, giving a random distribution where smaller distances are preferentially selected, and/or sample according to a Gaussian distribution around the current mapping, to preferentially select smaller distances. As another example, the probability density function can be generally decreasing, meaning that it does not have to be monotonic, but generally decreases as radius increases. In some implementations, the random search can be performed by sampling only those points whose distance is within an exponentially decreasing threshold from the mapping of the first patch. The patches <b>318</b>A-C can be evaluated to determine whether a better correspondence with the patch <b>308</b> can be achieved using a randomly selected patch. If any of the randomly selected mappings has a smaller patch distance than the current mapping, the current mapping can be replaced with a mapping to the new patch.</p>
<p id="p-0052" num="0051">In some implementations, multiple other images are chosen at random and a similar processing as just described is performed on one or more patches in each of those other images. The current mapping can be replaced with a different mapping each time a patch with shorter patch distance is found.</p>
<p id="p-0053" num="0052">Second, an example of randomly searching within the same target image will now be described. Referring again to <figref idref="DRAWINGS">FIG. 3C</figref>, assume now instead that k=j, such that B<sub>k </sub>is the same image as B<sub>j</sub>. Assume further that the mapping <b>314</b>&#x2032; is instead the mapping for the patch <b>308</b> that has been identified in a propagation step, for example as described above. Based on this existing mapping <b>314</b>&#x2032;, one or more randomly selected mappings can then be evaluated, in analogy with the above example regarding searching in a different image. For example, patches <b>318</b>A, <b>318</b>B and <b>318</b>C can be randomly selected within the same image as the current mapping for the patch <b>308</b>, and these mappings <b>318</b>A-C can be evaluated as to whether any of their patches would have a smaller patch distance for the patch <b>308</b> than its current mapping. If so, the current mapping can be replaced with a mapping to the new patch.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 4</figref> schematically shows an example of a system <b>400</b> that performs synthesis using the image web <b>110</b> of <figref idref="DRAWINGS">FIG. 1</figref>. Particularly, the system <b>400</b> includes an image synthesizer <b>410</b> that here operates on the image web <b>110</b> and at least one arbitrary image <b>420</b>.</p>
<p id="p-0055" num="0054">The image synthesizer <b>410</b> takes the image <b>420</b> as an input and generates one or more images <b>430</b> as a result. In some implementations, the image <b>430</b> is generated so that it has some image content from the image <b>420</b> and some other content that has been synthesized based on the image <b>420</b>, using the image web <b>110</b>. One or more original patches (labeled OP) <b>440</b> can be obtained from the image <b>420</b>, and using the original patch(es) <b>440</b> one or more synthetic patches (labeled SP) <b>450</b> can be generated. For example, the image synthesizer <b>410</b> takes the original patch(es) <b>440</b> and makes comparison(s) against the image web <b>110</b>, and then generates one or more of the synthetic patches <b>450</b> as a result.</p>
<p id="p-0056" num="0055">A particular example of image synthesis is hole filling. That is, the image <b>420</b> may have a hole in it, meaning that at one or more locations in the image information corresponding to at least one pixel is missing from an otherwise regular pixel pattern. The hole may exist for any of multiple reasons, such as that a camera, scanner, memory or image transferring equipment malfunctions; that a person marks unwanted pixels in an image; or that a person assembles the image from smaller image fragments leaving some regions incomplete.</p>
<p id="p-0057" num="0056">In such implementations, the image synthesizer <b>410</b> takes patches that are elsewhere in the image <b>420</b>, compares them with the image web <b>110</b>, and thereby obtains one or more similar patches that can be used to fill the hole.</p>
<p id="p-0058" num="0057">Creation of an image collage is another example where one or more patches of image content are added to existing content. In some implementations, the image <b>420</b> can be created by a user who places one or more image contents (e.g., patches) on a larger canvas. For example, the user can cut and paste a rough collage of image fragments and then let the image synthesizer <b>410</b> can fill the gaps between the image fragments using matching parts from the many patches in the image web <b>110</b>. Depending on the implementation, the image synthesizer <b>410</b> can generate a plausible image around the image fragments.</p>
<p id="p-0059" num="0058">In some examples the collage is created without modifying the original image fragments. In other examples, the image synthesizer <b>410</b> is allowed to resynthesize the entire canvas, and therefore uses the original image fragments as a rough guide, or constraints, in generating the image <b>430</b>.</p>
<p id="p-0060" num="0059">Super resolution of an image, and retargeting an image to a greater size, are other examples where one or more patches of image content are added to existing content. Here as well, one challenge is that information must be assumed, to interpolate between known pixels. For example, the image <b>420</b> has a particular resolution (e.g., 200&#xd7;200 pixels) and should now be given a higher resolution (e.g., 250&#xd7;250). If this is done to the entire image, the synthetic patches <b>450</b> should equal a total of 22,500 new pixels. First, the original patches <b>440</b> can be formed by dividing the image <b>420</b> into suitably sized areas, each area forming one of the patches. Second, each of the new pixels for the synthetic patches <b>450</b> can be obtained from the image web <b>110</b> based on one or more of the original patches <b>440</b>. Finally, the patches <b>440</b> and <b>450</b> can be assembled into the image <b>430</b> in a suitable way (e.g., by interspersing new pixels).</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 5</figref> is an example block diagram of a system <b>500</b> that performs image processing. In the system <b>500</b>, an image processing component <b>510</b> can perform one or more types of processing on the image <b>420</b>. In some implementations, the image processing component <b>510</b> can perform image synthesis that results in the image <b>430</b>, and the image processing component may then be similar or identical to the image synthesizer <b>410</b> (<figref idref="DRAWINGS">FIG. 4</figref>). In some implementations, however, the image processing component <b>510</b> can also or instead perform other useful processing.</p>
<p id="p-0062" num="0061">A first example is that the image processing component <b>510</b> can be used in generating one or more image webs, for example the image web <b>110</b> described in examples above. In general terms, the generation of image webs can be said to fall into one of three categories:</p>
<p id="p-0063" num="0062">A. Adding a single image to an N-web, forming an (N+1)-web</p>
<p id="p-0064" num="0063">B. Combining an M-web with an N-web, forming an (M+N)-web</p>
<p id="p-0065" num="0064">C. Starting with N images and forming an N-web</p>
<p id="p-0066" num="0065">For example, in category C one can start by generating random mappings between all patches in the N images and then improve the mappings by iterative processes that will be exemplified below. As another example, an N-web can be iteratively constructed in category A, starting by expanding a 2-web to a 3-web, and so on. In category B, individual elements from the M-web can be added to the N-web, while retaining the best patch distances from the M-web where applicable, to name just one example.</p>
<p id="p-0067" num="0066">Basically, in implementations where only one nearest neighbor should be registered for each patch, the image web can be represented as a multi-channel image where each location (i,j) contains the following:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0067">R, G, B, x, y, n, d</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0068" num="0068">Here, R, G and B are the respective RGB values for the pixel in the source image; x and y are the coordinates of the nearest neighbor that has been found for that source pixel (that is, the patch at (i,j) is mapped to the patch at (x,y)); n is the number of the image having the nearest neighbor; and d reflects the patch distance between the source patch and its nearest neighbor. For example, using the L<sub>2 </sub>norm the patch distance could be equal to the square root of d. In some implementations, 12 bits are used for each of x and y, 16 bits for the image number n, and 24 bits are used for the patch distance (i.e., for d), which gives a total of 64 bits in addition to the RGB information.</p>
<p id="p-0069" num="0069">Because of coherency in two or more images, some of the mappings may be redundant. Basically, the number of mappings used can in principle be the lowest number at which the image web is a useful structure, taking into account various factors, such as storage space, processing time, and fidelity (i.e., that a sufficiently similar patch can be found). As an example, and without limitation, in some situations it may be the case that an image web of 50 images requires the image web to be dense, or in other words to have one mapping for each patch. However, in a larger image web (e.g., having one million images) it may be sufficient to have only a subset or fraction of all possible mappings (e.g., 1% of the mappings). That is, an image web can have a specific sparsity in how many mappings are defined for the number of patches that the images contain.</p>
<p id="p-0070" num="0070">In some implementations, mappings are stored sparsely, with fewer than one mapping per pixel. As a first example, the image web <b>110</b> (<figref idref="DRAWINGS">FIG. 1</figref>) can be computed and then made sparse for later storage and computation. As a second example, dense mappings can be computed for the working set and then made sparse only when writing to disk. As a third example, the algorithm that generates the image web <b>110</b> can be adapted so that it considers multiple patches at a time, and optimizes both sparse offsets and the regions that share those offsets in the inner loop.</p>
<p id="p-0071" num="0071">A second example is that the image processing component <b>510</b> can be used in compressing one or more images. In some implementations, each image is stored not as compressed image information, but rather as a collection of mappings or other links to a suitable image web. When the image should be displayed, edited or otherwise accessed, it is first resynthesized from the image web using the mappings.</p>
<p id="p-0072" num="0072"><figref idref="DRAWINGS">FIG. 6</figref> shows an example implementation <b>600</b> wherein iterations of propagation, randomized search and enrichment are performed. Here, the implementation <b>600</b> includes a randomized approximation algorithm <b>602</b>. The randomized approximation algorithm <b>602</b> can identify, obtain and/or receive images <b>604</b> that are to be processed by the algorithm. In some examples, the implementation <b>600</b> is configured to determine bi-directional similarity in a synthesis algorithm and find correspondence between image regions, and the target image(s) may be somewhat similar to the source image.</p>
<p id="p-0073" num="0073">The implementation <b>600</b> can include an initialization stage <b>606</b> that is performed to define the initial offsets or mappings for patches and/or pixels in at least one of the images <b>604</b>. In some implementations, offset objects can be initialized with random offsets in the domains of the target and source images, respectively. For example, when one offset is identified per patch (i.e., k=1), the chance of any one pixel being assigned the best offset in such an approach can be (1/n), where n is the number of pixels in the image. However, the likelihood that at least one pixel in the image is assigned the best offset can be (1&#x2212;(1&#x2212;1/n)<sup>n</sup>). Moreover, the chance that a pixel is assigned an offset close to the correct offset can be (1&#x2212;(1&#x2212;m/n)<sup>n</sup>), where m is the area of the &#x201c;close&#x201d; offset region, for example a circle with a suitable radius. For large images these probabilities can converge to 1&#x2212;1/e and 1&#x2212;exp(&#x2212;m), respectively. If the random initialization is used in an implementation where multiple offsets are identified for each patch, this increases the chance that the best offset is among the randomly chosen initial offsets.</p>
<p id="p-0074" num="0074">Other ways of initializing the offset objects can be used in the initialization <b>606</b>. In some implementations, seeding can be used. For example, a small number of patch offsets can be initialized using a full k-d tree search to seed the initial estimates with a few pixels guaranteed to be optimal. In some implementations, external and/or manual correspondence can be used. For example, in an image analogy implementation the user may provide labels that constrain the initial guesses to a specific region of the input. In some implementations, a rough initial search can be performed. For example, approximate nearest neighbors can be found using a smaller patch size, such as a single pixel, and/or a reduced-dimensionality patch, and/or a search with a relatively fast distance metric such as L<sub>2</sub>.</p>
<p id="p-0075" num="0075">The approximation algorithm <b>602</b> can include an iterative evaluation <b>608</b>. In some implementations, each iteration of the iterative algorithm can involve scanning through each pixel in the source image in a scan order, and the iterative evaluation can be continued until a stopping criterion is reached. The iterative evaluation <b>608</b> can include a propagation phase <b>610</b> and a phase for perturbing a result of the propagation phase <b>610</b>, such as a random search phase <b>612</b>.</p>
<p id="p-0076" num="0076">In the propagation phase <b>610</b>, the algorithm can loop through each pixel in an offset object, attempting to lessen the patch distance between the current patch and the matching patch(es). In implementations that search also among rotations and/or scales of the patches, the patch distance can be expressed as
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>D[S(i,j),T(W<sub>S</sub>(k,l)&#xb7;(i,j))]<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0077" num="0077">where W<sub>S </sub>is a warping matrix being multiplied with the target patch location (i,j) to perform a warping action on the target patch. Then, the propagation phase seeks to determine whether the warping applied to another candidate patch (e.g., in a neighborhood) gives a better result than the current warping.</p>
<p id="p-0078" num="0078">For example, one can define
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(u,v)&#x2190;arg min<sub>(k,l)&#x2208;N(i,j)</sub>D[S(i,j),T(W<sub>S</sub>(k,l)&#xb7;(i,j))]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>W<sub>S</sub>(i,j)&#x2190;W<sub>S</sub>(u,v)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0079" num="0079">where N is a neighborhood of a particular offset pixel and W<sub>S</sub>(k,l)&#xb7;(i,j) represents the result of applying the warping action of patch (k,l) to the patch (i,j). That is, the propagation phase <b>610</b> applies the warping action of other patches (i.e., W<sub>S</sub>(k,l)) to the present candidate patch (i.e., (i,j)), and the best such warping action (i.e., W<sub>S</sub>(u,v)) is assigned as the warping action. For simplicity, the warping is here represented as a multiplication (dot product) between the warping object and the candidate patch. It will be understood that some warpings, such as polar transformations, do not involve a multiplication of the candidate patch.</p>
<p id="p-0080" num="0080">The neighborhood N can be defined in various ways. In some implementations, a fixed spatial neighborhood of the pixel can be searched. For example, the neighborhood can include only the 4 adjacent pixels in the same row or column, or the eight surrounding pixels in the adjacent rows and columns, or the 24 closest pixels in the adjacent two rows and columns on all sides, to name a few examples.</p>
<p id="p-0081" num="0081">A perturbation phase can be introduced, such as the random search phase <b>612</b> that uses random perturbations. For example, this can seek to overcome one or more local minima and to obtain convergence to a global optimum in the limit. In some implementations, the random search phase <b>612</b> can test a random set of alternate patches in the same or a different target image for each offset pixel. In some implementations, the random set can have an arbitrary distribution. In some implementations, however, the random set can be obtained according to a pattern, such as at an exponentially or otherwise decreasing distance from the currently guessed offset:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>cand(i,j,t)&#x2190;W<sub>S</sub>(i,j)+&#x3c9;&#x3b1;<sup>&#x2212;t</sup>(a,b)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>W<sub>S</sub>(i,j)&#x2190;arg min<sub>(k,l)&#x2208;cand(i,j,t)</sub>D[S(i,j),T(k,l)]<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0082" num="0082">in which &#x3c9; can be a fixed large distance (such as the image width), &#x3b1; can be a fixed ratio between search window sizes, and a and b are random variables in a domain, for example [&#x2212;0.5, 0.5]. In some implementations, &#x3c9; can be the larger of image height and width, and &#x3b1;=2. The above assignments to the cand variable can be repeated starting with t=0 and incrementing t until &#x3c9;&#x3b1;<sup>&#x2212;t </sup>is 1 or less. For example, this can allow the approximation algorithm <b>602</b> to jump relatively quickly to distant patch location and then sample more locally in that region.</p>
<p id="p-0083" num="0083">Thus, the propagation phase <b>610</b> can serve to select the best mapping for a given patch/pixel based on what mappings are implied by the neighboring offset pixels. The random search phase <b>612</b>, in turn, can serve to perturb that mapping selected in the propagation phase <b>610</b>, for example by randomizations of geometrically decreasing size, and then select the best of the random offsets. Accordingly, the iterative evaluation can include an inner loop <b>614</b> that runs over each pixel and the propagation phase <b>610</b> and the random search phase <b>612</b> can be performed in the inner loop <b>614</b> over each pixel.</p>
<p id="p-0084" num="0084">Accordingly, the sampling pattern in a random-search step can change locally (instead of a fixed pattern) to adapt locally to some properties of the patch. Examples of patch properties include: the distance at the previous patch-matching iteration, the local structure of the patch (e.g, each patch can be classified as one of several structures, such as a blob, a horizontal edge, a vertical edge, a uniform region, by convolving with some filters), and the local color of the patch and other local properties.</p>
<p id="p-0085" num="0085">In some implementations, enrichment of a &#x201c;forward&#x201d; type or of an &#x201c;inverse&#x201d; type can be used. In the following examples about enrichment, a multi-valued function &#x192; indicates a mapping from a patch position in an image to the patch positions of each of its k nearest neighbors. Enrichment can seek to propagate good matches across the space of patches themselves, as opposed to propagation across the spatial dimensions of the image. For example, an image A is sometimes matched to itself, such as in non-local-means denoising. In such implementations, patch matching can be performed for regions in a single image, as opposed to in separate images.</p>
<p id="p-0086" num="0086">In forward enrichment, the function &#x192; is composited with itself one or more times. As an example, the function &#x192;<sup>2 </sup>can be created by considering all k nearest neighbors of each of the k nearest neighbors for the patch, which gives k<sup>2 </sup>nearest neighbors of the nearest neighbors. As a nearest neighbor is a candidate patch, the nearest neighbors of the nearest neighbors can be considered candidate patches of the candidate patches, or candidate-candidate patches. From among the k nearest neighbors for the patch and the k<sup>2 </sup>nearest neighbors for those, the top k matches are taken. In some implementations, higher orders of the function can be used, such as &#x192;<sup>3</sup>,&#x192;<sup>4</sup>, and so forth. A variant of forward enrichment can then be used, for example by taking k random samples from the function &#x192;<sup>n</sup>, or taking the top n&#x221a;{square root over (k)} If elements of &#x192;.</p>
<p id="p-0087" num="0087">In some implementations, an enrichment procedure <b>618</b> can be performed before a result is generated. In the enrichment procedure <b>618</b> it can be evaluated whether the neighbor of the current nearest neighbor is a better match than the current nearest neighbor itself. With reference again to <figref idref="DRAWINGS">FIG. 2</figref>, assume that at least the mappings <b>200</b>A and <b>200</b>C have been determined so far in the process. That is, the currently nearest neighbor for the patch <b>210</b>A is the patent <b>210</b>B, and the currently nearest neighbor for the patch <b>210</b>B is the patch <b>210</b>E. The evaluation can then compute the patch distance of the patch <b>210</b>E with regard to the patch <b>210</b>A. If this patch distance is less than the patch distance that the patch <b>210</b>B has, then the patch <b>210</b>E is the better match of the two for the patch <b>210</b>A. Accordingly, the patch <b>210</b>E can instead be made the current nearest neighbor for the patch <b>210</b>A.</p>
<p id="p-0088" num="0088">In inverse enrichment, candidates are produced by reversing pointers to nearest neighbors. As an example, the function &#x192;<sup>&#x2212;1 </sup>represents the multi-valued inverse of the function &#x192;. That is, for an arbitrary patch a, say in the image T (<figref idref="DRAWINGS">FIG. 1</figref>), the function &#x192;<sup>&#x2212;1 </sup>returns any patch(es) in the image S pointing to the patch a. If no patch in S points to the patch a, then the function &#x192;<sup>&#x2212;1 </sup>has no value for that patch. If the patch distance function is symmetric, such that the distance from patch a to patch b is the same as the distance from patch b to patch a, then patch distances need not be explicitly calculated for the function &#x192;<sup>1</sup>. The function &#x192;<sup>&#x2212;1 </sup>can be stored using a list of varying length at each position. From among the k nearest neighbors for the patch and the neighbors from the function &#x192;<sup>&#x2212;1</sup>, the top k matches are taken. In some implementations, higher orders of the function can be used, such as &#x192;<sup>&#x2212;2</sup>,&#x192;<sup>&#x2212;3</sup>, and so forth. In some implementations, forward enrichment is followed by inverse enrichment, or vice versa. For example, &#x192;<sup>&#x2212;1 </sup>inverse enrichment can be followed by &#x192;<sup>2 </sup>forward enrichment.</p>
<p id="p-0089" num="0089">In some implementations, an inverse enrichment procedure <b>619</b> can be performed before a result is generated. In the inverse enrichment procedure <b>619</b> it can be evaluated whether a current patch is a better match for its nearest neighbor than the patch that the nearest neighbor currently is mapped to. Still referring to <figref idref="DRAWINGS">FIG. 2</figref>, the patch distance of patch <b>210</b>A with regard to patch <b>210</b>B is the same as the patch distance of patch <b>210</b>B with regard to patch <b>210</b>A. Because the latter distance has already been calculated, the inverse enrichment procedure <b>619</b> can simply read the value from the offset file or another location. Similarly, the patch distance of patch <b>210</b>E with regard to patch <b>210</b>B has also been calculated previously. By comparing these distances, the inverse enrichment procedure <b>619</b> can decide whether the patch <b>210</b>B should be mapped to the patch <b>210</b>A instead of as currently to the patch <b>210</b>E.</p>
<p id="p-0090" num="0090">The above examples illustrate how enrichment can be viewed as making different numbers of &#x201c;hops&#x201d; forwards or backwards the graph. That is, the example &#x192;<sup>2 </sup>forward enrichment corresponds to one &#x201c;forward&#x201d; hop in the graph, because it goes from taking into account only the neighbors of a patch to taking into account also the neighbors of those neighbors. The example &#x192;<sup>&#x2212;1 </sup>inverse enrichment, in turn, corresponds to one &#x201c;backward&#x201d; hop in the graph, because it considers also all patches that point to a particular neighbor.</p>
<p id="p-0091" num="0091">In some implementations, the number of hops in an enrichment phase can be handled in an analogous way. A fixed distribution, or an adaptively changing distribution, can be used. The distribution can be adapted using a local property, such as the previous patch distance (based on the notion that the closer one is to the true nearest neighbor, the fewer hops one should make).</p>
<p id="p-0092" num="0092">The approximation algorithm <b>602</b> can be terminated using one or more stopping criteria. In some implementations, a stopping criterion can be defined by the application in the implementation <b>600</b>. For example, a fixed number of iterations can be used or the iterations can be performed until the fraction of pixels changed in the offset object(s) is below a threshold. As an example, 5-10 iterations can be used in some implementations.</p>
<p id="p-0093" num="0093">The approximation algorithm <b>602</b> can generate one or more results <b>616</b>. For example, the result <b>616</b> can include an image in which one or more holes in the image <b>604</b> have been filled. As another example, the result <b>616</b> can indicate, for at least one patch in the image <b>604</b>, a corresponding at least one patch in the same image or in another one of multiple images. In some implementations, the result can reflect a bidirectional similarity between the images <b>604</b>.</p>
<p id="p-0094" num="0094">Varying numbers of candidates can be identified for one or more patches. In some implementations, fewer than all k offsets are taken into account in the propagation <b>610</b>. For example, only the offset with the smallest distance is subjected to propagation. As another example, one or more elements among the k offsets can be randomly chosen for propagation. Similarly, the random search <b>612</b> can be performed only for the offset(s) having smallest patch distances, or for one or more randomly chosen offsets. Some implementations perform propagation and/or random search on the m best offsets (with the number m randomly chosen from 1 to k.)</p>
<p id="p-0095" num="0095">The number k can be changed during iterations. In some implementations, iteration number one can start with k<sub>0 </sub>number of nearest neighbors, and after a portion of the iterations are completed (e.g., half of them), the number can be increased or decreased to k, the final desired number of nearest neighbors. For example, the worst elements of the heap can be dropped, or uniform random elements can be added. In some implementations, k<sub>0</sub>=k/2 or k<sub>0</sub>=2 k can be used.</p>
<p id="p-0096" num="0096">Computer processing can involve more than one processor core. An implementation can be practiced in a computer system that has a multi-core architecture. For example, the computer system <b>620</b> can have a processor <b>622</b> that is a multi-core processor, such as an eight-core processor. As another example, the computer system <b>620</b> can have multiple single-core processors.</p>
<p id="p-0097" num="0097">Processing in the system <b>600</b> can be performed on multiple computers. In some implementations, the image web <b>110</b> (<figref idref="DRAWINGS">FIG. 1</figref>) can be distributed across a network of computers that perform various parts of the processing. It can then be useful to divide the images into working sets. For example, the working sets can be chosen based on locality in the network.</p>
<p id="p-0098" num="0098"><figref idref="DRAWINGS">FIG. 7</figref> schematically shows working sets <b>700</b> for the image web <b>110</b> of <figref idref="DRAWINGS">FIG. 1</figref>. In this example, M number of working sets <b>700</b> are being used, which are here labeled W<sub>1</sub>, W<sub>2</sub>, . . . , W<sub>M</sub>, respectively.</p>
<p id="p-0099" num="0099">For example, the working sets <b>700</b> can serve to distribute various aspects of the processing performed in propagation, random search, and/or enrichment phases over more than one core. That is, the images that are to be processed can be assigned to respective ones of the working sets <b>700</b>. Each of the working sets <b>700</b> can then be processed by one of multiple processes <b>710</b>.</p>
<p id="p-0100" num="0100">In some implementations, images are assigned to working sets as follows. Each working set should be sized so that it fits in memory available to the corresponding process <b>710</b>. To choose the proper number of images, they are selected as three different subgroups. A first subgroup, here called w<b>1</b>, is made up of images selected by choosing random locations in a current image, determining what image(s) these locations map to, and selecting those target images for w<b>1</b>.</p>
<p id="p-0101" num="0101">A second subgroup w<b>2</b> is made up of images selected by choosing random locations in a current image, determining what patch(es) these locations map to, and selecting target images for w<b>1</b> that contain the nearest neighbors for the patched mapped to by the randomly selected locations.</p>
<p id="p-0102" num="0102">A third subgroup w<b>3</b> is made up of images selected randomly.</p>
<p id="p-0103" num="0103">Thus, the entire working set is:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>w=w</i>1+<i>w</i>2+<i>w</i>3<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0104" num="0104">If parallel or cluster processing is performed, the image in the working set that is being modified by one of the processors can be locked. If a processor that is creating a working set attempts to take an image that is locked, the processor can simply choose another image in the same fashion (i.e., according to subset w<b>1</b>, w<b>2</b> or w<b>3</b>). In some implementations the working set is divided into readable sets, which may overlap between processors, and writeable sets, which are locked per-core. For example, even if a first processor is reading an image to which a second processor is writing but has not yet committed to the data store, the first processor can use the previously computed offsets in the image to find nearest neighbors.</p>
<p id="p-0105" num="0105">The sweep over an image can proceed in the order of: propagation, random search, inverse enrichment, enrichment. However, for all operations, the current processor can only read or update those of the images that are in the current working set.</p>
<p id="p-0106" num="0106">The image that is currently to be worked on can be chosen at random from the respective working set. In some implementations, the selection takes into account which images have already been worked on the most. That is, images that have been worked on a few times less than the most worked on images can be selected with a probability near one. This way, the algorithm tends to localize images of a particular type that it works on, as things similar to the current working set are continually being provided in form of the subsets w<b>1</b> and w<b>2</b>. One cluster may tend to do images depicting grass, as an example. As new images are brought into the working set, if they haven't been worked on previously in another process, they are chosen to be worked on in the current process with high probability.</p>
<p id="p-0107" num="0107">Images can be ejected from a working set. In some implementations, a subgroup w<b>4</b> is randomly chosen from the working set (i.e., from w), the subgroup w<b>4</b> is ejected, and the subgroup w<b>4</b> is replaced with other images. For example, the other images can be selected based on the respective subgroup of the ejected images.</p>
<p id="p-0108" num="0108">Another form of eviction is &#x201c;least used&#x201d; eviction. In some implementations, this is done based on a counter that is maintained for each image. For example, the counter shows how many times the offsets of this image have been improved, and/or how many times the offsets have been used in improving the mapping in another image. The least used images can then be evicted, and the counters be reset for the new images.</p>
<p id="p-0109" num="0109">Some portions of the detailed description are presented in terms of algorithms or symbolic representations of operations on binary digital signals stored within a memory of a specific apparatus or special purpose computing device or platform. In the context of this particular specification, the term specific apparatus or the like includes a general purpose computer once it is programmed to perform particular functions pursuant to instructions from program software. Algorithmic descriptions or symbolic representations are examples of techniques used by those of ordinary skill in the signal processing or related arts to convey the substance of their work to others skilled in the art. An algorithm is here, and generally, is considered to be a self-consistent sequence of operations or similar signal processing leading to a desired result. In this context, operations or processing involve physical manipulation of physical quantities. Typically, although not necessarily, such quantities may take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared or otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to such signals as bits, data, values, elements, symbols, characters, terms, numbers, numerals or the like. It should be understood, however, that all of these or similar terms are to be associated with appropriate physical quantities and are merely convenient labels. Unless specifically stated otherwise, as apparent from the discussion, it is appreciated that throughout this specification discussions utilizing terms such as &#x201c;processing,&#x201d; &#x201c;computing,&#x201d; &#x201c;calculating,&#x201d; &#x201c;determining&#x201d; or the like refer to actions or processes of a specific apparatus, such as a special purpose computer or a similar special purpose electronic computing device. In the context of this specification, therefore, a special purpose computer or a similar special purpose electronic computing device is capable of manipulating or transforming signals, typically represented as physical electronic or magnetic quantities within memories, registers, or other information storage devices, transmission devices, or display devices of the special purpose computer or similar special purpose electronic computing device.</p>
<p id="p-0110" num="0110">Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer program products, i.e., one or more modules of computer program instructions encoded on a tangible program carrier for execution by, or to control the operation of, data processing apparatus. The tangible program carrier can be a computer-readable medium. The computer-readable medium can be a machine-readable storage device, a machine-readable storage substrate, a memory device, or a combination of one or more of them.</p>
<p id="p-0111" num="0111">The term &#x201c;data processing apparatus&#x201d; encompasses all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.</p>
<p id="p-0112" num="0112">A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.</p>
<p id="p-0113" num="0113">The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).</p>
<p id="p-0114" num="0114">Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, to name just a few.</p>
<p id="p-0115" num="0115">Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.</p>
<p id="p-0116" num="0116">To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.</p>
<p id="p-0117" num="0117">Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (&#x201c;LAN&#x201d;) and a wide area network (&#x201c;WAN&#x201d;), e.g., the Internet.</p>
<p id="p-0118" num="0118">The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.</p>
<p id="p-0119" num="0119">While this specification contains many specifics, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.</p>
<p id="p-0120" num="0120">Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.</p>
<p id="p-0121" num="0121">Particular embodiments of the subject matter described in this specification have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain implementations, multitasking and parallel processing may be advantageous.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer-implemented method for determining correspondence between images, the method comprising:
<claim-text>receiving images in a computer system;</claim-text>
<claim-text>performing iterations using the computer system to find respective mappings for each patch of pixels in the images to a patch in another one of the images such that the mappings have minimal patch distance, the iterations including at least: (i) evaluation of a nearby-pixel mapping in a current image, (ii) evaluation of a randomly selected mapping in the current image, and (iii) evaluation of a randomly selected mapping in another one of the images; and</claim-text>
<claim-text>generating a mapping record that results from the iterations, the mapping record having a specific sparsity with less than one mapping per pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a first patch is currently mapped to a second patch, and wherein the second patch is currently mapped to a third patch, the method further comprising determining whether the third patch has a smaller patch distance to the first patch than what the second patch has, and if so mapping the first patch to the third patch instead.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a first patch is currently mapped to a second patch, and wherein the second patch is currently mapped to a third patch, the method further comprising determining whether the first patch has a smaller patch distance to the second patch than what the third patch has, and if so mapping the second patch to the first patch instead.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising assigning groups of the images to each of multiple working sets, and providing each of multiple processes with at least one of the working sets, wherein each process uses the group of images in the respective working set.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The computer-implemented method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein assigning the group of images for at least one of the working sets comprises: finding a first subset of the group by choosing random locations in a first image and selecting the images to which the respective random locations are mapped; finding a second subset of the group by choosing random locations in the first image and selecting the images that are mapped to by locations to which the random locations are mapped; and finding a third subset of the group by choosing images at random.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The computer-implemented method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising ejecting at least some of the images from the working set and replacing them with a new group from the received images, each image in the new group selected based on which of the first, second and third subsets included a corresponding ejected image.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the performing continues until a stopping criteria is met.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A computer program product embodied in a non-transitory storage device and comprising instructions that when executed by a processor perform a method comprising:
<claim-text>receiving images in a computer system;</claim-text>
<claim-text>performing iterations using the computer system to find respective mappings for each patch of pixels in the images to a patch in another one of the images such that the mappings have minimal patch distance, the iterations including at least: (i) evaluation of a nearby-pixel mapping in a current target image, and (ii) evaluation of a randomly selected mapping in another one of the images; and</claim-text>
<claim-text>generating a mapping record that results from the iterations, the mapping record having a specific sparsity with less than one mapping per pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein a first patch is currently mapped to a second patch, and wherein the second patch is currently mapped to a third patch, the method further comprising determining whether the third patch has a smaller patch distance to the first patch than what the second patch has, and if so mapping the first patch to the third patch instead.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein a first patch is currently mapped to a second patch, and wherein the second patch is currently mapped to a third patch, the method further comprising determining whether the first patch has a smaller patch distance to the second patch than what the third patch has, and if so mapping the second patch to the first patch instead.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the method further comprising assigning groups of the images to each of multiple working sets, and providing each of multiple processes with at least one of the working sets, wherein each process uses the group of images in the respective working set.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The computer program product of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein assigning the group of images for at least one of the working sets comprises: finding a first subset of the group by choosing random locations in a first image and selecting the images to which the respective random locations are mapped; finding a second subset of the group by choosing random locations in the first image and selecting the images that are mapped to by locations to which the random locations are mapped; and finding a third subset of the group by choosing images at random.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer program product of <claim-ref idref="CLM-00012">claim 12</claim-ref>, the method further comprising ejecting at least some of the images from the working set and replacing them with a new group from the received images, each image in the new group selected based on which of the first, second and third subsets included a corresponding ejected image.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the method further comprising storing the generated mapping record.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the method further comprising resynthesizing one of the received images based, at least in part, on the generated mapping record.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A system comprising:
<claim-text>a repository of images; and</claim-text>
<claim-text>an image processing component that performs iterations to find respective mappings for each patch of pixels in the images to a patch in another one of the images such that the mappings have minimal patch distance, the iterations including at least: (i) evaluation of a nearby-pixel mapping in a current image, (ii) evaluation of a randomly selected mapping in the current image, and (iii) evaluation of a randomly selected mapping in another one of the images; and</claim-text>
<claim-text>generates a mapping record based on the iterations, the mapping record having a specific sparsity with less than one mapping per pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein a first patch is currently mapped to a second patch, and wherein the second patch is currently mapped to a third patch, and wherein the image processing component further determines whether the third patch has a smaller patch distance to the first patch than what the second patch has, and if so maps the first patch to the third patch instead.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein a first patch is currently mapped to a second patch, and wherein the second patch is currently mapped to a third patch, and wherein the image processing component further determines whether the first patch has a smaller patch distance to the second patch than what the third patch has, and if so maps the second patch to the first patch instead.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the image processing component further assigns groups of the images to each of multiple working sets, and provides each of multiple processes with at least one of the working sets, wherein each process uses the group of images in the respective working set.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein assigning the group of images for at least one of the working sets comprises: the image processing component finding a first subset of the group by choosing random locations in a first image and selecting the images to which the respective random locations are mapped; the image processing component finding a second subset of the group by choosing random locations in the first image and selecting the images that are mapped to by locations to which the random locations are mapped; and the image processing component finding a third subset of the group by choosing images at random.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the image processing component further ejects at least some of the images from the working set and replaces them with a new group from the received images, each image in the new group selected based on which of the first, second and third subsets included a corresponding ejected image. </claim-text>
</claim>
</claims>
</us-patent-grant>
