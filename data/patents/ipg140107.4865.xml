<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625958-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625958</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11708774</doc-number>
<date>20070221</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>P2000-165298</doc-number>
<date>20000602</date>
</priority-claim>
<priority-claim sequence="02" kind="national">
<country>JP</country>
<doc-number>P2001-001031</doc-number>
<date>20010109</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1664</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>765</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>386232</main-classification>
<further-classification>386248</further-classification>
<further-classification>386264</further-classification>
<further-classification>386284</further-classification>
<further-classification>386332</further-classification>
<further-classification>386230</further-classification>
</classification-national>
<invention-title id="d2e92">Apparatus and method for image coding and decoding</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5231492</doc-number>
<kind>A</kind>
<name>Dangi et al.</name>
<date>19930700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1412</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5327235</doc-number>
<kind>A</kind>
<name>Richards</name>
<date>19940700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5519446</doc-number>
<kind>A</kind>
<name>Lee</name>
<date>19960500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5731847</doc-number>
<kind>A</kind>
<name>Tsukagoshi</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348589</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5754235</doc-number>
<kind>A</kind>
<name>Urano et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5847770</doc-number>
<kind>A</kind>
<name>Yagasaki</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348563</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5848217</doc-number>
<kind>A</kind>
<name>Tsukagoshi et al.</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386239</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5862300</doc-number>
<kind>A</kind>
<name>Yagasaki et al.</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386230</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5912710</doc-number>
<kind>A</kind>
<name>Fujimoto</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5970072</doc-number>
<kind>A</kind>
<name>Gammenthaler, Jr. et al.</name>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6011598</doc-number>
<kind>A</kind>
<name>Tsuji et al.</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6055270</doc-number>
<kind>A</kind>
<name>Ozkan et al.</name>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6160954</doc-number>
<kind>A</kind>
<name>Ogawa</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386208</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6310915</doc-number>
<kind>B1</kind>
<name>Wells et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6393202</doc-number>
<kind>B1</kind>
<name>Yamauchi et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6424792</doc-number>
<kind>B1</kind>
<name>Tsukagoshi et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386243</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6483945</doc-number>
<kind>B1</kind>
<name>Kato et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6490320</doc-number>
<kind>B1</kind>
<name>Vetro et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6785463</doc-number>
<kind>B2</kind>
<name>Yamauchi et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6788347</doc-number>
<kind>B1</kind>
<name>Kim et al.</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348441</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6801709</doc-number>
<kind>B1</kind>
<name>Park</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386345</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6900845</doc-number>
<kind>B1</kind>
<name>Christopher et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6915531</doc-number>
<kind>B2</kind>
<name>Yun</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725131</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>7010032</doc-number>
<kind>B1</kind>
<name>Kikuchi et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>7020195</doc-number>
<kind>B1</kind>
<name>McMahon</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>7072396</doc-number>
<kind>B2</kind>
<name>Wang</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>7872668</doc-number>
<kind>B2</kind>
<name>Mead et al.</name>
<date>20110100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>7986846</doc-number>
<kind>B2</kind>
<name>Seo et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>7995896</doc-number>
<kind>B1</kind>
<name>Comer et al.</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386337</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2001/0052135</doc-number>
<kind>A1</kind>
<name>Balakrishnan et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2002/0012530</doc-number>
<kind>A1</kind>
<name>Bruls</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2002/0057382</doc-number>
<kind>A1</kind>
<name>Yui</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2002/0176506</doc-number>
<kind>A1</kind>
<name>Ferreira Florencio et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2003/0001981</doc-number>
<kind>A1</kind>
<name>Milne</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348839</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>EP</country>
<doc-number>0665693</doc-number>
<kind>A2</kind>
<date>19950800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>EP</country>
<doc-number>0 915 623</doc-number>
<kind>A1</kind>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>EP</country>
<doc-number>0 989 563</doc-number>
<kind>A2</kind>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>EP</country>
<doc-number>1 001 582</doc-number>
<kind>A2</kind>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>JP</country>
<doc-number>11102550</doc-number>
<kind>A</kind>
<date>19990400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>JP</country>
<doc-number>11285002</doc-number>
<kind>A</kind>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>JP</country>
<doc-number>2000059788</doc-number>
<kind>A</kind>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>WO</country>
<doc-number>WO-99/23560</doc-number>
<kind>A1</kind>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>MPEG-2 Video: ITU-T Recommendation H.262, International Standard ISO/IEC 13818.2, &#x201c;Information Technology&#x2014;Generic Coding of Moving Pictures and Associated Audio Information: Video&#x201d;, (1995) pp. 2-8 and 39-62.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00044">
<othercit>Wee, S.J. et al., &#x201c;Field-to-Frame Transcoding With Spatial and Temporal Downsampling&#x201d;, IEEE, US, Oct. 24, 1999, pp. 271-275.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00045">
<othercit>Hori et al., &#x201c;Annotation of Web Content for Transcoding&#x201d;, W3C NOTE, Jul. 10, 1999, pp. 1-11.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00046">
<othercit>Office Action from Japanese Application No. 2001-136505, dated Feb. 15, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>European Search Report Application No. EP 10176823, dated Apr. 4, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>Hori et al: &#x201c;Annotation of Web content for Transcoding&#x201d;, W3C NOTE. Jul. 10, 1999 XP 002264429, Retrieved from the Internet: URL:http://www.w3/org/TR/annot [retrieved on Dec. 9, 2003].</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>&#x201c;High Definition (HD) Image Formats for Television Production&#x201d;, EBU Technical Jan. 1, 2010, pp. 1-10, XP 55022496, Geneva Retrieved from the Internet: URL:http://tech.ebu.ch/docs/tech/tech3299.pdf [retrieved on Mar. 21, 2012].</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00050">
<othercit>Communication from EP Application No. 01304813.7, dated Feb. 28, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>Office Action from Japanese Application No. 2011-092191, dated Dec. 4, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>14</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>386248</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386264</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386284</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386332</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386232</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386230</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>25</number-of-drawing-sheets>
<number-of-figures>32</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09872147</doc-number>
<date>20010601</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7224890</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11708774</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070147789</doc-number>
<kind>A1</kind>
<date>20070628</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kato</last-name>
<first-name>Motoki</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kato</last-name>
<first-name>Motoki</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Lerner, David, Littenberg, Krumholz &#x26; Mentlik, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Shibru</last-name>
<first-name>Helen</first-name>
<department>2484</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A computer-readable medium has data stored thereon for processing by an image decoding apparatus so that multimedia content is presented in an intended manner by a display. A data recording area contains data representing a converted video stream, at least another stream, and multimedia coding data for controlling display of the video stream and the at least another stream on a common display device. The converted video stream is generated by performing a predetermined conversion process on an original video stream. The predetermined conversion process is controlled by additional information such that a display mismatch between the converted video stream and the at least another stream is avoided. The additional information is based on the multimedia coding data.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="124.29mm" wi="127.00mm" file="US08625958-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="238.25mm" wi="161.46mm" orientation="landscape" file="US08625958-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="249.85mm" wi="160.87mm" orientation="landscape" file="US08625958-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="271.36mm" wi="176.87mm" orientation="landscape" file="US08625958-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="266.62mm" wi="149.52mm" orientation="landscape" file="US08625958-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="250.02mm" wi="148.51mm" orientation="landscape" file="US08625958-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="145.54mm" wi="160.61mm" file="US08625958-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="220.39mm" wi="180.00mm" file="US08625958-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="209.89mm" wi="185.84mm" file="US08625958-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="180.09mm" wi="183.30mm" file="US08625958-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="236.14mm" wi="190.16mm" file="US08625958-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="125.98mm" wi="183.30mm" file="US08625958-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="198.97mm" wi="154.01mm" file="US08625958-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="182.37mm" wi="145.54mm" file="US08625958-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="217.09mm" wi="135.64mm" orientation="landscape" file="US08625958-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="246.04mm" wi="124.21mm" orientation="landscape" file="US08625958-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="274.32mm" wi="177.04mm" file="US08625958-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="261.96mm" wi="165.52mm" file="US08625958-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="233.93mm" wi="153.84mm" orientation="landscape" file="US08625958-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="214.38mm" wi="144.02mm" orientation="landscape" file="US08625958-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="260.86mm" wi="156.13mm" orientation="landscape" file="US08625958-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="243.42mm" wi="174.50mm" orientation="landscape" file="US08625958-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="252.31mm" wi="171.20mm" orientation="landscape" file="US08625958-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="207.35mm" wi="126.75mm" file="US08625958-20140107-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="262.47mm" wi="154.77mm" orientation="landscape" file="US08625958-20140107-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="224.37mm" wi="138.68mm" orientation="landscape" file="US08625958-20140107-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present application is a continuation of U.S. application Ser. No. 09/872,147, filed Jun. 1, 2001, which claims priority from Japanese Application No. P2000-165298, filed Jun. 2, 2000, and Japanese Application No. P2001-001031, filed Jan. 9, 2001, the disclosures of which are incorporated by reference herein.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to an image coding apparatus and method, an image decoding apparatus and method, and a recording medium. More specifically, the present invention relates to an image coding apparatus and method, an image decoding apparatus and method, and a recording medium which are suitable for use in apparatus for re-encoding video streams and recording and reproducing the re-encoded video streams.</p>
<p id="p-0004" num="0003">Digital television broadcasts such as European DVB (Digital Video Broadcast), American DTV (Digital Television) broadcast, and Japanese BS (Broadcast Satellite) digital broadcast use MPEG (Motion Picture Expert Group) 2 transport streams. A transport stream consists of continuous transport packets, each packet carrying video data or audio data, for example. The data length of one transport packet is 188 bytes.</p>
<p id="p-0005" num="0004">Unlike analog television broadcasts, digital television broadcasts are capable of providing services added with multimedia coding data. In these services, data such as video data, audio data, character graphics data, and still picture data, for example, are associated with each other for transmission by the multimedia coding data. For the multimedia coding data, a coding method based on XML (Extensible Markup Language) is used in the Japanese BS digital broadcast, for example. The details of this method are disclosed in ARIB STD-B24 Data Coding And Transmission Specification for Digital Broadcasting, for example.</p>
<p id="p-0006" num="0005">Data such as video data, audio data, character graphics data, and still picture data are each packetized into a transport packet for transmission.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIGS. 1A and 1B</figref> show an example of synthesizing data to be transferred between the sending and receiving sides and a multimedia screen. As shown in <figref idref="DRAWINGS">FIG. 1A</figref>, the sending side sends to the receiving side video data, character graphics data for displaying buttons A through C, text data for displaying &#x201c;XYZABC . . . ,&#x201d; and multimedia coding data for relating these data to each other. The sending side generally denotes a television broadcast station, for example. However, herein it denotes a television broadcast station which includes a recording apparatus (the recording side) which receives and records data transmitted from broadcast stations, as shown in the example illustrated in <figref idref="DRAWINGS">FIG. 1A</figref> including the data which is output from this recording apparatus.</p>
<p id="p-0008" num="0007">The multimedia coding data includes data which can synthesize on the receiving side video data, character graphics data, and text data and display the synthesized data. To be more specific, the multimedia coding data includes the data associated with the display positions of the video, character graphics, and text which are displayed by the size-associated data such as the multimedia plane (the display area of images on the television receiver, for example) size (plane_height and plane_width) and video display size (video_height and video_width), video data, character graphics data, and text data, as shown in <figref idref="DRAWINGS">FIG. 1B</figref>.</p>
<p id="p-0009" num="0008">On the basis of the multimedia coding data, the receiving side processes the video data, the character graphics data, and the text data to display a resultant image, as shown in <figref idref="DRAWINGS">FIG. 1B</figref>.</p>
<p id="p-0010" num="0009">Through the screen on which the above-mentioned image is displayed, the user can receive services such as displaying desired information in the video section by clicking button A corresponding to that information and obtaining, from the text data displayed in the bottom of the screen, the information associated with the matter displayed in the video section, for example.</p>
<p id="p-0011" num="0010">If a television program carried by a transport stream transmitted from a digital television broadcast is recorded without change to a recording medium on the received side, the program can be recorded without its picture and audio qualities being deteriorated at all. However, in order to record as long a television program as possible to a recording medium having a limited recording capacity by presupposing a certain degree of picture quality deterioration, the received video stream must be decoded and then encoded again to lower the bit rate of the transport stream.</p>
<p id="p-0012" num="0011">For example, the re-encoding of the video stream of a television program attached with multimedia coding data to lower its bit rate for recording may be implemented by sub-sampling the image to change writing blocks. However, this approach presents a problem of causing a mismatch in the relationship between the video stream resulting from re-encoding and the multimedia coding data. The following describes an example of this mismatch with reference to <figref idref="DRAWINGS">FIGS. 2A and 2B</figref>.</p>
<p id="p-0013" num="0012">In the example shown in <figref idref="DRAWINGS">FIG. 2A</figref>, the sending side (the recording side) converts the original video writing block to a smaller picture frame at the time of re-encoding. Therefore, as shown in <figref idref="DRAWINGS">FIG. 2B</figref>, on the receiving side (the reproducing side), changes occur in the video display size and position, resulting in a display screen which is different from the display screen intended by the sending side (the display screen to be displayed on the basis of the data before being re-encoded).</p>
<p id="p-0014" num="0013">It is therefore desirable to provide an image coding apparatus and method, an image decoding apparatus and method, and a recording medium, wherein there is no mismatch of information caused in the relationship between a video stream after re-encoding and other data is generated and recorded on the recording side and reproduction on the reproducing side. For example, it is desirable to prevent a smaller picture frame from occurring on the reproducing side by referencing the information generated on the recording side.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0015" num="0014">In carrying out the invention and according to a first aspect thereof, there is provided a first image coding apparatus comprising: inputting means for inputting a multiplexed stream containing multimedia coding data; separating means for separating a video stream from the multiplexed stream input to the separating means from the inputting means; converting means for performing a predetermined converting process on the video stream separated by the separating means; generating means for generating additional information indicating that a mismatch will occur when the converted video stream is displayed on the basis of the multimedia coding data; and outputting means for outputting the converted video stream, the multimedia coding data, and the additional information.</p>
<p id="p-0016" num="0015">The first image coding apparatus may further comprise: coding means for coding the additional information generated by the generating means as data separate from the multiplexed stream containing the converted video stream.</p>
<p id="p-0017" num="0016">The first image coding apparatus may further comprise: coding means for multiplexing the additional information generated by the generating means with the multiplexed stream containing the converted video stream and then coding a multiplexed result.</p>
<p id="p-0018" num="0017">The converting means may convert a video stream picture frame parameter.</p>
<p id="p-0019" num="0018">The conversion by the converting means may include at least a process of decoding the video stream separated by the separating means and a process of encoding the decoded video stream.</p>
<p id="p-0020" num="0019">The additional information generated by the generating means may contain at least one of an original picture frame information and an original screen aspect ratio.</p>
<p id="p-0021" num="0020">The additional information generated by the generating means may contain an original video format and a video format after the conversion.</p>
<p id="p-0022" num="0021">The additional information generated by the generating means may contain an original screen aspect ratio and a screen aspect ratio after the conversion.</p>
<p id="p-0023" num="0022">The additional information generated by the generating means may contain at least one of information indicating whether or not a picture frame of the video stream has been converted by the converting means, information about an original picture frame of the video stream separated by the separating means, and an original screen aspect ratio.</p>
<p id="p-0024" num="0023">In carrying out the invention and according to a second aspect thereof, there is provided a first image coding method comprising the steps of: inputting a multiplexed stream containing multimedia coding data; separating a video stream from the multiplexed stream input in the inputting step; performing a predetermined converting process on the video stream separated in the separating step; generating additional information indicating that a mismatch will occur when the converted video stream is displayed on the basis of the multimedia coding data; and outputting the converted video stream, the multimedia coding data, and the additional information.</p>
<p id="p-0025" num="0024">The first image coding method may further comprise the step of: coding the additional information generated in the generating step as data separate from the multiplexed stream containing the converted video stream.</p>
<p id="p-0026" num="0025">The first image coding method may further comprise: a coding step of multiplexing the additional information generated in the generating step with the multiplexed stream containing the converted video stream and then coding a multiplexed result.</p>
<p id="p-0027" num="0026">A video stream picture frame parameter may be converted in the converting step.</p>
<p id="p-0028" num="0027">The conversion in the converting step may include at least a process of decoding the video stream separated in the separating step and a process of encoding the decoded video stream.</p>
<p id="p-0029" num="0028">The additional information generated in the generating step may contain at least one of original picture frame information and an original screen aspect ratio.</p>
<p id="p-0030" num="0029">The additional information generated in the generating step may contain an original video format and a video format after the conversion.</p>
<p id="p-0031" num="0030">The additional information generated in the generating step may contain an original screen aspect ratio and a screen aspect ratio after the conversion.</p>
<p id="p-0032" num="0031">The additional information generated in the generating step may contain at least one of information indicating whether or not a picture frame of the video stream has been converted in the converting step, information about an original picture frame of the video stream separated in the separating step, and an original screen aspect ratio.</p>
<p id="p-0033" num="0032">In carrying out the invention and according to a third aspect thereof, there is provided a first method for recording a computer-readable program on a first recording medium, the method comprising: inputting a multiplexed stream containing multimedia coding data; separating a video stream from the multiplexed stream input; performing a predetermined converting process on the video stream separated from the multiplexed stream to form a converted video stream; generating additional information indicating that a mismatch will occur when the converted video stream is displayed on the basis of the multimedia coding data; and outputting the converted video stream, the multimedia coding data, and the additional information.</p>
<p id="p-0034" num="0033">In carrying out the invention and according to a fourth aspect thereof, there is provided a second computer-readable medium having data stored thereon for processing by an image decoding apparatus so that multimedia content is presented in an intended manner by a display. The computer-readable medium having a data recording area data representing a converted video stream, at least another stream, and multimedia coding data for controlling display of the video stream and the at least another stream on a common display device, the converted video stream being generated by performing a predetermined conversion process on an original video stream, the predetermined conversion process being controlled by additional information such that a display mismatch between the converted video stream and the at least another stream is avoided, the additional information being based on the multimedia coding data.</p>
<p id="p-0035" num="0034">The additional information may be coded and recorded as data different from a multiplexed stream containing the converted video stream.</p>
<p id="p-0036" num="0035">The additional information may be coded and recorded as multiplexed with a multiplexed stream containing the converted video stream.</p>
<p id="p-0037" num="0036">The video stream may be converted in its picture frame parameter.</p>
<p id="p-0038" num="0037">The video stream may be decoded and then encoded.</p>
<p id="p-0039" num="0038">The additional information may contain at least one of original picture frame information and an original screen aspect ratio.</p>
<p id="p-0040" num="0039">The additional information may contain information about an original video format and information about a video format after the conversion.</p>
<p id="p-0041" num="0040">The additional information may contain information about an original screen aspect ratio and information about a screen aspect ratio after the conversion.</p>
<p id="p-0042" num="0041">The additional information may contain at least one of information indicating whether a picture frame of the video stream has been converted, information about an original picture frame of the video stream, and information about an original screen aspect ratio.</p>
<p id="p-0043" num="0042">In carrying out the invention and according to a fifth aspect thereof, there is provided a first image decoding apparatus comprising: inputting means for inputting a multiplexed stream containing multimedia coding data; separating means for separating a video stream from the multiplexed stream input by the inputting means; decoding means for decoding the video stream separated from said multiplexed stream by the separating means; and processing means for performing a predetermined conversion process on the decoded video stream in accordance with additional information indicating an occurrence of a mismatch when displaying the decoded video stream on the basis of the multimedia decoding data.</p>
<p id="p-0044" num="0043">The first image decoding apparatus may further comprise: acquiring means for acquiring the additional information from data different than the multiplexed stream.</p>
<p id="p-0045" num="0044">The first image decoding apparatus may further comprise: acquiring means for acquiring the additional information from a multiplexed stream containing the additional information.</p>
<p id="p-0046" num="0045">The processing means may convert a picture frame parameter of the video stream.</p>
<p id="p-0047" num="0046">The conversion by the processing means may include at least a process of decoding the video stream separated by the separating means from said multiplexed stream and a process of encoding the decoded video stream.</p>
<p id="p-0048" num="0047">The additional information may contain at least one of information about an original picture frame and information about an original screen aspect ratio.</p>
<p id="p-0049" num="0048">The additional information may contain an original video format and information about a video format after the conversion.</p>
<p id="p-0050" num="0049">The additional information may contain information about an original screen aspect ratio and information about a screen aspect ratio after the conversion.</p>
<p id="p-0051" num="0050">The additional information may contain at least one of information indicating whether a picture frame of the video stream has been converted by the converting means, information about an original picture frame of the video stream separated by the separating means, and information about an original screen aspect ratio.</p>
<p id="p-0052" num="0051">In carrying out the invention and according to a sixth aspect thereof, there is provided a first image decoding method comprising the steps of: inputting a multiplexed stream containing multimedia coding data; separating a video stream from the multiplexed stream input in the inputting step; decoding the video stream separated in the separating step; and performing a predetermined conversion process on the decoded video stream in accordance with additional information indicating an occurrence of a mismatch when displaying the decoded video stream on the basis of the multimedia decoding data.</p>
<p id="p-0053" num="0052">The first image decoding method may further comprise the step of: acquiring the additional information from data different than the multiplexed stream.</p>
<p id="p-0054" num="0053">The first image decoding method may further comprise the step of: acquiring the additional information from a multiplexed stream containing the additional information.</p>
<p id="p-0055" num="0054">A picture frame parameter of the video stream may be converted in the processing step.</p>
<p id="p-0056" num="0055">The conversion in the processing step may include at least a process of decoding the video stream separated from the multiplexed stream in the separating step and a process of encoding the decoded video stream.</p>
<p id="p-0057" num="0056">The additional information may contain at least one of information about an original picture frame and information about an original screen aspect ratio.</p>
<p id="p-0058" num="0057">The additional information may contain an original video format and information about a video format after the conversion.</p>
<p id="p-0059" num="0058">The additional information may contain information about an original screen aspect ratio and information about a screen aspect ratio after the conversion.</p>
<p id="p-0060" num="0059">The additional information may contain at least one of information indicating whether a picture frame of the video stream has been converted in the converting step, information about an original picture frame of the video stream separated in the separating step, and information about an original screen aspect ratio.</p>
<p id="p-0061" num="0060">In carrying out the invention and according to a seventh aspect thereof, there is provided a second method for recording a computer-readable program on a third recording medium, the method comprising the steps of: inputting a multiplexed stream containing multimedia coding data; separating a video stream from the multiplexed stream input in the inputting step; decoding the video stream separated from the multiplexed stream in the separating step; and performing a predetermined conversion process on the decoded video stream in accordance with additional information indicating occurrence of a mismatch when displaying the decoded video stream on the basis of the multimedia decoding data.</p>
<p id="p-0062" num="0061">In carrying out the invention and according to an eighth aspect thereof, there is provided a second image coding apparatus comprising: inputting means for inputting a multiplexed stream; separating means for separating a video stream from the multiplexed stream input by the inputting means; determining means for determining whether multimedia coding data is contained in the multiplexed stream input by the inputting means; generating means for generating coding control information based on the presence of said multimedia coding data for instructing that a display format of the video stream separated by the separating means is not changed; converting means for performing a predetermined conversion process on the video stream separated by the separating means on the basis of the coding control information generated by the generating means; and multiplexing means for generating a multiplexed stream that contains the video stream converted by the converting means.</p>
<p id="p-0063" num="0062">The generating means may provide an instruction not to change any of a picture frame, a video format, and an aspect ratio.</p>
<p id="p-0064" num="0063">In carrying out the invention and according to a ninth aspect thereof, there is provided a second image coding method comprising the steps of: inputting a multiplexed stream; separating a video stream from the multiplexed stream input in the inputting step; determining whether multimedia coding data is contained in the multiplexed stream input in the inputting step; generating coding control information based on the presence of said multimedia coding data in said multiplexed stream for instructing that a display format of the video stream separated in the separating step is not changed; performing a predetermined conversion process on the video stream separated in the separating step on the basis of the coding control information generated in the generating step; and generating a multiplexed stream that contains the video stream converted in the converting step.</p>
<p id="p-0065" num="0064">Coding control information for providing an instruction not to change any of a picture frame, a video format, and an aspect ratio may be generated in the generating step.</p>
<p id="p-0066" num="0065">In carrying out the invention and according to a tenth aspect thereof, there is provided a third method for recording a computer-readable program on a fourth recording medium, the method comprising the steps of: inputting a multiplexed stream; separating a video stream from the multiplexed stream input in the inputting step; determining whether multimedia coding data is contained in the multiplexed stream input in the inputting step; generating coding control information based on the presence of the multimedia coding in the multiplexed stream for instructing that a display format of the video stream separated in the separating step is not changed; performing a predetermined conversion process on the video stream separated in the separating step on the basis of the coding control information generated in the generating step; and generating a multiplexed stream that contains the video stream converted in the converting step.</p>
<p id="p-0067" num="0066">In carrying out the invention and according to an eleventh aspect thereof, there is provided a fifth recording medium comprising a data recording area, wherein coding control information is recorded for instructing that a display format is not changed for a video stream and a multiplexed stream containing a video stream on which a predetermined conversion process has been performed on the basis of the coding control information.</p>
<p id="p-0068" num="0067">As described and according to the first image coding apparatus and method and the program stored in the first recording medium, a video steam is separated from a multiplexed stream containing multimedia coding data, and a predetermined conversion process is performed on the separated video stream, and additional information indicating that a mismatch will occur when displaying the converted video stream on the basis of the multimedia coding data.</p>
<p id="p-0069" num="0068">The second recording medium stores a video stream converted by a predetermined conversion process, the multimedia coding data, and the additional information indicating that a mismatch will occur when displaying the converted video stream on the basis of the above-mentioned multimedia coding data.</p>
<p id="p-0070" num="0069">As described and according to the image decoding apparatus and method and the program stored in the third recording medium, when a video stream is separated from an input multiplexed stream, the separated video stream is decoded, and the decoded video stream is displayed on the basis of multimedia coding data, a mismatch occurs. On the basis of the additional information about this mismatch occurrence, a predetermined conversion process is performed on the decoded video stream. This novel configuration prevents the mismatch from occurring between the video stream and the multimedia coding data.</p>
<p id="p-0071" num="0070">As described and according to the second image coding apparatus and method and the program stored in the fourth recording medium, a video stream is separated from an input multiplexed stream, the input multiplexed stream is checked whether or not multimedia coding data is contained and, if the multimedia coding data is contained, coding control information for giving an instruction not to change the display format of the separated video stream is generated, and a predetermined conversion process is performed on the separated video stream on the basis of the generated coding control information.</p>
<p id="p-0072" num="0071">The fifth recording medium also stores the above-mentioned coding control information giving instruction not to change the display format of a video stream and a multiplexed stream containing the video stream on which a predetermined conversion process has been performed on the basis of the coding control information.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0073" num="0072">These and other objects of the invention will be seen by reference to the description, taken in connection with the accompanying drawings, in which:</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIGS. 1A and 1B</figref> are schematic diagrams illustrating a display screen to be shown on the basis of multimedia coding information;</p>
<p id="p-0075" num="0074"><figref idref="DRAWINGS">FIGS. 2A and 2B</figref> are schematic diagrams illustrating a mismatch which takes place when a video stream is re-encoded;</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating a recording apparatus practiced as one embodiment of the present invention;</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIGS. 4A and 4B</figref> illustrate the operation of a multiplexer shown in <figref idref="DRAWINGS">FIG. 3</figref>;</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIGS. 5A</figref>, <b>5</b>B and <b>5</b>C illustrate the processing by an arrival timestamp adding block;</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 6</figref> illustrates multimedia display sub-information;</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an example of ProgramInfo( ) syntax;</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. 8</figref> illustrates an example of StreamCodingInfo( ) syntax;</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. 9</figref> illustrates the meaning of stream_coding type;</p>
<p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. 10</figref> illustrates the meaning of video_format;</p>
<p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. 11</figref> illustrates the meaning of frame_rate;</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. 12</figref> illustrates the meaning of display_aspect_ratio;</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart describing the processing of coding AV stream and multimedia display sub-information;</p>
<p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart describing the coding processing to be executed for restricting the re-encoding of a multiplexed stream video including multimedia coding data;</p>
<p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. 15</figref> illustrates an example of an input transport stream;</p>
<p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. 16</figref> illustrates an example of a transport stream after the re-encoding of the video stream shown in <figref idref="DRAWINGS">FIG. 15</figref>;</p>
<p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. 17</figref> is a flowchart describing a recording rate control process by a recording apparatus shown in <figref idref="DRAWINGS">FIG. 3</figref>;</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 18</figref> is a flowchart describing another recording rate control process by the recording apparatus shown in <figref idref="DRAWINGS">FIG. 3</figref>;</p>
<p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. 19</figref> illustrates another example of a transport stream resulting from the re-encoding of the video stream;</p>
<p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. 20</figref> illustrates another example of the input transport stream;</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. 21</figref> is a block diagram illustrating a configuration of a reproducing apparatus practiced as one embodiment of the present invention;</p>
<p id="p-0095" num="0094"><figref idref="DRAWINGS">FIGS. 22A and 22B</figref> illustrate a display screen to be shown when multimedia display sub-information is added;</p>
<p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. 23</figref> is a block diagram illustrating another configuration of the recording apparatus practiced as one embodiment of the present invention;</p>
<p id="p-0097" num="0096"><figref idref="DRAWINGS">FIG. 24</figref> is a flowchart describing the processing of reproducing an AV stream which uses multimedia display sub-information;</p>
<p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. 25</figref> is a block diagram illustrating another configuration of the reproducing apparatus practiced as one embodiment of the present invention; and</p>
<p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. 26</figref> illustrates recording media.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0100" num="0099">This invention will be described in further detail by way of example with reference to the accompanying drawings. Now, referring to <figref idref="DRAWINGS">FIG. 3</figref>, there is shown a block diagram illustrating an exemplary configuration of a recording apparatus <b>1</b> practiced as one embodiment of the invention. A transport stream received at an antenna, not shown, is input in a selector <b>10</b>. A program number (a channel number) specified by the user is also input from a terminal <b>11</b> to the selector <b>10</b>. Referring to the received program number, the selector <b>10</b> extracts the specified program from the received transport stream and outputs a partial transport stream. The partial transport stream is input in a demultiplexer <b>12</b> and an analyzing block <b>13</b>.</p>
<p id="p-0101" num="0100">The partial transport stream input in the demultiplexer <b>12</b> is separated into a video stream and other streams (audio, still picture, character graphics, and multimedia coding data for example). The video stream thus obtained is output to a decoder <b>14</b>. The other streams are output to a multiplexer <b>16</b>. In addition to the transport packets other than video, the demultiplexer <b>12</b> outputs the output timing information in the input transport stream of these transport packets to the multiplexer <b>16</b>.</p>
<p id="p-0102" num="0101">The decoder <b>14</b> applies a predetermined decoding scheme, for example, MPEG2 to the input video stream and outputs the decoded video data to an encoder <b>15</b>. Also, the decoder <b>14</b> outputs the stream information about the video stream obtained at decoding to a coding controller <b>18</b>.</p>
<p id="p-0103" num="0102">On the other hand, the analyzing block <b>13</b> analyzes the input transport stream to obtain the stream information about the non-video streams, for example, a bit rate, and outputs it to the coding controller <b>18</b>. The stream information about the non-video streams output from the analyzing block <b>13</b>, the video stream information output from decoder <b>14</b>, and a stream recording bit rate output from a terminal <b>19</b> are input in the coding controller <b>18</b>. From these data, the coding controller <b>18</b> sets the video data coding conditions (coding control information) to be executed by the encoder <b>15</b> and outputs these coding conditions to the encoder <b>15</b> and a coding block <b>20</b>.</p>
<p id="p-0104" num="0103">The coding controller <b>18</b> uses, as a bit rate to be allocated to the video data encoding, a value obtained by subtracting a total value (the data input from the analyzing block <b>13</b>) of the bit rates of the non-video streams from a stream recording bit rate (the data input, via the terminal <b>19</b>, from a controller, not shown, for controlling the operation of the recording apparatus <b>1</b>, for example). The coding controller <b>18</b> sets coding control information such as bit rate and picture frame such that an optimum picture quality can be achieved with the bit rate thus obtained and outputs this coding control information to the encoder <b>15</b> and the coding block <b>20</b>. The details of the coding control information will be described later with reference to <figref idref="DRAWINGS">FIGS. 15 through 20</figref>.</p>
<p id="p-0105" num="0104">When a stream is recorded to a recording medium with a fixed rate, this stream recording bit rate becomes the fixed rate; if a stream is recorded with a variable bit rate, this stream recording bit rate is a mean bit rate per predetermined time. However, the maximum value of the variable bit rate in this case needs to be lower than the maximum recording bit rate ensured by the recording medium concerned.</p>
<p id="p-0106" num="0105">The encoder <b>15</b> encodes (on the basis of MPEG2, for example) the video data output from the decoder <b>14</b> on the basis of the coding control information output from the coding controller <b>18</b> and outputs the resultant video data to the multiplexer <b>16</b>. The video stream from the encoder <b>15</b>, the transport stream packets other than video from the demultiplexer <b>12</b>, and the information about the occurrence timing of the transport stream packets other than video are input in the multiplexer <b>16</b>. On the basis of the input occurrence timing information, the multiplexer <b>16</b> multiplexes the video stream with the transport stream packets, other than video, and outputs the result to the arrival timestamp adding block <b>17</b> as a transport stream.</p>
<p id="p-0107" num="0106"><figref idref="DRAWINGS">FIGS. 4A and 4B</figref> schematically illustrate the above-mentioned processing to be executed by the multiplexer <b>16</b>. <figref idref="DRAWINGS">FIG. 4A</figref> shows the timing of the input transport stream packets. In these figures, the cross-hatched portions indicate the video packets while the white portions indicate the stream packets other than video. As shown in <figref idref="DRAWINGS">FIG. 4A</figref>, the input transport stream packets are continuous; however, the data volume of the video data is reduced by the re-encoding of video data by the encoder <b>15</b>. Consequently, the number of video packets is reduced.</p>
<p id="p-0108" num="0107">As shown in <figref idref="DRAWINGS">FIG. 4B</figref>, the multiplexer <b>16</b> does not change the timing of the stream packets other than video but causes only the timing of the video packets to be different from the original state (shown in <figref idref="DRAWINGS">FIG. 4A</figref>).</p>
<p id="p-0109" num="0108">As shown in <figref idref="DRAWINGS">FIGS. 5A</figref>, <b>5</b>B and <b>5</b>C, the arrival timestamp adding block <b>17</b> adds a header (TP_extra_header) including an arrival timestamp to each of the packets (<figref idref="DRAWINGS">FIG. 5A</figref>) of the input transport stream to generate a source packet (<figref idref="DRAWINGS">FIG. 5B</figref>), arranges the generated source packets continuously (<figref idref="DRAWINGS">FIG. 5C</figref>), and outputs them to a writing block <b>21</b>. The arrival timestamp is information indicative of the timing with which the transport stream packets occur in a transport stream. The writing block <b>21</b> takes the input source packet stream consisting of continuous source packets and records the file to a recording medium <b>22</b>. It should be noted that the recording medium <b>22</b> may be any type of recording medium.</p>
<p id="p-0110" num="0109">The information output from the coding block <b>20</b> is also input in the writing block <b>21</b>. On the basis of the video coding information from the coding controller <b>18</b>, the coding block <b>20</b> generates multimedia display sub-information and outputs the same to the writing block <b>21</b>. The multimedia display sub-information to be output to the writing block <b>21</b> is information for keeping the video display position and display size unchanged on multimedia plane from those of the image (the image which would be displayed without re-encoding) intended by the sending side even if the picture frame size has changed by transcoding (decoding by the decoder <b>14</b> and then encoding by the encoder <b>15</b>) a video stream. This information also is used at the time of reproduction in combination with multimedia coding data.</p>
<p id="p-0111" num="0110">The following describes the multimedia display sub-information more specifically. As shown in <figref idref="DRAWINGS">FIG. 6</figref>, the multimedia display sub-information consists of three flags of a mismatch flag (mismatch_MMinfo_flag), a re-encoded flag (Re_encoded_flag), and a frame size change flag (changed_frame_size_flag), data associated with two sizes indicative of an original horizontal size (original_horizontal_size) and an original vertical size (original_vertical_size), and an original screen aspect ratio (original_display_aspect_ratio).</p>
<p id="p-0112" num="0111">The mismatch flag indicates whether there exists a mismatch in the relationship between video and multimedia coding data. The re-encoded flag indicates whether the video has been re-encoded at the time of recording. The frame size change flag indicates whether the picture frame of video has been changed by re-encoding, for example. The original horizontal size indicates the horizontal size of a picture frame before re-encoding. The original vertical size indicates the vertical size of a picture frame before re-encoding. The original screen aspect ratio indicates the aspect ratio of a frame screen before re-encoding.</p>
<p id="p-0113" num="0112">It should be noted that the above-mentioned multimedia display sub-information is illustrative only. Therefore, information other than that shown in <figref idref="DRAWINGS">FIG. 6</figref> may be included in, or part of the information shown in <figref idref="DRAWINGS">FIG. 6</figref> may be excluded from, the multimedia display sub-information.</p>
<p id="p-0114" num="0113">The following describes another example of the multimedia display sub-information. In the following example, the multimedia display sub-information is stored in a ProgramInfo( ) syntax shown in <figref idref="DRAWINGS">FIG. 7</figref>. The following describes the fields associated with the present invention in the ProgramInfo( ) syntax.</p>
<p id="p-0115" num="0114">&#x201c;length&#x201d; indicates the number of bytes between the byte just after the length field and the last byte of ProgramInfo( ) inclusive.</p>
<p id="p-0116" num="0115">&#x201c;num_of_program_sequences&#x201d; indicates the number of program sequences in the an AV stream file. A source packet sequence with which the program contents specified by this format in the AV stream file are constant is referred to as a program sequence.</p>
<p id="p-0117" num="0116">&#x201c;SPN_program_sequences_start&#x201d; indicates an address at which the program sequence starts in the AV stream file. &#x201c;SPN_program_sequences_start&#x201d; is of a size in unit of source packet number and counted from the initial value 0 starting with the first packet of the AV stream file.</p>
<p id="p-0118" num="0117">&#x201c;program_map_PID&#x201d; is value of the PID of a transport packet having PMT (Program Map Table) applicable to that program sequence.</p>
<p id="p-0119" num="0118">&#x201c;num_of_streams_in_ps&#x201d; indicates the number of elementary streams defined in that program sequence.</p>
<p id="p-0120" num="0119">&#x201c;stream_PID&#x201d; indicates the value of the PID for the elementary stream defined in the PMT which is referenced by the program map PID of that program sequence.</p>
<p id="p-0121" num="0120">&#x201c;StreamCodingInfo( )&#x201d; indicates the information about the elementary stream indicated by the above-mentioned stream PID.</p>
<p id="p-0122" num="0121"><figref idref="DRAWINGS">FIG. 8</figref> shows the syntax of StreamCodingInfo( ). &#x201c;length&#x201d; indicates the number of bytes between the byte just after this length field and the last byte of StreamCodingInfo( ) inclusive.</p>
<p id="p-0123" num="0122">&#x201c;stream_coding_type&#x201d; indicates the coding type of the elementary stream indicated by the stream PID for this StreamCodingInfo( ). The meanings of the individual types are shown in <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0124" num="0123">If the value of stream coding type is 0x02, it indicates that the elementary stream indicated by the stream PID is a video stream.</p>
<p id="p-0125" num="0124">If the value of stream coding type is 0x0A, 0x0B, or 0x0D, it indicates that the elementary stream indicated by the stream PID is multimedia coding data.</p>
<p id="p-0126" num="0125">If the value of stream coding type is 0x06, it indicates that the elementary stream indicated by the stream PID is subtitles or teletext.</p>
<p id="p-0127" num="0126">&#x201c;video_format&#x201d; indicates the video format of a video stream indicated by the stream PID for this StreamCodingInfo( ). The meanings of the individual video formats are shown in <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0128" num="0127">In <figref idref="DRAWINGS">FIG. 10</figref>, 480i indicates video display of NTSC standard TV (interlace frame of 720 pixels&#xd7;480 lines). 576i indicates video display of PAL standard TV (interlace frame of 720 pixels&#xd7;576 lines). 480p indicates video display of progressive frame of 720 pixels&#xd7;480 lines. 1080i indicates video display of interlace frame of 1920 pixels&#xd7;1080 lines. 720p indicates video display of progressive frame of 1230 pixels&#xd7;720 lines.</p>
<p id="p-0129" num="0128">&#x201c;frame_rate&#x201d; indicates the frame rate of a video stream indicated by the stream PID for this StreamCodingInfo( ). The meanings of the individual frame rates are shown in <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0130" num="0129">&#x201c;display_aspect_ratio&#x201d; indicates the display aspect ratio of a video stream indicated by the stream PID for this StreamCodingIndo( ). The meaning of the individual display aspect ratios are shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0131" num="0130">&#x201c;original_video_format_flag&#x201d; indicates whether there exists original video format and original display aspect ratio in this StreamCodingInfo( ).</p>
<p id="p-0132" num="0131">&#x201c;original_video_format&#x201d; indicates a video format before a video stream indicated by the stream PID for this StreamCodingInfo( ) is coded. The meanings of the individual original video formats are the same as shown in <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0133" num="0132">&#x201c;original_display_aspect_ratio&#x201d; is the display aspect ratio before a video stream indicated by the stream PID for this StreamCodingInfo( ) is coded. The meanings of the individual aspect ratios are the same as shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0134" num="0133">It is assumed that, in transcoding a transport stream with a multimedia data stream (BML stream or subtitles) multiplexed along with a video stream, the re-encoding of the video stream changes its video format (for example, from 1080i to 480i), while the multimedia data stream retains its original stream contents. In this case, a mismatch in information may occur between a new video stream and the multimedia data stream. For example, although the parameters associated with the display of the multimedia data stream are determined on the supposition of the video format of the original video stream, the video format may be changed by the re-encoding of the video stream.</p>
<p id="p-0135" num="0134">The video format of the original video stream is indicated by the video format and the display aspect ratio. The video format of the re-encoded video stream is indicated by the original video format and the original display aspect ratio.</p>
<p id="p-0136" num="0135">If a mismatch exists between the values of the video format and the original video format and/or between the display aspect ratio and the original display aspect ratio, it indicates that a video format change has been caused by the video re-encoding at the time of recording.</p>
<p id="p-0137" num="0136">If the stream PID in which the stream coding type indicates multimedia coding data and subtitles are included in ProgramInfo( ), it indicates that the multimedia data is multiplexed in an AV stream file (a transport stream).</p>
<p id="p-0138" num="0137">If ProgramInfo( ) indicates that a video format change has been caused by the re-encoding of video at the time of recording and multimedia data is multiplexed in the AV stream file, then it is determined that a mismatch exists in display between the video stream (re-encoded) and the multimedia data (the original multimedia data) in the AV stream file.</p>
<p id="p-0139" num="0138">In such a case, the information about the original video stream, namely the original video format and the original display aspect ratio, becomes effective. The reproducing apparatus generates a display screen from the above-mentioned new video stream and multimedia data stream as follows.</p>
<p id="p-0140" num="0139">The video stream is up-sampled to a video format indicated by the original video format and the original display aspect ratio.</p>
<p id="p-0141" num="0140">The up-sampled image and the multimedia data stream are synthesized to form a correct display screen.</p>
<p id="p-0142" num="0141">The multimedia display sub-information generated by the coding block <b>20</b> is recorded by the writing block <b>21</b> to the recording medium <b>22</b> but stored as a file which is different from the source packet stream file output from the arrival timestamp adding block <b>17</b>. If the multimedia display sub-information is recorded by the writing block <b>21</b> to the recording medium <b>22</b> as a file different from the source packet stream file, the filed multimedia display sub-information is output from the coding block <b>20</b>.</p>
<p id="p-0143" num="0142"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart describing the processing of coding an AV stream and multimedia display sub-information.</p>
<p id="p-0144" num="0143">In step <b>50</b>, a multiplexed stream including multimedia coding data is input in the recording apparatus <b>1</b>.</p>
<p id="p-0145" num="0144">In step <b>51</b>, the demultiplexer <b>12</b> separates the video stream from the multiplexed stream.</p>
<p id="p-0146" num="0145">In step <b>52</b>, the encoder <b>15</b> re-encodes the video stream decoded by the decoder <b>14</b>.</p>
<p id="p-0147" num="0146">In step <b>53</b>, the multiplexer <b>16</b> multiplexes the above-mentioned video stream and multimedia coding data to generate a multiplexed stream.</p>
<p id="p-0148" num="0147">In step <b>54</b>, the coding block <b>20</b> generates multimedia display sub-information.</p>
<p id="p-0149" num="0148">In the above description, the coding controller <b>18</b> generates the coding control information including bit rate and picture frame on the basis of the input data. The coding controller <b>18</b> may generate the following information as alternative coding control information. Namely, if the input transport stream is found to include multimedia coding data by the analyzing block <b>13</b>, then the coding controller <b>18</b> may generate coding control information when encoding is executed by the encoder <b>15</b> for instructing the encoder <b>15</b> to execute the re-encoding with a picture frame (the picture frame before re-encoding) of the same size as that of the picture frame of the original video, and output the generated coding control information to the encoder <b>15</b>.</p>
<p id="p-0150" num="0149">When the above-mentioned method is used, the encoder <b>15</b> re-encodes the video data supplied from the decoder <b>14</b> with the same value as that of the picture frame of the original video stream on the basis of the input coding control information. If such coding control information is generated and the re-encoding is executed on the basis of the coding control information, no picture frame change is caused by the re-encoding, thereby preventing a mismatch from occurring in the relationship between the video stream obtained by re-encoding and the multimedia coding data.</p>
<p id="p-0151" num="0150">Still alternatively, the following information may be generated as the coding control information generated by the coding controller <b>18</b>. Namely, if the input transport stream is found to include multimedia coding data by the analyzing block <b>13</b>, then the coding controller <b>18</b> may generate coding control information when encoding is executed by the encoder <b>15</b> for instructing the encoder <b>15</b> to execute the re-encoding under the same conditions as the video format (shown in <figref idref="DRAWINGS">FIG. 10</figref>) and screen aspect ratio (shown in <figref idref="DRAWINGS">FIG. 12</figref>) of the original video, and output the coding control information to the encoder <b>15</b>.</p>
<p id="p-0152" num="0151">When the above-mentioned method is used, the encoder <b>15</b> re-encodes the video supplied from the decoder <b>14</b> under the same conditions as the video format (shown in <figref idref="DRAWINGS">FIG. 10</figref>) and screen aspect ratio (shown in <figref idref="DRAWINGS">FIG. 12</figref>) of the original video on the basis of the input coding control information. If such coding control information is generated and the re-encoding is executed on the basis of the coding control information, no video format and no screen aspect ratio change is caused by the re-encoding, thereby preventing a mismatch from occurring in the relationship between the video stream obtained by re-encoding and the multimedia coding data.</p>
<p id="p-0153" num="0152"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart describing the coding for restricting the re-encoding of the video of a multiplexed stream including multimedia coding data.</p>
<p id="p-0154" num="0153">In step <b>70</b>, a multiplexed stream is input in the recording apparatus <b>1</b>.</p>
<p id="p-0155" num="0154">In step <b>71</b>, the demultiplexer <b>12</b> separates the video stream from the multiplexed stream.</p>
<p id="p-0156" num="0155">In step <b>72</b>, the analyzing block <b>13</b> checks if the multimedia coding data is included in the video stream. If the multimedia coding data is included, the analyzing block <b>13</b> sends the coding control information to the encoder <b>15</b> instructing the same to re-encode the video stream without changing the display format. On the basis of the supplied control information, the encoder <b>15</b> re-encodes the video stream.</p>
<p id="p-0157" num="0156">In step <b>73</b>, the multiplexer <b>16</b> generates a multiplexed stream including the above-mentioned video stream.</p>
<p id="p-0158" num="0157">With reference to <figref idref="DRAWINGS">FIGS. 15 through 20</figref>, the following describes one example of control to be executed on the basis of the coding control information.</p>
<p id="p-0159" num="0158">It is assumed here that a transport stream to be input to the selector <b>10</b> has a constant bit rate R<sub>I </sub>as shown in <figref idref="DRAWINGS">FIG. 15</figref>, for example. The video stream and the non-video streams are coded by variable bit rates. In the example shown in <figref idref="DRAWINGS">FIG. 15</figref>, in unit time (for example, GOP) A, the bit rate of the video stream is R<sub>VA </sub>and the bit rate of non-video streams is R<sub>OA</sub>. In unit time B, the bit rate of the video stream is R<sub>VB </sub>and the bit rate of non-video streams is R<sub>OB</sub>. In unit time C, the bit rate of the video stream is R<sub>VC </sub>and the bit rate of non-video streams is R<sub>OC</sub>.</p>
<p id="p-0160" num="0159">If the transport stream as shown in <figref idref="DRAWINGS">FIG. 15</figref> is re-encoded to output the transport stream having fixed bit rate S (S&#x3c;R<sub>I</sub>) as shown in <figref idref="DRAWINGS">FIG. 16</figref> from the multiplexer <b>16</b>, the coding controller <b>18</b> executes the processing described by the flowchart shown in <figref idref="DRAWINGS">FIG. 17</figref>.</p>
<p id="p-0161" num="0160">First, in step S<b>1</b>, the coding controller <b>18</b> sets the bit rate to S (recording rate) of a transport stream to be output from the multiplexer <b>16</b> on the basis of a control signal input from a controller, not shown, via the terminal <b>19</b>. Next, in step S<b>2</b>, the coding controller <b>18</b> determines non-video streams to be recorded and computes a maximum total value D of the bit rates of the determined streams.</p>
<p id="p-0162" num="0161">The maximum value D is determined from the stream specification of the input transport stream. For example, if two audio streams are to be recorded in addition to the video stream, the maximum value D is 384&#xd7;2 Kbps since the maximum value of the bit rate of one audio stream is 384 Kbps according to the Japanese digital BS broadcast stream specification.</p>
<p id="p-0163" num="0162">In step S<b>3</b>, the coding controller <b>18</b> uses value C obtained by subtracting the maximum value D computed in step S<b>2</b> from the recording bit rate set in step S<b>1</b> (C=S&#x2212;D), as a bit rate to be allocated to the re-encoding of the video data. In step S<b>4</b>, the coding controller <b>18</b> analyzes the coding information such as the video stream bit rate and picture frame from the video stream information output from the decoder <b>14</b>.</p>
<p id="p-0164" num="0163">In step S<b>5</b>, the coding controller <b>18</b> determines, on the basis of the value C computed in step S<b>3</b> and the video stream coding information analyzed in step S<b>4</b>, a video coding parameter (video coding control information) such that an optimum picture quality is achieved.</p>
<p id="p-0165" num="0164">For example, in the example shown in <figref idref="DRAWINGS">FIG. 16</figref>, value S is &#xbd; of value R<sub>I</sub>. In the present example, the bit rate of steams other than video is the maximum value D, which is used without change as the bit rate of non-video steams in a multiplexed stream after re-encoding.</p>
<p id="p-0166" num="0165">Then, video coding parameters are determined such that an optimum picture quality can be achieved within the range of (S&#x2212;D). If the picture frame is controlled, the horizontal direction of a picture frame of 720&#xd7;480 pixels, for example, is sampled by &#xbd; into 360&#xd7;480 pixels. The determined, coding parameters (bit rate and picture angle) are supplied to the encoder <b>15</b> as video coding control information.</p>
<p id="p-0167" num="0166">In step S<b>6</b>, on the basis of the video coding control information supplied from the coding controller <b>18</b>, the encoder <b>15</b> re-encodes the video data of unit time (in this example, unit time A) to be processed now. In the example shown in <figref idref="DRAWINGS">FIG. 16</figref>, the actual bit rate R<sub>OA </sub>is smaller than the maximum value D in unit time A; however, since the maximum value D is fixed, the video allocated bit rate becomes (S&#x2212;D). A wasted portion Rsa which cannot be used for video coding occurs because the maximum value D is fixed. The wasted portion is filled with stuffing bits.</p>
<p id="p-0168" num="0167">In step S<b>7</b>, the coding controller <b>18</b> determines whether there remains any stream to be re-encoded. If any streams remain to be re-encoded, the procedure returns to step S<b>4</b> to repeat the above-mentioned processes.</p>
<p id="p-0169" num="0168">If, in step S<b>7</b>, no more streams remain to be re-encoded, this processing comes to an end.</p>
<p id="p-0170" num="0169">Thus, in the example shown in <figref idref="DRAWINGS">FIG. 16</figref>, in unit time B, the bit rate of non-video streams also is D and the video stream allocated bit rate is S&#x2212;D because it is fixed. Stuffing bits are inserted in value R<sub>sb </sub>(R<sub>sb</sub>=S&#x2212;(S&#x2212;D)&#x2212;R<sub>OB</sub>=D&#x2212;R<sub>OB</sub>).</p>
<p id="p-0171" num="0170">In unit time C, too, the bit rate of non-video streams is D and the video stream allocated bit rate is S&#x2212;D. It should be noted that, in unit time C,</p>
<p id="p-0172" num="0171">D=R<sub>OC</sub>, so that no stuffing bits exist.</p>
<p id="p-0173" num="0172">Thus, in the example shown in <figref idref="DRAWINGS">FIG. 16</figref>, the video stream is coded with a fixed bit rate.</p>
<p id="p-0174" num="0173"><figref idref="DRAWINGS">FIG. 18</figref> is a flowchart describing a processing example in which the video re-encoding allocated bit rate is variable. First, in step S<b>21</b>, the coding controller <b>18</b> sets recording rate S on the basis of the information supplied via the terminal <b>19</b>. Next, in step S<b>22</b>, the coding controller <b>18</b> analyzes the coding information of the video stream on the basis of the video stream information supplied from the decoder <b>14</b>. The processes of steps S<b>21</b> and S<b>22</b> are the same as those of steps S<b>1</b> and S<b>4</b> of <figref idref="DRAWINGS">FIG. 17</figref>.</p>
<p id="p-0175" num="0174">In step S<b>23</b>, the coding controller <b>18</b> computes, from the output of the analyzing block <b>13</b>, the total bit rate B in each unit time of non-video streams.</p>
<p id="p-0176" num="0175">In step S<b>24</b>, the coding controller <b>18</b> uses, as the video re-encoding allocated bit rate, value C (C=S&#x2212;B) obtained by subtracting value B obtained in step S<b>23</b> from value S obtained in S<b>1</b>.</p>
<p id="p-0177" num="0176">In step S<b>25</b>, the coding controller <b>18</b> determines, on the basis of value C obtained in step S<b>24</b> and a result of analysis of the video stream coding information obtained in step S<b>22</b>, video coding parameters such that an optimum picture quality is obtained. The determined coding parameters are output to the encoder <b>15</b>.</p>
<p id="p-0178" num="0177">In step S<b>26</b>, the encoder <b>15</b> re-encodes the video data of the current unit time on the basis of the coding parameters determined in step S<b>25</b>. Consequently, as shown in <figref idref="DRAWINGS">FIG. 19</figref>, for example, after allocation of R<sub>oa </sub>(=R<sub>OA</sub>) as the bit rate in unit time of non-video streams, the bit rate of the video stream is set to bit rate R<sub>va </sub>specified by (S&#x2212;R<sub>oa</sub>).</p>
<p id="p-0179" num="0178">In step S<b>27</b>, the coding controller <b>18</b> determines whether any streams remain to be processed. If any streams remain to be processed, the procedure returns to step S<b>22</b> to repeat the above-mentioned processes. If no more streams remain to be processed, this processing comes to an end.</p>
<p id="p-0180" num="0179">Thus, in unit time B, after allocation of bit rate R<sub>ob </sub>(=S&#x2212;R<sub>OB</sub>) of non-video streams, the remaining R<sub>vb </sub>(=S&#x2212;R<sub>ob</sub>) is the bit rate of the video stream. In unit time C, the bit rate of the video stream is set to R<sub>vc </sub>(=S&#x2212;R<sub>OC</sub>), except for bit rate Roc of non-video streams.</p>
<p id="p-0181" num="0180">Thus, in the present processing example, the bit rate of the video stream is variable and, therefore, no stuffing bit is needed or the number of stuffing bits can be reduced, thereby coding the video stream more efficiently.</p>
<p id="p-0182" num="0181">In the above, the input transport stream has a fixed bit rate. The present invention also is applicable to an example in which the bit rate of the input transport stream is variable as shown in <figref idref="DRAWINGS">FIG. 20</figref>.</p>
<p id="p-0183" num="0182">Consequently, a transport stream of longer content can be recorded to the recording medium <b>22</b> at a lower bit rate as required.</p>
<p id="p-0184" num="0183">In addition, the above-mentioned novel embodiment prevents the qualities of audio data, still picture and character graphics data, multimedia coding data, and other non-video data from being conspicuously deteriorated. The non-video data is basically smaller in data volume than video data, so that reducing the bit rate of the non-video data in the same ratio as the bit rate of video data makes the effects on the non-video data relatively greater than those on video data. The novel embodiment can prevent these effects from being caused.</p>
<p id="p-0185" num="0184">The following describes the reproduction of a source packet stream file recorded on the recording medium <b>22</b>. Referring to <figref idref="DRAWINGS">FIG. 21</figref>, there is shown a block diagram illustrating the configuration of a reproducing apparatus practiced as one embodiment of the invention. A source packet stream file recorded on the recording medium <b>22</b> is read by a reading block <b>31</b>. The reading block <b>31</b> also reads multimedia display sub-information recorded on the recording medium <b>22</b> as a file separate from the source packet stream file.</p>
<p id="p-0186" num="0185">The source packet stream read by the reading block <b>31</b> is output to a arrival timestamp separating block <b>32</b> and the multimedia display sub-information is output to a synthesizing block <b>36</b>. The arrival timestamp separating block <b>32</b> incorporates a reference clock. The arrival time stamp separating block <b>32</b> compares the reference clock with the value of the arrival timestamp added to the source packet of the input source packet stream and, when a match is found, removes the arrival timestamp from the source packet having the matching arrival timestamp, outputting the resultant packet to a demultiplexer <b>33</b> as a transport stream packet.</p>
<p id="p-0187" num="0186">The demultiplexer <b>33</b> separates the input transport stream into a video/audio stream and data streams such as multimedia coding data, character graphics, text, and still picture. Of these separated data, the video/audio stream is output to an AV decoder <b>34</b>, the multimedia coding data is output to the synthesizing block <b>36</b>, and the data stream such as character graphics, text, and still picture is output to a character graphics/still picture decoder <b>35</b>.</p>
<p id="p-0188" num="0187">The AV decoder <b>34</b> separates the input video/audio stream into video data and audio data, decodes each data, and outputs the decoded audio data to an audio reproducing device, not shown, and the decoded video data to the synthesizing block <b>36</b>. The character graphics/still picture decoder <b>35</b> decodes the input data stream, such as character graphics, text, and still picture, and outputs the decoded character graphics data, text data, and still picture data to the synthesizing block <b>36</b>.</p>
<p id="p-0189" num="0188">In the synthesizing block <b>36</b>, the video data from the AV decoder <b>34</b>, the multimedia coding data from the demultiplexer <b>33</b>, the data from the character graphics/still picture decoder <b>35</b>, and the multimedia display sub-information from the reading block <b>31</b> are input. Checking the mismatch flag (<figref idref="DRAWINGS">FIG. 6</figref>) of the input multimedia display sub-information, the synthesizing block <b>36</b> determines whether a mismatch exists in the relationship between the input video signal and the multimedia coding data.</p>
<p id="p-0190" num="0189">If a mismatch exists between the value of video format and the value of original video format shown in <figref idref="DRAWINGS">FIG. 8</figref> and/or a mismatch exists between the value of display aspect ratio and the original display aspect ratio, the synthesizing block <b>36</b> determines that a video format change has been caused by the video re-encoding at the time of recording, detecting a mismatch in the relationship between the input video signal and the multimedia encoding data. If no mismatch exists between the value of video format and the value of original video format and no mismatch exists between the value of display aspect radio and the value of original display aspect ratio, the synthesizing block <b>36</b> determines that no mismatch exists in the relationship between the input video signal and the multimedia coding data.</p>
<p id="p-0191" num="0190">If a mismatch is found in the relationship between the input video signal and the multimedia coding data, the synthesizing block <b>36</b> further references the original horizontal size and vertical size of the multimedia display sub-information or references the original video format and the original display aspect ratio. Then, the synthesizing block <b>36</b> scale-converts the input video signal so that it can be displayed in a frame of the referenced size. On the basis of the multimedia coding data, the synthesizing block <b>36</b> outputs the video signal with the scale-converted video signal and the data, such as character graphics synthesized on a multimedia plane, to a television receiver, not shown, which serves as a display device.</p>
<p id="p-0192" num="0191">On the other hand, if no mismatch is found in the relationship between the input video signal and the multimedia coding data, the synthesizing block <b>36</b> synthesizes the input video signal with other data on a multimedia plane without scale conversion and outputs the synthesized data.</p>
<p id="p-0193" num="0192">Thus, recording the multimedia display sub-information and using it at the time of reproduction allow the receiving side to display a screen as intended on the sending side. Referring to <figref idref="DRAWINGS">FIG. 22</figref>, if the re-encoding on the sending side (recording side) results in a smaller video picture frame than the original, the size reduction is recorded as multimedia display sub-information, which is referenced at the time of reproduction. Consequently, because there exists no mismatch between video data and other data, the receiving side (the reproduction side) can display the same screen as the original.</p>
<p id="p-0194" num="0193"><figref idref="DRAWINGS">FIG. 24</figref> is a flowchart describing AV stream reproduction processing which uses multimedia display sub-information.</p>
<p id="p-0195" num="0194">In step <b>60</b>, a multiplexed stream including multimedia coding data is read from a recording medium and input in a reproduction device.</p>
<p id="p-0196" num="0195">In step <b>61</b>, multimedia display sub-information is input. This information is read from the recording medium in the case of the reproducing device shown in <figref idref="DRAWINGS">FIG. 21</figref>; in the case of a reproducing device shown in <figref idref="DRAWINGS">FIG. 25</figref>, this information is separated from the multiplexed stream.</p>
<p id="p-0197" num="0196">In step <b>62</b>, a video stream is separated from the multiplexed stream.</p>
<p id="p-0198" num="0197">In step <b>63</b>, the video stream is decoded.</p>
<p id="p-0199" num="0198">In step S<b>64</b>, if a mismatch exists between the video data and the multimedia coding data, the synthesizing block <b>36</b> scale-converts the video data on the basis of the multimedia display sub-information.</p>
<p id="p-0200" num="0199">In step <b>65</b>, the synthesizing block <b>36</b> synthesizes the processed image and the multimedia data to generate a display image.</p>
<p id="p-0201" num="0200">As described, the multimedia display sub-information may be recorded on the recording medium <b>22</b> as a file which is different from the source packet stream file containing character graphics data and video signals. Alternatively, the multimedia display sub-information may be embedded in a source packet stream file and then recorded on the recording medium <b>22</b>. <figref idref="DRAWINGS">FIG. 23</figref> shows the configuration of the recording apparatus <b>1</b> in which the multimedia display sub-information is embedded in a source packet stream file.</p>
<p id="p-0202" num="0201">In comparison between the configuration of the recording apparatus <b>1</b> shown in <figref idref="DRAWINGS">FIG. 23</figref> and the configuration shown in <figref idref="DRAWINGS">FIG. 3</figref>, the former outputs the multimedia display sub-information output from the coding block <b>20</b> and supplies this output to the multiplexer <b>16</b>. The multiplexer <b>16</b> then generates a transport packet of the input multimedia display sub-information and embeds it into a source packet stream file, outputting the same to the arrival timestamp adding block <b>17</b>. Instead of embedding the multimedia display sub-information into a source packet stream file as a transport packet, the multimedia display sub-information may be written to a user data area in an MPEG video stream.</p>
<p id="p-0203" num="0202">In the present embodiment of the invention, video data may be re-encoded using other methods than that described above; for example, an input video stream may be converted in the DCT area to convert the coding parameters such as picture frame.</p>
<p id="p-0204" num="0203"><figref idref="DRAWINGS">FIG. 25</figref> shows the configuration of the reproducing apparatus <b>30</b> in which the multimedia display sub-information is embedded in a source packet stream file to be recorded on the recording medium <b>22</b>. In comparison between the configuration of the reproducing apparatus shown in <figref idref="DRAWINGS">FIG. 25</figref> and the configuration shown in <figref idref="DRAWINGS">FIG. 21</figref>, the former reads only the source packet stream through the reading block <b>31</b>. The source packet stream read by the reading block <b>31</b> is input to the demultiplexer <b>33</b> via the arrival timestamp separating block <b>32</b>.</p>
<p id="p-0205" num="0204">The demultiplexer <b>33</b> extracts the multimedia display sub-information from the input source packet stream file and outputs the extracted information to the synthesizing block <b>36</b>. The further processing is the same as that of the configuration shown in <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0206" num="0205">Thus, if the multimedia display sub-information is recorded as embedded in a source packet stream file, the receiving side can also obtain the video picture size and display position intended by the sending side.</p>
<p id="p-0207" num="0206">In the present embodiment of the invention, a transport stream was used as an example. The present invention also is applicable to multiplexed streams such as a program stream.</p>
<p id="p-0208" num="0207">The above-described sequence of processing operations can be executed by hardware as well as software. In the software approach, the recording apparatus <b>1</b> (and the reproducing apparatus <b>30</b>) is constituted by a personal computer as shown in <figref idref="DRAWINGS">FIG. 26</figref>.</p>
<p id="p-0209" num="0208">Referring to <figref idref="DRAWINGS">FIG. 26</figref>, a CPU (Central Processing Unit) <b>101</b> executes various processing operations as instructed by programs stored in a ROM (Read Only Memory) <b>102</b> or loaded from a storage block <b>108</b> into a RAM (Random Access Memory) <b>103</b>. The RAM <b>103</b> also stores, as required, the data necessary for the CPU <b>101</b> to execute various processing operations.</p>
<p id="p-0210" num="0209">The CPU <b>101</b>, the ROM <b>102</b>, and the RAM <b>103</b> are interconnected via a bus <b>104</b>. The bus <b>104</b> also is connected to an input/output interface <b>105</b>.</p>
<p id="p-0211" num="0210">The input/output interface <b>105</b> is connected to an input block <b>106</b>, such as a keyboard and a mouse, a display device such as a CRT or LCD, an output block <b>107</b>, such as a speaker, a storage block <b>108</b> such as hard disk, and a communication block <b>109</b> such as modem or terminal adapter. The communication block <b>109</b> executes communication processing via a network.</p>
<p id="p-0212" num="0211">The input/output interface <b>105</b> also is connected to a drive <b>110</b>, as required, in which a magnetic disc <b>121</b>, an optical disc <b>122</b>, a magneto-optical disc <b>123</b>, or a semiconductor memory <b>124</b> is loaded. Computer programs read from these storage media are installed in the storage block <b>108</b> as required.</p>
<p id="p-0213" num="0212">The execution of a sequence of processing operations by software requires the use of a computer having a dedicated hardware device storing beforehand the programs constituting the software or a general-purpose computer in which these programs are installed, as required, from a recording medium.</p>
<p id="p-0214" num="0213">The program recording medium for storing computer-readable and executable programs may be a package medium which is distributed to users providing programs and embodied by, the magnetic disk <b>121</b> (including floppy disk), the optical disc <b>122</b> (including CD-ROM (Compact Disc-Read Only Memory) and DVD (Digital Versatile Disc)), the magneto-optical disk <b>123</b> (including MD (Mini Disk)), the semiconductor memory <b>124</b>, a ROM <b>102</b> or a hard disk which is preinstalled in a personal computer and provided for users and on which the programs are stored temporarily or permanently as shown in <figref idref="DRAWINGS">FIG. 26</figref>.</p>
<p id="p-0215" num="0214">It should be noted that the steps describing the programs to be stored on the program storage medium are not only executed in a time-dependent manner in the order described, but also in parallel or in a discrete manner.</p>
<p id="p-0216" num="0215">As described, and according to the first image coding apparatus and method and the program stored in the first recording medium, a video steam is separated from a multiplexed stream containing multimedia coding data, a predetermined conversion process is performed on the separated video stream, and additional information indicative of a mismatch occurs when displaying the converted video stream on the basis of the multimedia coding data.</p>
<p id="p-0217" num="0216">The first recording medium stores the converted video stream, the multimedia coding data, and the additional information indicative that a mismatch will occur when displaying the converted video stream on the basis of the above-mentioned multimedia coding data.</p>
<p id="p-0218" num="0217">Consequently, in any case, the reproducing side can prevent a mismatch from occurring between the video stream and the multimedia coding data.</p>
<p id="p-0219" num="0218">As described and according to the image decoding apparatus and method and the program stored in the second recording medium, a mismatch occurs when a video stream is separated from an input multiplexed stream, the separated video stream is decoded, and the decoded video stream is displayed on the basis of multimedia coding information. On the basis of the additional information about this mismatch occurrence, a predetermined conversion process is performed on the decoded video stream. This novel configuration prevents the mismatch from occurring between the video stream and the multimedia coding data.</p>
<p id="p-0220" num="0219">As described and according to the second image coding apparatus and method and the program stored in the third recording medium, a video stream is separated from an input multiplexed stream, the input multiplexed stream is checked for multimedia coding data and, if the multimedia coding data is found, coding control information for giving an instruction not to change the display format of the separated video stream is generated, and a predetermined conversion process is performed on the separated video stream on the basis of the generated coding control information.</p>
<p id="p-0221" num="0220">The second recording medium also stores the above-mentioned coding control information giving instruction not to change the display format of a video stream and a multiplexed stream containing the video stream on which a predetermined conversion process has been performed on the basis of the coding control information.</p>
<p id="p-0222" num="0221">Consequently, in any case, the reproduction side can prevent a mismatch from occurring between the video stream and the multimedia coding data.</p>
<p id="p-0223" num="0222">Although the invention herein has been described with reference to particular embodiments, it is to be understood that these embodiments are merely illustrative of the principles and applications of the present invention. It is therefore to be understood that numerous modifications may be made to the illustrative embodiments and that other arrangements may be devised without departing from the spirit and scope of the present invention as defined by the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A non-transitory computer-readable medium having data stored thereon for processing by an image decoding apparatus so that multimedia content is presented in an intended manner by a display, said computer-readable medium comprising:
<claim-text>a data recording area containing data representing a converted video stream, at least another stream, multimedia coding data for controlling display of an original video stream and the at least another stream on a common display device, and sub-information, the converted video stream being generated for inclusion in the data recording area by performing a predetermined conversion process on the original video stream, the sub-information including at least one of a display frame size or an aspect ratio of the original video stream and including an indicator value representing whether a mismatch is present in a relationship between the converted video stream and the multimedia decoding data as a result of the predetermined conversion process performed on the original video stream, the predetermined conversion process being controlled by control information on which the sub-information is based such that upon reproduction of the data contained in the data recording area and in response to the indicator value contained in the sub-information indicating that the mismatch is present in the relationship between the converted video stream and the multimedia decoding data, a display mismatch on the common display device between the converted video stream and the at least another stream is avoided using the at least one of a display frame size or an aspect ratio of the original video stream contained in the sub-information in combination with the multimedia coding data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said data recording area stores the sub-information which is coded and stored as data separate from a multiplexed stream containing the converted video stream, the at least another stream, and the multimedia coding data.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said data recording area stores the sub-information which is coded and stored as data multiplexed with a multiplexed stream containing the converted video stream, the at least another stream, and the multimedia coding data such that the sub-information is distinct from the converted video stream, the at least another stream, and the multimedia coding data within the data stream.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined conversion process includes converting the original video stream in its picture frame parameter.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined conversion process includes the original video stream being decoded and then encoded.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sub-information includes another of the display frame size or the original screen aspect ratio associated with the original video stream.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sub-information includes information about an original video format associated with the original video stream.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sub-information includes information indicating whether a picture frame of said original video stream has been converted during the predetermined conversion process.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the multimedia coding data includes a video display position and video display size of the original video stream on the common display device.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the multimedia coding data includes a display position and display size of the at least another stream on the common display device.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein upon the reproduction of the data contained in the data recording area, the display mismatch on the common display device between the converted video stream and the at least another stream is avoided using the sub-information, in combination with the multimedia coding data, to keep a video display position and video display size of the converted video stream unchanged from the video display position and video display size of the original video stream regardless of the predetermined conversion process carried out.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sub-information includes a mismatch flag as the indicator value representing whether there exists the mismatch in the relationship between the converted video stream and the multimedia coding data.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sub-information includes a re-encoded flag indicating whether the original video stream has been re-encoded.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sub-information includes a frame size change flag indicating whether a picture frame of the original video stream has been changed. </claim-text>
</claim>
</claims>
</us-patent-grant>
