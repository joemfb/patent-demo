<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624744-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624744</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12812635</doc-number>
<date>20090116</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>SE</country>
<doc-number>0800149</doc-number>
<date>20080122</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>602</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>08</class>
<subclass>B</subclass>
<main-group>21</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>3405733</main-classification>
<further-classification>3405731</further-classification>
<further-classification>340540</further-classification>
<further-classification>348 46</further-classification>
<further-classification>348135</further-classification>
<further-classification>119 1402</further-classification>
<further-classification>119 1408</further-classification>
</classification-national>
<invention-title id="d2e71">Arrangement and method for determining positions of the teats of a milking animal</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4805557</doc-number>
<kind>A</kind>
<name>van der Lely et al.</name>
<date>19890200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>119 1408</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6118118</doc-number>
<kind>A</kind>
<name>Lely et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2005/0115506</doc-number>
<kind>A1</kind>
<name>Van Den Berg et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>119 1403</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>EP</country>
<doc-number>0880889</doc-number>
<kind>A2</kind>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>EP</country>
<doc-number>1460453</doc-number>
<kind>A1</kind>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>EP</country>
<doc-number>1523879</doc-number>
<kind>A2</kind>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>EP</country>
<doc-number>1537774</doc-number>
<kind>A1</kind>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>EP</country>
<doc-number>1537775</doc-number>
<kind>A1</kind>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>NZ</country>
<doc-number>285631</doc-number>
<date>19970500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>WO</country>
<doc-number>WO 2005/094565</doc-number>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>WO</country>
<doc-number>WO 2007/104124</doc-number>
<kind>A1</kind>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Examination Report, issued Jan. 26, 2012 in corresponding New Zealand Application No. 586159, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>International Search Report of PCT/SE2009/050040, mailed on Jun. 4, 2009, 7 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Oggier et al., <i>An all-solid-state optical range camera for 3D real-time imaging with sub-centimeter depth resolution </i>(<i>SwissRanger</i>&#x2122;), available at http://www.mesa-imaging.ch/ on Dec. 27, 2007, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Oggier et al., <i>3D-Imaging in Real-Time with Miniaturized Optical Range Camera</i>, available at http://www.mesa-imaging.ch/ on Dec. 27, 2007, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>23</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>3405733</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3405731</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>340540</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 46</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348135</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>119 1402</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>119 1408</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100289649</doc-number>
<kind>A1</kind>
<date>20101118</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Holmgren</last-name>
<first-name>Hans</first-name>
<address>
<city>Stockholm</city>
<country>SE</country>
</address>
</addressbook>
<residence>
<country>SE</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Axelsson</last-name>
<first-name>Thomas</first-name>
<address>
<city>Farsta</city>
<country>SE</country>
</address>
</addressbook>
<residence>
<country>SE</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Liao</last-name>
<first-name>Bohao</first-name>
<address>
<city>Sollentuna</city>
<country>SE</country>
</address>
</addressbook>
<residence>
<country>SE</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Holmgren</last-name>
<first-name>Hans</first-name>
<address>
<city>Stockholm</city>
<country>SE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Axelsson</last-name>
<first-name>Thomas</first-name>
<address>
<city>Farsta</city>
<country>SE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Liao</last-name>
<first-name>Bohao</first-name>
<address>
<city>Sollentuna</city>
<country>SE</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Finnegan, Henderson, Farabow, Garrett &#x26; Dunner, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Delaval Holding AB</orgname>
<role>03</role>
<address>
<city>Tumba</city>
<country>SE</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Ghayour</last-name>
<first-name>Mohammad</first-name>
<department>2687</department>
</primary-examiner>
<assistant-examiner>
<last-name>Rushing</last-name>
<first-name>Mark</first-name>
</assistant-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/SE2009/050040</doc-number>
<kind>00</kind>
<date>20090116</date>
</document-id>
<us-371c124-date>
<date>20100713</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2009/093965</doc-number>
<kind>A </kind>
<date>20090730</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An arrangement is provided for attaching teat cups to teats of a milking animal in a rotary milking system having a milking stall for housing the milking animal during milking. The arrangement comprises a three-dimensional camera configured to be directed towards the udder of the milking animal in the milking stall and to repeatedly record three-dimensional images of the udder of the milking animal in real time. The three-dimensional camera is further configured to be directed towards the teat cups located in a magazine and to repeatedly record three-dimensional images of the teat cups in real time. The arrangement also includes an image processing device configured to repeatedly detect the teats of the milking animal and determine the positions of the teats in three spatial dimensions based on said repeatedly recorded three-dimensional images of the teats. The image processing device is also configured to repeatedly detect the plurality of teat cups and determine the positions of the teat cups in three spatial dimensions based on said repeatedly recorded three-dimensional images of the teat cups located in the magazine. The arrangement also includes a control device configured to control a robot arm, based on the determined positions of the teats of the milking animal and the determined positions of the teat cups, to automatically attach at least one teat cup to at least one teat of the milking animal in the milking stall.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="140.46mm" wi="140.89mm" file="US08624744-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="158.07mm" wi="140.21mm" file="US08624744-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="244.26mm" wi="183.05mm" file="US08624744-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.53mm" wi="121.92mm" file="US08624744-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">This is a U.S. National Phase application of PCT/SE2009/050040, filed Jan. 16, 2009, which claims priority to Swedish Patent Application Number 0800149-7, filed Jan. 22, 2008, both of which are incorporated herein by reference in their entirety.</p>
<heading id="h-0001" level="1">TECHNICAL FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention generally relates to dairy farm robot milking and to automatic attachment of teat cups related thereto.</p>
<heading id="h-0002" level="1">DESCRIPTION OF RELATED ART AND BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">WO 2007/104124 discloses a teat location system for automated milking systems comprising a sensor housing mounted on a robot arm for sensing the location and attitude of teats on an udder. The output of the sensor is used to control the application of the automated milking apparatus that includes milking cups that are also mounted on the robot arm. The milking apparatus is adapted to receive instructions characterizing the location of the teats, to move the robot arm to such location so as to engage the milking cups onto the teats.</p>
<p id="p-0005" num="0004">The sensor housing includes a modulated light source for radiating throughout the field of view that encompasses the udder, the teats and the hind legs of the animal. Further, the sensor housing includes a camera, control, image capture and readout electronics and suitable optics. The camera consists of a two-dimensional array of pixels, each of which can report time of flight data synchronized to the light source, as well as intensity.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0006" num="0005">However, there are some drawbacks with the teat location system disclosed above. The location of the sensor including the time of flight camera, being mounted on the robot arm, may cause difficulties to view all teats of an animal, particularly simultaneously. As a consequence the teat cup attachment procedure may fail, or at least be prolonged.</p>
<p id="p-0007" num="0006">Further, the location of the sensor housing renders its use in a rotary milking system with several robot arms inappropriate.</p>
<p id="p-0008" num="0007">Yet further, the location of the sensor may limit the use of the sensor for other purposes in the milking system.</p>
<p id="p-0009" num="0008">Still further, the sensor is very much exposed to a dirty and unpredictable environment in immediate proximity of the animal. The sensor may easily get soiled and dirty or even get damaged. As a consequence, the sensor will not operate properly or not operate at all.</p>
<p id="p-0010" num="0009">In particular, in a rotary milking system with moving platforms, moving milking stations and milking equipment, and moving animals, it has been found that a sensor mounted on the robot arm is inappropriate.</p>
<p id="p-0011" num="0010">Accordingly, it is an object of the present invention to provide an arrangement and a method for determining positions of the teats of a milking animal in a milking system comprising a milking stall for housing the milking animal during milking, a movable robot arm for automatically attaching teat cups to the teats of the milking animal in the milking stall, and a control device for controlling the movement of the robot arm based on determined positions of the teats of the milking animal, which arrangement and method alleviates or mitigates the drawbacks of the prior art as set forward above.</p>
<p id="p-0012" num="0011">It is a further object of the invention to provide such an arrangement and such a method, which are robust, effective, fast, precise, accurate, reliable, safe, easy to use, and of low cost.</p>
<p id="p-0013" num="0012">It is still a further object of the invention to provide such an arrangement and such a method, which are capable of obtaining a very high number of correct teat cup attachments.</p>
<p id="p-0014" num="0013">These objects among others are, according to the present invention, attained by arrangements and methods as claimed in the appended patent claims.</p>
<p id="p-0015" num="0014">According to one aspect of the invention an arrangement for determining positions of the teats of a milking animal comprises a three-dimensional camera, preferably a time-of-flight camera, directable towards the udder of the milking animal in the milking stall for repeatedly recording three-dimensional images of the udder of the milking animal in real time, and image processing means for repeatedly detecting the teats of the milking animal and determining their positions in all three spatial dimensions based on the repeatedly recorded three-dimensional images. The image processing means is comprised in or operatively connected to the control device of the milking system. The arrangement is implemented in a rotary milking system, wherein the three-dimensional camera is preferably located at a fix position with respect to a floor, on which the rotary milking system is installed and with respect to which a rotary platform of the rotary milking system rotates during milking. The location of the three-dimensional camera provides for the detection and location of all the teats of the milking animal simultaneously.</p>
<p id="p-0016" num="0015">By such arrangement the control device may control the robot arm very fast and accurately. The three-dimensional real time measurements and the subsequent processing of the measurement data provide high quality information extremely fast and as a result the milking system is capable of operating at higher speed. The milking time will be shorter and the throughput of animals is increased.</p>
<p id="p-0017" num="0016">Further, a single three-dimensional camera can serve several or all of the milking stalls of the milking system. The fast operation of the inventive arrangement is required since the milking stalls are moving (rotating) with respect to the three-dimensional camera.</p>
<p id="p-0018" num="0017">In such a milking system the position of the teat cups when being stored in e.g. a magazine, i.e. when not being used, may not be known. However, the three-dimensional camera of the inventive arrangement may be directed towards teat cups located in the magazine and provided to repeatedly record three-dimensional images of the teat cups in real time. Hereby the image processing means is capable of detecting the teat cups and determining their positions in all three spatial dimensions in the magazine.</p>
<p id="p-0019" num="0018">The three-dimensional camera can be located at a side of the milking animal and be directed essentially sideways, i.e., horizontally, towards the udder of the milking animal. Alternatively, the three-dimensional camera can be located below the milking animal and be directed upwards towards the udder of the milking animal.</p>
<p id="p-0020" num="0019">The above positions/orientations of the camera seem to be the most favorable ones in order to fast locate the udder and the teats of the milking animals. The camera positions/orientations seem to provide the best contrast between the udder/teats and other objects in the view field of the camera. Other orientations may be conceivable.</p>
<p id="p-0021" num="0020">Further, the camera may be movable between several positions/orientations depending on the application or status of the camera.</p>
<p id="p-0022" num="0021">Further embodiments of the inventive arrangement are set out in the dependent claims.</p>
<p id="p-0023" num="0022">According to a second aspect of the invention a method for determining positions of the teats of a milking animal is provided. According to the method a three-dimensional camera, preferably a time-of-flight camera, is directed towards the teats of the milking animal in the milking stall, three-dimensional images of the teats of the milking animal are repeatedly recorded in real time by the three-dimensional camera, and the teats of the milking animal are repeatedly detected and their positions are determined in all three spatial dimensions based on the repeatedly recorded three-dimensional images. The method is implemented in a rotary milking system, wherein the three-dimensional camera is located at a fix position with respect to a floor, on which the rotary milking system is installed and with respect to which a rotary platform of the rotary milking system rotates during milking.</p>
<p id="p-0024" num="0023">An advantage of the present invention is that the determination of the positions of the teats of an animal in all three spatial coordinates is made very fast. The invention provides in particular for the recording of three-dimensional images in real time and all visible teats can be detected, and the positions of all the teats can be determined, simultaneously. Hence, teat cup attachment can be made very fast.</p>
<p id="p-0025" num="0024">Further characteristics of the invention, and advantages thereof will be evident from the following detailed description of preferred embodiments of the present invention given hereinafter and the accompanying <figref idref="DRAWINGS">FIGS. 1-5</figref>, which are given by way of illustration only, and are thus not limitative of the present invention.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 1-3</figref> display each a schematically outlined milking system including an arrangement for determining positions of the teats of a milking animal according to a respective embodiment of the present invention. <figref idref="DRAWINGS">FIGS. 1 and 3</figref> are top views while <figref idref="DRAWINGS">FIG. 2</figref> is a perspective view.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 4</figref> displays schematically, in a top view, an arrangement for determining the identity of a milking animal according to an embodiment of the present invention.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 5</figref> displays schematically, in a side elevation view, an arrangement for determining the weight of a milking animal according to an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF EMBODIMENTS</heading>
<p id="p-0029" num="0028">In <figref idref="DRAWINGS">FIG. 1</figref> is shown a milking system, in which an arrangement for determining positions of the teats of milking animals according to an embodiment of the invention is implemented. The rotary milking system <b>3</b> comprises a plurality of milking stalls <b>5</b>, which milking animals <b>8</b> enter in a sequential order. Each of the milking stalls <b>5</b> comprises milking equipment including teat cups that are attached to the teats of the milking animal present in the milking stall prior to milking. For sake of simplicity teat cups <b>11</b> are illustrated only for one of the milking stalls <b>5</b>. The rotary milking system <b>3</b> may be of parallel, tandem, or herringbone configuration. In the parallel configuration the longitudinal directions of the milking stalls and of the milking animals therein extend radially (the milking animals stand side by side), in the tandem configuration the longitudinal directions of the milking stalls and of the milking animals therein extend circumferentially (the milking animals stand one after the other), and in the herringbone configuration, which is illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, the longitudinal directions x of the milking stalls and of the milking animals therein extends partly radially, partly circumferentially.</p>
<p id="p-0030" num="0029">A robot <b>14</b> provided with a robot arm <b>15</b> is provided for automatically attaching teat cups <b>11</b> to the teats of the milking animals <b>8</b> present in the milking stalls <b>5</b> under the control of a control device <b>19</b>, which is operatively connected to the milking robot <b>14</b>. The milking robot <b>14</b> is preferably stationary with respect to a rotatable carousel or rotating platform <b>20</b> of the rotary milking system <b>3</b>, which forms the support for the milking stalls <b>5</b>. Alternatively, the milking robot <b>14</b> is movable back and forth in e.g. a circumferential direction.</p>
<p id="p-0031" num="0030">The rotating platform <b>20</b> may, for each of the milking animals, be kept still while the milking robot <b>14</b> automatically attaches teat cups <b>11</b> to the teats of the milking animal <b>8</b>, and is rotated there in between. Alternatively, the rotating platform is rotated continuously during the attachment of the teat cups and the milking of the milking animals <b>8</b>.</p>
<p id="p-0032" num="0031">In order to determine positions of the teats of the milking animals <b>8</b> present in the milking stalls <b>5</b>, and thus be capable of moving the teat cups <b>11</b> to the teats of the milking animal, a three-dimensional camera <b>21</b>, preferably a time-of-flight camera, is provided. A commercially available camera that can be used in the present invention is the SwissRanger SR3000 from Mesa Imaging AG, Switzerland. The SR3000 is a general purpose range three-dimensional real time imaging camera. The camera can easily be connected to a computer via USB 2.0, enabling straightforward measurement of real-time depth maps. Designed for operation under lighting conditions, the compact camera is offered with a complete visualization software program.</p>
<p id="p-0033" num="0032">The camera and the technique behind the camera are further disclosed in the publications &#x201c;An all-solid-state optical range camera for 3D real-time imaging with sub-centimeter depth resolution (SwissRanger&#x2122;)&#x201d; and &#x201c;3D-Imaging in Real-Time with Miniaturized Optical Range Camera&#x201d; by T. Oggier et al. and available at the Mesa Imaging AG Internet site http://www.mesa-imaging.ch/ on Dec. 27, 2007. The contents of the above publications are hereby incorporated by reference.</p>
<p id="p-0034" num="0033">The three-dimensional camera <b>21</b> is, for each of the milking animals in the milking stalls, directed towards the udder of the milking animal, wherein the three-dimensional camera repeatedly records three-dimensional images of the udder of the milking animal in real time. Image processing means <b>22</b> is provided, for each of the milking animals, for repeatedly detecting the teats of the milking animal and determining their positions in all three spatial dimensions by a calculation method based on the repeatedly recorded three-dimensional images of the udder of the milking animal.</p>
<p id="p-0035" num="0034">The three-dimensional camera <b>21</b> thus determines directly the position in all three spatial coordinates for each object point that is found in the pixels of the image recorded. Thus, the coordinates are in principle determined in real time.</p>
<p id="p-0036" num="0035">The image processing means <b>22</b> is preferably implemented as a software module in the control device <b>19</b>, which thus is operatively connected to the three-dimensional camera <b>21</b>, or in any other device operatively connected to the three-dimensional camera <b>21</b> and the control device <b>19</b>. Yet alternatively, the software module may be integrated into the three-dimensional camera <b>21</b> itself.</p>
<p id="p-0037" num="0036">The calculation method used can be any calculation method suitable for use in the field of digital image processing.</p>
<p id="p-0038" num="0037">In particular, the calculation method involves the formation of a three-dimensional surface representation, i.e. a topography or elevation map, of a portion of the milking animal <b>8</b> from the three-dimensional image of the milking animal, the analyzing of the surface of the three-dimensional surface representation, and the determination of the position of the teats of the milking animal <b>8</b> based on the analysis of the surface of the three-dimensional surface representation. Thus, the intensity or color of the pixels of the three-dimensional image may not be used at all in the calculation method for detecting and locating the teats of the milking animal.</p>
<p id="p-0039" num="0038">The analysis preferably includes the comparison of elevation gradients of the surface of the three-dimensional surface representation with reference gradients. This may be implemented by comparing elevations of portions of the surface of the three-dimensional surface representation located adjacent one another.</p>
<p id="p-0040" num="0039">By such measures full use of the three-dimensional imaging is made. The analysis follows the surface of the udder and the surface of the teats to thereby detect, identify and locate the teats fastly and efficiently. Simultaneously, background noise may easily be removed from the image since it is located at an distance from the camera which is entirely different from the distance between the teats of the milking animal and the camera. The three-dimensional real time camera <b>21</b> can be mounted in fixed positions with respect to the different parts of the milking system <b>3</b> depending on the application in question. The camera <b>21</b> can be located at a fix position with respect to a floor, on which the rotary milking system <b>3</b> is installed and with respect to which the rotary platform <b>20</b> of the rotary milking system <b>3</b> rotates during milking. In such instance, the camera <b>21</b> may be mounted in a ceiling of a building in which the milking system is installed or on a frame or fence surrounding the rotary platform <b>20</b>. Such position may enable the inventive arrangement to detect and determine all the teats of the milking animal <b>8</b> simultaneously.</p>
<p id="p-0041" num="0040">Alternatively, the camera <b>21</b> is mounted on the rotating platform <b>20</b> or on the robot arm <b>15</b>. Still alternatively, the camera <b>21</b> is movable along some path. In one version, for instance, the three-dimensional camera <b>21</b> can be movable between a first position, in which the camera <b>21</b> is located during the detections of the three-dimensional images, and a second position, in which the camera <b>21</b> is located there in between, that is, when being idle.</p>
<p id="p-0042" num="0041">The three-dimensional real time camera <b>21</b> can further be located in a number of different positions and orientations depending on the application in question. The camera <b>21</b> can, during each of the recordings of the three-dimensional images of the udder of each of the milking animals, be located at a side of the milking animal and be directed essentially sideways in the horizontal plane and perpendicular to a longitudinal direction of the milking animal. Alternatively, the camera <b>21</b> can, during each of the recordings of the three-dimensional images of the udder of each of the milking animals, be located below the milking animal and be directed upwards.</p>
<p id="p-0043" num="0042">Still further, two or more three-dimensional real time cameras can be provided operatively connected to the control device <b>19</b> in order to provide further detailed three-dimensional information of the positions and orientations of the teats of the milking animals.</p>
<p id="p-0044" num="0043">For instance, several of the three-dimensional real time cameras seem to be advantageous if they are not mounted fixedly on the robot arm since at least one teat would always be obscured. Further, one or several three-dimensional real time cameras arranged stationary on the floor or on the rotating platform could be combined with one three-dimensional real time camera mounted on the robot arm, or a single three-dimensional real time camera mounted on the robot arm could be used in the invention.</p>
<p id="p-0045" num="0044">The speed and accuracy of the arrangement for determining teat positions as provided by the three-dimensional real time measurements are of outermost importance in order to provide a milking system with accurate and fast automatic attachments of teat cups to teats of milking animals. This is of particular importance in a rotary milking system where not only the robot arm for attaching the teat cups is movable, but also the entire robot may be movable. Further, the rotating platform and the milking stalls are moving (rotating).</p>
<p id="p-0046" num="0045">Since also the milking stalls and the milking equipments belonging to the milking stalls are moving it is typically not known&#x2014;at least not in a fixed coordinate system&#x2014;where the teat cups are located, particularly when they are stored in a magazine (not illustrated) in each of the milking stalls.</p>
<p id="p-0047" num="0046">In a rotary milking system it may be particularly difficult to find the magazines since they may appear in different positions in different milking stalls, and the position of a magazine in a milking stall can be stored only if the position of the milking stall is monitored.</p>
<p id="p-0048" num="0047">The three-dimensional real time camera <b>21</b> of the inventive arrangement may thus be provided to record three-dimensional images of the teat cups <b>11</b> in real time, particularly when the teat cups <b>11</b> are located in the magazine, and the image processing means <b>22</b> detects the teat cups and determines their positions in all three spatial dimensions by the above calculation method based on the recorded three-dimensional images of the teat cups when being located in the magazine.</p>
<p id="p-0049" num="0048">In another embodiment of the present invention the three-dimensional real time camera <b>21</b> can be used to establish a position of each of the milking animals in at least one spatial dimension, e.g. a longitudinal direction x or in a direction perpendicular thereto, with respect to the milking stalls in which they are housed. Thus, the three-dimensional camera <b>21</b> is, for each of the milking animals, directed towards a leg or an outer contour of the milking animal in the milking stall, wherein the three-dimensional camera <b>21</b> records a three-dimensional image in real time of the leg or the outer contour of the milking animal. The image processing means <b>22</b> detects the milking animal and determines its position in the spatial dimension by the calculation method based on the recorded three-dimensional image of the leg or the outer contour of the milking animal.</p>
<p id="p-0050" num="0049">Such embodiment may be advantageous in a milking system where a detection device is used to detect the teats of a milking animal in a milking stall based on the prior knowledge of where in the milking stall the milking animal is located and possibly on the physical dimensions of the milking animal itself.</p>
<p id="p-0051" num="0050">Thus, the control device <b>19</b> may, for each of the milking animals, hold information in, or receive information from, a database <b>23</b> regarding the position of the udder of the milking animal relative the milking animal itself. This may be a single approximate figure valid for all the animals. Further, the control device <b>19</b> directs the three-dimensional camera <b>21</b> and controls the robot arm <b>15</b> of the milking robot <b>14</b> to move towards the udder of the milking animal based on the information of the position of the at least one teat of the milking animal relative the milking animal itself, and on the detected position of the milking animal in the spatial dimension relative the milking stall.</p>
<p id="p-0052" num="0051">The information of the position of the at least one teat of the milking animal relative the milking animal itself can be deduced from the recording of visual detections of the milking animal in connection with an earlier milking of the milking animal.</p>
<p id="p-0053" num="0052">The inventive arrangement for determining teat positions is particularly advantageous in situations where one or more teats are obscured and is/are not clearly detectable by the three-dimensional camera. Thus, the control device <b>19</b> may, for each of the milking animals, hold information in, or receive information from, the database <b>23</b> regarding the position of each of the teats of the milking animal relative the other teats of the milking animal. Further, the control device <b>19</b> controls the robot arm <b>15</b> of the milking robot <b>14</b> to move a teat cup to an obscured teat of the milking animal based on the information of the position of each of the teats of the milking animal relative the other teats of the milking animal and on a determined position of a repeatedly detected teat of the milking animal, which is not obscured.</p>
<p id="p-0054" num="0053">In one version the above algorithm is applied in an arrangement where the three-dimensional camera is, during each of the recordings of the three-dimensional images, located behind the milking animal and is directed forward towards the back of the milking animal. The spatial dimension determined is then preferably in a direction perpendicular to a longitudinal direction of the milking stall. The leg or outer contour of the milking animal may include one or both back legs of the milking animal, preferably the inner contours of the back legs.</p>
<p id="p-0055" num="0054">The determination of the positions of the teats of the milking animal can be made in the following manner. First the milking animal is detected and the position thereof is determined. Based on this information the contour of the back legs and the body therein between is detected and the positions thereof are determined. Based on this information an area of interest (i.e. where the teats most probably are found) is located, and in this area the udder of the milking animal is searched for. When the udder has been detected and located the teats are searched for and located. Finally, when the positions of the teats have been determined the teat cup attachment can be initiated.</p>
<p id="p-0056" num="0055">Such algorithm is characterized by fast object recognition and can be applied in situations where a new milking animal is detected or where a milking animal has a position of the legs which renders the determination of the teat positions more difficult.</p>
<p id="p-0057" num="0056">It shall further be appreciated that the arrangement of the present invention may be used as a multifunctional detection system for detecting any of the following: (i) presence of a milking animal in a milking stall, (ii) the behavior of a milking animal, (iii) the activity of a milking animal, (iv) the body shape of a milking animal, (v) an incorrect teat cup attachment, (vi) a teat cup kick-off, (vii) presence of an obstacle in the working area of the milking robot, (viii) a parameter related to the operation of the milking robot, and (ix) a parameter related to the operation of the three-dimensional camera.</p>
<p id="p-0058" num="0057">With reference next to <figref idref="DRAWINGS">FIG. 2</figref> a further embodiment of the present invention will be described. The arrangement for determining teat positions is here implemented in a voluntary milking system or station <b>3</b> comprising an enclosure having an inlet gate <b>4</b> and an outlet gate <b>5</b>, which are both capable of being opened automatically. The front end of the milking station <b>3</b> is denoted by <b>3</b><i>a</i>, the back end is denoted by <b>3</b><i>b</i>, the sides are denoted by <b>3</b><i>c </i>and <b>3</b><i>d. </i></p>
<p id="p-0059" num="0058">The milking station <b>3</b> comprises further an automatic milking machine (not explicitly illustrated) including teat cups <b>11</b> connected to an end unit by means of milk lines (only the portions attached to the teat cups <b>11</b> are shown in <figref idref="DRAWINGS">FIG. 2</figref>). The milking station further includes a milking robot <b>14</b> having a movable robot arm <b>15</b> provided with a gripper. The milking robot <b>14</b> is arranged to automatically apply the teat cups <b>11</b> of the milking machine to the teats of a milking animal <b>8</b> present in the milking station <b>3</b> prior to milking. In <figref idref="DRAWINGS">FIG. 2</figref> three of the teat cups <b>11</b> are arranged in a teat cup rack or magazine <b>16</b>, whereas the fourth one is held by the gripper of the robot arm <b>15</b>. Typically, a teat cleaning device including e.g. a teat cleaning cup <b>24</b> or brushes <b>25</b> may be provided for cleaning the teats of the milking animal <b>8</b> prior to milking.</p>
<p id="p-0060" num="0059">Further, the milking station <b>3</b> comprises an identification device (not illustrated) provided to identify a milking animal approaching the milking station <b>3</b>, and a control device <b>19</b>, which is responsible for controlling of the milking system, which inter alia includes the initiation of various activities in connection with the milking such as e.g. opening and closing of the gates <b>4</b> and <b>5</b>, and control of the milking machine and its handling device <b>14</b></p>
<p id="p-0061" num="0060">The arrangement for determining teat positions comprises a three-dimensional time-of-flight real time camera <b>21</b> for repeatedly recording three-dimensional images of the udder of the milking animal in real time. Image processing means <b>22</b> of e.g. the control device <b>19</b> detects repeatedly the teats of the milking animal and determines their positions in all three spatial dimensions based on the repeatedly recorded three-dimensional images of the udder of the milking animal <b>8</b>.</p>
<p id="p-0062" num="0061">The three-dimensional camera <b>21</b> is mounted on the movable robot arm <b>15</b> of the milking robot <b>14</b> and the control device <b>19</b> is thus provided for determining the positions of the teats of the milking animal in all three spatial dimensions relative the movable robot arm <b>15</b>.</p>
<p id="p-0063" num="0062">The inventive arrangement may further be arranged for determination of the positions and orientations of the teat cups <b>11</b>, the teat cleaning cup <b>24</b>, and the brushes <b>25</b>.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a further embodiment of the invention wherein the arrangement for determining teat positions is implemented in a voluntary milking system of the above kind. Here, two three-dimensional cameras <b>21</b> are mounted in fixed positions with respect to the milking station <b>3</b>. One three-dimensional camera <b>21</b> is arranged to record three-dimensional images of the udder of a milking animal from behind and one three-dimensional camera <b>21</b> is arranged to record three-dimensional images of the udder of the milking animal from a side.</p>
<p id="p-0065" num="0064">The image processing means of the control device <b>19</b>, to which the three-dimensional cameras <b>21</b> are operatively connected, is provided for determining the positions of the teats of the milking animal in all three spatial dimensions relative the milking station <b>3</b> based on three-dimensional images recorded by the two three-dimensional cameras.</p>
<p id="p-0066" num="0065">It shall be appreciated that the inventive arrangement for determining teat positions of the present invention may be implemented in virtually any kind of milking system where the teat positions need to be found automatically.</p>
<p id="p-0067" num="0066">There are many prior art techniques for determining the identities of milking animals, however, many of them being complex or requiring the providing of each of the milking animals to be identified with a transducer or tag.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 4</figref> shows a novel arrangement for determining the identity of a milking animal based on the above three-dimensional measurement concept. A three-dimensional camera <b>41</b>, preferably a three-dimensional time-of-flight camera, is directed towards the milking animal <b>42</b>, or a part thereof, wherein the three-dimensional camera is arranged to record a three-dimensional image of the milking animal, or the part thereof. An image processing device <b>43</b> is provided for digitally processing the recorded three-dimensional image and for determining the identity of the milking animal among a group of milking animals based on comparisons between the digitally processed three-dimensional image and (i) physical parameters characteristic for each milking animal of the group of milking animals or (ii) previously recorded digitally processed three-dimensional images of each milking animal of the group of milking animals.</p>
<p id="p-0069" num="0068">Preferably, the three-dimensional camera <b>41</b> is provided to record the three-dimensional image to be digitally processed as a three-dimensional image of the udder/teats of the milking animal <b>42</b>, preferably from a position below the udder of the milking animal <b>42</b>. Alternatively, the three-dimensional camera <b>41</b> is positioned elsewhere and/or oriented differently.</p>
<p id="p-0070" num="0069">The physical parameters characteristic for the milking animals can be found by detailed analysis of digital images of the milking animals, e.g. as recorded by the three-dimensional camera <b>41</b>.</p>
<p id="p-0071" num="0070">The above arrangement is less complicated than prior art systems. The milking animals have not to be provided with transducers or tags. A three-dimensional camera, which may already be provided for other purposes such as e.g. the above determination of teat positions, can be used for the identification. Thus, less equipment is needed for the achievement of a certain number of functions of the milking system.</p>
<p id="p-0072" num="0071">Further, the time-of-flight based three-dimensional imaging technology provides for rapid and direct identification of milking animals.</p>
<p id="p-0073" num="0072">Still further, the arrangement may be provided for detecting damaged or swollen teats or any other abnormal teat condition and to alert a dairy farmer of such condition.</p>
<p id="p-0074" num="0073">It shall be appreciated that the above arrangement may be implemented in a milking system or a milking stall, but alternatively it may be implemented in a feeding station, at a gate arrangement, or elsewhere at a dairy farm.</p>
<p id="p-0075" num="0074">In the prior art the weights of milking animals are typically determined by weighing devices, onto which the milking animals are led or guided. Such devices, however, are bulky and costly.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 5</figref> shows a novel arrangement for determining the weight of a milking animal <b>52</b> based on the above three-dimensional measurement concept. A three-dimensional camera <b>51</b>, preferably a three-dimensional time-of-flight camera, is directed towards the milking animal <b>52</b>, wherein the three-dimensional camera is provided to record a three-dimensional image of the milking animal. An image processing device <b>53</b> is provided for digitally processing the recorded three-dimensional image and for determining the weight of the milking animal based on the digitally processed three-dimensional image and a table which correlates dimensions or volumes with weights for the species or breed, to which the milking animal belongs.</p>
<p id="p-0077" num="0076">Preferably, the three-dimensional camera <b>51</b> is located above the milking animal <b>52</b> and is directed downwards towards the milking animal <b>52</b>. The camera may be located at an angle &#x3b1; with respect to a vertical plane parallel with a longitudinal direction of the milking animal <b>52</b>.</p>
<p id="p-0078" num="0077">In one version, the arrangement comprises a second three-dimensional camera (not illustrated) directed towards the milking animal, wherein the three-dimensional cameras are provided to record three-dimensional images of the milking animal at different view angles, wherein the image processing device <b>53</b> is provided for digitally processing the recorded three-dimensional images and for determining the weight of the milking animal based on the digitally processed three-dimensional images and the table which correlates dimensions with weights for the breed, to which the milking animal belongs.</p>
<p id="p-0079" num="0078">Alternatively, the three-dimensional images of the milking animal at different view angles may be recorded by a single three-dimensional camera, which is movable between at least two positions. For instance, the three-dimensional camera may be movable between two positions located at each side of a vertical plane parallel with a longitudinal axis of the animal.</p>
<p id="p-0080" num="0079">The above arrangement is less bulky than a conventional weighing device and the arrangement may be used for other purposes as well. The arrangement may be implemented at any location of a dairy farm.</p>
<p id="p-0081" num="0080">It shall be noted that the arrangement of <figref idref="DRAWINGS">FIG. 4</figref> may be arranged for determining or calculating a body score index (BSI), which can be used as a parameter related to the health of the milking animal. While any of the above described camera locations may be used for body score index determinations, it seems like that locating the three-dimensional camera <b>51</b> above the milking animal <b>52</b> at an angle &#x3b1; with respect to a vertical plane parallel with a longitudinal direction of the milking animal <b>52</b> and directing the camera diagonally downwards towards the milking animal <b>52</b> is a preferred option.</p>
<p id="p-0082" num="0081">By placing the camera so that the important body parts for body score index can be exposed and then making a computer &#x201c;cut out&#x201d; of the model, a calculation of the volume can be made. From a reference value for each milking animal stored in a database, a current body score index can be determined.</p>
<p id="p-0083" num="0082">It shall further be noted that the arrangements of <figref idref="DRAWINGS">FIGS. 4 and 5</figref> may be applied to other animals than milking animals.</p>
<p id="p-0084" num="0083">It shall be appreciated by a person skilled in the art that various features of the above embodiments can be combined to form yet further embodiments of the present invention. Particularly, a multifunctional arrangement may be provided for determining teat positions, for identifying animals, and for weighing animals.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An arrangement for attaching teat cups to teats of a milking animal in a rotary milking system having a rotatable milking stall for housing the milking animal during milking, the arrangement comprising:
<claim-text>a three-dimensional camera configured to be directed towards the udder of the milking animal in the rotatable milking stall and to repeatedly record three-dimensional images of the udder of the milking animal in real time, said three-dimensional camera further configured to be directed towards the teat cups located in a magazine, configured to rotate with the rotatable milking stall, and to repeatedly record three-dimensional images of the teat cups in real time, wherein the three-dimensional camera is configured to not rotate along with the rotatable milking stall and the rotatable magazine;</claim-text>
<claim-text>an image processing device configured to:</claim-text>
<claim-text>repeatedly detect the teats of the milking animal in the rotatable milking stall and determine the positions of the teats in three spatial dimensions based on said repeatedly recorded three-dimensional images of the teats, and</claim-text>
<claim-text>repeatedly detect the plurality of teat cups in the rotatable magazine and determine the positions of the teat cups in three spatial dimensions based on said repeatedly recorded three-dimensional images of the teat cups located in the rotatable magazine; and</claim-text>
<claim-text>a control device configured to control a robot arm, based on the determined positions of the teats of the milking animal and the determined positions of the teat cups, to automatically attach at least one teat cup to at least one teat of the milking animal in the rotatable milking stall.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said three-dimensional camera is a three-dimensional time-of-flight camera.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image processing device is configured to simultaneously determine positions of all of the teats of the milking animal in three spatial dimensions.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image processing device is configured to:
<claim-text>form a three-dimensional surface representation of at least a portion of the milking animal from at least one of the three-dimensional images;</claim-text>
<claim-text>analyze a surface of the three-dimensional surface representation; and</claim-text>
<claim-text>determine the position of the teats of the milking animal based on the analysis of the surface of the three-dimensional surface representation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The arrangement of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein said analysis includes comparing elevations of adjacent portions of said surface of the three-dimensional surface representation.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The arrangement of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein said analysis includes comparing elevation gradients of said surface of the three-dimensional surface representation with reference gradients.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said three-dimensional camera is movable between a first position at which said three-dimensional camera records said three-dimensional images and a second position at which said three-dimensional camera is in an idle state.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>said three-dimensional camera is configured to be directed towards a leg or an outer contour of the milking animal in the milking stall to record a three-dimensional image in real time of the leg or the outer contour of the milking animal; and</claim-text>
<claim-text>the image processing device is configured to detect the milking animal and determine a position of the milking animal in at least one spatial dimension based on said recorded three-dimensional image of the leg or the outer contour of the milking animal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The arrangement of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said leg or outer contour of the milking animal includes a back leg of the milking animal.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The arrangement of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said image processing device is configured to first detect and determine the position of the milking animal, and to thereafter detect and determine the position of the udder of the milking animal based on the position of the milking animal.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The arrangement of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein:
<claim-text>said three-dimensional camera is, when recording said three-dimensional images of the leg or the outer contour of the milking animal, located behind the milking animal and directed towards the back of the milking animal; and</claim-text>
<claim-text>said at least one spatial dimension is in a direction perpendicular to a longitudinal direction of the milking stall.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said three-dimensional camera is, when recording said three-dimensional images of the teats, located at a side of the milking animal and is directed towards a side of the milking animal.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said three-dimensional camera is, when recording said three-dimensional images of the teats, located below the milking animal and is directed upwards towards the milking animal.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control device is configured to receive information on the position of each teat of the milking animal relative the other teats of the milking animal and control said robot arm to move to an obscured teat of the milking animal based on said received information and on the determined position of a repeatedly detected teat of the milking animal that is not obscured.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said arrangement is a multifunctional detection system further configured to detect at least one of:
<claim-text>(i) presence of the milking animal in the milking stall,</claim-text>
<claim-text>(ii) a behavior of the milking animal,</claim-text>
<claim-text>(iii) an activity of the milking animal,</claim-text>
<claim-text>(iv) a body shape of the milking animal,</claim-text>
<claim-text>(v) an incorrect teat cup attachment,</claim-text>
<claim-text>(vi) a teat cup kick-off,</claim-text>
<claim-text>(vii) presence of an obstacle in a working area of the robot arm,</claim-text>
<claim-text>(viii) a parameter related to an operation of the robot arm, or</claim-text>
<claim-text>(ix) a parameter related to an operation of the three-dimensional camera.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>said three-dimensional camera is configured to record a three-dimensional image of at least a portion of the milking animal; and</claim-text>
<claim-text>the image processing device is configured to digitally process the recorded three-dimensional image of the at least one portion of the milking animal and determine an identity of the milking animal based on comparisons between the digitally processed three-dimensional image and:</claim-text>
<claim-text>(i) a physical parameter characteristic associated with the milking animal, or</claim-text>
<claim-text>(ii) a previously recorded digitally processed three-dimensional image of the milking animal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The arrangement of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the three-dimensional camera is provided to record a three-dimensional digital image of the udder of the milking animal from a position below the udder of the milking animal.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The arrangement of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>said three-dimensional camera is configured to be directed towards the milking animal to record a further three-dimensional image of the milking animal; and</claim-text>
<claim-text>the image processing device is configured to digitally process the further recorded three-dimensional image and determine the weight of the milking animal based on the digitally processed further three-dimensional image and a table that correlates dimensions or volumes with weights for the species or breed to which the milking animal belongs.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The arrangement of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein said three-dimensional camera is located above the milking animal and is directed downwards towards the milking animal when recording the further three-dimensional image of the milking animal.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The arrangement of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:
<claim-text>said arrangement comprises a second three-dimensional camera configured to be directed towards the milking animal to record three-dimensional images of the milking animal at different view angles; and</claim-text>
<claim-text>the image processing device is configured to digitally process the recorded three-dimensional images at different view angles and determine the weight of the milking animal based on the digitally processed three-dimensional images at different view angles and the table that correlates dimensions with weights for the breed to which the milking animal belongs.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. A method for attaching teat cups to the teats of a milking animal in a rotary milking system having a rotatable milking stall for housing the milking animal during milking, said method comprising:
<claim-text>directing a three-dimensional camera towards the teats of the milking animal in the rotatable milking stall;</claim-text>
<claim-text>repeatedly recording three-dimensional images of the teats of the milking animal in real time by said three-dimensional camera;</claim-text>
<claim-text>repeatedly recording three-dimensional images of teat cups located in a magazine, configured to rotate with the rotatable milking stall, in real time by said three-dimensional camera and determining the positions of the teat cups in three spatial dimensions based on said repeatedly recorded three-dimensional images of the teat cups located in the rotatable magazine, wherein the three-dimensional camera is configured to not rotate along with the rotatable milking stall and the rotatable magazine;</claim-text>
<claim-text>repeatedly detecting the teats of the milking animal in the rotatable milking stall and determining the positions of the teats in three spatial dimensions based on said repeatedly recorded three-dimensional images of the teats; and</claim-text>
<claim-text>automatically attaching at least one teat cup, from the rotatable magazine, to at least one teat of the milking animal in the rotatable milking stall based on the determined position of the teats.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein said three-dimensional camera is a three-dimensional time-of-flight camera.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. An arrangement for attaching teat cups to teats of a milking animal in a rotary milking system having a rotatable milking stall for housing the milking animal during milking, the arrangement comprising:
<claim-text>a three-dimensional camera configured to be directed towards the udder of the milking animal in the rotatable milking stall and to record three-dimensional images of the udder of the milking animal, said three-dimensional camera further configured to be directed towards teat cups located in a magazine, configured to rotate with the rotatable milking stall, and to record three-dimensional images of the teat cup, wherein the three-dimensional camera is configured to not rotate along with the rotatable milking stall and the rotatable magazine;</claim-text>
<claim-text>an image processing device configured to:</claim-text>
<claim-text>detect the teats of the milking animal in the rotatable milking stall and determine the positions of the teats in three spatial dimensions based on said recorded three-dimensional images of the teats, and</claim-text>
<claim-text>detect the plurality of teat cups in the rotatable magazine and determine the positions of the teat cups in three spatial dimensions based on said recorded three-dimensional images of the teat cups located in the rotatable magazine; and</claim-text>
<claim-text>a control device configured to control a robot arm, based on the determined positions of the teats of the milking animal and the determined positions of the teat cups, to attach at least one teat cup to at least one teat of the milking animal in the rotatable milking stall. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
