<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626126-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626126</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13408594</doc-number>
<date>20120229</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>1</main-group>
<subgroup>725</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>4554121</main-classification>
</classification-national>
<invention-title id="d2e43">Selective generation of conversations from individually recorded communications</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4868867</doc-number>
<kind>A</kind>
<name>Davidson et al.</name>
<date>19890900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6029063</doc-number>
<kind>A</kind>
<name>Parvulescu et al.</name>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4554121</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6643621</doc-number>
<kind>B1</kind>
<name>Dodrill et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7013267</doc-number>
<kind>B1</kind>
<name>Huart et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7970875</doc-number>
<kind>B1</kind>
<name>Shaffer et al.</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2004/0121790</doc-number>
<kind>A1</kind>
<name>Wolff et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455518</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>4554121</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130225133</doc-number>
<kind>A1</kind>
<date>20130829</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Goertz</last-name>
<first-name>Michael</first-name>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Achtzehn</last-name>
<first-name>Jeff</first-name>
<address>
<city>Gilroy</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Goertz</last-name>
<first-name>Michael</first-name>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Achtzehn</last-name>
<first-name>Jeff</first-name>
<address>
<city>Gilroy</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Kaplan</last-name>
<first-name>Cindy</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Cisco Technology, Inc.</orgname>
<role>02</role>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Beamer</last-name>
<first-name>Temica M</first-name>
<department>2646</department>
</primary-examiner>
<assistant-examiner>
<last-name>Ajayi</last-name>
<first-name>Joel</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">In one embodiment, a method includes recording a communication at a mobile device, wherein the recorded communication is a user's portion of a conversation between the user and at least one other participant, transmitting the recorded communication to a network device, transmitting a request for the conversation to the network device, and receiving the conversation generated from the recorded communication and at least one other recorded communication from the other participant. An apparatus is also disclosed.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="143.68mm" wi="181.95mm" file="US08626126-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="192.28mm" wi="176.87mm" orientation="landscape" file="US08626126-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="206.33mm" wi="201.25mm" file="US08626126-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="230.04mm" wi="175.60mm" file="US08626126-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="183.47mm" wi="93.05mm" file="US08626126-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="185.50mm" wi="95.00mm" file="US08626126-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present disclosure relates generally to communication systems, and more particularly, to selective generation of conversations from individually recorded communications.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Mobile devices are increasingly used as primary communication devices for many users. There may be times when a user cannot recall parts of a conversation previously had using the mobile device and would like to review the conversation. The user may not have thought to record the conversation at the time, and even if the user had the foresight to record the conversation, recording a conversation between multiple parties may interfere with other people's privacy rights.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example of a network in which embodiments described herein may be implemented.</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 2</figref> depicts an example of a mobile device useful in implementing embodiments described herein.</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a system for storing recorded communications and recreating conversations, in accordance with one embodiment.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating an overview of a process at a mobile device for recording a communication and requesting a conversation recreated from individually recorded communications, in accordance with one embodiment.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating an overview of a process at a network device for storing recorded communications and generating a recording of the conversation from the recorded communications, in accordance with one embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0009" num="0008">Corresponding reference characters indicate corresponding parts throughout the several views of the drawings.</p>
<heading id="h-0004" level="1">DESCRIPTION OF EXAMPLE EMBODIMENTS</heading>
<heading id="h-0005" level="1">Overview</heading>
<p id="p-0010" num="0009">In one embodiment, a method generally comprises recording a communication at a mobile device, wherein the recorded communication comprises the user's portion of a conversation between the user and at least one other participant, transmitting the recorded communication to a network device, transmitting a request for the conversation to the network device, and receiving the conversation generated from the recorded communication and at least one other recorded communication from the other participant.</p>
<p id="p-0011" num="0010">In another embodiment, a method generally comprises receiving and storing a plurality of recorded communications at a network device, each of the recorded communications representing a participant's portion of a conversation between at least two participants, receiving a request for the conversation, generating the conversation from the recorded communications at a network device, and transmitting the generated conversation.</p>
<p id="p-0012" num="0011">In yet another embodiment, an apparatus generally comprises memory for storing a plurality of recorded communications, each of the recorded communications representing a participant's portion of a conversation between at least two participants, and a processor for receiving a request for the conversation, generating the conversation from the recorded communications, and transmitting the generated conversation.</p>
<heading id="h-0006" level="1">Example Embodiments</heading>
<p id="p-0013" num="0012">The following description is presented to enable one of ordinary skill in the art to make and use the embodiments. Descriptions of specific embodiments and applications are provided only as examples, and various modifications will be readily apparent to those skilled in the art. The general principles described herein may be applied to other applications without departing from the scope of the embodiments. Thus, the embodiments are not to be limited to those shown, but are to be accorded the widest scope consistent with the principles and features described herein. For purpose of clarity, details relating to technical material that is known in the technical fields related to the embodiments have not been described in detail.</p>
<p id="p-0014" num="0013">The embodiments described herein may be used to selectively generate a recreation of a multiparty conversation from individually recorded communications without having to know in advance that the conversation should be recorded. In one embodiment, each participant's portion of the conversation is recorded and transmitted to a central storage device. As described below, each participant's portion of the conversation may be included in the generated recording of the conversation, if the user requesting the conversation and participants belong to a common group that allows others within their group to use their recorded communications.</p>
<p id="p-0015" num="0014">The term &#x2018;communication&#x2019; as used herein refers to a user's or participant's portion of a conversation. The term &#x2018;conversation&#x2019; as used herein refers to a multiparty conversation and may be an original conversation taking place between participants in which two or more of the participants' portions of the conversation are recorded (recorded communication) or a generated conversation, which is a recreation of the original conversation from the recorded communications. The generated conversation may be audio, video (i.e., video including text), or both audio and video.</p>
<p id="p-0016" num="0015">The communication is recorded at a mobile device and includes audio only for the mobile device user's portion of the conversation. The conversation may take place over the mobile device (e.g., user talking to another participant over a cellular phone connection), may be live (e.g., with one or more participants in same room with user), or a combination of both. If participants other than the user are present and their voices can be picked up by the mobile device, the mobile device is preferably configured to filter out the other participants' voices so that only the user's portion of the conversation is recorded. This may be accomplished, for example, by the use of a microphone or headset worn by the user. The other participant's portion of the conversation may be recorded on their mobile device.</p>
<p id="p-0017" num="0016">Referring now to the drawings, and first to <figref idref="DRAWINGS">FIG. 1</figref>, an example of a network in which embodiments described herein may be implemented is shown. For simplification, only a small number of nodes are shown in a communication system. The communication system includes mobile devices <b>10</b> in communication with a network device <b>12</b> over a network <b>14</b>.</p>
<p id="p-0018" num="0017">The network <b>14</b> may include one or more networks (e.g., local area network, wireless local area network, cellular network, metropolitan area network, wide area network, satellite network, Internet, intranet, radio access network, public switched network, virtual private network, or any other network or combination thereof). Communication paths between the mobile devices <b>10</b> and network device <b>12</b> may include any number or type of intermediate nodes (e.g., routers, switches, gateways, base stations, access points, or other network devices), which facilitate passage of data between the devices.</p>
<p id="p-0019" num="0018">The mobile device <b>10</b> may be any suitable equipment that supports wireless communication, including for example, a cellular phone, personal digital assistant, portable computing device, tablet, multimedia device, and the like. The mobile device <b>10</b> may be in communication with a base station (not shown), which connects to a wired data network and serves as a gateway or access point through which the mobile device <b>10</b> has access to the network <b>14</b>. The mobile device <b>10</b> and base station each include one or more antenna for wireless communication (e.g., 3G/4G (third generation/fourth generation of cellular wireless standards) wide area network (WAN) connection). The mobile device <b>10</b> may also comprise a Wi-Fi interface and communicate with the network <b>14</b> via an access point (not shown), rather than the base station.</p>
<p id="p-0020" num="0019">The mobile device <b>10</b> includes a recording module <b>16</b> (e.g., software, application, code, program, device) used to record an audio communication at the mobile device <b>10</b>. The recording module <b>16</b> may be configured, for example, to record only the user's portion of a conversation, along with the time and date of the conversation. The audio communications recorded at mobile device <b>10</b> are uploaded to network storage (e.g., memory <b>20</b>) at network device <b>12</b>. The mobile device <b>10</b> is preferably configured to compress the audio before transmitting the audio to the network device <b>12</b>. The audio may be encrypted, compressed, or encoded according to any format. The network device <b>12</b> may also be configured to decompress or decrypt audio received from the mobile device <b>10</b> and compress or encrypt audio or video transmitted to the mobile device. Details of one example of the mobile device <b>10</b> are described below with respect to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0021" num="0020">The network device <b>12</b> may be any device (e.g., server, host) or group of devices configured to receive, process, and store recorded audio communications from the mobile devices <b>10</b>. The network device <b>12</b> is a programmable machine that may be implemented in hardware, software, or any combination thereof. The network device <b>12</b> includes one or more processor <b>18</b>, memory <b>20</b>, and network interface <b>22</b>. Memory <b>20</b> may be a volatile memory or non-volatile storage, which stores various applications, operating systems, modules, and data for execution and use by the processor <b>18</b>. Recorded communications <b>24</b> may be stored in memory <b>20</b>. Memory <b>20</b> may also store trust groups or a list of recorded communications or available conversations identified by date/time, participants, or keywords, for example.</p>
<p id="p-0022" num="0021">The recorded communications <b>24</b> are stored at network storage at the network device (e.g., memory <b>20</b>) or remotely located network storage. The network storage may be configured to provide a first-in-first-out buffer of a specified duration (e.g., day, week, month) and may also be configured to prioritize conversations. For example, the user may identify an important conversation or one or more communications as high priority, in which case these recorded communications remain in storage after other lower priority communications are deleted to make room for new communications. The user may also select preferences for prioritizing communications. For example, the user may identify high priority conversations as those which include select participants or communications that contain specified keywords. The user may also identify conversations or communications with low priority (e.g., those including selected participants or containing specified keywords). Low priority communications may be stored in memory for shorter durations or may not be stored at all.</p>
<p id="p-0023" num="0022">Logic may be encoded in one or more tangible media for execution by the processor <b>18</b>. For example, the processor <b>18</b> may execute codes stored in a computer-readable medium such as memory <b>20</b>. The computer-readable medium may be, for example, electronic (e.g., RAM (random access memory), ROM (read-only memory), EPROM (erasable programmable read-only memory)), magnetic, optical (e.g., CD, DVD), electromagnetic, semiconductor technology, or any other suitable medium.</p>
<p id="p-0024" num="0023">The network interface <b>22</b> may comprise one or more interfaces (linecards, ports) for receiving signals or data or transmitting signals or data to other devices. The interface <b>22</b> may include, for example, an Ethernet interface for connection to a computer or network.</p>
<p id="p-0025" num="0024">The network device <b>12</b> also includes a conversation module <b>26</b> operable to generate a conversation (e.g., audio/video recording) from two or more recorded audio communications representing different participants' portions of the conversation. As described in detail below with respect to <figref idref="DRAWINGS">FIG. 3</figref>, the conversation module <b>26</b> is configured to interact with the mobile device <b>10</b>, tag/categorize received communications, store recorded communications, search a database of recorded communications, and generate a conversation from the recorded communications. The generated conversation may be an audio recreation of the original conversation, a video containing text corresponding to the recorded audio, or an animated video with audio.</p>
<p id="p-0026" num="0025">The network device <b>12</b> may be configured, for example, to generate a transcription of the recorded audio communication. The transcription (e.g., computer generated transcription) may be used to identify keywords (e.g., for use in prioritizing or tagging the recorded communication as described below) or to provide text for display in a video, in which case audio is not needed for the generated conversation.</p>
<p id="p-0027" num="0026">In another example, the generated conversation comprises video and audio. In one embodiment, the user may choose an avatar (e.g., from a group of preloaded graphical images) or create an avatar to represent the user. The user may also specify a preferred or default avatar to use to represent him in any generated video. The avatars may be configured such that their emotions, voices, or gestures differ based on the recorded communication. The avatars may also automatically lip-sync the recorded words. The user may also select from a variety of scenes for the video (e.g., cubicle, park, office, dinner table) and pick camera angles, sound effects, etc.</p>
<p id="p-0028" num="0027">In one embodiment, the network device <b>12</b> is operable to configure security groups each containing a list of people that the user trusts enough to access the user's portion of the conversation. The trust group may include, for example, friends, family, co-workers, team members, employers, employees, etc. If a participant is in the user's trust group, the participant's portion of the conversation is included in the generated conversation. The conversation may include, for example, two or more of the participants' recorded communications, while leaving out one or more other participant's portion of the conversation if they are not included in the user's trust group or their portion of the conversation was not recorded. The system may also be configured to allow participants to exclude their portion of the conversation for a specified communication (e.g., date/time, participants).</p>
<p id="p-0029" num="0028">It is to be understood that the network and network device <b>12</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> and described herein are only examples and that other networks and network devices having different components or configurations may be used, without departing from the scope of the embodiments. For example, the network device <b>12</b> may further include any suitable combination of hardware, software, algorithms, processors, devices, components, or elements operable to facilitate the capabilities described herein.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of the mobile device <b>10</b> in which embodiments described herein may be implemented. The mobile device <b>10</b> includes a visual display <b>32</b> and a keypad <b>34</b> comprising multiple keys (not shown) used in operation of the device. The screen <b>32</b> may be used to display a graphical user interface for use in entering user preferences (e.g., priorities, number of communications to store, time period to store communications) or other information (e.g., user identifier or password, trust group, mobile identifier). The screen <b>32</b> may also be used to display a video of the generated conversation. The keypad <b>34</b> may also be a touch screen integrated with the display <b>32</b>. The keypad <b>34</b> may include numeric keys, alphabetic keys, standard telephone keys, or any other icons or symbols. The mobile device <b>10</b> may include any number of other user interfaces such as one or more manual buttons (e.g., switch <b>35</b>).</p>
<p id="p-0031" num="0030">A user can select and activate the recording module <b>16</b> by touching the display screen <b>32</b> (e.g., selecting an icon on the touch screen) or pressing one or more buttons. Once activated, the recording module <b>16</b> may record all communications at the mobile device <b>10</b> (e.g., calls initiated by user at the mobile device <b>10</b>, incoming calls received at the mobile device, or user's conversations at the location of the mobile device). The mobile device <b>10</b> may also be configured so that a user can selectively initiate or turn off the recording module <b>16</b> using one or more user interfaces. For example, after the recording module <b>16</b> is activated, the user may be presented with an option such as &#x201c;Press to start recording&#x201d;, or the recording may be automatically initiated at the start of each new communication. Once the recording module is active, another message may be displayed on the touch screen (e.g., &#x201c;Press to stop recording&#x201d;).</p>
<p id="p-0032" num="0031">In one embodiment, the recording module <b>16</b> (or other module or application at mobile device <b>10</b>) may be configured for displaying a graphical user interface on the display screen <b>32</b> for use by the user in requesting a generated conversation from network device <b>12</b>. For example, the graphical user interface may present the user with a list of available conversations (e.g., identified by date/time, participants, keywords) and options (e.g., participants to include, format (audio, video, audio and video), portion of conversation). The graphical user interface may also be used to enter search information for use in finding a conversation to recreate.</p>
<p id="p-0033" num="0032">Referring again to <figref idref="DRAWINGS">FIG. 2</figref>, the mobile device <b>10</b> also includes an antenna <b>36</b>, which may be internal or external to the device, for wireless communications. One or more external ports <b>38</b> may be provided for connection with another input or output device (e.g., external display or microphone). The mobile device <b>10</b> also includes a speaker <b>37</b> and microphone <b>39</b>.</p>
<p id="p-0034" num="0033">As illustrated in the block diagram of <figref idref="DRAWINGS">FIG. 2</figref>, the mobile device <b>10</b> further includes memory <b>40</b>, one or more processors <b>42</b>, mobile device controller <b>44</b>, RF (Radio Frequency) circuitry <b>46</b>, network interface <b>48</b>, and recording module <b>16</b>.</p>
<p id="p-0035" num="0034">Memory <b>40</b>, which may include one or more computer readable storage mediums, may be any form of volatile or nonvolatile memory, including for example, random access memory (RAM), read-only memory (ROM), magnetic media, optical media, flash memory, removable media, or any other suitable memory component. Memory <b>40</b> may store any data or information, including software and encoded logic, utilized by the mobile device <b>10</b>. Memory <b>40</b> may also store the recorded communication before it is transmitted to the network device <b>12</b>.</p>
<p id="p-0036" num="0035">The one or more processors <b>42</b> run or execute various code, software programs, or instructions stored in memory <b>40</b> to perform functions for the mobile device <b>10</b> and to process data. Logic may be encoded in one or more tangible media for execution by the processor <b>42</b>. For example, memory <b>40</b> can be utilized to store and retrieve software programs incorporating computer code that implements aspects of the embodiments, data for use with the embodiments, and the like. As described above, the processor may also be configured to encode/decode audio or video.</p>
<p id="p-0037" num="0036">The RF circuitry <b>46</b> receives and transmits RF signals and converts electrical signals to or from electromagnetic signals and communicates with communication devices via the electromagnetic signals. Communication circuitry allows the mobile device <b>10</b> to communicate with other network devices using any suitable communications protocol.</p>
<p id="p-0038" num="0037">The mobile device controller <b>44</b> provides for management and control of various elements within the device <b>10</b>. For example, the controller <b>44</b> may access information maintained within memory <b>40</b> and control other elements to interact with users and other communication devices.</p>
<p id="p-0039" num="0038">The network interface <b>48</b> may include one or more interfaces. The interfaces <b>48</b> may comprise, for example, a radio interface (e.g., 3G/4G radio interface) for communication via a base station or a Wi-Fi interface for communication with an access point.</p>
<p id="p-0040" num="0039">It is to be understood that the mobile device <b>10</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> and described herein is only one example of a mobile device, and that the device may have additional, fewer, or different components, or a different arrangement or configuration of components, without departing from the scope of the embodiments. For example, the mobile device <b>10</b> may further include any suitable combination of hardware, software, algorithms, processors, devices, components, or elements operable to facilitate the capabilities described herein.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating components of a communication storage and conversation construction system <b>50</b>, in accordance with one embodiment. In the example shown in <figref idref="DRAWINGS">FIG. 3</figref>, the system includes a user interface <b>52</b>, tag/categorize module <b>54</b>, database <b>56</b>, search engine <b>58</b>, and conversation generator <b>60</b>. Recorded communications are received from the mobile devices <b>10</b> at the tag/categorize module <b>54</b>. The communications may be categorized, for example, by user, date/time, participants, keywords, etc. In one embodiment, the tag/categorize module <b>54</b> is configured to translate the audio to text for use in identifying keywords in the communication. The module <b>54</b> transmits the tagged/categorized communications to the database <b>56</b> for storage.</p>
<p id="p-0042" num="0041">The database <b>56</b> may also contain access control lists (e.g., trust groups) for use in identifying whether or not a specified user is allowed access to recorded communications from other participants.</p>
<p id="p-0043" num="0042">The user interface <b>52</b> interacts with the mobile device <b>10</b> to receive requests for generated conversations. The user interface <b>52</b> may also receive information from the search engine <b>58</b> for use in generating a list of available conversations. The list may include, for example, conversations identified by date/time, participants, keywords, priority, etc.</p>
<p id="p-0044" num="0043">The search engine <b>58</b> uses the information provided in a user request to search the database <b>56</b> for recorded communications which are part of the requested conversation. The search engine <b>58</b> is preferably configured to rapidly locate specific communications stored in database <b>56</b>. The search engine <b>58</b> retrieves the recorded communications that are part of the requested conversation and for which the user is authorized to receive. For example, a conversation may comprise three recorded communications (from the user and two other participants), however, only one participant is in the same trust group as the user. In this case, the generated conversation will only include two of the recorded communications. The search engine <b>58</b> transmits the recorded communications to the conversation generator <b>60</b>. The generator <b>60</b> stitches together the recorded communications in the requested format (e.g., audio, video, audio and video). The conversation generator <b>60</b> may use a time stamp or common audio signal in the recordings to properly align the communications. The conversation generator <b>60</b> may receive format information or other preferences from the user interface <b>52</b> for use in recreating the conversation.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating an overview of a process at the mobile device <b>10</b> for recording a communication and requesting a generated conversation, in accordance with one embodiment. At step <b>62</b>, a communication is recorded at the mobile device <b>10</b> using recording module <b>16</b>. In one example, the recording module <b>16</b> at the user's mobile device records the user's portion of the conversation, and another participant's portion of the conversation is recorded at their mobile device. The recorded communications from each mobile device <b>10</b> are transmitted to the network device <b>12</b> (step <b>64</b>). The user may request a conversation by identifying a date and time, participants, keywords, etc., or selecting the conversation from a list of available conversations (step <b>66</b>).</p>
<p id="p-0046" num="0045">For example, the user may realize that a conversation he had on the previous day would be of interest to others on his team. The user may scroll through a list of his conversations and identify the one he wants (e.g., based on time of conversation or participants). The user may also request a format (e.g., audio, video, audio and video) for the generated conversation and select one or more options (e.g., specify avatars for use in the video). The user may also enter a name or password for a trust group in order to have access to recorded communications corresponding to the other participants' portions of the conversation. The network device <b>12</b> generates the requested conversation, as described below with respect to <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0047" num="0046">The mobile device <b>10</b> receives the generated conversation from the network device <b>12</b> (step <b>68</b>). The generated conversation may be delivered, for example, via streaming video or file to the mobile device <b>10</b> or may be sent to a specified contact (e.g., user e-mail).</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating an overview of a process at the network device <b>12</b> for storing recorded communications and generating a conversation (recording of the conversation) from the recorded communications, in accordance with one embodiment. At step <b>70</b>, the network device <b>12</b> receives recorded communications from recording modules <b>16</b> at mobile devices <b>10</b>. The network <b>12</b> device may tag or categorize the communications as previously described and stores the recorded communications (step <b>72</b>). The recorded communication may be identified, for example, by the user (e.g., username, identifier, password), participants, date/time, keyword, or any combination thereof. The network device <b>12</b> may also generate a list of recorded communications and link related communications (i.e., recorded communications from same conversation). As previously described, the network device <b>12</b> may generate a list of the recorded communications or conversations for each user and transmit the list to the user's mobile device <b>10</b> for use in selecting a conversation.</p>
<p id="p-0049" num="0048">The network device <b>12</b> receives a request for a conversation generated from two or more recorded communications (step <b>74</b>). The request may identify, for example, the user and date/time of communication or may indicate a conversation selected from a list presented to the user on the mobile device <b>10</b>. If the other participants in the conversation are in the same trust group as the user requesting the conversation, the network device <b>12</b> allows the user to include the other participants' recorded communications (portions of the conversation) in the generated conversation. The request may also specify one or more options for the conversation (e.g., format, graphical image to represent user, background, music, special effects). If no preferences are specified, stored user options or default options may be used.</p>
<p id="p-0050" num="0049">The network device <b>12</b> generates the conversation from the recorded audio communications (step <b>76</b>). The individually recorded communications are stitched together using, for example, time as a common indicator. The network device <b>12</b> transmits the generated conversation to the user requesting the conversation (step <b>78</b>). As noted above, video may be transmitted, for example, as streaming video to the mobile device <b>10</b> associated with the user or a file (e.g., audio, video, audio and video) may be transmitted to the user's e-mail or mobile device.</p>
<p id="p-0051" num="0050">It is to be understood that the processes illustrated in <figref idref="DRAWINGS">FIGS. 4 and 5</figref> are only examples and that steps may be modified, added, removed, or combined, without departing from the scope of the embodiments.</p>
<p id="p-0052" num="0051">Although, the method and apparatus have been described in accordance with the embodiments shown, one of ordinary skill in the art will readily recognize that there could be variations made without departing from the scope of the embodiments. Accordingly, it is intended that all matter contained in the above description and shown in the accompanying drawings shall be interpreted as illustrative and not in a limiting sense.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>recording a communication at a mobile device, wherein the recorded communication comprises a user's portion of a conversation between the user and at least one other participant, said at least one other participant's portion of the conversation not included in the recorded communication;</claim-text>
<claim-text>transmitting the recorded communication comprising the user's portion of the conversation, from the mobile device to a network device operable to combine the user's portion of the conversation and said at least one other participant's portion of the conversation to generate the conversation from the recorded communication and at least one other recorded communication from said at least one other participant;</claim-text>
<claim-text>transmitting a request for the conversation to the network device; and</claim-text>
<claim-text>receiving the generated conversation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein recording a communication comprises automatically recording communications at the mobile device.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the generated conversation comprises a video comprising images representing the user and said at least one other participant and audio of the recorded communications.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the generated conversation comprises audio of the recorded communications.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the generated conversation comprises the recorded communications from all participants in the conversation belonging to a common trust group with the user.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein transmitting said request comprises selecting the conversation from a list of available conversations.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein transmitting said request comprises identifying a format for the generated conversation.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A method comprising:
<claim-text>receiving and storing a plurality of recorded communications from mobile devices at a network device, each of the recorded communications comprising only a participant's portion of a conversation between at least two participants, each of the participants associated with one of the mobile devices;</claim-text>
<claim-text>receiving a request for the conversation;</claim-text>
<claim-text>generating at the network device, the conversation by combining at least two of the participant's portions of the conversation to generate the conversation from the recorded communications; and</claim-text>
<claim-text>transmitting the generated conversation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the generated conversation comprises a video comprising images representing the participants and audio of the recorded communications.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the generated conversation comprises the recorded communications from all participants in the conversation belonging to a common trust group.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising categorizing the recorded communications.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising transcribing the recorded communications and identifying keywords in the recorded communications for use in tagging the recorded communications.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising generating a list of available conversations stored at the network device.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising searching a database for the recorded communications associated with the conversation after receiving said request for the conversation.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An apparatus comprising:
<claim-text>memory for storing a plurality of recorded communications received from mobile devices, each of the recorded communications comprising only a participant's portion of a conversation between at least two participants, each participant associated with one of the mobile devices; and</claim-text>
<claim-text>a processor for receiving a request for the conversation, generating the conversation by combining at least two of the participant's portions of the conversation to generate the conversation from the recorded communications, and transmitting the generated conversation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref> further comprising a module for categorizing the recording communications.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref> further comprising a search engine for locating the recorded communications associated with the conversation.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the generated conversation comprises a video comprising images representing the participants and audio of the recorded communications.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the memory further stores a list of users associated with a trust group and wherein the generated conversation comprises the recorded communications from all participants in the conversation belonging to a common trust group.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the processor is operable to transcribe the recorded communications and identify keywords in the recorded communications for use in tagging the recorded communications. </claim-text>
</claim>
</claims>
</us-patent-grant>
