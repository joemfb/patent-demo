<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627300-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627300</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12578295</doc-number>
<date>20091013</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>688</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>45</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>717149</main-classification>
<further-classification>717150</further-classification>
<further-classification>717151</further-classification>
<further-classification>717152</further-classification>
<further-classification>717153</further-classification>
<further-classification>717154</further-classification>
<further-classification>717155</further-classification>
<further-classification>717156</further-classification>
<further-classification>717157</further-classification>
<further-classification>717158</further-classification>
<further-classification>717159</further-classification>
<further-classification>717160</further-classification>
<further-classification>717161</further-classification>
</classification-national>
<invention-title id="d2e53">Parallel dynamic optimization</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4210962</doc-number>
<kind>A</kind>
<name>Marsh et al.</name>
<date>19800700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705  711</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4916659</doc-number>
<kind>A</kind>
<name>Persoon et al.</name>
<date>19900400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5806059</doc-number>
<kind>A</kind>
<name>Tsuchida et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5826079</doc-number>
<kind>A</kind>
<name>Boland et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6289369</doc-number>
<kind>B1</kind>
<name>Sundaresan</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6567806</doc-number>
<kind>B1</kind>
<name>Tsuchida et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>  1  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6658448</doc-number>
<kind>B1</kind>
<name>Stefaniak et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6745336</doc-number>
<kind>B1</kind>
<name>Martonosi et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713340</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6769017</doc-number>
<kind>B1</kind>
<name>Bhat et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6782410</doc-number>
<kind>B1</kind>
<name>Bhagat et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7143412</doc-number>
<kind>B2</kind>
<name>Koenen</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7146607</doc-number>
<kind>B2</kind>
<name>Nair et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717151</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>7363523</doc-number>
<kind>B2</kind>
<name>Kurts et al.</name>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>7383396</doc-number>
<kind>B2</kind>
<name>Wyman</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711141</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>7574567</doc-number>
<kind>B2</kind>
<name>Wyman</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711141</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>8078832</doc-number>
<kind>B1</kind>
<name>Agarwal et al.</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>8108843</doc-number>
<kind>B2</kind>
<name>Nair et al.</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717139</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>8181169</doc-number>
<kind>B2</kind>
<name>Nakaike et al.</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717151</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>8214817</doc-number>
<kind>B2</kind>
<name>Mendelson et al.</name>
<date>20120700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>8443341</doc-number>
<kind>B2</kind>
<name>Berg et al.</name>
<date>20130500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2003/0171907</doc-number>
<kind>A1</kind>
<name>Gal-On et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703 14</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2003/0236919</doc-number>
<kind>A1</kind>
<name>Johnson et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2004/0181730</doc-number>
<kind>A1</kind>
<name>Monfared et al.</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2005/0154861</doc-number>
<kind>A1</kind>
<name>Arimilli et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2005/0210472</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2005/0246461</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2006/0041599</doc-number>
<kind>A1</kind>
<name>Tsuchida et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707200</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2007/0027972</doc-number>
<kind>A1</kind>
<name>Agrawal et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2007/0044084</doc-number>
<kind>A1</kind>
<name>Wang et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717151</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2007/0079308</doc-number>
<kind>A1</kind>
<name>Chiaramonte et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2008/0046895</doc-number>
<kind>A1</kind>
<name>Dillenberger et al.</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2008/0126751</doc-number>
<kind>A1</kind>
<name>Mizrachi et al.</name>
<date>20080500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2008/0178183</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2008/0229127</doc-number>
<kind>A1</kind>
<name>Felter et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>2009/0031317</doc-number>
<kind>A1</kind>
<name>Gopalan et al.</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>2009/0031318</doc-number>
<kind>A1</kind>
<name>Gopalan et al.</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>2009/0070553</doc-number>
<kind>A1</kind>
<name>Wallach et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>712 34</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>2009/0077562</doc-number>
<kind>A1</kind>
<name>Sen et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>2009/0125894</doc-number>
<kind>A1</kind>
<name>Nair et al.</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>2009/0126006</doc-number>
<kind>A1</kind>
<name>Zhang et al.</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>2010/0122101</doc-number>
<kind>A1</kind>
<name>Naffiger et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>2010/0225496</doc-number>
<kind>A1</kind>
<name>Hou et al.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>2011/0088022</doc-number>
<kind>A1</kind>
<name>Kruglick</name>
<date>20110400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>2011/0088038</doc-number>
<kind>A1</kind>
<name>Kruglick</name>
<date>20110400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>2011/0093733</doc-number>
<kind>A1</kind>
<name>Kruglick</name>
<date>20110400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00046">
<document-id>
<country>EP</country>
<doc-number>1736851</doc-number>
<kind>A2</kind>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>Albonesi, D., &#x201c;Selective Cache Ways: On-Demand Cache Resource Allocation,&#x201d; Nov. 1999, Proceedings of the International Symposium on Microarchitecture, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>Bala, et al., &#x201c;Dynamo: A Transparent Dynamic Optimization System,&#x201d; Jun. 2000, Proceedings of Programming Language Design and Implementation, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>Baraz, et al., &#x201c;IA<sub>&#x2014;</sub>32 Execution Layer: A Two-Phase Dynamic Translator Designed to Support IA-32 Application on Itanium&#xae;-based Systems,&#x201d; Dec. 2003, Proceedings of the 36th International Symposium on Microarchitecture, 11 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00050">
<othercit>Dehnert, et al., &#x201c;The Transmeta Code Morphing&#x2122; Software: Using Speculation, Recovery, and Adaptive Retranslation to Address Real-Life Challenges,&#x201d; 2003, ACM International Conference Proceedings Series, vol. 37, Proceedings of the International Symposium on Code Generation and Optimization: Feedback-directed and Runtime Optimization, Abstract, 9 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>Ebcioglu, et al., &#x201c;DAISY: Dynamic Compilation for 100% Architectural Compatibility,&#x201d; 1997, Proceedings of the 24th International Symposium on Computer Architecture, 13 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00052">
<othercit>Microsoft .NET Framework, http://www.microsoft.com/net/, accessed Oct. 13, 2009, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00053">
<othercit>International Search Report and Written Opinion dated Feb. 3, 2011 in PCT Application No. PCT/US10/53110.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>U.S. Office Action dated Jan. 31, 2012 in U.S. Appl. No. 12/578,321.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>U.S. Office Action dated Jul. 5, 2012 in U.S. Appl. No. 12/578,321.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00056">
<othercit>U.S. Office Action dated Jun. 21, 2012 in U.S. Appl. No. 12/578,336.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00057">
<othercit>U.S. Office Action dated Nov. 14, 2011 in U.S. Appl. No. 12/582,301.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00058">
<othercit>U.S. Office Action dated Jun. 28, 2012 in U.S. Appl. No. 12/582,301.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00059">
<othercit>Kang et al., &#x201c;Preliminary Study toward Intelligent Run-time Resource Management Techniques for Large Multi-Core Architectures,&#x201d; Apr. 15, 2008, University of Southern California&#x2014;Information Sciences Institute, 2 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00060">
<othercit>Song, et al., &#x201c;Analytical Modeling and Optimization for Affinity Based Tread Scheduling on Multicore Systems&#x201d;, Jul. 14, 2009, IEEE CLUSTER 2009, New Orleans, Louisiana, 10 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00061">
<othercit>Song, et al., &#x201c;Feedback-Directed Thread Scheduling with Memory Considerations,&#x201d; ACM, Jun. 2007, pp. 1-10.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00062">
<othercit>Brooks et al., &#x201c;Dynamic Thermal Management for High-Performance Microprocessors&#x201d; Jan. 2001, Proceedings of the 7th International Symposium on High Performance Computer Architecture, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00063">
<othercit>Donald et al., &#x201c;Techniques for Multicore Thermal Management: Classification and New Exploration&#x201d;. Jun. 2006, Proceedings of the 33rd Annual International Symposium on Computer Architecture, pp. 78-88.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00064">
<othercit>Shirako et al., &#x201c;Compiler Control Power Saving Scheme for Multi Core Processors&#x201d; In Lecture Notes in Computer Science: Languages and Compilers for Parallel Computing. vol. 4339/2006. Springer-Verlag, Berlin, pp. 362-376, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00065">
<othercit>&#x201c;P6T New Era for Ultimate Performance! Intel&#xae; Core&#x2122; i7 Platform,&#x201d; accessed at http://www.asus.com/Motherboards/Intel<sub>&#x2014;</sub>Socket<sub>&#x2014;</sub>1366/P6T/, accessed on Mar. 5, 2012, pp. 4.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00066">
<othercit>U.S. Office Action dated Nov. 21, 2012 in U.S. Appl. No. 12/578,336.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00067">
<othercit>U.S. Notice of Allowance dated Sep. 17, 2013 in U.S. Appl. No. 12/578,336.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00068">
<othercit>Japanese Office Action dated Sep. 3, 2013 in Japanese Application No. 2012535286 Abstract.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00069">
<othercit>U.S. Office Action dated Sep. 5, 2013 in U.S. Appl. No. 12/578,321.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110088021</doc-number>
<kind>A1</kind>
<date>20110414</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kruglick</last-name>
<first-name>Ezekiel John Joseph</first-name>
<address>
<city>Poway</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kruglick</last-name>
<first-name>Ezekiel John Joseph</first-name>
<address>
<city>Poway</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Hope Baldauff, LLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Empire Technology Development LLC</orgname>
<role>02</role>
<address>
<city>Wilmington</city>
<state>DE</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Tsai</last-name>
<first-name>Henry</first-name>
<department>2184</department>
</primary-examiner>
<assistant-examiner>
<last-name>Shyu</last-name>
<first-name>Jing-Yih</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Technologies are generally described for parallel dynamic optimization using multicore processors. A runtime compiler may be adapted to generate multiple instances of executable code from a portable intermediate software module. The various instances of executable code may be generated with variations of optimization parameters such that the code instances each express different optimization attempts. A multicore processor may be leveraged to simultaneously execute some, or all, of the various code instances. Preferred optimization parameters may be determined from the executable code instances that may correctly complete in the least time, or may use the least amount of memory, or that may prove superior according to some other fitness metric. Preferred optimization parameters may be used to seed future optimization attempts. Output generated from the preferred instances may be used as soon as the first instance correctly completes block.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="230.46mm" wi="170.52mm" file="US08627300-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="201.08mm" wi="126.66mm" orientation="landscape" file="US08627300-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="237.24mm" wi="182.80mm" file="US08627300-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="220.22mm" wi="97.54mm" orientation="landscape" file="US08627300-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="214.04mm" wi="129.79mm" file="US08627300-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="253.83mm" wi="205.99mm" orientation="landscape" file="US08627300-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="253.32mm" wi="183.30mm" orientation="landscape" file="US08627300-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">Unless otherwise indicated herein, the materials described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.</p>
<p id="p-0003" num="0002">Dynamic compilations performed by compilers leveraging dynamic optimization attempt to improve the operation of software or microcode at runtime. These dynamic optimization systems may make repeated iterated executions through dynamically compiled code in attempts to find compilation optimizations. For example, procedure calls having high demand may be tracked to focus optimization on those procedure calls. Traditional dynamic optimization systems generally do not perform more complex optimizations that require additional understanding of code behavior. Furthermore, code may generally be optimized to a conservative level to ensure functionality of the resultant executable code.</p>
<p id="p-0004" num="0003">Multicore processors are generally made up of multiple processor cores with interconnections between the individual cores. As core counts within multicore processors increase, making effective use of the multiple cores within a system becomes an important operational consideration. Computers having multiple processors or multiple processor cores may often lack apparent parallelizable operations to make use of the multiple processors or processing cores.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading>
<p id="p-0005" num="0004">The foregoing and other features of this disclosure will become more fully apparent from the following description and appended claims, taken in conjunction with the accompanying drawings. Understanding that these drawings depict only several embodiments in accordance with the disclosure and are, therefore, not to be considered limiting of its scope, the disclosure will be described with additional specificity and detail through use of the accompanying drawings, in which:</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a computer having a multicore processor and a memory configured with executable software components for performing parallel dynamic optimization using multiple cores of the multicore processor;</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating parallel dynamic optimization during the runtime execution of multiple instances of executable code;</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating executable code instances within cores of a multicore processor and a graph of execution times for the instances of executable code;</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 4</figref> is a flow diagram illustrating a process for parallel dynamic optimization using multicore processors;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram illustrating an example computing system; and</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 6</figref> is a schematic illustrating a partial view of a computer program product that includes a computer program for executing a computer process on a computing device, all arranged according to at least some embodiments presented herein.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0003" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0012" num="0011">In the following detailed description, reference is made to the accompanying drawings, which form a part hereof. In the drawings, similar symbols typically identify similar components, unless context dictates otherwise. The illustrative embodiments described in the detailed description, drawings, and claims are not meant to be limiting. Other embodiments may be utilized, and other changes may be made, without departing from the spirit or scope of the subject matter presented herein. It will be readily understood that the present disclosure, as generally described herein, and illustrated in the figures can be arranged, substituted, combined, separated, and designed in a wide variety of different configurations, all of which are explicitly contemplated herein. It should be appreciated that while multicore processor embodiments are discussed throughout this disclosure, various other multiprocessor or parallel computing architectures may be leveraged for the parallel dynamic optimization technologies discussed herein. As such, a processing unit may be a core within one or more multicore processors, a processor within a multiprocessor system, a processor within any other parallel processing architecture, or any combination thereof.</p>
<p id="p-0013" num="0012">This disclosure is generally drawn to methods, apparatus, systems, and computer program products related to parallel dynamic optimization. Runtime compilation performed by compilers leveraging dynamic optimization (DO) attempt to improve the operation of software or microcode at runtime. Examples of DO systems include CODE MORPHING from TRANSMETA, DAISY from INTERNATIONAL BUSINESS MACHINES CORPORATION, DYNAMO from HEWLETT PACKARD CORPORATION, various JAVA virtual machines, MICROSOFT&#xae; .NET from MICROSOFT CORPORATION, and the INTEL&#xae; IA32 Execution Layer from INTEL CORPORATION.</p>
<p id="p-0014" num="0013">According to various embodiments presented herein, a runtime compiler may be adapted to generate many instances of executable code. The various instances of executable code may be generated with variations of optimization parameters such that the code instances each express different optimization attempts. A multiprocessor system, such as a multicore processor in one or more embodiments, may be leveraged to simultaneously execute some or all of the various code instances. Preferred optimization parameters may be determined from the executable code instances that correctly complete in the least time, or use the least amount of memory, or prove superior according to some other fitness metric. Preferred optimization parameters may be used to seed future optimization attempts, while the less desirable optimization parameters may be avoided. Output generated from the code instances using preferred optimization parameters may be used as soon as they correctly complete operation.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram that illustrates a computer <b>100</b> having a multicore processor <b>120</b> and a memory <b>12</b> configured with executable software components for performing parallel dynamic optimization using multiple cores <b>101</b>-<b>116</b> of the multicore processor <b>120</b> according to one or more embodiments presented herein. The computer <b>100</b> may employ the multiple cores <b>101</b>-<b>116</b> of the multicore processor <b>120</b> to perform various computing tasks. The computing tasks may include the execution of code such as an object file <b>230</b>. The object file <b>230</b> may be described as a portable intermediate software module. Such a portable intermediate representation may also be referred to as a thin binary, a slim binary, or a partially compiled code module. The object file <b>230</b> may contain partially compiled code from which a final generation of executable code is performed at runtime by a code generating loader <b>240</b>. The code generating loader <b>240</b> may be configured to generate many parallel, or simultaneous, instances of the executable code where each instance may be generated using different optimization parameters <b>150</b>. The optimization parameters <b>150</b> may specify settings for various compiler optimization options to be used by the code generating loader <b>240</b> as discussed in further detail below.</p>
<p id="p-0016" num="0015">The various code instances created by the code generating loader <b>240</b> may be executed in parallel, each on a respective core <b>101</b>-<b>116</b> of the multicore processor <b>120</b>. An executable code instance having a faster, or more efficient, correct completion may be considered to have been generated using a preferred set of optimization parameters <b>150</b>. Such a code instance may be referred to herein as the preferred instance. Results of the code execution may be provided from the code instance using the preferred optimization parameters as they become available. Other instances of executable code, still executing, may be terminated or observed once the preferred instance completes its execution. An optimizer <b>260</b> may be associated with execution of the generated code for identifying preferred instances of executable code and the associated preferred optimization parameters <b>150</b>. The optimizer <b>260</b> may use the preferred optimization parameters <b>150</b>, or variations thereof, to inform further operation of the code generating loader <b>240</b>.</p>
<p id="p-0017" num="0016">The memory <b>12</b> may be coupled to the multicore processor <b>120</b> to support the techniques discussed herein. For example, the memory <b>12</b> may be configured to store one or more of the object file <b>230</b>, the code generating loader <b>240</b>, the optimization parameters <b>150</b>, and/or the optimizer <b>260</b>. The code generating loader <b>240</b> and the optimizer <b>260</b> may be executed in association with the multicore processor <b>120</b> to apply parallel dynamic optimization techniques to the execution of the object file <b>230</b>. The parallel dynamic optimization may leverage one or more of the cores <b>101</b>-<b>116</b> of the multicore processor <b>120</b> to approximately optimize the runtime compilation of the object file <b>230</b>. It should also be appreciated that the techniques discussed herein may be implemented as hardware modules within, or associated with, the multicore processor <b>120</b>. The modules may also be combinations of hardware and software according to various embodiments. For example, functionality of the code generating loader <b>240</b> and the optimizer <b>260</b> may be performed by one or more hardware modules. Additional details regarding the computer <b>100</b>, including the operation of the memory <b>12</b>, are further detailed with respect to <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0018" num="0017">Turning now to <figref idref="DRAWINGS">FIG. 2</figref>, a block diagram illustrates parallel dynamic optimization during the runtime execution of multiple instances of executable code <b>250</b> according to one or more embodiments presented herein. At compile time, the compiler <b>220</b> may compile source code from a source text <b>210</b> into an object file <b>230</b>. The object file <b>230</b> may be a portable intermediate software module. The object file <b>230</b> may be distributed to various types of computing machines, such as the computer <b>100</b>, where compilation of the object file <b>230</b> may be completed locally. Local completion of the compilation may be performed at runtime. According to various embodiments, the object file <b>230</b> may run locally on the computer <b>100</b> in association with a virtual machine, a media player, a runtime player, an application plug-in, a runtime compiler, or a just-in-time (JIT) compiler.</p>
<p id="p-0019" num="0018">In association with the computer <b>100</b>, the object file <b>230</b> may be further converted into executable code <b>250</b> by a code generating loader <b>240</b>. Multiple instances of the executable code <b>250</b> may be generated by the code generating loader <b>240</b>. The multiple instances of the executable code <b>250</b> may be based on varying the optimization parameters <b>150</b> used by the code generating loader <b>240</b>. The optimization parameters <b>150</b> to be optimized, and the optimization ranges of these parameters, may be dependent upon characteristics of the computer <b>100</b> or the code generating loader <b>240</b>. According to embodiments, parameters that may be approximately optimized may include memory block sizes, memory usage, cache sizes, cache access protocols, disk access protocols, levels of loop unrolling, and balance of recalculation versus storage or look-up tables. The parameters that may be approximately optimized may also be related to the capabilities and available resources of the computer <b>100</b> where the executable code <b>250</b> is to be executed.</p>
<p id="p-0020" num="0019">The code generating loader <b>240</b> may be adapted to generate many parallel, or simultaneous, instances of the executable code where each instance may be generated using different optimization parameters <b>150</b>. The various code instances may be executed in parallel, each on one or more of cores <b>101</b>-<b>116</b> of the multicore processor <b>120</b>. The optimizer <b>260</b> may be associated with execution of the generated code for identifying preferred instances of executable code <b>250</b>. From the preferred instances, the optimizer <b>260</b> may be adapted to determine desirable values for the optimization parameters <b>150</b>. The optimizer <b>260</b> may be configured to use the preferred optimization parameters, or variations thereof, to inform further operation of the code generating loader <b>240</b>.</p>
<p id="p-0021" num="0020">The preferred optimization parameters, or variations thereof, may be stored into a database, file, memory, or other storage medium associated with optimization result records <b>270</b>. The optimization result records <b>270</b> may then provide the preferred optimization parameters for use in future executions of the object file <b>230</b>, or future operation of the code generating loader <b>240</b>. According to other embodiments, the optimization result records <b>270</b> may be uploaded by computer <b>100</b> via a network adapter over a communication network link to a network archive. The network archive may be a database, file, memory, or other storage medium associated with archiving the optimization parameters. The network archive may be used to establish and/or suggest improved optimization parameters <b>150</b> for the related object file <b>230</b>. Once uploaded, the optimization parameters <b>150</b> may be delivered to another computer <b>100</b> when the computer <b>100</b> downloads the object file <b>230</b>. The computer <b>100</b> may then use delivered optimization parameters <b>150</b> to provide suggested starting points for optimization parameters <b>150</b> as the computer <b>100</b> executes the object file <b>230</b>.</p>
<p id="p-0022" num="0021">The methodologies presented herein for parallel dynamic optimization on multicore processors may support riskier optimization strategies for some instances of the parallel executions. In some cases, taking large optimization risks may result in code that executes very slowly or even fails to execute. Even where these uncertain performance effects may result, the parallel nature of the executions may tolerate failure of some of the executing instances. Thus, more aggressive optimization may be attempted in contrast to traditional systems. Traditional optimization system may identify a safe setting of optimization parameters <b>150</b> that are least likely to fail and then optimize around that safe set even though performance may be less than achieved when higher levels of optimization are aggressively pursued.</p>
<p id="p-0023" num="0022">The methodologies presented herein for parallel dynamic optimization on multicore processors may also support optimization that generally cannot be done prospectively by altering optimization parameters <b>150</b>. For example, possible optimization parameters are memory block size or stack priority. These parameters may be difficult to optimize prior to code execution. In an empirical example, a particular mathematical program may be optimized for optimization parameters related to modifying memory access block sizes, where the optimal block sizes are difficult to predict. This type of optimization parameter <b>150</b> is one example that traditional dynamic optimization systems may not be able to optimize because the relationship between the parameter and performance may be unpredictable. The resulting performance may vary dramatically and there may be no clear monotonic trend to the performance as a function of the optimization parameters <b>150</b>. Such unpredictable optimizations may be very difficult for optimization. However, the parallel execution of many instances of executable code <b>250</b> in the parallel dynamic optimization system presented herein may support a rapid convergence towards increasingly desirable settings for the optimization parameters <b>150</b> by the code generating loader <b>240</b> and the optimizer <b>260</b>.</p>
<p id="p-0024" num="0023">The optimization parameters <b>150</b> may be approximately optimized within a multicore system by executing multiple instances of executable code <b>250</b> on different cores <b>101</b>-<b>116</b>. The multiple instances of executable code <b>250</b> may each have different setting of the optimization parameters <b>150</b>. The underperforming instances may be terminated and the preferred performers may be allowed to continue. A preferred performer of the multiple instances of executable code <b>250</b> may be identified by the optimizer <b>260</b> as having a more desirable performance level according to one or more specified fitness metrics. The optimization may be iterated by branching out from the preferred solutions or by generating new parameter mixes to test on other cores <b>101</b>-<b>116</b> as they become available.</p>
<p id="p-0025" num="0024">The parallel dynamic optimization techniques for multicore processors presented herein may scale with the number of available processor cores <b>101</b>-<b>116</b>. For example, if 128 cores are available and two are being used for the operating system and basic services, then 126 of the cores may be used for parallel dynamic optimization. If two different programs require optimization, the code generating loader <b>240</b> may generate 63 instances of executable code <b>250</b> for each program. Each program may then be executed on 63 cores. According to various embodiments, two separate optimizations may result in reallocation of cores between the two optimizations under an effective cost strategy based on one or more desired performance goals or other metrics. The optimizations may be performed using sets of cores that are selected to trade off processor cores <b>101</b>-<b>116</b> based on cost functions so that optimizations do not consume more resources than desired.</p>
<p id="p-0026" num="0025">Multicore processors <b>120</b> are available with increasing numbers of cores. The technology discussed herein is one example application that can capitalize on the increasing computational power of multicore processors <b>120</b> even where the application programs themselves may not be easily parallelizable. Available cores may be used to explore an optimization space that was previously unavailable for runtime code optimization. These improved optimizations may be utilized to speed up the execution of object files <b>230</b> on the computer <b>100</b>.</p>
<p id="p-0027" num="0026">The parallel dynamic optimization techniques for multicore processors discussed herein may be applied to software systems commonly in use. Runtime compiled and optimized systems such as JAVA from SUN MICROSYSTEMS, the MICROSOFT&#xae; .NET runtime from MICROSOFT CORPORATION, ACTIVE X&#x2122; from MICROSOFT CORPORATION, FLASH PLAYER from ADOBE SYSTEMS INCORPORATED, and other similar web browser plug-in technologies are increasingly common as the web browser becomes more involved in application execution. The parallel code optimization techniques presented herein may also be applied to dynamic optimization systems utilized in cloud computing applications.</p>
<p id="p-0028" num="0027">It should also be appreciated that the parallel dynamic optimization approaches presented herein may, in the worse case, provide a similar level of optimization as the best case results of traditional dynamic optimization systems where non-parallel executions may be iterated. The parallel dynamic optimization approach may, in many cases, provide significantly better optimization than the traditional techniques.</p>
<p id="p-0029" num="0028">Turning now to <figref idref="DRAWINGS">FIG. 3</figref>, a block diagram illustrates executable code instances <b>250</b>A-<b>250</b>H within cores <b>101</b>-<b>116</b> of a multicore processor <b>120</b> and a graph of execution times <b>300</b> for the instances <b>250</b>A-<b>250</b>H of executable code <b>250</b> according to one or more embodiments presented herein. When multiple instances <b>250</b>A-<b>250</b>H of executable code <b>250</b> are generated from the object file <b>230</b> by the code generating loader <b>240</b>, the instances <b>250</b>A-<b>250</b>H may each be executed on one or more of the cores <b>101</b>-<b>116</b> of the multicore processor <b>120</b>. One aspect of the optimizer <b>260</b> may be to act as a profiler for the multiple instances <b>250</b>A-<b>250</b>H of executable code <b>250</b> as they are executed. As a profiler, the optimizer <b>260</b> may be adapted to track a metric of optimization for each of the instances <b>250</b>A-<b>250</b>H of executable code <b>250</b>. Examples of metrics may include execution time, memory usage, context changes, cache misses, prediction failures, energy consumption, any other operation metric of a computing machine, or any combination thereof. As such, it should be appreciated that the bar chart of execution times <b>300</b> illustrated in <figref idref="DRAWINGS">FIG. 3</figref> is merely one example of a performance or fitness metric.</p>
<p id="p-0030" num="0029">The bar chart of execution times <b>300</b> illustrates a comparison of example execution time metrics for each of eight parallel instances <b>250</b>A-<b>250</b>H of executable code <b>250</b>. According to the values illustrated in the bar chart of execution times <b>300</b>, instance <b>250</b>B had the shortest execution time. Thus, instance <b>250</b>B may be identified by the optimizer <b>260</b> as the preferred instance. The optimization parameters <b>150</b> associated with instance <b>250</b>B may be specified as the preferred optimization parameters <b>150</b>. The preferred optimization parameters <b>150</b> may be stored to the optimization result record <b>270</b> for use in future executions of the code. The preferred optimization parameters may also be used to seed further optimization iterations.</p>
<p id="p-0031" num="0030">According to the values illustrated in the bar chart of execution times <b>300</b>, the executable code instances <b>250</b>C and <b>250</b>F may be identified by the optimizer <b>260</b> as less desirable instances. Optimization parameters <b>150</b> associated with the less desirable instances <b>250</b>C and <b>250</b>F may be flagged for avoidance in future executions. The less desirable optimization parameters may also be fed back to the code generating loader <b>240</b>. The code generating loader <b>240</b> may then use the information to inform further optimization iterations. The executable code instance <b>250</b>E may have failed to complete correctly. Optimization parameters <b>150</b> associated with the executable code instance <b>250</b>E that fails to complete may be fed back to the code generating loader <b>240</b> so that these parameter settings may be avoided in future executions.</p>
<p id="p-0032" num="0031">The execution times <b>300</b> may be collected by the optimizer <b>260</b> for comparison to one another. The optimizer <b>260</b> may be a program that executes at the level of applications or operating systems of the computer <b>100</b> using the multicore processor <b>120</b>. The optimizer <b>260</b> may also be associated with the firmware or basic input/output system (BIOS) of the associated computing system. According to other embodiments, the optimizer <b>260</b> may be provided within the multicore processor <b>120</b> in the form of one or more hardware modules or circuits. The optimizer <b>260</b> may be also be provided in the form of one or more hardware modules or circuits within the computer <b>100</b>.</p>
<p id="p-0033" num="0032">Referring now to <figref idref="DRAWINGS">FIG. 4</figref>, additional details will be provided regarding the embodiments presented herein for dynamic optimization that leverages multicore processors <b>120</b>. In particular, <figref idref="DRAWINGS">FIG. 4</figref> is a flow diagram illustrating a process <b>400</b> for parallel dynamic optimization using multicore processors according to at least some embodiments presented herein. Process <b>400</b> may include one or more operations, functions or actions as illustrated by one or more of blocks <b>410</b>, <b>420</b>, <b>430</b>, <b>440</b>, <b>450</b>, <b>460</b>, <b>470</b>, and/or <b>480</b>.</p>
<p id="p-0034" num="0033">It should be appreciated that the blocks described herein may be implemented as a sequence of computer implemented instructions or program modules running on a computing system, as interconnected machine logic circuits or circuit modules within the computing system, or some combination thereof. The implementation is a matter of choice dependent on the performance and other requirements of the various embodiments. Some of the logical operations described herein are referred to variously as state operations, functions, structural devices, actions, or modules. These operations, functions, structural devices, actions and modules may be implemented in software, in firmware, in special purpose digital logic, and any combination thereof. It should also be appreciated that in some implementations one or more of the illustrated blocks may be eliminated, combined or separated into additional blocks than those shown in the figures and described herein. These blocks may also be performed sequentially, in parallel, or in a different order than those described herein.</p>
<p id="p-0035" num="0034">The process <b>400</b> may begin at block <b>410</b> (Receive Object File), where an object file <b>230</b> may be received at the computer <b>100</b>. The object file <b>230</b> may be a thin binary, a portable intermediate representation, or any other compiled or partially compiled program code representation. The object file <b>230</b> may be received at the computer <b>100</b> from a network into a player, web browser, or other runtime system. The object file <b>230</b> may also be delivered to the computer <b>100</b>, or a user of the computer <b>100</b>, on a computer readable storage medium or provided as part of the preinstalled code of the computer <b>100</b>.</p>
<p id="p-0036" num="0035">Processing may continue from block <b>410</b> to block <b>420</b> (Determine Optimization Parameters), where the code generating loader <b>240</b> may determine optimization parameters <b>150</b> for dynamically optimizing the execution of the received object file <b>230</b>. As discussed above, examples of optimization parameters <b>150</b> may include memory block size, cache size, cache access protocols, memory access protocols, cache update policies, repeated computation versus look-up tables, loop unrolling, and various other computational optimization techniques known in the art. For each of the optimization parameters <b>150</b>, a range of optimization may be established. A starting point within each range may also be specified for beginning the optimization. An appropriate metric of performance or fitness may also be selected by the code generating loader <b>240</b> for measuring the effectiveness of variations in the selected optimization parameters <b>150</b>.</p>
<p id="p-0037" num="0036">Processing may continue from block <b>420</b> to block <b>430</b> (Generate Multiple Instance of Executable Code Based on Optimization Parameters), where the code generating loader <b>240</b> may be adapted to generate multiple instances of executable code <b>250</b> based on the object file <b>230</b> and the optimization parameters <b>150</b> determined at block <b>420</b>. According to some embodiments, one set of executable code <b>250</b> instances may be generated by the code generating loader <b>240</b> with optimization parameter combinations that evenly span the rages of the optimization parameters <b>150</b>. Such an optimization may then be iterated using preferred outcomes from the first set so as to perform a course-to-fine search of the optimization space. Other embodiments may focus on variations around the initial suggested values for the optimization parameters <b>150</b>. Various other embodiments may select initial optimization parameters randomly, using weighted functions, using prior knowledge of execution according to a type of program or according to the source of a program. These and other approaches for initializing the optimization parameters <b>150</b> may be applied within the spirit and scope of the technology discussed herein.</p>
<p id="p-0038" num="0037">Processing may continue from block <b>430</b> to block <b>440</b> (Execute Multiple Instances of Code in Parallel), where the multiple instances of executable code <b>250</b> generated at block <b>430</b> may be executed in parallel on the multicore processor <b>120</b>. The optimizer <b>260</b> may be arranged to profile the parallel execution of the multiple instances of executable code <b>250</b> to identify which of the instances of executable code <b>250</b> may be the most optimized for execution on the multicore processor <b>120</b>.</p>
<p id="p-0039" num="0038">Continuing from block <b>440</b> to block <b>450</b> (Provide Results from First Successful Completion among the Parallel Executions), the results from the first successful completion among the parallel executions of the executable code <b>250</b> may be provided as the results from the execution of the object file <b>230</b>. These results may be provided to a user or to a process or application that called for the execution of the object file <b>230</b>. The completion times of the other respective instances of executable code <b>250</b> may also be tracked for optimization purposes.</p>
<p id="p-0040" num="0039">Continuing from block <b>450</b> to block <b>460</b> (Identify Preferred Parameters), the preferred parameters may be identified by the optimizer <b>260</b>. As mentioned above, the preferred parameters may be the parameters associated with the first successful completing instances of the executable code <b>250</b>. According to other embodiments, the preferred parameters may be the parameters associated with the instances of the executable code <b>250</b> approximately maximizing, minimizing, or best balancing various other fitness metrics as discussed herein.</p>
<p id="p-0041" num="0040">Continuing from block <b>460</b> to block <b>470</b> (Identify Less Desirable Parameters), the less desirable parameters may be identified by the optimizer <b>260</b>. The less desirable parameters may be associated with instances of executable code <b>250</b> that may not complete or instances of the executable code <b>250</b> that may complete in a longer period of time or using more resources than those associated with the preferred parameters in block <b>460</b>.</p>
<p id="p-0042" num="0041">Continuing from block <b>470</b> to block <b>480</b> (Record Optimizing Parameters), the optimizing parameters <b>150</b> associated with the preferred instances of executable code <b>250</b> and the less desirable instances of executable code <b>250</b> may be stored by the code generating loader <b>240</b> or the optimizer <b>260</b> into the optimization result record <b>270</b> as discussed above. The resulting optimization parameters may be used to inform future compilation and execution of the object file <b>230</b>. The resulting optimization parameters <b>150</b> may also be used to inform refinement of the optimization by seeding the generation of another round of multiple instances of the executable code <b>250</b> as discussed with respect to block <b>430</b>. As such, the process <b>400</b> may loop back to block <b>430</b>.</p>
<p id="p-0043" num="0042">With reference to <figref idref="DRAWINGS">FIG. 5</figref>, an example computing system for implementing various embodiments presented herein will be discussed. The computing system includes a computer <b>10</b>. According to various embodiments, the computer <b>10</b> may be the computer <b>100</b> discussed with respect to <figref idref="DRAWINGS">FIG. 1</figref>. The computer <b>10</b> may include a processor <b>11</b>, a memory <b>12</b> and one or more storage drives <b>13</b>. The storage drives <b>13</b> and their associated computer storage media may provide storage of computer readable instructions, data structures, program modules <b>23</b> and other data for the computer <b>10</b>. The computing system may be adapted to support embodiments for implementing parallel dynamic optimization using one or more multicore processors <b>120</b>. For example, the computing system may comprise program modules <b>23</b> such as the code generating loader <b>240</b> and the optimizer <b>260</b>. Various embodiments may include computers, dedicated hardware, or embedded computing systems.</p>
<p id="p-0044" num="0043">The computer <b>10</b> may be implemented as a conventional computer system, an embedded control computer, a laptop, or a server computer, a mobile device, a set-top box, a kiosk, a vehicular information system, a mobile telephone, a customized machine, or other hardware platform. The processor <b>11</b> may be a general purpose processor, a processor core, a multiprocessor, a multicore processor <b>120</b>, a graphics processor, a digital signal processing (DSP) processor, a customized computing device implemented within an application specific integrated circuit (ASIC), a customized computing device implemented within a field programmable gate array (FPGA), a customized computing device implemented within any type of programmable logic, a state machine, a reconfigurable processor, any other processing unit, or any combination or multiplicity thereof. The processor <b>11</b> may support parallel dynamic optimization leveraging multicore processors as discussed herein.</p>
<p id="p-0045" num="0044">The storage drives <b>13</b>, other storage devices, or their associated computer-readable storage media may store an operating system <b>21</b>, application programs <b>22</b>, and program modules <b>23</b>. The computer <b>10</b> may include user input devices <b>15</b> through which a user may enter commands and data. Input devices may include an electronic digitizer, a microphone, a keyboard, a pointing device, or any combination thereof. Examples of pointing devices may include a mouse, trackball, light pen, touch screen, or touch pad. Other input devices to the computer <b>10</b> may include a joystick, game pad, satellite dish, scanner, or the like. Input devices may be coupled to processor <b>11</b> through a user input interface that is coupled to a system bus. The input devices may also be coupled by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). Computers such as computer <b>10</b> may also include other peripheral output devices such as speakers, which may be coupled through an output peripheral interface <b>19</b> or similar interface.</p>
<p id="p-0046" num="0045">The computer <b>10</b> may operate in a networked environment using logical connections to one or more computers, such as a remote computer coupled to network interface <b>16</b>. The remote computer may be a personal computer, a server, a router, a network PC, a peer device, or other common network node. The remote computer may include many or all of the elements described herein relative to the computer <b>10</b>. Networking environments may include networks (WAN), local area networks (LAN), intranets, the Internet, or combinations thereof.</p>
<p id="p-0047" num="0046">When used in a LAN or wireless LAN (WLAN) networking environment, the computer <b>10</b> may be coupled to the LAN through a network interface <b>16</b> or a network adapter. When used in a WAN networking environment, the computer <b>10</b> may include a modem or other mechanism for establishing communications over the WAN. The WAN may include the Internet, the illustrated network <b>18</b>, various other networks, or any combination thereof. It should be appreciated that other mechanisms of establishing a communications link, ring, mesh, bus, cloud, or network between computers may be used.</p>
<p id="p-0048" num="0047">According to one or more embodiments, computer <b>10</b> may be configured such that the processor <b>11</b> and/or program modules <b>23</b> may perform parallel dynamic optimization leveraging multicore processors in accordance with various embodiments presented herein. The computer <b>10</b> may include one or more instances of a physical computer-readable storage medium or media associated with storage drives <b>13</b> or other storage devices. The system bus may enable the processor <b>11</b> to read code and/or data to/from the computer-readable storage media. The media may represent an apparatus in the form of storage elements that are implemented using any suitable technology, including but not limited to semiconductors, magnetic materials, optical media, electrical storage, electrochemical storage, or any other such storage technology. The media may represent components associated with semiconductor memory <b>12</b>, whether characterized as RAM, ROM, flash, or other types of volatile or nonvolatile memory technology. The media may also represent secondary storage, whether implemented as the storage drives <b>13</b> or otherwise. Hard drive implementations may be characterized as solid state, or may include rotating media storing magnetically-encoded information.</p>
<p id="p-0049" num="0048">The storage media may include one or more program modules <b>23</b> such as the code generating loader <b>240</b> and the optimizer <b>260</b> for performing parallel dynamic optimization. The program modules <b>23</b> may include software instructions that, when loaded into the processor <b>11</b> and executed, transform a general-purpose computing system into a special-purpose computing system customized to facilitate all, or part of, the parallel dynamic optimization techniques disclosed herein. As detailed throughout this description, the program modules <b>23</b> may provide various tools or techniques by which the computer <b>10</b> may participate within the overall systems or operating environments using the components, logic flows, and/or data structures discussed herein.</p>
<p id="p-0050" num="0049">The processor <b>11</b> may be constructed from any number of transistors or other circuit elements, which may individually or collectively assume any number of states. More specifically, the processor <b>11</b> may operate as a state machine or finite-state machine. Such a machine may be transformed to a second machine, or specific machine by loading executable instructions contained within the program modules <b>23</b>. These computer-executable instructions may transform the processor <b>11</b> by specifying how the processor <b>11</b> transitions between states, thereby transforming the transistors or other circuit elements constituting the processor <b>11</b> from a first machine to a second machine, wherein the second machine may be specifically configured to support parallel dynamic optimization leveraging multicore processors. The states of either machine may also be transformed by receiving input from one or more user input devices <b>15</b>, network interfaces <b>16</b>, other peripherals, other interfaces, or one or more users or other actors. Either machine may also transform states, or various physical characteristics of various output devices such as printers, speakers, video displays, or otherwise.</p>
<p id="p-0051" num="0050">Encoding the program modules <b>23</b> may also transform the physical structure of the storage media. The specific transformation of physical structure may depend on various factors, in different implementations of this description. Examples of such factors may include, but are not limited to: the technology used to implement the storage media, whether the storage media are characterized as primary or secondary storage, and the like. For example, if the storage media are implemented as semiconductor-based memory, the program modules <b>23</b> may transform the physical state of the semiconductor-based memory <b>12</b> when the software is encoded therein. For example, the software may transform the state of transistors, capacitors, or other discrete circuit elements constituting the semiconductor-based memory <b>12</b>.</p>
<p id="p-0052" num="0051">As another example, the storage media may be implemented using magnetic or optical technology such as storage drives <b>13</b>. In such implementations, the program modules <b>23</b> may transform the physical state of magnetic or optical media, when the software is encoded therein. These transformations may include altering the magnetic characteristics of particular locations within given magnetic media. These transformations may also include altering the physical features or characteristics of particular locations within given optical media, to change the optical characteristics of those locations. It should be appreciated that various other transformations of physical media are possible without departing from the scope and spirit of the present description.</p>
<p id="p-0053" num="0052">Turning now to <figref idref="DRAWINGS">FIG. 6</figref>, a schematic illustrates a partial view of a computer program product <b>700</b> that includes a computer program for executing a computer process on a computing device, according to at least some embodiments presented herein. An illustrative embodiment of the example computer program product is provided using a signal bearing medium <b>702</b>, and may include at least one instruction of <b>704</b>: one or more instructions for determining optimization parameters to be explored for the optimized execution of the portable intermediate software module; one or more instructions for generating multiple instances of executable code from the portable intermediate software module, each of the instances generated using different values for the optimization parameters; or one or more instructions for executing two or more of the multiple instances of executable code on different cores of the multicore processor. The one or more instructions may be, for example, computer executable and/or logic implemented instructions. In some embodiments, the signal bearing medium <b>702</b> of the one or more computer program products <b>700</b> include a computer-readable medium <b>706</b>, a recordable medium <b>708</b>, and/or a communications medium <b>710</b>.</p>
<p id="p-0054" num="0053">In some implementations, signal bearing medium <b>702</b> may encompass a computer-readable medium <b>706</b>, such as, but not limited to, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, memory, etc. In some implementations, signal bearing medium <b>702</b> may encompass a recordable medium <b>708</b>, such as, but not limited to, memory, read/write (R/W) CDs, R/W DVDs, etc. In some implementations, signal bearing medium <b>702</b> may encompass a communications medium <b>710</b>, such as, but not limited to, a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.). Thus, for example, computer program product <b>700</b> may be conveyed to one or more modules of the described systems by an RF signal bearing medium <b>702</b>, where the signal bearing medium <b>702</b> is conveyed by a wireless form of communications medium <b>710</b> (e.g., a wireless communications medium conforming with the IEEE 802.11 standard).</p>
<p id="p-0055" num="0054">The present disclosure is not to be limited in terms of the particular embodiments described in this application, which are intended as illustrations of various aspects. Many modifications and variations can be made without departing from its spirit and scope, as will be apparent to those skilled in the art. Functionally equivalent methods and apparatuses within the scope of the disclosure, in addition to those enumerated herein, will be apparent to those skilled in the art from the foregoing descriptions. Such modifications and variations are intended to fall within the scope of the appended claims. The present disclosure is to be limited only by the terms of the appended claims, along with the full scope of equivalents to which such claims are entitled. It is to be understood that this disclosure is not limited to particular methods, components, elements, apparatuses, or systems, which can, of course, vary. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only, and is not intended to be limiting.</p>
<p id="p-0056" num="0055">With respect to the use of substantially any plural and/or singular terms herein, those having skill in the art can translate from the plural to the singular and/or from the singular to the plural as is appropriate to the context and/or application. The various singular/plural permutations may be expressly set forth herein for sake of clarity.</p>
<p id="p-0057" num="0056">It will be understood by those within the art that, in general, terms used herein, and especially in the appended claims (e.g., bodies of the appended claims) are generally intended as &#x201c;open&#x201d; terms (e.g., the term &#x201c;including&#x201d; should be interpreted as &#x201c;including but not limited to,&#x201d; the term &#x201c;having&#x201d; should be interpreted as &#x201c;having at least,&#x201d; the term &#x201c;includes&#x201d; should be interpreted as &#x201c;includes but is not limited to,&#x201d; etc.).</p>
<p id="p-0058" num="0057">It will be further understood by those within the art that if a specific number of an introduced claim recitation is intended, such an intent will be explicitly recited in the claim, and in the absence of such recitation no such intent is present. For example, as an aid to understanding, the following appended claims may contain usage of the introductory phrases &#x201c;at least one&#x201d; and &#x201c;one or more&#x201d; to introduce claim recitations. However, the use of such phrases should not be construed to imply that the introduction of a claim recitation by the indefinite articles &#x201c;a&#x201d; or &#x201c;an&#x201d; limits any particular claim containing such introduced claim recitation to embodiments containing only one such recitation, even when the same claim includes the introductory phrases &#x201c;one or more&#x201d; or &#x201c;at least one&#x201d; and indefinite articles such as &#x201c;a&#x201d; or &#x201c;an&#x201d; (e.g., &#x201c;a&#x201d; and/or &#x201c;an&#x201d; should be interpreted to mean &#x201c;at least one&#x201d; or &#x201c;one or more&#x201d;); the same holds true for the use of definite articles used to introduce claim recitations. In addition, even if a specific number of an introduced claim recitation is explicitly recited, those skilled in the art will recognize that such recitation should be interpreted to mean at least the recited number (e.g., the bare recitation of &#x201c;two recitations,&#x201d; without other modifiers, means at least two recitations, or two or more recitations).</p>
<p id="p-0059" num="0058">In instances where a convention analogous to &#x201c;at least one of A, B, and C, etc.&#x201d; is used, in general such a construction is intended in the sense one having skill in the art would understand the convention (e.g., &#x201c;a system having at least one of A, B, and C&#x201d; would include but not be limited to systems that have A alone, B alone, C alone, A and B together, A and C together, B and C together, and/or A, B, and C together, etc.). In those instances where a convention analogous to &#x201c;at least one of A, B, or C, etc.&#x201d; is used, in general such a construction is intended in the sense one having skill in the art would understand the convention (e.g., &#x201c;a system having at least one of A, B, or C&#x201d; would include but not be limited to systems that have A alone, B alone, C alone, A and B together, A and C together, B and C together, and/or A, B, and C together, etc.). It will be further understood by those within the art that virtually any disjunctive word and/or phrase presenting two or more alternative terms, whether in the description, claims, or drawings, should be understood to contemplate the possibilities of including one of the terms, either of the terms, or both terms. For example, the phrase &#x201c;A or B&#x201d; will be understood to include the possibilities of &#x201c;A&#x201d; or &#x201c;B&#x201d; or &#x201c;A and B.&#x201d;</p>
<p id="p-0060" num="0059">In addition, where features or aspects of the disclosure are described in terms of Markush groups, those skilled in the art will recognize that the disclosure is also thereby described in terms of any individual member or subgroup of members of the Markush group.</p>
<p id="p-0061" num="0060">As will be understood by one skilled in the art, for any and all purposes, such as in terms of providing a written description, all ranges disclosed herein also encompass any and all possible subranges and combinations of subranges thereof. Any listed range can be easily recognized as sufficiently describing and enabling the same range being broken down into at least equal halves, thirds, quarters, fifths, tenths, etc. As a non-limiting example, each range discussed herein can be readily broken down into a lower third, middle third and upper third, etc. As will also be understood by one skilled in the art all language such as &#x201c;up to,&#x201d; &#x201c;at least,&#x201d; &#x201c;greater than,&#x201d; &#x201c;less than,&#x201d; and the like include the number recited and refer to ranges which can be subsequently broken down into subranges as discussed above. Finally, as will be understood by one skilled in the art, a range includes each individual member. Thus, for example, a group having 1-3 elements refers to groups having 1, 2, or 3 elements. Similarly, a group having 1-5 elements refers to groups having 1, 2, 3, 4, or 5 elements, and so forth.</p>
<p id="p-0062" num="0061">While various aspects and examples have been disclosed herein, other aspects and examples will be apparent to those skilled in the art. The various aspects and examples disclosed herein are for purposes of illustration and are not intended to be limiting, with the true scope and spirit being indicated by the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer-implemented method for parallel dynamic optimization of a portable intermediate software module, the method comprising:
<claim-text>sequentially generating
<claim-text>a first instance of executable code from the portable intermediate software module, the first instance generated using a first set of values as optimization parameters, and</claim-text>
<claim-text>a second instance of executable code from the portable intermediate software module, the second instance generated using a second set of values as optimization parameters wherein the second set of values varied from the first set of values;</claim-text>
</claim-text>
<claim-text>executing substantially in parallel
<claim-text>the first instance of executable code on a first processor core of a multicore processor, and</claim-text>
<claim-text>the second instance of executable code on a second processor core of the multicore processor; and</claim-text>
</claim-text>
<claim-text>identifying a preferred instance of executable code executing on one of the first processor core and the second processor core of the multicore processor based on a highest ranked fitness metric from ranking fitness metrics evaluated for the first instance of executable code while executing on the first processor core of the multicore processor, and fitness metrics evaluated for the second instance of executable code while executing on the second processor core of the multicore processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>selecting the preferred instance of executable code executing on one of the first processor core or the second processor core of the multicore processor associated with the highest ranked fitness metric.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>sequentially generating additional instances of executable code each using different values for the optimization parameters based upon optimization parameters associated with the preferred instance of executable code executing on one of the first processor core and the second processor core of the multicore processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising storing an optimization parameter record in association with the portable intermediate software module, the optimization parameter record comprising optimization parameters associated with the preferred instance of executable code executing on one of the first processor core and the second processor core of the multicore processor.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the fitness metrics correspond to one or more of an execution time on one of the first processor core and the second processor core of the multicore processor, a memory usage of the executable code on a processor core of the multicore processor, or a power consumption of the executable code on a processor core of the multicore processor.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the optimization parameters comprise:
<claim-text>one or more of a block size associated with memory usage of the executable code on one of the first processor core and the second processor core of the multicore processor;</claim-text>
<claim-text>a total memory usage of the executable code on one of the first processor core and the second processor core of the multicore processor;</claim-text>
<claim-text>a power consumption associated with processing executable code on one of the first processor core and the second processor core of the multicore processor; and</claim-text>
<claim-text>an execution time associated with processing executable code on one of the first processor core and the second processor core of the multicore processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein substantially in parallel comprises having some overlap in time.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A non-transitory computer storage medium having computer-executable instructions stored thereon for a method which, when executed by a computer having a multicore processor performs parallel dynamic optimization of a portable intermediate software module, the method comprising:
<claim-text>determining optimization parameters to be explored for the optimized execution of the portable intermediate software module;</claim-text>
<claim-text>sequentially generating multiple instances of executable code from the portable intermediate software module, each of the sequentially generated multiple instances generated using different values for the optimization parameters;</claim-text>
<claim-text>executing substantially in parallel two or more of the multiple instances of executable code on different processor cores of the multicore processor; and</claim-text>
<claim-text>identifying a preferred instance of executable code executing on a respective core of the multicore processor based on a highest ranked fitness metric from ranking fitness metrics evaluated for each of the two or more of the multiple instances of executable code executing substantially in parallel on the respective cores of the multicore processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The non-transitory computer storage medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the preferred instance of executable code is associated with the highest ranked fitness metric.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The non-transitory computer storage medium of <claim-ref idref="CLM-00009">claim 9</claim-ref>, the method further comprising sequentially generating additional instances of executable code each using different values for the optimization parameters based upon optimization parameters associated with the preferred instance of executable code executing on the respective core of the multicore processor.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The non-transitory computer storage medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein each fitness metric associated with the respective one of the multiple instances of executable code corresponds to one or more of
<claim-text>a measure of the execution time on a processor core of the multicore processor,</claim-text>
<claim-text>a measure of memory usage of the executable code on a processor core of the multicore processor, or</claim-text>
<claim-text>a measure of energy resources consumed during an execution time</claim-text>
<claim-text>of the respective ones of the multiple instances of executable code on a processor core of the multicore processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The non-transitory computer storage medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein substantially in parallel comprises concurrently, overlapping in time, or partially overlapping in time.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A multicore computing system comprising:
<claim-text>a multicore processing unit having a plurality of cores; and</claim-text>
<claim-text>a runtime module configured to
<claim-text>receive a portable intermediate software module,</claim-text>
<claim-text>sequentially generate multiple instances of executable code from the portable intermediate software module, each of the sequentially generated instances having different optimization settings associated therewith,</claim-text>
<claim-text>execute substantially in parallel each of the sequentially generated multiple instances of executable code on different ones of the plurality of cores of the multicore processing unit, and</claim-text>
<claim-text>identify a preferred instance of the sequentially generated multiple instances of executable code executing on respective cores of the multicore processing unit based on a highest ranked fitness metric from ranking fitness metrics evaluated for each of the sequentially generated multiple instances of executable code executing on the different ones of the plurality of cores of the multicore processing unit.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The multicore computing system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the runtime module is further configured to:
<claim-text>identify the highest ranked fitness metric.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The multicore computing system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the runtime module is further configured to iterate the sequential generation of multiple instances of executable code using optimization settings varied from the optimization settings associated with the preferred instance of executable code executing on the respective processor core of the multicore processing unit from the previous iteration.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The multicore computing system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the multiple instances of sequentially generated executable code are generated in a quantity related to the number of available cores within the multicore processing unit.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The multicore computing system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the runtime module is further configured to store the optimization settings associated with the preferred instance of executable code executing on the respective processor core of the multicore processing unit for association with the portable intermediate software module.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The multicore computing system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein values for the optimization settings are initially determined from a default set of values.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The multicore computing system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the default set of values are received with the portable intermediate software module.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The multicore computing system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein substantially in parallel comprises concurrently, overlapping in time, or partially overlapping in time.</claim-text>
</claim>
</claims>
</us-patent-grant>
