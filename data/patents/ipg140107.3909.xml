<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624977-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624977</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12735912</doc-number>
<date>20090219</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2008-039395</doc-number>
<date>20080220</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>656</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>18</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348148</main-classification>
</classification-national>
<invention-title id="d2e71">Vehicle peripheral image displaying system</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2003/0108222</doc-number>
<kind>A1</kind>
<name>Sato et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382104</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2007/0147664</doc-number>
<kind>A1</kind>
<name>Kubota et al.</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382106</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2007/0247717</doc-number>
<kind>A1</kind>
<name>Konno et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>359613</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2012/0236152</doc-number>
<kind>A1</kind>
<name>De Wind et al.</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348148</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>JP</country>
<doc-number>2002-337605</doc-number>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>2003-244688</doc-number>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>2004-350303</doc-number>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>2005-335410</doc-number>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00009">
<othercit>International Search Report.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>10</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348148</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>16</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110043632</doc-number>
<kind>A1</kind>
<date>20110224</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Satoh</last-name>
<first-name>Noriyuki</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Satoh</last-name>
<first-name>Noriyuki</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Harness, Dickey &#x26; Pierce P.L.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Clarion Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Nguyen</last-name>
<first-name>Phuoc</first-name>
<department>2443</department>
</primary-examiner>
<assistant-examiner>
<last-name>Belani</last-name>
<first-name>Kishin G</first-name>
</assistant-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP2009/052879</doc-number>
<kind>00</kind>
<date>20090219</date>
</document-id>
<us-371c124-date>
<date>20100923</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2009/104675</doc-number>
<kind>A </kind>
<date>20090827</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A vehicle-peripheral image displaying system (a side view monitor system A<b>1</b>) comprises a side camera <b>1</b>, a monitor <b>3</b> and an image processing controlling unit <b>2</b>, wherein the image processing controlling unit <b>2</b> includes an image processor <b>43</b> configured to perform a viewpoint conversion of the actually shot camera image input from the side camera <b>1</b> into a virtual camera image which is to be converted as if it is viewed from the driver's eye position, an image memory <b>44</b> configured to store a vehicle interior image which is previously shot from the driver's eye position as a vehicle interior image, and a superimposing circuit <b>46</b> configured to make the vehicle interior image translucent to form a translucent vehicle interior image, to perform an image composition such that the translucent vehicle interior image is superimposed on the virtual camera image, and to produce a composite image which represents the virtual camera image transparently through the translucent vehicle interior image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="155.45mm" wi="230.21mm" file="US08624977-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="237.24mm" wi="183.56mm" orientation="landscape" file="US08624977-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="240.62mm" wi="159.94mm" file="US08624977-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="246.46mm" wi="153.84mm" file="US08624977-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="228.68mm" wi="155.53mm" file="US08624977-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="248.07mm" wi="167.72mm" file="US08624977-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="239.52mm" wi="172.30mm" orientation="landscape" file="US08624977-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="205.23mm" wi="185.50mm" file="US08624977-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="219.79mm" wi="196.34mm" orientation="landscape" file="US08624977-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="217.42mm" wi="181.19mm" file="US08624977-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="240.88mm" wi="150.28mm" file="US08624977-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="239.52mm" wi="179.24mm" file="US08624977-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to a vehicle-peripheral image displaying system which displays a vehicle-peripheral image including a blind area on a monitor screen of a vehicle interior based on the camera image obtained by a vehicle-mounted external camera.</p>
<heading id="h-0002" level="1">BACKGROUND ART</heading>
<p id="p-0003" num="0002">Today, a practically used side view monitor system, which has a side camera (CCD camera or the like) provided inside a side mirror, displays an actually shot camera image output from the side camera on a monitor screen of a front display unit which is also used for a navigation system.</p>
<p id="p-0004" num="0003">That is, a front lateral part of the vehicle, which is blind from a driver, is displayed on the monitor screen so that the driver can recognize a situation of the blind area.</p>
<p id="p-0005" num="0004">However, since the side camera is provided inside the side mirror, there is a greatly inadequate parallax between a viewing position of the camera and a viewing position of a driver. Shapes of an obstacle or other objects on the camera image and the shapes which can be seen from the driver's seat are totally different.</p>
<p id="p-0006" num="0005">In response, usually by a habituation of the driver, the driver reconfigures the camera image in his head and judges whilst restructuring a positional relationship between the objects so that consistency with the image which the driver is actually viewing is attained.</p>
<p id="p-0007" num="0006">On the other hand, in a case of an inexperienced driver or an unexpected case, the consistency between a screen image and the image which can be viewed from the driver's seat is collapsed and an uncomfortable feeling is produced.</p>
<p id="p-0008" num="0007">In order to eliminate such an uncomfortable feeling, the camera image obtained by the blind area camera which is mounted on a vehicle-exterior is converted into a virtual camera image as if the image is viewed from the driver's eye position so that a converted external image is produced.</p>
<p id="p-0009" num="0008">Further, out of the camera image obtained by a driver's eye position camera which is provided near the driver's eye position, a visible area image which is excluding the blind area is produced.</p>
<p id="p-0010" num="0009">And the converted external image is superimposed on the blind area which was excluded from the visible area image so that a composite image is obtained. The vehicle-peripheral image displaying system which obtains the composite image is proposed (for example, see Patent Document 1).</p>
<p id="p-0011" num="0010">Specifically, a viewpoint conversion of an image of a back camera which is provided on a trunk part of a vehicle exterior is performed as if a rearward of the vehicle is viewed from the driver's eye position.</p>
<p id="p-0012" num="0011">Here, images are combined. Of the combined rearward view image, a part which is visible from a window is a live image (an actually shot image) output from an interior camera image. And regarding a part which is blind because of a seat or a trunk and cannot be shot by the interior camera, an image is obtained such that an external camera image on which image processing is performed is superimposed.</p>
<p id="p-0013" num="0012">In this case, since converting the two images into an image which is a completely and smoothly continuous image is technically highly difficult, an effort in order to make a parting line less noticeable is made such that a border line for clipping the image is fitted to a window frame of the vehicle or other thing and an edge portion such as the window frame or the like is superimposed as a superimposed image having a form of thick-frame.
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0013">Patent Document 1: Japanese Patent Application Publication No. 2004-350303</li>
</ul>
</p>
<heading id="h-0003" level="1">DISCLOSURE OF THE INVENTION</heading>
<heading id="h-0004" level="1">Problems to be Solved by the Invention</heading>
<p id="p-0014" num="0014">However, the prior art vehicle-peripheral image displaying system holds the following problems.</p>
<p id="p-0015" num="0015">(1) The prior art vehicle-peripheral image displaying system needs to include two cameras of the blind area camera and the driver's eye position camera. Since the driver's eye position camera needs to be added on the existing system, a cost of the system is increased.</p>
<p id="p-0016" num="0016">In addition, the driver's eye position camera is provided near the drive's eye position, that is, the driver's eye position camera cannot be provided exactly at the driver's eye position. Thus, an inadequate parallax against the image which is actually viewed from the driver's viewing position is produced on the camera image obtained from the driver's eye position camera.</p>
<p id="p-0017" num="0017">(2) Attempts to eliminate the blind area and to eliminate the uncomfortable feeling are made such that mainly two camera images are clipped and combined, the edge portion such as the window frame or the like of the image is emphatically detected, and a superimposing is performed using what is emphatically detected. However, there are limitations and the uncomfortable feeling on the image is still produced.
<br/>
(3) As described as an example, if the blind camera which has a wide angle on a vertical direction of a depression and elevation angle direction is used, a range of view of the interior camera (the driver's eye position camera) is sufficiently covered. A contribution of the interior camera image for eliminating the blind area is only a part of the view of upside of the trunk or the like. Thus, the interior camera is systematically wasteful.
<br/>
(4) Despite that the frame on which the superimposing is performed requires an image processing function to be added, the superimposing frame which is made by emphasizing the edge and is used when the camera images are combined does not have enough effects on giving the driver a realization that the driver is viewing the blind area of the vehicle.
</p>
<p id="p-0018" num="0018">In view of solving the above problems, the present invention aims to provide a vehicle-peripheral image displaying system which uses only the vehicle-mounted external camera, is an inexpensive system, can make the blind area from the driver to be intuitively recognized without the inadequate parallax, and can make an external situation, which is the blind area from the driver, to be clearly visible in a relationship with the position of the vehicle.</p>
<heading id="h-0005" level="1">Solution to Problem</heading>
<p id="p-0019" num="0019">In the present invention, a vehicle-peripheral image displaying system includes a vehicle-mounted external camera which is mounted on a vehicle and shoots an image of a vehicle-periphery, a monitor provided in a vehicle interior at a position to cause the monitor to be visible for a driver, and a monitor-image producing unit which produces an image to be displayed on the monitor based on an actually shot camera image input from the vehicle-mounted external camera, wherein the monitor-image producing unit includes an image processor configured to perform the viewpoint conversion of the actually shot camera image input from the vehicle-mounted external camera into a virtual camera image which is to be converted as if it is viewed from the driver's eye position, an image memory configured to store a vehicle interior image which is previously shot from the driver's eye position as a vehicle interior image, and an image composition circuit configured to make the vehicle interior image output from the image memory translucent to form a translucent vehicle interior image, to perform an image composition such that the translucent vehicle interior image is superimposed on the virtual camera image output from the image processor, and to produce a composite image which represents the virtual camera image transparently through the translucent vehicle interior image.</p>
<heading id="h-0006" level="1">Advantageous Effects of Invention</heading>
<p id="p-0020" num="0020">Therefore, in the vehicle-peripheral image displaying system of the present invention, the vehicle interior image which is previously shot from the driver's viewing position is stored in the image memory of the monitor-image producing unit.</p>
<p id="p-0021" num="0021">In the image processor of the monitor-image producing unit, the viewing position conversion of the actually shot camera image input from the vehicle-mounted external camera is performed converting into a virtual camera image which is to be converted as if it is viewed from the driver's eye position.</p>
<p id="p-0022" num="0022">Then, in the image composition circuit, the vehicle interior image output from the image memory is made translucent so that the translucent vehicle interior image is formed, and the image composition is performed such that the translucent vehicle interior image is superimposed on the virtual camera image output from the image processor, then the composite image which represents the virtual camera image transparently through the translucent vehicle interior image is produced.</p>
<p id="p-0023" num="0023">As just described, in the image processor, the viewing position conversion of the actually shot camera image input from the vehicle-mounted external camera is performed converting into a virtual camera image which is to be converted as if it is viewed from the driver's eye position so that the driver who looks at the composite image displayed on the monitor can intuitively recognize the blind area, which is included in the virtual camera image, from the driver without the inadequate parallax.</p>
<p id="p-0024" num="0024">In the image composition circuit, the vehicle interior image which is previously shot from the driver's viewing position is made into the translucent vehicle interior image so that the virtual camera image is represented on the composite image displayed on the monitor transparently through the translucent vehicle interior image, as a result, the external situation, which is blind from the driver and viewed in the virtual camera image, becomes clearly visible in the relationship with the position of the vehicle by the translucent vehicle interior image.</p>
<p id="p-0025" num="0025">As a result, in addition to achieving the inexpensive system which uses only the vehicle-mounted external camera, the blind area from the driver is intuitively recognized without an inadequate parallax, and the external situation which is blind from the driver becomes clearly visible in the relationship with the position of the vehicle.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0007" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0026" num="0026"><figref idref="DRAWINGS">FIG. 1</figref> is an entire system block diagram showing the side view monitor system A<b>1</b> of the first embodiment (an example of the vehicle-peripheral image displaying system).</p>
<p id="p-0027" num="0027"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart showing a flow of composite image luminance controlling processing performed at the controlling circuit <b>45</b> in the side view monitor system A<b>1</b> of the first embodiment.</p>
<p id="p-0028" num="0028"><figref idref="DRAWINGS">FIG. 3</figref> shows a vehicle interior image which is previously shot from the driver's eye position toward the left front lateral side.</p>
<p id="p-0029" num="0029"><figref idref="DRAWINGS">FIG. 4</figref> is an oblique perspective view showing a state where the form of the vehicle is projected on the road surface from the vehicle on which the side view monitor system A<b>1</b> of the first embodiment is mounted.</p>
<p id="p-0030" num="0030"><figref idref="DRAWINGS">FIG. 5</figref> shows an image (the opaque part) which is the form of the vehicle projected on the road surface from the vehicle on which the side view monitor system A<b>1</b> of the first embodiment is mounted.</p>
<p id="p-0031" num="0031"><figref idref="DRAWINGS">FIG. 6</figref> shows the composite image which is obtained by combining in the side view monitor system A<b>1</b> of the first embodiment &#x201c;the opaque part DE&#x201d; of <figref idref="DRAWINGS">FIG. 5</figref> with the vehicle interior image RP of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0032" num="0032"><figref idref="DRAWINGS">FIG. 7</figref> shows the translucent vehicle interior image RG which is obtained by combining in the side view monitor system A<b>1</b> of the first embodiment &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d; and &#x201c;the arbitrary transparent part GE&#x201d; with the vehicle interior image RP of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0033" num="0033"><figref idref="DRAWINGS">FIG. 8</figref> shows an image in which the border frame EL is displayed on an outer circumference of the area set as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0% of the vehicle interior image RP shown in <figref idref="DRAWINGS">FIG. 3</figref> in the side view monitor system A<b>1</b> of the first embodiment.</p>
<p id="p-0034" num="0034"><figref idref="DRAWINGS">FIG. 9</figref> is an entire system block diagram showing the back view monitor system A<b>2</b> of the second embodiment (an example of the vehicle-peripheral image displaying system).</p>
<p id="p-0035" num="0035"><figref idref="DRAWINGS">FIG. 10</figref> shows the translucent vehicle interior image RG in which in the back view monitor system A<b>2</b> of the second embodiment &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d; and &#x201c;the arbitrary transparent part GE&#x201d; are combined with the vehicle interior image RP of the backside.</p>
<p id="p-0036" num="0036"><figref idref="DRAWINGS">FIG. 11</figref> is an entire system block diagram which shows the front view monitor system A<b>3</b> of the third embodiment (an example of the vehicle-peripheral image displaying system).</p>
<p id="p-0037" num="0037"><figref idref="DRAWINGS">FIG. 12</figref> is a flow chart which shows a flow of blending ratio sensor conjunction controlling processing operated in the controlling circuit <b>45</b> in the front view monitor system A<b>3</b> of the third embodiment.</p>
<p id="p-0038" num="0038"><figref idref="DRAWINGS">FIG. 13</figref> shows a vehicle interior image being previously shot toward foreside from the driver's eye position.</p>
<p id="p-0039" num="0039"><figref idref="DRAWINGS">FIG. 14</figref> shows the image (the opaque part) when the image, in which the vehicle form is vertically projected on the road surface from the vehicle on which the front view monitor system A<b>3</b> of the third embodiment is mounted, is transparently viewed through from the driver's eye position.</p>
<p id="p-0040" num="0040"><figref idref="DRAWINGS">FIG. 15</figref>, in the front view monitor system A<b>3</b> of the third embodiment, shows a composite image in which the divided areas of the left, right, and center front camera images and &#x201c;the opaque part DE&#x201d; of <figref idref="DRAWINGS">FIG. 14</figref> are combined.</p>
<p id="p-0041" num="0041"><figref idref="DRAWINGS">FIG. 16</figref> shows a translucent vehicle interior image RG in which &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d; and &#x201c;the arbitrary transparent part GE&#x201d; are combined with the vehicle interior image RP shown in <figref idref="DRAWINGS">FIG. 13</figref> in the front view monitor system A<b>3</b> of the third embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0008" level="1">DESCRIPTION OF NUMERIC CODES</heading>
<p id="p-0042" num="0000">
<ul id="ul0002" list-style="none">
    <li id="ul0002-0001" num="0000">
    <ul id="ul0003" list-style="none">
        <li id="ul0003-0001" num="0042">A<b>1</b> side view monitor system (an example of vehicle-peripheral image displaying system)</li>
        <li id="ul0003-0002" num="0043"><b>1</b> side camera (vehicle-mounted external camera)</li>
        <li id="ul0003-0003" num="0044">A<b>2</b> back view monitor system (an example of vehicle-peripheral image displaying system)</li>
        <li id="ul0003-0004" num="0045"><b>21</b> back camera (vehicle-mounted external camera)</li>
        <li id="ul0003-0005" num="0046">A<b>3</b> front view monitor system (an example of vehicle-peripheral image displaying system)</li>
        <li id="ul0003-0006" num="0047"><b>31</b>L left front camera (vehicle-mounted external camera)</li>
        <li id="ul0003-0007" num="0048"><b>31</b>R right front camera (vehicle-mounted external camera)</li>
        <li id="ul0003-0008" num="0049"><b>31</b>C center front camera (vehicle-mounted external camera)</li>
        <li id="ul0003-0009" num="0050"><b>2</b> image processing controlling unit (monitor-image producing unit)</li>
        <li id="ul0003-0010" num="0051"><b>41</b> decoder</li>
        <li id="ul0003-0011" num="0052"><b>41</b>L left decoder</li>
        <li id="ul0003-0012" num="0053"><b>41</b>R right decoder</li>
        <li id="ul0003-0013" num="0054"><b>41</b>C center decoder</li>
        <li id="ul0003-0014" num="0055"><b>42</b> image memory</li>
        <li id="ul0003-0015" num="0056"><b>42</b>L left image memory</li>
        <li id="ul0003-0016" num="0057"><b>42</b>R right image memory</li>
        <li id="ul0003-0017" num="0058"><b>42</b>C center image memory</li>
        <li id="ul0003-0018" num="0059"><b>43</b> image processor</li>
        <li id="ul0003-0019" num="0060"><b>44</b> image memory (image storing memory)</li>
        <li id="ul0003-0020" num="0061"><b>45</b> controlling circuit (CPU)</li>
        <li id="ul0003-0021" num="0062"><b>46</b> superimposing circuit (image composition circuit)</li>
        <li id="ul0003-0022" num="0063"><b>47</b> encoder</li>
        <li id="ul0003-0023" num="0064"><b>48</b> blending external controller</li>
        <li id="ul0003-0024" num="0065"><b>49</b> luminance determining sensor (luminance detector)</li>
        <li id="ul0003-0025" num="0066"><b>3</b> monitor</li>
        <li id="ul0003-0026" num="0067"><b>4</b> blending ratio manual controlling interface</li>
        <li id="ul0003-0027" num="0068"><b>5</b> external sensor</li>
        <li id="ul0003-0028" num="0069"><b>51</b> rudder angle sensor</li>
        <li id="ul0003-0029" num="0070"><b>52</b> speed sensor</li>
        <li id="ul0003-0030" num="0071"><b>53</b> illumination switch (lighting condition detector)</li>
        <li id="ul0003-0031" num="0072"><b>54</b> function switch</li>
        <li id="ul0003-0032" num="0073"><b>55</b> turning signal switch</li>
        <li id="ul0003-0033" num="0074">RP vehicle interior image</li>
        <li id="ul0003-0034" num="0075">SE area in which dimensions and a form of the vehicle is vertically projected on a road surface</li>
        <li id="ul0003-0035" num="0076">RG translucent vehicle interior image</li>
        <li id="ul0003-0036" num="0077">CE 100% transparent part</li>
        <li id="ul0003-0037" num="0078">GE arbitrary transparent part</li>
        <li id="ul0003-0038" num="0079">DE opaque part</li>
    </ul>
    </li>
</ul>
</p>
<heading id="h-0009" level="1">BEST MODE FOR CARRYING OUT THE INVENTION</heading>
<p id="p-0043" num="0080">Hereinafter, as a best mode for realizing a vehicle-peripheral image displaying system according to the present invention, blind area eliminating cameras of three directions will be described in first to third embodiments respectively.</p>
<p id="p-0044" num="0081">Basically, as represented in <figref idref="DRAWINGS">FIG. 1</figref>, an entire system structure includes a camera for eliminating a blind area, a digital image processor which processes an image of the camera, and a blend-processing section for the translucent images.</p>
<p id="p-0045" num="0082">When a single camera image is used, the basic structure is in common.</p>
<p id="p-0046" num="0083">However, regarding a placement and a number of the cameras, the configuration is devised in consideration of a cost and the like.</p>
<p id="p-0047" num="0084">Further, transparency of a translucent part on a monitor is displayed with a transmissivity which is initially set (an initial transmissivity value). However, the system is assumed to be such that the transmissivity is not fixed and can be arbitrarily changed in a range of the transmissivity from 0 to 100% by a user (=a driver).</p>
<p id="p-0048" num="0085">Also, the system is assumed to be such that the transmissivity of each area is customizable according to the user's desire.</p>
<heading id="h-0010" level="1">FIRST EMBODIMENT</heading>
<p id="p-0049" num="0086">A first embodiment is an example of a side view monitor system. The side view monitor system displays on a vehicle interior monitor a front lateral part, which is a blind area from the driver, of the vehicle by using a side camera which is provided inside or near a side mirror and is for eliminating the blind area as a vehicle-mounted external camera.</p>
<p id="p-0050" num="0087">First, the structure thereof will be described.</p>
<p id="p-0051" num="0088"><figref idref="DRAWINGS">FIG. 1</figref> is an entire system block diagram showing the side view monitor system A<b>1</b> of the first embodiment (an example of the vehicle-peripheral image displaying system).</p>
<p id="p-0052" num="0089">The side view monitor system A<b>1</b> of the first embodiment, as shown in <figref idref="DRAWINGS">FIG. 1</figref>, includes the side camera <b>1</b> (the vehicle-mounted external camera), an image processing controlling unit <b>2</b> (monitor-image producing unit), the monitor <b>3</b>, a blending ratio manual controlling interface <b>4</b>, and an external sensor <b>5</b>.</p>
<p id="p-0053" num="0090">The side camera <b>1</b> is provided inside or near a left side mirror to be mounted and shoots an image of the front lateral part, which is a blind area from the driver, of the vehicle.</p>
<p id="p-0054" num="0091">The side camera <b>1</b> obtains data of an actually shot camera image of the front lateral part of the vehicle by an image sensor (CCD, CMOS or the like).</p>
<p id="p-0055" num="0092">The monitor <b>3</b> is provided in the vehicle interior at a position to cause the monitor to be visible for the driver (for example, at a position of an instrument panel or the like). An image is output from the image processing controlling unit <b>2</b> to be displayed, and the image is input to be displayed on the monitor <b>3</b>. The monitor <b>3</b> includes a display screen <b>3</b><i>a </i>made with a liquid crystal display, an organic EL or the like.</p>
<p id="p-0056" num="0093">Here, as the monitor <b>3</b>, a dedicated monitor may be provided in the side view monitor system A<b>1</b> or a dedicated monitor may also be provided in a camera system for eliminating the blind area, and also, a monitor for the other system such as a navigation system or the like may be appropriated.</p>
<p id="p-0057" num="0094">The image processing controlling unit <b>2</b> produces an image to be displayed on the monitor <b>3</b> based on the actually shot camera image input from the side camera <b>1</b>.</p>
<p id="p-0058" num="0095">The image processing controlling unit <b>2</b>, as shown in <figref idref="DRAWINGS">FIG. 1</figref>, includes a decoder <b>41</b>, an image memory <b>42</b>, an image processor <b>43</b>, an image memory <b>44</b> (an image storing memory), a controlling circuit (CPU) <b>45</b>, a superimposing circuit <b>46</b> (an image composition circuit), an encoder <b>47</b>, a blending external controller <b>48</b>, and a luminance determining sensor <b>49</b> (a luminance detector).</p>
<p id="p-0059" num="0096">The image processor <b>43</b> performs the viewpoint conversion of the actually shot camera image input from the side camera <b>1</b> converting into a virtual camera image which is to be viewed from a driver's eye position.</p>
<p id="p-0060" num="0097">Specifically, an analog/digital conversion of the actually shot camera image input from the side camera <b>1</b> is performed by the decoder <b>41</b> and the actually shot camera image is stored in the image memory <b>42</b>.</p>
<p id="p-0061" num="0098">Then, in the image processor <b>43</b>, &#x201c;image processing including various processing (a luminance adjustment, a color correction, an edge correction or the like)&#x201d; and &#x201c;viewpoint conversion processing as if the virtual camera is provided at the driver's eye position&#x201d; are made.</p>
<p id="p-0062" num="0099">The image memory <b>44</b> stores a vehicle interior image RP (<figref idref="DRAWINGS">FIG. 3</figref>), which is previously shot from the driver's eye position, as a vehicle interior image.</p>
<p id="p-0063" num="0100">The superimposing circuit <b>46</b> makes the vehicle interior image RP output from the image memory <b>44</b> translucent to form a translucent vehicle interior image RG (<figref idref="DRAWINGS">FIG. 7</figref>), and performs an image composition such that the translucent vehicle interior image RG is superimposed on the virtual camera image output from the image processor <b>43</b>, then produces a composite image representing the virtual camera image transparently through the translucent vehicle interior image RG.</p>
<p id="p-0064" num="0101">The superimposing circuit <b>46</b> displays, of the vehicle interior image RP which is previously shot from the driver's eye position, an area SE (<figref idref="DRAWINGS">FIG. 4</figref>) in which dimensions and a form of the vehicle is vertically projected on a road surface as a shadow.</p>
<p id="p-0065" num="0102">Specifically, the superimposing circuit <b>46</b> includes a blending circuit <b>46</b><i>a </i>configured to set, of the vehicle interior image RP, the shadow area SE in which the vehicle is projected on the road surface as &#x201c;an opaque part DE&#x201d; having a transmissivity of 0% of the vehicle interior image, an area corresponding to a window glass of the vehicle as &#x201c;a 100% transparent part CE&#x201d; having a transmissivity of 100% of the vehicle interior image, and an area other than the shadow and the window glass as &#x201c;an arbitrary translucent part GE&#x201d; having an arbitrary transmissivity (<figref idref="DRAWINGS">FIG. 7</figref>).</p>
<p id="p-0066" num="0103">Further, the blending circuit <b>46</b><i>a </i>may set a border frame EL to be displayed on an outer circumference of the area set as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0% of the vehicle interior image RP (<figref idref="DRAWINGS">FIG. 8</figref>).</p>
<p id="p-0067" num="0104">Then, in the superimposing circuit <b>46</b>, the composite image made by a superimposing technique, which combines the translucent vehicle interior image RG and the virtual camera image, is transmitted to the encoder <b>47</b> and is processed by using digital/analog conversion in the encoder <b>47</b>, then is output to the monitor <b>3</b> and displayed on the display screen <b>3</b><i>a. </i></p>
<p id="p-0068" num="0105">The blending ratio manual controlling interface <b>4</b>, for example, may be composed of a touch panel switch of the monitor <b>3</b> and arbitrarily adjusts the transmissivity of &#x201c;arbitrary translucent part GE&#x201d; set on the vehicle interior image by a manual operation (a blending ratio manual adjuster).</p>
<p id="p-0069" num="0106">That is to say, once a transmissivity adjusting signal is input from the blending ratio manual controlling interface <b>4</b> to the blending external controller <b>48</b>, the signal passes over the controlling circuit <b>45</b>, and according to a transmissivity setting command from the controlling circuit <b>45</b>, the blending circuit <b>46</b><i>a </i>arbitrarily adjusts the transmissivity of &#x201c;arbitrary translucent part GE&#x201d; set on the vehicle interior image in a range of 0% to 100%.</p>
<p id="p-0070" num="0107">The external sensor <b>5</b> is a sensor, a switch or the like, which brings information to be input to the image processing controlling unit <b>2</b>. As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the external sensor <b>5</b> includes a rudder angle sensor <b>51</b>, a speed sensor <b>52</b>, an illumination switch <b>53</b> (a lighting condition detector), a function switch <b>54</b>, and the other sensor, switch or the like.</p>
<p id="p-0071" num="0108">When the function switch <b>54</b> is ON, based on vehicle information (a rudder angle, a vehicle speed or the like) and external environmental information obtained by the external sensor <b>5</b> (daytime, early-evening, nighttime, weather or the like), the blending circuit <b>46</b><i>a </i>automatically adjusts the transmissivity of &#x201c;arbitrary translucent part GE&#x201d; set on the vehicle interior image so that enhanced visibility of the composite image to be displayed on the monitor <b>3</b> is achieved (a blending ratio sensor conjunction adjuster).</p>
<p id="p-0072" num="0109">Further, the illumination switch <b>53</b> as a lighting condition detector which detects lighting/light-out of an illumination lamp in the vehicle interior and the luminance determining sensor <b>49</b> which detects a luminance of the actually shot camera image input from the side camera <b>1</b> are provided.</p>
<p id="p-0073" num="0110">When both of conditions where the illumination lamp is lighting and where a detected luminance value is lower than a set value Y are met, the superimposing circuit <b>46</b> inverts the luminance of the composite image along with displaying a line with a white line instead of a black line.</p>
<p id="p-0074" num="0111"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart showing a flow of composite image luminance controlling processing performed at the controlling circuit <b>45</b> in the side view monitor system A<b>1</b> of the first embodiment, and hereinafter, each step will be described (a composite image luminance controller).</p>
<p id="p-0075" num="0112">At a step S<b>1</b>, whether the function switch <b>54</b> is ON or not is judged, and if Yes, the process moves on to a step S<b>2</b>, and if No, returns to the judgment of the step S<b>1</b>.</p>
<p id="p-0076" num="0113">At the step S<b>2</b>, following the judgment at the step S<b>1</b> in which the function switch <b>54</b> is ON, whether the illumination switch <b>53</b> is ON is judged, that is, whether the illumination lamp is ON or not, and if Yes, the process moves on to a step S<b>3</b>, and if No, returns to the judgment of the step S<b>1</b>.</p>
<p id="p-0077" num="0114">At the step S<b>3</b>, following the judgment at the step S<b>2</b> in which the illumination switch <b>53</b> is ON, whether the detected luminance value detected by the luminance determining sensor <b>49</b> is lower than the set value Y or not is judged, and if Yes, the process moves on to a step S<b>4</b>, and if No, moves on to a step S<b>5</b>.</p>
<p id="p-0078" num="0115">At the step S<b>4</b>, following the judgment at the step S<b>3</b> in which the detected luminance value is lower than the set value Y, the luminance of the superimposed image is inverted along with displaying the line in the white line instead of the black line and the process is returned to the step S<b>1</b>.</p>
<p id="p-0079" num="0116">At the step S<b>5</b>, following the judgment at the step S<b>3</b> in which the detected luminance value is equal or larger than the set value Y, the luminance of the superimposed image is returned to an ordinary condition and the process is returned to the step S<b>1</b>.</p>
<p id="p-0080" num="0117">Next, a function is described.</p>
<p id="p-0081" num="0118">The purpose of the present invention including the first to the third embodiment is to propose the vehicle-peripheral image displaying system. The vehicle-peripheral image displaying system includes the external camera which is capable of contributing to eliminate the blind area. Also the purpose is to inexpensively propose, of systems each capable of displaying a camera image by using image processing, a system in which the driver is capable of intuitively recognizing the camera image as if the image is viewed transparently through the vehicle only by taking a glance at the image. Further the purpose is to propose the vehicle-peripheral image displaying system in which a move of the vehicle is capable of being recognized in the image.</p>
<p id="p-0082" num="0119">The main subject matter of the displaying system proposed by the present inventor is as follows.
<ul id="ul0004" list-style="none">
    <li id="ul0004-0001" num="0120">To achieve a displaying method in which a moving direction, dimensions and the other senses of the vehicle are intuitively recognized by a glance at the image displayed on the monitor.</li>
    <li id="ul0004-0002" num="0121">To achieve a displaying system in which the transmissivity and the like of the image is freely changed according to the driver's taste, and in which the basic transmissivity is capable of being automatically changed corresponding to the driving situation.</li>
</ul>
</p>
<p id="p-0083" num="0122">For example, at nightfall or the like, the external image is made more visible by changing the transmissivity corresponding to the luminance of the external image.</p>
<p id="p-0084" num="0123">Further, at nighttime or the like, ingenious efforts, in that the luminance inversion is made on a part of the image which is the part being superimposed with the external image to display the white line instead of the black line in order to make the camera image, on which the viewpoint conversion is performed, more visible, are made.</p>
<p id="p-0085" num="0124">Hereinafter, the function of the side view monitor system A<b>1</b> of the first embodiment will be described under &#x201c;Monitor-Image Displaying Function by Transparent Image&#x201d;, &#x201c;Translucent Part Transmissivity Changing Function&#x201d;, and &#x201c;Composite Image Luminance Controlling Function&#x201d;.</p>
<p id="h-0011" num="0000">[Monitor-Image Displaying Function by Transparent Image]</p>
<p id="p-0086" num="0125">The analog/digital conversion of the actually shot image input from the side camera <b>1</b> is performed by the decoder <b>41</b> and the image is stored in the image memory <b>42</b>.</p>
<p id="p-0087" num="0126">Then, in the image processor <b>43</b>, &#x201c;the image processing including various processing (the luminance adjustment, the color correction, the edge correction or the like)&#x201d; and &#x201c;the viewpoint conversion processing as if the virtual camera is provided at the driver's eye position&#x201d; are made, and the virtual camera image is obtained.</p>
<p id="p-0088" num="0127">On the other hand, the image memory <b>44</b> stores the vehicle interior image RP (<figref idref="DRAWINGS">FIG. 3</figref>) which is previously shot from the driver's eye position as the vehicle interior image.</p>
<p id="p-0089" num="0128">Then, the superimposing circuit <b>46</b> makes the vehicle interior image RP output from the image memory <b>44</b> translucent to form the translucent vehicle interior image RG (<figref idref="DRAWINGS">FIG. 7</figref>), and performs the image composition such that the translucent vehicle interior image RG is superimposed on the virtual camera image output from the image processor <b>43</b>, then produces the composite image which represents the virtual camera image transparently through the translucent vehicle interior image RG.</p>
<p id="p-0090" num="0129">The composite image, which is superimposed in the superimposing circuit <b>46</b>, is transmitted to the encoder <b>47</b>, and is processed by performing the digital/analog conversion, then is output to the monitor <b>3</b> and displayed on the display screen <b>3</b><i>a. </i></p>
<p id="p-0091" num="0130">Hereinafter, ingenious efforts for producing the translucent vehicle interior image RG are described.</p>
<p id="p-0092" num="0131"><figref idref="DRAWINGS">FIG. 3</figref> shows a vehicle interior image which is previously shot from the driver's eye position toward the left front lateral side.</p>
<p id="p-0093" num="0132"><figref idref="DRAWINGS">FIG. 4</figref> is an oblique perspective view showing a state where the form of the vehicle is projected on the road surface from the vehicle on which the side view monitor system A<b>1</b> of the first embodiment is mounted.</p>
<p id="p-0094" num="0133"><figref idref="DRAWINGS">FIG. 5</figref> shows an image (the opaque part) which is the form of the vehicle projected on the road surface from the vehicle on which the side view monitor system A<b>1</b> of the first embodiment is mounted, and which is viewed through from the driver's eye position.</p>
<p id="p-0095" num="0134"><figref idref="DRAWINGS">FIG. 6</figref> shows the composite image which is obtained by combining in the side view monitor system A<b>1</b> of the first embodiment &#x201c;the opaque part DE&#x201d; of <figref idref="DRAWINGS">FIG. 5</figref> with the vehicle interior image RP of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0096" num="0135"><figref idref="DRAWINGS">FIG. 7</figref> shows the translucent vehicle interior image RG which is obtained by combining in the side view monitor system A<b>1</b> of the first embodiment &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d; and &#x201c;the arbitrary transparent part GE&#x201d; with the vehicle interior image RP of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0097" num="0136">On the displayed vehicle interior image RP as shown in <figref idref="DRAWINGS">FIG. 3</figref>, ingenious efforts as follows are made.</p>
<p id="p-0098" num="0137">In <figref idref="DRAWINGS">FIG. 4</figref>, the vehicle is illustrated at a high position in the air so that it is discernible. However in fact, the form of the vehicle is vertically projected on the surface of the road or the like as a projection surface and the projected image is positioned at the same height position as a contact area of tires.</p>
<p id="p-0099" num="0138">The image shown in <figref idref="DRAWINGS">FIG. 5</figref> shows the vehicle form itself at an actual driving. Therefore, when the image shown in <figref idref="DRAWINGS">FIG. 5</figref> is superimposed on the image viewed from the driver's eye position, to touch the projected image is to touch the vehicle body.</p>
<p id="p-0100" num="0139">In other words, by superimposing a viewpoint conversion image and the projection surface and displaying the superimposed image, the vehicle sense which is needed at an avoidance of the obstacle or a wheel falling into a side ditch can be obtained at a glance and intuitive recognition can be achieved only by the driver taking a glance at the image (the side view image) so that a contributory level to a safe driving becomes larger.</p>
<p id="p-0101" num="0140">That is, as shown in <figref idref="DRAWINGS">FIG. 6</figref>, the part on which the vehicle form is projected is displayed as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0%, and the vehicle interior image RP is displayed as it is.</p>
<p id="p-0102" num="0141">On the area which does not overlap with the projected vehicle body image, the vehicle interior image RP is displayed with an arbitrary transmissivity by using an a (alpha) blend with the side camera image.</p>
<p id="p-0103" num="0142">Specifically, as shown in <figref idref="DRAWINGS">FIG. 7</figref>, the window glass part is displayed as &#x201c;the 100% transparent part CE&#x201d; having the transmissivity of 100% and the other part is displayed as &#x201c;the arbitrary translucent part GE&#x201d; having an arbitrary transmissivity, then once &#x201c;the opaque part DE&#x201d; having the transmissivity of 0% is added, the vehicle interior image RP viewed from the driver's eye position is 100% displayed.</p>
<p id="p-0104" num="0143">When the translucent vehicle interior image RG which is actually effected is checked, a floor surface, that is, the vehicle interior image RP which is not modified appears clearly different from a vicinity of the door having the transmissivity of 10 to 50% so that the vehicle form is easily distinguished.</p>
<p id="p-0105" num="0144">Further, when the virtual camera image is overlapped with the actually effected translucent vehicle interior image RG, because of a superimposing method using the vehicle interior image, it is extremely straightforward to recognize that the side camera image after performing the viewpoint conversion (=the virtual camera image) is the image which is obtained by transparently viewing through the door.</p>
<p id="p-0106" num="0145">As described above, by the image processing of the viewpoint conversion, the actually shot camera image of the side camera <b>1</b> provided on the side mirror is processed to be converted from the actual image into the virtual camera image as if it is shot by the virtual camera from the driver's eye position. The virtual camera and the vehicle interior image which is made translucent are combined to form the composite image to be displayed while superimposing so that the transparent image having a more improved sense of reality can be expressed.</p>
<p id="p-0107" num="0146">In addition, by displaying the shadow, in which the actual dimensions and the form of the vehicle are vertically projected on the road surface, on the vehicle interior image which is made translucent, a positional relationship between the external transparent image and the actual vehicle can be displayed to be clearly recognized.</p>
<p id="p-0108" num="0147">Furthermore, of the vehicle interior image RP of the driver's eye position, the shadow area, in which the dimensions and the form of the vehicle are projected on the road which is a virtual space screen when the above-described viewpoint conversion is made, is displayed as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0%, and the other part is displayed as the translucent area (&#x201c;the 100% transparent part CE&#x201d;, &#x201c;the arbitrary transparent part GE&#x201d;) having the arbitrary transmissivity.</p>
<p id="p-0109" num="0148">Therefore, the screen image is displayed as a superimposed image having the dimensions and the form of the vehicle clearly displayed, and the other part becomes a picture image blended with the camera image.</p>
<p id="p-0110" num="0149">As a result, the move of the vehicle becomes quite obvious at a glance and the possibility of a wheel coming off or the like is easily judged.</p>
<p id="p-0111" num="0150">The conventional system has required not only the external back camera but also an interior camera and a substantive advantage is rarely achieved considering the increased cost. It has been a redundant system.</p>
<p id="p-0112" num="0151">In contrast, in the present proposal, regarding the vehicle interior image, sufficient effects of required effects are achieved by using the image of the vehicle interior image RP which is previously shot from the driver's eye position, that is, the virtual camera viewing position. Also, because the form of the vehicle is recognized at a glance, it is extremely straightforward to see the traveling direction or to avoid the obstacle coming close by. Thus, it can contribute to a safe driving.</p>
<p id="p-0113" num="0152"><figref idref="DRAWINGS">FIG. 8</figref> shows an image in which the border frame EL is displayed on an outer circumference of the area set as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0% of the vehicle interior image RP shown in <figref idref="DRAWINGS">FIG. 3</figref> in the side view monitor system A<b>1</b> of the first embodiment.</p>
<p id="p-0114" num="0153">Of expressions of the translucent vehicle interior image RG, the distinction of the superimposed images can be made not only by the blending ratio which differentiates the transmissivity, as shown in <figref idref="DRAWINGS">FIG. 7</figref>, but also, as shown in <figref idref="DRAWINGS">FIG. 8</figref>, by having the projected image of the vehicle set as &#x201c;the opaque part DE&#x201d; which has the transmissivity of 0%, and by displaying the border frame EL on the outer circumference of the area &#x201c;the opaque part DE&#x201d; to express and superimposing &#x201c;the opaque part DE&#x201d; on the vehicle interior image RP to express. The same effects as the distinction by the blending ratio can be obtained.</p>
<p id="h-0012" num="0000">[Translucent Part Transmissivity Changing Function]</p>
<p id="p-0115" num="0154">As described above, the blending circuit <b>46</b><i>a </i>of the superimposing circuit <b>46</b>, of the vehicle interior image RP, sets the shadow area SE in which the form of the vehicle is vertically projected on the road surface as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0% of the vehicle interior image, sets the area corresponding to the window glass of the vehicle as &#x201c;the 100% transparent part CE&#x201d; having the transmissivity of 100% of the vehicle interior image, and sets the area other than the shadow and the window glass as &#x201c;the arbitrary translucent part GE&#x201d; having the arbitrary transmissivity (<figref idref="DRAWINGS">FIG. 7</figref>).</p>
<p id="p-0116" num="0155">As just described, because not by applying an uniform translucent image, but by blending and combining the images which have various transmissivities and the blendable translucent area of 100% and 100 to 0%, all kinds of misinterpretations or cognition errors caused by an uniform screen image can be eliminated.</p>
<p id="p-0117" num="0156">However, regarding &#x201c;the arbitrary transparent part GE&#x201d;, if a previously set single fixed transmissivity is used, the user cannot arbitrarily change the transmissivity so that a poor usability may be caused. Also if the transmissivity of the screen image is uniform even when there are environmental changes, a decreased visibility may be caused.</p>
<p id="p-0118" num="0157">In response, in the first embodiment, the transmissivity of &#x201c;the arbitrary transparent part GE&#x201d; is capable of being adjusted automatically or by the manual operation.</p>
<p id="p-0119" num="0158">That is to say, once a transmissivity adjusting signal is input by the manual operation on the blending ratio manual controlling interface <b>4</b> to the blending external controller <b>48</b>, the signal passing over the controlling circuit <b>45</b>, according to the transmissivity setting command from the controlling circuit <b>45</b>, the blending circuit <b>46</b><i>a </i>arbitrarily adjusts the transmissivity of &#x201c;the arbitrary translucent part GE&#x201d; set on the vehicle interior image in a range of 0% to 100%.</p>
<p id="p-0120" num="0159">Further, when the function switch <b>54</b> is ON, the blending circuit <b>46</b><i>a </i>automatically adjusts the transmissivity of &#x201c;the arbitrary translucent part GE&#x201d; set on the vehicle interior image based on vehicle information (rudder angle, vehicle speed or the like) and external environmental information (daytime, early-evening, nighttime, weather or the like) obtained by the external sensor <b>5</b> so as to enhance the visibility of the composite image displayed on the monitor <b>3</b>.</p>
<p id="p-0121" num="0160">Therefore, the blending ratio is capable of being changed by the manual operation, so that the transmissivity of &#x201c;the arbitrary transparent part GE&#x201d; is capable of being freely set and updated. As a result, a system which is highly user-friendly is achieved.</p>
<p id="p-0122" num="0161">Also, when the function switch <b>54</b> is ON, the system in which the transmissivity of &#x201c;the arbitrary transparent part GE&#x201d; is automatically adjusted without an operation by the user is achieved so that the enhanced visibility of the composite image displayed on the monitor <b>3</b> can be maintained.</p>
<p id="h-0013" num="0000">[Composite Image Luminance Controlling Function]</p>
<p id="p-0123" num="0162">The ON signal from the illumination switch <b>53</b> is detected when the outside sight is unclear such as nighttime, early-evening, and bad weather.</p>
<p id="p-0124" num="0163">Therefore, while the illumination lamp is lighting, the entire luminance of the display screen <b>3</b><i>a </i>of the monitor <b>3</b> turns down, and the vehicle interior image may disappear in the darkness on the usual superimposed screen image.</p>
<p id="p-0125" num="0164">Also, eyesight of the driver responds to the darkness, therefore the luminance of the entire screen image needs to be lowered.</p>
<p id="p-0126" num="0165">In this system, when the function switch <b>54</b> is ON and when both of conditions where the illumination lamp is lighting and where the detected luminance value is lower than the set value Y are met, in the flow chart of <figref idref="DRAWINGS">FIG. 2</figref>, the process moves onto step S<b>1</b>, step S<b>2</b>, step S<b>3</b>, and to step S<b>4</b>. At the step S<b>4</b>, the luminance of the composite image is inverted along with displaying the line with the white line instead of the black line.</p>
<p id="p-0127" num="0166">Once the detected luminance value becomes larger than the set value Y, in the flow chart of <figref idref="DRAWINGS">FIG. 2</figref>, the process moves onto step S<b>1</b>, step S<b>2</b>, step S<b>3</b>, and step S<b>5</b>. At the step S<b>5</b>, the luminance of the composite image is turned back to the normal condition.</p>
<p id="p-0128" num="0167">That is, in the controlling circuit <b>45</b>, the brightness of the screen is automatically corrected to be the most appropriate level based on the information from the luminance determining sensor <b>49</b>. At this time, based on the ON signal from the illumination switch <b>53</b> and the set value Y of the luminance signal which is previously set, the luminance inversion of the superimposed vehicle interior image is performed so that the line, which has been expressed with the black line, is displayed with the white line instead of the black line, and the inverted image is superimposed.</p>
<p id="p-0129" num="0168">As just described, by displaying the inverted image, the display screen of the monitor <b>3</b> made by superimposing becomes an image close to a line drawing of white line so that the vehicle sense can be intuitively recognized even in the dark external camera image.</p>
<p id="p-0130" num="0169">Next, the advantageous effects will be described.</p>
<p id="p-0131" num="0170">In the side view monitor system A<b>1</b> of the first embodiment, the advantageous effects described as follows are achieved.</p>
<p id="p-0132" num="0171">(1) In the vehicle-peripheral image displaying system (the side view monitor system A<b>1</b>) including the vehicle-mounted external camera (the side camera <b>1</b>) mounted on the vehicle and configured to shoot an image of the vehicle-periphery, the monitor <b>3</b> provided in the vehicle interior at the position to cause the monitor to be visible for the driver, and the monitor-image producing unit (the image processing controlling unit <b>2</b>) configured to produce an image to be displayed on the monitor <b>3</b> based on the actually shot camera image input from the vehicle-mounted external camera, the monitor-image producing unit includes the image processor <b>43</b> configured to performs the viewpoint conversion of the actually shot camera image input from the vehicle-mounted external camera into the virtual camera image which is to be viewed from the driver's eye position, the image memory (the image memory <b>44</b>) configured to store the shot image of the vehicle-interior which is previously shot from the driver's eye position as the vehicle interior image, and the image composition circuit (the superimposing circuit <b>46</b>) which makes the vehicle interior image output from the image memory translucent to form a translucent vehicle interior image, performs an image composition such that the translucent vehicle interior image is superimposed on the virtual camera image output from the image processor, and produces a composite image representing the virtual camera image transparently through the translucent vehicle interior image.</p>
<p id="p-0133" num="0172">Therefore, in addition to achieving the inexpensive system which uses only the vehicle-mounted external camera, the blind area from the driver is intuitively recognized without a disparity, and the external situation of the blind area from the driver is clearly visible in the relationship with the position of the vehicle.</p>
<p id="p-0134" num="0173">(2) The image composition circuit (the superimposing circuit <b>46</b>), of the entire area of the vehicle interior image which is previously shot from the driver's eye position, displays the area in which the dimensions and the form of the vehicle are vertically projected on the road surface as the shadow.</p>
<p id="p-0135" num="0174">Therefore, a positional relationship, a distant relationship and shifts of the position and the distance between the shadow, which represents the vehicle, and the obstacle or the like, which exists within the external area being blind from the driver, can be clearly recognized, and as a result, a slow driving or a parking can be done with an enhanced safety.</p>
<p id="p-0136" num="0175">(3) The image composition circuit (the superimposing circuit <b>46</b>) includes the blending circuit <b>46</b><i>a </i>configured to set, of the vehicle interior image RP, the shadow area SE in which the vehicle is projected on the road surface as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0% of the vehicle interior image RP, set the area corresponding to a window glass of the vehicle as &#x201c;the 100% transparent part CE&#x201d; having the transmissivity of 100% of the vehicle interior image, and set the area other than the shadow and the window glass as &#x201c;the arbitrary translucent part GE&#x201d; having the arbitrary transmissivity.</p>
<p id="p-0137" num="0176">Therefore, the superimposed screen image having the clear dimensions and the form of the vehicle is displayed on the monitor <b>3</b>. For example, the various misinterpretations or the cognition errors which occur if the screen image is displayed with a uniform translucent image can be eliminated. As a result, the move of the vehicle becomes quite obvious at a glance and the judgment for avoiding the wheel coming off or the like can be made easier.</p>
<p id="p-0138" num="0177">(4) The blending circuit <b>46</b><i>a </i>set the border frame EL to be display on the outer circumference of &#x201c;the opaque part DE&#x201d; having the transmissivity of 0% of the vehicle interior image.</p>
<p id="p-0139" num="0178">Therefore, by a simple technique which does not differentiate the blending ratio of the transmissivity, the positional relationship, the distant relationship and shifts of the position and the distance between the shadow, which represents the vehicle, and the obstacle or the like, which exists within the external area being blind from the driver, can be clearly recognized.</p>
<p id="p-0140" num="0179">(5) The blending circuit <b>46</b><i>a </i>includes the blending ratio manual adjuster (the blending ratio manual controlling interface <b>4</b>, the blending external controller <b>48</b>, and the controlling circuit <b>45</b>) which arbitrarily adjusts by the manual operation the transmissivity of the translucent part set on the vehicle interior image (&#x201c;the arbitrary transparent part GE&#x201d;).</p>
<p id="p-0141" num="0180">Therefore, the system having an improved usability can be achieved such that the transmissivity of the translucent part is adjusted by the manual operation according to the user's taste or the visibility of the image displayed on the monitor <b>3</b>.</p>
<p id="p-0142" num="0181">(6) The blending circuit <b>46</b><i>a </i>includes the blending ratio sensor conjunction adjuster (the controlling circuit <b>45</b>) which automatically adjusts the transmissivity of the translucent part set on the vehicle interior image (&#x201c;the arbitrary transparent part GE&#x201d;) based on the vehicle information and the external environmental information obtained by the external sensor <b>5</b> so that the enhanced visibility of the composite image displayed on the monitor <b>3</b> is obtained.</p>
<p id="p-0143" num="0182">Therefore, without requiring an operation by the user, the system which maintains the enhanced visibility of the composite image displayed on the monitor <b>3</b> is achieved by an adjusting performance which is automatically performed.</p>
<p id="p-0144" num="0183">(7) The lighting condition detector (the illumination switch <b>53</b>) which detects lighting/light-out of the illumination lamp in the vehicle interior and the luminance detector (the luminance determining sensor <b>49</b>) which detects the luminance of the actually shot camera image input from the vehicle-mounted external camera are provided. The image composition circuit (the superimposing circuit <b>46</b>) includes a composite image luminance controller (<figref idref="DRAWINGS">FIG. 2</figref>) which inverts the luminance of the composite image along with displaying the line with the white line instead of the black line when both of conditions where the illumination lamp is lighting and where a detected luminance value is lower than the set value are met.</p>
<p id="p-0145" num="0184">Therefore, when the outside sight is unclear such as nighttime, early-evening, and bad weather, the vehicle sense can be intuitively recognized even in the dark external camera image.</p>
<p id="p-0146" num="0185">(8) The vehicle-mounted external camera is the side camera <b>1</b> used for the side view monitoring system A<b>1</b> configured to display the front lateral part, which is the blind area from the driver, of the vehicle on the vehicle interior monitor <b>3</b>.</p>
<p id="p-0147" num="0186">Therefore, the vehicle sense which is needed when avoiding the obstacle or avoiding the wheel falling into the side ditch are achieved at a glance and can be intuitively recognized so that the contributory level to a safe driving can be made larger.</p>
<heading id="h-0014" level="1">SECOND EMBODIMENT</heading>
<p id="p-0148" num="0187">The second embodiment is an example of a back view monitor system configured to display a back part, which is the blind area from the driver, of the vehicle on the vehicle interior monitor by using a back camera provided at the back position of the vehicle as the vehicle-mounted external camera for eliminating the blind area.</p>
<p id="p-0149" num="0188">First, the structure is described.</p>
<p id="p-0150" num="0189"><figref idref="DRAWINGS">FIG. 9</figref> is an entire system block diagram showing the back view monitor system A<b>2</b> of the second embodiment (an example of the vehicle-peripheral image displaying system).</p>
<p id="p-0151" num="0190">The back view monitor system A<b>2</b> of the second embodiment, as shown in <figref idref="DRAWINGS">FIG. 9</figref>, includes the back camera <b>21</b> (the vehicle-mounted external camera), the image processing controlling unit <b>2</b> (monitor-image producing unit), the monitor <b>3</b>, the blending ratio manual controlling interface <b>4</b>, and the external sensor <b>5</b>.</p>
<p id="p-0152" num="0191">The image processing controlling unit <b>2</b>, as shown in <figref idref="DRAWINGS">FIG. 9</figref>, includes the decoder <b>41</b>, the image memory <b>42</b>, the image processor <b>43</b>, the image memory <b>44</b> (the image storing memory), the controlling circuit (CPU) <b>45</b>, the superimposing circuit <b>46</b> (the image composition circuit), the encoder <b>47</b>, the blending external controller <b>48</b>, and the luminance determining sensor <b>49</b> (the luminance detector).</p>
<p id="p-0153" num="0192">The external sensor <b>5</b> includes, as shown in <figref idref="DRAWINGS">FIG. 9</figref>, the rudder angle sensor <b>51</b>, the speed sensor <b>52</b>, the illumination switch <b>53</b> (the lighting condition detector), the function switch <b>54</b>, and the other sensor, switch or the like.</p>
<p id="p-0154" num="0193">The back camera <b>21</b> is provided to be mounted inside or near a trunk lid and a license plate in the case of a passenger car, and provided around an upper end of the back window in the case of a large car such as a recreational vehicle. The back camera <b>21</b> takes an image of the back of the vehicle which is the blind area from the driver.</p>
<p id="p-0155" num="0194">The back camera <b>21</b> obtains data of the actually shot camera image of the back part of the vehicle by the image sensor (CCD, CMOS or the like).</p>
<p id="p-0156" num="0195">In the present back view monitor system, the camera is positioned such that the vicinity of a bumper comes out in the image to be displayed so that the vehicle sense is to be obtained by getting a clue from the displayed vicinity of the bumper and a trajectory line.</p>
<p id="p-0157" num="0196">In the second embodiment, the vehicle sense is to be achieved, in the same way as the side view monitor system described in the first embodiment, by superimposing the vehicle interior image which is previously shot toward the back of the vehicle interior from the driver's eye position.</p>
<p id="p-0158" num="0197">The other structure is in the same way as <figref idref="DRAWINGS">FIG. 1</figref> of the first embodiment and an explanation is abbreviated with having the same numbers placed on the corresponding structure.</p>
<p id="p-0159" num="0198">Next, the function is described.</p>
<p id="p-0160" num="0199"><figref idref="DRAWINGS">FIG. 10</figref> shows the translucent vehicle interior image RG in which in the back view monitor system A<b>2</b> of the second embodiment &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d; and &#x201c;the arbitrary transparent part GE&#x201d; are combined with the vehicle interior image RP of the backside.</p>
<p id="p-0161" num="0200">The back view monitor system A<b>2</b> of the second embodiment has a form in which the side camera <b>1</b> of the side view monitor system A<b>1</b> of the first embodiment using the side camera <b>1</b> is displaced to the back camera <b>21</b>.</p>
<p id="p-0162" num="0201">As is the case in the side camera <b>1</b> as described above, the actually shot camera image from the back camera <b>21</b> is converted into the image in digital, and the viewpoint conversion is performed to form the virtual camera image of the driver's eye position.</p>
<p id="p-0163" num="0202">On the virtual camera image, the projected vehicle image as <figref idref="DRAWINGS">FIG. 4</figref> is taken toward the back side of the vehicle this time, and the projected area of the vehicle is adapted to the vehicle interior image which superimposes with the virtual camera image of the back camera <b>21</b>.</p>
<p id="p-0164" num="0203">When the vehicle interior image viewed from the driver's eye position is superimposed, as shown in <figref idref="DRAWINGS">FIG. 10</figref>, a hatched line area, which is corresponding to the shadow SE in which the vehicle is vertically projected, is set as &#x201c;the opaque part DE&#x201d; having the transmissivity of 0%, and likewise the window glass area is set as &#x201c;the transparent part CE&#x201d; having the transmissivity of 100%.</p>
<p id="p-0165" num="0204">Further the other area is set as the translucent &#x201c;arbitrary transparent area GE&#x201d; on which an alpha blend operation is performed at the arbitrary transmissivity. The transmissivity is capable of being set by the user.</p>
<p id="p-0166" num="0205">Therefore, the fact that the image expressed in the back view monitor system A<b>2</b> is the image which is viewed transparently through the backside of the vehicle can be straightforwardly expressed.</p>
<p id="p-0167" num="0206">Further, since the other functions are the same as the first embodiment, the explanation is abbreviated.</p>
<p id="p-0168" num="0207">Next, the advantageous effects will be described.</p>
<p id="p-0169" num="0208">In the back view monitor system A<b>2</b> of the second embodiment, the following effects can be achieved in addition to the effects of (1) to (7) of the first embodiment</p>
<p id="p-0170" num="0209">(9) The vehicle-mounted external camera is the back camera <b>21</b> used for the back view monitor system A<b>2</b>. The back view monitor system A<b>2</b> displays the back part, which is the blind area from the driver, of the vehicle on the vehicle interior monitor <b>3</b>.</p>
<p id="p-0171" num="0210">Therefore, for example, the vehicle stop line which is necessary when driving backward at parking, a vehicle stop curbstone, a positional sense or a distant sense of between the vehicle and a wall or the like, or a positional sense and a distant sense between the vehicle and the approaching following vehicle while running can be intuitively recognized so that the contributive level to the safe driving or a quick parking can be made larger.</p>
<heading id="h-0015" level="1">THIRD EMBODIMENT</heading>
<p id="p-0172" num="0211">The third embodiment is an example of a front view monitor system configured to display a vehicle's front part, which is the blind area from the driver, on the vehicle interior monitor by using a front camera provided at the vehicle's foreside position for eliminating the blind area as the vehicle-mounted external camera.</p>
<p id="p-0173" num="0212">First, the structure is described.</p>
<p id="p-0174" num="0213"><figref idref="DRAWINGS">FIG. 11</figref> is an entire system block diagram which shows the front view monitor system A<b>3</b> of the third embodiment (an example of the vehicle-peripheral image displaying system).</p>
<p id="p-0175" num="0214">The front view monitor system A<b>3</b> of the third embodiment, as shown in <figref idref="DRAWINGS">FIG. 11</figref>, includes a left front camera <b>31</b>L (the vehicle-mounted external camera), a right front camera <b>31</b>R (the vehicle-mounted external camera), a center front camera <b>31</b>C (the vehicle-mounted external camera), the image processing controlling unit <b>2</b> (monitor-image producing unit), the monitor <b>3</b>, the blending ratio manual controlling interface <b>4</b>, and the external sensor <b>5</b>.</p>
<p id="p-0176" num="0215">The image processing controlling unit <b>2</b>, as shown in <figref idref="DRAWINGS">FIG. 11</figref>, includes a left decoder <b>41</b>L, a right decoder <b>41</b>R, a center decoder <b>41</b>C, a left image memory <b>42</b>L, a right image memory <b>42</b>R, a center image memory <b>42</b>C, the image processor <b>43</b>, the image memory <b>44</b> (the image preserving memory), the controlling circuit (CPU) <b>45</b>, the superimposing circuit <b>46</b> (the image composition circuit), the encoder <b>47</b>, the blending external controller <b>48</b>, and the luminance determining sensor <b>49</b> (the luminance detector).</p>
<p id="p-0177" num="0216">The external sensor <b>5</b>, as shown in <figref idref="DRAWINGS">FIG. 11</figref>, includes the rudder angle sensor <b>51</b>, the speed sensor <b>52</b>, then illumination switch <b>53</b> (the lighting condition detector), the function switch <b>54</b>, a turning signal switch <b>55</b>, and the other sensor, switch or the like.</p>
<p id="p-0178" num="0217">The front view monitor system includes a number of cameras in many cases of the existing systems, and also may include three cameras of left, right, and center.</p>
<p id="p-0179" num="0218">Therefore, as an example of the front view monitor system A<b>3</b> of the third embodiment, the case which uses the three cameras of the left front camera <b>31</b>L, the right front camera <b>31</b>R, and the center front camera <b>31</b>C is cited.</p>
<p id="p-0180" num="0219">In the same way as the side camera <b>1</b> of the first embodiment, after the image processing of the digital conversion and the viewpoint conversion, the superimposing image, that is, the vehicle interior image on which the vertically projected shadow of the vehicle form is added is superimposed on the images output from each of the front camera <b>31</b>L, <b>31</b>R, and <b>31</b>C so that the composite image is obtained.</p>
<p id="p-0181" num="0220">In the third embodiment, since the imaging area is divided into 3 by the three front cameras <b>31</b>L, <b>31</b>R, and <b>31</b>C, the transmissivity of &#x201c;the arbitrary transparent part GE&#x201d; of the imaging area divided into 3 is automatically adjusted in conjunction with the turning signal switch <b>55</b> in which a switch signal is output when a course is changed by turning a steering wheel to either left or right at the slow driving or after stopping.</p>
<p id="p-0182" num="0221"><figref idref="DRAWINGS">FIG. 12</figref> is a flow chart which shows a flow of blending ratio sensor conjunction controlling processing operated in the controlling circuit <b>45</b> in the front view monitor system A<b>3</b> of the third embodiment. Hereinafter, each of the steps will be described (an example of a blending ratio sensor conjunction adjuster).</p>
<p id="p-0183" num="0222">Here, a case in which the user changes the blending ratio of the left and right at an arbitrary setting and sets the current transmissivity Tr<b>1</b> to, for example, a value such as 30% is assumed.</p>
<p id="p-0184" num="0223">At a step S<b>21</b>, whether the function switch <b>54</b> is ON or not is judged, if Yes, the process moves onto a step S<b>22</b>, if No, the judgment at the step S<b>21</b> is repeated.</p>
<p id="p-0185" num="0224">At the step S<b>22</b>, following the judgment at the step S<b>21</b> that the function switch <b>54</b> is ON, whether ON signal from the turning signal switch <b>55</b> is being output (whether the turning signal is blinking) or not is judged, if Yes, the process moves onto a step S<b>23</b>, if No, returns to the step S<b>21</b>.</p>
<p id="p-0186" num="0225">At the step S<b>23</b>, following the judgment at the step S<b>22</b> that the ON signal is being output from the turning signal switch <b>55</b>, whether the signal from the turning signal switch <b>55</b> is a course changing signal to the right or not is judged, if Yes (the turning signal is the signal to the right), the process moves onto the step S<b>24</b>, if No (the turning signal is left), moves onto a step S<b>26</b>.</p>
<p id="p-0187" num="0226">At the step S<b>24</b>, following the judgment at the step S<b>23</b> that the turning signal is to the right, whether the current transmissivity Tr<b>1</b> is lower than the set value Tr<b>0</b> or not is judged, if Yes (Tr<b>1</b>&#x3c;Tr<b>0</b>), the process moves onto a step S<b>25</b>, if No (Tr<b>1</b>&#x2267;Tr<b>0</b>), moves onto a step S<b>28</b>.</p>
<p id="p-0188" num="0227">Here, the set value Tr<b>0</b> is a transmissivity threshold for securing a range of view to the right which is the course direction to be changed.</p>
<p id="p-0189" num="0228">At the step S<b>25</b>, following the judgment at the step S<b>24</b> that Tr<b>1</b>&#x3c;Tr<b>0</b>, the transmissivity of an imaging area of the right front camera is forcibly changed from the current transmissivity Tr<b>1</b> to a transmissivity T (for example, Tr<b>0</b>) and the process returns to the step S<b>21</b>.</p>
<p id="p-0190" num="0229">At the step S<b>26</b>, following the judgment at the step S<b>23</b> that the turning signal is to the left, whether the current transmissivity Tr<b>1</b> is lower than the set value Tr<b>0</b> or not is judged, if Yes (Tr<b>1</b>&#x3c;Tr<b>0</b>), the process moves onto a step S<b>27</b>, if No (Tr<b>1</b>&#x2267;Tr<b>0</b>), moves onto the step S<b>28</b>.</p>
<p id="p-0191" num="0230">Here, the set value Tr<b>0</b> is the transmissivity threshold for securing a range of view to the left which is the course direction to be changed.</p>
<p id="p-0192" num="0231">At the step S<b>27</b>, following the judgment at the step S<b>26</b> that Tr<b>1</b>&#x3c;Tr<b>0</b>, the transmissivity of an imaging area of the left front camera is forcibly changed from the current transmissivity Tr<b>1</b> to a transmissivity T (for example, Tr<b>0</b>) and the process returns to the step S<b>21</b>.</p>
<p id="p-0193" num="0232">At the step S<b>28</b>, following the judgment at the step S<b>24</b> or the step S<b>26</b> that Tr<b>1</b>&#x2267;Tr<b>0</b>, the current transmissivity Tr<b>1</b> is kept unchanged and the process returns to the step S<b>21</b>.</p>
<p id="p-0194" num="0233">The other structure is in the same way as <figref idref="DRAWINGS">FIG. 1</figref> of the first embodiment and an explanation is abbreviated with having the same numbers placed on the corresponding structures.</p>
<p id="p-0195" num="0234">Next the function is described.</p>
<p id="p-0196" num="0235"><figref idref="DRAWINGS">FIG. 13</figref> shows a vehicle interior image which is previously shot toward foreside from the driver's eye position.</p>
<p id="p-0197" num="0236"><figref idref="DRAWINGS">FIG. 14</figref> shows the image (the opaque part) when the image, in which the vehicle form is vertically projected on the road surface from the vehicle on which the front view monitor system A<b>3</b> of the third embodiment is mounted, is transparently viewed through from the driver's eye position.</p>
<p id="p-0198" num="0237"><figref idref="DRAWINGS">FIG. 15</figref>, in the front view monitor system A<b>3</b> of the third embodiment, shows a composite image in which the divided areas of the left, right, and center front camera images and &#x201c;the opaque part DE&#x201d; of <figref idref="DRAWINGS">FIG. 14</figref> are combined.</p>
<p id="p-0199" num="0238"><figref idref="DRAWINGS">FIG. 16</figref> shows a translucent vehicle interior image RG in which &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d; and &#x201c;the arbitrary transparent part GE&#x201d; are combined with the vehicle interior image RP shown in <figref idref="DRAWINGS">FIG. 13</figref> in the front view monitor system A<b>3</b> of the third embodiment.</p>
<p id="p-0200" num="0239">On the vehicle interior image RP, which is previously shot toward foreside from the driver's eye position and shown in <figref idref="DRAWINGS">FIG. 13</figref>, the area in which the vehicle form is vertically projected on the road surface as shown in <figref idref="DRAWINGS">FIG. 14</figref> is made into &#x201c;the opaque part DE&#x201d; having the transmissivity of 0%.</p>
<p id="p-0201" num="0240">Then, a wide-angle screen image having more than 180-degree is to be displayed on the area which excludes &#x201c;the opaque part DE&#x201d; from the vehicle interior image RP.</p>
<p id="p-0202" num="0241">When the wide-angle screen image having more than 180-degree is converted into the image on which the viewpoint conversion is performed to be viewed from the driver's eye position, as shown in <figref idref="DRAWINGS">FIG. 15</figref>, the screen image is composed such that the camera image from the center front camera <b>31</b>C on the center area, the camera image of the left front camera <b>31</b>L on the left area, and the camera image of the right front camera <b>31</b>R on the right area are combined.</p>
<p id="p-0203" num="0242">That is, on the image using the cameras, because of the structure for securing the range of view, the camera images of the left, right, and center front cameras <b>31</b>L, <b>31</b>R, and <b>31</b>C are often displayed in one screen image.</p>
<p id="p-0204" num="0243">In this case, usually each of the camera images is combined so that the wide-angle screen image having more than 180-degree is to be displayed.</p>
<p id="p-0205" num="0244">The images of <figref idref="DRAWINGS">FIG. 13</figref> and <figref idref="DRAWINGS">FIG. 14</figref> are superimposed on the image of <figref idref="DRAWINGS">FIG. 15</figref> and the blending ratio of the vehicle interior image RP of <figref idref="DRAWINGS">FIG. 13</figref> is differentiated as &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d;, and &#x201c;the arbitrary transparent part GE&#x201d;. As a result, as shown in <figref idref="DRAWINGS">FIG. 16</figref>, the image in which the outside of the vehicle foreside is viewed transparently through the vehicle interior is offered to the driver.</p>
<p id="p-0206" num="0245">Therefore, in the case of the front view monitor system A<b>3</b> of the third embodiment, in the same way as the image of the previously described side view monitor system A<b>1</b> or the back view monitor system A<b>2</b>, along with eliminating the blind area, the image in which the vehicle sense, that is, the form and the dimensions of the vehicle are clearly seen at a glance and are intuitively recognized at the avoidance of a sudden possibility can be offered.</p>
<p id="h-0016" num="0000">[Transmissivity Automatic Adjusting Function by Turning Signal Conjunction]</p>
<p id="p-0207" num="0246">The turning signal switch <b>55</b> corresponds when a steering wheel is turned, that is, when the course is changed either to the left or right after a slow driving or stopping.</p>
<p id="p-0208" num="0247">In this case, the information of the approaching vehicle from left and right is more important than the view of the central part.</p>
<p id="p-0209" num="0248">In response, in the third embodiment, if the right turning signal is detected and if the current transimissivity Tr<b>1</b> is lower than the set value Tr<b>0</b>, in the flow chart of <figref idref="DRAWINGS">FIG. 12</figref>, the process moves onto the step S<b>21</b>, step S<b>22</b>, step S<b>23</b>, step S<b>24</b>, and then to step S<b>25</b>.</p>
<p id="p-0210" num="0249">At the step S<b>25</b>, since the view of the right side area is more important than the central area of the screen image, in order to secure the view, the system performs the alpha blend operation which automatically heightens the transmissivity.</p>
<p id="p-0211" num="0250">Further, if the left turning signal is detected and if the current transmissivity Tr<b>1</b> is lower than the set value Tr<b>0</b>, in the flow char of <figref idref="DRAWINGS">FIG. 12</figref>, the process moves onto the step S<b>21</b>, step S<b>22</b>, step S<b>23</b>, step S<b>26</b>, and then step S<b>27</b>.</p>
<p id="p-0212" num="0251">At the step S<b>27</b>, since the view of the left side area is more important than the central area of the screen image, in order to secure the view, the system performs the alpha blend operation which automatically heightens the transmissivity.</p>
<p id="p-0213" num="0252">Therefore, when the course is changed to the right, the right side view is more vividly secured. When the course is changed to the left, the left side view is more vividly secured.</p>
<p id="p-0214" num="0253">As a result, the information of the approaching vehicle from the side to which the course is changed can be accurately recognized.</p>
<p id="p-0215" num="0254">Here, while the above-described operation is running, the transmissivity may be set to be changed by weighting only on either one after distinguishing the turning signal being left or right.</p>
<p id="p-0216" num="0255">Since the other functions are the same as the first embodiment, the explanation is abbreviated.</p>
<p id="p-0217" num="0256">Next, the advantageous effects will be described.</p>
<p id="p-0218" num="0257">In the front view monitor system A<b>3</b> of the third embodiment, in addition to the effects of (1) to (7) of the first embodiment, the following effects can be achieved.</p>
<p id="p-0219" num="0258">(10) The vehicle-mounted external camera is each of the left, right, and center front cameras <b>31</b>L, <b>31</b>R, and <b>31</b>C used in the front view monitor system A<b>3</b> configured to display the foreside portions, which is the blind area from the driver, of the vehicle on the vehicle interior monitor <b>3</b>.</p>
<p id="p-0220" num="0259">Therefore, for example, the positional sense and the distant sense, which are needed when the vehicle is starting straight or starting whilst circling from a state of stopping or slow driving, of between the vehicle and the obstacle or the like of the vehicle's foreside or the positional sense and the distant sense of between the vehicle and the approaching vehicle are intuitively recognized so that the contributive level to the safe driving can be made larger.</p>
<p id="p-0221" num="0260">Hereinbefore, the vehicle-peripheral image displaying system of the present invention has been described in terms of the first to the third embodiments. However, regarding the concrete structure, it is not limited to the embodiments. And design changes, additions or the like are allowed as long as it does not depart from the scope of the present invention as defined by each of the following claims.</p>
<p id="p-0222" num="0261">In the first to third embodiments, as the translucent vehicle interior image which superimposes on the virtual camera image, the case in which the previously prepared vehicle interior image RP is distinguished as &#x201c;the opaque part DE&#x201d;, &#x201c;the 100% transparent part CE&#x201d;, and &#x201c;the arbitrary transparent part GE&#x201d; and additionally the case in which the border frame is displayed on &#x201c;the opaque part DE&#x201d; were exemplified.</p>
<p id="p-0223" num="0262">However, as substitute for &#x201c;the opaque part DE&#x201d;, &#x201c;the opaque part DE&#x201d; may be exemplified with a painted &#x201c;shadow part&#x201d;.</p>
<p id="p-0224" num="0263">Also, the vehicle interior image RP which is previously prepared may be distinguished as &#x201c;the opaque part DE&#x201d; or &#x201c;the shadow part&#x201d; and &#x201c;the arbitrary transparent part GE&#x201d;.</p>
<p id="p-0225" num="0264">Further, the vehicle interior image RP which is previously prepared may be distinguished as &#x201c;the opaque part DE&#x201d; or &#x201c;the shadow part&#x201d; and &#x201c;the transparent part whose transmissivity is gradationally changed&#x201d;.</p>
<heading id="h-0017" level="1">INDUSTRIAL APPLICABILITY</heading>
<p id="p-0226" num="0265">The first embodiment has described the example of the side view monitor system A<b>1</b> which uses the side camera as the vehicle-peripheral image displaying system.</p>
<p id="p-0227" num="0266">The second embodiment has described the example of the back view monitor system A<b>2</b> which uses the back camera as the vehicle-peripheral image displaying system.</p>
<p id="p-0228" num="0267">The third embodiment has described the example of the front view monitor system A<b>3</b> which uses the front cameras as the vehicle-peripheral image displaying system.</p>
<p id="p-0229" num="0268">However, as a vehicle-peripheral image displaying system, the vehicle-peripheral image displaying system can be applied to a monitor system in which the monitor is shared and one of the side, back or front views or the like can be chosen to be viewed, or to a monitor system in which the views are automatically switched over under a certain condition.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A vehicle-peripheral image displaying system comprising:
<claim-text>a vehicle-mounted external camera mounted on a vehicle and configured to shoot an image of a vehicle-periphery;</claim-text>
<claim-text>a monitor provided in a vehicle interior at a position to cause the monitor to be visible for a driver; and</claim-text>
<claim-text>a monitor-image producing unit configured to produce an image to be displayed on the monitor based on an actually shot camera image input from the vehicle-mounted external camera, wherein:</claim-text>
<claim-text>the monitor-image producing unit includes:</claim-text>
<claim-text>an image processor configured to perform a viewpoint conversion of the actually shot camera image input from the vehicle-mounted external camera into a virtual camera image which is to be converted as if it is viewed from the driver's eye position;</claim-text>
<claim-text>an image memory configured to store a vehicle interior image, being previously shot from the driver's eye position, as a vehicle interior image; and</claim-text>
<claim-text>an image composition circuit configured:</claim-text>
<claim-text>to make the vehicle interior image output from the image memory translucent to form a translucent vehicle interior image,</claim-text>
<claim-text>to perform an image composition such that the translucent vehicle interior image is superimposed on the virtual camera image output from the image processor,</claim-text>
<claim-text>to produce a composite image representing the virtual camera image transparently through the translucent vehicle interior image,</claim-text>
<claim-text>wherein:</claim-text>
<claim-text>the image composition circuit displays, of an entire area of the vehicle interior image being previously shot from the driver's eye position, an area in which dimensions and a form of the vehicle are vertically projected on a road surface as a shadow, and</claim-text>
<claim-text>the image composition circuit includes a blending circuit configured to set, of the vehicle interior image, the shadow area in which the vehicle is projected on the road surface as an opaque part having a transmissivity of 0% of the vehicle interior image, and set an area corresponding to a window glass of the vehicle as a transparent part having a transmissivity of 100% of the vehicle interior image, also set areas other than the shadow and the window glass as a translucent part having an arbitrary transmissivity.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the blending circuit sets a border frame to be displayed on an outer circumference of the opaque part having the transmissivity of 0% of the vehicle interior image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the blending circuit includes a blending ratio manual adjuster configured to arbitrarily adjust by a manual operation the transmissivity of the translucent part set on the vehicle interior image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the blending circuit includes a blending ratio sensor conjunction adjuster configured to automatically adjust the transmissivity of the translucent part set on the vehicle interior image based on vehicle information and external environmental information obtained by an external sensor so as to enhance visibility of the composite image displayed on the monitor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising:
<claim-text>a lighting condition detector configured to detect lighting/light-out of an illumination lamp in the vehicle interior; and</claim-text>
<claim-text>a luminance detector configured to detect a luminance of the actually shot camera image input from the vehicle-mounted external camera, wherein</claim-text>
<claim-text>the image composition circuit includes a composite image luminance controller configured to invert the luminance of the composite image along with displaying a line with a white line instead of a black line when both of conditions where the illumination lamp is lighting and where a detected luminance value is lower than a set value are met.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the vehicle-mounted external camera is a side camera used for a side view monitoring system configured to display on the vehicle interior monitor a front lateral part, being a blind area from the driver, of the vehicle.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the vehicle-mounted external camera is a back camera used for a back view monitoring system configured to display on the vehicle interior monitor a back part, being a blind area from the driver, of the vehicle.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the vehicle-mounted external camera is one or more front cameras used for a front view monitoring system configured to display on the vehicle interior monitor a front part, being a blind area from the driver, of the vehicle.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein
<claim-text>the blending circuit includes a blending ratio manual adjuster configured to arbitrarily adjust by a manual operation the transmissivity of the translucent part set on the vehicle interior image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The vehicle-peripheral image displaying system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein
<claim-text>the blending circuit includes a blending ratio sensor conjunction adjuster configured to automatically adjust the transmissivity of the translucent part set on the vehicle interior image based on vehicle information and external environmental information obtained by an external sensor so as to enhance visibility of the composite image displayed on the monitor. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
