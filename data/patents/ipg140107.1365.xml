<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622547-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622547</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13266148</doc-number>
<date>20100402</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2009-110840</doc-number>
<date>20090430</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>100</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>3</main-group>
<subgroup>14</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>3</main-group>
<subgroup>12</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>3</main-group>
<subgroup>1225</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>3</main-group>
<subgroup>14</subgroup>
<symbol-position>L</symbol-position>
<classification-value>A</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<classification-national>
<country>US</country>
<main-classification>351206</main-classification>
</classification-national>
<invention-title id="d2e71">Fundus observation apparatus</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6377349</doc-number>
<kind>B1</kind>
<name>Fercher</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2005/0018132</doc-number>
<kind>A1</kind>
<name>Fukuma et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2006/0100528</doc-number>
<kind>A1</kind>
<name>Chan et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2007/0222945</doc-number>
<kind>A1</kind>
<name>Tsukada et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>351205</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2007/0236661</doc-number>
<kind>A1</kind>
<name>Fukuma et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>351205</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2009/0033870</doc-number>
<kind>A1</kind>
<name>Hangai et al.</name>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>351206</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>EP</country>
<doc-number>1908397</doc-number>
<kind>A2</kind>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>09-276232</doc-number>
<kind>A</kind>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>11-325849</doc-number>
<kind>A</kind>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2002-139421</doc-number>
<kind>A</kind>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>2002-209849</doc-number>
<kind>A</kind>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2006-153838</doc-number>
<kind>A</kind>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>JP</country>
<doc-number>2007-24677</doc-number>
<kind>A</kind>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>JP</country>
<doc-number>2008-073099</doc-number>
<kind>A</kind>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>JP</country>
<doc-number>2008-148930</doc-number>
<kind>A</kind>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>WO</country>
<doc-number>2003-041571</doc-number>
<kind>A1</kind>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>WO</country>
<doc-number>2009059400</doc-number>
<kind>A1</kind>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Extended European Search Report for 10769448.1-1657/2425763 dated Feb. 27, 2013.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>International Search Report for PCT/JP2010/002428; Jun. 22, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>10</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>351206</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>351208</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120044456</doc-number>
<kind>A1</kind>
<date>20120223</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Hayashi</last-name>
<first-name>Takefumi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Hayashi</last-name>
<first-name>Takefumi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Pearne &#x26; Gordon LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Kabushiki Kaisha Topcon</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Mack</last-name>
<first-name>Ricky</first-name>
<department>2872</department>
</primary-examiner>
<assistant-examiner>
<last-name>Alexander</last-name>
<first-name>William</first-name>
</assistant-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP2010/002428</doc-number>
<kind>00</kind>
<date>20100402</date>
</document-id>
<us-371c124-date>
<date>20111025</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2010/125746</doc-number>
<kind>A </kind>
<date>20101104</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The controller <b>210</b> changes the projection region of the Landolt ring T on the fundus Ef by changing, based on the scanning region R, the relative display position of the Landolt ring T and the fixation target V on the LCD <b>39</b>, thereby overlapping the scanning region R and the projection region each other. Under this condition, the fundus observation apparatus <b>1</b> executes the eyesight measurement and OCT measurement, obtains the eyesight value at the site of interest of the fundus Ef, and forms a tomographic image of the fundus Ef in the scanning region R. The controller <b>210</b> stores in the storage <b>212</b> the eyesight value at the site of interest and the tomographic image corresponding to the scanning line closest to the measurement position of eyesight while correlating them with each other, and allows them to be displayed on the display device <b>3. </b></p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="174.16mm" wi="254.59mm" file="US08622547-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="255.78mm" wi="180.00mm" orientation="landscape" file="US08622547-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="281.77mm" wi="178.22mm" orientation="landscape" file="US08622547-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="242.06mm" wi="175.43mm" orientation="landscape" file="US08622547-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="258.91mm" wi="169.93mm" file="US08622547-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="261.03mm" wi="143.00mm" file="US08622547-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="270.76mm" wi="185.25mm" file="US08622547-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="266.19mm" wi="152.82mm" file="US08622547-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="246.38mm" wi="179.41mm" orientation="landscape" file="US08622547-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to a fundus observation apparatus configured to form images of a fundus of an eye by using optical coherence tomography.</p>
<heading id="h-0002" level="1">BACKGROUND ART</heading>
<p id="p-0003" num="0002">In recent years, optical coherence tomography that forms images of the surface morphology and internal morphology of an object by using a light beam from a laser light source or the like has attracted attention. Unlike an X-ray CT apparatus, optical coherence tomography is noninvasive to human bodies, and is therefore expected to be utilized in the medical field and biological field.</p>
<p id="p-0004" num="0003">Patent Document 1 discloses a device to which optical coherence tomography is applied. This device has such a configuration that: a measuring arm scans an object by a rotary deflection mirror (a Galvano mirror); a reference arm is provided with a reference mirror; and an interferometer is mounted at the outlet to analyze, by a spectrometer, the intensity of an interference light of light fluxes from the measurement arm and the reference arm. Moreover, the reference arm is configured to gradually change the light flux phase of the reference light by discontinuous values.</p>
<p id="p-0005" num="0004">The device of Patent Document 1 uses a technique of so-called &#x201c;Fourier Domain OCT (Optical Coherence Tomography).&#x201d; That is to say, the device irradiates a low coherence light beam to an object, superposes the reflected light and the reference light to generate an interference light, and acquires the spectral intensity distribution of the interference light to execute Fourier transform, thereby imaging the morphology in the depth direction (the z-direction) of the object. The technique of this type is also called Spectral Domain.</p>
<p id="p-0006" num="0005">Furthermore, the device described in Patent Document 1 is provided with a Galvano mirror that scans with a light beam (a signal light), and is thereby configured to form an image of a desired measurement target region of the object. Because this device is configured to scan with the light beam only in one direction (the x-direction) orthogonal to the z-direction, an image formed by this device is a two-dimensional tomographic image in the depth direction (the z-direction) along the scanning direction (the x-direction) of the light beam.</p>
<p id="p-0007" num="0006">Patent Document 2 discloses a technique of scanning with a signal light in the horizontal direction (x-direction) and the vertical direction (y-direction) to form a plurality of two-dimensional tomographic images in the horizontal direction, and acquiring and imaging three-dimensional tomographic information of a measured range based on the tomographic images. As the three-dimensional imaging, for example, a method of arranging and displaying a plurality of tomographic images in the vertical direction (referred to as stack data or the like), and a method of executing a rendering process on a plurality of tomographic images to form a three-dimensional image are considered.</p>
<p id="p-0008" num="0007">Patent Documents 3 and 4 disclose other types of OCT devices. Patent Document 3 describes an OCT device that images the morphology of an object by sweeping the wavelength of light that is irradiated to an object, acquiring the spectral intensity distribution based on an interference light obtained by superposing the reflected lights of the light of the respective wavelengths on the reference light, and executing Fourier transform. Such an OCT device is called a Swept Source type or the like. The Swept Source type is a kind of the Fourier Domain type.</p>
<p id="p-0009" num="0008">Further, Patent Document 4 describes an OCT device that irradiates a light having a predetermined beam diameter to an object and analyzes the components of an interference light obtained by superposing the reflected light and the reference light, thereby forming an image of the object in a cross-section orthogonal to the travelling direction of the light. Such an OCT device is called a full-field type, en-face type or the like.</p>
<p id="p-0010" num="0009">Patent Document 5 discloses a configuration in which the OCT is applied to the ophthalmologic field. Before the OCT device was applied to the ophthalmologic field, a fundus observation apparatus such as a retinal camera had been used (for example, refer to Patent Document 6).</p>
<p id="p-0011" num="0010">Compared to a retinal camera that can only photograph a fundus from the front, a fundus observation apparatus using OCT has a merit that tomographic images and 3-dimensional images of a fundus are obtained. Therefore, contribution to increase of the diagnosis accuracy and early detection of a lesion are expected.</p>
<p id="p-0012" num="0011">The fundus observation apparatus using optical coherence tomography thus occupies an important place in diagnosis and treatment of diseases. However, in reality, eyesight values are currently used in order to determine the necessity of treatment and the presence or absence of its effect.</p>
<p id="p-0013" num="0012">This is due to the fact that the main purpose of treatment is the improvement of eyesight, and the change in the morphology of the fundus (for example, hole shrinkage due to treatment of the macular hole) can be confirmed by the fundus observation apparatus, but it cannot be determined whether or not the change in the morphology results in improvement of eyesight without relying on eyesight measurement.</p>
<p id="p-0014" num="0013">It should be noted that eyesight measurement is an eye examination in which a visual target for measuring eyesight such as a Landolt ring is presented to the subject, commonly carried out using a subjective optometer (see, for example, Patent Document 7).</p>
<heading id="h-0003" level="1">PRIOR ART DOCUMENTS</heading>
<heading id="h-0004" level="1">Patent Documents</heading>
<p id="p-0015" num="0000">
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0014">[Patent Document 1]</li>
</ul>
</p>
<p id="p-0016" num="0015">Japanese Unexamined Patent Application Publication No. Hei 11-325849
<ul id="ul0002" list-style="none">
    <li id="ul0002-0001" num="0016">[Patent Document 2]</li>
</ul>
</p>
<p id="p-0017" num="0017">Japanese Unexamined Patent Application Publication No. 2002-139421
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0018">[Patent Document 3]</li>
</ul>
</p>
<p id="p-0018" num="0019">Japanese Unexamined Patent Application Publication No. 2007-24677
<ul id="ul0004" list-style="none">
    <li id="ul0004-0001" num="0020">[Patent Document 4]</li>
</ul>
</p>
<p id="p-0019" num="0021">Japanese Unexamined Patent Application Publication No. 2006-153838
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0022">[Patent Document 5]</li>
</ul>
</p>
<p id="p-0020" num="0023">Japanese Unexamined Patent Application Publication No. 2008-73099
<ul id="ul0006" list-style="none">
    <li id="ul0006-0001" num="0024">[Patent Document 6]</li>
</ul>
</p>
<p id="p-0021" num="0025">Japanese Unexamined Patent Application Publication No. Hei 9-276232
<ul id="ul0007" list-style="none">
    <li id="ul0007-0001" num="0026">[Patent Document 7]</li>
</ul>
</p>
<p id="p-0022" num="0027">Japanese Unexamined Patent Application Publication No. 2008-148930</p>
<heading id="h-0005" level="1">DISCLOSURE OF THE INVENTION</heading>
<heading id="h-0006" level="1">Problem that the Invention is to Solve</heading>
<p id="p-0023" num="0028">However, with eyesight measurement, it cannot be determined which site of the fundus is used to see the target (i.e., it cannot be determined which site of the fundus is projected with the target), and it cannot be determined if the eyesight value of the treatment sight has actually improved. For example, in a healthy eye, the target is projected on the macula flava due to the target being recognized in the macula flava having the highest visual ability; however, when there is a disorder in the macula flava, the target tends to be captured by a site other than the macula flava, so the eyesight value of the affected site actually cannot always be measured. In such a case, it is preferable that the visual ability be able to be confirmed by conducting eyesight measurement at the site of interest (treatment site, diagnosed site, etc.) of the fundus, while being able to confirm the morphology of the fundus by obtaining an image of the site of interest. However, conventional devices have not been able to obtain an image of the eyesight measurement position. Consequently, for example, it has not been possible to determine whether or not the treatment is actually reflected in improvement of eyesight.</p>
<p id="p-0024" num="0029">Moreover, the viewing angle (size) of the visual target for measuring eyesight projected on the fundus is sometimes changed due to the refractive power (eye refractive power) of the eye, and there has been a problem in that the eyesight value cannot be precisely measured in such a case.</p>
<p id="p-0025" num="0030">Furthermore, it is also conceivable that a conventional fundus observation apparatus is added with a target presenting function, but in such a case the subject has to simultaneously visually confirm the signal light, the fixation target and the visual target for measuring eyesight, increasing the complexity of the examination and possibly causing adverse effects.</p>
<p id="p-0026" num="0031">This invention resolves the above-mentioned problem, with the purpose of providing a fundus observation apparatus capable of obtaining an image at the eyesight measurement site of the fundus.</p>
<heading id="h-0007" level="1">Means for Solving the Problem</heading>
<p id="p-0027" num="0032">In order to achieve the aforementioned objects, an invention according to claim <b>1</b> is a fundus observation apparatus comprising: a projection part that includes a display part to display a visual target for measuring eyesight, and projects, via a predetermined optical path, said displayed visual target for measuring eyesight to the fundus of an eye; a light source that outputs low-coherence light; an optical system that splits said output low-coherence light into signal light and reference light, generates interference light by superposing said signal light that has passed through said fundus via said predetermined optical path and said reference light that has passed through a reference optical path, and detects said interference light; a scanning part that scans said fundus with said signal light; a controlling part that overlaps the projection region of said visual target for measuring eyesight projected by said projection part and the scanning region of said signal light scanned by said scanning part each other; an image forming part that forms an image of said fundus based on the detection results of interference light generated by superposing said signal light with which said scanning region is scanned and said reference light; and a storage part that stores said formed image and an eyesight value measured using said visual target for measuring eyesight while correlating them with each other.</p>
<p id="p-0028" num="0033">Further, an invention according to claim <b>2</b> is the fundus observation apparatus according to Claim <b>1</b>, wherein said controlling part controls said projection part based on the scanning region of said signal light scanned by said scanning part to overlap the projection region of said visual target for measuring eyesight in said fundus on the scanning region of said signal light.</p>
<p id="p-0029" num="0034">Further, an invention according to claim <b>3</b> is the fundus observation apparatus according to Claim <b>2</b>, wherein: said display part displays a fixation target for fixing said eye along with said visual target for measuring eyesight; said projection part projects said displayed fixation target on said fundus along with said visual target for measuring eyesight; and said controlling part changes said projection region by changing, based on said scanning region, the relative display positions of said visual target for measuring eyesight and said fixation target displayed by said display part.</p>
<p id="p-0030" num="0035">Further, an invention according to claim <b>4</b> is the fundus observation apparatus according to Claim <b>1</b>, wherein said controlling part controls said scanning part based on the display position of said visual target for measuring eyesight displayed by said display part to overlap the scanning region of said signal light in said fundus on the projection region of said visual target for measuring eyesight.</p>
<p id="p-0031" num="0036">Further, an invention according to claim <b>5</b> is the fundus observation apparatus according to Claim <b>1</b>, wherein said controlling part allows said visual target for measuring eyesight corresponding to different eyesight values to be projected on said fundus, by allowing said visual target for measuring eyesight of different sizes to be displayed on said display part to change the size of said projection region.</p>
<p id="p-0032" num="0037">Further, an invention according to claim <b>6</b> is the fundus observation apparatus according to Claim <b>5</b>, wherein: said predetermined optical path is provided with a focusing lens that moves along an optical axis thereof to change the focus position of light towards said fundus; and said controlling part adjusts the size of said visual target for measuring eyesight displayed on said display part based on the position of said focusing lens.</p>
<p id="p-0033" num="0038">Further, an invention according to claim <b>7</b> is the fundus observation apparatus according to Claim <b>5</b>, further comprising an operation part for inputting response contents for said visual target for measuring eyesight projected on said fundus, wherein said controlling part changes the size of said visual target for measuring eyesight displayed on said display part based on said input response contents, and determines the eyesight value of said eye based on said response contents according to this change.</p>
<p id="p-0034" num="0039">Further, an invention according to claim <b>8</b> is the fundus observation apparatus according to Claim <b>1</b>, further comprising an operation part for inputting response contents for said visual target for measuring eyesight projected on said fundus, wherein said controlling part controls said projection part to project said visual target for measuring eyesight corresponding to a predetermined eyesight value to said fundus, determines whether said input response contents for this visual target for measuring eyesight are true or false, and if it is determined that they are correct, then controls said scanning part to scan said scanning region overlapping the projection region with said signal light.</p>
<p id="p-0035" num="0040">Further, an invention according to claim <b>9</b> is the fundus observation apparatus according to Claim <b>1</b>, wherein said light source outputs invisible light as said low-coherence light.</p>
<p id="p-0036" num="0041">Further, an invention according to claim <b>10</b> is the fundus observation apparatus according to Claim <b>9</b>, wherein said light source outputs near-infrared light of center wavelength within the range substantially from 1050 to 1060 nm.</p>
<heading id="h-0008" level="1">Effect of the Invention</heading>
<p id="p-0037" num="0042">According to the fundus observation apparatus related to the present invention, an image of the scanning region of the signal light on the fundus can be formed with said scanning region being superposed on the projection region of the visual target for measuring eyesight, and it is possible to measure the eyesight in the projection region and then store the formed image and the measured eyesight value while associating them with each other, allowing an image of the eyesight measurement site of the fundus to be obtained.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0009" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0038" num="0043"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic view showing an example of a configuration of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0039" num="0044"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic view showing an example of a configuration of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0040" num="0045"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic block diagram showing an example of a configuration of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0041" num="0046"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart showing an example of an action of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0042" num="0047"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic view for explaining an example of an action of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0043" num="0048"><figref idref="DRAWINGS">FIG. 6</figref> is a schematic view for explaining an example of an action of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0044" num="0049"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart showing an example of an action of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0045" num="0050"><figref idref="DRAWINGS">FIG. 8</figref> is a schematic view for explaining an example of an action of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0046" num="0051"><figref idref="DRAWINGS">FIG. 9</figref> is a schematic view for explaining an example of an action of an embodiment of a fundus observation apparatus according to the present invention.</p>
<p id="p-0047" num="0052"><figref idref="DRAWINGS">FIG. 10</figref> is a schematic block diagram showing an example of a configuration of a modification example of an embodiment of a fundus observation apparatus according to the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0010" level="1">MODE FOR CARRYING OUT THE INVENTION</heading>
<p id="p-0048" num="0053">An example of an embodiment of a fundus observation apparatus according to the present invention will be described in detail with reference to the drawings.</p>
<p id="p-0049" num="0054">The fundus observation apparatus according to the present invention forms tomographic images of a fundus using optical coherence tomography. Optical coherence tomography of an arbitrary type involving scanning with a signal light such as a Fourier Domain type, a swept source type, etc. are applicable to the fundus observation apparatus. It should be noted that an image obtained by optical coherence tomography is sometimes referred to as an OCT image. Furthermore, a measuring action for forming an OCT image is sometimes referred to as an OCT measurement.</p>
<p id="p-0050" num="0055">In the following embodiments, a configuration to which a Fourier-Domain-type is applied will be described in detail. To be specific, in these embodiments, similar to a device disclosed in Patent Document 5, a fundus observation apparatus that is capable of obtaining both tomographic images and photographed image of a fundus will be picked up.</p>
<p id="h-0011" num="0000">[Configuration]</p>
<p id="p-0051" num="0056">A fundus observation apparatus <b>1</b>, as shown in <figref idref="DRAWINGS">FIG. 1</figref> and <figref idref="DRAWINGS">FIG. 2</figref>, includes a retinal camera unit <b>2</b>, an OCT unit <b>100</b>, and an arithmetic and control unit <b>200</b>. The retinal camera unit <b>2</b> has almost the same optical system as a conventional retinal camera. The OCT unit <b>100</b> is provided with an optical system for obtaining an OCT image of a fundus. The arithmetic and control unit <b>200</b> is provided with a computer that executes various arithmetic processes, control processes, and so on.</p>
<p id="h-0012" num="0000">[Retinal Camera Unit]</p>
<p id="p-0052" num="0057">The retinal camera unit shown in <figref idref="DRAWINGS">FIG. 1</figref> is provided with an optical system for forming a 2-dimensional image (fundus image) representing the surface morphology of the fundus Ef of an eye E. Fundus images include observation images, photographed images, etc. The observation image is, for example, a monochrome image formed at a prescribed frame rate using near-infrared light. The photographed image is, for example, a color image captured by flashing visible light. It should be noted that the retinal camera unit <b>2</b> may also be configured so as to be capable of capturing other types of images such as a fluorescein angiography image or an indocyanine green fluorescent image.</p>
<p id="p-0053" num="0058">The retinal camera unit <b>2</b> is provided with a chin rest and a forehead placement for retaining the face of the subject, similar to a conventional retinal camera. Moreover, like a conventional retinal camera, the retinal camera unit <b>2</b> is provided with an illumination optical system <b>10</b> and an imaging optical system <b>30</b>. The illumination optical system <b>10</b> irradiates an illumination light to the fundus Ef. The imaging optical system <b>30</b> guides a fundus reflected light of the illumination light to imaging devices (CCD image sensors <b>35</b>, <b>38</b>). Moreover, the imaging optical system <b>30</b> guides a signal light LS coming from the OCT unit <b>100</b> to the fundus Ef, and guides the signal light propagated through the fundus Ef to the OCT unit <b>100</b>.</p>
<p id="p-0054" num="0059">An observation light source <b>11</b> of the illumination optical system <b>10</b> comprises, for example, a halogen lamp. Light (observation illumination light) output from the observation light source <b>11</b> is reflected by a reflection mirror <b>12</b> with a curved reflection surface, and becomes near infrared after passing through a visible cut filter <b>14</b> via a condenser lens <b>13</b>. Furthermore, the observation illumination light is once converged near an imaging light source <b>15</b>, reflected by a mirror <b>16</b>, and passes through relay lenses <b>17</b>, <b>18</b>, diaphragm <b>19</b>, and relay lens <b>20</b>. Then, the observation illumination light is reflected on the peripheral part (the surrounding region of an aperture part) of an aperture mirror <b>21</b> and illuminates the fundus Ef via an object lens <b>22</b>.</p>
<p id="p-0055" num="0060">The fundus reflection light of the observation illumination light is refracted by the object lens <b>22</b>, passes through the aperture part formed in the center region of the aperture mirror <b>21</b>, passes through a dichroic mirror <b>55</b> and, travels through a focusing lens <b>31</b>, and is reflected by a dichroic mirror <b>32</b>. Furthermore, the fundus reflection light passes through a half-mirror <b>40</b> and forms an image on the light receiving surface of the CCD image sensor <b>35</b> by a condenser lens <b>34</b> after being reflected by a dichroic mirror <b>33</b>. The CCD image sensor <b>35</b> detects, for example, the fundus reflection light at a prescribed frame rate. An image (observation image) K based on the fundus reflection light detected by the CCD image sensor <b>35</b> is displayed on a display device <b>3</b>.</p>
<p id="p-0056" num="0061">The imaging light source <b>15</b> consists of, for example, a xenon lamp. The light (imaging illumination light) output from the imaging light source <b>15</b> is irradiated to the fundus Ef via a route that is similar to the observation illumination light. The fundus reflection light of the imaging illumination light is guided to the dichroic mirror <b>33</b> via the same route as that of the observation illumination light, passes through the dichroic mirror <b>33</b>, and forms an image on the light receiving surface of the CCD image sensor <b>38</b> by a condenser lens <b>37</b> after being reflected by a mirror <b>36</b>. An image (photographed image) H based on the fundus reflection light detected by the CCD image sensor <b>38</b> is displayed on the display device <b>3</b>. It should be noted that the display device <b>3</b> for displaying an observation image K and the display device <b>3</b> for displaying a photographed image H may be the same or different.</p>
<p id="p-0057" num="0062">An LCD (Liquid Crystal Display) <b>39</b> displays a fixation target or a visual target for measuring eyesight. The fixation target is a visual target for fixing the eye E, and is used when photographing a fundus or forming a tomographic image. The visual target for measuring eyesight is a visual target used for measuring an eyesight value of the eye E, for example, such as Landolt rings. It should be noted that the visual target for measuring eyesight is sometimes simply referred to as a target.</p>
<p id="p-0058" num="0063">Part of the light output from the LCD <b>39</b> is reflected by a half-mirror <b>40</b>, reflected by the dichroic mirror <b>32</b>, passes through the aperture part of the aperture mirror <b>21</b> via the focusing lens <b>31</b> as well as a dichroic mirror <b>55</b>, is refracted by the object lens <b>22</b> and projected to the fundus Ef. LCD <b>39</b> is an example of a &#x201c;display part&#x201d; of the invention. Moreover, LCD <b>39</b> and the above-mentioned group of optical elements that project light output from LCD <b>39</b> on the fundus Ef are a &#x201c;projection part&#x201d; of the invention.</p>
<p id="p-0059" num="0064">By changing a display position of the fixation target on the screen of the LCD <b>140</b>, it is possible to change a fixation position of the eye E. As the fixation position of the eye E, there are a position for acquiring an image centered on the macula of the fundus Ef, a position for acquiring an image centered on the optic papilla, a position for acquiring an image centered on the fundus center between the macula and the optic papilla, and so on, for example, as in conventional retinal cameras.</p>
<p id="p-0060" num="0065">Furthermore, as with conventional fundus cameras, the retinal camera unit <b>2</b> is provided with an alignment optical system <b>50</b> and a focus optical system <b>60</b>. The alignment optical system <b>50</b> generates a target (alignment target) for matching the position (alignment) of the device optical system with respect to the eye E. The focus optical system <b>60</b> generates a target (split target) for matching the focus with respect to the eye Ef.</p>
<p id="p-0061" num="0066">Light (alignment light) output from the LED (Light Emitting Diode) <b>51</b> of the alignment optical system <b>50</b> is reflected by the dichroic mirror <b>55</b> via diaphragms <b>52</b>, <b>53</b> and a relay lens <b>54</b>, passes through the aperture part of the aperture mirror <b>21</b>, and is projected onto the cornea of the eye E by the object lens <b>22</b>.</p>
<p id="p-0062" num="0067">Part of cornea reflection light of the alignment light is transmitted through the dichroic mirror <b>55</b> via the object lens <b>22</b> and the aperture part, passes through the focusing lens <b>31</b>, is reflected by the dichroic mirror <b>32</b>, transmitted through the half-mirror <b>40</b>, reflected by the dichroic mirror <b>33</b>, and projected onto the light receiving surface of the CCD image sensor <b>35</b> by the condenser lens <b>34</b>. An image (alignment target) captured by the CCD image sensor <b>35</b> is displayed on the display device <b>3</b> along with the observation image K. A user conducts alignment by an operation that is the same as conventional fundus cameras. It should be noted that alignment may be performed, by an arithmetic and control unit <b>200</b>, as a result of analyzing the position of the alignment target and moving the optical system.</p>
<p id="p-0063" num="0068">In order to conduct focus adjustment, the reflection surface of a reflection rod <b>67</b> is provided in a slanted position on the light path of the illumination optical system <b>10</b>. Light (focus light) output from an LED <b>61</b> of the focus optical system <b>60</b> passes through a relay lens <b>62</b>, is split into two light fluxes by a split target plate <b>63</b>, passes through a two-hole diaphragm <b>64</b>, is reflected by a mirror <b>65</b>, and is reflected after an image is formed once on the reflection surface of the reflection rod <b>67</b> by a condenser lens <b>66</b>. Furthermore, the focus light is reflected at the aperture mirror <b>21</b> via the relay lens <b>20</b> and an image is formed on the fundus Ef by the object lens <b>22</b>.</p>
<p id="p-0064" num="0069">The fundus reflection light of the focus light passes through the same route as the cornea reflection light of the alignment light and is detected by the CCD image sensor <b>35</b>. A light (split target) captured by the CCD image sensor <b>35</b> is displayed on the display device <b>3</b> along with an observation image K. The arithmetic and control unit <b>200</b>, as in the past, analyzes the position of the split target, and moves the focusing lens <b>31</b> and the focus optical system <b>60</b> for focusing. It should be noted that focusing may be performed manually while visually recognizing the split target.</p>
<p id="p-0065" num="0070">An optical path including a mirror <b>41</b>, collimator lens <b>42</b>, and Galvano mirrors <b>43</b>, <b>44</b> is provided behind the dichroic mirror <b>32</b>. The optical path is connected to the OCT unit <b>100</b>.</p>
<p id="p-0066" num="0071">The Galvano mirror <b>44</b> performs scanning with a signal light LS from the OCT unit <b>100</b> in the x-direction. The Galvano mirror <b>43</b> performs scanning with a signal light LS in the y-direction. Scanning may be performed with the signal light LS in an arbitrary direction in the xy-plane due to the two Galvano mirrors <b>43</b> and <b>44</b>.</p>
<p id="h-0013" num="0000">[OCT Unit]</p>
<p id="p-0067" num="0072">The OCT unit <b>100</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> is provided with an optical system for obtaining a tomographic image of the fundus Ef. The optical system has a similar configuration to a conventional Fourier-Domain-type OCT device. That is to say, the optical system is configured to split a low coherence light into a reference light and a signal light, make the signal light propagated through a fundus and the reference light propagated through a reference optical path interfere with each other to generate an interference light, and detects the spectral components of this interference light. This detection result (detection signal) is transmitted to the arithmetic and control unit <b>200</b>.</p>
<p id="p-0068" num="0073">A light source unit <b>101</b> outputs a low coherence light L<b>0</b>. The low coherence light L<b>0</b> is, for example, light (invisible light) consisting of wavelengths that is impossible to be detected by human eyes. Furthermore, the low coherence light L<b>0</b> is, for example, near-infrared light having the center wavelength of about 1050-1060 nm. The light source unit <b>101</b> is configured to include light output device, such as an SLD (super luminescent diode), SOA (Semiconductor Optical Amplifier) and the like. A light source unit <b>101</b> is an example of a &#x201c;light source&#x201d; of the invention.</p>
<p id="p-0069" num="0074">The low coherence light L<b>0</b> output from the light source unit <b>101</b> is guided to a fiber coupler <b>103</b> by an optical fiber <b>102</b> and split into signal light LS and reference light LR. It should be noted that the fiber coupler <b>103</b> acts both as a means to split light (splitter) as well as a means to synthesize light (coupler), but herein the same is conventionally referred to as a &#x201c;fiber coupler.&#x201d;</p>
<p id="p-0070" num="0075">The signal light LS is guided by the optical fiber <b>104</b> and becomes a parallel light flux by a collimator lens unit <b>105</b>. Furthermore, the signal light LS is reflected by Galvano mirrors <b>44</b> and <b>43</b>, converged by the collimator lens <b>42</b>, reflected by the mirror <b>41</b>, transmitted through a dichroic mirror <b>32</b>, and irradiated to the fundus Ef after passing through a route that is the same as the light from the LCD <b>39</b>. The signal light LS is scattered and reflected at the fundus Ef. The scattered light and the reflection light are sometimes all together referred to as the fundus reflection light of the signal light LS. The fundus reflection light of the signal light LS progresses along the same route in the reverse direction and is guided to the fiber coupler <b>103</b>.</p>
<p id="p-0071" num="0076">The reference light LR is guided by an optical fiber <b>106</b> and becomes a parallel light flux by a collimator lens unit <b>107</b>. Furthermore, the reference light LR is reflected by mirrors <b>108</b>, <b>109</b>, <b>110</b>, dimmed by an ND (Neutral Density) filter <b>111</b>, and reflected by a mirror <b>112</b>, with the image formed on a reflection surface of a reference mirror <b>114</b> by a collimator lens <b>113</b>. The reference light LR reflected by the reference mirror <b>114</b> progresses along the same route in the reverse direction and is guided to the fiber coupler <b>103</b>. It should be noted that an optical element for dispersion compensation (pair prism, etc.) and/or an optical element for polarization correction (wave plate, etc.) may also be provided for the optical path (reference optical path) of the reference light LR.</p>
<p id="p-0072" num="0077">The fiber coupler <b>103</b> superposes the fundus reflection light of the signal light LS and the reference light LR reflected by the reference mirror <b>114</b>. Interference light LC thus generated is guided by an optical fiber <b>115</b> and output from an exit end <b>116</b>. Furthermore, the interference light LC is converted to a parallel light flux by a collimator lens <b>117</b>, spectrally divided (spectrally decomposed) by a diffraction grating <b>118</b>, converged by the convergence lens <b>119</b>, and projected onto the light receiving surface of a CCD image sensor <b>120</b>.</p>
<p id="p-0073" num="0078">The CCD image sensor <b>120</b> is for example a line sensor, and detects the respective spectral components of the spectrally decomposed interference light LC and converts the components into electric charges. The CCD image sensor <b>120</b> accumulates these electric charges and generates a detection signal. Furthermore, the CCD image sensor <b>120</b> transmits the detection signal to the arithmetic and control unit <b>200</b>.</p>
<p id="p-0074" num="0079">Although a Michelson-type interferometer is employed in this embodiment, it is possible to employ any type of interferometer such as a Mach-Zehnder-type as necessary. Instead of a CCD image sensor, other types of image sensors, such as a CMOS (Complementary Metal Oxide Semiconductor) image sensor, can be used.</p>
<p id="h-0014" num="0000">[Arithmetic and Control Unit]</p>
<p id="p-0075" num="0080">A configuration of the arithmetic and control unit <b>200</b> will be described. The arithmetic and control unit <b>200</b> analyzes the detection signals inputted from the CCD image sensor <b>120</b>, and forms an OCT image of the fundus Ef. An arithmetic process for this is the same as that of a conventional Fourier-Domain-type OCT device.</p>
<p id="p-0076" num="0081">Further, the arithmetic and control unit <b>200</b> controls each part of the retinal camera unit <b>2</b>, the display device <b>3</b> and the OCT unit <b>100</b>.</p>
<p id="p-0077" num="0082">As control of the retinal camera unit <b>2</b>, the arithmetic and control unit <b>200</b> executes: control of action of the observation light source <b>101</b>, the imaging light source <b>103</b> and LED's <b>51</b> and <b>61</b>; control of action of the LCD <b>39</b>; control of movement of the focusing lens <b>31</b>; control of movement of the reflection rod <b>67</b>; control of movement of the focus optical system <b>60</b>; control of action of the respective Galvano mirrors <b>43</b> and <b>44</b>; and so on.</p>
<p id="p-0078" num="0083">Further, as control of the OCT unit <b>100</b>, the arithmetic and control unit <b>200</b> executes: control of action of the light source unit <b>101</b>; control of movement of the reference mirror <b>114</b> and the collimator lens <b>113</b>; control of action of the CCD image sensor <b>120</b>; and so on.</p>
<p id="p-0079" num="0084">The arithmetic and control unit <b>200</b> includes a microprocessor, a RAM, a ROM, a hard disk drive, a communication interface, and so on, as in conventional computers. The storage device such as the hard disk drive stores a computer program for controlling the fundus observation apparatus <b>1</b>. The arithmetic and control unit <b>200</b> may be provided with a circuit board dedicated for forming OCT images based on detection signals from the CCD image sensor <b>120</b>. Moreover, the arithmetic and control unit <b>200</b> may be provided with operation devices (input devices) such as a keyboard and a mouse, and/or display devices such as LCD.</p>
<p id="p-0080" num="0085">The retinal camera unit <b>2</b>, display device <b>3</b>, OCT unit <b>100</b>, and arithmetic and control unit <b>200</b> may be integrally configured (that is, within a single case), or configured as separate bodies.</p>
<p id="h-0015" num="0000">[Input Device]</p>
<p id="p-0081" num="0086">The input device <b>300</b> is used in order for the subject to respond during the eyesight measurement. In the eyesight measurement, a predetermined visual target for measuring eyesight is projected onto the eye E. The subject inputs the result of visual confirmation of this target using the input device <b>300</b>. For example, when a Landolt ring is used as a target, the subject inputs the direction of the rift in the Landolt ring using the input device <b>300</b>.</p>
<p id="p-0082" num="0087">The input device <b>300</b> is configured, for example, to include a joy stick such as the one shown in <figref idref="DRAWINGS">FIG. 3</figref>. The subject tilts the joystick in the direction corresponding to the result of visual confirmation to the target. The input device <b>300</b> transmits an electrical signal corresponding to this operation content (tilting direction) to the arithmetic control unit <b>200</b>. The input device <b>300</b> is one example of the &#x201c;operation part&#x201d; of the invention.</p>
<p id="h-0016" num="0000">[Control System]</p>
<p id="p-0083" num="0088">A configuration of a control system of the fundus observation apparatus <b>1</b> will be described with reference to <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="h-0017" num="0000">(Controller)</p>
<p id="p-0084" num="0089">The control system of the fundus observation apparatus <b>1</b> has a configuration centered on a controller <b>210</b> of the arithmetic and control unit <b>200</b>. The controller <b>210</b> includes, for example, the aforementioned microprocessor, RAM, ROM, hard disk drive, and communication interface. The controller <b>210</b> is an example of a &#x201c;controlling part&#x201d; of the invention.</p>
<p id="p-0085" num="0090">A controller <b>210</b> is provided with a main controller <b>211</b>, storage <b>212</b> and a target setting part <b>214</b>. The main controller <b>211</b> performs the aforementioned various kinds of control. Specifically, the main controller <b>211</b> controls a scan driver <b>70</b> as well as a focus driver <b>80</b> of the retinal camera unit <b>2</b>, and further controls a reference driver <b>130</b> of the OCT unit <b>100</b>.</p>
<p id="p-0086" num="0091">The scan driver <b>70</b> is configured, for example, including a servo motor and independently changes the facing direction of the Galvano mirrors <b>43</b> and <b>44</b>. The scan driver <b>70</b> consists of one example of the &#x201c;scanning part&#x201d; in the invention along with the Galvano mirrors <b>43</b> and <b>44</b>.</p>
<p id="p-0087" num="0092">The focus driver <b>80</b> is configured, for example, including a pulse motor and moves the focusing lens <b>31</b> in the optical axis direction. Thereby, the focus position of light towards the fundus Ef is changed.</p>
<p id="p-0088" num="0093">The reference driver <b>130</b> is configured, for example, including a pulse motor and integrally moves the collimator lens <b>113</b> as well as the reference mirror <b>114</b> along the travelling direction of the reference light LR.</p>
<p id="p-0089" num="0094">The main controller <b>211</b> executes a process of writing data into the storage <b>212</b>, and a process of reading out the data from the storage <b>212</b>.</p>
<p id="p-0090" num="0095">The storage <b>212</b> stores various kinds of data. The data stored in the storage <b>212</b> is, for example, image data of OCT images, image data of fundus images, and eye information. The eye information includes information on the eye, for example, information on a subject such as a patient ID and a name, information on identification of left eye or right eye, and so on.</p>
<p id="p-0091" num="0096">Moreover, the eyesight value of the eye E measured by the fundus observation apparatus <b>1</b> is stored in the storage <b>212</b>. Although the details will be described later, this eyesight value is stored in correlation with the OCT image. The storage <b>212</b> is one example of the &#x201c;storage part&#x201d; of the invention.</p>
<p id="p-0092" num="0097">It should be noted that the storage part is not limited to storage devices such as hard disk drives and RAM, and may be any recording media writable by a drive device. As this recording media, for example, optical disks, magnetic optical disks (such as CD-R/DVD-RAM/MO), magnetic recording media (such as Floppy Disks&#xae;/ZIP), SSDs (Solid State Drives), etc. may also be used.</p>
<p id="p-0093" num="0098">Moreover, OCT images and eyesight values may be transmitted to the predetermined storage part to be stored via a network such as the Internet and LAN. Furthermore, it is not necessary to store OCT images and eyesight values in the same storage device, and they may be stored in separate storage devices. It should be noted that also in this case, the OCT images and the eyesight values must be correlated with each other.</p>
<p id="p-0094" num="0099">Furthermore, target size adjustment information <b>213</b> is preliminarily stored in the storage <b>212</b>. The target size adjustment information <b>213</b> includes the information that associates the position of the focusing lens <b>31</b> with the target size. Hereinafter, the target size adjustment information <b>213</b> is described in detail.</p>
<p id="p-0095" num="0100">In this embodiment, eyesight measurement is conducted on the eye E by projecting the visual target for measuring eyesight displayed on the LCD <b>39</b> to the fundus Ef. The eyesight examination is for determining the eyesight values based on the target size that can be visually confirmed. (As a specific example, the eyesight values are determined by presenting various sizes of Landolt rings to the eye E, obtaining a response regarding the direction of the rift in the presented Landolt ring, and then determining whether the response is true or false.)</p>
<p id="p-0096" num="0101">However, in the configuration in which the target displayed on the LCD <b>39</b> is projected on the fundus Ef, even if the size of the target displayed on the LCD <b>39</b> is the same, the size of the image projected on the fundus Ef may be different due to the eye refractive power of the eye E. Consequently, the accuracy of the eyesight examination is lowered.</p>
<p id="p-0097" num="0102">The target adjustment information <b>213</b> is referenced in order to avoid a decrease in measurement accuracy due to such a difference in eye refractive power. In this embodiment, as described above, focusing of the optical system on the fundus Ef is accomplished by projecting a split target on the fundus Ef using the focus optical system <b>60</b> and moving the focusing lens <b>31</b> and the focus optical system <b>60</b> based on the position of the split target. The position of the split target is affected by the eye refractive power of the eye E, i.e., the refractive power of the cornea and the lens.</p>
<p id="p-0098" num="0103">The target size adjustment information <b>213</b> includes, as information for making the projection size of the visual target for measuring eyesight onto the fundus independent of the eye refractive power, information that correlates the position of the focusing lens <b>31</b> and the size of the visual target for measuring eyesight. For example, information correlating, for the target at each eyesight value, the position of the focusing lens <b>31</b> and the display size of the target on the LCD <b>39</b> is recorded in the target size adjustment information <b>213</b>. This information is in the form of a table, graph, mathematical expression, etc.</p>
<p id="p-0099" num="0104">This information may be created by, for example, a numerical simulation such as a ray trace. Moreover, this information may also be created by actually performing a measurement using an eye model, an eye on a living body or an isolated eye.</p>
<p id="p-0100" num="0105">It should be noted that the information recorded in the target size adjustment information <b>213</b> is not limited to the above. For example, each position of the focusing lens <b>31</b> may be correlated with the display size of the target for each eyesight value.</p>
<p id="p-0101" num="0106">Moreover, the information recorded in the target size adjustment information <b>213</b> may be information that correlates the position of the focus optical system <b>60</b> and the target size. Here, the focus optical system <b>60</b> and the focusing lens <b>31</b> are moved in conjunction with each other, with the position of the focus optical system <b>60</b> having a one-on-one correspondence with the position of the focusing lens <b>31</b>. Therefore, this modification example can be considered equivalent to the case in which the position of the focusing lens <b>31</b> and the target size are correlated.</p>
<p id="p-0102" num="0107">Moreover, the information recorded in the target size adjustment information <b>213</b> may be the information that correlates the eye refractive power value and the target size. In this case, the eye refractive power value of the eye E that is previously acquired is input, and the target size is adjusted based on the input value. Here, since the eye refractive power value corresponds one-on-one with the position of the focusing lens <b>31</b> (at least theoretically), this modification example can also be considered equivalent to the case in which the position of the focusing lens <b>31</b> and the target size are correlated.</p>
<p id="p-0103" num="0108">The target setting part <b>214</b> executes various setting processes regarding the target projected on the eye E, such as a visual target for measuring eyesight and a fixation target. The target setting part <b>214</b> is provided with a target size setting part <b>215</b>, a fixation target setting part <b>216</b> and an eyesight value determination part <b>217</b>.</p>
<p id="p-0104" num="0109">The target size setting part <b>215</b> acquires the position information of the focusing lens <b>31</b> and obtains the size of the visual target for measuring eyesight based on the position information and the target size adjustment information <b>213</b>.</p>
<p id="p-0105" num="0110">An example of a process for acquiring the position information of the focusing lens <b>31</b> is described. The focusing lens <b>31</b> is, as described above, moved by the focus drive <b>80</b> based on the control by the main controller <b>211</b>. Consequently, based on the control content (control history) by the main controller <b>211</b>, the position information of the focusing lens <b>31</b> can be acquired. More specifically, when the focus drive <b>80</b> includes a pulse motor, the position information of the focusing lens <b>31</b> can be acquired with reference to the pulse number transmitted from the main controller <b>211</b> to the focus drive <b>80</b>. Moreover, it is also possible to use a detector (for example, a potentiometer) that detects the position of the focusing lens <b>31</b>.</p>
<p id="p-0106" num="0111">Upon acquisition of the position information of the focusing lens <b>31</b>, the target size setting part <b>215</b> obtains the target size corresponding to that position information with reference to the target size adjustment information <b>213</b>.</p>
<p id="p-0107" num="0112">The fixation target setting part <b>216</b> performs setting regarding the fixation target displayed on the LCD <b>39</b>. Specifically, the fixation target setting part <b>216</b> sets the display position of the fixation target on the LCD <b>39</b>. For example, the fixation target setting part <b>216</b> sets the display position of the fixation target on the LCD <b>39</b> based on the region for scanning with signal light LS (scanning region; described later) using Galvano mirrors <b>43</b>, <b>44</b>. The operational example of the fixation target setting part <b>216</b> will be described later.</p>
<p id="p-0108" num="0113">The eyesight value determination part <b>217</b> executes various processes for obtaining the eyesight value of the eye E. As these processes, for example, conventional approaches are applicable in which the visual targets for measuring eyesight corresponding to various eyesight values are automatically switched to be presented to the eye. (For example, see republished No. 03/041571.) Hereinafter, an operational example of the eyesight value determination part <b>217</b> is described.</p>
<p id="p-0109" num="0114">First, the eyesight value determination part <b>217</b> determines the visual target for measuring eyesight to be first presented to the eye E. As a target to be first presented, a target corresponding to the predetermined eyesight value is selected. This first target is a target corresponding to, for example, the eyesight value 0.1.</p>
<p id="p-0110" num="0115">Moreover, when previously measured eyesight values can be acquired for this eye E, the first target can be determined based on this information. For example, when the previously obtained eyesight value for the above eye E is 0.7, a target corresponding to an eyesight value lower than that value (for example, 0.5) by a predetermined value is selected as the first target.</p>
<p id="p-0111" num="0116">Previous eyesight values may be input using, for example, the operation part <b>250</b>, or may be obtained from, for example, an electronic medical record system through, for example, LAN. Moreover, previous eyesight values can be correlated to the above-mentioned information on the eye and stored in the storage <b>212</b>. In addition, the previous eyesight value referenced in this examination is preferably the newest among the previously measured eyesight values. When the previous eyesight value is obtained from the electric medical record system, it is possible to selectively obtain the newest eyesight value with reference to the medical examination date recorded in the electric medical records.</p>
<p id="p-0112" num="0117">Furthermore, the eyesight value determination part <b>217</b> determines the target to be presented next, based on the response to the target presented to the eye E from the subject. For this process, for example, the same process as the conventional process can be used. For example, if a correct answer is obtained twice for targets with a certain eyesight value, then a target with the next higher eyesight value is selected. In contrast, if a wrong answer is obtained twice for targets with a certain eyesight value, then a target with the next lower eyesight value is selected.</p>
<p id="p-0113" num="0118">Furthermore, the eyesight value determination part <b>217</b> determines the eyesight value of the eye E based on the response content from the subject according to the change in the target size. This process is, for example, executed similarly to the conventional process. For example, if a correct answer is obtained twice for targets with a certain eyesight value, and a wrong answer is obtained twice for targets with a next higher eyesight value, then the former certain eyesight value is determined as the eyesight value for the eye E. Moreover, if a correct answer is obtained twice for targets at the highest presentable eyesight value (for example, 2.0), that highest eyesight value is determined as the eyesight value for the eye E. Furthermore, if a wrong answer is obtained twice for targets with the lowest presentable eyesight value (for example, 0.1), the result is that the eyesight value is unmeasurable or less than a predetermined value.</p>
<p id="p-0114" num="0119">The target setting part <b>214</b> may be configured such that it can set the display position of the visual target for measuring eyesight on the LCD <b>39</b>.</p>
<p id="h-0018" num="0000">(Image Forming Part)</p>
<p id="p-0115" num="0120">An image forming part <b>220</b> forms image data of a tomographic image of the fundus Ef based on the detection signals from the CCD image sensor <b>120</b>. Like the conventional Fourier-Domain OCT, this process includes processes such as noise elimination (noise reduction), filtering, and FFT (Fast Fourier Transform).</p>
<p id="p-0116" num="0121">The image forming part <b>220</b> includes, for example, the aforementioned circuit board and communication interface. It should be noted that &#x201c;image data&#x201d; and the &#x201c;image&#x201d; presented based on the image data may be identified with each other in this specification.</p>
<p id="h-0019" num="0000">(Image Processor)</p>
<p id="p-0117" num="0122">An image processor <b>230</b> executes various image processing and analysis on images formed by the image forming part <b>220</b>. For example, the image processor <b>230</b> executes various correction processes such as luminance correction and dispersion correction of images.</p>
<p id="p-0118" num="0123">Further, the image processor <b>230</b> executes, for example, an interpolation process of interpolating pixels between tomographic images formed by the image forming part <b>220</b>, thereby forming image data of a three-dimensional image of the fundus Ef.</p>
<p id="p-0119" num="0124">Image data of a three-dimensional image refers to image data that the positions of pixels are defined by the three-dimensional coordinates. The image data of a three-dimensional image is, for example, image data composed of three-dimensionally arranged voxels. This image data is referred to as volume data, voxel data, or the like. For displaying an image based on the volume data, the image processor <b>230</b> executes a rendering process (such as volume rendering and MIP (Maximum Intensity Projection)) on this volume data, and forms image data of a pseudo three-dimensional image taken from a specific view direction. On a display device such as the display <b>240</b>, this pseudo three-dimensional image is displayed.</p>
<p id="p-0120" num="0125">Further, it is also possible to form stack data of a plurality of tomographic images as the image data of a three-dimensional image. Stack data is image data obtained by three-dimensionally arranging a plurality of tomographic images obtained along a plurality of scanning lines, based on the positional relation of the scanning lines. That is to say, stack data is image data obtained by expressing a plurality of tomographic images defined by originally individual two-dimensional coordinate systems by a three-dimensional coordinate system (namely, embedding into a three-dimensional space).</p>
<p id="p-0121" num="0126">The image processor <b>230</b> includes, for example, the aforementioned microprocessor, RAM, ROM, hard disk drive, circuit board, and so on.</p>
<p id="p-0122" num="0127">The image forming part <b>220</b> (and the image processor <b>230</b>) is an example of the &#x201c;image forming part&#x201d; of the invention.</p>
<p id="h-0020" num="0000">(Display and Operation Part)</p>
<p id="p-0123" num="0128">The display <b>240</b> is configured including a display device of the aforementioned arithmetic and control unit <b>200</b>. The operation part <b>250</b> is configured including an operation device of the aforementioned arithmetic and control unit <b>200</b>. Furthermore, the operation part <b>250</b> may also include various kinds of buttons or keys provided with the case of the fundus observation apparatus <b>1</b> or its outside. For example, if the retinal camera unit <b>2</b> has a case that is the same as conventional fundus cameras, a joy stick, operation panel, etc. provided with the case may also be included in the operation part <b>250</b>. Furthermore, the display <b>240</b> may also include various display devices such as a touch panel monitor, etc. provided with the case of the retinal camera unit <b>2</b>.</p>
<p id="p-0124" num="0129">The display <b>240</b> and the operation part <b>250</b> do not need to be composed as separate devices. For example, like a touch panel LCD, a device in which the display function and the operation function are integrated can be used.</p>
<p id="h-0021" num="0000">[Scan with Signal Light and OCT Image]</p>
<p id="p-0125" num="0130">A scan with the signal light LS and an OCT image will be described.</p>
<p id="p-0126" num="0131">The scan aspect of the signal light LS by the fundus observation apparatus <b>1</b> is, for example, a horizontal scan, vertical scan, cruciform scan, radial scan, circular scan, concentric scan, and helical scan. These scan aspects are selectively used as necessary in consideration of an observation site of the fundus, an analysis target (the retinal thickness or the like), a time required to scan, the accuracy of a scan, and so on.</p>
<p id="p-0127" num="0132">A horizontal scan is a scan with the signal light LS in the horizontal direction (x-direction). The horizontal scan includes an aspect of scanning with the signal light LS along a plurality of scanning lines extending in the horizontal direction arranged in the vertical direction (y-direction). In this aspect, it is possible to set any interval between scanning lines. By setting the interval between adjacent scanning lines to be sufficiently narrow, it is possible to form the aforementioned three-dimensional image (three-dimensional scan). A vertical scan is also performed in a similar manner.</p>
<p id="p-0128" num="0133">A cruciform scan is a scan with the signal light LS along a cross-shape trajectory formed by two linear trajectories (line trajectories) orthogonal to each other. A radial scan is a scan with the signal light LS along a radial trajectory formed by a plurality of line trajectories arranged at predetermined angles. The cruciform scan is an example of the radial scan.</p>
<p id="p-0129" num="0134">A circular scan is a scan with the signal light LS along a circular trajectory. A concentric scan is a scan with the signal light LS along a plurality of circular trajectories arranged concentrically around a predetermined center position. The circular scan is regarded as a special example of the concentric scan. A helical scan is a scan with the signal light LS along a helical trajectory while making the turning radius gradually smaller (or greater).</p>
<p id="p-0130" num="0135">With the configuration as described before, the Galvano mirrors <b>43</b> and <b>44</b> are capable of scanning with the signal light LS in the x-direction and the y-direction independently, and is therefore capable of scanning with the signal light LS along an arbitrary trajectory on the xy-plane. Thus, it is possible to realize various types of scan aspects as described above.</p>
<p id="p-0131" num="0136">By scanning the signal light LS in the mode described above, it is possible to form tomographic images of the depthwise direction (z-direction) along scanning lines (scan trajectory). Moreover, in a case that the interval between scanning lines is narrow, it is possible to form the aforementioned three-dimensional image.</p>
<p id="p-0132" num="0137">A region on the fundus Ef subjected to scanning by the signal light LS as above is referred to as a scanning region. For example, a scanning region in three-dimensional scanning is a rectangular-shaped region in which a plurality of horizontal scans are arranged. Furthermore, a scanning region in a concentric circular scan is a disc-shaped region surrounded by the trajectories of a circular scan of a maximum diameter. Moreover, the scanning region in a radial scan is a disc-shaped (or polygonal-shaped) region linking end positions of scanning lines.</p>
<p id="h-0022" num="0000">[Operation]</p>
<p id="p-0133" num="0138">The operation of the fundus observation apparatus <b>1</b> is described. The flow chart shown in <figref idref="DRAWINGS">FIG. 4</figref> represents an example of the operation of the fundus observation apparatus <b>1</b>.</p>
<p id="p-0134" num="0139">First, as in the conventional manner, the main controller <b>211</b> controls, for example, the alignment optical system <b>50</b> to perform alignment to the eye E, and also controls, for example, the focus optical system <b>60</b>, the focus drive <b>80</b>, etc., to perform focusing on the fundus Ef (S<b>1</b>).</p>
<p id="p-0135" num="0140">Next, the main controller <b>211</b> adjusts the position of the reference mirror <b>114</b> (as well as the position of the collimator lens <b>113</b>) to adjust the interference state of the signal light LS and the reference light LR (S<b>2</b>). At this time, adjustment is made so that the image of the desired depthwise position of the fundus Ef becomes clear. Moreover, it is desirable to adjust the position of the reference mirror <b>114</b> so that the image of the predetermined depthwise position (for example, the retina surface) is located within a predetermined range in the frame. It should be noted that the position adjustment of the reference mirror <b>114</b> may be manually performed using the operation part <b>250</b> or may be automatically performed.</p>
<p id="p-0136" num="0141">Upon completion of the adjustment of the interference state, the fixation target setting part <b>216</b> sets the display position of the fixation target on the LCD <b>39</b> corresponding to the predetermined scanning region (for example, a rectangular region for three-dimensional scanning) (S<b>3</b>). It should be noted that the scanning region is set, for example, before or after step <b>1</b>.</p>
<p id="p-0137" num="0142">Furthermore, the fixation target setting part <b>215</b> adjusts the size of the visual target for measuring eyesight based on the position of the focusing lens <b>31</b>, which is moved during focusing in step <b>1</b>, and the target size adjustment information <b>213</b> (S<b>4</b>).</p>
<p id="p-0138" num="0143">The main controller <b>211</b> controls the LCD <b>39</b> to display the fixation target in the display position set in step <b>3</b> and fixate the eye E (S<b>5</b>). Furthermore, the main controller <b>211</b> allows the first visual target for measuring eyesight, of which the size has been adjusted in step <b>4</b>, to be displayed on the LCD <b>39</b>, and begins the eyesight measurement (S<b>6</b>). This eyesight measurement is for measuring the eyesight at the position on the fundus Ef (i.e., projection position of the fixation target) corresponding to this fixation position.</p>
<p id="p-0139" num="0144">In this operational example, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, the fixation target V is displayed in the central position of the display screen of the LCD <b>39</b>, and the Landolt ring T is displayed such that the central position of the Landolt ring T matches the position of the fixation target V.</p>
<p id="p-0140" num="0145">At the same time as the start of the eyesight examination, the main controller <b>211</b> controls the light source unit <b>101</b> and the Galvano mirrors <b>43</b> and <b>44</b> to begin the measurement in the predetermined scanning region (for example, three-dimensional scanning) (S<b>7</b>).</p>
<p id="p-0141" num="0146">The positional relationship between the scanning region of the signal light LS and the target projection region on the fundus Ef is shown in <figref idref="DRAWINGS">FIG. 6</figref>. In this operational example, as in the <figref idref="DRAWINGS">FIG. 5</figref>, the fixation target V is projected on the central position of the projection region of the Landolt ring T, and furthermore, the projection region of the fixation target V is matched to the central position of the scanning region R (rectangular region). It should be noted that the fixation target displayed on the LCD <b>39</b> and the projected image of this fixation target on the fundus Ef are denoted by the same symbol V, and the Landolt ring displayed on the LCD <b>39</b> and the projected image of this Landolt ring on the fundus Ef are denoted by the same symbol T.</p>
<p id="p-0142" num="0147">Such a projection mode is achieved, for example, as follows. First, the central position of the display screen of the LCD <b>39</b> is placed on an optical axis of the imaging optical system <b>30</b>. Moreover, the scanning region R is set such that its central position is located on the optical axis of the imaging optical system <b>30</b>. Therefore, by displaying the fixation target V in the central position of the display screen of the LCD <b>39</b> and setting this scanning region R as such, the central position of the scanning region R is matched to the projection region of the fixation target V (i.e., both are placed on the extended line of the optical axis). Furthermore, since the Landolt ring T is displayed on the LCD <b>39</b> such that its central position is placed in the central position of the display screen, the central position of the Landolt ring T, the projection region of the fixation target V and the central position of the scanning region R are matched on the fundus Ef.</p>
<p id="p-0143" num="0148">The controller <b>210</b> executes the eyesight measurement at the position of the fundus Ef projected with the fixation target V while scanning the scanning region R with the signal light LS. At this time, the signal light LS is used to sequentially scan a plurality of lines of horizontal scanning (scanning lines) included in the three-dimensional scanning. Then, the image forming part <b>220</b> forms a tomographic image corresponding to each scanning line based on the detection results of interference light LC of the signal light LS and the reference light LR (S<b>8</b>). Tomographic images that are formed sequentially are stored in the storage <b>212</b> while being correlated with position information of corresponding scanning line (scanning position information). The scanning position information is, for example, information based on the control to the scan drive <b>70</b> (i.e., the direction of the Galvano mirrors <b>43</b>, <b>44</b>). When the scanning along all scanning lines is completed, the scanning may be ended or similar scanning may be executed again. Here, the eyesight measurement is executed by the eyesight value determination part <b>217</b> in the manner described above.</p>
<p id="p-0144" num="0149">When the eyesight value is obtained by the eyesight value determination part <b>217</b> (S<b>9</b>), the main controller <b>211</b> selects a tomographic image corresponding to the scanning line closest to the eyesight measurement position (the position projected with the fixation target V) (S<b>10</b>), and stores this tomographic image and the eyesight value in the storage <b>212</b> while correlating them with each other (S<b>11</b>). Here, the selection process of the tomographic image is executed with reference to the above-mentioned scanning position information.</p>
<p id="p-0145" num="0150">The main controller <b>211</b> allows the tomographic image and the eyesight value to be displayed on the display device <b>3</b> (or the display <b>240</b>) (S<b>12</b>). Consequently, the examiner can observe the tomographic image of the fundus Ef at the eyesight measurement position.</p>
<p id="p-0146" num="0151">In this operational example, examination at the fixation position is conducted as described above. Therefore, for the eye E that has no disorder in the macula flava (including a healthy eye), the eyesight value and the tomographic image in the macula flava are generally obtained. On the other hand, for the eye E that has, for example, a disorder in the macula flava, the fixation target V tends to be viewed by the site having the highest visual ability in the fundus Ef (other than the macula flava), so the eyesight value and the tomographic image in such a site are generally obtained.</p>
<p id="p-0147" num="0152">Instead of conducting an examination on the fixation position in this way, it is also possible to conduct an examination on the site of interest (treatment site, diagnosed site, etc.) other than the fixation position. To this end, as described in detail in the following operational example, it is effective to conduct an examination under the condition that the display position of the fixation target V is shifted from the display position of the visual target for measuring eyesight on the LCD <b>39</b>.</p>
<p id="h-0023" num="0000">[Another Operational Example]</p>
<p id="p-0148" num="0153">In this operational example, eyesight measurement is conducted on various positions in the fundus Ef by changing the relative position of the projection region of the visual target for measuring eyesight and the projection region of the fixation target, and furthermore, a tomographic image covering the eyesight measurement position is obtained. Hereinafter, the operational example shown in the flowchart shown in <figref idref="DRAWINGS">FIG. 7</figref> is described.</p>
<p id="p-0149" num="0154">As a preliminary stage of the examination, as in the operational example described above, the alignment, focusing, determination of the scanning region, and adjustment of the interference state are performed (S<b>21</b>).</p>
<p id="p-0150" num="0155">The fixation target setting part <b>216</b> sets the display position of the fixation target on the LCD <b>39</b> corresponding to the scanning region (for example, a rectangular region for three-dimensional scanning) (S<b>22</b>). Moreover, the target setting part <b>214</b> sets the display position of the visual target for measuring eyesight on the LCD <b>39</b> (S<b>23</b>). Furthermore, the target size setting part <b>215</b> adjusts the size of the visual target for measuring eyesight based on the position of the focusing lens <b>31</b> after focusing and the target size adjustment information <b>213</b> (S<b>24</b>).</p>
<p id="p-0151" num="0156">It should be noted that, in this operational example, as opposed to the case shown in <figref idref="DRAWINGS">FIG. 5</figref>, it is not necessary to display the fixation target on the central position of the display screen, and furthermore, it is not necessary to match the central position of the visual target for measuring eyesight to the position of the fixation target. For example, as shown in <figref idref="DRAWINGS">FIG. 8</figref>, the fixation target V is displayed in a position deviating from the central position of the display screen of the LCD <b>39</b>, and the Landolt ring T is displayed with its central position deviating from the position of the fixation target V. It should be noted that, in the example shown in <figref idref="DRAWINGS">FIG. 8</figref>, the display positions of the fixation target V and the Landolt ring T both deviate from the central position of the display screen, but one of these positions may be displayed in this central position while the other is displayed in other positions.</p>
<p id="p-0152" num="0157">The important point here is that the fixation target V and the Landolt ring T are displayed in different positions. Specifically, when the fixation target V and the Landolt ring T are displayed in different positions, on the assumption that the eye E is fixed by the fixation target V, the eyesight in the position on the fundus Ef that is different from the fixation position can be measured. (In the above operational example, the eyesight in the fixation position is measured.) Moreover, by changing the relative position of the fixation target V and the Landolt ring T, eyesight in various positions on the fundus Ef can be measured.</p>
<p id="p-0153" num="0158">The main controller <b>211</b> controls the LCD <b>39</b> to display the fixation target in the display position set in step <b>22</b> and fix the eye E (S<b>25</b>). Furthermore, the main controller <b>211</b> controls the LCD <b>39</b> to display the first visual target for measuring eyesight in the display position set in step <b>23</b>, and begins the eyesight measurement (S<b>26</b>).</p>
<p id="p-0154" num="0159">At the same time as the start of the eyesight measurement, the main controller <b>211</b> begins the measurement in the scanning region (for example, three-dimensional scanning) (S<b>27</b>).</p>
<p id="p-0155" num="0160">The positional relationship between the scanning region of the signal light LS and the target projection region on the fundus Ef is shown in <figref idref="DRAWINGS">FIG. 9</figref>. In this operational example, as in <figref idref="DRAWINGS">FIG. 8</figref>, the fixation target V and the Landolt ring T are projected at different positions. Moreover, as in the operational example described above (<figref idref="DRAWINGS">FIG. 6</figref>), the scanning region R is set such that its central position is located on the optical axis of the imaging optical system <b>30</b>. Consequently, the fixation target V and the Landolt ring T are projected at a position different from the central position of the scanning region R. It should be noted that, as described above, when the fixation target V or the Landolt ring T is displayed at the central position of the display screen of the LCD <b>39</b>, the target displayed at this central position is projected at the central position of the scanning region R.</p>
<p id="p-0156" num="0161">The controller <b>210</b> executes the eyesight measurement on the position of the fundus Ef projected with the Landolt ring T while scanning the scanning region R with the signal light LS. At this time, the signal light LS is used to sequentially scan a plurality of scanning lines included in the three-dimensional scanning. The image forming part <b>220</b> forms a tomographic image corresponding to each scanning line (S<b>28</b>). Tomographic images that are formed sequentially are stored in the storage <b>212</b> while being correlated with the scanning position information. The scanning position information is, for example, information based on the control to the scan drive <b>70</b> (i.e., the direction of the Galvano mirrors <b>43</b>, <b>44</b>). When the scanning along all scanning lines is completed, the scanning may be ended or similar scanning may be executed again. Here, the eyesight measurement is executed by the eyesight value determination part <b>217</b> in the manner described above.</p>
<p id="p-0157" num="0162">When the eyesight value of this measurement position is obtained (S<b>29</b>), the main controller <b>211</b> selects a tomographic image corresponding to the scanning line closest to the eyesight measurement position (S<b>30</b>), and stores the measurement position, the tomographic image and the eyesight value in the storage <b>212</b> while correlating them with each other (S<b>31</b>). Here, the correlation of the tomographic image and the eyesight value can be achieved similarly to the above operational example. Moreover, the measurement position can be determined based on, for example, the relative position of the fixation target V and the Landolt ring T (the relative position of both display positions).</p>
<p id="p-0158" num="0163">If the examination is not completed at all the measurement positions (S<b>32</b>: No), the target setting part <b>214</b> sets the display positions of the fixation target V and the Landolt ring T on the LCD <b>39</b> corresponding to the next measurement position. The main controller <b>211</b> allows the fixation target V and the Landolt ring T to be displayed at the set display positions. Consequently, each projection region of the fixation target V and the Landolt ring T on the fundus Ef is changed. Under the condition that the eye E is fixed by this fixation target V, the Landolt ring T is projected at the next measurement position described above (S<b>33</b>). Then, the eyesight measurement at this new measurement position is started (S<b>26</b>). At this time, scanning with the signal light LS may be executed again (S<b>27</b>).</p>
<p id="p-0159" num="0164">It should be noted that, when the new measurement position deviates from the prior scanning region R, the controller <b>210</b> newly sets the scanning region to include the new measurement position (i.e., so that a new projection region of the Landolt ring T is overlapped), and performs scanning with the signal light LS to form a tomographic image.</p>
<p id="p-0160" num="0165">The change in the measurement position as described above is, for example, sequentially executed for a predetermined number of positions. As a specific example, the eyesight measurement is first conducted on the central position of the scanning region R as shown in <figref idref="DRAWINGS">FIG. 6</figref>, and then the eyesight measurement is further conducted on each apex position of a rectangle enclosing this central position.</p>
<p id="p-0161" num="0166">Moreover, it is also possible to set the measurement position based on the condition of the eye E. For example, it is also possible to set the site of interest and its peripheral position of the eye E as the measurement position. Such a measurement position can be set based on, for example, the positional relationship of the site of interest relative to the macular area. Moreover, this positional relationship can be obtained based on, for example, the fundus image. In addition, it is also possible to set the measurement position so as to avoid the region on the fundus Ef that is thought to have low eyesight (for example, a region affected due to cataracts, a region that has an untreatable retinal disease, etc.)</p>
<p id="p-0162" num="0167">When the examination of all measurement positions is completed (S<b>32</b>: Yes), the main controller <b>211</b> selects the highest value among the acquired eyesight values (S<b>34</b>). The main controller <b>211</b> allows the selected eyesight value and the measurement position and tomographic image correlated to this eyesight value to be displayed on the display device <b>3</b> (or the display <b>240</b>) (S<b>35</b>). Consequently, the examiner can recognize the site having good eyesight on the fundus Ef, and furthermore, can observe the tomographic image of the fundus Ef at this site.</p>
<p id="p-0163" num="0168">When such an examination is applied at follow-ups, the measurement position in which the highest eyesight value is obtained may be changed. For example, in the follow-ups after the treatment of the disease in the macula flava, the highest eyesight value is obtained first at a site other than the macula flava, and then, in the course of treatment, the highest eyesight value may be obtained in the macula flava. In this way, therapeutic effect may appear not only as the improvement of the eyesight value, but also the change in the measurement position in which the highest eyesight value is obtained. Moreover, it is also possible to specify the measurement position at which the highest eyesight value is obtained as an actual fixation position.</p>
<p id="h-0024" num="0000">[Actions and Effects]</p>
<p id="p-0164" num="0169">The actions and effects of the fundus observation apparatus <b>1</b> as described above will be described.</p>
<p id="p-0165" num="0170">According to the fundus observation apparatus <b>1</b>, it is possible to execute the OCT measurement and the eyesight measurement while superposing the scanning region R of the signal light LS on the projection region of the visual target for measuring eyesight (Landolt ring T) to form the tomographic image of the fundus Ef at the scanning region R, and it is also possible to store the eyesight value measured using the Landolt ring T and the tomographic image while correlating them to each other.</p>
<p id="p-0166" num="0171">Here, the fundus observation apparatus <b>1</b> controls the LCD <b>39</b> based on the scanning region R of the signal light LS to superpose the projection region of the Landolt ring T on the fundus Ef on the scanning region R. Furthermore, the fundus observation apparatus <b>1</b> can display the fixation target V on the LCD <b>39</b> along with the Landolt ring T to project them on the fundus Ef, and changes the projection region of the Landolt ring T on the fundus Ef by changing the relative display position of the Landolt ring T and the fixation target V based on the scanning region R.</p>
<p id="p-0167" num="0172">According to such the fundus observation apparatus <b>1</b>, it is possible to acquire an image (tomographic image) of the eyesight measurement site in the fundus Ef. In particular, when the projection region and the scanning region are set to include a site of interest in the fundus Ef, the tomographic image and the eyesight value of that site of interest can be acquired. Consequently, the condition of the eyesight and the morphology of the retina, etc., can be recognized, and furthermore, their relationship can also be recognized.</p>
<p id="p-0168" num="0173">For example, even if the morphology of the retina is improved, the patient cannot realize the therapeutic effect unless the eyesight is improved. By using the fundus observation apparatus <b>1</b>, it is possible to closely investigate whether or not such a situation has occurred.</p>
<p id="p-0169" num="0174">Moreover, the fundus observation apparatus <b>1</b> allows different sizes of visual targets for measuring eyesight to be displayed on the LCD <b>39</b> to change the size of the projection region on the fundus Ef, thereby making it possible to project the visual target for measuring eyesight corresponding to different eyesight values on the fundus Ef. It should be noted that the size of the projection region on the fundus Ef can also be changed with a target of the same size being displayed by providing an optical element such as a lens between the LCD <b>39</b> and the eye E.</p>
<p id="p-0170" num="0175">Furthermore, the fundus observation apparatus <b>1</b> can adjust the size of the visual target for measuring eyesight displayed on the LCD <b>39</b> based on the position of the focusing lens <b>31</b>. It should be noted that, in place of adjusting the display size, the size of the projection region may be changed by the optical element described above.</p>
<p id="p-0171" num="0176">With such a configuration, it is possible to precisely measure the eyesight value without being affected by the eye refractive power of the eye E.</p>
<p id="p-0172" num="0177">Moreover, the fundus observation apparatus <b>1</b> is configured to change the size of the visual target for measuring eyesight displayed on the LCD <b>39</b> based on the response contents from the subject against the visual target for measuring eyesight presented to the eye E, and furthermore, to determine the eyesight value of the eye E based on the response contents according to the change of the visual target for measuring eyesight.</p>
<p id="p-0173" num="0178">With such a configuration, it is possible to automatically measure the eyesight at a predetermined site in the eye E (macula flava, site of interest, etc.).</p>
<p id="p-0174" num="0179">Moreover, the low-coherence light L<b>0</b> used in the OCT measurement by the fundus observation apparatus <b>1</b> is preferably invisible light. By using such invisible light, even when the eyesight measurement and the OCT measurement are conducted simultaneously, the signal light LS is not visually recognized by the subject. Consequently, the complexity in the examination can be reduced and the examination can be smoothly conducted, thereby further improving the accuracy and precision of the examination results. It should be noted that it is necessary for the subject to visually confirm the fixation target and the visual target for measuring eyesight.</p>
<p id="p-0175" num="0180">Furthermore, the invisible light used in the OCT measurement is preferably near-infrared light of center wavelength within the range from about 1050 to 1060 nm. Here, if the center wavelength is shorter than 1050 nm, there is a risk that the signal light LS may not certainly reach the fundus Ef. On the other hand, if the center wavelength is longer than 1060 nm, there is a risk that the signal light LS will be absorbed by the water content within the eyeball so that it may not certainly reach the fundus Ef.</p>
<p id="p-0176" num="0181">The configuration described above is merely one example for favorably implementing the present invention. Therefore, it is possible to properly make arbitrary modification within the scope of the present invention.</p>
<p id="p-0177" num="0182">In the above embodiment, the configuration in which the projection region of the visual target for measuring eyesight on the fundus is superposed on the scanning region by controlling the display part based on the scanning region of the signal light, but it is also possible to apply a configuration for performing the opposite process. Specifically, it is possible to apply a configuration in which the scanning region of the signal light on the fundus is superposed on the projection region of the visual target for measuring eyesight by controlling the scanning part based on the display position of the visual target for measuring eyesight on the display part.</p>
<p id="p-0178" num="0183">Such a configuration is shown in <figref idref="DRAWINGS">FIG. 10</figref>. It should be noted that the retinal camera unit <b>2</b> and the OCT unit <b>100</b> have the same configuration as that in the above embodiment (refer to <figref idref="DRAWINGS">FIG. 1</figref>, <figref idref="DRAWINGS">FIG. 2</figref>).</p>
<p id="p-0179" num="0184">Moreover, it is possible to apply various configurations described in the above embodiments to this modification example. For example, it is possible to apply the configuration in which the visual targets for measuring eyesight corresponding to various eyesight values is presented, the configuration in which the size of the visual target for measuring eyesight is adjusted, the configuration in which the eyesight value is automatically obtained, the configuration for the light source, etc.</p>
<p id="p-0180" num="0185">The block diagram shown in <figref idref="DRAWINGS">FIG. 10</figref> is almost the same as that shown in <figref idref="DRAWINGS">FIG. 3</figref>. However, it is different from the configuration in <figref idref="DRAWINGS">FIG. 3</figref> in that the controller <b>210</b> of this modification example is provided with a scan setting part <b>218</b> and in that the fixation target setting part <b>216</b> is not provided. It should be noted that the fixation target setting part <b>216</b> may also be provided in this modification example.</p>
<p id="p-0181" num="0186">The scan setting part <b>218</b> performs setting in regard to scanning with the signal light LS. Specifically, the scan setting part <b>218</b> sets the scanning region of the signal light LS by the Galvano mirrors <b>43</b>, <b>44</b>. For example, the scan setting part <b>218</b> sets the scanning region based on the display position of the visual target for measuring eyesight on the LCD <b>39</b> so that the projection region of the visual target for measuring eyesight and the scanning region are overlapped with each other.</p>
<p id="p-0182" num="0187">An operation example of the scan setting part <b>218</b> is described. The display position of the visual target for measuring eyesight on the LCD <b>39</b> can be recognized by the main controller <b>211</b> because it is controlled by the main controller <b>211</b>. For example, when the central position of the display screen of the LCD <b>39</b> is located on an optical axis of the imaging optical system <b>30</b>, the display position of the target can be recognized as a displacement of the central position of the target relative to the central position of the display screen. Moreover, the display region of the target on the display screen can be recognized based on the display size of the target.</p>
<p id="p-0183" num="0188">Furthermore, the direction of each of the Galvano mirrors <b>43</b>, <b>44</b> can be recognized by the main controller <b>211</b>. Specifically, the main controller <b>211</b> can recognize the position (reference position) of each Galvano mirror <b>43</b>, <b>44</b> for directing the signal light LS such that it is guided in a direction parallel with the optical axis.</p>
<p id="p-0184" num="0189">Moreover, the scanning mode of the signal light LS (three-dimensional scanning, radial scanning, etc.) is selected beforehand, and the scan setting part <b>218</b> sets the position of the scanning region in the selected scanning mode based on the display position of the target.</p>
<p id="p-0185" num="0190">When achieving the condition shown in <figref idref="DRAWINGS">FIG. 6</figref>, since the Landolt ring T and the fixation target V are displayed on the optical axis, the scan setting part <b>218</b> sets a rectangular scanning region R centered on the reference position of the Galvano mirrors <b>43</b>, <b>44</b>. The main controller <b>211</b> allows the Landolt ring T and the fixation target V to be displayed at the central position of the LCD <b>39</b>, and also controls the scan drive <b>70</b> to sequentially scan with the signal light LS along a plurality of scanning lines included in the set scanning region R. Consequently, as shown in <figref idref="DRAWINGS">FIG. 6</figref>, it is possible to conduct the examination with the scanning region R and the Landolt ring T overlapped with each other.</p>
<p id="p-0186" num="0191">Moreover, when achieving the condition shown in <figref idref="DRAWINGS">FIG. 9</figref>, since the Landolt ring T and the fixation target V are displayed at any position on the display screen, the scan setting part <b>218</b> sets the scanning region R (i.e., the driving range of the Galvano mirrors <b>43</b>, <b>44</b>) so that it is superposed on the projection region of the Landolt ring T based on the display position of the Landolt ring T. The main controller <b>211</b> allows the Landolt ring T and the fixation target V to be displayed on the LCD <b>39</b>, and also controls the scan drive <b>70</b> to sequentially scan with the signal light LS along a plurality of scanning lines included in the set scanning region R. Consequently, as shown in <figref idref="DRAWINGS">FIG. 9</figref>, it is possible to conduct the examination with the scanning region R and the Landolt ring T overlapped with each other.</p>
<p id="p-0187" num="0192">According to such a modification example, it is possible to acquire an image of the eyesight measurement site in the fundus Ef. It should be noted that in the above embodiment the examination is conducted by setting the projection region of the target superposed on the preliminarily set scanning region, but in this modification example, conversely, the examination can be conducted by setting the scanning region superposed on the preliminarily set projection region of the target.</p>
<p id="p-0188" num="0193">In the above embodiment, the Landolt ring is used as the visual target for measuring eyesight, but it is possible to apply various targets other than this. For example, the target pattern can be changed such as by displaying various characters. Moreover, the target is not limited to a still image, and may be a moving image. Moreover, it may be configured so that not only the size of the target but also various presentation modes can be changed. For example, it is possible to change the color or brightness (contrast) of the target.</p>
<p id="p-0189" num="0194">In the above embodiment, the tomographic image and the eyesight value are stored while being correlated to each other, but the OCT image correlated to the eyesight value is not limited to a tomographic image. For example, a three-dimensional image obtained by three-dimensional scanning and an eyesight value can also be stored while being correlated to each other. In this case, it is possible to recognize the three-dimensional positional relationship between the site of interest in the fundus Ef and the fixation position. Moreover, it is also possible to recognize the size (area or volume) of the affected site. By making it possible to acquire such information, the therapeutic effect can be assessed in more detail than in the case in which two-dimensional tomographic images are captured.</p>
<p id="p-0190" num="0195">Moreover, it is also possible to form a tomographic image on any cross-section passing near the eyesight measurement position based on the volume data obtained by the three-dimensional scanning and store this tomographic image and the eyesight value while correlating them with each other. This tomographic image is formed by the image processor <b>230</b>.</p>
<p id="p-0191" num="0196">In the above embodiment, the OCT measurement is started at the same time as the start of the eyesight measurement, but the start timing of these two operations may be of any timing. For example, since the eyesight measurement takes more time than the OCT measurement, the OCT measurement may start in the course of the eyesight measurement. Moreover, it is sufficient if the OCT measurement is executed at least once for one scanning region.</p>
<p id="p-0192" num="0197">When the configuration of above embodiment is utilized, the following OCT measurement can be performed. In this OCT measurement, the actual fixation position of the eye E is identified by performing scanning with the signal light LS in two steps.</p>
<p id="p-0193" num="0198">In the first step, a scanning mode that can be executed for a relatively short time is applied, while in the second step, a scanning mode that can form a three-dimensional image is applied. It should be noted that it is possible to reverse the first step and the second step.</p>
<p id="p-0194" num="0199">As a specific example, the case in which cruciform scanning is applied in the first step and three-dimensional scanning is applied in the second step is described. In the first step, a fixation target is first presented to an eye E for fixation. Then, OCT measurement by cruciform scanning is performed on the fundus Ef of the fixed eye E to form a tomographic image corresponding to horizontal scanning (horizontal tomographic image) and a tomographic image corresponding to vertical scanning (vertical tomographic image). Here, since cruciform scanning is executed instantly, it is believed that there is no deviation of the fixation position of the eye E during the measurement.</p>
<p id="p-0195" num="0200">Next, as the second step, OCT measurement by three-dimensional scanning is performed on the eye E fixed by the same fixation target as that in the first step to form a plurality of tomographic images corresponding to a plurality of horizontal scanning (scanning lines). Moreover, the image processor <b>230</b> generates volume data or stack data based on these tomographic images. Since three-dimensional scanning takes some time (on the order of a few seconds), the fixation position of the eye E may deviate during the measurement.</p>
<p id="p-0196" num="0201">Subsequently, the image processor <b>230</b> calculates the image correlation between the horizontal tomographic image acquired in the first step and each tomographic image acquired in the second step, and identifies the cross-sectional position of the tomographic image in the second step with the highest correlation value. At this time, the correlation value between various cross-sectional images in the horizontal direction of the volume data generated in the second step and the horizontal tomographic image may be calculated and the cross-sectional position in the horizontal direction of the volume data with the highest correlation value may be identified.</p>
<p id="p-0197" num="0202">Similarly, the image processor <b>230</b> calculates the image correlation between the vertical tomographic image acquired in the first step and various cross-sectional images in the vertical direction of the volume data acquired in the second step, and identifies the cross-sectional position in the vertical direction of the volume data with the highest correlation value.</p>
<p id="p-0198" num="0203">The crossing position of the horizontal cross-sectional position and the vertical cross-sectional position in the three-dimensional image as identified above is the fixation position of the eye E. Consequently, the fixation position of the eye E on the three-dimensional image acquired in the second step can be easily identified. Furthermore, three-dimensional morphology of the fundus Ef near this fixation position can be recognized, allowing the recognized information to possibly aid in diagnosis and treatment.</p>
<p id="p-0199" num="0204">A modification example in which the OCT measurement is performed based on the eyesight measurement results is described. In this modification example, a visual target for measuring eyesight corresponding to a predetermined eyesight value is projected on the fundus Ef. This process is performed by the controller <b>210</b>. This predetermined eyesight value is a preliminarily set eyesight value such as an eyesight value considered as having good eyesight (for example, 1.0). The subject inputs the response content against this visual target for measuring eyesight using the input device <b>300</b>.</p>
<p id="p-0200" num="0205">The controller <b>210</b> determines whether the input response content is true or false. This process is executed by, for example, judging whether or not the direction indicated by the input device <b>300</b> matches the direction of the rift in the Landolt ring displayed on the LCD <b>39</b> as a visual target for measuring eyesight, and determining it as a correct answer if they match or determining it as a wrong answer if they do not match.</p>
<p id="p-0201" num="0206">If the response content is determined as a correct answer, the controller <b>210</b> controls the scan drive <b>70</b> to change the direction of the Galvano mirrors <b>43</b>, <b>44</b> and scans the scanning region superposed on the projection region of said visual target for measuring eyesight on the fundus Ef with the signal light LS.</p>
<p id="p-0202" num="0207">The CCD image sensor <b>120</b> detects interference light LC of the signal light LS and the reference light LR. The image forming part <b>220</b> forms a tomographic image of the above-mentioned scanning region based on the detection results. When this scanning region is a two-dimensional region, the image forming part <b>220</b> forms a tomographic image on each of a plurality of cross sections (scanning lines) within this scanning region, and the image processor <b>230</b> forms a three-dimensional image of this scanning region based on these tomographic images. The main controller <b>211</b> stores the formed OCT image (tomographic image or three-dimensional image) and above-mentioned predetermined eyesight value in the storage <b>212</b> while correlating them to each other. At this time, information indicating the projection region of the visual target for measuring eyesight on the fundus Ef (for example, display position of the visual target for measuring eyesight on the LCD <b>39</b>, position of the projection region on the fundus image, etc.) may be stored while being correlated with the OCT image and the predetermined eyesight value.</p>
<p id="p-0203" num="0208">According to such a modification example, an OCT image of a site in the fundus Ef having at least the predetermined eyesight value can be automatically acquired.</p>
<p id="p-0204" num="0209">As a further modification example, it is also possible to configure such that the OCT image of the measurement site can be acquired even when the eyesight value of the measurement site in the fundus Ef is below the predetermined value. As a specific example, if the response to the visual target for measuring eyesight of a predetermined eyesight value (for example, 1.0) is determined to be wrong, the controller <b>210</b> allows the visual target for measuring eyesight corresponding to the next lower eyesight value (for example, 0.8) to be displayed on the LCD <b>39</b>. Then, if a correct answer is obtained for this visual target for measuring eyesight projected on the fundus Ef, the controller <b>210</b> controls the scan drive <b>70</b> to change the direction of the Galvano mirrors <b>43</b>, <b>44</b> and scan the scanning region superposed on the projection region of this visual target for measuring eyesight on the fundus Ef with the signal light LS. The image forming part <b>220</b> etc. forms an OCT image based on the detection results of interference light LC of the signal light LS and the reference light LR. The main controller <b>211</b> stores the formed OCT image and above-mentioned eyesight value in storage <b>212</b> while correlating them to each other. At this time, information indicating the projection region of the visual target for measuring eyesight on the fundus Ef may be stored while being correlated to the OCT image and the eyesight value.</p>
<p id="p-0205" num="0210">It should be noted that, if a wrong answer is obtained again, the visual target for measuring eyesight corresponding to still lower eyesight values may be used to conduct the examination. Moreover, it is also possible to preset the lowest eyesight value for conducting the eyesight measurement.</p>
<p id="p-0206" num="0211">In the above embodiment, the position of the reference mirror <b>114</b> is changed so as to change an optical path length difference between the optical path of the signal light LS and the optical path of the reference light LR. However, a method for changing the optical path length difference is not limited thereto. For example, it is possible to change the optical path length difference by moving the retinal camera unit <b>2</b> and the OCT unit <b>100</b> with respect to the eye E to change the optical path length of the signal light LS. Moreover, in a case that an object is not a living site or the like, it is also effective to change the optical path length difference by moving the object in the depth direction (z-direction).</p>
<p id="p-0207" num="0212">The computer program used in the above embodiments can be stored in any kind of recording medium that can be read by a drive device of a computer. As this recording medium, for example, an optical disk, a magneto-optic disk (CD-ROM, DVD-RAM, DVD-ROM, MO, and so on), and a magnetic storage (a hard disk, a Floppy Disk&#x2122;), ZIP, and so on) can be used. Moreover, it is possible to store into a storing device such as a hard disk drive and a memory. Besides, it is possible to transmit/receive this program through a network such as internet or LAN etc.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A fundus observation apparatus comprising:
<claim-text>a projection part that includes a display part to display a visual target for measuring vision, and projects, via a predetermined optical path, said displayed visual target for measuring vision to the fundus of an eye;</claim-text>
<claim-text>a light source that outputs low-coherence light;</claim-text>
<claim-text>an optical system that splits said output low-coherence light into signal light and reference light, generates interference light by superposing said signal light that has passed through said fundus via said predetermined optical path and said reference light that has passed through a reference optical path, and detects said interference light;</claim-text>
<claim-text>a scanning part that scans said fundus with said signal light;</claim-text>
<claim-text>a controlling part that overlaps the projection region of said visual target for measuring vision projected by said projection part and the scanning region of said signal light scanned by said scanning part each other;</claim-text>
<claim-text>an image forming part that forms an image of said fundus based on the detection results of interference light generated by superposing said signal light with which said scanning region is scanned and said reference light; and</claim-text>
<claim-text>a storage part that stores said formed image and a vision value measured using said visual target for measuring vision while correlating them with each other.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The fundus observation apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said controlling part controls said projection part based on the scanning region of said signal light scanned by said scanning part to overlap the projection region of said visual target for measuring vision in said fundus on the scanning region of said signal light.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The fundus observation apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein:
<claim-text>said display part displays a fixation target for fixing said eye along with said visual target for measuring vision;</claim-text>
<claim-text>said projection part projects said displayed fixation target on said fundus along with said visual target for measuring vision; and</claim-text>
<claim-text>said controlling part changes said projection region by changing, based on said scanning region, the relative display positions of said visual target for measuring vision and said fixation target displayed by said display part.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The fundus observation apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said controlling part controls said scanning part based on the display position of said visual target for measuring vision displayed by said display part to overlap the scanning region of said signal light in said fundus on the projection region of said visual target for measuring vision.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The fundus observation apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said controlling part allows said visual target for measuring vision corresponding to different vision values to be projected on said fundus, by allowing said visual target for measuring vision of different sizes to be displayed on said display part to change the size of said projection region.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The fundus observation apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein:
<claim-text>said predetermined optical path is provided with a focusing lens that moves along an optical axis thereof to change the focus position of light towards said fundus; and</claim-text>
<claim-text>said controlling part adjusts the size of said visual target for measuring vision displayed on said display part based on the position of said focusing lens.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The fundus observation apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising an operation part for inputting response contents for said visual target for measuring vision projected on said fundus, wherein
<claim-text>said controlling part changes the size of said visual target for measuring vision displayed on said display part based on said input response contents, and determines the vision value of said eye based on said response contents according to this change.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The fundus observation apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising an operation part for inputting response contents for said visual target for measuring vision projected on said fundus, wherein
<claim-text>said controlling part controls said projection part to project said visual target for measuring vision corresponding to a predetermined vision value to said fundus, determines whether said input response contents for this visual target for measuring vision are true or false, and if it is determined that they are correct, then controls said scanning part to scan said scanning region overlapping the projection region with said signal light.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The fundus observation apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said light source outputs invisible light as said low-coherence light.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The fundus observation apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein said light source outputs near-infrared light of center wavelength within the range substantially from 1050 to 1060 nm. </claim-text>
</claim>
</claims>
</us-patent-grant>
