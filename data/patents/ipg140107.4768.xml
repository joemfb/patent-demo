<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625861-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625861</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12120936</doc-number>
<date>20080515</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1037</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382125</main-classification>
<further-classification>382115</further-classification>
<further-classification>382168</further-classification>
</classification-national>
<invention-title id="d2e53">Fingerprint representation using gradient histograms</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5187747</doc-number>
<kind>A</kind>
<name>Capello et al.</name>
<date>19930200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382124</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5610993</doc-number>
<kind>A</kind>
<name>Yamamoto</name>
<date>19970300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382124</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6201886</doc-number>
<kind>B1</kind>
<name>Nakayama</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7110581</doc-number>
<kind>B2</kind>
<name>Xia et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382124</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7539331</doc-number>
<kind>B2</kind>
<name>Wendt et al.</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382124</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7565548</doc-number>
<kind>B2</kind>
<name>Fiske et al.</name>
<date>20090700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713186</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7876933</doc-number>
<kind>B2</kind>
<name>Jang et al.</name>
<date>20110100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382124</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2002/0146178</doc-number>
<kind>A1</kind>
<name>Bolle et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382254</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2006/0023921</doc-number>
<kind>A1</kind>
<name>Saitoh et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382115</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2007/0297653</doc-number>
<kind>A1</kind>
<name>Bolle et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2008/0080750</doc-number>
<kind>A1</kind>
<name>Bee et al.</name>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2009/0310830</doc-number>
<kind>A1</kind>
<name>Bolle et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382124</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>WO</country>
<doc-number>2007/080133</doc-number>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>WO</country>
<doc-number>2007080133</doc-number>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>A.M. Bazen et al., &#x201c;A Correlation-Based Fingerprint Verification System,&#x201d; in Proceedings of the ProRISC Workshop on Circuits, Systems and Signal Processing, Nov. 2000, pp. 1-8, Netherlands.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>A.K. Jain et al., &#x201c;Filterbank-Based Fingerprint Matching,&#x201d; IEEE Transactions on Image Processing, May 2000, pp. 846-859, vol. 9, No. 5.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>A. Ross et al., &#x201c;A Hybrid Fingerprint Matcher,&#x201d; Pattern Recognition, Jul. 2003, pp. 1661-1673, vol. 36, No. 7.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>K. Nandakumar et al., &#x201c;Local Correlation-Based Fingerprint Matching,&#x201d; in Proceedings of Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP), Dec. 2004, pp. 1-6, Kolbata.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>N. Dalal et al., &#x201c;Histograms of Oriented Gradients for Human Detection,&#x201d; in Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition, 2005, 8 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>D. Maio et al., &#x201c;Fvc2002: Second Fingerprint Verification Competition,&#x201d; in Proceedings of the 16th International Conference on Pattern Recognition (3), 2002, 4 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>International Search Report for PCT/US09/40347 dated Jun. 12, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382115</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382125</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382124</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090285459</doc-number>
<kind>A1</kind>
<date>20091119</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Aggarwal</last-name>
<first-name>Gaurav</first-name>
<address>
<city>Greenbelt</city>
<state>MD</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Bolle</last-name>
<first-name>Rudolf Maarten</first-name>
<address>
<city>Bedford Hills</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Jea</last-name>
<first-name>Tsai-Yang</first-name>
<address>
<city>Poughkeepsie</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ratha</last-name>
<first-name>Nalini Kanta</first-name>
<address>
<city>Yorktown Heights</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Aggarwal</last-name>
<first-name>Gaurav</first-name>
<address>
<city>Greenbelt</city>
<state>MD</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Bolle</last-name>
<first-name>Rudolf Maarten</first-name>
<address>
<city>Bedford Hills</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Jea</last-name>
<first-name>Tsai-Yang</first-name>
<address>
<city>Poughkeepsie</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Ratha</last-name>
<first-name>Nalini Kanta</first-name>
<address>
<city>Yorktown Heights</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Young</last-name>
<first-name>Preston J.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<orgname>Ryan, Mason &#x26; Lewis, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Alavi</last-name>
<first-name>Amir</first-name>
<department>2668</department>
</primary-examiner>
<assistant-examiner>
<last-name>Cese</last-name>
<first-name>Kenny</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Techniques for generating a gradient characterization for a first fingerprint image are provided. One or more fingerprint feature points are selected from the first fingerprint image. A region is obtained for each of the one or more selected fingerprint feature points. The region is a representation of an area proximate a given fingerprint feature point. Each of the obtained regions is divided into a plurality of sub-regions. A histogram is generated for each of the plurality of sub-regions. For each of the one or more selected fingerprint feature points, the one or more generated histograms are combined into a concatenated histogram. The concatenated histogram is used for identification purposes.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="266.95mm" wi="163.41mm" file="US08625861-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="181.10mm" wi="90.00mm" file="US08625861-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="188.13mm" wi="102.70mm" orientation="landscape" file="US08625861-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="266.87mm" wi="162.56mm" file="US08625861-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="231.82mm" wi="156.63mm" orientation="landscape" file="US08625861-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="224.79mm" wi="144.02mm" file="US08625861-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The present invention generally relates to fingerprint image processing systems and, more particularly, to techniques for generating a gradient characterization for a fingerprint image which may be used for identification purposes in such fingerprint image processing systems.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Fingerprint based biometric matching continues to be a leading topic of research in the field of image analysis. Tremendous amounts of money and resources have been spent on analyzing fingerprints to match them accurately, robustly, and efficiently. Although great leaps and bounds have been achieved in fingerprint matching technology, there is still room for improvement. Currently, the performance of biometric matching is at an all time high, but operational demands continue to grow. As biometric databases increase in size, there is an equally growing demand for more processing power. One key goal is to increase processing speed without compromising matching efficiency. Conventional techniques address the issue of speed by purchasing faster computers. However, this solution fails to address the issue of efficiency. Efficiency can only be addressed by changing the way in which biometric data is processed.</p>
<p id="p-0004" num="0003">Current state-of-the-art fingerprint matchers are quite fast and robust as far as 1:1 verification is concerned, but these conventional systems are less efficient at comparing a query sequentially against a large set of gallery fingerprints for identification tasks. In an effort to maximize efficiency, indexing schemes have been proposed. Generally, the theory behind an indexing scheme is to create an index gallery of biometrics using suitable features so that sequential matching is not required for identification. Ideally, after a biometric image is indexed, it does not require any additional post-processing step prior to matching.</p>
<p id="p-0005" num="0004">Indexing schemes rely on particular characteristics of a biometric image and those characteristics are then used to index the biometric. For example, most existing approaches use minutiae graphs to characterize fingerprint images. Under this technique, the geometry of a minutiae graph of one fingerprint is compared to the geometry of other minutiae graphs stored in a biometric database. Although this technique is faster than comparing two biometric images pixel by pixel, this technique is still time-consuming and results in matching errors. In addition to the large number of required geometric calculations, the computed geometric values are prone to error if the minutiae points are slightly unclear.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0006" num="0005">Principles of the present invention provide techniques that overcome the above-mentioned drawbacks associated with existing methods by providing techniques that address the above needs, as well as other needs. More particularly, principles of the invention provide techniques for generating a gradient characterization for a fingerprint image. The gradient characterization may then be used for identification purposes. This technique of indexing fingerprint biometrics is more efficient because it does not utilize geometric information and is less prone to matching errors.</p>
<p id="p-0007" num="0006">For example, in one embodiment of the invention, a technique for generating a gradient characterization for a first fingerprint image comprises the following steps. One or more fingerprint feature points are selected from the first fingerprint image. A region is obtained for each of the one or more selected fingerprint feature points. The region being a representation of an area proximate a given fingerprint feature point. Each of the obtained regions is divided into a plurality of sub-regions. A histogram is generated for each of the plurality of sub-regions. The one or more generated histograms are combined into a concatenated histogram for each of the one or more selected fingerprint feature points. The concatenated histogram is then used for identification purposes. In one embodiment, the histogram may be a histogram of oriented gradient.</p>
<p id="p-0008" num="0007">The above technique may further comprise the step of enhancing the first fingerprint image before selecting the one or more fingerprint feature points. Further, each obtained region may be rotated into a comparable direction.</p>
<p id="p-0009" num="0008">In an additional embodiment, a first histogram set comprising the concatenated histograms of the first fingerprint image may be generated. Also, one or more second histogram sets using one or more second fingerprint images may be generated. The first histogram set may be compared to the one or more second histogram sets. In an alternate embodiment, the step of comparing may further comprise the step of computing a degree of correlation between the first histogram set and the one or more second histogram sets. The degree of correlation may be based on a number of correspondences between the first histogram set and the one or more second histogram sets.</p>
<p id="p-0010" num="0009">These and other objects, features, and advantages of the present invention will become apparent from the following detailed description of illustrative embodiments thereof, which is to be read in connection with the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 1</figref> is a flow diagram illustrating a methodology for generating a gradient characterization for a fingerprint image, according to an embodiment of the present invention.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating the local regions around a fingerprint minutiae which are used to generate gradient characterizations, according to an embodiment of the present invention.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating the methodology of <figref idref="DRAWINGS">FIG. 1</figref> as applied to a given example, according to an embodiment of the present invention.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram illustrating a comparison of a concatenated gradient histogram to matching and non-matching gradient histograms, according to an embodiment of the present invention.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 5</figref> is a flow diagram illustrating a system for generating a gradient characterization for a fingerprint image, according to an embodiment of the present invention.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram illustrating an illustrative hardware implementation of a computing system in accordance with which one or more components/methodologies of the present invention may be implemented, according to an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading>
<p id="p-0017" num="0016">The present invention will be described in conjunction with exemplary methods for generating a gradient characterization for a fingerprint. It should be understood, however, that the invention is not limited to the particular embodiments described herein. The principles of this invention are generally applicable to the generation of any suitable biometric characterization which may be used for identification purposes, and modifications to the illustrative embodiments will become apparent to those skilled in the art given the teachings described herein.</p>
<p id="p-0018" num="0017">The term &#x201c;gradient characterization&#x201d; as used herein is intended to be construed broadly so as to encompass, by way of example and without limitation, any gradient-based representation of an image.</p>
<p id="p-0019" num="0018">The term &#x201c;histogram&#x201d; as used herein is intended to be construed broadly so as to encompass, by way of example and without limitation, any graph of tabulated frequencies. A &#x201c;gradient histogram&#x201d; as described in conjunction with the present invention refers to a graph of tabulated light gradients for a particular image.</p>
<p id="p-0020" num="0019">Existing biometric approaches utilize the geometry of minutiae graphs to characterize fingerprints. We propose a gradient-based approach that utilizes the textural features of a biometric image. Referring initially to <figref idref="DRAWINGS">FIG. 1</figref>, a flow diagram illustrates a methodology <b>100</b> for generating a gradient characterization for a fingerprint image, according to an embodiment of the present invention. In an illustrative embodiment, methodology <b>100</b> is performed by a computer-based image processing unit which is coupled to a biometric database and/or a biometric scanner. A biometric image (e.g., a fingerprint image) is first scanned or retrieved from a biometric database for analysis. At step <b>102</b>, fingerprint feature points are selected from the fingerprint image. The selection of feature points involves identifying the minutiae points of a fingerprint. Fingerprint minutiae contain ridge endings and/or bifurcations which are unique to an individual. Techniques for locating minutiae are well known to a person having ordinary skill in the art.</p>
<p id="p-0021" num="0020">After selecting fingerprint feature points, a region representing an area proximate (i.e., near) each selected feature point is obtained (step <b>104</b>). These regions may be referred to as patches. At step <b>106</b>, each region, or patch, is divided into a plurality of sub-regions. An illustrative embodiment of a division in to sub-regions will be described in greater detail with reference to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0022" num="0021">At step <b>108</b>, a histogram is generated for each sub-region of a given patch. In an illustrative embodiment, the histogram is a Histogram of Oriented Gradient (HOG). HOG representations are a class of feature descriptors often used for the task of object detection. N. Dalal et al., &#x201c;Histograms of oriented gradients for human detection,&#x201d; in <i>Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition, </i>2005, pp. 886-893, the disclosure of which is incorporated by reference herein. HOG-based object detectors rely on the hypothesis that local object appearance may be characterized using the distribution of local gradients, even without precise knowledge of the gradient positions.</p>
<p id="p-0023" num="0022">In an exemplary embodiment, we use HOG-based descriptors to characterize fingerprint textures. HOGs are conventionally computed using a dense grid of overlapping blocks. However, computing HOG descriptors on a dense grid of overlapping blocks may neither be efficient nor robust for the task of fingerprint matching. Therefore, unlike most HOG-based approaches for object/person detection, we compute HOG descriptors for local regions around minutiae locations (e.g., histograms of the sub-regions of a given patch). This approach satisfies our goal to generate efficient, discriminable, and robust descriptions of the ridge flow patterns of a fingerprint. For instance, computing histograms for small sub-regions around minutiae locations provide robustness as compared to any point-wise descriptor. Further, since the HOG descriptors are computed for small unique regions, it ensures that the discriminable information of the minutiae are not lost. Finally, the HOGs are unaffected by translations and rotations and the gradients can be normalized with respect to minutiae orientation. Therefore, the textural characterizations of the minutiae are independent of their absolute location on a fingerprint and there is no need to uniformly align fingerprints images in a consistent and precise manner prior to matching.</p>
<p id="p-0024" num="0023">At step <b>110</b>, the generated histograms derived from each fingerprint feature point are combined into a concatenated histogram. For example, if fifty feature points are selected from a fingerprint image and each patch associated with each fingerprint feature point is divided into five sub-regions, there will be fifty concatenated histograms each containing the gradient information of five sub-histograms. In an illustrative embodiment, the fifty concatenated histograms derived from a given fingerprint image are stored together as one histogram set.</p>
<p id="p-0025" num="0024">It should be noted that the steps of methodology <b>100</b> may be repeated for multiple fingerprint images, yielding multiple histogram sets. One histogram set represents one fingerprint image (e.g., fingerprint representation). The fingerprint representation may be used in fingerprint recognition systems. In an exemplary matching process, one fingerprint representation, in the form of a histogram set, is compared to a database of stored fingerprint representations for identification purposes.</p>
<p id="p-0026" num="0025">The steps of methodology <b>100</b> will be illustrated below in greater detail with reference to <figref idref="DRAWINGS">FIG. 3</figref>. Furthermore, the comparison (e.g., matching) of concatenated histograms will be described in greater detail with reference to <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0027" num="0026">Referring now to <figref idref="DRAWINGS">FIG. 2</figref>, a diagram illustrates the local regions around a fingerprint minutiae which are used to generate gradient characterizations, according to an embodiment of the present invention. In this exemplary embodiment, fingerprint region <b>202</b> is divided into five sub-regions using an image template <b>204</b>. A histogram is generated for each image portion falling within the five sub-regions <b>206</b>.</p>
<p id="p-0028" num="0027">Referring now to <figref idref="DRAWINGS">FIG. 3</figref>, a diagram illustrates the methodology of <figref idref="DRAWINGS">FIG. 1</figref> as applied to a given example, according to an embodiment of the present invention. <figref idref="DRAWINGS">FIG. 3</figref> shows a schematic of one proposed approach. First, a fingerprint image <b>302</b> is input. The fingerprint image may be scanned or may be an existing fingerprint image stored in a biometric database. In an illustrative embodiment, the fingerprint image is enhanced <b>304</b> for better image resolution. Enhancing a fingerprint image increases the resolution of ridge flow patterns, which results in more accurate gradient characterizations. Techniques to enhance an image are known to a person having ordinary skill in the art. Enhancement may be carried out by designing suitable filters using a particular frequency domain or spatial domain. The filters may be tuned to a specific range of fingerprint ridge characteristics and/or noise models. Also, methods to create filters using expert marked fingerprint ridges have also been reported.</p>
<p id="p-0029" num="0028">Minutiae (e.g., fingerprint feature points) of the fingerprint image are then detected using any conventional technique. For each minutiae feature, a suitable-sized neighborhood block (e.g., region or patch) is obtained (<b>306</b>-<b>1</b>, . . . <b>306</b>-N). In an exemplary embodiment, each patch is rotated based on a general minutiae orientation to negate the effect of global rotation on HOG computation. The rotation may be a vertical alignment or a horizontal alignment. Each of the rotated patches (<b>308</b>-<b>1</b>, . . . <b>308</b>-N) are then divided into five sub-regions (<b>310</b>-<b>1</b>, . . . <b>310</b>-N). HOG descriptors are then computed for each sub-region creating a collection of HOG descriptors (<b>312</b>) unique to a given patch (<b>308</b>-<b>1</b>, . . . <b>308</b>-N).</p>
<p id="p-0030" num="0029">In an illustrative embodiment, the HOG computation involves spatial smoothing followed by a gradient computation. Each HOG is the weighted histogram of the gradient orientations where weights are given by the gradient magnitudes. The gradient value at every pixel in a sub-region may be calculated using many well known gradient operators including: Roberts Cross, Sobel, and Prewitt. Other discrete differentiation schemes to compute the gradient, G<sub>x </sub>and G<sub>y </sub>(gradients in the x and y directions) may also be constructed. Once the G<sub>x </sub>and G<sub>y </sub>are computed, the gradient orientation is computed using &#x398;=arctan(G<sub>x</sub>/G<sub>y</sub>). For the purpose of computing the histogram, &#x398; is quantized to a desired number of bins.</p>
<p id="p-0031" num="0030">The HOGs of the sub-regions are then combined into a concatenated HOG, or histogram <b>314</b>. The concatenation process simply involves connecting the HOGs of the sub-regions, one after the other in a consistent manner. In an exemplary embodiment, a HOG is presented in graphical form and a concatenated HOG is a combined graph comprising the HOGs of a patch. If a patch is divided into five sub-regions labeled MIDDLE, TOP LEFT, TOP_RIGHT, BOTTOM_LEFT, and BOTTOM_RIGHT, one concatenation may be, from left to right, MIDDLE&#x2014;TOP_LEFT&#x2014;TOP_RIGHT&#x2014;BOTTOM_LEFT&#x2014;BOTTOM_RIGHT. For matching purposes, every concatenated histogram should be concatenated in the same order or else two concatenated histograms which should have matched will not match. For instance, the gradient characterization of MIDDLE&#x2014;TOP_LEFT&#x2014;TOP_RIGHT&#x2014;BOTTOM_LEFT&#x2014;BOTTOM_RIGHT, will look different than TOP_LEFT&#x2014;TOP_RIGHT&#x2014;MIDDLE&#x2014;BOTTOM_LEFT&#x2014;BOTTOM_RIGHT.</p>
<p id="p-0032" num="0031">For the above example, it should be noted that each concatenated HOG comprises five HOGs (one for each sub-region). The concatenated HOG will be the textural description of a patch of a corresponding minutiae point. In an exemplary embodiment, the generation of a concatenated HOG is repeated for each selected fingerprint feature point (e.g., minutiae point). In the end, the inputted fingerprint image will be represented as one set of concatenated HOGs, one concatenated HOG <b>314</b> for each selected minutiae (<b>306</b>-<b>1</b>, . . . <b>306</b>-N).</p>
<p id="p-0033" num="0032">Referring now to <figref idref="DRAWINGS">FIG. 4</figref>, a diagram illustrates a comparison of a concatenated gradient histogram to matching and non-matching gradient histograms, according to an embodiment of the present invention. Given two fingerprints to match, one can easily compare the concatenated HOG features as follows. In an exemplary embodiment, the matching algorithm is based on counting the number of correspondences between the HOG features of two fingerprints. Two HOG features are corresponding if they are maximally correlated with each other in both directions. The details of this algorithm are as follows. Suppose M<sub>1 </sub>and M<sub>2 </sub>denote the set of HOG features for two fingerprints with m<sub>1 </sub>and m<sub>2 </sub>histograms, respectively. A histogram m<sub>1</sub><sup>i </sup>&#x3b5; M<sub>1 </sub>corresponds to a histogram m<sub>2</sub><sup>j </sup>if and only if:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>{<i>m</i><sub>1</sub><sup>i</sup><i>&#xb7;m</i><sub>2</sub><sup>j</sup><i>&#x3e;m</i><sub>1</sub><sup>i</sup><i>&#xb7;m</i><sub>2</sub><sup>k</sup><i>|&#x2200;m</i><sub>2</sub><sup>k </sup><i>&#x3b5; M</i><sub>2</sub><i>,k&#x2260;j</i>}, and<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>{<i>m</i><sub>1</sub><sup>i</sup><i>&#xb7;m</i><sub>2</sub><sup>j</sup><i>&#x3e;m</i><sub>1</sub><sup>l</sup><i>&#xb7;m</i><sub>2</sub><sup>j</sup><i>|&#x2200;m</i><sub>1</sub><sup>l </sup><i>&#x3b5; M</i><sub>1</sub><i>,l&#x2260;i}</i><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
In an alternative embodiment, a threshold may be applied to the value m<sub>1</sub><sup>i</sup>&#xb7;m<sub>2</sub><sup>j </sup>to avoid any chance correspondence. The total number of correspondences obtained this way is normalized by the total number of minutiae in the two fingerprints and is used as the similarity score for matching tasks. <figref idref="DRAWINGS">FIG. 4</figref> shows an example comparison of a given concatenated HOG <b>402</b> to matching HOG (<b>404</b>) and non-matching HOGs (<b>406</b>-<b>1</b>, . . . <b>406</b>-N). Further, since the HOG features are computed around minutiae locations, one can use the proposed HOG-based characterizations to verify the quality of minutiae matches across two fingerprints.
</p>
<p id="p-0034" num="0033">Referring now to <figref idref="DRAWINGS">FIG. 5</figref>, a flow diagram illustrates a system for generating a gradient characterization for a fingerprint image, according to an embodiment of the present invention. The components of system <b>500</b> carry out the methods illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. System <b>500</b> begins at feature locator <b>502</b>. The feature locator carries out step <b>102</b> of <figref idref="DRAWINGS">FIG. 1</figref>, in which fingerprint feature points are selected from a fingerprint image. Next, the feature summarizer <b>504</b> carries out step <b>104</b> of <figref idref="DRAWINGS">FIG. 1</figref>. The feature summarizer obtains a region representing an area proximate each selected fingerprint feature point.</p>
<p id="p-0035" num="0034">After summarizing the feature points, feature divider <b>506</b> carries out step <b>106</b> of <figref idref="DRAWINGS">FIG. 1</figref>. In an illustrative embodiment, the feature divider divides each obtained region into a plurality of sub-regions. The histogram generator <b>508</b>, which carries out step <b>108</b> of <figref idref="DRAWINGS">FIG. 1</figref>, then generates a histogram for each of the plurality of sub-regions. The histograms are then combined into a concatenated histogram by the histogram concatenator <b>510</b>. The histogram concatenator <b>510</b> carries out step <b>110</b> of <figref idref="DRAWINGS">FIG. 1</figref>. The concatenated histograms are then used for identification purposes.</p>
<p id="p-0036" num="0035">Referring now to <figref idref="DRAWINGS">FIG. 6</figref>, block diagram <b>600</b> illustrates an exemplary hardware implementation of a computing system in accordance with which one or more components/methodologies of the invention (e.g., components/methodologies described in the context of <figref idref="DRAWINGS">FIGS. 1-5</figref>) may be implemented, according to an embodiment of the present invention.</p>
<p id="p-0037" num="0036">As shown, the techniques for generating a gradient characterization for a fingerprint image may be implemented in accordance with a processor <b>610</b>, a memory <b>612</b>, I/O devices <b>614</b>, and a network interface <b>616</b>, coupled via a computer bus <b>618</b> or alternate connection arrangement.</p>
<p id="p-0038" num="0037">It is to be appreciated that the term &#x201c;processor&#x201d; as used herein is intended to include any processing device, such as, for example, one that includes a CPU (central processing unit) and/or other processing circuitry. It is also to be understood that the term &#x201c;processor&#x201d; may refer to more than one processing device and that various elements associated with a processing device may be shared by other processing devices.</p>
<p id="p-0039" num="0038">The term &#x201c;memory&#x201d; as used herein is intended to include memory associated with a processor or CPU, such as, for example, RAM, ROM, a fixed memory device (e.g., hard drive), a removable memory device (e.g., diskette), flash memory, etc. Such memory may be considered a computer readable storage medium.</p>
<p id="p-0040" num="0039">In addition, the phrase &#x201c;input/output devices&#x201d; or &#x201c;I/O devices&#x201d; as used herein is intended to include, for example, one or more input devices (e.g., keyboard, mouse, scanner, etc.) for entering data to the processing unit, and/or one or more output devices (e.g., speaker, display, printer, etc.) for presenting results associated with the processing unit.</p>
<p id="p-0041" num="0040">Still further, the phrase &#x201c;network interface&#x201d; as used herein is intended to include, for example, one or more transceivers to permit the computer system to communicate with another computer system via an appropriate communications protocol.</p>
<p id="p-0042" num="0041">Software components including instructions or code for performing the methodologies described herein may be stored in one or more of the associated memory devices (e.g., ROM, fixed or removable memory) and, when ready to be utilized, loaded in part or in whole (e.g., into RAM) and executed by a CPU.</p>
<p id="p-0043" num="0042">Although illustrative embodiments of the present invention have been described herein with reference to the accompanying drawings, it is to be understood that the invention is not limited to those precise embodiments, and that various other changes and modifications may be made by one skilled in the art without departing from the scope or spirit of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for generating a gradient characterization for a first fingerprint image of an individual, the method comprising:
<claim-text>selecting one or more fingerprint feature points from the first fingerprint image, wherein selecting a feature point includes selecting a fingerprint feature that is unique to the individual;</claim-text>
<claim-text>obtaining a region for each of the one or more selected fingerprint feature points, wherein each obtained region is a representation of an area proximate a given selected fingerprint feature point;</claim-text>
<claim-text>dividing each of the obtained regions into a plurality of sub-regions;</claim-text>
<claim-text>for each obtained region, generating a gradient histogram for each of the plurality of sub-regions associated with the obtained region; and</claim-text>
<claim-text>combining the generated gradient histograms for the plurality of sub-regions of a given region into a concatenated gradient histogram representative of the given region, wherein the concatenated gradient histogram is used for identification purposes.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the gradient histogram is a histogram of oriented gradient.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of enhancing the first fingerprint image before selecting the one or more fingerprint feature points.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of rotating each obtained region into a comparable direction.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of generating a first histogram set comprising the concatenated histograms of the first fingerprint image.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising the step of generating one or more second histogram sets using one or more second fingerprint images.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising the step of comparing the first histogram set to the one or more second histogram sets.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the step of comparing further comprises the step of computing a degree of correlation between the first histogram set and the one or more second histogram sets.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the degree of correlation is based on a number of correspondences between the first histogram set and the one or more second histogram sets.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An article of manufacture for generating a gradient characterization for a first fingerprint image, wherein the article of manufacture comprises a physical computer readable storage medium storing one or more programs, which when executed by a computer implement the steps of <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An apparatus for generating a gradient characterization for a first fingerprint image of an individual, the apparatus comprising:
<claim-text>a memory; and</claim-text>
<claim-text>at least one processor coupled to the memory and operative to:</claim-text>
<claim-text>select one or more fingerprint feature points from the first fingerprint image, wherein selecting a feature point includes selecting a fingerprint feature that is unique to the individual;</claim-text>
<claim-text>obtain a region for each of the one or more selected fingerprint feature points, wherein each obtained region is a representation of an area proximate a given selected fingerprint feature point;</claim-text>
<claim-text>divide each of the obtained regions into a plurality of sub-regions;</claim-text>
<claim-text>for each obtained region, generate a gradient histogram for each of the plurality of sub-regions associated with the obtained region; and</claim-text>
<claim-text>combine the generated gradient histograms for the plurality of sub-regions of a given region into a concatenated gradient histogram representative of the given region, wherein the concatenated gradient histogram is used for identification purposes.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the gradient histogram is a histogram of oriented gradient.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is further operative to enhance the first fingerprint image before selecting the one or more fingerprint feature points.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is further operative to rotate each obtained region into a comparable direction.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is further operative to generate a first histogram set comprising the concatenated histograms of the first fingerprint image.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the at least one processor is further operative to generate one or more second histogram sets using one or more second fingerprint images.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the at least one processor is further operative to compare the first histogram set to the one or more second histogram sets.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the at least one processor is further operative to compute a degree of correlation between the first histogram set and the one or more second histogram sets.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The apparatus of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the degree of correlation is based on a number of correspondences between the first histogram set and the one or more second histogram sets.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A system comprising:
<claim-text>a memory for storing program instructions for a biometric identification system, the program instructions being executable by a computer processing system to implement:</claim-text>
<claim-text>a feature locator for selecting one or more fingerprint feature points from the first fingerprint image of an individual, wherein selecting a feature point includes selecting a fingerprint feature that is unique to the individual;</claim-text>
<claim-text>a feature summarizer for obtaining a region for each of the one or more selected fingerprint feature points, wherein each obtained region is a representation of an area proximate a given selected fingerprint feature point;</claim-text>
<claim-text>a feature divider for dividing each of the obtained regions into a plurality of sub-regions;</claim-text>
<claim-text>a histogram generator for generating, for each obtained region, a gradient histogram for each of the plurality of sub-regions associated with the obtained region; and</claim-text>
<claim-text>a histogram concatenator for combining the generated gradient histograms for the plurality of sub-regions of is given region into a concatenated gradient histogram representative of the given region, wherein the concatenated gradient histogram is used for identification purposes.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
