<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626699-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626699</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12560872</doc-number>
<date>20090916</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>668</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>08</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>706 58</main-classification>
</classification-national>
<invention-title id="d2e53">Construction of photo trip patterns based on geographical information</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6868169</doc-number>
<kind>B2</kind>
<name>Staas et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2007/0115373</doc-number>
<kind>A1</kind>
<name>Gallagher et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482313</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2007/0271297</doc-number>
<kind>A1</kind>
<name>Jaffe et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>7071041</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2008/0204317</doc-number>
<kind>A1</kind>
<name>Schreve et al.</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2008/0319974</doc-number>
<kind>A1</kind>
<name>Ma et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2009/0019085</doc-number>
<kind>A1</kind>
<name>Abhyanker</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2009/0063536</doc-number>
<kind>A1</kind>
<name>Naaman et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2009/0143977</doc-number>
<kind>A1</kind>
<name>Beletski et al.</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2009/0257663</doc-number>
<kind>A1</kind>
<name>Luo et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2010/0002122</doc-number>
<kind>A1</kind>
<name>Larson et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34833301</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2010/0076976</doc-number>
<kind>A1</kind>
<name>Sotirov et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707737</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Towards Automatic Extraction of Event and Place Semantics from Flickr Tags Tye Rattenbury, Nathaniel Good, and Mor Naaman Yahoo! Research Berkeley Berkeley, CA, USA (tye, ngood, mor)@yahoo-inc.com.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Mapping the World's Photos David Crandall, Lars Backstrom, Daniel Huttenlocher and Jon Kleinberg Department of Computer Science Cornell University Ithaca, NY {crandall,lars,dph,kleinber}@cs.cornell.edu.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Towards Automatic Extraction of Event and Place Semantics from Flickr Tags Tye Rattenbury, Nathaniel Good &#x2020; and Mor Naaman Yahoo! Research Berkeley Berkeley, CA, USA (tye, ngood, mor)@yahoo-inc.com.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Building Realistic Mobility Models from Coarse-Grained Traces Jungkeun Yoon, Brian D. Noble, Mingyan Liu Electrical Engineering and Computer Science University of Michigan Ann Arbor, MI 48109-2122 fjkyoon, bnoble, mingyang@eecs.umich.edu Minkyong Kim Department of Computer Science Dartmouth College Hanover, NH 03755 minkyong@cs.dartmouth.edu.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Towards Automatic Extraction of Event and Place Semantics from Flickr Tags Tye Rattenbury , Nathaniel Good and Mor Naaman Yahoo! Research Berkeley Berkeley, CA, USA (tye, ngood, mor)@yahoo-inc.com.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Exploiting Location and Time for Photo Search and Storytelling in MyLifeBits Aleks Aris, Jim Gemmell and Roger Lueder Microsoft Research, San Francisco, CA, USA.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Ames et al., &#x201c;Why We Tag: Motivations for Annotation in Mobile and Online Media&#x201d;, retrived at http://www.stanford.edu/&#x2dc;morganya/research/chi2007-tagging.pdf, Apr. 28-May 3, 2007, ACM SIGCHI Conf, 10 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>Arya et al., &#x201c;Approximate Nearest Neighbor Queries in Fixed Dimensions&#x201d;, retrived at http://www.cs.umd.edu/&#x2dc;mount/Papers/soda93-ann.pdf, Proc ACM SIAM Symposium on Discrete Algorithms, Jan. 1993, 10 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>Cooper et al., &#x201c;Temporal Event Clustering for Digital Photo Collections&#x201d; ACM Trans on Multimedia Computing, Communications and Applications, vol. 1, No. 3., Apr. 2005, 23 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>&#x201c;Flickr&#x2014;Photo Sharing&#x201d;, retrived Aug. 4, 2009 at http://www.flickr.com, 1 pg.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>Giannotti et al., &#x201c;Efficient Mining of Temporally Annotated Sequences&#x201d;, retrived at http://www.siam.org/meetings/sdm06/proceedings/032giannottif.pdf on Aug. 4, 2009, Proc SIAM Conf on Data Mining, Apr. 2006, pp. 346-357.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00023">
<othercit>Jing et al., &#x201c;VirtualTour: An Online Travel Assistant Based on High Quality Images&#x201d;, Proc ACM Intl Conf on Multimedia, Oct. 23-27, 2006, 4 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00024">
<othercit>Kleinberg,&#x201c;Authoritative Sources in a Hyperlinked Environment&#x201d;, Journal of the ACM, vol. 46, No. 5, Sep. 1999, pp. 604-632.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>Loui et al., &#x201c;Automated Event Clustering and Quality Screening of Consumer Pictures for Digital Albuming&#x201d;, IEEE Transactions on Mulitmedia, vol. 5, No. 3, Sep. 2003, pp. 390-402.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Naaman et al., &#x201c;Automatic Organization for Digital Photographs with Geographic Coordinates&#x201d;, Proc Joint Conf on Digital Libraries (JCDL04), Jun. 7-11, 2004, pp. 53-62.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Naaman et al.,&#x201c;Automatically Generating Metadata for Digital Photographs with Geographic Coordinates&#x201d;, Proc 13th Intl World Wide Web Conf on Alternate Track Papers and Posters, May 17-22, 2004, pp. 244-245.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Pevzner et al.,&#x201c;A Critique and Improvement of an Evaluation Metric for Text Segmentation&#x201d;, Association for Computational Linguistics, vol. 16, No. 1, Feb. 1994, 22 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>Picasa 3, retrived at http://picasa.google.com/ on Aug. 4, 2009, 1 pg.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>Platt et al. , &#x201c;PhotoTOC: Automatic Clustering for Browsing Personal Photographs&#x201d;, Microsoft Research, Technical Report SR-TR-2002-17, Feb. 2002, retrived at http://research.microsoft.com/pubs/68922/phototoc-pacrim.pdf on Aug. 4, 2009, 5 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00031">
<othercit>Rattenbury et al., &#x201c;Methods for extracting Place Semantics from Flickr Tags&#x201d;, ACM Transatcions on the Web, Vo. 3, No. 1, Article 1, Jan. 2009, 30 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00032">
<othercit>Rattenbury et al., &#x201c;Towards Automatic Extraction of Event and Place Semantics from Flickr Tags&#x201d;, SIGIR'07, Jul. 23-27, 2007, 8 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00033">
<othercit>Torniai et al., &#x201c;Sharing, Discovering and Browsing Geotagged Pictures on the Web&#x201d;, May 2007, retrived at http://www.hpl.hp.com/personal/Steve<sub>&#x2014;</sub>Cayzer/downloads/papers/geospatial<sub>&#x2014;</sub>final<sub>&#x2014;</sub>pdf, 18 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Torpelund-Bruin et al., &#x201c;Geographic Knowledge Discovery from Geo-referenced Web 2.0&#x201d;, 2008 Intl Workshop on Education Technology and Training &#x26; 2008 Intl Workshop on Geoscience and Remote Sensing, retrived at http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&#x26;arnumber=5070363&#x26;isnumber=5070285, Dec. 2008, pp. 291-294.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Wang et al., &#x201c;Detecting Dominant Locations from Search Queries&#x201d;, retrived at http://research.microsoft.com/en-us/people/xingx/qld.pdf , Aug. 15-19, 2005, 8 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>Wikipedia, &#x201c;Paradise, Nevada&#x201d;, retrived Aug. 4, 2009 at http://en.wikipedia.org/wiki/Paradise,<sub>&#x2014;</sub>Nevada, Jun. 2009, 2 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>Yuan et al.,&#x201c;Mining GPS Traces and Visual Words for Event Classification&#x201d; retrived at http://portal.acm.org/ft<sub>&#x2014;</sub>gateway.cfm?id=1460099&#x26;type=pdf&#x26;coll=GUIDE&#x26;d1=GUIDE&#x26;CFID=46277133&#x26;CFTOKEN=38029187, Proc ACM Intl Conf on Multimedia Information Retrieval, Oct. 30-31, 2008, pp. 2-9.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>Zheng et al., &#x201c;Mining Interesting Locations and Travel Sequences from GPS Trajectories&#x201d;, Proc Intl World Wide Conf, Apr. 20-24, 2009, 10 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110066588</doc-number>
<kind>A1</kind>
<date>20110317</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Xie</last-name>
<first-name>Xing</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
<residence>
<country>CN</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Arase</last-name>
<first-name>Yuki</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Xie</last-name>
<first-name>Xing</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Arase</last-name>
<first-name>Yuki</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Lee &#x26; Hayes, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Microsoft Corporation</orgname>
<role>02</role>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Chaki</last-name>
<first-name>Kakali</first-name>
<department>2122</department>
</primary-examiner>
<assistant-examiner>
<last-name>Seck</last-name>
<first-name>Ababacar</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Techniques for reconstructing photo trip patterns from geo-tagged photos are described. Photo trip patterns are reconstructed by mining geo-tagged photos from the Web or a data storage and segmenting the photos based on at least the geographical identification information associated with the photos. Mining semantics of each photo trip pattern may also be performed using tags associated with the photos.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="228.94mm" wi="191.43mm" file="US08626699-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="209.72mm" wi="158.75mm" file="US08626699-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="250.02mm" wi="192.11mm" file="US08626699-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="241.13mm" wi="203.03mm" file="US08626699-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="242.49mm" wi="174.41mm" file="US08626699-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="250.70mm" wi="174.41mm" file="US08626699-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="233.68mm" wi="175.77mm" file="US08626699-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="235.20mm" wi="197.10mm" file="US08626699-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="250.02mm" wi="207.09mm" file="US08626699-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="197.10mm" wi="176.19mm" orientation="landscape" file="US08626699-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">The prevalence of digital image capturing devices such as digital cameras and mobile phones equipped with camera capability, coupled with increasing popularity of Web posting, allow people to post their photographs (hereinafter referred to as photos) on the Web for sharing with others. Many websites allow people to add tags to photos in order to make it relatively easy to organize and share large number of photos. Tags allow people posting photos on the Web to add contexts to photos, as people can organize the photos better as well as communicate with their friends and families with the tags. Some of these tags are considered as geo-tags and adding a geo-tag to a photo is known as geotagging.</p>
<p id="p-0003" num="0002">Geotagging is a process of adding geographical identification information, or metadata, to various media such as photos. A geo-tagged photo usually has geographical identification information including the latitudinal and longitudinal coordinates of the location where the geo-tagged photo was captured. The geographical identification information of a geo-tagged photo may be either recorded automatically by the digital image capturing device at the time the photo was captured or entered manually by a person when posting the photo on a website. Geotagging can help one to find photos taken near a given location by searching with latitudinal and longitudinal coordinates on the Web.</p>
<p id="p-0004" num="0003">Given the ever-increasing number of photos being posted on the Web, it is not easy to search and organize photos even though the photos may be geo-tagged. With a large number of photos, it is also time-consuming to organize the photos taken from a trip as a sequence of photos captured at various locations visited during the trip. Accordingly, there is an ongoing need to improve techniques for mining geo-tagged photos and reconstructing sequences of memorable moments and scenes, such as trips, from geo-tagged photos.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0005" num="0004">Techniques for reconstructing photo trip patterns from geo-tagged photos are described. One technique reconstructs photo trip patterns by mining geo-tagged photos from the Web and segmenting the photos based on at least geographical identification information associated with the photos. In other techniques, mining semantics of each photo trip pattern may also be performed using tags associated with the photos.</p>
<p id="p-0006" num="0005">This summary is provided to introduce concepts relating to mining of photo trip patterns among geo-tagged photos. These techniques are further described below in the detailed description. This summary is not intended to identify essential features of the claimed subject matter, nor is it intended for use in determining the scope of the claimed subject matter.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0007" num="0006">The detailed description is described with reference to the accompanying figures. In the figures, the left-most digit(s) of a reference number identifies the figure in which the reference number first appears. The same numbers are used throughout the drawings to reference like features and components.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an exemplary scenario of photo trips.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an exemplary geographical hierarchy of the location where a photo was captured.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an exemplary set of metadata associated with a photo.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 4</figref> illustrates an exemplary sequence of photo trips.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an exemplary segmentation of a photo collection</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. 6 through 10</figref> are flow diagrams illustrating exemplary processes for reconstructing photo trip patterns.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 11</figref> is a block diagram showing an exemplary computing device.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0015" num="0014">This disclosure describes techniques for reconstructing photo trip patterns from geo-tagged photos. As people usually take photos to record memorable moments and scenes in their life, it is possible to reconstruct a person's memorable moments from a collection of photos taken by such person based on geo-tags and timestamps associated with the photos. The techniques described below extract photo trip patterns from large scale personal geo-tagged photos posted on the Web. A photo trip may be, for example, a set of photos associated with information of cities or destinations a photo owner visited and the travel time among the cities or destinations. A photo trip pattern may be, for example, a sequence of cities or destinations a user, or photo owner, visited as well as typical travel time between among the cities or destinations and semantics of the trip. To extract photo trip patterns, a set of photos is segmented into a number of subsets of photos using algorithms involving location gaps and timestamps. Frequent photo trip patterns are then mined from these subsets of photos. Finally, semantics of photo trip patterns are extracted from tags of the photos, where the hierarchy of the tags is considered in the extraction of semantics.</p>
<p id="p-0016" num="0015">While aspects of described techniques relating to reconstruction of photo trip patterns from geo-tagged photos can be implemented in any number of different computing systems, environments, and/or configurations, embodiments are described in the context of the following exemplary system architecture(s).</p>
<p id="p-0017" num="0016">Exemplary Scenario</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an exemplary scenario <b>100</b> of photo trips during which the city <b>104</b>A (City A), city <b>104</b>B (City B), and city <b>104</b>C (City C) are visited by traveler <b>102</b>. As with any typical traveler, the traveler <b>102</b> takes, or captures, photos with his/her image capturing device <b>110</b>, such as a digital camera for example, as the traveler <b>102</b> visits each of the cities <b>104</b>A-C. While visiting the city <b>104</b>A, the traveler <b>102</b> captures a set of photos <b>106</b>A of various sites and moments in the city <b>104</b>A. While visiting the city <b>104</b>B, the traveler <b>102</b> captures an additional set of photos <b>106</b>B of various sites and moments in the city <b>104</b>B. Similarly, the traveler <b>102</b> captures another set of photos <b>106</b>C while visiting the city <b>104</b>C to record memories of various sites and moments in the city <b>104</b>C.</p>
<p id="p-0019" num="0018">Following the photo trips to the cities <b>104</b>A, <b>104</b>B, and <b>104</b>C, the traveler <b>102</b> ends up with a collection of photos that include the set of photos <b>106</b>A taken in the city <b>104</b>A, the set of photos <b>106</b>B taken in the city <b>104</b>B, and the set of photos <b>106</b>C taken in the city <b>104</b>C. The traveler <b>102</b>, who is the photo owner of a collection of photos captured during the photo trips, may decide to post some or all of these photos on the Web such as, for example, on a social networking website or a personal blog webpage. Additionally or alternatively, the traveler <b>102</b> may post some or all of these photos to data storage somewhere, such as a storage device or a computer that may not be connected to the Internet. In any case, whether the photos are posted on the Web or to data storage, techniques disclosed herein are applicable.</p>
<p id="p-0020" num="0019">It should be understood that, while cities is used in the example, other destinations, sites, or locations may be used. For example, a traveler may visit national parks in the United States like Yellowstone, Zion, and Grand Canyon. None of these sites are cities but are certainly identifiable.</p>
<p id="p-0021" num="0020">When the photo owner posts photos on the Web, the photo owner can enter user information to be associated with the photos posted. The user information may include, for example, a user identification, or user ID, and a user location, such as the location of the photo owner's residence. Since the format of the user location as entered by the photo owner may not be uniform or consistent from one photo owner to another, the techniques described in this disclosure can convert the user-entered user location to a predetermined format. For example, ambiguous user-entered locations, such as &#x201c;Seattle, WA, USA&#x201d; and &#x201c;Seattle US,&#x201d; are converted to a predetermined format, for example, as &#x201c;Seattle/Washington/United States.&#x201d; Table 1 shows an example of the user information of the photos taken by the traveler <b>102</b>.</p>
<p id="p-0022" num="0021">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Example of User Information</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="49pt" align="left"/>
<colspec colname="2" colwidth="98pt" align="left"/>
<colspec colname="3" colwidth="70pt" align="left"/>
<tbody valign="top">
<row>
<entry>Name</entry>
<entry>Description</entry>
<entry>Example</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
<row>
<entry>User ID</entry>
<entry>Unique user ID</entry>
<entry>abc123@XYZ</entry>
</row>
<row>
<entry>User location</entry>
<entry>Location entered freely by a user</entry>
<entry>Brooklyn, New York</entry>
</row>
<row>
<entry>City</entry>
<entry>Converted city name</entry>
<entry>New York</entry>
</row>
<row>
<entry>State</entry>
<entry>Converted state name</entry>
<entry>New York</entry>
</row>
<row>
<entry>Country</entry>
<entry>Converted country name</entry>
<entry>United States</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0023" num="0022">A set of users can be modeled as <img id="CUSTOM-CHARACTER-00001" he="2.79mm" wi="6.01mm" file="US08626699-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>{u}, where u is a tuple {&#x3b8;<sub>u</sub>, <img id="CUSTOM-CHARACTER-00002" he="3.56mm" wi="14.82mm" file="US08626699-20140107-P00002.TIF" alt="custom character" img-content="character" img-format="tif"/> containing a unique user ID as &#x3b8;<sub>u </sub>and the location as the scope of city/state/country as <img id="CUSTOM-CHARACTER-00003" he="3.13mm" wi="17.27mm" file="US08626699-20140107-P00003.TIF" alt="custom character" img-content="character" img-format="tif"/> respectively. It should be noted that, not all users enter their user location and, therefore, not all photos have these attributes associated therewith.</p>
<p id="p-0024" num="0023">After the photos are posted on the Web, they can be mined and photo trip patterns can be extracted to reconstruct the photo trips based on metadata associated with the photos. The metadata may be of many different types and/or formats. As one example, timestamps are a form of metadata associated with photos. As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the image capturing device <b>110</b> is equipped with a time coder <b>112</b>. As a photo is taken by the image capturing device <b>110</b>, the time coder <b>112</b> associates a timestamp to the photo to indicate the date and time when the photo was taken. A timestamp indicates temporal information related to the respective photo, such as the date (e.g., represented by the month, day, and year in any form or order) and time (e.g., represented by the hour of the day, minute of the hour, and second of the minute) the photo was captured. Unless such capability is disabled by the traveler <b>102</b>, each photo captured with the image capturing device <b>110</b> should have a timestamp associated with it.</p>
<p id="p-0025" num="0024">In addition to timestamps, geographical information is another kind of metadata that can be associated with photos. The geographical information of a photo is typically related to the location where the photo was captured. In general, there are two ways to assign geographical information to photos. One way is to use a image capturing device that automatically records the geographical information (typically represented by the latitudinal and longitudinal coordinates) of a location where a photo is captured when capturing the photo image. For example, a digital image capturing device with an internal global positioning system (GPS) receiver can record the latitude and longitude of the location where a photo is taken when capturing the photo image. Another way is to use an external GPS receiver and synchronize the recorded latitudinal and longitudinal information to photos later. Alternatively, the geographical information, which may be latitudinal and longitudinal coordinates, can be manually assigned using the interface on some photo sharing websites when posting the photos on the Web. As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the image capturing device <b>110</b> includes a GPS receiver <b>114</b>. As a photo is taken by the image capturing device <b>110</b>, the GPS receiver <b>114</b> associates geographical information of the location where the photo is taken to the photo to indicate such location.</p>
<p id="p-0026" num="0025">Manually assigned geographical information, however, tends to be less accurate than desired. For example, when manually assigning latitudinal and longitudinal coordinates to a photo, the photo owner may look at a map to determine the approximate coordinates of the city where the photo was taken. If the map has a relatively small scale, such that it shows the entire state, country, or the world for instance, then the approximate coordinates of the location where the photo was taken may not be very accurate. To compensate for the inaccuracy, the techniques represent the geographical information as a hierarchy of geographical regions, as will be described next.</p>
<p id="p-0027" num="0026">Exemplary Geographical Hierarchy</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an exemplary geographical hierarchy <b>200</b> of the location where a photo was captured. The hierarchy <b>200</b> has a plurality of levels and is derived from the geographical information associated with the photo, for example, the latitudinal and longitudinal coordinates of the location where the photo was captured. In one embodiment, the hierarchy <b>200</b> has at least two levels, consisting of a geographical region of a first level and a geographical region of a second level that encompasses the geographical region of the first level. For example, the hierarchy <b>200</b> may have a first level showing the city where the photo was captured and a second level showing the country in which the city where the photo was captured is located. In another embodiment, the hierarchy <b>200</b> has three levels, as shown in <figref idref="DRAWINGS">FIG. 2</figref>, including a first level showing the city where the photo was captured, a second level showing the state that includes the city, and a third level showing the country that includes the state. In other embodiments, there may be more levels in the hierarchy <b>200</b> such as four levels, for example, including city, county, state, and landmarks where the photo was captured.</p>
<p id="p-0029" num="0028">In the exemplary geographical hierarchy <b>200</b> shown in <figref idref="DRAWINGS">FIG. 2</figref>, the geographical region of the first level is city and includes the cities of Los Angeles, San Francisco, Seattle, and Toronto. The geographical region of the second level is state (and equivalently, provinces) and includes the states of California, which encompasses Los Angeles and San Francisco, and Washington, which encompasses Seattle, as well as the province of Ontario, which encompasses Toronto. The geographical region of the third level is country, or nation, and includes the countries of United States, which encompasses California and Washington, and Canada, which encompasses Ontario. In one embodiment, the hierarchy <b>200</b> is derived from the latitudinal and longitudinal coordinates of the photos taken on the photo trips by the traveler <b>102</b> regardless of whether the coordinates were obtained by an internal GPS receiver of the digital image capturing device of the traveler <b>102</b> or an external GPS receiver, or entered manually by the traveler <b>102</b>.</p>
<p id="p-0030" num="0029">There are various ways to convert the latitude and longitude of a photo into a hierarchical representation of the location where the photo was captured. In one embodiment, a nearest-neighbor searching algorithm is used to extract the nearest city within a distance threshold of the latitudinal and longitudinal coordinates associated with the photo. Given a set of data points in a d-dimensional space, the algorithm detects the k nearest points of a query point, such as the location where the photo was captured as indicated by its latitudinal and longitudinal coordinates. The distance between two points can be defined in a number of ways, including Euclidean distance and Manhattan distance for example. In one embodiment, the nearest neighbor from the latitudinal and longitudinal coordinates of a photo is identified from a set of centers of cities in a 2-dimensional space. That is, the city with the shortest distance between the latitude/longitude of the city center and the latitude/longitude of the photo is identified as the nearest city.</p>
<p id="p-0031" num="0030">Exemplary Set of Metadata</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an exemplary set of metadata <b>300</b> associated with a photo posted on the Web. In one embodiment, the set of metadata <b>300</b> includes a unique photo ID <b>302</b> associated with the photo, a user ID <b>304</b> of the photo owner, a timestamp <b>306</b> of the date and time of when the photo was captured, latitude/longitude <b>308</b> of the location where the photo was captured, and a tag <b>310</b> having semantics describing the location where the photo was captured. In other embodiments, the set of metadata <b>300</b> may include other data fields or elements that together form the metadata <b>300</b> such as, for example, elevation, user's impression, etc. Semantics associated with photos may include description of places and landmarks to see when visiting locations, representative activities that people expect to enjoy during the trip, and/or feelings attached to the places visited. For example, trip semantics for Sydney, Australia can include &#x201c;Opera House,&#x201d; &#x201c;Harbor Bridge,&#x201d; and &#x201c;Diving.&#x201d; In another embodiment, the set of metadata <b>300</b> further includes the geographical hierarchy of the location where the photo was captured. With a three-level hierarchy, the set of metadata <b>300</b> further includes, for example, the city, state, and country associated with the latitudinal and longitudinal coordinates of the location where the photo was captured.</p>
<p id="p-0033" num="0032">In one embodiment, a set of photos is modeled as <img id="CUSTOM-CHARACTER-00004" he="3.13mm" wi="5.25mm" file="US08626699-20140107-P00004.TIF" alt="custom character" img-content="character" img-format="tif"/>{p}, where p is defined as a tuple (&#x3b8;<sub>p</sub>, t<sub>p</sub>, u<sub>p</sub>, &#x3b4;<sub>p</sub>, &#x3bb;<sub>p</sub>, <img id="CUSTOM-CHARACTER-00005" he="3.89mm" wi="14.48mm" file="US08626699-20140107-P00005.TIF" alt="custom character" img-content="character" img-format="tif"/> containing a unique photo ID as &#x3b8;<sub>p</sub>, captured time as t<sub>p</sub>, unique user ID as the photo owner as u<sub>p</sub>, and the latitude/longitude of the location where the photo was captured as &#x3b4;<sub>p</sub>/&#x3bb;<sub>p</sub>, also represented in the form of city/state/country as <img id="CUSTOM-CHARACTER-00006" he="3.13mm" wi="13.04mm" file="US08626699-20140107-P00006.TIF" alt="custom character" img-content="character" img-format="tif"/> respectively. Based on this definition, each user's photo collection is denoted as <img id="CUSTOM-CHARACTER-00007" he="3.13mm" wi="10.58mm" file="US08626699-20140107-P00007.TIF" alt="custom character" img-content="character" img-format="tif"/> where all of the photos <img id="CUSTOM-CHARACTER-00008" he="3.13mm" wi="11.60mm" file="US08626699-20140107-P00008.TIF" alt="custom character" img-content="character" img-format="tif"/> satisfy the constraint of u<sub>p</sub>=&#x3b8;<sub>u </sub>and are sorted in chronological order. That is, <img id="CUSTOM-CHARACTER-00009" he="2.46mm" wi="4.91mm" file="US08626699-20140107-P00009.TIF" alt="custom character" img-content="character" img-format="tif"/> can be regarded as a spatial and temporal sequence. In addition, a set of the user's photos captured in a city <img id="CUSTOM-CHARACTER-00010" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00010.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>i </sub>is denoted as <img id="CUSTOM-CHARACTER-00011" he="3.13mm" wi="14.82mm" file="US08626699-20140107-P00011.TIF" alt="custom character" img-content="character" img-format="tif"/></p>
<p id="p-0034" num="0033">In one embodiment, tags associated with the photos of a set of photos are modeled separately from the photos. In one embodiment, the variable l denotes a tag and <img id="CUSTOM-CHARACTER-00012" he="2.46mm" wi="2.12mm" file="US08626699-20140107-P00012.TIF" alt="custom character" img-content="character" img-format="tif"/> denotes the set of all tags. Each photo can have multiple tags and each tag is often assigned to multiple photos. For example, a photo of the city London can have multiple tags such as &#x201c;London,&#x201d; &#x201c;shopping,&#x201d; and &#x201c;Big Ben.&#x201d; Similarly, the tag &#x201c;sunny&#x201d; can be assigned to, or associated with, a number of photos such as photos taken in Los Angeles, Barcelona, and Sydney. In one embodiment, the notation <img id="CUSTOM-CHARACTER-00013" he="2.79mm" wi="3.13mm" file="US08626699-20140107-P00013.TIF" alt="custom character" img-content="character" img-format="tif"/> is used to denote the set of tags that appear in any subset <img id="CUSTOM-CHARACTER-00014" he="2.79mm" wi="10.24mm" file="US08626699-20140107-P00014.TIF" alt="custom character" img-content="character" img-format="tif"/> of a set of photos. The subset of photos associated with a specific tag is denoted as <img id="CUSTOM-CHARACTER-00015" he="2.79mm" wi="10.92mm" file="US08626699-20140107-P00015.TIF" alt="custom character" img-content="character" img-format="tif"/> Accordingly, photos with the tag l in a subset <img id="CUSTOM-CHARACTER-00016" he="2.46mm" wi="3.89mm" file="US08626699-20140107-P00016.TIF" alt="custom character" img-content="character" img-format="tif"/> of <img id="CUSTOM-CHARACTER-00017" he="2.46mm" wi="2.46mm" file="US08626699-20140107-P00017.TIF" alt="custom character" img-content="character" img-format="tif"/> are denoted as <img id="CUSTOM-CHARACTER-00018" he="2.46mm" wi="3.56mm" file="US08626699-20140107-P00018.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>,l</sub>. In addition, the notation <img id="CUSTOM-CHARACTER-00019" he="3.13mm" wi="4.57mm" file="US08626699-20140107-P00019.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>l </sub>is used to denote the set of users associated with photos in <img id="CUSTOM-CHARACTER-00020" he="2.79mm" wi="2.46mm" file="US08626699-20140107-P00020.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>s,l</sub>, and <img id="CUSTOM-CHARACTER-00021" he="3.13mm" wi="3.89mm" file="US08626699-20140107-P00021.TIF" alt="custom character" img-content="character" img-format="tif"/> denotes the set of all users associated with photos in <img id="CUSTOM-CHARACTER-00022" he="2.46mm" wi="3.89mm" file="US08626699-20140107-P00022.TIF" alt="custom character" img-content="character" img-format="tif"/></p>
<p id="p-0035" num="0034">Exemplary Sequence of Photo Trips</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 4</figref> illustrates an exemplary sequence of photo trips <b>400</b> of a user. As shown in <figref idref="DRAWINGS">FIG. 4</figref>, the sequence of photo trips <b>400</b> includes a first photo trip <b>410</b>A, a second photo trip <b>410</b>B, and a third photo trip <b>410</b>C. Two cities, city <b>402</b> and city <b>404</b>, were visited on the first photo trip <b>410</b>A. One city, city <b>406</b>, was visited on the second photo trip <b>410</b>B. One city, city <b>408</b>, was visited on the third photo trip <b>410</b>C. Photos were taken in each of the cities <b>402</b>, <b>404</b>, <b>406</b>, and <b>408</b>, and there are tags associated with these photos. A set of tags <b>412</b> is associated with the set of photos taken in city <b>402</b>, a set of tags <b>414</b> is associated with the set of photos taken in city <b>404</b>, a set of tags <b>416</b> is associated with the set of photos taken in city <b>406</b>, and a set of tags <b>418</b> is associated with the set of photos taken in city <b>408</b>.</p>
<p id="p-0037" num="0036">In one embodiment, a photo trip is defined by the expression <img id="CUSTOM-CHARACTER-00023" he="2.46mm" wi="2.46mm" file="US08626699-20140107-P00023.TIF" alt="custom character" img-content="character" img-format="tif"/>T=(<img id="CUSTOM-CHARACTER-00024" he="3.13mm" wi="2.79mm" file="US08626699-20140107-P00024.TIF" alt="custom character" img-content="character" img-format="tif"/> T, <img id="CUSTOM-CHARACTER-00025" he="3.13mm" wi="8.13mm" file="US08626699-20140107-P00025.TIF" alt="custom character" img-content="character" img-format="tif"/> Here, <img id="CUSTOM-CHARACTER-00026" he="2.79mm" wi="2.12mm" file="US08626699-20140107-P00026.TIF" alt="custom character" img-content="character" img-format="tif"/>=(<img id="CUSTOM-CHARACTER-00027" he="3.13mm" wi="4.23mm" file="US08626699-20140107-P00027.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00028" he="3.13mm" wi="4.23mm" file="US08626699-20140107-P00028.TIF" alt="custom character" img-content="character" img-format="tif"/> denotes the sequence of cities users visited, T=(T<sub>1</sub>, . . . , T<sub>n&#x2212;1</sub>) denotes the sequence of travel time between two consecutive cities, and <img id="CUSTOM-CHARACTER-00029" he="2.46mm" wi="2.79mm" file="US08626699-20140107-P00029.TIF" alt="custom character" img-content="character" img-format="tif"/>=<img id="CUSTOM-CHARACTER-00030" he="3.13mm" wi="6.01mm" file="US08626699-20140107-P00030.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00031" he="3.56mm" wi="6.35mm" file="US08626699-20140107-P00031.TIF" alt="custom character" img-content="character" img-format="tif"/> and <img id="CUSTOM-CHARACTER-00032" he="2.46mm" wi="2.46mm" file="US08626699-20140107-P00032.TIF" alt="custom character" img-content="character" img-format="tif"/>=<img id="CUSTOM-CHARACTER-00033" he="3.13mm" wi="6.01mm" file="US08626699-20140107-P00033.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00034" he="3.13mm" wi="6.35mm" file="US08626699-20140107-P00034.TIF" alt="custom character" img-content="character" img-format="tif"/> denote the set of photos captured in the visited cities and the tags assigned to the photos, respectively, as shown in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0038" num="0037">As will be further described in detail below, the techniques disclosed herein mine frequent photo trip patterns as a frequently visited set of cities and the associated typical transition times among cities, as well as characteristic tags that represent the trip semantics. More specifically, a proposed photo trip pattern mining technique first segments a collection of photos from a number of users into a number of subsets of photos representing a number of photo trips. Photo trip patterns are then extracted from the subsets of photos. Further, trip semantics are extracted by mining tags associated with photos taken in the cities of frequent photo trip patterns.</p>
<p id="p-0039" num="0038">As an example, a collection of photos is denoted as <img id="CUSTOM-CHARACTER-00035" he="2.79mm" wi="3.13mm" file="US08626699-20140107-P00035.TIF" alt="custom character" img-content="character" img-format="tif"/> with user information <img id="CUSTOM-CHARACTER-00036" he="2.46mm" wi="2.46mm" file="US08626699-20140107-P00036.TIF" alt="custom character" img-content="character" img-format="tif"/> and a set of tags <img id="CUSTOM-CHARACTER-00037" he="2.79mm" wi="2.12mm" file="US08626699-20140107-P00037.TIF" alt="custom character" img-content="character" img-format="tif"/> associated with <img id="CUSTOM-CHARACTER-00038" he="2.46mm" wi="2.79mm" file="US08626699-20140107-P00038.TIF" alt="custom character" img-content="character" img-format="tif"/> A parameter determining the balance between captured time and distance gap is denoted as &#x3b1;, a minimum support is denoted as s<sub>min</sub>, and a temporal threshold is denoted as &#x3c4;. Accordingly, given a set of photo collections <img id="CUSTOM-CHARACTER-00039" he="3.56mm" wi="12.70mm" file="US08626699-20140107-P00039.TIF" alt="custom character" img-content="character" img-format="tif"/> the segmentation of the collection of photos can be expressed as <img id="CUSTOM-CHARACTER-00040" he="2.79mm" wi="2.46mm" file="US08626699-20140107-P00040.TIF" alt="custom character" img-content="character" img-format="tif"/>T=PhotoCollectionSegmentation<img id="CUSTOM-CHARACTER-00041" he="3.56mm" wi="8.47mm" file="US08626699-20140107-P00041.TIF" alt="custom character" img-content="character" img-format="tif"/> &#x3b1;), the mined photo trip patterns can be expressed as <img id="CUSTOM-CHARACTER-00042" he="2.79mm" wi="2.79mm" file="US08626699-20140107-P00042.TIF" alt="custom character" img-content="character" img-format="tif"/>=TripPatternMining(<img id="CUSTOM-CHARACTER-00043" he="2.79mm" wi="2.46mm" file="US08626699-20140107-P00043.TIF" alt="custom character" img-content="character" img-format="tif"/>T, s<sub>min</sub>, &#x3c4;), and the identification of trip semantics can be expressed as TripSemanticIdentification<img id="CUSTOM-CHARACTER-00044" he="3.56mm" wi="9.14mm" file="US08626699-20140107-P00044.TIF" alt="custom character" img-content="character" img-format="tif"/></p>
<p id="p-0040" num="0039">Exemplary Photo Collection Segmentation</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an exemplary segmentation of a photo collection <b>500</b>. As shown in <figref idref="DRAWINGS">FIG. 5</figref>, the photo collection <b>500</b> is segmented into three segments: segment <b>1</b>, segment <b>2</b>, and segment <b>3</b>. Each segment corresponds to a photo trip and each segment corresponds to a subset of photos from the photo collection <b>500</b> being segmented. In the sample shown, segment <b>1</b> corresponds to photo trip <b>1</b>, during which the cities of Los Angeles and San Francisco were visited. Segment <b>2</b> corresponds to photo trip <b>2</b>, during which the city of Seattle was visited. Segment <b>3</b> corresponds to photo trip <b>3</b>, during which the city of Toronto was visited. The transition time gap between Los Angeles and San Francisco is 3 days, and the location gap, or distance, is 382 miles. The transition time gap between the trip to San Francisco and the trip to Seattle is 25 days, and the location gap is 820 miles. The transition time gap between the trip to Seattle and the trip to Toronto is 7 days, and the location gap is 2,586 miles.</p>
<p id="p-0042" num="0041">In one embodiment, the photo collection <b>500</b> is segmented based on just the geographical information (e.g., the latitudinal and longitudinal coordinates) associated with the photos. In an alternative embodiment, the photo collection <b>500</b> is segmented based on both the temporal information (e.g., timestamps) and geographical information associated with the photos. In the interest of brevity, only the embodiment using both temporal and geographical information to segment the photo collection will be described below.</p>
<p id="p-0043" num="0042">When segmenting a photo collection based on temporal information, photos in the collection are first sorted chronologically into a list of photos according to the timestamps. If g<sub>i </sub>is defined as the captured time difference between photo p<sub>i </sub>and photo p<sub>i+1 </sub>in the sorted list of photos, then g<sub>N </sub>is considered a gap between events if it is much longer than a local log gap average as expressed by Equation (1) below.</p>
<p id="p-0044" num="0043">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>log</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <msub>
              <mi>g</mi>
              <mi>N</mi>
            </msub>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>&#x2265;</mo>
        <mrow>
          <mi>K</mi>
          <mo>+</mo>
          <mrow>
            <mrow>
              <mn>1</mn>
              <mo>/</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mrow>
                    <mn>2</mn>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.3em" height="0.3ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>d</mi>
                  </mrow>
                  <mo>+</mo>
                  <mn>1</mn>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>*</mo>
            <mrow>
              <munderover>
                <mo>&#x2211;</mo>
                <mrow>
                  <mi>i</mi>
                  <mo>=</mo>
                  <mrow>
                    <mo>-</mo>
                    <mi>d</mi>
                  </mrow>
                </mrow>
                <mi>d</mi>
              </munderover>
              <mo>&#x2062;</mo>
              <mrow>
                <mi>log</mi>
                <mo>&#x2061;</mo>
                <mrow>
                  <mo>(</mo>
                  <msub>
                    <mi>g</mi>
                    <mrow>
                      <mi>N</mi>
                      <mo>+</mo>
                      <mi>i</mi>
                    </mrow>
                  </msub>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0045" num="0044">Here, K is a suitable threshold, and d is a window size. If N+i refers to a photo beyond the end of the collection, the term is ignored, and the denominator 2d+1 is decremented for every ignored term to keep the average normalized.</p>
<p id="p-0046" num="0045">When segmenting a photo collection based on geographical information, photos in the collection that were captured in the same city as the user's city are separated out, since it is apparent that there exists a change of trips from one trip to another. For example, the separation is performed according to the expression <img id="CUSTOM-CHARACTER-00045" he="3.13mm" wi="15.16mm" file="US08626699-20140107-P00045.TIF" alt="custom character" img-content="character" img-format="tif"/> (<img id="CUSTOM-CHARACTER-00046" he="2.79mm" wi="3.56mm" file="US08626699-20140107-P00046.TIF" alt="custom character" img-content="character" img-format="tif"/>=<img id="CUSTOM-CHARACTER-00047" he="3.13mm" wi="3.56mm" file="US08626699-20140107-P00047.TIF" alt="custom character" img-content="character" img-format="tif"/>). Afterwards, noticeable gaps of transition times and noticeable distances between consecutive cities are detected and used to segment the rest of the photos. The transition times and distances of city <img id="CUSTOM-CHARACTER-00048" he="2.79mm" wi="3.13mm" file="US08626699-20140107-P00048.TIF" alt="custom character" img-content="character" img-format="tif"/> and <img id="CUSTOM-CHARACTER-00049" he="2.79mm" wi="2.12mm" file="US08626699-20140107-P00049.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>+1 </sub>as the gap between captured time and locations of the last photo of <img id="CUSTOM-CHARACTER-00050" he="2.79mm" wi="8.13mm" file="US08626699-20140107-P00050.TIF" alt="custom character" img-content="character" img-format="tif"/> p<sub>last </sub>and the first photo of <img id="CUSTOM-CHARACTER-00051" he="2.46mm" wi="9.14mm" file="US08626699-20140107-P00051.TIF" alt="custom character" img-content="character" img-format="tif"/> p<sub>init</sub>. The transition time gap and location gap are calculated based on Equations (2) and (3), respectively, below.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>time[hour]=<i>t</i><sub>pinit</sub><i>&#x2212;t</i><sub>plast</sub>&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>distance[km]=<i>D</i>&#xb7;&#x3c6; where&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x3c6;[rad]=2&#xb7;arcsin {sqrt[sin<sup>2</sup>(&#x394;&#x3b4;/2)+cos(&#x3b4;<sub>plast</sub>)&#xb7;cos(&#x3b4;<sub>pinit</sub>)&#xb7;sqrt[sin<sup>2</sup>(&#x394;&#x3bb;/2)]}&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0047" num="0046">Here, &#x3b4;<sub>plast </sub>and &#x3b4;<sub>pinit </sub>at are the latitudes of p<sub>last </sub>and p<sub>init</sub>, &#x394;&#x3b4; and &#x394;&#x3bb; are the differences of latitude and longitude of these photos, respectively, and D is radius of the earth, for example, 6,370 km. By defining &#x3b1; as a parameter to balance the effects of transition time gap and location gap, the g<sub>N </sub>in Equation (1) can be expresses as Equation (5) below.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>g</i><sub>N</sub>=&#x3b1;&#xb7;time[hour]+(1&#x2212;&#x3b1;)&#xb7;distance[km]&#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0048" num="0047">A gap is considered a change of trips when it is much larger than a local gap average. The collection of photos is segmented accordingly. For instance, in <figref idref="DRAWINGS">FIG. 5</figref>, the photo collection <b>500</b> is segmented into photo trip <b>1</b>, photo trip <b>2</b>, and photo trip <b>3</b>. The segmentation is based on both the location gap, or distance, and the transition time gap among the locations or cities visited. Between photo trip <b>1</b> and photo trip <b>2</b>, the transition time gap is 25 days and the location gap is 820 miles. Between photo trip <b>2</b> and photo trip <b>3</b>, the transition time gap is 7 days and the location gap is 2,586 miles. With photo trip <b>1</b>, the transition time gap between Los Angeles and San Francisco is 3 days and the location gap is 382 miles. By adjusting the parameter &#x3b1;, results of segmentation may change accordingly. For example, the same photo collection <b>500</b> may be segmented into four photo trips with the trip to Los Angeles being identified as one trip, and the trip to San Francisco being identified as another separate trip.</p>
<p id="p-0049" num="0048">Following segmentation of the photo collection, frequent photo trip patterns are identified. In one embodiment, a mining algorithm known as Temporary Annotated Sequence (TAS) is used to mine, or identify, photo trip patterns since a sequence of cities annotated with transition times in a photo trip can be regarded as a temporary annotated sequence. In other embodiments, mining algorithms other than TAS are employed to extract photo trip patterns. TAS is an extension of sequential patterns that enrich sequences with information about the typical transition times between elements of the sequences, expresses as follows:</p>
<p id="p-0050" num="0049"><chemistry id="CHEM-US-00001" num="00001">
<img id="EMI-C00001" he="5.59mm" wi="47.41mm" file="US08626699-20140107-C00001.TIF" alt="embedded image" img-content="chem" img-format="tif"/>
</chemistry>
</p>
<p id="p-0051" num="0050">Similar to traditional sequential pattern mining, the notion of frequency is based on the notion of support of a TAS, which is defined as the number of input sequences that contain the TAS. The key notion of containment can be determined as Definition: &#x3c4;-containment<img id="CUSTOM-CHARACTER-00052" he="2.79mm" wi="3.56mm" file="US08626699-20140107-P00052.TIF" alt="custom character" img-content="character" img-format="tif"/> Given a time threshold &#x3c4;, a TAS is &#x3c4;-contained (or occurs) in an input sequence I=<img id="CUSTOM-CHARACTER-00053" he="3.56mm" wi="2.79mm" file="US08626699-20140107-P00053.TIF" alt="custom character" img-content="character" img-format="tif"/>I<sub>1</sub>, &#x3c4;<sub>1</sub><img id="CUSTOM-CHARACTER-00054" he="3.56mm" wi="2.12mm" file="US08626699-20140107-P00054.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . <img id="CUSTOM-CHARACTER-00055" he="3.56mm" wi="1.44mm" file="US08626699-20140107-P00055.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>m</sub>, &#x3c4;<sub>m</sub><img id="CUSTOM-CHARACTER-00056" he="3.56mm" wi="2.79mm" file="US08626699-20140107-P00056.TIF" alt="custom character" img-content="character" img-format="tif"/> denoted as T<img id="CUSTOM-CHARACTER-00057" he="2.79mm" wi="3.56mm" file="US08626699-20140107-P00057.TIF" alt="custom character" img-content="character" img-format="tif"/>I, if and only if there exists a sequence of integers 1&#x2266;i<sub>1</sub>&#x3c; . . . &#x3c;i<sub>n</sub>&#x2266;m such that:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><sup> <o ostyle="single">v</o></sup>1<i>&#x2266;k&#x2266;n. s</i><sub>k</sub><i><u style="single">&#x2282;</u>I</i><sub>ik</sub>&#x2003;&#x2003;1.<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><sup> <o ostyle="single">v</o></sup>2<i>&#x2266;k&#x2266;n. |&#x3b1;</i><sub>k</sub>&#x2212;&#x3b1;&#x2032;<sub>k</sub>|&#x2266;&#x3c4;&#x2003;&#x2003;2.<?in-line-formulae description="In-line Formulae" end="tail"?>
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0051">where <sup> <o ostyle="single">v</o></sup>2&#x2266;k&#x2266;n. &#x3b1;&#x2032;<sub>k</sub>=T<sub>ik</sub>&#x2212;T<sub>ik&#x2212;1 </sub></li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0052" num="0052">Essentially, a TAS T is contained into an input sequence I if there is an occurrence of T in I (condition 1) having transition times similar to the annotations in T in terms of the threshold &#x3c4; (condition 2). An example of &#x3c4;-containment is as follows:</p>
<p id="p-0053" num="0053"><chemistry id="CHEM-US-00002" num="00002">
<img id="EMI-C00002" he="23.62mm" wi="96.18mm" file="US08626699-20140107-C00002.TIF" alt="embedded image" img-content="chem" img-format="tif"/>
</chemistry>
</p>
<p id="p-0054" num="0054">In this example, TAS T is a photo trip visiting Rome at first and moving to Florence 5 days later, finally arriving in Venice after staying 8 days in Florence. The sequence in T occurs in I, possibly including visit to Pisa instead of Florence and possibly including Milano between Florence/Pisa and Venice. The transition times of the occurrence differ at most of 2 time units (days) between T and I. Therefore, if &#x3c4;&#x2267;2, we have that T<img id="CUSTOM-CHARACTER-00058" he="2.79mm" wi="3.56mm" file="US08626699-20140107-P00058.TIF" alt="custom character" img-content="character" img-format="tif"/>I.</p>
<p id="p-0055" num="0055">TAS mining extracts frequent sets of TAS that are contained in at least s<sub>min </sub>input sequences with the condition of threshold &#x3c4; regarding the transition time, where s<sub>min </sub>is a minimum support threshold provided by the user. As TAS mining is performed on photo trips, e.g., a set of segmented city sequences annotated with transition times (<img id="CUSTOM-CHARACTER-00059" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00059.TIF" alt="custom character" img-content="character" img-format="tif"/>, T), frequent city sequences and the associated transition times among the cities are resultantly extracted as frequent photo trip patterns. However, although the TAS mining algorithm can detect frequent TAS, it cannot determine each pattern's semantics. It is thus difficult to interpret what people can expect from these trip patterns. Therefore, in some embodiments, semantics of frequent photo trip patterns are mined, or identified, based on tags assigned to photos captured in cities of frequent photo trip patterns.</p>
<p id="p-0056" num="0056">In one embodiment, mining of semantics is based on the term frequency/inverse document frequency (TF/IDF) technique. An assumption is that tags that are primarily associated with the cities of a photo trip pattern but are not associated with other cities are more representative of the identified patterns. Here, one of the characteristics of the mined dataset is that tags have a hierarchy such that tags can be associated with the various levels of the geographical hierarchy, e.g., city/state/country. As the mined dataset contains tags from photos from all over the world, a rather large set of data, elements of the traditional TF/IDF calculation are modified in mining the semantics as described below.</p>
<p id="p-0057" num="0057">Each tag l used in a set of cities <img id="CUSTOM-CHARACTER-00060" he="2.79mm" wi="2.12mm" file="US08626699-20140107-P00060.TIF" alt="custom character" img-content="character" img-format="tif"/> in a photo trip pattern is scored, as l&#x3b5;<img id="CUSTOM-CHARACTER-00061" he="3.13mm" wi="4.23mm" file="US08626699-20140107-P00061.TIF" alt="custom character" img-content="character" img-format="tif"/> according to the following factors: term frequency tf, inverse document frequency idf, and user frequency uf. The term frequency tf for a given tag l used in a set of cities <img id="CUSTOM-CHARACTER-00062" he="2.79mm" wi="2.12mm" file="US08626699-20140107-P00060.TIF" alt="custom character" img-content="character" img-format="tif"/> in a photo trip pattern is defined as the count of the number of times l was assigned for photos captured in those cities, expressed as tf(C, l)<img id="CUSTOM-CHARACTER-00063" he="3.13mm" wi="1.44mm" file="US08626699-20140107-P00062.TIF" alt="custom character" img-content="character" img-format="tif"/>|<img id="CUSTOM-CHARACTER-00064" he="2.79mm" wi="4.23mm" file="US08626699-20140107-P00063.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>l</sub>| where C=(<img id="CUSTOM-CHARACTER-00065" he="3.13mm" wi="3.89mm" file="US08626699-20140107-P00064.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00066" he="2.79mm" wi="3.56mm" file="US08626699-20140107-P00065.TIF" alt="custom character" img-content="character" img-format="tif"/>). The inverse document frequency idf for a tag l computes the overall ratio of the tag l among all photos under consideration. To obtain a meaningful value of the inverse document frequency idf for a tag l in the cities, the scope under consideration should be limited. Without this limitation, it is very difficult to filter out locally common tags, since the dataset includes photos from the entire the world and the granularity of the inverse document frequency based on this data can be too large. For example, one of the common tags used in Paris is &#x201c;concert&#x201d; while it is not so common on a worldwide basis. Thus, the inverse document frequency based on the whole dataset cannot filter out such locally common tags.</p>
<p id="p-0058" num="0058">With respect to the hierarchy of geographical regions in the metadata associated with the photos, the relationship of the levels for a three-level hierarchy is defined as <img id="CUSTOM-CHARACTER-00067" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00066.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x2282;<img id="CUSTOM-CHARACTER-00068" he="3.13mm" wi="2.79mm" file="US08626699-20140107-P00067.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x2282;<img id="CUSTOM-CHARACTER-00069" he="2.79mm" wi="4.57mm" file="US08626699-20140107-P00068.TIF" alt="custom character" img-content="character" img-format="tif"/> where (<img id="CUSTOM-CHARACTER-00070" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00069.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x3b5;<img id="CUSTOM-CHARACTER-00071" he="3.13mm" wi="6.69mm" file="US08626699-20140107-P00070.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x3b5;<img id="CUSTOM-CHARACTER-00072" he="3.13mm" wi="7.79mm" file="US08626699-20140107-P00071.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x3b5;<img id="CUSTOM-CHARACTER-00073" he="3.13mm" wi="3.56mm" file="US08626699-20140107-P00072.TIF" alt="custom character" img-content="character" img-format="tif"/>|<sup>&#x2203;</sup>i&#x3b5;n). Therefore, the inverse document frequency idf for a tag l is modified as the overall ratio of the tag l used in a set of instances among all photos taken in the instances according to Equation (6) below.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>idf</i>(<img id="CUSTOM-CHARACTER-00074" he="3.13mm" wi="2.79mm" file="US08626699-20140107-P00073.TIF" alt="custom character" img-content="character" img-format="tif"/>,<i>l</i>)<img id="CUSTOM-CHARACTER-00075" he="2.46mm" wi="3.56mm" file="US08626699-20140107-P00074.TIF" alt="custom character" img-content="character" img-format="tif"/>|<img id="CUSTOM-CHARACTER-00076" he="3.13mm" wi="1.44mm" file="US08626699-20140107-P00075.TIF" alt="custom character" img-content="character" img-format="tif"/>|/|<img id="CUSTOM-CHARACTER-00077" he="2.46mm" wi="3.56mm" file="US08626699-20140107-P00076.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>,l</sub>|&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0059" num="0059">where <img id="CUSTOM-CHARACTER-00078" he="2.46mm" wi="2.12mm" file="US08626699-20140107-P00077.TIF" alt="custom character" img-content="character" img-format="tif"/>=(<img id="CUSTOM-CHARACTER-00079" he="3.13mm" wi="3.89mm" file="US08626699-20140107-P00078.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00080" he="2.79mm" wi="3.13mm" file="US08626699-20140107-P00079.TIF" alt="custom character" img-content="character" img-format="tif"/>|<img id="CUSTOM-CHARACTER-00081" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00080.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x2282;<img id="CUSTOM-CHARACTER-00082" he="2.79mm" wi="3.13mm" file="US08626699-20140107-P00081.TIF" alt="custom character" img-content="character" img-format="tif"/>) or (<img id="CUSTOM-CHARACTER-00083" he="3.13mm" wi="5.25mm" file="US08626699-20140107-P00082.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00084" he="3.13mm" wi="4.57mm" file="US08626699-20140107-P00083.TIF" alt="custom character" img-content="character" img-format="tif"/><img id="CUSTOM-CHARACTER-00085" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00084.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x2282;<img id="CUSTOM-CHARACTER-00086" he="2.79mm" wi="4.57mm" file="US08626699-20140107-P00085.TIF" alt="custom character" img-content="character" img-format="tif"/>)</p>
<p id="p-0060" num="0060">The inverse document frequency idf of the state level is calculated by idf(S, l)<img id="CUSTOM-CHARACTER-00087" he="2.79mm" wi="3.56mm" file="US08626699-20140107-P00086.TIF" alt="custom character" img-content="character" img-format="tif"/>|<img id="CUSTOM-CHARACTER-00088" he="3.13mm" wi="1.44mm" file="US08626699-20140107-P00087.TIF" alt="custom character" img-content="character" img-format="tif"/>|/|<img id="CUSTOM-CHARACTER-00089" he="2.79mm" wi="3.89mm" file="US08626699-20140107-P00088.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>l</sub>| where (<img id="CUSTOM-CHARACTER-00090" he="2.79mm" wi="2.46mm" file="US08626699-20140107-P00089.TIF" alt="custom character" img-content="character" img-format="tif"/>=(<img id="CUSTOM-CHARACTER-00091" he="3.13mm" wi="3.89mm" file="US08626699-20140107-P00090.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00092" he="2.79mm" wi="3.13mm" file="US08626699-20140107-P00091.TIF" alt="custom character" img-content="character" img-format="tif"/>|<img id="CUSTOM-CHARACTER-00093" he="2.79mm" wi="3.13mm" file="US08626699-20140107-P00092.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x2282;<img id="CUSTOM-CHARACTER-00094" he="3.56mm" wi="3.89mm" file="US08626699-20140107-P00093.TIF" alt="custom character" img-content="character" img-format="tif"/> while for country level it is calculated by idf(<img id="CUSTOM-CHARACTER-00095" he="3.13mm" wi="4.23mm" file="US08626699-20140107-P00094.TIF" alt="custom character" img-content="character" img-format="tif"/> l)<img id="CUSTOM-CHARACTER-00096" he="3.13mm" wi="1.44mm" file="US08626699-20140107-P00095.TIF" alt="custom character" img-content="character" img-format="tif"/>|<img id="CUSTOM-CHARACTER-00097" he="2.46mm" wi="3.89mm" file="US08626699-20140107-P00096.TIF" alt="custom character" img-content="character" img-format="tif"/>|/|<img id="CUSTOM-CHARACTER-00098" he="2.79mm" wi="4.91mm" file="US08626699-20140107-P00097.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>l</sub>| where (<img id="CUSTOM-CHARACTER-00099" he="2.79mm" wi="3.56mm" file="US08626699-20140107-P00098.TIF" alt="custom character" img-content="character" img-format="tif"/>=(<img id="CUSTOM-CHARACTER-00100" he="3.13mm" wi="4.91mm" file="US08626699-20140107-P00099.TIF" alt="custom character" img-content="character" img-format="tif"/> . . . , <img id="CUSTOM-CHARACTER-00101" he="2.79mm" wi="4.57mm" file="US08626699-20140107-P00100.TIF" alt="custom character" img-content="character" img-format="tif"/><img id="CUSTOM-CHARACTER-00102" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00101.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x2282;<img id="CUSTOM-CHARACTER-00103" he="2.79mm" wi="4.57mm" file="US08626699-20140107-P00102.TIF" alt="custom character" img-content="character" img-format="tif"/>). The hierarchy to bed used is based on the size of an instance and density of photos. If states of cities of a photo trip pattern are small or the number of tags used there is small, the algorithm can use an upper hierarchy such as countries.</p>
<p id="p-0061" num="0061">The user frequency uf with respect to a tag l accounts for the effect from the number of users who used the tag l. An assumption made is that a tag is more valuable the larger the number of different users who use that tag. More specifically, the percentage of the users who used the tag l for photos taken in a set of cities among all the users who have taken a photo in the cities is computed according to Equation (7) below.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>uf</i>(<img id="CUSTOM-CHARACTER-00104" he="3.13mm" wi="2.79mm" file="US08626699-20140107-P00103.TIF" alt="custom character" img-content="character" img-format="tif"/><i>l</i>)<img id="CUSTOM-CHARACTER-00105" he="3.13mm" wi="1.44mm" file="US08626699-20140107-P00104.TIF" alt="custom character" img-content="character" img-format="tif"/>|<img id="CUSTOM-CHARACTER-00106" he="2.79mm" wi="3.89mm" file="US08626699-20140107-P00105.TIF" alt="custom character" img-content="character" img-format="tif"/><sub>,l</sub>|/|<img id="CUSTOM-CHARACTER-00107" he="2.79mm" wi="3.89mm" file="US08626699-20140107-P00106.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0062" num="0062">A score is calculated for a tag l for a photo trip pattern based on Equation (8) below. The higher the score is the more likely the tag l is a trip semantic.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>score(<img id="CUSTOM-CHARACTER-00108" he="2.79mm" wi="2.79mm" file="US08626699-20140107-P00107.TIF" alt="custom character" img-content="character" img-format="tif"/>T,<i>l</i>)=<i>tf</i>(<img id="CUSTOM-CHARACTER-00109" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00108.TIF" alt="custom character" img-content="character" img-format="tif"/><i>l</i>)&#xb7;<i>idf</i>(<img id="CUSTOM-CHARACTER-00110" he="2.79mm" wi="2.12mm" file="US08626699-20140107-P00109.TIF" alt="custom character" img-content="character" img-format="tif"/><i>l</i>)&#xb7;<i>uf</i>(<img id="CUSTOM-CHARACTER-00111" he="3.13mm" wi="3.13mm" file="US08626699-20140107-P00110.TIF" alt="custom character" img-content="character" img-format="tif"/><i>l</i>)&#x2003;&#x2003;(8)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0063" num="0063">There are some prior art techniques for determining whether each tag has a coherent semantic of places. However, the concept of &#x201c;place&#x201d; in the context of these prior art techniques is smaller region, e.g., San Francisco Bay Area, compared to the geographical regions utilized by the techniques described in this disclosure. Moreover, prior art techniques do not consider the hierarchy of tags.</p>
<p id="p-0064" num="0064">Exemplary Processes</p>
<p id="p-0065" num="0065"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an exemplary process <b>600</b> for reconstructing photo trip patterns according to one embodiment. The process <b>600</b> (as well as other processes described below) is illustrated as a collection of blocks in a logical flow graph, which represents a sequence of operations that can be implemented in hardware, software, or a combination thereof. In the context of software, the blocks represent computer instructions that, when executed by one or more processors, perform the recited operations.</p>
<p id="p-0066" num="0066">It should be noted that the order in which the process is described is not intended to be construed as a limitation, and any number of the described process blocks can be combined in any order to implement the process, or an alternate process. Additionally, individual blocks maybe deleted from the process without departing from the spirit and scope of the subject matter described herein.</p>
<p id="p-0067" num="0067">At block <b>602</b>, a plurality of sets of metadata associated with a plurality of photos is identified. In one implementation, the sets of metadata are associated with respective groups of photos. For instance, as shown in <figref idref="DRAWINGS">FIG. 1</figref>, the sets of metadata <b>108</b> are associated with the collections of photos <b>106</b> captured at various locations. The metadata may include different information. In the described implantation, the metadata includes geographical information related to a location where the respective photo was captured. The metadata may also include a timestamp, a photo ID, a tag, etc., as shown in <figref idref="DRAWINGS">FIG. 3</figref>. At block <b>604</b>, photo trip patterns from the plurality of photos are determined based on the plurality of sets of metadata. In one implementation, each photo trip pattern is representative of a set of frequently visited locations as well as the associated typical transition times. For instance, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, photo trip patterns from the photos of the photo collection <b>500</b> are determined as photo trip <b>1</b>, photo trip <b>2</b>, and photo trip <b>3</b> based on sets of metadata such as the sets of metadata <b>108</b>.</p>
<p id="p-0068" num="0068"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an exemplary process <b>700</b> for reconstructing photo trip patterns according to one embodiment. At block <b>702</b>, a plurality of sets of metadata associated with a plurality of photos is identified. Each set of metadata is associated with a respective one of the photos and includes at least geographical information related to a location where the respective photo was captured. In one embodiment, the geographical information includes the latitudinal and longitudinal coordinates of the location where the respective photo was captured. At block <b>704</b>, the latitudinal and longitudinal coordinates related to each photo are converted into a hierarchical representation of the respective location. In one embodiment, the hierarchical representation includes at least a geographical region of a first level and a geographical region of a second level that encompasses the geographical region of the first level. For example, the latitude/longitude associated to a photo can be converted to a city, state, and country. At block <b>706</b>, photo trip patterns from the plurality of photos are determined based on the plurality of sets of metadata. Each photo trip pattern is representative of a set of frequently visited locations and the associated typical transition times.</p>
<p id="p-0069" num="0069">In one embodiment, when determining the photo trip patterns, the plurality of photos are segmented into subsets of photos based on at least the geographical information related to each of the photos. For example, the photos may be segmented based on the latitude/longitude of each photo. In one implementation, a respective location gap between the location where the respective photo was captured and a reference location is determined for each of the plurality of photos. Additionally, the photos having respective location gaps that fall within a respective threshold location gap range are grouped into a respective subset of photos.</p>
<p id="p-0070" num="0070">In an alternative embodiment, when determining the photo trip patterns, the plurality of photos are segmented into subsets of photos based on the geographical information and time information related to each of the photos. For example, besides the latitude/longitude associated with each photo, the timestamp associated with each photo is also utilized in segmenting a photo collection. In one implementation, a respective location gap between the location where the respective photo was captured and a reference location is determined for each of the plurality of photos. Additionally, for each pair of consecutively visited locations, a respective transition time gap between the last photo captured at the first location and the first photo captured at a second location that was visited after the first location. Furthermore, photos having respective location gaps that fall within a respective threshold location gap range are grouped into a respective subset of photos. In another implementation, a sequence of locations is identified as a photo trip pattern. Each location in the sequence of locations has at least one subset of photos associated therewith, and is separated from another location by a respective transition time gap that is greater than a threshold transition time gap. Moreover, semantics associated with each photo trip pattern are identified based on the respective tag associated with each of the photos.</p>
<p id="p-0071" num="0071"><figref idref="DRAWINGS">FIG. 8</figref> illustrates an exemplary process <b>800</b> as one implementation of a part of identifying semantics associated with the photo trip patterns according to one embodiment. In particular, the process <b>800</b> describes one exemplary implementation of identifying the semantics associated with the photo trip patterns. At block <b>802</b>, a term frequency is determined for each tag as a number of times the respective tag is related to photos captured in the plurality of locations. At block <b>804</b>, an inverse document frequency is determined for each tag as a ratio of a number of total photos of the plurality of photos to a number of the photos having the respective tag associated therewith. At block <b>806</b>, a user frequency is determined for each tag as a ratio of a number of photo owners who use the respective tag to describe at least one photo of the plurality of photos to a number of total photo owners of the plurality of photos. In another embodiment, the process <b>800</b> further determines a score for each tag using the respective term frequency, inverse document frequency, and user frequency at block <b>808</b>.</p>
<p id="p-0072" num="0072"><figref idref="DRAWINGS">FIG. 9</figref> illustrates an exemplary process <b>900</b> for reconstructing photo trip patterns according to one embodiment. At block <b>902</b>, a plurality of photos is segmented into subsets of photos based on geographical information and time information related to each of the photos. At block <b>904</b>, photo trip patterns are identified. Each photo trip pattern has a sequence of locations. Each location has at least one of the subsets of photos associated therewith and is separated from another location by a respective transition time gap greater than a threshold transition time gap. At block <b>906</b>, semantics associated with each photo trip pattern are identified based on tags associated with the plurality of photos. Each of the tags is associated with at least a respective one of the plurality of photos and describes the location where the respective photo was captured.</p>
<p id="p-0073" num="0073"><figref idref="DRAWINGS">FIG. 10</figref> illustrates an exemplary process <b>1000</b> as one implementation of the process <b>900</b> according to one embodiment. To segment the plurality of photos into subsets of photos, at block <b>1002</b>, a respective location gap between the location where the respective photo was captured and a reference location is determined for each of the plurality of photos. Next, at block <b>1004</b>, a respective transition time gap between the last photo captured at a first location and the first photo captured at a second location that was visited after the first location is determined for each pair of consecutively visited locations. Further, at block <b>1006</b>, the plurality of photos is grouped into subsets of photos based on the location gaps and the transition time gaps, where each subset of photos is related to a respective one of the plurality of locations. To identify the semantics associated with each photo trip pattern, at block <b>1008</b>, a term frequency is determined for each tag as a number of times the respective tag is related to photos captured in the plurality of photos. Next, at block <b>1010</b>, an inverse document frequency is determined for each tag as a ratio of a number of total photos of the plurality of photos to a number of the photos having the respective tag associated therewith. Further, at block <b>1012</b>, a user frequency is determined for each tag as a ratio of a number of photo owners who use the respective tag to describe at least one photo of the plurality of photos to a number of total photo owners of the plurality of photos.</p>
<p id="p-0074" num="0074">In an alternative embodiment, the process <b>1000</b> further extends the process <b>900</b>. At block <b>1014</b>, the latitudinal and longitudinal information included in the geographical information related to each of the photos is converted into a hierarchical representation of the location where the respective photo was captured. The hierarchical representation includes at least a geographical region of a first level and a geographical region of a second level that encompasses the geographical region of the first level.</p>
<p id="p-0075" num="0075">Exemplary Computing Device</p>
<p id="p-0076" num="0076"><figref idref="DRAWINGS">FIG. 1100</figref> illustrates a representative computing device <b>1100</b> that may implement the techniques for reconstructing photo trip patterns based on geo-tagged photos. However, it will be readily appreciated that the techniques disclosed herein may be implemented in other computing devices, systems, and environments. The computing device <b>1100</b> shown in <figref idref="DRAWINGS">FIG. 11</figref> is only one example of a computing device and is not intended to suggest any limitation as to the scope of use or functionality of the computer and network architectures.</p>
<p id="p-0077" num="0077">In at least one configuration, computing device <b>1100</b> typically includes at least one processing unit <b>1102</b> and system memory <b>1104</b>. Depending on the exact configuration and type of computing device, system memory <b>1104</b> may be volatile (such as RAM), non-volatile (such as ROM, flash memory, etc.) or some combination thereof. System memory <b>1104</b> may include an operating system <b>1106</b>, one or more program modules <b>1108</b>, and may include program data <b>1110</b>. The computing device <b>1100</b> is of a very basic configuration demarcated by a dashed line <b>1114</b>. Again, a terminal may have fewer components but may interact with a computing device that may have such a basic configuration.</p>
<p id="p-0078" num="0078">In one embodiment, the program module <b>1108</b> includes a photo trip pattern reconstruction module <b>1112</b>. The photo trip pattern reconstruction module <b>1112</b> identifies a plurality of sets of metadata associated with a plurality of photos. Each set of metadata is associated with a respective one of the photos and includes at least geographical information related to a location where the respective photo was captured. Based on the plurality sets of metadata, the photo trip pattern reconstruction module <b>1112</b> also determines photo trip patterns from the plurality of photos, where each photo trip pattern is representative of a set of visited locations and associated typical transition times. For example, the photo trip pattern reconstruction module <b>1112</b> may carry out one or more processes as described above with reference to <figref idref="DRAWINGS">FIGS. 6-10</figref>.</p>
<p id="p-0079" num="0079">Computing device <b>1100</b> may have additional features or functionality. For example, computing device <b>1100</b> may also include additional data storage devices (removable and/or non-removable) such as, for example, magnetic disks, optical disks, or tape. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. 11</figref> by removable storage <b>1116</b> and non-removable storage <b>1118</b>. Computer storage media may include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data. System memory <b>1104</b>, removable storage <b>1116</b> and non-removable storage <b>1118</b> are all examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device <b>1100</b>. Any such computer storage media may be part of the computing device <b>1100</b>. Computing device <b>1100</b> may also have input device(s) <b>1120</b> such as keyboard, mouse, pen, voice input device, touch input device, etc. Output device(s) <b>1122</b> such as a display, speakers, printer, etc. may also be included.</p>
<p id="p-0080" num="0080">Computing device <b>1100</b> may also contain communication connections <b>1124</b> that allow the device to communicate with other computing devices <b>1126</b>, such as over a network. These networks may include wired networks as well as wireless networks. Communication connections <b>1124</b> are some examples of communication media. Communication media may typically be embodied by computer readable instructions, data structures, program modules, etc.</p>
<p id="p-0081" num="0081">It is appreciated that the illustrated computing device <b>1100</b> is only one example of a suitable device and is not intended to suggest any limitation as to the scope of use or functionality of the various embodiments described. Other well-known computing devices, systems, environments and/or configurations that may be suitable for use with the embodiments include, but are not limited to personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-base systems, set top boxes, game consoles, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and/or the like.</p>
<heading id="h-0005" level="1">CONCLUSION</heading>
<p id="p-0082" num="0082">Although the subject matter has been described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as exemplary forms of implementing the claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-chemistry idref="CHEM-US-00001" cdx-file="US08626699-20140107-C00001.CDX" mol-file="US08626699-20140107-C00001.MOL"/>
<us-chemistry idref="CHEM-US-00002" cdx-file="US08626699-20140107-C00002.CDX" mol-file="US08626699-20140107-C00002.MOL"/>
<us-math idrefs="MATH-US-00001" nb-file="US08626699-20140107-M00001.NB">
<img id="EMI-M00001" he="9.14mm" wi="76.20mm" file="US08626699-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>identifying a plurality of sets of metadata associated with a plurality of photos, at least one set of metadata being associated with a respective one of the plurality of photos and including at least geographical information related to a location where the respective photo was captured; and</claim-text>
<claim-text>determining, by using a processor, photo trip patterns from the plurality of photos based at least in part on the plurality of sets of metadata, at least one photo trip pattern being representative of a set of visited locations and associated transition times, in which the set of visited locations is segmented into different trips based on a calculated gap between events, the gap between events being calculated according to a function of a transition time gap between consecutive locations, a location gap between consecutive locations, and a parameter to balance an effect on the gap between events attributable to the transition time gap and an effect on the gap between events attributable to the location gap, such that:
<claim-text>a first value of the parameter results in a first calculated gap between events;</claim-text>
<claim-text>a second value of the parameter value, different from the first value of the parameter, results in a second calculated gap between events, different from the first calculated gap between events;</claim-text>
<claim-text>the calculated gap between events represents no change of trips when the calculated gap between events is less than a threshold value; and</claim-text>
</claim-text>
</claim-text>
<claim-text>the calculated gap between events represents a change of trips when the calculated gap between events is greater than a threshold value.</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one set of metadata further includes:
<claim-text>time information related to date and time on which the respective photo was captured;</claim-text>
<claim-text>a photo identification associated with the respective photo;</claim-text>
<claim-text>a user identification associated with a photo owner by whom the respective photo was captured; and</claim-text>
<claim-text>a tag associated with the respective photo having description of the location where the photo was captured.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining photo trip patterns comprises:
<claim-text>segmenting the plurality of photos into subsets of photos based at least in part on the geographical information related to one or more of the plurality of photos.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein segmenting the plurality of photos into subsets of photos comprises:
<claim-text>determining a respective location gap between the location where the respective photo was captured and a reference location for one or more of the plurality of photos; and</claim-text>
<claim-text>grouping photos having the respective location gaps that fall within a respective threshold location gap range into a respective subset of photos.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <b>1</b>, wherein the at least one set of metadata associated with the respective one of the plurality of photos further includes time information related to date and time on which the respective photo was captured, and wherein determining photo trip patterns comprises:
<claim-text>segmenting the plurality of photos into subsets of photos based at least in part on the geographical information and the time information related to one or more of the plurality of photos.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one set of metadata associated with the respective one of the plurality of photos further includes time information related to date and time on which the respective photo was captured, and wherein determining photo trip patterns comprises:
<claim-text>determining a respective location gap between the location where the respective photo was captured and a reference location for one or more of the plurality of photos;</claim-text>
<claim-text>determining a respective transition time gap between the last photo captured at a first location and the first photo captured at a second location visited after the first location for a pair of consecutively visited locations; and</claim-text>
<claim-text>grouping the plurality of photos into subsets of photos based at least in part on the location gaps and the transition time gaps, in which one or more of the photos of the subsets of photos are related to a respective one of the plurality of locations and having a transition time gap with another subset greater than a threshold transition time gap.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein determining photo trip patterns further comprises:
<claim-text>identifying a sequence of locations as a photo trip pattern, at least one location having at least one subset of photos associated therewith and being separated from another location by a respective transition time gap greater than the threshold transition time gap.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one set of metadata associated with a respective one of the photos further includes a tag associated with the respective photo having description of the location where the photo was captured, and wherein determining photo trip patterns further comprises:
<claim-text>identifying semantics associated with the at least one photo trip pattern based at least in part on the tag associated with one or more of the plurality of photos.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein identifying semantics associated with the at least one photo trip pattern comprises:
<claim-text>determining a term frequency for the tag as a number of times the respective tag is related to photos captured in the plurality of locations;</claim-text>
<claim-text>determining an inverse document frequency for the tag as a ratio of a number of total photos of the plurality of photos to a number of the photos having the respective tag associated therewith; and</claim-text>
<claim-text>determining a user frequency for the tag as a ratio of a number of photo owners who use the respective tag to describe at least one of the plurality of photos to a number of total photo owners of the plurality of photos.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref> further comprising:
<claim-text>determining a score for the tag using the respective term frequency, inverse document frequency, and user frequency.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the location is represented by a hierarchy of geographical regions including at least a first level of geographical region and a second level of geographical region that includes the first level of geographical region, and wherein identifying semantics associated with the photo trip pattern based at least in part on the tag associated with the plurality of photos comprises identifying semantics associated with the photo trip pattern by considering tags at the first level of geographical region.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the geographical information includes latitudinal and longitudinal information of the location where the respective photo was captured.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref> further comprising:
<claim-text>converting the latitudinal and longitudinal information to a hierarchical representation of the respective location, the hierarchical representation including at least a geographical region of a first level and a geographical region of a second level that encompasses the geographical region of the first level.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the hierarchical representation of the location includes a name of a city where the respective photo was captured, a name of a state in which the city is located, and a name of a country in which the state is located.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A method comprising:
<claim-text>segmenting a plurality of photos into subsets of photos based at least in part on geographical information and time information related to the plurality of photos;</claim-text>
<claim-text>identifying, by using a processor, photo trip patterns, at least one photo trip pattern having a sequence of locations, a location of the sequence of locations having at least one of the subsets of photos associated therewith and being separated from another location based on a determination that a calculated event gap value is greater than a threshold event gap value, wherein the event gap value is calculated based on a transition time gap and a location gap, adjusted by a parameter to balance respective contributions to the event gap value by the transition time gap and the location gap; and</claim-text>
<claim-text>identifying semantics associated with the at least one photo trip pattern based at least in part on tags associated with the plurality of photos, one or more of the tags being associated with at least one of the plurality of photos and describing the location where the at least one of the plurality of photos was captured.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein segmenting a plurality of photos into subsets of photos based at least in part on geographical information and time information related to the plurality of photos comprises:
<claim-text>determining a respective location gap between the location where the respective photo was captured and a reference location for one or more of the plurality of photos;</claim-text>
<claim-text>determining a respective transition time gap between a last photo captured at a first location and a first photo captured at a second location visited after the first location for a pair of consecutively visited locations; and</claim-text>
<claim-text>grouping the plurality of photos into the subsets of photos based at least in part on the location gaps and the transition time gaps.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein identifying semantics associated with the at least one photo trip pattern based at least in part on tags associated with the plurality of photos comprises:
<claim-text>determining a term frequency for a tag as a number of times the tag is related to photos captured in the plurality of locations;</claim-text>
<claim-text>determining an inverse document frequency for the tag as a ratio of a number of total photos of the plurality of photos to a number of the photos having the tag associated therewith; and</claim-text>
<claim-text>determining a user frequency for the tag as a ratio of a number of photo owners who use the tag to describe at least one of the plurality of photos to a number of total photo owners of the plurality of photos.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> further comprising:
<claim-text>converting latitudinal and longitudinal information included in the geographical information into a hierarchical representation of the location where the respective photo was captured, the hierarchical representation including at least a geographical region of a first level and a geographical region of a second level that encompasses the geographical region of the first level.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A computer storage device storing computer-executable instructions that, when executed by one or more processors, perform acts comprising:
<claim-text>identifying a plurality of sets of metadata associated with a plurality of photos, at least one set of metadata being associated with a respective one of the photos and including at least geographical information related to a location where the respective photo was captured; and</claim-text>
<claim-text>determining photo trip patterns from the plurality of photos based at least in part on the plurality sets of metadata, at least one photo trip pattern being representative of a set of visited locations and associated typical transition times, in which the set of visited locations is segmented into different trips by comparing an event gap value to a threshold gap value, wherein the event gap value is calculated based on a transition time gap, a location gap, and a parameter to reflect a weight given to the transition time gap and a weight given to the location gap, such that a first value of the parameter results in a first event gap value, and a second value of the parameter, different from the first value of the parameter, results in a second event gap value, different from the first event gap value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The computer storage device of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the act of determining photo trip patterns from the plurality of photos based at least in part on the plurality sets of metadata comprises:
<claim-text>segmenting the plurality of photos into subsets of photos based at least in part on the geographical information related to at least one of the plurality of photos;</claim-text>
<claim-text>identifying the photo trip patterns wherein the location has at least one of the subsets of photos associated therewith; and</claim-text>
<claim-text>identifying semantics associated with the at least one photo trip pattern based at least in part on tags associated with the plurality of photos, at least one of the tags being associated with a respective one of the plurality of photos and describing the location where the respective photo was captured.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
