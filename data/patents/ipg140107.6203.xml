<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627327-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627327</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11923360</doc-number>
<date>20071024</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1584</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>46</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>13</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>718104</main-classification>
<further-classification>718102</further-classification>
<further-classification>718105</further-classification>
<further-classification>711151</further-classification>
<further-classification>711152</further-classification>
<further-classification>711158</further-classification>
</classification-national>
<invention-title id="d2e53">Thread classification suspension</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6910210</doc-number>
<kind>B1</kind>
<name>Chew</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718103</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6941437</doc-number>
<kind>B2</kind>
<name>Cook et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7080220</doc-number>
<kind>B2</kind>
<name>Dunshea et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2002/0107901</doc-number>
<kind>A1</kind>
<name>Hay</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709102</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2004/0216112</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2005/0022186</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2005/0086660</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2005/0149933</doc-number>
<kind>A1</kind>
<name>Saito et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2005/0246707</doc-number>
<kind>A1</kind>
<name>Ismail et al.</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2006/0036810</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2006/0037020</doc-number>
<kind>A1</kind>
<name>Accapadi et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2006/0280434</doc-number>
<kind>A1</kind>
<name>Suzuki et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386 83</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2007/0157207</doc-number>
<kind>A1</kind>
<name>Kim et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718103</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2007/0157210</doc-number>
<kind>A1</kind>
<name>Inoue</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718105</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2012/0240205</doc-number>
<kind>A1</kind>
<name>Casey</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>726  5</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>21</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090113433</doc-number>
<kind>A1</kind>
<date>20090430</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Dunshea</last-name>
<first-name>Andrew</first-name>
<address>
<city>Austin</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Griffith</last-name>
<first-name>Douglas James</first-name>
<address>
<city>Georgetown</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Dunshea</last-name>
<first-name>Andrew</first-name>
<address>
<city>Austin</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Griffith</last-name>
<first-name>Douglas James</first-name>
<address>
<city>Georgetown</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Yee &#x26; Associates, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Mims, Jr.</last-name>
<first-name>David A.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Al Kawsar</last-name>
<first-name>Abdullah</first-name>
<department>2195</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The exemplary embodiments provide a computer-implemented method, apparatus, and computer-usable program code for managing memory. A notice of a shortage of real memory is received. For each active thread, the thread classification of the active thread is compared to a global hierarchy of thread classifications to determine a thread to affect. The global hierarchy of thread classifications defines the relative importance of each thread classification. An action to take for the determined thread is determined. The determined action is performed for the determined thread.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="139.28mm" wi="102.02mm" file="US08627327-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="220.98mm" wi="179.32mm" file="US08627327-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="220.39mm" wi="168.66mm" file="US08627327-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="212.34mm" wi="147.24mm" file="US08627327-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates generally to data processing systems. More specifically, exemplary embodiments provide a method, computer program product and a system for managing memory in a data processing system.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">System memory is difficult to manage in applications with adhoc/variable memory requirements where the amount of memory a particular thread(s) requires is highly dependent on the complexity of the transformation or query being performed by the thread(s). For example, a SAP query, which is complex and retrieves a large data-set, may require a significantly greater amount of memory than a simple query. Large, complex data base queries are another good example of where complex transformations require very large amounts of memory.</p>
<p id="p-0006" num="0005">When a shortage of memory condition occurs, memory load control algorithms are used to suspend threads, or even kill threads, in order to free memory for other processes/threads running, avoiding a memory thrashing condition from occurring. Memory thrashing is a degraded case of swapping. Memory thrashing means that every time a process wants to use memory, the process has to swap some data out and some more data in, resulting in the data processing system running very slowly. Currently, the memory load control algorithms select threads by either randomly picking threads, or choosing threads with the greatest amount of memory allocated.</p>
<p id="p-0007" num="0006">Random selection may affect a required subsystem/component that is not predeterministic for the administration of the system. A suspension of a critical service, such as, for example, High Availability Cluster Multi-Processing (HACMP)/general parallel file system (GPFS), can, and often does, result in a complete system outage. HACMP is a product that provides fail-over capability. That is, the product allows for a second node to take over for a first, failed node. GPFS is a clustered distributed file system. Even the suspension of non-critical components can cause serious issues to the business, such as, for example, missed service level agreements (SLA's) or unacceptable response times to users.</p>
<p id="p-0008" num="0007">An alternative approach to this problem tried in the past has been to set real memory limits per process, sometimes grouped within a workload manager (WLM) class, for example. A workload manager manages resources given to applications. A WLM class is an object that encapsulates WLM definitions and associations to various applications. When an application process attempts to exceed the real memory limit, the application process is forced to page-out some of the existing pages of the application process in real memory in order to make room.</p>
<p id="p-0009" num="0008">The problem with this approach is that any paging activity can result in severe performance degradation to the system as a whole. In severe cases, paging can result in page space becoming exhausted, or system performance issues, which can lead to outages, such as, for example, a delayed heartbeat. A heartbeat refers to a mechanism that nodes uses to signal their availability between each other. For example, the nodes could send a sync pulse every few seconds to indicate that they are still up and available. Also, this approach may force a process to page, when there is free real memory available. These limits also need to be adjusted as the workload/resource changes and must assume worse case scenario when the limits are set.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">The exemplary embodiments provide a computer-implemented method, apparatus, and computer-usable program code for managing memory. A notice of a shortage of real memory is received. For each active thread, the thread classification of the active thread is compared to a global hierarchy of thread classifications to determine a thread to affect. The global hierarchy of thread classifications defines the relative importance of each thread classification. An action to take for the determined thread is determined. The determined action is performed for the determined thread.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0011" num="0010">The novel features believed characteristic of the invention are set forth in the appended claims. The invention itself, however, as well as a preferred mode of use, further objectives and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein:</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 1</figref> depicts a pictorial representation of a network of data processing systems in which illustrative embodiments may be implemented;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a data processing system in which the illustrative embodiments may be implemented;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a system for suspending a process based on a global hierarchy of thread classifications that define the relative importance of each thread classification, in accordance with an exemplary embodiment;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating the operation of establishing a global hierarchy of thread classifications that define the relative importance of each thread classification in accordance with an exemplary embodiment;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating the operation of dynamically classifying the work a thread or process is performing in accordance with an exemplary embodiment; and</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating the operation of suspending a process based on a global hierarchy of thread classifications that define the relative importance of each thread classification, in accordance with an exemplary embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
<p id="p-0018" num="0017">With reference now to the figures and in particular with reference to <figref idref="DRAWINGS">FIGS. 1-2</figref>, exemplary diagrams of data processing environments are provided in which illustrative embodiments may be implemented. It should be appreciated that <figref idref="DRAWINGS">FIGS. 1-2</figref> are only exemplary, and are not intended to assert or imply any limitation with regard to the environments in which different embodiments may be implemented. Many modifications to the depicted environments may be made.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 1</figref> depicts a pictorial representation of a network of data processing systems in which illustrative embodiments may be implemented. Network data processing system <b>100</b> is a network of computers in which the illustrative embodiments may be implemented. Network data processing system <b>100</b> contains network <b>102</b>, which is the medium used to provide communications links between various devices and computers connected together within network data processing system <b>100</b>. Network <b>102</b> may include connections, such as wire, wireless communication links, or fiber optic cables.</p>
<p id="p-0020" num="0019">In the depicted example, server <b>104</b> and server <b>106</b> connect to network <b>102</b> along with storage unit <b>108</b>. In addition, clients <b>110</b>, <b>112</b>, and <b>114</b> connect to network <b>102</b>. Clients <b>110</b>, <b>112</b>, and <b>114</b> may be, for example, personal computers or network computers. In the depicted example, server <b>104</b> provides data, such as boot files, operating system images, and applications to clients <b>110</b>, <b>112</b>, and <b>114</b>. Clients <b>110</b>, <b>112</b>, and <b>114</b> are clients to server <b>104</b> in this example. Network data processing system <b>100</b> may include additional servers, clients, and other devices not shown.</p>
<p id="p-0021" num="0020">In the depicted example, network data processing system <b>100</b> is the Internet with network <b>102</b> representing a worldwide collection of networks and gateways that use the Transmission Control Protocol/Internet Protocol (TCP/IP) suite of protocols to communicate with one another. At the heart of the Internet is a backbone of high-speed data communication lines between major nodes or host computers, consisting of thousands of commercial, governmental, educational, and other computer systems that route data and messages. Of course, network data processing system <b>100</b> also may be implemented as a number of different types of networks, such as, for example, an intranet, a local area network (A), or a wide area network (WAN). <figref idref="DRAWINGS">FIG. 1</figref> is intended as an example, and not as an architectural limitation for the different illustrative embodiments.</p>
<p id="p-0022" num="0021">With reference now to <figref idref="DRAWINGS">FIG. 2</figref>, a block diagram of a data processing system is shown in which illustrative embodiments may be implemented. Data processing system <b>200</b> is an example of a computer, such as server <b>104</b> or client <b>110</b> in <figref idref="DRAWINGS">FIG. 1</figref>, in which computer-usable program code or instructions implementing the processes may be located for the illustrative embodiments.</p>
<p id="p-0023" num="0022">In the depicted example, data processing system <b>200</b> employs a hub architecture including a north bridge and memory controller hub (NB/MCH) <b>202</b> and a south bridge and input/output (I/O) controller hub (SB/ICH) <b>204</b>. Processing unit <b>206</b>, main memory <b>208</b>, and graphics processor <b>210</b> are coupled to north bridge and memory controller hub <b>202</b>. Processing unit <b>206</b> may contain one or more processors and even may be implemented using one or more heterogeneous processor systems. Graphics processor <b>210</b> may be coupled to the NB/MCH through an accelerated graphics port (AGP), for example.</p>
<p id="p-0024" num="0023">In the depicted example, local area network (LAN) adapter <b>212</b> is coupled to south bridge and I/O controller hub <b>204</b> and audio adapter <b>216</b>, keyboard and mouse adapter <b>220</b>, modem <b>222</b>, read only memory (ROM) <b>224</b>, universal serial bus (USB) and other ports <b>232</b>, and PCI/PCIe devices <b>234</b> are coupled to south bridge and I/O controller hub <b>204</b> through bus <b>238</b>, and hard disk drive (HDD) <b>226</b> and CD-ROM <b>230</b> are coupled to south bridge and I/O controller hub <b>204</b> through bus <b>240</b>. PCI/PCIe devices may include, for example, Ethernet adapters, add-in cards, and PC cards for notebook computers. PCI uses a card bus controller, while PCIe does not. ROM <b>224</b> may be, for example, a flash binary input/output system (BIOS). Hard disk drive <b>226</b> and CD-ROM <b>230</b> may use, for example, an integrated drive electronics (IDE) or serial advanced technology attachment (SATA) interface. A super I/O (SIO) device <b>236</b> may be coupled to south bridge and I/O controller hub <b>204</b>.</p>
<p id="p-0025" num="0024">An operating system runs on processing unit <b>206</b> and coordinates and provides control of various components within data processing system <b>200</b> in <figref idref="DRAWINGS">FIG. 2</figref>. The operating system may be a commercially available operating system such as Microsoft&#xae; Windows&#xae; XP (Microsoft and Windows are trademarks of Microsoft Corporation in the United States, other countries, or both). An object oriented programming system, such as the Java&#x2122; programming system, may run in conjunction with the operating system, and provides calls to the operating system from Java&#x2122; programs or applications executing on data processing system <b>200</b>. Java&#x2122; and all Java&#x2122;-based trademarks are trademarks of Sun Microsystems, Inc. in the United States, other countries, or both.</p>
<p id="p-0026" num="0025">Instructions for the operating system, the object-oriented programming system, and applications or programs are located on storage devices, such as hard disk drive <b>226</b>, and may be loaded into main memory <b>208</b> for execution by processing unit <b>206</b>. The processes of the illustrative embodiments may be performed by processing unit <b>206</b> using computer-implemented instructions, which may be located in a memory such as, for example, main memory <b>208</b>, read only memory <b>224</b>, or in one or more peripheral devices.</p>
<p id="p-0027" num="0026">The hardware in <figref idref="DRAWINGS">FIGS. 1-2</figref> may vary depending on the implementation. Other internal hardware or peripheral devices, such as flash memory, equivalent non-volatile memory, or optical disk drives and the like, may be used in addition to or in place of the hardware depicted in <figref idref="DRAWINGS">FIGS. 1-2</figref>. Also, the processes of the illustrative embodiments may be applied to a multiprocessor data processing system.</p>
<p id="p-0028" num="0027">In some illustrative examples, data processing system <b>200</b> may be a personal digital assistant (PDA), which is generally configured with flash memory to provide non-volatile memory for storing operating system files and/or user-generated data. A bus system may be comprised of one or more buses, such as a system bus, an I/O bus and a PCI bus. Of course, the bus system may be implemented using any type of communications fabric or architecture that provides for a transfer of data between different components or devices attached to the fabric or architecture. A communications unit may include one or more devices used to transmit and receive data, such as a modem or a network adapter. A memory may be, for example, main memory <b>208</b> or a cache such as found in north bridge and memory controller hub <b>202</b>. A processing unit may include one or more processors or CPUs. The depicted examples in <figref idref="DRAWINGS">FIGS. 1-2</figref> and above-described examples are not meant to imply architectural limitations. For example, data processing system <b>200</b> also may be a tablet computer, laptop computer, or telephone device in addition to taking the form of a PDA.</p>
<p id="p-0029" num="0028">Exemplary embodiments define a global hierarchy of thread classifications that define the relative importance of each thread classification. When real memory is tightly constrained, the system uses the global thread classification hierarchy to suspend the least important processes. Exemplary embodiments thus provide a flexible and deterministic approach that can be applied when a memory shortage occurs without tuning for a worse case scenario or requiring the administrators to adjust real memory limits as either the workload or the system resource changes. The workload is used to determine the thread classification. A process can have many threads.</p>
<p id="p-0030" num="0029">Exemplary embodiments allow a thread or process to statically or dynamically classify the work the thread or process is performing. Processes can statically classify themselves, as once the process classifies the work the application is performing, the classification remains until switched. Thus, when a process changes the work the process is performing, the process classifies the new work being performed. For example, a DB2 thread when given a complex query would classify the work being performed as performing a complex query. The thread classifications could be passed either from the user process or from the worker thread actually running the query. A critical process or thread could provide a thread classification that indicates the process being performed is of critical importance to the system.</p>
<p id="p-0031" num="0030">Each individual application determines the current thread classification for the application based on what the application is doing at any particular point in time. For example, a database query could use an optimizer to determine the complexity of the query, or a large complex database query may use the transformation steps of the large complex database query to determine a thread classification for the large complex database query.</p>
<p id="p-0032" num="0031">Exemplary embodiments allow for defining the relative importance of each thread classification in comparison to the other work being performed. Thread classifications are further refined based on user identification, or, in an alternate embodiment, based on process executable. For example, an alternative consideration could be the amount of resources, such as memory, being consumed versus other processes or versus an excepted allowance. For example, the classification could give an expected amount of memory used by a process with the classification. This amount could be considered in light of the actual memory the process is using. That is, when selecting from an otherwise similar group of threads running under the same classification, the largest consumer of memory could become less favored. Additionally, exemplary embodiments provide a global default thread classification to handle any process that does not have a thread classification.</p>
<p id="p-0033" num="0032">When the system runs short of real memory and enters a state in which memory thrashing is likely to occur, the system will use the table of thread classifications to determine the order in which processes/threads should be suspended. For each thread classification, the administrator will be allowed to define the action to be taken to reduce memory, for example suspend the thread, kill the thread, or perform some other user defined option, such as, for example, run a particular script.</p>
<p id="p-0034" num="0033">The relative importance of each thread classification is defined by a set of rules generated by the system administrator. Each application or user of an application submits a list of the thread classifications that the application uses to classify work being performed. Further, a list of user identifiers and/or process executables for each application is also submitted. Based on this information, a system administrator establishes a set of rules that define which processes the system considers more important than other processes. This set of rules defines a global hierarchy of thread classifications that define the relative importance of each thread classification.</p>
<p id="p-0035" num="0034">The use of user identifications and process executables tied to the thread classifications allows for finer grained tuning of the global hierarchy of thread classifications. For example, take the case where the situation has arisen that the system needs to suspend or kill a thread because of lack of memory. Based on the global hierarchy, the system has decided that work with a thread classification of X of application Y needs to be suspended. However, there are two users of application Y currently processing work with a thread classification of X. The system then determines if one user is more important than the other user.</p>
<p id="p-0036" num="0035">For example, user <b>1</b> could be a member of the accounts department while user <b>2</b> is an employee in another department. The global hierarchy may have rules that state that users of the account department are more important then other users, so then the process belonging to user <b>2</b> would be suspended. Further, the global hierarchy may have rules further breaking the importance of a user to the individual's user level in that user A may be more important then user B because user A is a higher ranking official, such as a manager, within a company, and so on.</p>
<p id="p-0037" num="0036">Turning back to the figures, <figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a system for suspending a process based on a global hierarchy of thread classifications that define the relative importance of each thread classification, in accordance with an exemplary embodiment. System <b>300</b> comprises data processing system <b>302</b>, which may be implemented as a data processing system such as data processing system <b>200</b> in <figref idref="DRAWINGS">FIG. 2</figref>. Data processing system <b>302</b> comprises resource allocator <b>304</b>, applications <b>306</b>, <b>308</b>, <b>310</b>, and <b>312</b>, which are running on data processing system <b>302</b>, thread classification database <b>314</b> and rules database <b>316</b>, wherein the rules define a global hierarchy of thread classifications.</p>
<p id="p-0038" num="0037">Thread classification database <b>314</b> is a current record of all the active processes and the current classification of each active process. In an alternate embodiment, rules database <b>316</b> also includes instructions as to what specific actions to take if a particular process is chosen to reduce memory usage. While thread classification database <b>314</b> and rules database <b>316</b> are depicted as databases in the present exemplary embodiment, alternate embodiments encompass implementing thread classification database <b>314</b> and rules database <b>316</b> as a table or a file, or any in other suitable form.</p>
<p id="p-0039" num="0038">When applications <b>306</b>, <b>308</b>, <b>310</b>, and <b>312</b> running on data processing system <b>302</b> cause data processing system <b>302</b> to run short of real memory and enter a state in which memory thrashing is likely to occur, resource allocator <b>304</b> uses thread classification database <b>314</b> and rules database <b>316</b> to determine the order in which processes/threads of applications <b>306</b>, <b>308</b>, <b>310</b>, and <b>312</b> should be suspended.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating the operation of establishing a global hierarchy of thread classifications that define the relative importance of each thread classification in accordance with an exemplary embodiment. The steps of <figref idref="DRAWINGS">FIG. 4</figref> may be implemented in a resource allocator, such as resource allocator <b>304</b> in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0041" num="0040">The operation begins when thread classifications for applications are received (step <b>402</b>). A default thread classification is created (step <b>404</b>). The default classification serves to classify any process that, for whatever reason, is not classified by an application. The thread classifications and default classification are combined with user identifications and process executables to generate a set of rules that establishes a global hierarchy of thread classifications that define the relative importance of each thread classification to the other thread classifications (step <b>406</b>) and the process ends.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating the operation of dynamically classifying the work a thread or process is performing in accordance with an exemplary embodiment. The steps of <figref idref="DRAWINGS">FIG. 5</figref> may be implemented in a resource allocator, such as resource allocator <b>304</b> in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0043" num="0042">The operation begins when a classification for a process is received (step <b>502</b>). The thread classification for that process is then updated based on the received thread classification (step <b>504</b>) and the process ends.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating the operation of suspending a process based on a global hierarchy of thread classifications that define the relative importance of each thread classification, in accordance with an exemplary embodiment. The steps of <figref idref="DRAWINGS">FIG. 6</figref> may be implemented in a resource allocator, such as resource allocator <b>304</b> in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0045" num="0044">The operation begins when a notice is received that real memory is running short and that thrashing is likely to occur (step <b>602</b>). The operating system monitors memory usage and triggers an alarm when paging space becomes critically short. When paging space becomes critically short, the operating system begins the selection process. The operation examines all the active processes and determines, based on a global hierarchy of thread classifications, which process or processes to affect in order to reduce the memory problem and what actions to take for the selected process or processes (step <b>604</b>). The operation then performs the action indicated in the global hierarchy of thread classification for each affected process (step <b>606</b>) and the process ends.</p>
<p id="p-0046" num="0045">Exemplary embodiments define a global hierarchy of thread classifications that define the relative importance of each thread classification. When real memory is tightly constrained, the system uses the global thread classification hierarchy to suspend the least important processes. Exemplary embodiments thus provide a flexible and deterministic approach that can be applied when a memory shortage occurs without tuning for a worse case scenario or requiring the administrators to adjust real memory limits as either the workload or the system resource changes.</p>
<p id="p-0047" num="0046">The invention can take the form of an entirely hardware embodiment, an entirely software embodiment or an embodiment containing both hardware and software elements. In a preferred embodiment, the invention is implemented in software, which includes but is not limited to firmware, resident software, microcode, etc.</p>
<p id="p-0048" num="0047">Furthermore, the invention can take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description, a computer-usable or computer-readable medium can be any tangible apparatus that can contain, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device.</p>
<p id="p-0049" num="0048">The medium can be an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system (or apparatus or device) or a propagation medium. Examples of a computer-readable medium include a semiconductor or solid-state memory, magnetic tape, a removable computer diskette, a random access memory (RAM), a read-only memory (ROM), a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk-read only memory (CD-ROM), compact disk-read/write (CD-R/W) and DVD.</p>
<p id="p-0050" num="0049">Further, a computer storage medium may contain or store a computer-readable program code such that when the computer-readable program code is executed on a computer, the execution of this computer-readable program code causes the computer to transmit another computer-readable program code over a communications link. This communications link may use a medium that is, for example without limitation, physical or wireless.</p>
<p id="p-0051" num="0050">A data processing system suitable for storing and/or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code, bulk storage, and cache memories, which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.</p>
<p id="p-0052" num="0051">Input/output or I/O devices (including but not limited to keyboards, displays, pointing devices, etc.) can be coupled to the system either directly or through intervening I/O controllers.</p>
<p id="p-0053" num="0052">Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems, cable modem and Ethernet cards are just a few of the currently available types of network adapters.</p>
<p id="p-0054" num="0053">The description of the present invention has been presented for purposes of illustration and description, and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention, the practical application, and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer-implemented method for managing memory, the computer-implemented method comprising:
<claim-text>monitoring memory usage while running a plurality of applications and each individual application of the plurality of the applications comprised of a plurality of active threads;</claim-text>
<claim-text>receiving a notice of a shortage of real memory while running the plurality of applications;</claim-text>
<claim-text>establishing a global hierarchy of thread classifications for the plurality of active threads of the each individual application and a default thread classification for any process not classified by an application running on a computer;</claim-text>
<claim-text>responsive to receiving the notice, comparing, for each active thread of the plurality of applications, a thread classification of the plurality of active threads to the global hierarchy of thread classifications, wherein the global hierarchy of thread classifications defines a relative importance of each thread classification based on a classification of a process currently being performed by each active thread of the each individual application, an identification of a user performing the process and process executables, to identify a selected thread to affect, wherein the classification of the process is determined by the each individual application comprising the active threads;</claim-text>
<claim-text>determining an action to take for the selected thread to form a determined action; and</claim-text>
<claim-text>performing the determined action for the selected thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>receiving the thread classification from a thread; and</claim-text>
<claim-text>storing the thread classification for the thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The computer-implemented method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:
<claim-text>receiving a new thread classification from the thread; and</claim-text>
<claim-text>updating the thread classification for the thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>creating a default thread classification; and</claim-text>
<claim-text>receiving at least one thread classification for at least one application.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The computer-implemented method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:
<claim-text>creating the global hierarchy of thread classifications based on the default classification and the received at least one thread classification.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the thread classification is based on a workload of the thread.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determined action is to kill the determined thread.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>performing the action indicated in the global hierarchy of thread classification for each selected thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A computer program product comprising:
<claim-text>a computer-readable storage device storing computer-usable program code for managing memory, the computer program product comprising:</claim-text>
<claim-text>computer-usable program code for monitoring memory usage while running a plurality of applications and each individual application of the plurality of applications comprised of a plurality of active threads;</claim-text>
<claim-text>computer-usable program code for receiving a notice of a shortage of real memory while running the plurality of applications;</claim-text>
<claim-text>computer-usable program code for establishing a global hierarchy of thread classifications for the plurality of applications of the each individual application and a default thread classification for any process not classified by an application running on a computer;</claim-text>
<claim-text>computer-usable program code, responsive to receiving the notice, for comparing, for each active thread of the plurality of applications, a thread classification of the plurality of active threads to the global hierarchy of thread classifications, wherein the global hierarchy of thread classifications defines a relative importance of each thread classification based on a classification of a process currently being performed by each active thread of the each individual application, an identification of a user performing the process and process executables, to identify a selected thread to affect, wherein the classification of the process is determined by the each individual application comprising the active threads;</claim-text>
<claim-text>computer-usable program code for determining an action to take for the selected thread to form a determined action; and</claim-text>
<claim-text>computer-usable program code for performing the determined action for the selected thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer program product of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising:
<claim-text>computer-usable program code for receiving the thread classification from a thread; and</claim-text>
<claim-text>computer-usable program code for storing the thread classification for the thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The computer program product of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:
<claim-text>computer-usable program code for receiving a new thread classification from the thread; and</claim-text>
<claim-text>computer-usable program code for updating the thread classification for the thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The computer program product of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising:
<claim-text>computer-usable program code for creating a default thread classification; and</claim-text>
<claim-text>computer-usable program code for receiving at least one thread classification for at least one application.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer program product of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising:
<claim-text>computer-usable program code for creating the global hierarchy of thread classifications based on the default classification and the received at least one thread classification.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The computer program product of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the thread classification is based on a workload of a thread.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The computer program product of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the determined action is to kill the determined thread.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A data processing system for managing memory, the data processing system comprising:
<claim-text>a bus;</claim-text>
<claim-text>a communications unit connected to the bus;</claim-text>
<claim-text>a storage device connected to the bus, wherein the storage device includes computer-usable program code; and</claim-text>
<claim-text>a processor unit connected to the bus, wherein the processor unit executes the computer-usable program code to monitor memory usage while running a plurality of applications and each individual application of the plurality of applications comprised of a plurality of active threads;</claim-text>
<claim-text>receive a notice of a shortage of real memory while running the plurality of applications;</claim-text>
<claim-text>establish a global hierarchy of thread classifications for the plurality of active threads of the each individual application and a default thread classification for any process not classified by an application running on a computer;</claim-text>
<claim-text>responsive to receiving the notice, compare, for each active thread of the plurality of applications, a thread classification of the plurality of active threads to the global hierarchy of thread classifications, wherein the global hierarchy of thread classifications defines a relative importance of each thread classification based on a classification of a process currently being performed by each active thread of the each individual application, an identification of a user performing the process and process executables, to identify a selected thread to affect, wherein the classification of the process is determined by the each individual application comprising the active threads;</claim-text>
<claim-text>determine an action to take for the selected thread to form a determined action; and</claim-text>
<claim-text>perform the determined action for the selected thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The data processing system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the processor further executes the computer-usable program code to receive the thread classification from a thread; and
<claim-text>store the thread classification for the thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The data processing system of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the processor further executes the computer-usable program code to receive a new thread classification from the thread; and
<claim-text>update the thread classification for the thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The data processing system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the processor further executes the computer-usable program code to create a default thread classification; and
<claim-text>receive at least one thread classification for at least one application.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The data processing system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the processor further executes the computer-usable program code to create the global hierarchy of thread classifications based on the default classification and the received at least one thread classification.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The data processing system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the thread classification is based on a workload of a thread. </claim-text>
</claim>
</claims>
</us-patent-grant>
