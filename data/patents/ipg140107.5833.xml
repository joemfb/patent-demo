<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626941-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626941</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13546983</doc-number>
<date>20120711</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709231</main-classification>
<further-classification>709234</further-classification>
</classification-national>
<invention-title id="d2e43">Delivering a video stream</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5442390</doc-number>
<kind>A</kind>
<name>Hooper et al.</name>
<date>19950800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 90</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5566208</doc-number>
<kind>A</kind>
<name>Balakrishnan</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>375240</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7334078</doc-number>
<kind>B2</kind>
<name>Parry et al.</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7558918</doc-number>
<kind>B2</kind>
<name>Parry et al.</name>
<date>20090700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711118</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7620753</doc-number>
<kind>B1</kind>
<name>Beaman et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710 56</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7979570</doc-number>
<kind>B2</kind>
<name>Chapweske et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>8069260</doc-number>
<kind>B2</kind>
<name>Speicher et al.</name>
<date>20111100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>8254442</doc-number>
<kind>B2</kind>
<name>Person et al.</name>
<date>20120800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524002</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2009/0259765</doc-number>
<kind>A1</kind>
<name>Karlsson et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2009/0259767</doc-number>
<kind>A1</kind>
<name>Karlsson et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709231</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709234</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12454563</doc-number>
<date>20090519</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8244899</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13546983</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120278500</doc-number>
<kind>A1</kind>
<date>20121101</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ganjam</last-name>
<first-name>Aditya R.</first-name>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Stoica</last-name>
<first-name>Ion</first-name>
<address>
<city>Piedmont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lakshminarayanan</last-name>
<first-name>Karthik K.</first-name>
<address>
<city>San Mateo</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Huebsch</last-name>
<first-name>Ryan J.</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Zhan</last-name>
<first-name>Jibin</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Zhang</last-name>
<first-name>Hui</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Ganjam</last-name>
<first-name>Aditya R.</first-name>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Stoica</last-name>
<first-name>Ion</first-name>
<address>
<city>Piedmont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Lakshminarayanan</last-name>
<first-name>Karthik K.</first-name>
<address>
<city>San Mateo</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Huebsch</last-name>
<first-name>Ryan J.</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Zhan</last-name>
<first-name>Jibin</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Zhang</last-name>
<first-name>Hui</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Van Pelt, Yi &#x26; James LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Conviva Inc.</orgname>
<role>02</role>
<address>
<city>San Mateo</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Shingles</last-name>
<first-name>Kristie</first-name>
<department>2448</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Delivering a video stream is disclosed. A request for the video stream is received. A past portion of the video stream is delivered to a client. The past portion has a marker time that precedes a current time by an interval that corresponds to a buffer length in a client buffer. Receiving a video stream is also disclosed. A request for the video stream is transmitted. A past portion of the video stream is received. The received past portion has a marker time that precedes a current time by an interval that corresponds to a buffer length in a client buffer.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="164.00mm" wi="265.09mm" file="US08626941-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="233.93mm" wi="176.19mm" file="US08626941-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="140.38mm" wi="162.14mm" file="US08626941-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="141.65mm" wi="183.90mm" file="US08626941-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="264.08mm" wi="175.26mm" orientation="landscape" file="US08626941-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="103.80mm" wi="125.56mm" file="US08626941-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="136.14mm" wi="101.35mm" file="US08626941-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="226.23mm" wi="153.16mm" orientation="landscape" file="US08626941-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="164.08mm" wi="128.19mm" file="US08626941-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO OTHER APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of co-pending U.S. patent application Ser. No. 12/454,563, entitled DELIVERING A VIDEO STREAM filed May 19, 2009 which is incorporated herein by reference for all purposes.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Typically, viewers of streaming content, such as a sporting event feed, wish to view the content in as high a quality as possible. For example, viewers do not want the video stream to freeze or skip frames. Such viewers typically also wish the video stream to start playing as quickly as possible. For example, viewers do not want to wait several seconds for a video feed to appear in a player window after having decided to watch the feed. And, simultaneous viewers of the same feed may desire that the respective videos they watch are synchronized with those of other viewers. Unfortunately, these goals are in conflict. For example, one way to improve the quality of a video stream is for a client to make use of a large buffer. As packets are received, the client inserts them at the end of the buffer and plays packets at the front of the buffer. A large buffer gives the client more time to recover from occasional network congestions, or even from server failure. However, a large buffer takes longer to fill, resulting in a correspondingly longer startup time.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0004" num="0003">Various embodiments of the invention are disclosed in the following detailed description and the accompanying drawings.</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example of an environment in which video is streamed.</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of an embodiment of a client.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an example of an embodiment of a buffer.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 4</figref> illustrates an example of an environment in which video is distributed.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an example of a process for delivering a video stream.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an example of a process for receiving a video stream.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an embodiment of an environment in which video is streamed.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 8</figref> illustrates an example of a process for coordinating the assignment of parents.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0013" num="0012">The invention can be implemented in numerous ways, including as a process; an apparatus; a system; a composition of matter; a computer program product embodied on a computer readable storage medium; and/or a processor, such as a processor configured to execute instructions stored on and/or provided by a memory coupled to the processor. In this specification, these implementations, or any other form that the invention may take, may be referred to as techniques. In general, the order of the steps of disclosed processes may be altered within the scope of the invention. Unless stated otherwise, a component such as a processor or a memory described as being configured to perform a task may be implemented as a general component that is temporarily configured to perform the task at a given time or a specific component that is manufactured to perform the task. As used herein, the term &#x2018;processor&#x2019; refers to one or more devices, circuits, and/or processing cores configured to process data, such as computer program instructions.</p>
<p id="p-0014" num="0013">A detailed description of one or more embodiments of the invention is provided below along with accompanying figures that illustrate the principles of the invention. The invention is described in connection with such embodiments, but the invention is not limited to any embodiment. The scope of the invention is limited only by the claims and the invention encompasses numerous alternatives, modifications and equivalents. Numerous specific details are set forth in the following description in order to provide a thorough understanding of the invention. These details are provided for the purpose of example and the invention may be practiced according to the claims without some or all of these specific details. For the purpose of clarity, technical material that is known in the technical fields related to the invention has not been described in detail so that the invention is not unnecessarily obscured.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example of an environment in which video is streamed. Source <b>102</b> distributes video to clients such as nodes <b>104</b>-<b>114</b> via one or more networks represented herein as a single network cloud <b>118</b>. In the example shown, the video being distributed is a live sporting event, such as a football game, captured by camera <b>120</b> and encoded by encoder <b>122</b>. In various embodiments, other video sources are distributed and the techniques herein adapted accordingly. For example, in addition to live events, source <b>102</b> can be configured to distribute continuous feeds such as security camera data and also feeds of prerecorded content such as for a television network channel.</p>
<p id="p-0016" num="0015">Camera <b>120</b>, encoder <b>122</b>, and source <b>102</b> may be collocated on a single platform, or may be physically separate, as applicable. Additionally, in some embodiments camera <b>120</b> and/or encoder <b>122</b> are under the control of a different entity than source <b>102</b>. In addition to source <b>102</b>, other nodes, such as traditional content distribution network (CDN) nodes are used to distribute content in various embodiments.</p>
<p id="p-0017" num="0016">Network cloud <b>118</b> includes the Internet and assorted intranets. For example, clients <b>104</b> and <b>108</b> are both nodes on the same corporate network and are both also connected to source <b>102</b> via the Internet.</p>
<p id="p-0018" num="0017">Clients <b>106</b>-<b>112</b> are typical consumer-oriented computers and include components such as a storage drive, RAM, and one or more processors. As described in more detail below, client <b>104</b> (also referred to herein as a &#x201c;boost node&#x201d;) has a reliable, high speed connection to network <b>118</b> and also has considerable computing resources such as multiple fast processors and a large amount of memory. In contrast, client <b>110</b> has a slower connection to network <b>118</b> and limited memory. Client <b>114</b> is a handheld device, such as a web-enabled cellular phone. Other examples of clients (not shown) such as personal digital assistants, set-top boxes, game consoles, broadband routers, and digital video recorders may also be used in conjunction with the techniques described herein as applicable.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of an embodiment of a client. In the example shown, client <b>110</b> includes a communication interface <b>202</b> that is used by client <b>110</b> to communicate with other devices/systems that are accessible via network cloud <b>118</b>. For example, client <b>110</b> receives video packets from clients <b>106</b> and <b>104</b> via communication interface <b>202</b>. Client <b>110</b> also transmits video packets to client <b>112</b> via communication interface <b>202</b>. Buffer <b>206</b> holds video information. Whenever client <b>110</b> performs a task (such as requesting a portion of a video stream), either a single component or a subset of components or all components client <b>110</b> may cooperate to perform the task.</p>
<p id="p-0020" num="0019">In the example of <figref idref="DRAWINGS">FIG. 1</figref>, client <b>104</b> has installed on it an application that facilitates the streaming of video content. The application is configured to receive content from source <b>102</b> (and/or from one or more other clients) and to redistribute the content to other nodes using peer-to-peer techniques. When client <b>104</b> is distributing video content to other clients, it is also referred to herein acting as a &#x201c;parent&#x201d; to those other clients. As used herein, &#x201c;parent&#x201d; denotes any node that sends data to another node and is applicable irrespective of whether tree-based protocols (in which a parent is defined with respect to an entire (sub)stream) or swarming protocols (in which a parent is defined with respect to a small granularity data unit such as a data packet or block) are used to distribute the stream data. Source <b>102</b> is also a parent for clients <b>106</b>, <b>104</b>, and <b>108</b>. Client <b>114</b> also has an application installed on it to facilitate the streaming of video, but it is not configured to redistribute the content.</p>
<p id="p-0021" num="0020">Client <b>110</b> does not have a dedicated video streaming application installed. Instead, client <b>110</b> has installed on it a typical commercially available web browser application such as MICROSOFT INTERNET EXPLORER, MOZILLA FIREFOX, or APPLE SAFARI. Client <b>110</b> streams video content and redistributes it to other clients via browser application <b>204</b> in conjunction with a JAVA applet, ADOBE FLASH content, SILVERLIGHT component or similar technology.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an example of an embodiment of a buffer. Suppose a user of client <b>110</b> (hereinafter referred to as &#x201c;Alice&#x201d;) is currently viewing a live basketball game with client <b>110</b>. Buffer <b>206</b> is a first-in-first-out buffer of size <b>302</b> (e.g., 30 seconds) and stores video data received from source <b>102</b> (and/or parent nodes such as node <b>106</b>) by client <b>110</b>. As client <b>110</b> receives packets, they are inserted at the end of the buffer (<b>310</b>). The packets at the beginning of the buffer (<b>304</b>) are played by a video player. In the example shown, buffer <b>206</b> is approximately 85% full of video data, as indicated by region <b>308</b>.</p>
<p id="p-0023" num="0022">When a client begins receiving a video stream, the client requests a portion of the video that is T seconds behind the live event, where T is the maximum size of the buffer. Accordingly, the maximum size of the buffer dictates by how much the video being played to a user of a client is behind the live event. For example, if the maximum size of the buffer the client is configured to build is 30 seconds, then, assuming a full buffer, the video being played is at least 30 seconds behind the live feed.</p>
<p id="p-0024" num="0023">Suppose the current time is 11:05:00 am and that the basketball game Alice is watching started 65 minutes ago, at 10:00:00 am. As used herein, the &#x201c;current&#x201d; time in such a scenario is 11:05:00. In contrast, the portion of the game that would appear in Alice's video player at the current time is offset by T time. If T is 30 seconds, the video shown by the player would have been captured (e.g., by camera <b>120</b>) at time 11:04:30. The time at which the video that is currently being played on client <b>110</b> was captured (or otherwise received by source <b>102</b>) is denoted as the &#x201c;marker&#x201d; time. In the above example, the &#x201c;marker&#x201d; time is 11:04:30&#x2212;30 seconds earlier than the &#x201c;current&#x201d; time.</p>
<p id="p-0025" num="0024">In the example shown in <figref idref="DRAWINGS">FIG. 3</figref>, line <b>306</b> indicates the current time at source <b>102</b> (e.g., 0 seconds in the past). Line <b>304</b> indicates the portion of the frame at the head of the buffer currently being played for Alice. As mentioned above, the video being played for Alice was received at the source 30 seconds ago. The difference between the time of current time at source <b>310</b> and the time of frame at the head of the buffer <b>306</b> is 30 seconds. The data in the buffer represents an approximately 25 second span of data, the most recent of which was captured (e.g., by camera <b>120</b>) approximately 5 seconds ago. The buffer does not yet have the most recent 5 seconds of the game, as indicated by the gap between segment <b>308</b> and point <b>306</b>.</p>
<p id="p-0026" num="0025">In some embodiments the amount of buffered video data required to start playing a video stream is less than size <b>308</b>. Instead of waiting for the entire buffer to fill up, client <b>110</b> is configured to show video to Alice after only a subset of the buffer has been downloaded. This allows for video to be displayed quickly, minimizing startup time. The startup time is determined by the size of the subset (e.g., 3 seconds), while the quality of the feed is determined by the entire buffer size (e.g., 30 seconds). Once the video is playing, the client tries aggressively to fill the rest of the buffer. For example, client <b>110</b> may initially receive video data from source <b>102</b> directly or from a high quality node such as node <b>104</b> until client <b>110</b>'s buffer is filled. Once the buffer is filled, client <b>110</b> may be directed to change the node(s) from which it receives video data. For example, client <b>110</b> may be directed to receive subsequent video data from node <b>106</b> and to stop receiving video data directly from source <b>102</b>.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 4</figref> illustrates an example of an environment in which video is distributed. In the example shown, node A (<b>404</b>) and node B (<b>406</b>) each receive video data from source <b>402</b>. Nodes C (<b>408</b>) and D (<b>410</b>) receive data from node A (<b>404</b>), while node E (<b>412</b>) receives video data from node B (<b>406</b>).</p>
<p id="p-0028" num="0027">Each of the nodes maintains a buffer. The buffers have a maximum size (e.g., 30 seconds) and also an operative size, which can vary from node to node, and can vary for a particular node based on factors such as network conditions. As explained previously, when a client begins receiving a video stream, the client requests a portion of the video that is T seconds behind the live event, where T is the maximum size of the buffer. In the example shown in <figref idref="DRAWINGS">FIG. 4</figref>, each of nodes A-E would thus be simultaneously playing to their respective users the feed of the basketball game 30 seconds in the past.</p>
<p id="p-0029" num="0028">Typically, the more hops away a client is from source <b>102</b>, the smaller the operative buffer of the client will be. In the example of <figref idref="DRAWINGS">FIG. 3</figref>, node <b>110</b> has a maximum buffer of 30 seconds, and an operative buffer of 25 seconds. In the example shown in <figref idref="DRAWINGS">FIG. 4</figref>, node D also has a buffer of maximum size 30 seconds. However, node D's operative buffer is much smaller&#x2014;approximately 15 seconds. Nonetheless, both node D and Alice's node <b>110</b> will display the same portion of the basketball game at the same time. Both clients' players will display the game in a synchronized (though slightly delayed) fashion.</p>
<p id="p-0030" num="0029">In the example shown in <figref idref="DRAWINGS">FIG. 4</figref>, upon joining in the streaming of a feed, every client (e.g., A-E) knows the current time and requests video frames that are T seconds behind that current time. As described in more detail below, a variety of techniques can be used to propagate current time information to clients, both initially, and, in some embodiments, periodically while the video continues to be streamed.</p>
<p id="p-0031" num="0030">Since every client plays frames at the marker time, latency (e.g., introduced as packets are propagated using peer-to-peer techniques) and other delay along the data path does not influence viewer synchronization. Instead, such delays impact only the size of the buffer (and thus, potentially, video quality). For instance, the size of the buffer at client D is T&#x2212;(d<sub>SA</sub>+d<sub>AD</sub>), where d<sub>SA </sub>represents the delay between source <b>102</b> and client A, and d<sub>AD </sub>represents the delay between client A (which is the parent of D) and D. The size of the buffer at client D is smaller than the size of the buffer at the source.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an example of a process for delivering a video stream. In some embodiments the process shown in <figref idref="DRAWINGS">FIG. 5</figref> is performed by source <b>102</b>. The process begins at <b>502</b> when a request for the video stream is received. For example, when Alice instructs client <b>110</b> that she would like to watch the basketball game (e.g., by clicking on a &#x201c;watch live now&#x201d; button provided on a web page as rendered in her web browser), a request is received from client <b>110</b> by source <b>102</b> at <b>502</b>.</p>
<p id="p-0033" num="0032">At <b>504</b>, a past portion of the video stream is delivered to the client. As explained above, the past portion has a marker time that precedes the current time by an interval T. For example, once a request for the basketball game is received from client <b>110</b>, source <b>102</b> causes the video stream to be delivered to client <b>110</b>. In this case, source <b>102</b> initiates the delivery of video data that begins with the frame having a marker time <b>304</b>.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an example of a process for receiving a video stream. In some embodiments the process shown in <figref idref="DRAWINGS">FIG. 6</figref> is performed by a client such as client <b>110</b>. The process begins at <b>602</b> when a request for the video stream is transmitted. For example, when Alice instructs client <b>110</b> that she would like to watch the basketball game (e.g., by clicking on a &#x201c;watch live now&#x201d; button), a request is transmitted from client <b>110</b> to source <b>102</b> at <b>602</b>. Client <b>110</b> can also request content (starting at what client <b>110</b> believes is the marker time) from other clients, as applicable, and the process shown in <figref idref="DRAWINGS">FIG. 6</figref> adapted accordingly.</p>
<p id="p-0035" num="0034">At <b>604</b>, a past portion of the video stream is received. As explained above, the past portion has a marker time that precedes the current time by an interval. For example, in response to the request transmitted at <b>602</b>, at <b>604</b> client <b>110</b> receives&#x2014;either from source <b>102</b> or from another node such as node <b>104</b>&#x2014;video data that begins with the frame having a marker time <b>304</b>.</p>
<p id="p-0036" num="0035">Redistribution of Data</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an embodiment of an environment in which video is streamed. In various embodiments source <b>102</b>, and/or another system working in conjunction with source <b>102</b> (not pictured) coordinates the redistribution of data from nodes such as clients <b>106</b> and <b>104</b> to other nodes such as clients <b>110</b> and <b>114</b>. In the example shown in <figref idref="DRAWINGS">FIG. 7</figref>, nodes are classified into one of three groups based on factors such as their current and historic network connection speeds and reliability. Other groupings may also be used, as applicable.</p>
<p id="p-0038" num="0037">Nodes included in the top level of a three-level hierarchy of nodes (<b>702</b>) include high capacity and stable nodes whose output capacity is larger than the rate of the data being distributed. Nodes in level <b>702</b> are used as &#x201c;boost&#x201d; nodes to assist clients in quickly filling their buffers. In some cases, nodes in level <b>702</b> are typical end-user-owned computers that are also used to view content. Nodes in level <b>702</b> can also be provided by the entity that controls source <b>102</b>, or by a third party, for the purpose of improving the distribution of content.</p>
<p id="p-0039" num="0038">The second level (<b>704</b>) includes nodes configured both to receive content and to redistribute content. Nodes in level <b>704</b> typically have fewer resources than nodes in level <b>702</b>, but are nonetheless able to simultaneously receive and transmit video stream data.</p>
<p id="p-0040" num="0039">The bottom level (<b>706</b>) includes mainly low-capacity nodes that are configured to receive but not redistribute content. Typically, the output capacities of nodes in level <b>706</b> are lower than the data rate. However, in some embodiments clients in level <b>706</b> may be physically capable of redistributing stream data, but are configured not to&#x2014;such as due to a policy set by a user of the node, or by an administrator.</p>
<p id="p-0041" num="0040">In various embodiments, source <b>102</b> is configured to continually assess and reassign, on an ongoing basis, the node(s) from which a client receives data, and also, if applicable, the node(s) to which the client redistributes that data. The reassessment/reassignment process can occur with a very high frequency, such as on second-level intervals, to help address the situations such as the distribution of a live feed in which high availability of a connection may be paramount. One example way to perform fast reassignment is as follows. Clients are organized based on their available uplink capacities using a priority queue. When a client loses one or more of its parents or the aggregate rate it receives from its parents is less than the stream rate, the reassignment algorithm will select new parents for the client by choosing the clients with the highest available bandwidth from the priority queue. In some embodiments, source <b>102</b> balances between the parent's uplink capacity and geographic proximity by first selecting a larger set of potential parents and then selecting the parents which are the closest to the client from this set. A potential parent is a node whose available bandwidth is larger than the additional required bandwidth of the child node.</p>
<p id="p-0042" num="0041">Source <b>102</b> periodically exchanges information with clients using messages referred to herein as heartbeat messages. Source <b>102</b> provides instructions on which nodes the client should obtain the appropriate stream data from and, as described in more detail below, can also provide information such as the current time and the marker time. Clients send source <b>102</b> information such as current CPU load, available storage, geographic location, information for each data stream received/sent from/to other clients, and an IP-level path to other clients. In addition to this information, source <b>102</b> has access to BGP feeds and the mappings between IP addresses and their geographic locations. Source <b>102</b> uses the received information to maintain a global and up-to-date view of the environment shown in <figref idref="DRAWINGS">FIG. 7</figref>. This view includes the locations of the clients, whether a client is behind NAT/firewall (and if yes, the type of NAT/firewall), client resource availability, and the level of network congestion along the paths between various clients.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 8</figref> illustrates an example of a process for coordinating the assignment of parents. In some embodiments the process shown in <figref idref="DRAWINGS">FIG. 8</figref> is implemented by source <b>102</b>. The process begins at <b>802</b> when an assignment of one or more parents is sent to a client such as client <b>110</b>. As one example, source <b>102</b> is assigned as a parent at <b>802</b>. Boost nodes such as node <b>104</b> and/or other nodes may also be assigned as initial parents at <b>802</b> instead of or in addition to source <b>102</b>.</p>
<p id="p-0044" num="0043">At <b>804</b>, a determination is made (e.g., by source <b>102</b>) that a modification should be made to the parents assigned at <b>802</b>. One reason for such a determination is that a client could be successfully served by a parent that is currently idle or otherwise underutilized. For example, suppose client <b>110</b>'s buffer is filled completely within a few seconds of the initial assignment at <b>802</b> being made. At <b>804</b>, source <b>102</b> might determine that client <b>110</b> no longer needs the benefit of boost node <b>104</b>'s bandwidth and that client <b>106</b> would make an acceptable parent for client <b>110</b>. Another reason for the determination of <b>804</b> is that a client is being underserved by its current parent (e.g., due to a change in a network condition), that the parent has dropped off the network, etc.</p>
<p id="p-0045" num="0044">If it is determined that the parent(s) of a client should be changed, at <b>806</b> the revised assignment is propagated to the client. In some embodiments the revised assignment is transmitted by source <b>102</b> via a heartbeat message.</p>
<p id="p-0046" num="0045">Propagating Timestamps</p>
<p id="p-0047" num="0046">As explained above, when clients initially request a video stream, they are configured to play the feed as of the marker time, rather the current time. It is possible that, due to the peer-to-peer distribution techniques used by clients in environment <figref idref="DRAWINGS">FIG. 1</figref>, frames may be received (and possibly out of chronological order) from different parents. And, a client such as a grandchild (the child of a child) of client <b>112</b> may receive a frame only after it has been propagated through many clients, with the corresponding latency introduced. Accordingly, in some embodiments clients need to know a time at the source (e.g. the current or marker time) so that they can correctly play the appropriate frames at the appropriate time.</p>
<p id="p-0048" num="0047">In some embodiments clients are continuously aware of the current (and/or marker) time at the source, and not just when the client initially requests the feed. Such reoccurring time synchronization can be used, for example, to address the different clock skew times that different clients might have.</p>
<p id="p-0049" num="0048">One way of maintaining knowledge of the time at source <b>102</b> is for all clients in the environment shown in <figref idref="DRAWINGS">FIG. 1</figref> to use a protocol such as the Network Time Protocol (NTP) to synchronize their times. In this case, a client needs only to know by how much is the marker behind the synchronized global time. If the synchronized global time is G and the marker is T seconds behind, then the marker is G&#x2212;T.</p>
<p id="p-0050" num="0049">An application level protocol can also be used to distribute the appropriate time information. For example, when source <b>102</b> receives a packet from encoder <b>122</b> (at a time &#x201c;t&#x201d;), source <b>102</b> can be configured to embed a timestamp in the packet. When source <b>102</b> transmits the packet, it embeds in the packet an indication that the marker time is t&#x2212;T (where T is the maximum buffer size). Every client maintains a local marker time M<sub>L </sub>that is used to track information about the marker time at the source. Whenever the client receives a packet of the stream&#x2014;whether from source <b>102</b> or from another client&#x2014;the client updates its local M<sub>L </sub>as being the maximum value of the existing M<sub>L </sub>and the marker value included in the packet. In doing so, the client will maintain a value for the marker time with an accuracy that is bounded by the shortest delay path between the source and the client.</p>
<p id="p-0051" num="0050">Yet another way to propagate timing information is to use a control plane such as is formed by the heartbeat messages exchanged between clients and source <b>102</b>. As explained above, source <b>102</b> periodically sends heartbeat messages to clients. Such messages can include the marker time of source <b>102</b> and clients can adjust their M<sub>L </sub>values as appropriate based on those messages. In some embodiments the heartbeats are distributed by a computer cluster in a well-connected datacenter. In such an environment, the source sends its heartbeats to the computer cluster which in turn redistributes the heartbeats to the appropriate clients.</p>
<p id="p-0052" num="0051">In various embodiments a combination of techniques is used to maintain knowledge of the time at source <b>102</b>. For example, clients can be configured to receive the information via heartbeat messages and also encoded in stream data, and to update M<sub>L </sub>as being the maximum value received from either source, accordingly.</p>
<p id="p-0053" num="0052">Although the foregoing embodiments have been described in some detail for purposes of clarity of understanding, the invention is not limited to the details provided. There are many alternative ways of implementing the invention. The disclosed embodiments are illustrative and not restrictive.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system, comprising:
<claim-text>at least one or more interfaces configured to:
<claim-text>transmit a request for a video stream; and</claim-text>
<claim-text>receive a past portion of the requested video stream;</claim-text>
</claim-text>
<claim-text>a processor configured to:
<claim-text>dynamically determine an operative buffer size based at least in part on a function of a propagation delay in receiving the past portion of the requested video stream;</claim-text>
<claim-text>fill a client buffer with at least a portion of the received past portion of the requested video stream;</claim-text>
<claim-text>determine that the client buffer has been filled to the dynamically determined operative buffer size; and</claim-text>
<claim-text>cause the past portion of the requested video stream to be played in response to the determination that the client buffer has been filled to the operative buffer size; and</claim-text>
</claim-text>
<claim-text>a memory coupled to the processor and configured to provide the processor with instructions.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the delay is associated with a data path used to receive the past portion of the video stream, and wherein the data path includes one or more hops between the system and a source of the video stream.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the operative buffer size is less than a maximum size of the client buffer.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the system comprises a first client and wherein the past portion is received from a second client.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref> wherein the first and second clients are associated with different operative buffer sizes.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the past portion has a marker time.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref> wherein the system is configured to play a frame stamped with the marker time.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the past portion of the video stream is caused to be played while filling the client buffer.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the past portion is received from a first source and wherein a subsequent portion of the video stream is received from a second source.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is further configured to:
<claim-text>receive a first portion of the video stream, including a first marker time, from a first node;</claim-text>
<claim-text>receive a second portion of the video stream, including a second marker time, from a second node; and</claim-text>
<claim-text>determine whether the first marker time or the second marker time is more recent.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is further configured to receive a timestamp associated with a frame of the past portion.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is further configured to receive a subsequent portion of the video stream from a first node and receive a timestamp from a second node.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the timestamp is received with a heartbeat message.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is further configured to synchronize a local time with a source of the video stream.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A method, comprising:
<claim-text>transmitting, via an interface on a client, a request for a video stream;</claim-text>
<claim-text>receiving a past portion of the requested video stream;</claim-text>
<claim-text>dynamically determining an operative buffer size based at least in part on a function of a propagation delay in receiving the past portion of the requested video stream;</claim-text>
<claim-text>filling a client buffer with at least a portion of the received past portion of the requested video stream;</claim-text>
<claim-text>determining that the client buffer has been filled to the dynamically determined operative buffer size; and</claim-text>
<claim-text>causing the past portion of the requested video stream to be played in response to the determination that the client buffer has been filled to the operative buffer size.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the delay is associated with a data path used to receive the past portion of the video stream, and wherein the data path includes one or more hops between the client and a source of the video stream.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the operative buffer size is less than a maximum size of the client buffer.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the client comprises a first client and wherein the past portion is received from a second client.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref> wherein the first and second clients are associated with different operative buffer sizes.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A computer program product, the computer program product being embodied in a non-transitory computer readable storage medium and comprising computer instructions for:
<claim-text>transmitting a request for a video stream;</claim-text>
<claim-text>receiving a past portion of the requested video stream;</claim-text>
<claim-text>dynamically determining an operative buffer size based at least in part on a function of a propagation delay in receiving the past portion of the requested video stream;</claim-text>
<claim-text>filling a client buffer with at least a portion of the received past portion of the requested video stream;</claim-text>
<claim-text>determining that the client buffer has been filled to the dynamically determined operative buffer size; and</claim-text>
<claim-text>causing the past portion of the requested video stream to be played in response to the determination that the client buffer has been filled to the operative buffer size. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
