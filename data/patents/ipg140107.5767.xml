<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626872-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626872</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10519633</doc-number>
<date>20030627</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>FR</country>
<doc-number>02 08091</doc-number>
<date>20020628</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1889</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>932</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>77</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709218</main-classification>
<further-classification>709217</further-classification>
<further-classification>386201</further-classification>
<further-classification>386228</further-classification>
</classification-national>
<invention-title id="d2e73">Synchronization system and method for audiovisual programmes associated devices and methods</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4230990</doc-number>
<kind>A</kind>
<name>Lert, Jr. et al.</name>
<date>19801000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5886995</doc-number>
<kind>A</kind>
<name>Arsenault et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5920477</doc-number>
<kind>A</kind>
<name>Hoffberg et al.</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2002/0056129</doc-number>
<kind>A1</kind>
<name>Blackketter et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2003/0233451</doc-number>
<kind>A1</kind>
<name>Ludvig et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0005795</doc-number>
<kind>A1</kind>
<name>Gonzalez</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>EP</country>
<doc-number>1286541</doc-number>
<kind>A1</kind>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>10191315</doc-number>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>WO</country>
<doc-number>WO 01/22729</doc-number>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>WO</country>
<doc-number>0131497</doc-number>
<kind>A1</kind>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>WO</country>
<doc-number>WO 01/60061</doc-number>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>WO</country>
<doc-number>0180553</doc-number>
<kind>A1</kind>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>WO</country>
<doc-number>WO 02/21840</doc-number>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Tanaka, Kiyoshi,Taura, Takahisa, Akutsu, Akihito, and Tonomura Yoshinobu: &#x201c;LiveWatch: Interactive Live Broadcast System&#x201d;, ITE Technical Report, Japan, The Institute of Image Information and Television Engineers, Oct. 2001, vol. 25, No. 66, p. 7-12.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Search Report Dated Nov. 18, 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>27</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709218</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386 38</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060117339</doc-number>
<kind>A1</kind>
<date>20060601</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lesenne</last-name>
<first-name>Laurent</first-name>
<address>
<city>Acigne</city>
<country>FR</country>
</address>
</addressbook>
<residence>
<country>FR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Maillard</last-name>
<first-name>Alain</first-name>
<address>
<city>Paris</city>
<country>FR</country>
</address>
</addressbook>
<residence>
<country>FR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Pasquier</last-name>
<first-name>Fr&#xe9;d&#xe9;ric</first-name>
<address>
<city>Laille</city>
<country>FR</country>
</address>
</addressbook>
<residence>
<country>FR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Lesenne</last-name>
<first-name>Laurent</first-name>
<address>
<city>Acigne</city>
<country>FR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Maillard</last-name>
<first-name>Alain</first-name>
<address>
<city>Paris</city>
<country>FR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Pasquier</last-name>
<first-name>Fr&#xe9;d&#xe9;ric</first-name>
<address>
<city>Laille</city>
<country>FR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Jack Schwartz and Associates, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Thomson Licensing</orgname>
<role>03</role>
<address>
<country>FR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Beharry</last-name>
<first-name>Noel</first-name>
<department>2478</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/EP03/50272</doc-number>
<kind>00</kind>
<date>20030627</date>
</document-id>
<us-371c124-date>
<date>20050809</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2004/004360</doc-number>
<kind>A </kind>
<date>20040108</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The present invention relates in particular to a synchronization system and method. The synchronization system comprises a specification unit for specifying synchronization signals associated with an audiovisual program, the latter comprising an audiovisual content and control information, a recognition unit for recognizing the synchronization signals in a transmitted stream carrying this program, by recognition of at least one extracted portion of the audiovisual content, and an activation unit triggering an action in case of detection of these signals. The specification unit prepares and transmits to the recognition unit recognition elements making it possible to obtain this extracted portion, as well as at least one action timeout lag in case of detection of the synchronization signals. The recognition or activation unit then delays the triggering of this action according to the lag transmitted, in case of detection of the synchronization signals. In variants, the timeout lag is determined and/or the recognition elements are obtained independently of the specification unit.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="129.29mm" wi="172.55mm" file="US08626872-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="259.08mm" wi="172.80mm" file="US08626872-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="264.08mm" wi="175.43mm" file="US08626872-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="175.43mm" wi="148.67mm" file="US08626872-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="241.13mm" wi="153.25mm" file="US08626872-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="254.34mm" wi="156.04mm" file="US08626872-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">This application claims the benefit, under 35 U.S.C. &#xa7;365 of International Application PCT/EP03/50272, filed Jun. 27, 2003, which was published in accordance with PCT Article 21(2) on Jan. 8, 2004 in English and which claims the benefit of French patent application No. 0208091, filed Jun. 28, 2002.</p>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention concerns a synchronization system and method for audiovisual programmes, as well as associated devices and methods. It pertains in particular to units and methods for recognizing and specifying synchronization signals.</p>
<heading id="h-0002" level="1">DESCRIPTION OF THE RELATED ART</heading>
<p id="p-0004" num="0003">Interactive television allows a viewer to act on the course of the transmissions that he is watching. He can thus interact with interactive services. To do this, mass-market interactive terminals are connected to a dual communication network:</p>
<p id="p-0005" num="0004">a bidirectional network (modem return path, cable, . . . ) of point-to-point type, such as in particular a telephone network, implementing one or more point-to-point servers,</p>
<p id="p-0006" num="0005">and a unidirectional distribution network, such as in particular an RF, cable or satellite TV broadcasting network, implementing one or more general broadcasting servers; the expression &#x201c;general broadcasting&#x201d; (or just broadcasting), is understood to mean the transmitting of identical data to a set of destinations, whether this be performed in particular by radio broadcasting, by cable or by Internet.</p>
<p id="p-0007" num="0006">The relevant terminals consist for example of television receivers, DVB (standing for Digital Video Broadcasting) decoders or Internet decoders. The interactive services are generally downloaded into the terminals by broadcasting via the unidirectional network. In other cases, they are hosted by servers that can be accessed by the telephone network. These services are then accessed through references or web addresses (also called URLs standing for Universal Resource Locators, or universal addresses) broadcast as an adjunct to an audiovisual programme. They determine the server to which the terminals must address themselves and the service to be invoked on this server. The audiovisual programmes broadcast synchronously either with the services, or with URLs of the services, are then referred to as &#x201c;enhanced programmes&#x201d;.</p>
<p id="p-0008" num="0007">In practice, the known techniques of interactive television rely on the operations which follow. A broadcasting centre, or broadcaster, broadcasts an interactive service emanating from a services operator, in a manner synchronized with an audiovisual programme (unidirectional network). For this purpose, data relating to this service are embedded with audiovisual signals specific to this programme. When an interactive terminal receives the enhanced programme thus obtained, it broadcasts on the screen (image and sound) the audiovisual programme and interprets the data of the interactive service. It then screens the latter in synchronization with the audiovisual programme, typically in the form of a video overlayed graphical or textual display.</p>
<p id="p-0009" num="0008">A viewer can then interact with the interactive service, this interaction possibly leading to the setting up of a connection with a server of the services operator (bidirectional network).</p>
<p id="p-0010" num="0009">One of the essential aspects of interactive television relates to the establishing and managing of synchronization between programmes and interactive services data. In particular, it is generally envisaged to broadcast the interactive content or its URL in a loop (carousel) for the duration of the associated audiovisual programme. Two items of broadcaster equipment are customarily used for synchronization:</p>
<p id="p-0011" num="0010">a traffic system, that creates an events execution list (playlist) comprising time information (start time and end time), object information (device to be driven) and operation information (command to be executed);</p>
<p id="p-0012" num="0011">and an automaton system that manages the execution list so as to drive and control the broadcaster's broadcasting equipment (video servers, video recorders, subtitling apparatus, etc.).</p>
<p id="p-0013" num="0012">The traffic system enables modifications to be made to the execution list in case of significant modifications in the temporal organization of the programmes. The automation system is for its part capable of tweaking the list in case of last minute tiny modifications, and of redirecting the list to the traffic system if more consequential modifications are required.</p>
<p id="p-0014" num="0013">The synchronizing of the interactive services with the programmes is achieved by incorporating a broadcasting server (which acts as server of interactive applications) from among the devices to be driven by the automation system. The service operator is assumed to be connected permanently to the broadcaster's broadcasting server, so as to be notified of the actual broadcasting of the programmed contents. This involves a link of the TCP-IP (standing for Transmission Control Protocol/Internetwork Protocol) type or the like in which a layer of a particular application package can be deployed. This link serves in one sense to programme the broadcasting server on the basis of administration applications present at the service operator, and in the other sense to inform the services operator in particular of the state of the broadcasting server, of the progress of broadcasts of contents and of any incidents.</p>
<p id="p-0015" num="0014">Problems of desynchronization between the broadcasting of the programmes and those of associated interactive contents are thus avoided. Specifically, if an audiovisual programme is delayed or advanced, the execution list is updated by the broadcaster. In this way, the devices used&#x2014;including the broadcasting server&#x2014;trigger at the appropriate moments.</p>
<p id="p-0016" num="0015">However, such a technique requires the intervention of the broadcaster, who must modify his events execution lists to take account of events related to the broadcasting of interactive services. Moreover, it requires a convention between the broadcaster and the services operator, so that they understand one another with regard to commands relating to the broadcasting of such services.</p>
<p id="p-0017" num="0016">Various procedures have also been proposed in which synchronization signals are inserted into the audiovisual programme itself. Thus, document WO-01/50764 describes a computer method for utilizing an interactive digital television transmission, in which service signals corresponding to &#x201c;synchronization pulse&#x201d; sequences, which bring about the downloading of a multimedia application, are detected. In U.S. Pat. No. 5,818,440, an interactive application is downloaded into an interactive television network, and this application is automatically switched on upon the detection of an application token incorporated into the video programme.</p>
<p id="p-0018" num="0017">Such implementations likewise require the intervention of a broadcaster or of a services provider in order to insert the stream of appropriate synchronization signals, and therefore have an intrusive nature.</p>
<p id="p-0019" num="0018">These difficulties are resolved by the invention disclosed in document WO-01/91462. This priority document describes a device for synchronizing broadcast audiovisual programmes and complementary information. The device comprises a pictures and/or sound detection assembly capable of extracting at least one semantic element from the content of an audiovisual programme being broadcast. It also comprises a unit for recognizing these semantic elements, linked to a programme guide which comprises a chronologically ordered list of information sets associated with the audiovisual programmes. The recognition unit, prepared by prior learning, selects the information set which is most probably correlated with these semantic elements. A synthesis block then synchronizes the audiovisual programmes with the information sets selected.</p>
<p id="p-0020" num="0019">However, this invention demands complex means and requires reference to a programme guide.</p>
<p id="p-0021" num="0020">Patent Application WO-02/21840 proposes a procedure for synchronizing a client with a media signal. According to one embodiment of this procedure, one or more actions corresponding to an audiovisual signal (the media signal) is or are received, an application for performing the actions (for example by syntactic analysis&#x2014;or &#x201c;parsing&#x201d;&#x2014;of action information) is determined, and a switching on of the actions is triggered by this application. In the examples described, an operator defines actions that he dispatches to a server, which itself transmits them by broadcasting via the Internet to clients. Either the actions dispatched have to be executed as soon as they are received, or they are accompanied by time information making it possible to determine the moments at which to execute them.</p>
<p id="p-0022" num="0021">A drawback of this procedure is that it demands relatively complex operations in respect of synchronization, either in the form of interventions by an operator at suitable moments, or in the form of prior preparation making it possible to trigger the dispatchings of the actions at the suitable moments.</p>
<p id="p-0023" num="0022">Document WO-01/82623 discloses the automatic insertion of interactive TV triggering messages (&#x201c;triggers&#x201d;) into an audiovisual data stream. The insertion can in particular be based on the recognition of particular elements in the stream, such as audio/video samples. Moreover, this insertion can be triggered before or after broadcasting of the stream. The description also mentions the use of a tag table comprising links between, on the one hand, the samples to be found and, on the other hand, interactive elements and associated attributes, such as, for example, the station number.</p>
<p id="p-0024" num="0023">This very flexible technology is, however, restricted to programmes known in advance, for which the particular elements required must be recorded beforehand for the implementation of the recognition operations. In particular, it is not applicable to transmissions broadcast live.</p>
<p id="p-0025" num="0024">One possibility for widening the field of applications of this type of technology would consist in introducing recognition elements into audiovisual programmes, these elements being able to trigger the recognition operations at the desired moments. For example, a specific banner could be inserted during the broadcasting of a live transmission. However, such a solution would require inlay steps, that would have to be performed by the transmitting station. This is therefore an intrusive procedure, which is rather impractical in particular when the interactivity is driven by an operator who is not involved in the broadcasting process.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0026" num="0025">Document WO-01/60061 deals with methods and apparatus for recording programs prior to or beyond a preset recording time period. In accordance with the described technique, a video signal is processed to generate one or more signatures associated with a broadcast program to be recorded. The signatures are then further processed, for example by being compared with known stored information regarding the broadcast program, so as to determine an actual start time and end time of the program.</p>
<p id="p-0027" num="0026">The teaching of that document seems interesting in that it introduces some flexibility in the recognition of the exploited synchronization signals. It mentions notably solutions in which recognition is possible even when no specific synchronisation signals are introduced in broadcast signals and when no reference signal is previously stored at the receiving side. This is possible by exploiting the detection of relevant variations in the received audio and/or video signals. However, the signatures may not be always easy and practical to process, because significant detectable signals or signals variations are not necessarily available without being specifically introduced upstream, every time a synchronisation is needed.</p>
<p id="p-0028" num="0027">The present invention relates to a system and a method of synchronizing audiovisual programmes and interactive services, which may make it possible to be completely unintrusive with regard to broadcasters and operators of services, while permitting simple and reliable implementation and avoiding recourse to a programme guide. The system and the method of the invention enable applications not only to programmes known in advance, but also to transmissions broadcast live or to programmes that have not formed the subject of a processing or of a prior examination.</p>
<p id="p-0029" num="0028">The synchronization system and method of the invention apply also to other types of synchronization relating to audiovisual programmes, in particular in respect of automatic recordings of films or transmissions, or of automatic substitutions of contents of audiovisual programmes (the user being able, for example, to decide in advance a real-time replacement on screen of a certain category of programmes by another, by means of selection from among several broadcasting sources). What is more, they also relate to radio transmissions. Hereinafter, and for simplicity, including in the definition of the invention, the expression &#x201c;audiovisual programme&#x201d; is aimed at audio and/or video programmes.</p>
<p id="p-0030" num="0029">The subject of the invention are also units and methods for specifying and recognizing synchronization signals, usable for the synchronization system of the invention and capable of offering the aforesaid advantages.</p>
<p id="p-0031" num="0030">It is also aimed at a broadcasting centre (broadcaster), a service operator, a terminal (interactive or otherwise) for receiving audiovisual programmes and software, which are associated with one at least of the abovementioned subjects of the invention.</p>
<p id="p-0032" num="0031">For this purpose, the subject of the invention is a recognition unit for recognizing synchronization signals in at least one audiovisual programme received, that audiovisual programme comprising an audiovisual content intended to be broadcast to users (that is to say which is realized in visual or audible form) and control information. The recognition unit is in accordance with claim <b>1</b>.</p>
<p id="p-0033" num="0032">The recognition unit of the invention is therefore capable of detecting synchronization signals without any modification being made to the audiovisual programmes, by direct analysis of the audiovisual content (such as pictures, sounds, parts of the latter or combinations) broadcast to the users. Thus, by contrast with the intrusive methods consisting in intervening on the event playlists, no modification of these lists is necessary. In particular, in this way the risks of broadcasting an interactive service on an audiovisual programme that does not correspond are reduced. Specifically, by virtue of the recognition pertaining to the content, an error has a small possibility of occurring, while with the above methods, these risks are considerably increased through the manipulating of identification entities and the presence of a third party providing information which cannot be verified by the services operator (identifier of the programme).</p>
<p id="p-0034" num="0033">Moreover, in contradistinction to the techniques relying on the recognition of specific detection signals incorporated into the audiovisual programme streams transmitted, no action on the signals carrying these programmes is required.</p>
<p id="p-0035" num="0034">What is more, as compared with the technique disclosed in Patent Application WO 01/91462, the recognition elements are communicated beforehand to the recognition unit, thereby making it possible to avoid recourse to complex identification techniques associated with a programme guide.</p>
<p id="p-0036" num="0035">Moreover, the recognition unit of the invention contrasts with the teaching of the prior document WO 01/82623 through the presence of the timeout module, which introduces a lag before the transmission of the action instructions when the synchronization signals are detected in the audiovisual programme. The use of this lag is particularly beneficial, in so far as it makes it possible to lock the synchronization with respect to an event that can be anticipated, then to meter the time gap between this synchronization and a suitable moment, so as to trigger at this moment the actions to be synchronized.</p>
<p id="p-0037" num="0036">Thus, in particular, a live transmission generally being preceded&#x2014;or even punctuated&#x2014;by adverts, it is possible to lock the detection onto an end of advertising banner credits and adjust the timeout so that an interactive service is displayed, for example, 10 minutes after the commencement of the transmission (by way of illustration, the time required by a promoter to announce the possibility of interacting with his television).</p>
<p id="p-0038" num="0037">This technique may in particular allow a services operator to manage synchronization operations, including with regard to transmissions broadcast live, without having to ask a station broadcasting the transmissions to take a demanding part in these operations. It is in fact sufficient for the station to provide a sample, such as for example an image of an advertising banner, and an approximate timing for the triggering of desired actions, for example the appearance of interactivity. In particular, this embodiment allows synchronization of the broadcasting of interactive services with audiovisual programmes that are designed a priori without any interactivity.</p>
<p id="p-0039" num="0038">The recognition unit of the invention can also serve in particular to trigger in due course at the level of a terminal, local interactivity or recording during the broadcasting of a film or of a transmission, without it being necessary for this terminal to be supplied beforehand with extracted portions of their content. It is sufficient for the terminal to be capable of recognizing portions of a programme broadcast beforehand (advertising, opening credits for a broadcast or a series, etc.). This recognition can then provide a reference time, on the basis of which several subsequent instants can be accurately determined by means of predefined timeouts. The invention can thus be particularly advantageous in the case where the synchronization is implemented at the level of receivers, since it can make it possible to reduce the dispatching and recording of reference events (gain in bandwidth, in processing time and in space required for storage).</p>
<p id="p-0040" num="0039">The use of a lag, designed to delay the triggering of an action in case of detection of the synchronization signals, appears to be particularly unexpected having regard to the commonly accepted concepts. Specifically, the concept of lag is associated in the state of the art with a bringing into action at a precise and predefined instant, that the lag makes it possible to specify (such as, for example, in the prior document WO 02/21840, page 8, lines 17-24). On the contrary, in the invention, the lag leads to a non-predefined and unforecastable instant that is conditioned and made precise through the detection of the synchronization signals.</p>
<p id="p-0041" num="0040">In the definition of the recognition unit, as in the remainder of the patent application, the &#x201c;units&#x201d; and &#x201c;modules&#x201d; are to be understood in a functional sense, and are therefore not limited to particular realizations. Thus, they may in particular be grouped together into one and the same component or one and the same piece of software, or on the contrary be dispersed among various components. Moreover, the recognition unit can be installed broadcasting side (typically at the broadcaster's premises), service operator side, or in a terminal for receiving audiovisual programmes, preferably an interactive one, in embedded form.</p>
<p id="p-0042" num="0041">The recognition elements received and/or the portions extracted can be applied to one or to several programmes, broadcasting simultaneously or successively. For example, programmes being recurrent over time, it is sufficient to transmit images just once for a synchronization to actually be programmed.</p>
<p id="p-0043" num="0042">Moreover, to a given detection of synchronization elements, there may correspond several timeouts defining successive instants. The timeout and transmission modules are then able to use a detection instant as a reference instant, from which the timeout module determines several instants for triggering dispatching of action instructions. In a sophisticated version, the timeout module is able to combine more complex information than a single detection instant and predefined durations to determine these triggering instants. Such information may in particular consist of:</p>
<p id="p-0044" num="0043">several detection instants (for example two detection instants serve to specify at least three instants for triggering dispatching of instructions);</p>
<p id="p-0045" num="0044">operators pertaining to the synchronization signals detected (for example, distinct extracted portions are associated respectively with various groups of lags);</p>
<p id="p-0046" num="0045">detection time slots (for example the lags are shorter if the detections are performed during later time slots);</p>
<p id="p-0047" num="0046">or any combination of the above information.</p>
<p id="p-0048" num="0047">Preferably, the modules for receiving and recording the recognition elements in the recognition unit are designed so as respectively to receive and record also at least one timeout lag and the timeout module is designed to use this lag. According to other embodiments, the lag is predefined, or determined locally by the user.</p>
<p id="p-0049" num="0048">Advantageously, the modules for receiving and recording recognition elements and the module for transmitting action instructions are designed so as respectively to receive, record and transmit identifiers relating to the actions to be triggered. The recognition criteria and the actions to be performed are thus specified at one and the same time.</p>
<p id="p-0050" num="0049">In a preferred form of communication of action identifiers, recognition elements and action identifiers are received jointly in the form of pairs, each of these pairs comprising a set of recognition elements and an associated identifier of actions.</p>
<p id="p-0051" num="0050">In other embodiments, the action identifiers are received separately and are applied to all the detections subsequently performed with the successively transmitted recognition elements. In yet other embodiments, the actions to be triggered are predefined, or decided by users independently of the recognition operations.</p>
<p id="p-0052" num="0051">Preferably, each of the portions of content consists of at least one of the following portions: an image, an image part, a sound and any combination of at least two of these portions.</p>
<p id="p-0053" num="0052">In a first advantageous form of the recognition elements, the latter include at least one boolean operator. The detection module is designed to detect at least two of the portions of content in conjunction with this boolean operator (such as, in particular, &#x201c;and&#x201d; or &#x201c;or&#x201d;) and the transmission module is designed to transmit the action instructions in case of such detection.</p>
<p id="p-0054" num="0053">For example, identifications associated with action identifiers are combined in the following manner:</p>
<p id="p-0055" num="0054">if (image <b>1</b> detection AND image <b>2</b> detection), then trigger action <b>1</b>,</p>
<p id="p-0056" num="0055">if (image <b>3</b> detection OR image <b>4</b> detection), then trigger action <b>2</b>.</p>
<p id="p-0057" num="0056">In a second advantageous form of the recognition elements, the latter include at least one time information item. The detection module is designed to detect the portions of content in conjunction with this time information item and the transmission module is designed to transmit the action instructions in case of such detection. Preferably, this time information item comprises at least one information item chosen from among a date of detection and a detection time slot.</p>
<p id="p-0058" num="0057">For example, a start of detection date/time and an end of detection date/time are indicated for each detection, thereby making it possible to restrict the number of comparisons to be performed for each recognition element received. This technique is beneficial in particular for the broadcasting of interactive services. Specifically, the time of broadcasting of an audiovisual programme is generally known to within a few minutes and only one service is broadcast at a time, so that the programming of a single detection at a given instant is sufficient to trigger the broadcasting of this service.</p>
<p id="p-0059" num="0058">In another example, the detection of the portions of contents is combined with tests on the current date:</p>
<p id="p-0060" num="0059">if (image <b>1</b> detection AND image <b>2</b> detection), then trigger service <b>1</b>,</p>
<p id="p-0061" num="0060">if (image <b>3</b> detection AND current_date( )==06092002), then trigger recording.</p>
<p id="p-0062" num="0061">In a third advantageous form of the recognition elements, the latter include at least one channel reference. The detection module is then designed to detect the portions of content in conjunction with this channel reference and the transmission module is designed to transmit the action instructions in the case of such detection.</p>
<p id="p-0063" num="0062">By transmitting an information item regarding the station on which detection should be done, one avoids unnecessarily invoking the recognition unit when no detection is programmed on the current station. This extra information item also makes it possible to programme detection on a station in particular, the recognition element to be detected possibly being broadcast on several stations&#x2014;for example a commercial break. By default and without any information as to station, the detection is preferably activated permanently and without distinction of station.</p>
<p id="p-0064" num="0063">Upstream of the recognition unit, the extracted portions of the content of the audiovisual programme can be obtained directly and explicitly from the programme, or be determined separately from the programme by virtue of knowledge of the latter. For example, this may involve a word or a group of words that a presenter has to utter, or an object that has to appear on the screen. In all cases, the portion of content is known a priori, and communicated to the recognition unit prior to the transmission of the audiovisual programmes. The recognition may thus be of a deterministic nature, and not be based in any way on statistical or experimental matches (such as the teaching of document WO 01/91462).</p>
<p id="p-0065" num="0064">On the other hand, in advantageous embodiments, the detection of the synchronization signals relies on the recognition of several portions of content, or on the crossing of recognition of such portions with other types of information (station, system variable such as the current date, possibly programme guide, etc.). Thus, several images are advantageously used in case of uncertainty regarding the content of the programme or in order to boost the chances of detection of the programme, the detection of one of the images triggering the action process.</p>
<p id="p-0066" num="0065">Three preferred modes of obtaining the portions extracted by the recognition unit are distinguished, the latter advantageously combining the capabilities of at least two of these embodiments:</p>
<p id="p-0067" num="0066">the recognition elements include the extracted portion; the extracted portions included in the recognition elements are thus advantageously transmitted to the recognition unit by a specific unit (such as that defined hereinafter as the &#x201c;specification unit&#x201d;);</p>
<p id="p-0068" num="0067">the recognition elements comprise instructions for extracting the portion of content in at least one stream of an audiovisual programme previously received by the stream reception module; the recording module is then designed to extract directly this portion of the stream according to the extraction instructions and to record it in the storage space;</p>
<p id="p-0069" num="0068">and the recognition elements include at least one identifier of the extracted portion, this portion being intended to be recorded in the storage space prior to a detection (as described above).</p>
<p id="p-0070" num="0069">In the embodiment with extraction instructions, it is possible to receive and record directly the portions extracted from the audiovisual programmes received, under the effect of instructions for extractions at determined instants and according to determined conditions. The module for receiving the transmitted stream is then utilized as part of the recognition elements reception module.</p>
<p id="p-0071" num="0070">This avoids voluminous transmissions of information, that might be very penalizing in certain cases (for example, communication of complete images in an analogue television environment, for which the bandwidth in terms of data is reduced to a few tens of k-bytes/second).</p>
<p id="p-0072" num="0071">Thus, according to an advantageous embodiment with implementation of the recognition unit in a terminal, a trigger of particular type is used, indicating to the terminal the fact that the image or the sound broadcast at the moment of receipt of the trigger must be stored, as must the extracted-portion identifier transmitted with the trigger. In practice, the accuracy in the synchronization between the receipt of this trigger and the broadcasting of the image or of the sound to be recorded is not paramount, in so far as any extracted portion whatsoever of a determined sequence able to serve as tag (for example broadcasting of advertising banner credits) may be suitable.</p>
<p id="p-0073" num="0072">Moreover, in an embodiment combining the modes of obtainment by inclusion of portions in the recognition elements and by utilization of identifiers, the reception and recording modules are able to receive and store extracted portions utilizable for several distinct types of detection. Each portion or set of portions associated with a type of detection is then specified by a one-to-one portion identifier. This prior storage allows the subsequent dispatching to the recognition unit of recognition partial elements including the identifiers of portions instead of the extracted portions themselves. These recognition partial elements, which may comprise recognition information such as in particular time slot, broadcasting channel and/or boolean operator, are possibly accompanied by action information and/or timeout information. Thus, the recognition elements in their entirety are obtained in at least two successive steps: extracted portions, then associated recognition instructions.</p>
<p id="p-0074" num="0073">This embodiment avoids bandwidth-hungry multiple operations of transmitting one and the same extracted portion, once the initial step of transmitting this portion has been accomplished. Moreover, even in case of single use of an extracted portion, it makes it possible to anticipate subsequent recognition instructions. Thus, the extracted portions can be dispatched in periods of greatest availability of bandwidth (typically, at night or during the weekend) and subsequently communicate the recognition instructions, which may require only a small bandwidth (since the portion identifiers are sufficient to unambiguously designate these portions). In this way, even if these instructions are transmitted only shortly before they are implemented, the reliability of their reception and of their utilization in due course is substantially increased.</p>
<p id="p-0075" num="0074">The advantages mentioned hereinabove are particularly beneficial if the recognition unit is installed in a terminal, or more generally downstream of an extended communication network designed to support the transport of the extracted portions.</p>
<p id="p-0076" num="0075">The invention also relates to a specification unit for specifying synchronization signals associated with at least one audiovisual programme, this (or these) audiovisual programme(s) comprising an audiovisual content intended to be broadcast to users and control information, and the synchronization signals being intended to be detected in at least one transmitted stream carrying this audiovisual programme and to thus trigger at least one action.</p>
<p id="p-0077" num="0076">According to the invention, the specification unit comprises:</p>
<p id="p-0078" num="0077">a preparation module for preparing recognition elements making it possible to obtain at least one extracted portion of the content of the audiovisual programme,</p>
<p id="p-0079" num="0078">and a transmission module for transmitting the recognition elements independently of transmissions of the audiovisual programme, to at least one recognition unit intended to detect the synchronization signals in the transmitted stream carrying the audiovisual programme, by recognizing the extracted portion(s) in the content of the audiovisual programme.</p>
<p id="p-0080" num="0079">The preparation and transmission modules of this specification unit are designed respectively to prepare and transmit at least one action timeout lag in case of detection of synchronization signals.</p>
<p id="p-0081" num="0080">This specification unit is preferably capable of cooperating with any one of the embodiments of the recognition unit of the invention. The action timeout lag transmitted by the specification unit can also be utilized downstream of the recognition system, at the level of the executing of the actions.</p>
<p id="p-0082" num="0081">More precisely, in a first form of use of the timeout lag, the latter is designed to bring about a timeout between the detection of the detection signals and the transmission of action instructions. The lag is then preferably transmitted separately from the recognition elements and action identifiers, and jointly with the corresponding elements and identifiers. In a second form, it is designed to bring about a timeout between the reception of action instructions and their triggering. The lag is then preferably incorporated into a corresponding action identifier.</p>
<p id="p-0083" num="0082">Preferably, the preparation and transmission modules of this specification unit are designed respectively to prepare and transmit identifiers relating to the actions to be triggered in case of detection of the synchronization signals.</p>
<p id="p-0084" num="0083">The action identifiers then advantageously relate to at least one of the following actions: broadcasting of an interactive service, triggering of an interactive service, triggering of an update of an interactive service, triggering of a recording of the audiovisual programme and connection to a website. The first action is more specifically intended for a detection of synchronization signals at the level of a broadcaster or of a services operator, while the last three actions are typically applicable in the case where the recognition is performed in a terminal for receiving audiovisual programmes (for example triggering of an embedded service, possibly consisting in the triggering of its appearance).</p>
<p id="p-0085" num="0084">It is thus possible to distinguish in particular two embodiments implementing an action timeout lag:</p>
<p id="p-0086" num="0085">local determination of the lag at the level of the detecting of the synchronization signals or of the executing of the action (predefined lag or one chosen by a user);</p>
<p id="p-0087" num="0086">or determination of the lag upstream of the detection, preferably at the level of the specifying of the recognition elements.</p>
<p id="p-0088" num="0087">Moreover, in each of these two cases, it is possible to envisage an application of the action timeout lag at the detection level, or at the action execution level.</p>
<p id="p-0089" num="0088">Moreover, in other embodiments already alluded to above, this determination can pertain to criteria giving the timeout lag or lags. For example, pairs of lags and of time slots respectively associated are determined for the detecting of the synchronization signals.</p>
<p id="p-0090" num="0089">As far as the recognition elements are concerned, the following three embodiments are distinguished for the obtainment of the extracted portion:</p>
<p id="p-0091" num="0090">the recognition elements include this extracted portion;</p>
<p id="p-0092" num="0091">the recognition elements comprise instructions for extracting this extracted portion in at least one stream of an audiovisual programme previously received by the recognition unit;</p>
<p id="p-0093" num="0092">and the recognition elements include at least one identifier of this extracted portion previously recorded in the storage space.</p>
<p id="p-0094" num="0093">The invention also relates to an assembly for activation by recognition of synchronization signals in at least one audiovisual programme received, comprising a recognition unit and an activation unit and in accordance with claim <b>15</b>. In such an activation assembly, the triggering delay by means of the timeout lag is applied either by the recognition unit, or by the activation unit, or by both (two aggregated delays). It is beneficial for the recognition unit to be in accordance with one of the embodiments of the invention.</p>
<p id="p-0095" num="0094">According to an advantageous form, the activation assembly is designed to receive said timeout lag with the recognition elements.</p>
<p id="p-0096" num="0095">The invention applies also to a synchronization system as defined in claim <b>17</b>, comprising a unit for specifying synchronization signals, a unit for recognizing the synchronization signals, and an activation unit designed to trigger at least one action in case of detection of the synchronization signals by the recognition unit.</p>
<p id="p-0097" num="0096">The recognition unit, the specification unit and/or the activation assembly made up of the recognition and activation units, are preferably in accordance with any one of the embodiments of the invention.</p>
<p id="p-0098" num="0097">The subjects of the invention are also a broadcasting centre, a services operator and a terminal for receiving audiovisual programmes, comprising a specification module, a recognition module, an activation assembly and/or a synchronization system which are in accordance with any one of the embodiments of the invention.</p>
<p id="p-0099" num="0098">In the case where the recognition unit is in a reception terminal, according to an advantageous implementation, recognition elements and associated interactive services are advantageously transmitted in phase advance to the terminal. When, for example, the viewers are offered no interactivity, this makes it possible to increase the proportion of televisions capable of offering interactivity. The terminal then preferably has means for storing the recognition elements and interactive services in the permanent memory, for example of flash type. This embodiment makes it possible to program continuing synchronizations with switch offs and switch ons of the terminal. In this way, the chances of offering interactivity are increased despite a complete provisional shutdown of the system.</p>
<p id="p-0100" num="0099">In a first mode of dispatching the recognition elements and associated services to a terminal comprising a recognition unit, one or more associations of sets of recognition elements and of corresponding interactive services are transmitted jointly (in phase advance), preferably by broadcasting. The dispatching of several associations of this type which are intended to be utilized in parallel is completed by communicating action identifiers coupled to the sets of elements, these identifiers indicating which services are the ones to be instigated.</p>
<p id="p-0101" num="0100">In a second mode of dispatching the recognition elements and associated services to a terminal comprising a recognition unit, the dispatching of the recognition elements and of the services is separated. Action identifiers are then attached to the recognition elements so as to make the latter correspond to the services to be instigated.</p>
<p id="p-0102" num="0101">The invention also relates to a method of activation by recognition of synchronization signals in at least one audiovisual programme received, in accordance with claim <b>21</b>. This recognition method is preferably implemented by means of an activation assembly in accordance with any one of the forms of the invention.</p>
<p id="p-0103" num="0102">The invention moreover relates to a method of specifying synchronization signals and a method of synchronization which are respectively in accordance with claims <b>22</b> and <b>23</b>. These methods are preferably implemented respectively by means of a specification unit and a synchronization system which are in accordance with any one of the forms of the invention.</p>
<p id="p-0104" num="0103">Preferably, in the methods defined hereinabove, the audiovisual programmes comprise at least one recognition part containing at least one of the recognition portions, and at least one live transmission intended to be broadcast following the recognition part. In this way, the synchronization signals are detected during the broadcasting of the recognition part and the action is triggered during the broadcasting of the following live transmission, by means of the timeout lag.</p>
<p id="p-0105" num="0104">The subject of the invention is also a computer programme product, characterized in that it comprises programme code instructions for executing the steps of one of the methods according to the invention when this programme is executed on a computer. The expression &#x201c;computer programme product&#x201d; is understood to mean a computer programme support that can consist not only of a storage space containing the programme, such as a diskette or a cassette, but also of a signal, such as an electrical or optical signal.</p>
<p id="p-0106" num="0105">The invention will be better understood and illustrated by means of the following wholly nonlimiting exemplary embodiments and implementations, with reference to the appended figures in which:</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0107" num="0106"><figref idref="DRAWINGS">FIG. 1</figref> is a basic diagram of a synchronization system in accordance with the invention;</p>
<p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. 2</figref> represents a specification unit of the synchronization system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. 3</figref> represents a recognition unit of the synchronization system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0110" num="0109"><figref idref="DRAWINGS">FIG. 4</figref> represents an activation unit of the synchronization system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0111" num="0110"><figref idref="DRAWINGS">FIG. 5</figref> diagrammatically illustrates a communication network comprising a broadcasting centre (or broadcaster) together with a broadcasting server, a services operator together with point-to-point server and a mass-market terminal, interactive or otherwise;</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 6</figref> shows the time profile of a carousel broadcast of services;</p>
<p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. 7</figref> shows a first mode of implementation of the synchronization system of <figref idref="DRAWINGS">FIG. 1</figref> in the communication network of <figref idref="DRAWINGS">FIG. 5</figref>, with synchronization system at the services operator's premises;</p>
<p id="p-0114" num="0113"><figref idref="DRAWINGS">FIG. 8</figref> shows a second mode of implementation of the synchronization system of <figref idref="DRAWINGS">FIG. 1</figref> in the communication network of <figref idref="DRAWINGS">FIG. 5</figref>, with specification unit at the services operator's premises and recognition and activation units at the broadcaster's premises;</p>
<p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. 9</figref> shows a third mode of implementation of the synchronization system of <figref idref="DRAWINGS">FIG. 1</figref> in the communication network of <figref idref="DRAWINGS">FIG. 5</figref>, with specification unit at the broadcaster's premises and recognition and activation units in the terminal;</p>
<p id="p-0116" num="0115">and <figref idref="DRAWINGS">FIG. 10</figref> represents in diagrammatic form a set-up of the recognition and activation units in the terminal, for the mode of implementation of <figref idref="DRAWINGS">FIG. 9</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0117" num="0116">A synchronization system <b>5</b> (<figref idref="DRAWINGS">FIG. 1</figref>) is designed to synchronize audiovisual programmes <b>15</b> and interactive services S. It comprises a synchronization signals specification unit <b>1</b>, able to prepare pairs <b>10</b> each consisting of a set of recognition elements <b>11</b> and of an action identifier <b>12</b>, from audiovisual programmes <b>15</b> and selection operations performed by a user, before broadcasting of the programmes <b>15</b> over a network. In each of these pairs <b>10</b>, the recognition elements <b>11</b> include at least one extracted portion of the content of the programme <b>15</b>, which portion is intended to serve as synchronization signal (at least partial). The action identifiers <b>12</b> of each of the pairs <b>10</b> contain information relating to the execution of actions in case of detection of such synchronization signals in the streams carrying the programmes <b>15</b>.</p>
<p id="p-0118" num="0117">A recognition unit <b>2</b> is designed to record the pairs <b>10</b> originating from the specification unit <b>1</b>, to use them upon receipt of streams carrying the programmes <b>15</b> so as to recognize the portions of content in the programmes and, under the conditions defined by the sets of recognition elements <b>11</b>, to identify occurrences of synchronization. It is also intended to transmit the action identifiers <b>12</b> for triggering of these actions, in case of detections of identification signals corresponding to these actions.</p>
<p id="p-0119" num="0118">An activation unit <b>3</b> is designed to receive the action identifiers <b>12</b> originating from the recognition unit <b>2</b> and to trigger the appropriate actions A.</p>
<p id="p-0120" num="0119">The three units <b>1</b>, <b>2</b> and <b>3</b> of the synchronization system will now be detailed, with reference respectively to <figref idref="DRAWINGS">FIGS. 2</figref>, <b>3</b> and <b>4</b>. The specification unit <b>1</b> (<figref idref="DRAWINGS">FIG. 2</figref>) comprises an input module <b>31</b> for the audiovisual programmes <b>15</b> and a module <b>32</b> for controlled broadcasting to an operator of contents <b>16</b> of these programmes <b>15</b>. The programmes <b>15</b>, or at least significant parts of these programmes (picture, sound, colour of a banner, etc.), are for this purpose available in phase advance for the operator responsible for programming the synchronization system <b>5</b>. Typically, the latter has available a recording on cassette or DVD, or a sequence intended to be inserted into a transmission. The operator can, for example, view one of the programmes <b>15</b> picture by picture, or listen to certain passages of sound.</p>
<p id="p-0121" num="0120">A user interface <b>33</b> of the specification unit <b>1</b> allows the operator to input commands <b>17</b> in conjunction with this controlled broadcasting. It permits the operator to select pictures, sounds, parts of pictures or combinations of these portions of content, so as to construct them into recognition elements <b>11</b>. The interface <b>33</b> also allows him to define more complex recognition criteria, based on conjunctions or alternatives (respectively: several portions, or at least one portion from several, to be recognized), time criteria (date, time slot) or stations. The interface <b>33</b> also allows the operator to define action identifiers <b>12</b> associated with the recognition elements <b>11</b>, such as the triggering or the broadcasting of an identified interactive service, and timeout lags, between the detecting of synchronization signals and the triggering of corresponding actions. Such lags are:</p>
<p id="p-0122" num="0121">either transmitted separately in the form of lags <b>13</b> designed for a timeout between a detection by the recognition unit <b>2</b> and a transmission of the action identifiers <b>12</b> to the activation unit <b>3</b>,</p>
<p id="p-0123" num="0122">or incorporated into the action identifiers <b>12</b> for timeouts between their reception by the activation unit <b>3</b> and the triggering of the corresponding actions A.</p>
<p id="p-0124" num="0123">The joint use of the two types of lags is also possible.</p>
<p id="p-0125" num="0124">A preparation module <b>34</b> establishes the pairs <b>10</b> and the lags <b>13</b> as a function of the operator's commands and communicates them to a transmission module <b>37</b> for transmission to the recognition unit <b>2</b>. This preparation module <b>34</b> comprises in particular a submodule <b>35</b> for extracting the portions selected from the programmes <b>15</b> and a submodule <b>36</b> for defining the action identifiers <b>12</b>.</p>
<p id="p-0126" num="0125">The recognition unit <b>2</b> (<figref idref="DRAWINGS">FIG. 3</figref>) comprises for its part a reception module <b>21</b> for receiving the audiovisual programmes <b>15</b> and a reception module <b>24</b> for receiving the information originating from the specification unit <b>1</b>, including the pairs <b>10</b> and the timeout lags <b>13</b>. A recording module <b>25</b> makes it possible to automatically record this information in a storage space <b>20</b>.</p>
<p id="p-0127" num="0126">The recognition unit <b>2</b> also comprises a synchronization signals detection module <b>22</b> intended in particular for comparing the contents of the programmes <b>15</b> with the portions of contents of the recognition elements <b>11</b>, contained in the pairs <b>10</b> stored in the storage space <b>20</b>. The detection module <b>22</b> is in conjunction with the information sources capable of serving for the identification of the selection criteria, for example a clock <b>28</b> providing time information in case of time criteria (date, time span). The detection module <b>22</b> is designed to communicate the action identifiers <b>12</b> and the associated timeout lags <b>13</b> as they are in case of detection of the synchronization signals, to a transmission module <b>23</b> for transmitting instructions via a timeout module <b>26</b>. The function of the latter is to possibly time out the transmission in the presence of timeout lags <b>13</b>, while the transmission module <b>23</b> is intended to transmit the action identifiers <b>12</b> to the activation unit <b>3</b> as they are.</p>
<p id="p-0128" num="0127">In an improved version, the interface <b>33</b> and the preparation module <b>34</b> of the specification unit <b>1</b> permits the operator not only to shape the recognition elements <b>11</b> including the portions of contents to be used for detection, but also to proceed in another manner, by formulating information which allows the recognition unit <b>2</b> to identify and obtain the portions of contents via the reception module <b>21</b> for receiving the audiovisual programmes <b>15</b>. For example, this information may consist of a channel and a timetable, this timetable possibly being replaced by an indicator of instantaneous selection. This information may be dispatched in the form of triggers, designed to trigger at the level of the recognition unit <b>2</b> the extraction and the recording of the targeted portions.</p>
<p id="p-0129" num="0128">The recording module <b>25</b> of the recognition unit <b>2</b> is then capable of proceeding to the recording of the extracted portions as a function of the information transmitted by the specification unit <b>1</b>, without these portions having had to travel between the specification unit <b>1</b> and the recognition unit <b>2</b>.</p>
<p id="p-0130" num="0129">The activation unit <b>3</b> (<figref idref="DRAWINGS">FIG. 4</figref>) comprises a reception module <b>41</b> for receiving the action identifiers <b>12</b>, a module for extracting action information from these identifiers <b>12</b>, and for transmitting action instructions <b>18</b> and timeout lags <b>19</b>, if any, to an action triggering module <b>44</b>, via a timeout module <b>43</b>. The function of the latter is to time out the transmission of the action instructions <b>18</b> as they are, according to the timeout lags <b>19</b>. The job of the triggering module <b>44</b> is to trigger the actions A targeted by the action instructions <b>18</b>, as soon as the latter are received.</p>
<p id="p-0131" num="0130">The synchronization system <b>5</b> will now be set forth in several practical applications of interactive television, involving a communication network (<figref idref="DRAWINGS">FIG. 5</figref>) which comprises a broadcaster <b>50</b>, a services operator <b>60</b> and a mass-market interactive terminal <b>70</b>. The broadcaster <b>50</b> is linked to terminals of the type of the terminal <b>70</b>, by a mono-directional network <b>81</b> (an RF cable or satellite TV broadcasting network). The services operator <b>60</b> may or may not be linked to the terminal <b>70</b>, by a bi-directional network <b>82</b> (modem return path, cable, etc.) of point-to-point type, such as the telephone network. The broadcaster <b>50</b> and the services operator <b>60</b> are, for example, connected to one another by a link <b>83</b> of the TCP-IP type, on which a bus in accordance with the CORBA (standing for Common Object Request Broker Architecture) standard is deployed.</p>
<p id="p-0132" num="0131">It is envisaged that the broadcaster <b>50</b> broadcasts in a loop (carousel) interactive contents or their URLS, called interactive services S for simplicity, for the duration of the associated audiovisual programmes <b>15</b>. In an operational example (<figref idref="DRAWINGS">FIG. 6</figref>), the broadcaster <b>50</b> broadcasts successively in the course of the time t the services S<b>1</b>, S<b>2</b> and S<b>3</b> in a loop, jointly with the respective enhanced programmes PG<b>1</b>, PG<b>2</b> and PG<b>3</b>, until instants of end of availability FS<b>1</b>, FS<b>2</b> and FS<b>3</b> of the services S.</p>
<p id="p-0133" num="0132">In a first embodiment (<figref idref="DRAWINGS">FIG. 7</figref>), the synchronization system <b>5</b> is installed in a computer <b>62</b> of the services operator <b>60</b> and is controlled by an operator <b>61</b> via a network <b>84</b>. When operational, the following is carried out:</p>
<p id="p-0134" num="0133">Step 1: programming of the specification unit <b>1</b> of the synchronization system <b>5</b>, by locking onto the station where the audiovisual programme <b>15</b> is broadcast and defining of pictures and/or sounds to be detected (recognition elements <b>11</b>) and the action identifier <b>12</b> to be dispatched;</p>
<p id="p-0135" num="0134">Step 2: when the moment of broadcasting the programme <b>15</b> has arrived, a video server or a video recorder of the broadcaster <b>50</b> commences the broadcasting of the audiovisual programme <b>15</b>;</p>
<p id="p-0136" num="0135">Step 3: broadcasting of the audiovisual programme <b>15</b> alone (via broadcasting relays <b>56</b>);</p>
<p id="p-0137" num="0136">Step 4: the synchronization system <b>5</b> then receives the audiovisual programme <b>15</b> pictures with which it has to synchronize an interactive service S and analyses them;</p>
<p id="p-0138" num="0137">Step 5: when the programmed picture is detected, the synchronization system <b>5</b> notifies a broadcasting server of the broadcaster <b>50</b>, which can then trigger the broadcasting of the interactive service S simultaneously with the audiovisual programme <b>15</b>;</p>
<p id="p-0139" num="0138">Step 6: broadcasting of the interactive service S and of the audiovisual programme <b>15</b> simultaneously.</p>
<p id="p-0140" num="0139">In a second embodiment (<figref idref="DRAWINGS">FIG. 8</figref>), the specification unit <b>1</b> is installed within the services operator <b>60</b>, as in the first embodiment of <figref idref="DRAWINGS">FIG. 7</figref>, but the recognition <b>2</b> and activation <b>3</b> units are installed in the broadcasting server of the broadcaster <b>50</b>. The course of the operational steps is for the remainder similar to that of the first embodiment.</p>
<p id="p-0141" num="0140">In a third embodiment (<figref idref="DRAWINGS">FIG. 9</figref>), the specification unit <b>1</b> is now installed at the broadcaster <b>50</b>, and the recognition <b>2</b> and activation <b>3</b> units are embedded in the terminal <b>70</b>. More precisely (<figref idref="DRAWINGS">FIG. 10</figref>), the terminal <b>70</b> comprises a block <b>71</b> for retrieving broadcast signals (involving the operating system and drivers), which is designed to receive in particular pictures to be detected (more generally: pairs <b>10</b> of sets of recognition elements <b>11</b> and of action identifiers <b>12</b>) and interactive services S. This block <b>71</b> is designed to communicate the pictures to be detected to the recognition unit <b>2</b>, and the interactive services S to an interactivity or presentation engine <b>72</b>.</p>
<p id="p-0142" num="0141">While operational, the following is carried out:</p>
<p id="p-0143" num="0142">Step 1: programming by an operator of the broadcaster <b>50</b> of the recognition unit <b>2</b> of the synchronization system <b>5</b>, by choosing the sound or picture elements for the synchronization and broadcasting in phase advance of the element to be detected (more generally: of the pair <b>10</b>) and of the interactive service S to be executed when this element is detected;</p>
<p id="p-0144" num="0143">Step 2: when the moment of broadcasting the programme <b>15</b> has arrived, a video server or a video recorder of the broadcaster <b>50</b> commences the broadcasting of the audiovisual programme <b>15</b>;</p>
<p id="p-0145" num="0144">Step 3: broadcasting of the audiovisual programme <b>15</b> alone;</p>
<p id="p-0146" num="0145">Step 4: the recognition unit <b>2</b> embedded in the terminal <b>70</b> then receives the audiovisual programme <b>15</b> pictures to which it has to synchronize the interactive service S and analyses them;</p>
<p id="p-0147" num="0146">Step 5: when the programmed picture and/or sound is detected, the recognition unit <b>2</b> notifies the interactivity engine <b>72</b> via the activation unit <b>3</b>, and the engine <b>72</b> can then trigger the execution of the interactive service S; in variants, the action to be triggered is the displaying or the updating of the interactive service on the terminal <b>70</b>;</p>
<p id="p-0148" num="0147">Step 6: appearance of the interactive service S and of the audiovisual programme <b>15</b> simultaneously.</p>
<p id="p-0149" num="0148">An advantage of this third embodiment as compared with the first two is that a shift is avoided between the moment at which the audiovisual programme <b>15</b> is broadcast and the moment at which the interactive service S is inserted into the latter. However, it requires appreciable resources in the terminal <b>70</b> (CPU, memory, etc.).</p>
<p id="p-0150" num="0149">In a variant embodiment, the specification unit <b>1</b> is designed to communicate beforehand to the recognition unit <b>2</b>, several extracted portions associated respectively with one-to-one identifiers of portions. Thus, during the phase of storing each extracted portion in the storage space <b>20</b>, the recording module <b>25</b> also stores the corresponding portion identifier. During a subsequent step of specifying a targeted detection, the specification unit <b>1</b> simply has to dispatch the portion identifiers instead of the portions themselves, in the recognition elements <b>11</b> of the pairs <b>10</b>. These identifiers then play the role of keys making it possible to link the appearance of the extracted portions and the other parameters, such as in particular timeout lags <b>13</b> or <b>19</b> and/or actions to be triggered.</p>
<p id="p-0151" num="0150">For example, the prior step of transmitting extracted portions defines three identifiers ID<b>1</b>, ID<b>2</b> and ID<b>3</b> associated respectively with three extracted portions POR<b>1</b>, POR<b>2</b> and POR<b>3</b> (Table 1), then the subsequent transmission step giving instructions for synchronizing actions defines lags and actions A&#x2032; and A&#x2033; respectively associated with the identifiers ID<b>2</b> and ID<b>1</b> (Table 2).</p>
<p id="p-0152" num="0151">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Recording of portions and of associated identifiers</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="35pt" align="left"/>
<colspec colname="1" colwidth="56pt" align="center"/>
<colspec colname="2" colwidth="126pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>Portion identifier</entry>
<entry>Extracted portion</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>ID1</entry>
<entry>POR1</entry>
</row>
<row>
<entry/>
<entry>ID2</entry>
<entry>POR2</entry>
</row>
<row>
<entry/>
<entry>ID3</entry>
<entry>POR3</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0153" num="0152">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 2</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Instructions for synchronizing actions</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="112pt" align="center"/>
<colspec colname="2" colwidth="21pt" align="center"/>
<colspec colname="3" colwidth="84pt" align="center"/>
<tbody valign="top">
<row>
<entry>Portion identifier</entry>
<entry>Lag</entry>
<entry>Action</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="112pt" align="center"/>
<colspec colname="2" colwidth="21pt" align="char" char="."/>
<colspec colname="3" colwidth="84pt" align="center"/>
<tbody valign="top">
<row>
<entry>ID2</entry>
<entry>8</entry>
<entry>A&#x2032;&#x2009;</entry>
</row>
<row>
<entry>ID1</entry>
<entry>10</entry>
<entry>A&#x2033;</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0154" num="0153">In a particular embodiment of this variant, the detection specificauons targeted may also contain detection time slots. If the recognition unit <b>2</b> detects that the current time is outside these time slots, it does not proceed to the analysis of the contents broadcast. In the converse case, the detection module is activated. Several recognition time slots may moreover overlap. For example, the identifiers ID<b>1</b> and ID<b>2</b> are respectively associated with a detection &#x201c;Every Friday between 3 p.m. and 4 p.m.&#x201d; and &#x201c;Every day except weekends between 12 midday and 4 p.m.&#x201d;.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. Recognition unit comprising a processor for executing instructions for recognizing audiovisual portions of audiovisual content from at least a first audiovisual programme in at least a second audiovisual programme, said audiovisual portions serving as synchronization signals, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a first audiovisual programme and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, said recognition unit comprising:
<claim-text>a reception module for receiving recognition elements and a recording module for recording said recognition elements in a storage space, said recognition elements comprising at least one audiovisual portion of audiovisual content extracted from said at least a first audiovisual programme, said recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these audiovisual portions of audiovisual content of said first audiovisual programme, said at least one audiovisual portion being also comprised in said at least a second audiovisual programme, and said recording module extracting said at least one audiovisual portion of content from said at least a first audiovisual programme and said recording module recording said at least one extracted audiovisual portion in said storage space,</claim-text>
<claim-text>a reception module for receiving said at least a second audiovisual programme and said at least a first audiovisual programme, said at least a first audiovisual programme being received prior to reception of said at least a second audiovisual programme,</claim-text>
<claim-text>a detection module for detecting said synchronization signals in said at least a second audiovisual programme by means of said recognition elements stored in said storage space, by recognition in the audiovisual content of said at least a second audiovisual programme, of said at least one extracted audiovisual portion,</claim-text>
<claim-text>and a transmission module for transmitting action instructions in case of detection of said synchronization signals in said at least a second audiovisual programme, said instructions triggering at least one action,</claim-text>
<claim-text>and said recognition unit also comprising a timeout module for timeout before said transmission of action instructions by the transmission module when said synchronization signals are detected in said at least a second audiovisual programme.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. Recognition unit according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said reception module for receiving recognition elements and said recording module for recording said recognition elements receive and record also at least one timeout lag and in that the timeout module uses said lag.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. Recognition unit according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the module for receiving recognition elements and said recording module for recording recognition elements and the module for transmitting action instructions respectively receive, record and transmit identifiers relating to said actions to be triggered.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. Recognition unit according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said recognition elements include at least one Boolean operator, said detection module detecting at least two of said audiovisual portions of audiovisual content in conjunction with said boolean operator and the transmission module transmitting said action instructions in case of such detection.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. Recognition unit according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said recognition elements include at least one time information item, said detection module detecting said audiovisual portions of audiovisual content in conjunction with said time information item and the transmission module being transmitting said action instructions in case of such detection.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. Recognition unit according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein said time information item comprises at least one information item chosen from among a date of detection and a detection time slot.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. Recognition unit according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said recognition elements include at least one channel reference, said detection module detecting said audiovisual portions of audiovisual content in conjunction with said channel reference and the transmission module transmitting said action instructions in the case of said detecting.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. Recognition unit according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the reception module for receiving recognition elements receives among said recognition elements, instructions for extracting said at least one audiovisual portion of said at least a first audiovisual programme, and said recording module extracts directly said at least one audiovisual portion according to said instructions for extracting and records said at least one audiovisual portion in the storage space.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. Recognition unit according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the reception module for receiving recognition elements receives from among said recognition elements, at least one identifier of said at least one audiovisual portion, and in that said detection module retrieves from the storage space said at least one audiovisual portion previously recorded and associated with said identifier, so as to recognize in the audiovisual content of said at least a second audiovisual programme said at least one audiovisual portion.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. Activation assembly comprising a processor for executing instructions for activation by recognition of audiovisual portions of audiovisual content from at least a first audiovisual programme in at least a second audiovisual programme, said audiovisual portions serving as synchronization signals, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a first audiovisual programme and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, the activation assembly comprising:
<claim-text>a recognition unit for recognizing said synchronization signals in said at least a second audiovisual programme, by recognition of at least one audiovisual portion of audiovisual content in said at least a second audiovisual programme, by means of recognition elements comprising said at least one audiovisual portion being extracted from said at least a first audiovisual programme and being recorded in a storage space, said audiovisual portion being also comprised in said at least a second audiovisual programme, said at least a first audiovisual programme being received prior to reception of said at least a second audiovisual programme, said recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these audiovisual portions of audiovisual content,</claim-text>
<claim-text>and an activation unit triggering at least one action in case of detection of said synchronization signals by the recognition unit, wherein at least one of said recognition and activation units delays the triggering of said action by at least a determined timeout lag, in case of detection of said synchronization signals,</claim-text>
<claim-text>said recognition unit being in accordance with <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. Activation assembly according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein said activation assembly receives said timeout lag with said recognition elements.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. Specification unit comprising a processor for executing instructions for specifying audiovisual portions of audiovisual content of at least a second audiovisual programme serving as synchronization signals associated with said at least a second audiovisual programme, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, and said synchronization signals being detected in said audiovisual programme and thus triggering at least one action,
<claim-text>wherein said specification unit comprises</claim-text>
<claim-text>a preparation module for preparing recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these audiovisual portions of audiovisual content of a first audiovisual programme, which audiovisual portions are also comprised in said second audiovisual programme, said at least a first audiovisual programme being transmitted prior to transmission of said at least a second audiovisual programme,</claim-text>
<claim-text>and a transmission module for transmitting said recognition elements independently of transmissions of said at least a second audiovisual programme, to at least one recognition unit detecting said synchronization signals in said at least a second audiovisual programme, by recognizing said audiovisual portions of audiovisual content of said at least a first audiovisual programme in the audiovisual content of said at least a second audiovisual programme,</claim-text>
<claim-text>and the preparation and transmission modules of said unit respectively prepare and transmit at least one action timeout lag in case of detection of said synchronization signals,</claim-text>
<claim-text>said specification unit cooperating with said recognition unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. Specification unit according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the preparation and transmission modules of said unit respectively prepare and transmit identifiers relating to said actions to be triggered in case of detection of said synchronization signals.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. Specification unit according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein said action identifiers relate to at least one of the following actions: broadcasting of an interactive service, triggering of an interactive service, triggering of an update of an interactive service, triggering of a recording of said at least a second audiovisual programme and connection to a website.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. Synchronization system comprising a processor for executing instructions comprising:
<claim-text>a specification unit for specifying audiovisual portions of audiovisual content of at least a second audiovisual programme, said audiovisual portions serving as synchronization signals, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content broadcast to users,</claim-text>
<claim-text>a recognition unit for recognizing said synchronization signals in said at least a second audiovisual programme, by recognition of at least one audiovisual portion of audiovisual content extracted from at least a first audiovisual programme in the at least a second audiovisual programme, said at least one audiovisual portion are being comprised in said at least a second audiovisual programme, said at least a first audiovisual programme being received prior to reception of said at least a second audiovisual programme,</claim-text>
<claim-text>and an activation unit triggering at least one action in case of detection of said synchronization signals by the recognition unit, said detection being done through recognition in said at least a second audiovisual programme of said at least one audiovisual portion of audiovisual content extracted from said at least a first audiovisual programme, the recognition unit and the activation unit forming an activation assembly,</claim-text>
<claim-text>wherein the specification unit prepares and transmits to the recognition unit recognition elements, as well as at least one action timeout lag in case of detection of said synchronization signals, and in that the activation assembly delays the triggering of said action according to said lag transmitted, in case of detection of said synchronization signals,</claim-text>
<claim-text>the specification unit being in accordance with <claim-ref idref="CLM-00012">claim 12</claim-ref>.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. Broadcasting centre, wherein it comprises a device chosen from among at least a specification unit in accordance with <claim-ref idref="CLM-00012">claim 12</claim-ref>, a recognition unit, an activation assembly, and a synchronization system.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. Services operator, wherein it comprises a device chosen from among at least a specification unit in accordance with <claim-ref idref="CLM-00012">claim 12</claim-ref>, a recognition unit, an activation assembly, and a synchronization system.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. Terminal for receiving audiovisual programmes, wherein it comprises a device chosen from among at least a specification unit in accordance with <claim-ref idref="CLM-00012">claim 12</claim-ref>, a recognition unit, an activation assembly, and a synchronization system.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. Method, implemented by a processor including executable instructions, of activation by recognition of audiovisual portions of audiovisual content from at least a first audiovisual programme in at least a second audiovisual programme, said audiovisual portions serving as synchronization signals, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a first audiovisual programme and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, said method comprising the following steps:
<claim-text>reception of at said at least a first audiovisual programme and of said at least a second audiovisual programme, said at least a first audiovisual programme being received prior to reception of said at least a second audiovisual programme,</claim-text>
<claim-text>detection of said synchronization signals in said at least a second audiovisual programme received by means of recognition elements comprising at least one audiovisual portion of audiovisual content being extracted from said at least a first audiovisual programme and being stored in a storage space, by recognition of said at least one audiovisual portion in the audiovisual content of said at least a second audiovisual programme, said recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these portions of audiovisual content of said first audiovisual programme, which audiovisual portions are also comprised in said second audiovisual programme,</claim-text>
<claim-text>and triggering of at least one action in case of detection of said synchronization signals in said audiovisual programme,</claim-text>
<claim-text>wherein the triggering of said action is delayed by at least one determined lag in case of detection of said synchronization signals,</claim-text>
<claim-text>said method of activation being implemented by means of an activation assembly.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. Method according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein said at least a first audiovisual programme and said at least a second audiovisual programme comprise at least one recognition part containing said at least one audiovisual portion, and at least one live transmission to be broadcast following said recognition part, said synchronization signals being detected during the broadcast of said recognition part and said action being triggered during the broadcast of said following live transmission, by means of said timeout lag.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. Method, implemented by a processor including executable instructions, of specifying audiovisual portions of audiovisual content of at least a second audiovisual programme, said audiovisual portions serving as synchronization signals associated with said at least a second audiovisual programme, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, said synchronization signals being detected in said at least a second audiovisual programme and thus triggering at least one action,
<claim-text>wherein said method of specification comprises the following steps:</claim-text>
<claim-text>preparation of recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these audiovisual portions of audiovisual content of at least a first audiovisual programme, which audiovisual portions are also comprised in said at least a second audiovisual programme, said at least a first audiovisual programme being transmitted prior to transmission of said at least a second audiovisual programme,</claim-text>
<claim-text>transmission of said recognition elements independently of transmissions of said at least a second audiovisual programme, for detection of said synchronization signals in said at least a second audiovisual programme, by recognition of said audiovisual portions of audiovisual content of said at least a first audiovisual programme in the audiovisual content of said at least a second audiovisual programme,</claim-text>
<claim-text>and transmission of at least one action timeout lag in case of detection of said synchronization signals independently of transmissions of said audiovisual programme,</claim-text>
<claim-text>said method being implemented by means of a specification unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. Method according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein said at least a first audiovisual programme and said at least a second audiovisual programme comprise at least one recognition part containing said at least one audiovisual portion, and at least one live transmission to be broadcast following said recognition part, said synchronization signals being detected during the broadcast of said recognition part and said action being triggered during the broadcast of said following live transmission, by means of said timeout lag.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. Synchronization method, implemented by a processor including executable instructions, comprising the following steps:
<claim-text>a step of specifying audiovisual portions of audiovisual content of at least a second audiovisual programme, said audiovisual portions serving as synchronization signals associated with said at least a second audiovisual programme, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, in which recognition elements that comprise at least one audiovisual portion of the audiovisual content of said at least a second audiovisual programme are specified for said detection, said recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these audiovisual portions of audiovisual content,</claim-text>
<claim-text>a step of detecting said synchronization signals in said at least a second audiovisual programme, in which said synchronization signals are detected in said at least a second audiovisual programme, by recognition of said audiovisual portions of audiovisual content of said at least a first audiovisual programme in the audiovisual content of said at least a second audiovisual programme, said audiovisual portions being also comprised in said at least a second audiovisual programme, said at least a first audiovisual programme being transmitted prior to transmission of said at least a second audiovisual programme,</claim-text>
<claim-text>and a step of triggering at least one action in case of detection of said synchronization signals,</claim-text>
<claim-text>wherein the triggering of said action is delayed by at least one determined lag in case of detection of said synchronization signals,</claim-text>
<claim-text>said synchronization method being implemented by a synchronization system.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. Method according to <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein said at least a first audiovisual programme and said at least a second audiovisual programme comprise at least one recognition part containing said at least one audiovisual portion, and at least one live transmission to be broadcast following said recognition part, said synchronization signals being detected during the broadcast of said recognition part and said action being triggered during the broadcast of said following live transmission, by means of said timeout lag.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. A computer readable non-transitory storage medium encoded with a computer program comprising the steps of:
<claim-text>receiving at least a first audiovisual programme and at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content broadcast to users, said least a first audiovisual programme being received prior to reception of said at least a second audiovisual programme, and said at least a first audiovisual programme comprising audiovisual portions of content that are also comprised in said second audiovisual programme,</claim-text>
<claim-text>detection of audiovisual portions of audiovisual content in said at least a second audiovisual programme, said audiovisual portions of audiovisual content serving as synchronization signals in said at least a second audiovisual programme, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and where said detection is done by means of recognition elements extracted from said at least a first audiovisual programme and stored in a storage space, by recognition of said extracted audiovisual portion, in the audiovisual content of said at least a second audiovisual programme, said recognition elements being audiovisual portions of audiovisual content extracted from said at least a first audiovisual programme,</claim-text>
<claim-text>and triggering of at least one action in case of detection of said synchronization signals in said at least a second audiovisual programme, wherein the triggering of said action is delayed by at least one determined lag in case of detection of said synchronization signals.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. A computer readable non-transitory storage medium encoded with a computer program comprising the steps of:
<claim-text>preparing recognition elements comprising at least one audiovisual portion of audiovisual content extracted from at least a first audiovisual programme which at least one audiovisual portion of audiovisual content is also present in at least a second audiovisual programme, said at least a first audiovisual programme being transmitted prior to transmission of said at least a second programme, each of said at least one audiovisual portion of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a first audiovisual programme and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, said recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these audiovisual portions of audiovisual content,</claim-text>
<claim-text>transmitting said recognition elements independently of transmissions of said at least a second audiovisual programme, for detection of audiovisual portions of audiovisual content of at least a second audiovisual programme, said audiovisual portions serving as synchronization signals in said at least a second audiovisual programme, by recognition of said audiovisual portions in the audiovisual content of said at least a second audiovisual programme,</claim-text>
</claim-text>
<claim-text>and
<claim-text>transmitting at least one action timeout lag in case of detection of said synchronization signals independently of transmissions of said at least a second audiovisual programme.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. A computer readable non-transitory storage medium encoded with a computer program comprising the steps of:
<claim-text>specifying audiovisual portions of audiovisual content of at least a second audiovisual programme, said portions serving as synchronization signals associated with said at least a second audiovisual programme, each of said audiovisual portions of audiovisual content consisting of at least one of the following audiovisual portions: an image, an image part, a sound and any combination of at least two of said audiovisual portions, and said at least a second audiovisual programme, being audio and/or video, comprising an audiovisual content to be broadcast to users, in which recognition elements that comprise at least one audiovisual portion of the audiovisual content of said at least a second audiovisual programme are specified for detection, said recognition elements being constructed from pictures, sounds, parts of pictures or combinations of these audiovisual portions of audiovisual content,</claim-text>
<claim-text>detecting said synchronization signals in said at least a second audiovisual programme, in which synchronization signals are detected in said at least a second audiovisual programme, by recognition of said audiovisual portions of audiovisual content of said at least a first audiovisual programme in the audiovisual content of said at least a second audiovisual programme, said at least one audiovisual portion being also comprised in said at least a second audiovisual programme, said at least a first audiovisual programme being received prior to reception of said at least a second audiovisual programme,</claim-text>
<claim-text>triggering at least one action in case of detection of said synchronization signals, wherein the triggering of said action is delayed by at least one determined lag in case of detection of said synchronization signals. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
