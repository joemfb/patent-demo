<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624864-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624864</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13782825</doc-number>
<date>20130301</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>041</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345173</main-classification>
<further-classification>3404072</further-classification>
</classification-national>
<invention-title id="d2e43">System and method for display of multiple data channels on a single haptic display</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6647359</doc-number>
<kind>B1</kind>
<name>Verplank et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703  2</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7765333</doc-number>
<kind>B2</kind>
<name>Cruz-Hernandez et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710  5</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7979146</doc-number>
<kind>B2</kind>
<name>Ullrich et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>700 94</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>8141947</doc-number>
<kind>B2</kind>
<name>Nathan et al.</name>
<date>20120300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>2972173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>8207832</doc-number>
<kind>B2</kind>
<name>Yun et al.</name>
<date>20120600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3404072</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>8260972</doc-number>
<kind>B2</kind>
<name>Cruz-Hernandez et al.</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710  5</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>8279193</doc-number>
<kind>B1</kind>
<name>Birnbaum et al.</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>8280448</doc-number>
<kind>B2</kind>
<name>Bang et al.</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455566</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2005/0060070</doc-number>
<kind>A1</kind>
<name>Kapolka et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701 29</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2006/0129719</doc-number>
<kind>A1</kind>
<name>Cruz-Hernandez et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710 58</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2007/0242040</doc-number>
<kind>A1</kind>
<name>Ullrich et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345157</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2008/0266066</doc-number>
<kind>A1</kind>
<name>Braun et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3404072</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2009/0015045</doc-number>
<kind>A1</kind>
<name>Nathan et al.</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>2972173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2009/0231276</doc-number>
<kind>A1</kind>
<name>Ullrich et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345157</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2009/0322498</doc-number>
<kind>A1</kind>
<name>Yun et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3404072</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2009/0325645</doc-number>
<kind>A1</kind>
<name>Bang et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455566</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2010/0073304</doc-number>
<kind>A1</kind>
<name>Grant et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2010/0231550</doc-number>
<kind>A1</kind>
<name>Cruz-Hernandez et al.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345174</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2012/0139844</doc-number>
<kind>A1</kind>
<name>Ramstein et al.</name>
<date>20120600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2012/0223880</doc-number>
<kind>A1</kind>
<name>Birnbaum et al.</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2012/0229402</doc-number>
<kind>A1</kind>
<name>Grant et al.</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>30</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345156-184</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>178 1801- 1809</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>340  412</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3404071</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3404072</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>463 30</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>19</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>13472713</doc-number>
<date>20120516</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8570296</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13782825</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130222310</doc-number>
<kind>A1</kind>
<date>20130829</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Birnbaum</last-name>
<first-name>David</first-name>
<address>
<city>Oakland</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ullrich</last-name>
<first-name>Chris</first-name>
<address>
<city>Ventura</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Short</last-name>
<first-name>Jason</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Devenish</last-name>
<first-name>Ryan</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Birnbaum</last-name>
<first-name>David</first-name>
<address>
<city>Oakland</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Ullrich</last-name>
<first-name>Chris</first-name>
<address>
<city>Ventura</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Short</last-name>
<first-name>Jason</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Devenish</last-name>
<first-name>Ryan</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Hassing</last-name>
<first-name>Thomas A.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Immersion Corporation</orgname>
<role>02</role>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bolotin</last-name>
<first-name>Dmitriy</first-name>
<department>2623</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system that produces a haptic effect and generates a drive signal that includes at least two haptic effect signals each having a priority level. The haptic effect is a combination of the haptic effect signals and priority levels. The haptic effect may optionally be a combination of the two haptic effect signals if the priority levels are the same, otherwise only the haptic effect signal with the highest priority is used. The frequency of haptic notifications may also be used to generate a drive signal using foreground and background haptic effect channels depending on whether the frequency ratio exceeds a foreground haptic effect threshold.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="184.74mm" wi="243.42mm" file="US08624864-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="242.99mm" wi="183.73mm" orientation="landscape" file="US08624864-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="235.37mm" wi="165.52mm" orientation="landscape" file="US08624864-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="261.20mm" wi="189.06mm" file="US08624864-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="249.94mm" wi="171.11mm" file="US08624864-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="232.07mm" wi="169.84mm" file="US08624864-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="198.63mm" wi="173.82mm" file="US08624864-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="248.58mm" wi="151.30mm" orientation="landscape" file="US08624864-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="233.43mm" wi="203.62mm" orientation="landscape" file="US08624864-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="251.29mm" wi="181.44mm" file="US08624864-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="235.71mm" wi="170.52mm" file="US08624864-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims the benefit of priority under 35 USC &#xa7;120 to application Ser. No. 13/472,713, filed May 16, 2012.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">One embodiment is directed generally to a user interface for a device, and in particular to the display of multiple data channels of haptic feedback for the user interface.</p>
<heading id="h-0003" level="1">BACKGROUND INFORMATION</heading>
<p id="p-0004" num="0003">Electronic device manufacturers strive to produce a rich interface for users. Conventional devices use visual and auditory cues to provide feedback to a user. In some interface devices, kinesthetic feedback (such as active and resistive force feedback) and/or tactile feedback (such as vibration, texture, and heat) is also provided to the user, more generally known collectively as &#x201c;haptic feedback&#x201d; or &#x201c;haptic effects&#x201d;. Haptic feedback can provide cues that enhance and simplify the user interface. Specifically, vibration effects, or vibrotactile haptic effects, may be useful in providing cues to users of electronic devices to alert the user to specific events, or provide realistic feedback to create greater sensory immersion within a simulated or virtual environment.</p>
<p id="p-0005" num="0004">In order to generate vibration effects, many devices utilize some type of actuator or haptic output device. Known haptic output devices used for this purpose include an electromagnetic actuator such as an Eccentric Rotating Mass (&#x201c;ERM&#x201d;) in which an eccentric mass is moved by a motor, a Linear Resonant Actuator (&#x201c;LRA&#x201d;) in which a mass attached to a spring is driven back and forth, or a &#x201c;smart material&#x201d; such as piezoelectric, electro-active polymers or shape memory alloys. Haptic output devices also broadly include non-mechanical or non-vibratory devices such as those that use electrostatic friction (ESF), ultrasonic surface friction (USF), or those that induce acoustic radiation pressure with an ultrasonic haptic transducer, or those that use a haptic substrate and a flexible or deformable surface, or those that provide projected haptic output such as a puff of air using an air jet, and so on.</p>
<p id="p-0006" num="0005">Traditional architectures are designed to provide haptic feedback only for a single haptic event. However, if multiple haptic events are combined it may overwhelm or distract the user from a primary task. Therefore, there is a need for an improved system of providing a haptic effect where low-importance or high-density information is perceivable, but not overwhelming or distracting from a primary task.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">One embodiment is a system that produces a haptic effect and generates a drive signal that includes at least two haptic effect signals each having a priority level. The haptic effect is a combination of the haptic effect signals and priority levels. The haptic effect may optionally be a combination of the two haptic effect signals if the priority levels are the same, otherwise only the haptic effect signal with the highest priority is used. The frequency of haptic notifications may also be used to generate a drive signal using foreground and background haptic effect channels depending on whether the frequency ratio exceeds a foreground haptic effect threshold.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a haptically-enabled system according to one embodiment of the present invention.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> is a cut-away perspective view of an LRA implementation of a haptic actuator according to one embodiment of the present invention.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 3</figref> is a cut-away perspective view of an ERM implementation of a haptic actuator according to one embodiment of the present invention.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. 4A-4C</figref> are views of a piezoelectric implementation of a haptic actuator according to one embodiment of the present invention.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 5</figref> is a view of a haptic device using electrostatic friction (ESF) according to one embodiment of the present invention.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 6</figref> is a view of a haptic device for inducing acoustic radiation pressure with an ultrasonic haptic transducer according to one embodiment of the present invention.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 7</figref> is a view of a haptic device using a haptic substrate and flexible or deformable surface according to one embodiment of the present invention.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. 8A-8B</figref> are views of a haptic device using ultrasonic surface friction (USF) according to one embodiment of the present invention.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. 9A-9D</figref> are screen views of example foreground and background haptic applications according to one embodiment of the present invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. 10A-10B</figref> are display graphs of example multiple data channels of haptic feedback according to one embodiment of the present invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 11</figref> is a flow diagram for displaying multiple data channels of haptic feedback for priority based haptic events according to one embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 12</figref> is a flow diagram for displaying multiple data channels of haptic feedback for frequency based haptic events according to one embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0020" num="0019">As described below, a dynamic haptic effect refers to a haptic effect that evolves over time as it responds to one or more input parameters. Dynamic haptic effects are haptic or vibrotactile effects displayed on haptic devices to represent a change in state of a given input signal. The input signal can be a signal captured by sensors on the device with haptic feedback, such as position, acceleration, pressure, orientation, or proximity, or signals captured by other devices and sent to the haptic device to influence the generation of the haptic effect.</p>
<p id="p-0021" num="0020">A dynamic effect signal can be any type of signal, but does not necessarily have to be complex. For example, a dynamic effect signal may be a simple sine wave that has some property such as phase, frequency, or amplitude that is changing over time or reacting in real time according to a mapping schema which maps an input parameter onto a changing property of the effect signal. An input parameter may be any type of input capable of being provided by a device, and typically may be any type of signal such as a device sensor signal. A device sensor signal may be generated by any means, and typically may be generated by capturing a user gesture with a device. Dynamic effects may be very useful for gesture interfaces, but the use of gestures or sensors are not necessarily required to create a dynamic signal.</p>
<p id="p-0022" num="0021">One common scenario that does not involve gestures directly is defining the dynamic haptic behavior of an animated widget. For example, when a user scrolls a list, it is not typically the haptification of the gesture that will feel most intuitive, but instead the motion of the widget in response to the gesture. In the scroll list example, gently sliding the list may generate a dynamic haptic feedback that changes according to the speed of the scrolling, but flinging the scroll bar may produce dynamic haptics even after the gesture has ended. This creates the illusion that the widget has some physical properties and it provides the user with information about the state of the widget such as its velocity or whether it is in motion.</p>
<p id="p-0023" num="0022">A gesture is any movement of the body that conveys meaning or user intent. It will be recognized that simple gestures may be combined to form more complex gestures. For example, bringing a finger into contact with a touch sensitive surface may be referred to as a &#x201c;finger on&#x201d; gesture, while removing a finger from a touch sensitive surface may be referred to as a separate &#x201c;finger off&#x201d; gesture. If the time between the &#x201c;finger on&#x201d; and &#x201c;finger off&#x201d; gestures is relatively short, the combined gesture may be referred to as &#x201c;tapping&#x201d;; if the time between the &#x201c;finger on&#x201d; and &#x201c;finger off&#x201d; gestures is relatively long, the combined gesture may be referred to as &#x201c;long tapping&#x201d;; if the distance between the two dimensional (x,y) positions of the &#x201c;finger on&#x201d; and &#x201c;finger off&#x201d; gestures is relatively large, the combined gesture may be referred to as &#x201c;swiping&#x201d;; if the distance between the two dimensional (x,y) positions of the &#x201c;finger on&#x201d; and &#x201c;finger off&#x201d; gestures is relatively small, the combined gesture may be referred to as &#x201c;smearing&#x201d;, &#x201c;smudging&#x201d; or &#x201c;flicking&#x201d;. Any number of two dimensional or three dimensional simple or complex gestures may be combined in any manner to form any number of other gestures, including, but not limited to, multiple finger contacts, palm or first contact, or proximity to the device. A gesture can also be any form of hand movement recognized by a device having an accelerometer, gyroscope, or other motion sensor, and converted to electronic signals. Such electronic signals can activate a dynamic effect, such as shaking virtual dice, where the sensor captures the user intent that generates a dynamic effect.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a haptically-enabled system <b>10</b> according to one embodiment of the present invention. System <b>10</b> includes a touch sensitive surface <b>11</b> or other type of user interface mounted within a housing <b>15</b>, and may include mechanical keys/buttons <b>13</b>. Internal to system <b>10</b> is a haptic feedback system that generates vibrations on system <b>10</b>. In one embodiment, the vibrations are generated on touch surface <b>11</b>.</p>
<p id="p-0025" num="0024">The haptic feedback system includes a processor <b>12</b>. Coupled to processor <b>12</b> is a memory <b>20</b> and an actuator drive circuit <b>16</b>, which is coupled to a haptic actuator <b>18</b>. Processor <b>12</b> may be any type of general purpose processor, or could be a processor specifically designed to provide haptic effects, such as an application-specific integrated circuit (&#x201c;ASIC&#x201d;). Processor <b>12</b> may be the same processor that operates the entire system <b>10</b>, or may be a separate processor. Processor <b>12</b> can decide what haptic effects are to be played and the order in which the effects are played based on high level parameters. In general, the high level parameters that define a particular haptic effect include magnitude, frequency and duration. Low level parameters such as streaming motor commands could also be used to determine a particular haptic effect. A haptic effect may be considered dynamic if it includes some variation of these parameters when the haptic effect is generated or a variation of these parameters based on a user's interaction.</p>
<p id="p-0026" num="0025">Processor <b>12</b> outputs the control signals to drive circuit <b>16</b> which includes electronic components and circuitry used to supply actuator <b>18</b> with the required electrical current and voltage to cause the desired haptic effects. System <b>10</b> may include more than one actuator <b>18</b>, and each actuator may include a separate drive circuit <b>16</b>, all coupled to a common processor <b>12</b>. Memory device <b>20</b> can be any type of storage device or computer-readable medium, such as random access memory (RAM) or read-only memory (ROM). Memory <b>20</b> stores instructions executed by processor <b>12</b>. Among the instructions, memory <b>20</b> includes an actuator drive module <b>22</b> which are instructions that, when executed by processor <b>12</b>, generate drive signals for actuator <b>18</b> while also determining feedback from actuator <b>18</b> and adjusting the drive signals accordingly. The functionality of module <b>22</b> is discussed in more detail below. Memory <b>20</b> may also be located internal to processor <b>12</b>, or any combination of internal and external memory.</p>
<p id="p-0027" num="0026">Touch surface <b>11</b> recognizes touches, and may also recognize the position and magnitude or pressure of touches on the surface, such as the number of touches, the size of the contact points, pressure, etc. The data corresponding to the touches is sent to processor <b>12</b>, or another processor within system <b>10</b>, and processor <b>12</b> interprets the touches and in response generates haptic effect signals. Touch surface <b>11</b> may sense touches using any sensing technology, including capacitive sensing, resistive sensing, surface acoustic wave sensing, pressure sensing, optical sensing, etc. Touch surface <b>11</b> may sense multi-touch contacts and may be capable of distinguishing multiple touches that occur at the same time. Touch surface <b>11</b> may be a touchscreen that generates and displays images for the user to interact with, such as keys, dials, etc., or may be a touchpad with minimal or no images.</p>
<p id="p-0028" num="0027">System <b>10</b> may be a handheld device, such as a cellular telephone, PDA, computer tablet, gaming console, etc. or may be any other type of device that provides a user interface and includes a haptic effect system that includes one or more ERMs, LRAs, electrostatic or other types of actuators. The user interface may be a touch sensitive surface, or can be any other type of user interface such as a mouse, touchpad, mini-joystick, scroll wheel, trackball, game pads or game controllers, etc. In embodiments with more than one actuator, each actuator may have a different output capability in order to create a wide range of haptic effects on the device. Each actuator may be any type of haptic actuator or a single or multidimensional array of actuators.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 2</figref> is a cut-away side view of an LRA implementation of actuator <b>18</b> in accordance to one embodiment. LRA <b>18</b> includes a casing <b>25</b>, a magnet/mass <b>27</b>, a linear spring <b>26</b>, and an electric coil <b>28</b>. Magnet <b>27</b> is mounted to casing <b>25</b> by spring <b>26</b>. Coil <b>28</b> is mounted directly on the bottom of casing <b>25</b> underneath magnet <b>27</b>. LRA <b>18</b> is typical of any known LRA. In operation, when current flows through coil <b>28</b> a magnetic field forms around coil <b>28</b> which in interaction with the magnetic field of magnet <b>27</b> pushes or pulls on magnet <b>27</b>. One current flow direction/polarity causes a push action and the other a pull action. Spring <b>26</b> controls the up and down movement of magnet <b>27</b> and has a deflected up position where it is compressed, a deflected down position where it is expanded, and a neutral or zero-crossing position where it is neither compressed or deflected and which is equal to its resting state when no current is being applied to coil <b>28</b> and there is no movement/oscillation of magnet <b>27</b>.</p>
<p id="p-0030" num="0029">For LRA <b>18</b>, a mechanical quality factor or &#x201c;Q factor&#x201d; can be measured. In general, the mechanical Q factor is a dimensionless parameter that compares a time constant for decay of an oscillating physical system's amplitude to its oscillation period. The mechanical Q factor is significantly affected by mounting variations. The mechanical Q factor represents the ratio of the energy circulated between the mass and spring over the energy lost at every oscillation cycle. A low Q factor means that a large portion of the energy stored in the mass and spring is lost at every cycle. In general, a minimum Q factor occurs with system <b>10</b> is held firmly in a hand due to energy being absorbed by the tissues of the hand. The maximum Q factor generally occurs when system <b>10</b> is pressed against a hard and heavy surface that reflects all of the vibration energy back into LRA <b>18</b>.</p>
<p id="p-0031" num="0030">In direct proportionality to the mechanical Q factor, the forces that occur between magnet/mass <b>27</b> and spring <b>26</b> at resonance are typically 10-100 times larger than the force that coil <b>28</b> must produce to maintain the oscillation. Consequently, the resonant frequency of LRA <b>18</b> is mostly defined by the mass of magnet <b>27</b> and the compliance of spring <b>26</b>. However, when an LRA is mounted to a floating device (i.e., system <b>10</b> held softly in a hand), the LRA resonant frequency shifts up significantly. Further, significant frequency shifts can occur due to external factors affecting the apparent mounting weight of LRA <b>18</b> in system <b>10</b>, such as a cell phone flipped open/closed or the phone held tightly.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 3</figref> is a cut-away perspective view of an ERM implementation of actuator <b>18</b> according to one embodiment of the present invention. ERM <b>18</b> includes a rotating mass <b>301</b> having an off-center weight <b>303</b> that rotates about an axis of rotation <b>305</b>. In operation, any type of motor may be coupled to ERM <b>18</b> to cause rotation in one or both directions around the axis of rotation <b>305</b> in response to the amount and polarity of voltage applied to the motor. It will be recognized that an application of voltage in the same direction of rotation will have an acceleration effect and cause the ERM <b>18</b> to increase its rotational speed, and that an application of voltage in the opposite direction of rotation will have a braking effect and cause the ERM <b>18</b> to decrease or even reverse its rotational speed.</p>
<p id="p-0033" num="0032">One embodiment of the present invention provides haptic feedback by determining and modifying the angular speed of ERM <b>18</b>. Angular speed is a scalar measure of rotation rate, and represents the magnitude of the vector quantity angular velocity. Angular speed or frequency &#x3c9;, in radians per second, correlates to frequency v in cycles per second, also called Hz, by a factor of 2&#x3c0;. The drive signal includes a drive period where at least one drive pulse is applied to ERM <b>18</b>, and a monitoring period where the back electromagnetic field (&#x201c;EMF&#x201d;) of the rotating mass <b>301</b> is received and used to determine the angular speed of ERM <b>18</b>. In another embodiment, the drive period and the monitoring period are concurrent and the present invention dynamically determines the angular speed of ERM <b>18</b> during both the drive and monitoring periods.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. 4A-4C</figref> are views of a piezoelectric implementation of a haptic actuator <b>18</b> according to one embodiment of the present invention. <figref idref="DRAWINGS">FIG. 4A</figref> shows a disk piezoelectric actuator that includes an electrode <b>401</b>, a piezo ceramics disk <b>403</b> and a metal disk <b>405</b>. As shown in <figref idref="DRAWINGS">FIG. 4B</figref>, when a voltage is applied to electrode <b>401</b>, the piezoelectric actuator bends in response, going from a relaxed state <b>407</b> to a transformed state <b>409</b>. When a voltage is applied, it is that bending of the actuator that creates the foundation of vibration. Alternatively, <figref idref="DRAWINGS">FIG. 4C</figref> shows a beam piezoelectric actuator that operates similarly to a disk piezoelectric actuator by going from a relaxed state <b>411</b> to a transformed state <b>413</b>.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 5</figref> is a view of a haptic device using electrostatic friction (ESF) according to one embodiment of the present invention. Similar to the operational principles described by Makinen et al. in U.S. Pat. No. 7,982,588, the embodiment is based on the discovery that subcutaneous Pacinian corpuscles can be stimulated by means of a capacitive electrical coupling and an appropriately dimensioned control voltage, either without any mechanical stimulation of the Pacinian corpuscles or as an additional stimulation separate from such mechanical stimulation. An appropriately dimensioned high voltage is used as the control voltage. In the present context, a high voltage means such a voltage that direct galvanic contact must be prevented for reasons of safety and/or user comfort. This results in a capacitive coupling between the Pacinian corpuscles and the apparatus causing the stimulation, wherein one side of the capacitive coupling is formed by at least one galvanically isolated electrode connected to the stimulating apparatus, while the other side, in close proximity to the electrode, is formed by the body member, preferably a finger, of the stimulation target, such as the user of the apparatus, and more specifically the subcutaneous Pacinian corpuscles.</p>
<p id="p-0036" num="0035">It likely that the invention is based on a controlled formation of an electric field between an active surface of the apparatus and the body member, such as a finger, approaching or touching it. The electric field tends to give rise to an opposite charge on the proximate finger. A local electric field and a capacitive coupling can be formed between the charges. The electric field directs a force on the charge of the finger tissue. By appropriately altering the electric field a force capable of moving the tissue may arise, whereby the sensory receptors sense such movement as vibration.</p>
<p id="p-0037" num="0036">As shown in <figref idref="DRAWINGS">FIG. 5</figref>, one or more conducting electrodes <b>501</b> are provided with an insulator. When a body member such as finger <b>505</b> is proximate to the conducting electrode <b>501</b>, the insulator prevents flow of direct current from the conducting electrode to the body member <b>505</b>. A capacitive coupling field force <b>503</b> over the insulator is formed between the conducting electrode <b>501</b> and the body member <b>505</b>. The apparatus also comprises a high-voltage source for applying an electrical input to the one or more conducting electrodes, wherein the electrical input comprises a low-frequency component in a frequency range between 10 Hz and 1000 Hz. The capacitive coupling and electrical input are dimensioned to produce an electrosensory sensation which is produced independently of any mechanical vibration of the one or more conducting electrodes or insulators.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 6</figref> is a view of a haptic device for inducing acoustic radiation pressure with an ultrasonic haptic transducer similar to that described by Iwamoto et al., &#x201c;Non-contact Method for Producing Tactile Sensation Using Airborne Ultrasound&#x201d;, Eurohaptics 2008, LNCS 5024, pp. 504-513. An airborne ultrasound transducer array <b>601</b> is designed to provide tactile feedback in three-dimensional (3D) free space. The array radiates airborne ultrasound, and produces high-fidelity pressure fields onto the user's hands without the use of gloves or mechanical attachments. The method is based on a nonlinear phenomenon of ultrasound; acoustic radiation pressure. When an object interrupts the propagation of ultrasound, a pressure field is exerted on the surface of the object. This pressure is called acoustic radiation pressure. The acoustic radiation pressure P [Pa] is simply described as P=&#x3b1;E, where E [J=m<sup>3</sup>] is the energy density of the ultrasound and a is a constant ranging from 1 to 2 depending on the reflection properties of the surface of the object. The equation describes how the acoustic radiation pressure is proportional to the energy density of the ultrasound. The spatial distribution of the energy density of the ultrasound can be controlled by using the wave field synthesis techniques. With an ultrasound transducer array, various patterns of pressure field are produced in 3D free space. Unlike air-jets, the spatial and temporal resolutions are quite fine. The spatial resolution is comparable to the wavelength of the ultrasound. The frequency characteristics are sufficiently fine up to 1 kHz.</p>
<p id="p-0039" num="0038">The airborne ultrasound can be applied directly onto the skin without the risk of the penetration. When the airborne ultrasound is applied on the surface of the skin, due to the large difference between the characteristic acoustic impedance of the air and that of the skin, about 99.9% of the incident acoustic energy is reflected on the surface of the skin. Hence, this tactile feedback system does not require the users to wear any clumsy gloves or mechanical attachments.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 7</figref> shows a three-dimensional (3D) diagram illustrating a haptic device <b>701</b> using a haptic substrate and a flexible surface in accordance with one embodiment of the present invention. Device <b>701</b> includes a flexible surface layer <b>703</b>, a haptic substrate <b>705</b>, and a deforming mechanism <b>711</b>. It should be noted that device <b>701</b> can be a user interface device, such as an interface for a cellular phone, a personal digital assistant (&#x201c;PDA&#x201d;), an automotive data input system, and so forth. It should be further noted that the underlying concept of the exemplary embodiment of the present invention would not change if one or more blocks (circuits or layers) were added to or removed from device <b>701</b>.</p>
<p id="p-0041" num="0040">Flexible surface layer <b>703</b>, in one instance, is made of soft and/or elastic materials such as silicone rubber, which is also known as polysiloxane. A function of the flexible surface layer <b>703</b> is to change its surface shape or texture upon contact with the physical pattern of haptic substrate <b>705</b>. The physical pattern of haptic substrate <b>705</b> is variable as one or more of the local features <b>110</b>-<b>124</b> can be raised or lowered to present features to affect the surface of the flexible surface layer <b>703</b> upon contact. Once the physical pattern of haptic substrate <b>705</b> is determined, the texture of flexible surface layer <b>703</b> can change to confirm its surface texture to the physical pattern of haptic substrate <b>705</b>. It should be note that the deformation of flexible surface layer <b>703</b> from one texture to another can be controlled by deforming mechanism <b>711</b>. For example, when deforming mechanism <b>711</b> is not activated, flexible surface layer <b>703</b> maintains its smooth configuration floating or sitting over haptic substrate <b>705</b>. The surface configuration of flexible surface layer <b>703</b>, however, deforms or changes from a smooth configuration to a coarse configuration when deforming mechanism <b>711</b> is activated and the haptic substrate <b>705</b> is in contact with the flexible surface layer <b>703</b> so as to generate a similar pattern on the top surface of the flexible surface layer <b>703</b>.</p>
<p id="p-0042" num="0041">Alternatively, flexible surface layer <b>703</b> is a flexible touch sensitive surface, which is capable of accepting user inputs. The flexible touch sensitive surface can be divided into multiple regions wherein each region of the flexible touch sensitive surface can accept an input when the region is being touched or depressed by a finger. In one embodiment, the flexible touch sensitive surface includes a sensor, which is capable of detecting a nearby finger and waking up or turning on the device. Flexible surface layer <b>703</b> may also include a flexible display, which is capable of deforming together with flexible surface layer <b>703</b>. It should be noted that various flexible display technologies can be used to manufacture flexible displays, such as organic light-emitting diode (OLED), organic, or polymer TFT (Thin Film Transistor).</p>
<p id="p-0043" num="0042">Haptic substrate <b>705</b> is a surface reconfigurable haptic device capable of changing its surface pattern in response to one or more pattern activating signals. Haptic substrate <b>705</b> can also be referred to as a haptic mechanism, a haptic layer, a tactile element, and the like. Haptic substrate <b>705</b>, in one embodiment, includes multiple tactile or haptic regions <b>707</b>, <b>709</b>, wherein each region can be independently controlled and activated. Since each tactile region can be independently activated, a unique surface pattern of haptic substrate <b>705</b> can be composed in response to the pattern activating signals. In another embodiment, every tactile region is further divided into multiple haptic bits wherein each bit can be independently excited or activated or deactivated.</p>
<p id="p-0044" num="0043">Haptic substrate <b>705</b>, or a haptic mechanism, in one embodiment, is operable to provide haptic feedback in response to an activating command or signal. Haptic substrate <b>705</b> provides multiple tactile or haptic feedbacks wherein one tactile feedback is used for surface deformation, while another tactile feedback is used for input confirmation. Input confirmation is a haptic feedback to inform a user about a selected input. Haptic mechanism <b>705</b>, for example, can be implemented by various techniques including vibration, vertical displacement, lateral displacement, push/pull technique, air/fluid pockets, local deformation of materials, resonant mechanical elements, piezoelectric materials, micro-electro-mechanical systems (&#x201c;MEMS&#x201d;) elements, thermal fluid pockets, MEMS pumps, variable porosity membranes, laminar flow modulation, or the like.</p>
<p id="p-0045" num="0044">Haptic substrate <b>705</b>, in one embodiment, is constructed by semi-flexible or semi-rigid materials. In one embodiment, haptic substrate should be more rigid than flexible surface <b>703</b> thereby the surface texture of flexible surface <b>703</b> can confirm to the surface pattern of haptic substrate <b>705</b>. Haptic substrate <b>705</b>, for example, includes one or more actuators, which can be constructed from fibers (or nanotubes) of electroactive polymers (&#x201c;EAP&#x201d;), piezoelectric elements, fiber of shape memory alloys (&#x201c;SMAs&#x201d;) or the like. EAP, also known as biological muscles or artificial muscles, is capable of changing its shape in response to an application of voltage. The physical shape of an EAP may be deformed when it sustains large force. EAP may be constructed from Electrostrictive Polymers, Dielectric elastomers, Conducting Polyers, Ionic Polymer Metal Composites, Responsive Gels, Bucky gel actuators, or a combination of the above-mentioned EAP materials.</p>
<p id="p-0046" num="0045">SMA (Shape Memory Alloy), also known as memory metal, is another type of material which can be used to construct haptic substrate <b>705</b>. SMA may be made of copper-zinc-aluminum, copper-aluminum-nickel, nickel-titanium alloys, or a combination of copper-zinc-aluminum, copper-aluminum-nickel, and/or nickel-titanium alloys. A characteristic of SMA is that when its original shape is deformed, it regains its original shape in accordance with the ambient temperature and/or surrounding environment. It should be noted that the present embodiment may combine the EAP, piezoelectric elements, and/or SMA to achieve a specific haptic sensation.</p>
<p id="p-0047" num="0046">Deforming mechanism <b>711</b> provides a pulling and/or pushing force to translate elements in the haptic substrate <b>705</b> causing flexible surface <b>703</b> to deform. For example, when deforming mechanism <b>711</b> creates a vacuum between flexible surface <b>703</b> and haptic substrate <b>705</b>, flexible surface <b>703</b> is pushed against haptic substrate <b>705</b> causing flexible surface <b>703</b> to show the texture of flexible surface <b>703</b> in accordance with the surface pattern of haptic substrate <b>705</b>. In other words, once a surface pattern of haptic substrate <b>705</b> is generated, flexible surface is pulled or pushed against haptic substrate <b>705</b> to reveal the pattern of haptic substrate <b>705</b> through the deformed surface of flexible surface <b>703</b>. In one embodiment, haptic substrate <b>705</b> and deforming mechanism <b>711</b> are constructed in the same or substantially the same layer.</p>
<p id="p-0048" num="0047">Upon receipt of a first activating signal, haptic substrate <b>705</b> generates a first surface pattern. After formation of the surface pattern of haptic substrate <b>705</b>, deforming mechanism <b>711</b> is subsequently activated to change surface texture of flexible surface <b>703</b> in response to the surface pattern of haptic substrate <b>705</b>. Alternatively, if haptic substrate <b>705</b> receives a second activating signal, it generates a second pattern.</p>
<p id="p-0049" num="0048">Haptic substrate <b>705</b> further includes multiple tactile regions wherein each region can be independently activated to form a surface pattern of the substrate. Haptic substrate <b>705</b> is also capable of generating a confirmation feedback to confirm an input selection entered by a user. Deforming mechanism <b>711</b> is configured to deform the surface texture of flexible surface <b>703</b> from a first surface characteristic to a second surface characteristic. It should be noted that haptic device further includes a sensor, which is capable of activating the device when the sensor detects a touch on flexible surface <b>703</b>. Deforming mechanism <b>711</b> may be a vacuum generator, which is capable of causing flexible surface <b>703</b> to collapse against the first surface pattern to transform its surface configuration in accordance with the configuration of first pattern of haptic substrate <b>705</b>.</p>
<p id="p-0050" num="0049">Haptic substrate <b>705</b> illustrates the state when tactile regions <b>707</b> and <b>709</b> are activated. Tactile regions <b>707</b> and <b>709</b> are raised in a z-axis direction. Upon receipt of one or more activating signals, haptic substrate <b>705</b> identifies a surface pattern in accordance with the activating signals. Haptic substrate <b>705</b> provides identified pattern by activating various tactile regions such as regions <b>707</b> and <b>709</b> to generate the pattern. It should be noted that tactile regions <b>707</b> and <b>709</b> imitate two buttons or keys. In another embodiment, tactile region <b>707</b> or <b>709</b> includes multiple haptic bits wherein each bit can be controlled for activating or deactivating.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 8</figref> is a view of a haptic device using ultrasonic surface friction (USF) similar to that described by Biet et al., &#x201c;New Tactile Devices Using Piezoelectric Actuators&#x201d;, ACTUATOR 2006, 10<sup>th </sup>International Conference on New Actuators, 14-16 Jun. 2006, Bremen, Germany. An ultrasonic vibration display <b>801</b> produces ultrasonic vibrations in the order of a few micrometers. The display <b>801</b> consists of a touch interface surface <b>803</b> that vibrates at the ultrasound range. The vibrations <b>805</b> travel along the touch surface <b>803</b> at a speed v<sub>t </sub>when a finger <b>809</b> is in contact and applies a force <b>807</b> F<sub>t </sub>to the surface <b>803</b>. The vibrations <b>805</b> create an apparent reduction of friction on the surface <b>803</b>. One explanation is that by moving up and down, the touch surface <b>803</b> creates an air gap <b>813</b> between the surface <b>803</b> and the interacting finger <b>809</b>, and is the air gap <b>813</b> that causes the reduction in friction. This can be thought as of a Lamb wave <b>815</b> along the surface <b>803</b> that at some instants in time is in contact with the finger <b>809</b> when the finger <b>809</b> is in contact with the crest or peak of the wave <b>805</b>, and sometimes is not when the finger <b>809</b> is above the valley of the wave <b>805</b>. When finger <b>809</b> is moved in a lateral direction <b>811</b> at a speed v<sub>t</sub>, the apparent friction of the surface <b>803</b> is reduced due to the on and off contact of the surface <b>803</b> with the finger <b>809</b>. When the surface <b>803</b> is not activated, the finger <b>809</b> is always in contact with the surface <b>803</b> and the static or kinetic coefficients of friction remain constant.</p>
<p id="p-0052" num="0051">Because the vibrations <b>805</b> occur on surface <b>803</b> in the ultrasound range of typically 20 KHz or greater, the wavelength content is usually smaller than the finger size, thus allowing for a consistent experience. It will be noted that the normal displacement of surface <b>803</b> is in the order of less than 5 micrometers, and that a smaller displacement results in lower friction reduction.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIGS. 9A-9D</figref> are screen views of example foreground and background haptic applications according to one embodiment of the present invention. It will be recognized that more than one haptic enabled software application may be running simultaneously on a device having a haptic actuator, and that a window on the top of a virtual windows environment may overlap or obscure portions of any windows that are on the bottom. <figref idref="DRAWINGS">FIG. 9A</figref> shows a screen view of an example application window having a virtual download application button located in the center of the screen. In <figref idref="DRAWINGS">FIG. 9B</figref> the user selects the download application button, whereupon <figref idref="DRAWINGS">FIG. 9C</figref> shows a new screen view having a status bar in the center of the screen which indicates the percentage completion of the download. The status bar changes color proportionally from left to right corresponding to the percentage completion text shown directly below the status bar. Because the status bar is haptified, a haptic effect signal is generated and output to the haptic actuator concurrently with the visual display of the status bar. In one embodiment, the haptic effect signal changes over time corresponding to the percentage completion of the download.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 9D</figref> shows a screen view of a text input window. The text input window, selected by the user as the active window, is running in the foreground and completely obscures the download application status bar which is running simultaneously in the background. Although the download application window is no longer the active window and the status bar is completely obscured on the visual display, the status bar haptic effect signal continues to be generated and output to the haptic actuator as a background haptic effect. Because the text input window is also haptified, a foreground haptic effect signal is generated and output to the haptic actuator for each typed character concurrently with the visual display of the typed character in the text input window. In one embodiment, the foreground and background haptic effect signals are combined, modified or synthesized in such a way that the user perceives the foreground and background haptic effects as being distinct haptic effects even though they are both being output concurrently via a single haptic actuator.</p>
<p id="p-0055" num="0054">The perception of a haptic effect has three different levels. The first level is the threshold of perception, which is the minimum applied haptic effect signal component or components required for a user to detect the haptic effect. Such haptic components include, but are not limited to, strength, frequency, duration, rhythm and dynamics of the haptic effect signal. It will be recognized that the threshold of haptic perception may be highly non-linear and may vary greatly between users, and may even vary for a single user depending on many factors such as the user's sensitivity to touch, how tightly the user may be holding a handheld device, the ambient temperature, the user's age, or the user's physical activity or environment such as walking or riding in a vehicle, and so on.</p>
<p id="p-0056" num="0055">The second level of haptic effect perception is the threshold of attention break-in, which is the minimum change in the applied haptic effect signal that results in drawing the user's attention away from the primary focus to the attention break-in haptic effect itself. It will be recognized that the threshold of attention break-in may vary between users or for a single user depending on many factors as described above, and may also vary depending on whether the attention break-in is related to various types of haptic effects including a positive additive effect, or a negative subtractive effect, or a change in the haptic effect. The third level of haptic effect perception is the threshold of pain, which also varies between users or for a single user depending on many factors as described above. It will be recognized that under some circumstances, the threshold of perception may be the same as the threshold of attention break-in, which may also be the same as the threshold of pain.</p>
<p id="p-0057" num="0056">The present invention is compatible with a wide variety of haptic actuators, and can present multiple channels of haptic effect data with different intensity levels. In one embodiment, the multiple channels are represented by a foreground channel and one or more background channels. A background haptic effect is any haptic effect or haptic effect component which meets or exceeds the threshold of perception. A foreground haptic effect is any haptic effect or haptic effect component which meets or exceeds the threshold of attention break-in. In one embodiment, a foreground or background haptic effect may be a defined set of static or dynamic haptic effects or effect components. In another embodiment, a foreground or background haptic effect may be an adaptive set of static or dynamic haptic effects or haptic effect components in response to user input, system input, device sensor input or ambient input.</p>
<p id="p-0058" num="0057">Using multiple haptic channels, such as foreground and background channels, enables subtle haptic effects to be provided concurrently with more obvious haptic effects, allowing a user to distinguish between the different effects and identifying them as originating from different sources. In one embodiment, low-importance or high-density information is perceivable, but not overwhelming or distracting from a primary task, and multiple channels further enable haptic ambient awareness. For example, a haptic enabled handheld or mobile device which is monitoring the local weather during a rainstorm activates a background haptic channel to provide a sensation of raindrops that increases or decreases as it rains harder or softer.</p>
<p id="p-0059" num="0058">In one embodiment, foreground and background channels are used to distinguish the feedback originating from a local device and the feedback originating from another user. For example, a message notification arriving from another user activates a foreground haptic effect, while the status of a ticking clock on the local device activates a background haptic effect.</p>
<p id="p-0060" num="0059">In one embodiment, foreground and background channels are used to distinguish the feedback originating from a local device and the feedback originating from a primary user. For example, the feedback originated by a primary user typing on a haptic enabled keyboard activates a foreground haptic effect, while the status of a progress bar on the local device activates a background haptic effect.</p>
<p id="p-0061" num="0060">In one embodiment, foreground and background channels are used to distinguish the feedback within or between virtual simulations or animations. For example, the motion of a virtual rolling ball activates a foreground haptic effect, while the virtual texture the ball is rolling on activates a background haptic effect.</p>
<p id="p-0062" num="0061">In one embodiment, background haptic effects are additive such that when multiple background effects are received concurrently or in quick succession, the overall result is a natural or gradual foregrounding of the haptic effects. For example, a single background text message &#x201c;tweet&#x201d; notification received from a non-primary user may be easily missed or ignored by the primary user, but when hundreds or thousands of message notifications constituting a &#x201c;tweet storm&#x201d; are received in a short amount of time, the multiple haptic effects add up and the overall result is a haptic experience in the foreground which draws the primary user's attention to the event.</p>
<p id="p-0063" num="0062">In one embodiment, background haptic effects are used to provide non-distracting or &#x201c;polite&#x201d; augmentation of a commercial advertisement or any other type of haptic encoded content. For example, an advertisement for a carbonated soft drink provides a background haptic &#x201c;fizz&#x201d; effect that can be felt if the user is paying attention but otherwise can be easily ignored.</p>
<p id="p-0064" num="0063">It will be recognized that any type of input such as user, device, system, application or network input may be represented by any number of haptic events on one or more foreground or background haptic channels. Examples include, but are not limited to, multi-tasking applications, incoming email, &#x201c;tweet&#x201d; message notifications, passive notifications, outgoing messages, progress bars, Bluetooth or local device pairings, network add or drop connection, continuous antenna signal level, and so on.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIGS. 10A-10B</figref> are display graphs of example multiple data channels of haptic feedback according to one embodiment of the present invention. <figref idref="DRAWINGS">FIG. 10A</figref> shows a graph of the perceptual magnitude of a haptic signal over time for priority based haptic events, along with a corresponding graph of notification activity. At time T<b>1</b>, the perceptual magnitude of a haptic signal <b>1001</b> corresponding to the medium priority notifications N<b>1</b> and N<b>2</b> starts in the background channel <b>1003</b>. Upon receipt of a high priority notification N<b>3</b>, at time T<b>2</b> the haptic signal <b>1001</b> begins to rise until at time T<b>3</b> the haptic signal <b>1001</b> crosses the threshold from the background channel <b>1003</b> into the foreground channel <b>1005</b>. The haptic signal <b>1001</b> continues to increase up to a peak level <b>1007</b>, where in the absence of any further notifications the haptic signal <b>1001</b> decreases and crosses the threshold from the foreground channel <b>1005</b> to the background channel <b>1003</b> at time T<b>4</b>.</p>
<p id="p-0066" num="0065">At time T<b>5</b>, receipt of a high priority notification once again causes the haptic signal <b>1001</b> to rise until at time T<b>6</b> the haptic signal crosses <b>1001</b> the threshold from the background channel <b>1003</b> into the foreground channel <b>1005</b>. The haptic signal <b>1001</b> continues to increase up to a peak level <b>10010</b>, where in the absence of any further notifications the haptic signal <b>1001</b> decreases and crosses the threshold from the foreground channel <b>1005</b> to the background channel <b>1003</b> at time T<b>7</b>. It will be recognized that a stream of low-priority or medium-priority notifications punctuated with high-priority notifications results in a haptic signal <b>1001</b> that shifts between the background channel <b>1003</b> and foreground channel <b>1005</b> without limitation.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 10B</figref> shows a graph of the perceptual magnitude of a haptic signal over time for frequency based haptic events, along with a corresponding graph of notification activity. At time T<b>8</b>, the perceptual magnitude of a haptic signal <b>1011</b> corresponding to the relatively infrequent notifications N<b>1</b> through N<b>3</b> starts in the background channel <b>1013</b>. Upon receipt of higher frequency notifications, at time T<b>9</b> the haptic signal <b>1011</b> begins to rise until at time T<b>10</b> the haptic signal <b>1011</b> crosses the threshold from the background channel <b>1013</b> into the foreground channel <b>1015</b>. With continuing receipt of higher frequency notifications, the haptic signal <b>1011</b> continues to increase up to a peak level <b>1017</b>, where in the absence of any further notifications the haptic signal <b>1011</b> decreases and crosses the threshold from the foreground channel <b>1015</b> to the background channel <b>1013</b> at time T<b>11</b>. It will be recognized that a stream of low-frequency notifications punctuated with high-frequency notifications results in a haptic signal <b>1011</b> that shifts between the background channel <b>1013</b> and foreground channel <b>1015</b> without limitation. In one embodiment, priority based haptic events and frequency based haptic events may be interspersed with each other or received at any time or in any order, and may be used in any manner to generate an overall combined haptic signal.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 11</figref> is a flow diagram for displaying multiple data channels of haptic feedback for priority based haptic events according to one embodiment of the present invention. In one embodiment, the functionality of the flow diagram of <figref idref="DRAWINGS">FIG. 11</figref> is implemented by software stored in memory or other computer readable or tangible medium, and executed by a processor. In other embodiments, the functionality may be performed by hardware (e.g., through the use of an application specific integrated circuit (&#x201c;ASIC&#x201d;), a programmable gate array (&#x201c;PGA&#x201d;), a field programmable gate array (&#x201c;FPGA&#x201d;), etc.), or any combination of hardware and software.</p>
<p id="p-0069" num="0068">At <b>1101</b>, the system receives input of first and second haptic effect signals having first and second priority levels. It will be recognized that any type or number of priority levels may be used, such as foreground and background priority levels, or any number of alpha-numeric or any other sequential or non-sequential priority levels, without limitation. The first and second haptic effect signals may be received in any order or time sequence, either sequentially with non-overlapping time periods or in parallel with overlapping or concurrent time periods. At <b>1103</b>, the system compares the first priority level to the second priority level. If at <b>1105</b> the first priority level is less than the second priority level, at <b>1107</b> an interaction parameter is generated using the second haptic signal. It will be recognized that any type of input synthesis method may be used to generate the interaction parameter from one or more haptic effect signals including, but not limited to, the method of synthesis examples listed in TABLE 1 below. If at <b>1109</b> the first priority level is equal to the second priority level, at <b>1111</b> an interaction parameter is generated using the second haptic signal. If at <b>1113</b> the first priority level is greater than the second priority level, at <b>1115</b> an interaction parameter is generated using the second haptic signal. At <b>1117</b>, a drive signal is applied to a haptic actuator according to the interaction parameter.</p>
<heading id="h-0007" level="1">TABLE 1</heading>
<heading id="h-0008" level="1">Methods of Synthesis</heading>
<p id="h-0009" num="0000">Additive synthesis&#x2014;combining inputs, typically of varying amplitudes</p>
<p id="h-0010" num="0000">Subtractive synthesis&#x2014;filtering of complex signals or multiple signal inputs</p>
<p id="h-0011" num="0000">Frequency modulation synthesis&#x2014;modulating a carrier wave signal with one or more operators</p>
<p id="h-0012" num="0000">Sampling&#x2014;using recorded inputs as input sources subject to modification</p>
<p id="h-0013" num="0000">Composite synthesis&#x2014;using artificial and sampled inputs to establish a resultant &#x201c;new&#x201d; input</p>
<p id="h-0014" num="0000">Phase distortion&#x2014;altering the speed of waveforms stored in wavetables during playback</p>
<p id="h-0015" num="0000">Waveshaping&#x2014;intentional distortion of a signal to produce a modified result</p>
<p id="h-0016" num="0000">Resynthesis&#x2014;modification of digitally sampled inputs before playback</p>
<p id="h-0017" num="0000">Granular synthesis&#x2014;combining of several small input segments into a new input</p>
<p id="h-0018" num="0000">Linear predictive coding&#x2014;similar technique as used for speech synthesis</p>
<p id="h-0019" num="0000">Direct digital synthesis&#x2014;computer modification of generated waveforms</p>
<p id="h-0020" num="0000">Wave sequencing&#x2014;linear combinations of several small segments to create a new input</p>
<p id="h-0021" num="0000">Vector synthesis&#x2014;technique for fading between any number of different input sources</p>
<p id="h-0022" num="0000">Physical modeling&#x2014;mathematical equations of the physical characteristics of virtual motion</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 12</figref> is a flow diagram for displaying multiple data channels of haptic feedback for frequency based haptic events according to one embodiment of the present invention. At <b>1201</b>, the system receives one or more haptic effect notifications N over a non-zero time period T. At <b>1203</b>, the system generates a notification frequency ratio R, calculated by using at least the number of haptic effect notifications N and the non-zero time period T. In one embodiment, the notification frequency ratio R is calculated as N divided by T. At <b>1205</b>, the system compares the notification frequency ratio R to a foreground haptic threshold F. Haptic threshold F may be static or dynamic and may vary over time depending on many factors such as the user's sensitivity to touch, how tightly the user may be holding a handheld device, the ambient temperature, the user's age, or the user's physical activity or environment such as walking or riding in a vehicle, and so on. It will be recognized that the notification frequency ratio R may be directly calculated or may be normalized corresponding to a wide range of variation for the haptic threshold F, and that the haptic threshold F may be directly calculated or may be normalized corresponding to a wide range of variation for the notification frequency ratio R.</p>
<p id="p-0071" num="0070">If at <b>1207</b> the notification frequency ratio R is less than the foreground haptic threshold F, at <b>1209</b> an interaction parameter is generated using a background haptic signal. If at <b>1211</b> the notification frequency ratio R is greater than or equal to the foreground haptic threshold F, at <b>1213</b> an interaction parameter is generated using a foreground haptic signal. At <b>1215</b>, a drive signal is applied to a haptic actuator according to the interaction parameter</p>
<p id="p-0072" num="0071">Several embodiments are specifically illustrated and/or described herein. However, it will be appreciated that modifications and variations of the disclosed embodiments are covered by the above teachings and within the purview of the appended claims without departing from the spirit and intended scope of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of producing a haptic effect comprising:
<claim-text>receiving a notification signal from a local device, the notification signal having a percentage completion value;</claim-text>
<claim-text>comparing the notification signal to a foreground haptic threshold;</claim-text>
<claim-text>if the percentage completion value is greater than or equal to the foreground haptic threshold, generating an interaction parameter using a foreground haptic effect signal corresponding to a primary task from a first application;</claim-text>
<claim-text>if the percentage completion value is less than the foreground haptic threshold, generating an interaction parameter using a background haptic effect signal corresponding to a non-primary task from a second application; and</claim-text>
<claim-text>applying a drive signal to a haptic output device according to the interaction parameter allowing a user to distinguish between the primary task and the non-primary task.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the foreground haptic effect signal or the background haptic effect signal comprises a haptic effect signal selected from the list consisting of strength, frequency, duration, rhythm, dynamics, positive additive effect, negative subtractive effect, or change in effect.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the foreground haptic effect signal or the background haptic effect signal comprises an adaptive set of static or dynamic haptic effects or effect components in response to user input, system input, device sensor input or ambient input.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the notification signal from a local device comprises a notification signal selected from the list consisting of a local user, a primary user, or a remote user.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device according to the interaction parameter concurrently with a visual display.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a user to distinguish between different effects and identifying them as originating from different sources.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a user to distinguish between virtual simulations or animations.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a natural or gradual foregrounding of haptic effects.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a non-distracting augmentation of haptic encoded content.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device representing any type of input by any number of haptic events on one or more foreground or background haptic channels.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A haptic effect enabled system comprising:
<claim-text>a haptic output device;</claim-text>
<claim-text>a drive module electronically coupled to the haptic output device for receiving a notification signal from a local device, the notification signal having a percentage completion value, and comparing the notification signal to a foreground haptic threshold, and generating an interaction parameter using a first haptic effect signal combined with a first priority level and a second haptic effect signal combined with a second priority level; and if the percentage completion value is greater than or equal to the foreground haptic threshold, generating an interaction parameter using a foreground haptic effect signal corresponding to a primary task from a first application; and if the percentage completion value is less than the foreground haptic threshold, generating an interaction parameter using a background haptic effect signal corresponding to a non-primary task from a second application; and</claim-text>
<claim-text>a drive circuit electronically coupled to the drive module and the haptic output device for applying a drive signal to the haptic output device according to the interaction parameter allowing a user to distinguish between the primary task and the non-primary task.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the foreground haptic effect signal or the background haptic effect signal comprises a haptic effect signal selected from the list consisting of strength, frequency, duration, rhythm, dynamics, positive additive effect, negative subtractive effect, or change in effect.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the foreground haptic effect signal or the background haptic effect signal comprises an adaptive set of static or dynamic haptic effects or effect components in response to user input, system input, device sensor input or ambient input.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the notification signal from a local device comprises a notification signal selected from the list consisting of a local user, a primary user, or a remote user.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device according to the interaction parameter concurrently with a visual display.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a user to distinguish between different effects and identifying them as originating from different sources.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a user to distinguish between virtual simulations or animations.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a natural or gradual foregrounding of haptic effects.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a non-distracting augmentation of haptic encoded content.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device representing any type of input by any number of haptic events on one or more foreground or background haptic channels.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. A non-transitory computer readable medium having instructions stored thereon that, when executed by a processor, causes the processor to produce a haptic effect, the instructions comprising:
<claim-text>receiving a notification signal from a local device, the notification signal having a percentage completion value;</claim-text>
<claim-text>comparing the notification signal to a foreground haptic threshold;</claim-text>
<claim-text>if the percentage completion value is greater than or equal to the foreground haptic threshold, generating an interaction parameter using a foreground haptic effect signal corresponding to a primary task from a first application;</claim-text>
<claim-text>if the percentage completion value is less than the foreground haptic threshold, generating an interaction parameter using a background haptic effect signal corresponding to a non-primary task from a second application; and</claim-text>
<claim-text>applying a drive signal to a haptic output device according to the interaction parameter allowing a user to distinguish between the primary task and the non-primary task.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the foreground haptic effect signal or the background haptic effect signal comprises a haptic effect signal selected from the list consisting of strength, frequency, duration, rhythm, dynamics, positive additive effect, negative subtractive effect, or change in effect.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the foreground haptic effect signal or the background haptic effect signal comprises an adaptive set of static or dynamic haptic effects or effect components in response to user input, system input, device sensor input or ambient input.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the notification signal from a local device comprises a notification signal selected from the list consisting of a local user, a primary user, or a remote user.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device according to the interaction parameter concurrently with a visual display.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a user to distinguish between different effects and identifying them as originating from different sources.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a user to distinguish between virtual simulations or animations.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a natural or gradual foregrounding of haptic effects.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device providing a non-distracting augmentation of haptic encoded content.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The non-transitory computer readable medium of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein applying a drive signal comprises applying a drive signal to a haptic output device representing any type of input by any number of haptic events on one or more foreground or background haptic channels.</claim-text>
</claim>
</claims>
</us-patent-grant>
