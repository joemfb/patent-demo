<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624990-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624990</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12589971</doc-number>
<date>20091030</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>P2008-302831</doc-number>
<date>20081127</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>484</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>228</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>3482221</main-classification>
<further-classification>34820799</further-classification>
</classification-national>
<invention-title id="d2e71">Signal processing device, camera module, mobile terminal device and imaging method</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4878119</doc-number>
<kind>A</kind>
<name>Beikirch et al.</name>
<date>19891000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358471</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2006/0285004</doc-number>
<kind>A1</kind>
<name>Suemoto</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348340</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2007/0291132</doc-number>
<kind>A1</kind>
<name>Shigeta et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482221</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2008/0111910</doc-number>
<kind>A1</kind>
<name>Nikkanen et al.</name>
<date>20080500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348345</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2009/0251584</doc-number>
<kind>A1</kind>
<name>Alakarhu</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>2005260733</doc-number>
<kind>A</kind>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>2007-133028</doc-number>
<kind>A</kind>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>2009-518913</doc-number>
<kind>T</kind>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>WO</country>
<doc-number>2007065964</doc-number>
<kind>A1</kind>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00010">
<othercit>Office Action from Japanese Application No. 2008-302831, dated Sep. 14. 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>8</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>3482221</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>34820799</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>12</number-of-drawing-sheets>
<number-of-figures>12</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100128143</doc-number>
<kind>A1</kind>
<date>20100527</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ohtsubo</last-name>
<first-name>Shinichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Ohtsubo</last-name>
<first-name>Shinichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Lerner, David, Littenberg, Krumholz &#x26; Mentlik, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Hannett</last-name>
<first-name>James</first-name>
<department>2663</department>
</primary-examiner>
<assistant-examiner>
<last-name>Garces-Rivera</last-name>
<first-name>Angel L</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A signal processing device is provided which includes, an input terminal to receive input of an imaging start instruction signal, and a signal processing unit to output an exposure start instruction signal when the imaging start instruction signal is input to the input terminal.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="134.62mm" wi="159.09mm" file="US08624990-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="207.35mm" wi="110.15mm" file="US08624990-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="169.76mm" wi="100.08mm" file="US08624990-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="186.86mm" wi="85.01mm" orientation="landscape" file="US08624990-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="202.44mm" wi="134.96mm" orientation="landscape" file="US08624990-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="202.10mm" wi="91.52mm" orientation="landscape" file="US08624990-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="265.94mm" wi="149.52mm" orientation="landscape" file="US08624990-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="169.08mm" wi="171.28mm" file="US08624990-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="261.28mm" wi="125.56mm" orientation="landscape" file="US08624990-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="240.45mm" wi="157.31mm" orientation="landscape" file="US08624990-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="239.18mm" wi="144.27mm" orientation="landscape" file="US08624990-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="268.56mm" wi="155.02mm" orientation="landscape" file="US08624990-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="217.93mm" wi="132.00mm" file="US08624990-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">The present application claims priority from Japanese Patent Application No. JP 2008-302831 filed in the Japanese Patent Office on Nov. 27, 2008, the entire content of which is incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to a signal processing device, a camera module, a mobile terminal device and an imaging method.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Mobile terminal devices become increasingly multifunctional today, and a camera module that implements an advanced digital camera function is incorporated into many mobile terminal devices. For example, a mobile phone that incorporates such a camera module can perform imaging with advanced digital processing such as autofocus and image stabilization, in addition to basic communication such as phone calls and email, in a single mobile phone terminal.</p>
<p id="p-0007" num="0006">In such a multifunctional mobile terminal device, various functional modules are incorporated into a single housing. The respective functional modules are controlled with use of a command prepared for each module, and a user interface or an internal bus for issuing such a command is often shared among modules because of constraints on device size. For example, Japanese Unexamined Patent Application Publication No. 2007-133028 discloses a camera-equipped mobile phone on which a plurality of shared buttons that are used as an operating unit for operating a camera module in a camera mode are mounted.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0008" num="0007">However, in a release operation of a camera shutter, for example, instant reaction is required from an operation by a user to actuation of a functional module. From this point of view, if a user interface or an internal bus is shared among a plurality of modules, an overhead necessary for interpretation or transmission of a signal increases, which causes an increase in a time lag between an operation by a user and actuation of a functional module. Specifically, in the case where a camera module is incorporated into a mobile terminal device, for example, it is likely to miss a photo opportunity due to a time lag between pressing of a release button and start of exposure.</p>
<p id="p-0009" num="0008">In light of the foregoing, it is desirable to provide a novel and improved signal processing device, camera module, mobile terminal device and imaging method that enable reduction of a time lag between a release operation and start of exposure.</p>
<p id="p-0010" num="0009">According to an embodiment of the present invention, there is provided a signal processing device including, an input terminal to receive input of an imaging start instruction signal, and a signal processing unit to output an exposure start instruction signal when the imaging start instruction signal is input to the input terminal.</p>
<p id="p-0011" num="0010">The signal processing unit may detect input of the imaging start instruction signal to the input terminal with use of an external interrupt.</p>
<p id="p-0012" num="0011">The signal processing unit may output the exposure start instruction signal as an asynchronous signal without synchronization with a cyclic signal.</p>
<p id="p-0013" num="0012">The signal processing unit may forcibly switch vertical synchronization timing of its own device in accordance with output of the exposure start instruction signal.</p>
<p id="p-0014" num="0013">The signal processing unit may further output an exposure start notification signal for notifying start of exposure to an external device when the imaging start instruction signal is input to the input terminal.</p>
<p id="p-0015" num="0014">According to another embodiment of the present invention, there is provided a camera module including, an input terminal to receive input of an imaging start instruction signal, a signal processing unit to output an exposure start instruction signal when the imaging start instruction signal is input to the input terminal, and an image sensor unit to image external light and generate an image signal when the exposure start instruction signal is input.</p>
<p id="p-0016" num="0015">According to another embodiment of the present invention, there is provided a camera-equipped mobile terminal device including, a release button to generate an imaging start instruction signal when pressed by a user, an input terminal to receive input of the imaging start instruction signal generated by the release button, a signal processing unit to output an exposure start instruction signal when the imaging start instruction signal is input to the input terminal, and an image sensor unit to image external light and generate an image signal when the exposure start instruction signal is input.</p>
<p id="p-0017" num="0016">According to another embodiment of the present invention, there is provided an imaging method comprising the steps of, transmitting an imaging start instruction signal from a release button pressed by a user to an input terminal of a camera module without through a host control unit, detecting the imaging start instruction signal input to the input terminal by a signal processing unit of the camera module, transmitting an exposure start instruction signal from the signal processing unit to an image sensor, and imaging external light and generating an image signal by the image sensor where the exposure start instruction signal is input.</p>
<p id="p-0018" num="0017">According to the embodiments of the present invention described above, it is possible to provide the signal processing device, camera module, mobile terminal device and imaging method that enable reduction of a time lag between a release operation and start of exposure.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic view showing an appearance of a camera-equipped mobile terminal device according to an embodiment.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic view showing an appearance of a camera module according to an embodiment.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 3</figref> is an explanatory view showing an example of a signal transmission channel in a general camera-equipped mobile terminal device.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 4</figref> is an explanatory view showing a connection pattern between a host control unit and a camera module through an I2C bus.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 5</figref> is an explanatory view showing definition of two kinds of a time lag related to a release operation.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 6</figref> is a timing chart showing a shutter release lag in a general camera-equipped mobile terminal device.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram showing a configuration of a mobile terminal device according to an embodiment.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram showing a configuration of a camera module according to an embodiment.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 9</figref> is an explanatory view showing an example of allocation of a release input terminal according to an embodiment.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 10</figref> is an explanatory view showing another example of allocation of a release input terminal according to an embodiment.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 11</figref> is a timing chart showing a shutter release lag in a camera-equipped mobile terminal device according to an embodiment.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing a flow of imaging processing according to an embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF EMBODIMENT</heading>
<p id="p-0031" num="0030">Hereinafter, preferred embodiments of the present invention will be described in detail with reference to the appended drawings. Note that, in this specification and the appended drawings, structural elements that have substantially the same function and structure are denoted with the same reference numerals, and repeated explanation of these structural elements is omitted.</p>
<p id="p-0032" num="0031">A preferred embodiment of the present invention will be described hereinafter in the following order.</p>
<p id="p-0033" num="0032">1. Outline of Device</p>
<p id="p-0034" num="0033">2. Explanation of Issues Related to the Present Invention</p>
<p id="p-0035" num="0034">3. Explanation of Embodiment of the Present Invention</p>
<p id="p-0036" num="0035">4. Summary</p>
<p id="h-0006" num="0000">&#x3c;1. Outline of Device&#x3e;</p>
<p id="p-0037" num="0036">An outline of a camera-equipped mobile terminal device is described hereinafter with reference to <figref idref="DRAWINGS">FIGS. 1 and 2</figref>.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic view showing an appearance of a camera-equipped mobile terminal device <b>100</b> (which is referred to hereinafter simply as the mobile terminal device <b>100</b>) according to an embodiment of the present invention. Referring to <figref idref="DRAWINGS">FIG. 1</figref>, a keypad <b>110</b>, a dedicated button <b>112</b>, a display unit <b>132</b>, a lens <b>172</b> and so on appear on the outside of the mobile terminal device <b>100</b>.</p>
<p id="p-0039" num="0038">The display unit <b>132</b> is an image display means that is made of a liquid crystal, OLED (Organic Light Emitting Diode) or the like, and the display unit <b>132</b> displays given still images or moving images for a user.</p>
<p id="p-0040" num="0039">The keypad <b>110</b> includes a plurality of buttons that are used in common by various functional modules incorporated in the mobile terminal device <b>100</b>. If a user presses any button of the keypad <b>110</b>, a signal for identifying the kind of the pressed button is transmitted to a control unit (not shown; which is referred to hereinafter as a host control unit), such as a CPU (Central Processing Unit), inside the mobile terminal device <b>100</b>.</p>
<p id="p-0041" num="0040">The dedicated button <b>112</b> is a button that is used exclusively by a particular functional module, such as a camera module <b>140</b> which is described later with reference to <figref idref="DRAWINGS">FIG. 2</figref>, incorporated in the mobile terminal device <b>100</b>.</p>
<p id="p-0042" num="0041">The lens <b>172</b> is a lens that is mounted on the camera module <b>140</b> incorporated in the mobile terminal device <b>100</b>. The camera module <b>140</b>, which is described later with reference to <figref idref="DRAWINGS">FIG. 2</figref>, images external light through the lens <b>172</b>.</p>
<p id="p-0043" num="0042">The layout of the parts on the outside of the mobile terminal device <b>100</b> is not limited to such an example. Further, although <figref idref="DRAWINGS">FIG. 1</figref> shows a mobile phone as an example of the mobile terminal device <b>100</b>, the mobile terminal device <b>100</b> is not limited to a mobile phone. For example, the mobile terminal device <b>100</b> may be an arbitrary terminal device such as a PC (Personal Computer), a PDA (Personal Digital Assistants) or a mobile game terminal.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic view showing an appearance of the camera module <b>140</b> incorporated in the mobile terminal device <b>100</b>. Referring to <figref idref="DRAWINGS">FIG. 2</figref>, a terminal unit <b>160</b>, an image sensor unit <b>170</b> and a lens <b>172</b> appear on the outside of the camera module <b>140</b>.</p>
<p id="p-0045" num="0044">The terminal unit <b>160</b> includes at least one input terminal for inputting a signal from the host control unit to the camera module <b>140</b> and at least one output terminal for outputting a signal from the camera module <b>140</b> to the host control unit. Further, the terminal unit <b>160</b> includes an input terminal that directly receives a signal input from an external button without through another control unit, which is a feature of the present invention. The signal that is input to the camera module <b>140</b> through the terminal unit <b>160</b> is processed by a signal processing unit (not shown), which is described later, incorporated in the camera module <b>140</b>. An example of allocation of input and output terminals in the terminal unit <b>160</b> is described in detail later.</p>
<p id="p-0046" num="0045">The image sensor unit <b>170</b> is placed on the inner side of the lens <b>172</b>, and it images external light that reaches a light-receiving surface through the lens <b>172</b> and generates an image signal. The image sensor unit <b>170</b> may be an image sensor using a CCD (Charge Coupled Device Image Sensor), a CMOS (Complementary Metal Oxide Semiconductor) or the like.</p>
<p id="p-0047" num="0046">The lens <b>172</b> is a part that appears on the outside of the device when the camera module <b>140</b> is mounted on the mobile terminal device <b>100</b>, for example, as shown in <figref idref="DRAWINGS">FIG. 1</figref>. As described above, the camera module <b>140</b> images external light through the lens <b>172</b>.</p>
<p id="h-0007" num="0000">&#x3c;2. Explanation of Issues Related to the Present Invention&#x3e;</p>
<p id="p-0048" num="0047">In order to clarify an issue related to the present invention, a signal transmission channel inside a general camera-equipped mobile terminal device related to the present invention is described hereinafter.</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 3</figref> is an explanatory view showing a signal transmission channel through which a signal is transmitted to a camera module via a host control unit after a button is pressed in a general camera-equipped mobile terminal device.</p>
<p id="p-0050" num="0049">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, a keypad <b>10</b>, a keypad control unit <b>20</b>, a host control unit <b>30</b> and a camera module <b>40</b>, which are included in a general camera-equipped mobile terminal device, are shown.</p>
<p id="p-0051" num="0050">The keypad <b>10</b> includes a plurality of buttons to be pressed by a user. The plurality of buttons of the keypad <b>10</b> form a key matrix, for example, and they are periodically scanned along each line of the key matrix by the keypad control unit <b>20</b>. The keypad control unit <b>20</b> determines which button of the keypad <b>10</b> is pressed by such periodic monitoring of the key matrix and outputs an input signal associated with the kind of the pressed button to the host control unit <b>30</b>.</p>
<p id="p-0052" num="0051">The host control unit <b>30</b> recognizes the input signal from the keypad control unit <b>20</b>, interprets the meaning of the input signal and generates a signal to be output to the camera module <b>40</b>. The host control unit <b>30</b> and the camera module <b>40</b> are connected by an I2C (Inter-Integrated Circuit) bus, an SPI (Serial Peripheral Interface) bus or the like, for example.</p>
<p id="p-0053" num="0052">The I2C bus is one of standard specifications of a bus for connecting a CPU with a peripheral device by two signal lines. The I2C bus is widespread as a bus to be used for a mobile terminal device for its merits of allowing device weight and power consumption reduction, production cost reduction or the like, for example.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 4</figref> is an explanatory view showing a more specific connection pattern in the case of connecting the host control unit <b>30</b> and the camera module <b>40</b> with use of the I2C bus. Referring to <figref idref="DRAWINGS">FIG. 4</figref>, the I2C bus is composed of two lines: SCL (Serial Clock Line) and SDA (Serial DAta line). The SCL is a line for transmitting a clock pulse. The SDA is a line for serially transmitting data.</p>
<p id="p-0055" num="0054">In the connection pattern using the I2C bus shown in <figref idref="DRAWINGS">FIG. 4</figref>, the host control unit <b>30</b> serves as a master device on the I2C bus. Specifically, the host control unit <b>30</b> first generates a clock pulse and outputs it to the SCL. The host control unit <b>30</b> then transmits an address designating the camera module <b>40</b> as a slave to the SDA subsequent to a start state. Then, the camera module <b>40</b> recognizes that the received data contains the address designating itself and transmits a confirmation response signal by return. The host control unit <b>30</b> can thereby transmit and receive data to and from the camera module <b>40</b> until outputting a stop state.</p>
<p id="p-0056" num="0055">Further, in addition to the I2C bus composed of SCL and SDA, a line for event output from the camera module <b>40</b> is placed in some cases between the host control unit <b>30</b> and the camera module <b>40</b>. The line for event output is used to notify completion of processing executed by the camera module <b>40</b> to the host control unit <b>30</b>, for example. The host control unit <b>30</b> can thereby read the event of the camera module <b>40</b> through the I2C bus.</p>
<p id="p-0057" num="0056">The signal transmission channel of a general camera-equipped mobile terminal device is described in the foregoing with reference to <figref idref="DRAWINGS">FIGS. 3 and 4</figref>. The signal transmission channel, however, has various factors contributing to the occurrence of a time lag between a user's operation and start of the operation of the camera module <b>40</b>.</p>
<p id="p-0058" num="0057">A first factor is periodic monitoring on the respective buttons of the keypad <b>10</b>. Because periodic monitoring by the keypad control unit <b>20</b> is generally performed at intervals of 10 to 20 ms, there is a possibility that a time lag of 20 ms at maximum is occurring after a user presses a button until the host control unit <b>30</b> recognizes pressing of the button. Further, in the case where a plurality of times of sampling is performed in order to prevent incorrect determination due to noise in the keypad <b>10</b>, the time lag becomes wider by multiplication of the number of times of sampling.</p>
<p id="p-0059" num="0058">A second factor is delay due to removal of chattering in the keypad <b>10</b>. The chattering is a phenomenon in which on and off are repeated in a short time by vibration of a contact point due to manual switch, which causes malfunction of the device. Therefore, the chattering in the keypad <b>10</b> is removed by reading a port by adding a delay time of about 10 ms in the keypad control unit <b>20</b>, for example.</p>
<p id="p-0060" num="0059">A third factor is translation of a signal for the I2C bus by the host control unit <b>30</b>. A signal that is transmitted or received through the I2C bus contains control information such as an I2C address, a packet length or an access code which is necessary for providing commonality of connection with various peripheral devices. Thus, a certain amount of time lag can occur while the host control unit <b>30</b> interprets an input signal and generates such control information. Further, a time lag can also occur after the host control unit <b>30</b> transmits a signal to the camera module <b>40</b> until the host control unit <b>30</b> frees the I2C bus for a wait for a phone call or the like, for example, after waiting for a response from the camera module <b>40</b>.</p>
<p id="p-0061" num="0060">A fourth possible factor is delay inside the camera module <b>40</b>. Because exposure is generally started in accordance with a screen cyclic signal of a mobile terminal device in a camera module incorporated in a camera-equipped mobile terminal device, a time lag corresponding a cycle of a screen cyclic signal can occur.</p>
<p id="p-0062" num="0061">A time lag related to a release operation of a camera is mainly classified into two kinds. <figref idref="DRAWINGS">FIG. 5</figref> shows definition of a time lag in a guideline (CIPA DCG-002-2007-J) for specifications of a digital camera developed by CIPA (Camera and Imaging Products Association). According to the guideline, a time lag related to a release operation is classified into a shooting time lag and a shutter release lag. The shooting time lag indicates a period of time up until exposure start when a release button is pressed all the way down to the 2nd release from a standby state in the case where there is a distinction between the 1st release (half-press) and the 2nd release (full-press) for the pressed state of the release button. In the case where there is no distinction between the 1st release and the 2nd release for the pressed state of the release button, the shooting time lag indicates a period of time from pressing of the release button to start of exposure (a lag for autofocus is not included). On the other hand, the shutter release lag indicates a period of time after pressing of the 2nd release after stabilization of the 1st release up until start of exposure in the case where there is a distinction between the 1st release and the 2nd release for the pressed state of the release button.</p>
<p id="p-0063" num="0062">The above-described four factors contributing to the occurrence of a time lag can affect both the shooting time lag and the shutter release lag shown in <figref idref="DRAWINGS">FIG. 5</figref>. Hereinafter, the term &#x201c;time lag&#x201d; includes both the shooting time lag and the shutter release lag unless otherwise noted.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 6</figref> is a timing chart to describe a shutter release lag in a general camera-equipped mobile terminal device as an example in further detail.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 6(</figref><i>a</i>) indicates a screen cycle that is a cycle of updating a screen displayed on a display unit of a camera-equipped mobile terminal device. <figref idref="DRAWINGS">FIG. 6(</figref><i>b</i>) indicates a state of a screen displayed on the display unit in accordance with the screen cycle of <figref idref="DRAWINGS">FIG. 6(</figref><i>a</i>). <figref idref="DRAWINGS">FIG. 6(</figref><i>c</i>) indicates a signal that is generated when the release button mounted on the camera-equipped mobile terminal device is pressed by a user.</p>
<p id="p-0066" num="0065">On the other hand, <figref idref="DRAWINGS">FIG. 6(</figref><i>d</i>) indicates a vertical synchronization signal for synchronizing the operations of the respective parts inside a camera module incorporated in the camera-equipped mobile terminal device. <figref idref="DRAWINGS">FIG. 6(</figref><i>e</i>) indicates an operating cycle of an image sensor of the camera module. The operating cycle of the image sensor is twice the screen cycle of a host, for example, and synchronized with the screen cycle of the host. <figref idref="DRAWINGS">FIG. 6(</figref><i>f</i>) indicates a state of imaging processing by the camera module.</p>
<p id="p-0067" num="0066">At the left end of the timing chart of <figref idref="DRAWINGS">FIG. 6</figref>, the state of imaging processing by the camera module is in &#x201c;LOCK operation&#x201d; as a result that a user half-presses the release button. In this state, the camera module executes exposure control, autofocus, auto white balance or the like and then waits for a user's instruction for start of imaging. At this time, the screen of the host is in the state of &#x201c;draft moving image&#x201d; in which a rough image captured by the image sensor is displayed as it is.</p>
<p id="p-0068" num="0067">After that, when a user full-presses the release button at timing T<b>1</b>, an imaging start instruction signal is generated by a host control unit and transmitted to the camera module through the I2C bus. Then, a signal processing unit of the camera module recognizes that the release button is fully pressed at the first vertical synchronization timing after transmission of the imaging start instruction signal and then outputs an exposure start instruction signal that instructs the image sensor to start exposure at the next vertical synchronization timing (T<b>2</b>). Receiving the exposure start instruction signal, the image sensor starts preparation for exposure (&#x201c;exposure preparation&#x201d;) and then starts exposure at the next timing (T<b>3</b>) of the operating cycle of the image sensor (&#x201c;exposure operation&#x201d;).</p>
<p id="p-0069" num="0068">After the image sensor starts exposure preparation, the screen of the host is in the state of &#x201c;mute screen&#x201d; until a captured image signal is output. This is because an image signal output from the image sensor during this period is not a normal image. Therefore, the signal processing unit of the camera module switches the screen of the host to the mute screen by outputting an event to the host control unit, for example, before instructing the image sensor to start exposure.</p>
<p id="p-0070" num="0069">As described above with reference to <figref idref="DRAWINGS">FIG. 6</figref>, the shutter release lag after a user full-presses the release button until the camera module starts exposure corresponds to the period from T<b>1</b> to T<b>3</b>. During the shutter release lag, the period from T<b>1</b> to T<b>2</b>, particularly, is substantially a period of waiting for start of imaging processing (start of exposure preparation). Therefore, if the above-described factors causing the time lag can be eliminated, the time lag between the release operation and the exposure start is reduced.</p>
<p id="h-0008" num="0000">&#x3c;3. Explanation of Embodiment of the Present Invention&#x3e;</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram showing a configuration of a mobile terminal device <b>100</b> according to an embodiment of the present invention. Referring to <figref idref="DRAWINGS">FIG. 7</figref>, the mobile terminal device <b>100</b> includes a keypad <b>110</b>, a release button <b>112</b>, a keypad control unit <b>120</b>, a host control unit <b>130</b>, a display unit <b>132</b> and a camera module <b>140</b>.</p>
<p id="p-0072" num="0071">The keypad <b>110</b> and the keypad control unit <b>120</b> have equal functions to the keypad <b>10</b> and the keypad control unit <b>20</b> described earlier with reference to <figref idref="DRAWINGS">FIG. 3</figref>. Specifically, when any button of the keypad <b>110</b> is pressed by a user, the keypad control unit <b>120</b> determines which button of the keypad <b>110</b> is pressed by periodic monitoring of the key matrix and outputs an input signal associated with the kind of the pressed button to the host control unit <b>130</b>.</p>
<p id="p-0073" num="0072">The release button <b>112</b> is substantially the same button as the dedicated button <b>112</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>. When pressed by a user, the release button <b>112</b> generates an imaging start instruction signal and outputs it to the camera module <b>140</b>. The release button <b>112</b> may be a button that is physically the same as one of a plurality of buttons included in the keypad <b>110</b> or a button that is independent of the keypad <b>110</b>.</p>
<p id="p-0074" num="0073">The host control unit <b>130</b> is typically configured using a CPU and controls the functions of the mobile terminal device <b>100</b> as a whole. For example, the host control unit <b>130</b> controls the operation of the camera module <b>140</b> by using the I2C bus between the host control unit <b>130</b> and the camera module <b>140</b> or displays an captured image read from the camera module <b>140</b>, a mute screen or the like on the display unit <b>132</b>.</p>
<p id="p-0075" num="0074">In addition to being controlled by the host control unit <b>130</b>, the camera module <b>140</b> receives input of the imaging start instruction signal from the release button <b>112</b> and images external light.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram showing a specific configuration of the camera module <b>140</b>. Referring to <figref idref="DRAWINGS">FIG. 8</figref>, the camera module <b>140</b> includes a signal processing unit <b>150</b>, a terminal unit <b>160</b> and an image sensor unit <b>170</b>.</p>
<p id="p-0077" num="0076">The signal processing unit <b>150</b> is typically configured using a DSP (Digital Signal Processing). When the imaging start instruction signal is input to the terminal unit <b>160</b> from the release button <b>112</b> shown in <figref idref="DRAWINGS">FIG. 7</figref>, for example, the signal processing unit <b>150</b> detects input of the imaging start instruction signal by means of an external interrupt. Upon detecting input of the imaging start instruction signal, the signal processing unit <b>150</b> outputs an exposure start instruction signal to the image sensor unit <b>170</b> as an asynchronous signal without synchronization with vertical synchronization timing of the camera module <b>140</b>. Further, the signal processing unit <b>150</b> forcibly switches the vertical synchronization timing of the camera module <b>140</b> in accordance with output of the exposure start instruction signal, for example.</p>
<p id="p-0078" num="0077">The signal processing unit <b>150</b> may further output an exposure start notification signal for notifying start of exposure to the host control unit <b>130</b> via the terminal unit <b>160</b> upon detecting input of the imaging start instruction signal, for example. The host control unit <b>130</b> can thereby switch the screen to the mute screen during imaging processing by the camera module <b>140</b>.</p>
<p id="p-0079" num="0078">The terminal unit <b>160</b> includes terminals for inputting and outputting signals from the host control unit <b>130</b> to the camera module <b>140</b> as described earlier with reference to <figref idref="DRAWINGS">FIG. 2</figref>. In the example of <figref idref="DRAWINGS">FIG. 8</figref>, the terminal unit <b>160</b> includes I2C bus terminals <b>164</b> and <b>166</b>. For example, the exposure start notification signal that notifies start of exposure from the signal processing unit <b>150</b> to the host control unit <b>130</b> can be output through the I2C bus terminals.</p>
<p id="p-0080" num="0079">The terminal unit <b>160</b> further includes an external interrupt input terminal <b>162</b> for inputting the imaging start instruction signal from the release button <b>112</b>. In the case where there is a distinction between the 1st release (half-press) and the 2nd release (full-press) for the pressed state of the release button <b>112</b>, two external interrupt input terminals <b>162</b> may be placed to recognize each pressed state.</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. 9</figref> is an explanatory view partially showing allocation of terminals in the case of placing two external interrupt input terminals <b>162</b> in the terminal unit <b>160</b> by way of illustration.</p>
<p id="p-0082" num="0081">Referring to the left side of <figref idref="DRAWINGS">FIG. 9</figref>, the 24th terminal is allocated to an external interrupt input terminal <b>162</b><i>a </i>(CAPT<b>1</b>), and the 28th terminal is allocated to an external interrupt input terminal <b>162</b><i>b </i>(CAPT<b>2</b>), among the terminals included in the terminal unit <b>160</b>.</p>
<p id="p-0083" num="0082">The external interrupt input terminal <b>162</b><i>a </i>corresponds to a switch SW<b>1</b> that detects the 1st release of the release button <b>112</b>, and it turns on both in the half-pressed state and the full-pressed state. On the other hand, the external interrupt input terminal <b>162</b><i>b </i>corresponds to a switch SW<b>2</b> that detects the 2nd release of the release button <b>112</b>, and it turns off in the half-pressed state and turns on in the full-pressed state.</p>
<p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. 10</figref> is an explanatory view partially showing allocation of terminals in the case of placing one external interrupt input terminal <b>162</b> in the terminal unit <b>160</b> by way of illustration.</p>
<p id="p-0085" num="0084">Referring to the left side of <figref idref="DRAWINGS">FIG. 10</figref>, the 28th terminal among the terminals included in the terminal unit <b>160</b> is allocated to an external interrupt input terminal <b>162</b> (CAPT). A signal corresponding to an exclusive OR between an output of the switch SW<b>1</b> that detects the 1st release of the release button <b>112</b> and an output of the switch SW<b>2</b> that detects the 2nd release of the release button <b>112</b> is input to the external interrupt input terminal <b>162</b>. In this case, a rising edge at which the input signal changes from Low to High corresponds to the half-press of the release button <b>112</b>, and a falling edge at which the input signal changes from High to Low corresponds to the full-press of the release button <b>112</b> (cf. on the right side of <figref idref="DRAWINGS">FIG. 10</figref>). In this case, it is preferred to eliminate malfunction due to chattering with use of a Schmitt trigger circuit.</p>
<p id="p-0086" num="0085">An existing connector ground terminal (GND terminal), for example, may be used as the external interrupt input terminal <b>162</b> (<b>162</b><i>a </i>and <b>162</b><i>b</i>). Alternatively, the external interrupt input terminal <b>162</b> may be newly provided.</p>
<p id="p-0087" num="0086">Referring back to <figref idref="DRAWINGS">FIG. 8</figref>, the configuration of the camera module <b>140</b> is further described hereinbelow.</p>
<p id="p-0088" num="0087">Upon input of the exposure start instruction signal from the signal processing unit <b>150</b>, the image sensor unit <b>170</b> prepares for exposure and then images external light that reaches a light-receiving surface through the lens <b>172</b> (cf. <figref idref="DRAWINGS">FIG. 2</figref>) on the outside of the mobile terminal device <b>100</b> and generates an image signal. The image sensor unit <b>170</b> then outputs the generated image signal to the signal processing unit <b>150</b>.</p>
<p id="p-0089" num="0088">In the camera module <b>140</b> described in this specification, the signal processing unit <b>150</b> and the terminal unit <b>160</b> may constitute a signal processing device <b>190</b>. In this case, the image sensor unit <b>170</b> is a separate image sensor module including the lens <b>172</b>. Further, an image sensor interface (not shown) may be mounted on the signal processing unit <b>150</b>, so that signals are input and output between the signal processing unit <b>150</b> and the image sensor unit <b>170</b> through the interface. This allows the signal processing device <b>190</b> to be treated as an independent device.</p>
<p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. 11</figref> is a timing chart to describe a shutter release lag in the mobile terminal device <b>100</b> according to the embodiment described above.</p>
<p id="p-0091" num="0090">At the left end of the timing chart of <figref idref="DRAWINGS">FIG. 11</figref>, the state of the camera module <b>140</b> is in &#x201c;LOCK operation&#x201d; as a result that a user half-presses the release button <b>112</b>. In this state, the camera module <b>140</b> executes exposure control, autofocus, auto white balance or the like. At this time, the screen of the display unit <b>132</b> is in the state of &#x201c;draft moving image&#x201d; in which a rough image captured by the image sensor <b>170</b> is displayed as it is.</p>
<p id="p-0092" num="0091">After that, when a user full-presses the release button <b>112</b> at timing T<b>1</b>&#x2032;, an imaging start instruction signal is input to the external interrupt input terminal <b>162</b> from the release button <b>112</b> without through the host control unit <b>130</b>. The imaging start instruction signal is detected as an external interrupt by the signal processing unit <b>150</b> of the camera module <b>140</b>.</p>
<p id="p-0093" num="0092">Next, at timing T<b>2</b>&#x2032;, the signal processing unit <b>150</b> outputs an exposure start instruction signal as an asynchronous signal to the image sensor unit <b>170</b> without waiting for vertical synchronization of the camera module <b>140</b>. Further, the signal processing unit <b>150</b> forcibly switches the vertical synchronization of the camera module <b>140</b> and the sensor cycle of the image sensor unit <b>170</b> in accordance with output of the exposure start instruction signal, for example.</p>
<p id="p-0094" num="0093">After that, the image sensor unit <b>170</b> that has received the exposure start instruction signal performs exposure preparation, and exposure is started at timing T<b>3</b>&#x2032;.</p>
<p id="p-0095" num="0094">The signal processing unit <b>150</b> may switch the screen displayed on the display unit <b>132</b> to the mute screen by outputting an event to the host control unit <b>130</b>, for example, before instructing the image sensor unit <b>170</b> to start exposure at T<b>2</b>&#x2032;. Alternatively, the host control unit <b>130</b> may receive the imaging start instruction signal from the release button <b>112</b> in parallel, and the host control unit <b>130</b> may control switching to the mute screen.</p>
<p id="p-0096" num="0095">In <figref idref="DRAWINGS">FIG. 11</figref>, the shutter release lag after a user full-presses the release button <b>112</b> until the camera module <b>140</b> starts exposure corresponds to the period from T<b>1</b>&#x2032; to T<b>3</b>&#x2032;. As obvious from a comparison between <figref idref="DRAWINGS">FIG. 6</figref> and <figref idref="DRAWINGS">FIG. 11</figref>, the shutter release lag in this embodiment is reduced in the period from T<b>1</b>&#x2032; to T<b>2</b>&#x2032; (from T<b>1</b> to T<b>2</b>) compared to the shutter release lag in <figref idref="DRAWINGS">FIG. 6</figref>. Such reduction of the time lag is for the following reasons.</p>
<p id="p-0097" num="0096">Firstly, in this embodiment, the imaging start instruction signal generated by the release button <b>112</b> that is pressed by a user is directly input to the camera module <b>140</b> without through the keypad control unit <b>120</b> or the host control unit <b>130</b>. A time lag for periodic monitoring of the keypad <b>110</b> thereby does not occur.</p>
<p id="p-0098" num="0097">Further, the state of the release button <b>112</b> directly corresponds to output of the imaging start instruction signal as shown in <figref idref="DRAWINGS">FIG. 9</figref>, for example, and delay for removal of chattering in the release button <b>112</b> does not occur when edge detection is not performed.</p>
<p id="p-0099" num="0098">Furthermore, because the imaging start instruction signal does not pass through the host control unit <b>130</b>, a time lag due to interpretation or translation of a signal when using a common signal transmission channel such as the I2C bus, for example, does not occur.</p>
<p id="p-0100" num="0099">In addition, in this embodiment, the imaging start instruction signal that is input to the external interrupt input terminal <b>162</b> of the camera module <b>140</b> (or the signal processing device <b>190</b>) is detected as an external interrupt by the signal processing unit <b>150</b>. Then, the signal processing unit <b>150</b> outputs the exposure start instruction signal without waiting for the arrival of the next sensor cycle of the image sensor unit <b>170</b>. A time lag during a wait for the arrival of a cyclic signal thereby does not occur inside the camera module <b>140</b> (or the signal processing device <b>190</b>).</p>
<p id="p-0101" num="0100">As described above, with use of the mobile terminal device <b>100</b> according to the embodiment, a time lag between pressing of a release button and start of exposure is reduced, and therefore a possibility that a user misses a photo opportunity decreases, for example. As an example, a time lag between T<b>1</b> and T<b>2</b> in <figref idref="DRAWINGS">FIG. 6</figref> is about 50 ms in a mobile terminal device according to related art. On the other hand, a time lag between T<b>1</b>&#x2032; and T<b>2</b>&#x2032; in <figref idref="DRAWINGS">FIG. 11</figref> is about 1 ms in the mobile terminal device <b>100</b> according to the present embodiment.</p>
<p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing an example of a flow of imaging processing according to an embodiment.</p>
<p id="p-0103" num="0102">Referring to <figref idref="DRAWINGS">FIG. 12</figref>, a user first full-presses the release button <b>112</b> (S<b>202</b>). The imaging start instruction signal is thereby input to the external interrupt input terminal <b>162</b> of the camera module <b>140</b> (or the signal processing device <b>190</b>).</p>
<p id="p-0104" num="0103">On the other hand, the signal processing unit <b>150</b> of the camera module <b>140</b> waits for input of the imaging start instruction signal by an external interrupt (S<b>204</b>). When the signal processing unit <b>150</b> detects the imaging start instruction signal, the signal processing unit <b>150</b> first outputs the exposure start notification signal to the host control unit <b>130</b>, for example (S<b>206</b>). Then, the signal processing unit <b>150</b> outputs the exposure start instruction signal as an asynchronous signal to the image sensor unit <b>170</b> without synchronization with vertical synchronization timing of the camera module <b>140</b> (S<b>208</b>).</p>
<p id="p-0105" num="0104">After that, the image sensor unit <b>170</b> prepares for exposure and then starts exposure (S<b>210</b>).</p>
<p id="h-0009" num="0000">&#x3c;4. Summary&#x3e;</p>
<p id="p-0106" num="0105">The camera-equipped mobile terminal device <b>100</b> according to the embodiment of the present invention, the camera module <b>140</b> incorporated in the device, and the signal processing device <b>190</b> used in the module are described above with reference to <figref idref="DRAWINGS">FIGS. 1 to 12</figref>.</p>
<p id="p-0107" num="0106">In the camera-equipped mobile terminal device <b>100</b> according to the embodiment, a time lag due to periodic monitoring of the keypad <b>110</b> or interpretation or translation of a signal when passing through the I2C bus or the like does not occur. Further, in the internal of the camera module <b>140</b> (or the signal processing device <b>190</b>) according to the present embodiment, a time lag during a wait for the arrival of a cyclic signal when giving instruction for exposure start does not occur. It is thereby possible to reduce a time lag such as the shooting time lag and the shutter release lag between a release operation and exposure start without degrading the image quality.</p>
<p id="p-0108" num="0107">It is feasible to use an existing device as the mobile terminal device (thus, the imaging start instruction signal passes through the host control unit) and use the camera module <b>140</b> according to the embodiment for the internal camera module. Further, the signal processing device <b>190</b> that includes the signal processing unit <b>150</b> and the terminal unit <b>160</b>, out of the camera module <b>140</b>, may be provided. In these cases also, reduction of a time lag inside the camera module is achieved, and therefore a time lag between a user's release operation and exposure start is reduced as a whole.</p>
<p id="p-0109" num="0108">It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A camera module connectable to a host control unit and a release button of a mobile device, said camera module comprising:
<claim-text>an input terminal to receive input of an imaging start instruction signal from the release button;</claim-text>
<claim-text>a signal processing unit to output an exposure start instruction signal when the imaging start instruction signal is input to the input terminal; and</claim-text>
<claim-text>an image sensor unit to image external light and generate an image signal when the exposure start instruction signal is input,</claim-text>
<claim-text>in which the signal processing unit outputs the exposure start instruction signal to the image sensor unit as an asynchronous signal without waiting for synchronization with a vertical synchronization signal of the camera module, in which the vertical synchronization signal has a plurality of normally occurring pulses associated therewith, such that the exposure start instruction signal is outputted to the image sensor unit before a pulse of the vertical synchronization signal which would have normally occurred next after generation or receipt by the input terminal of the imaging start instruction signal,</claim-text>
<claim-text>in which operation of the camera module is controlled by the host control unit,</claim-text>
<claim-text>in which the imaging start instruction signal is directly input to the camera module from the release button without passing through the host control unit, and</claim-text>
<claim-text>in which the mobile device includes a display which is connectable to the host control unit which controls the display to cause images or a mute screen to be displayed on the display such that the camera module is separate from and not connectable directly to the display.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The camera module according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal processing unit detects input of the imaging start instruction signal to the input terminal as an external interrupt.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The camera module according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal processing unit forcibly switches vertical synchronization timing of its own device from that which is normally occurring in accordance with output of the exposure start instruction signal.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The camera module according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal processing unit further outputs an exposure start notification signal for notifying start of exposure to the host control unit when the imaging start instruction signal is input to the input terminal.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The camera module according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which a time between the imaging start instruction signal and the output of the exposure start instruction signal is approximately 1 ms (milli-second).</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A camera-equipped mobile terminal device comprising:
<claim-text>a release button to generate an imaging start instruction signal when pressed by a user;</claim-text>
<claim-text>a camera module having (i) an input terminal to receive input of the imaging start instruction signal generated by the release button, (ii) a signal processing unit to output an exposure start instruction signal when the imaging start instruction signal is input to the input terminal, and (iii) an image sensor unit to image external light and generate an image signal when the exposure start instruction signal is input; and</claim-text>
<claim-text>a host control unit to control operation of the camera module; and</claim-text>
<claim-text>a display connectable to the host control unit which controls the display to cause images or a mute screen to be displayed on the display,</claim-text>
<claim-text>in which the signal processing unit outputs the exposure start instruction signal to the image sensor unit as an asynchronous signal without waiting for synchronization with a vertical synchronization signal of the camera-equipped mobile terminal device, in which the vertical synchronization signal has a plurality of normally occurring pulses associated therewith, such that the exposure start instruction signal is outputted to the image sensor unit before a pulse of the vertical synchronization signal which would have normally occurred next after generation due to the release button or receipt by the input terminal of the imaging start instruction signal,</claim-text>
<claim-text>in which the imaging start instruction signal is directly input to the camera module from the release button without passing through the host control unit, and</claim-text>
<claim-text>in which the camera module is separate from and not connectable directly to the display.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The camera-equipped mobile terminal device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, in which a time between the imaging start instruction signal and the output of the exposure start instruction signal is approximately 1 ms (milli-second).</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An imaging method for use with a mobile device, said method comprising the steps of:
<claim-text>transmitting an imaging start instruction signal from a release button pressed by a user to an input terminal of a camera module without passing through a host control unit, such that the imaging start instruction signal is directly input to the camera module from the release button without passing through the host control unit;</claim-text>
<claim-text>detecting the imaging start instruction signal input to the input terminal by a signal processing unit of the camera module;</claim-text>
<claim-text>transmitting an exposure start instruction signal from the signal processing unit to an image sensor; and</claim-text>
<claim-text>imaging external light and generating an image signal by the image sensor where the exposure start instruction signal is input,</claim-text>
<claim-text>wherein the signal processing unit outputs the exposure start instruction signal to the image sensor as an asynchronous signal without waiting for synchronization with a vertical synchronization signal of the camera module, in which the vertical synchronization signal has a plurality of normally occurring pulses associated therewith, such that the exposure start instruction signal is outputted to the image sensor before a pulse of the vertical synchronization signal which would have normally occurred next after generation due to the release button or receipt by the input terminal of the imaging start instruction signal,</claim-text>
<claim-text>in which operation of the camera module is controlled by the host control unit, and</claim-text>
<claim-text>in which the mobile device includes the camera module, the host control unit, and a display in which the display is connected to the host control unit which controls the display to cause images or a mute screen to be displayed on the display such that the camera module is separate from and not connected directly to the display. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
