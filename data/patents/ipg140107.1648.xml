<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622832-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622832</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13693918</doc-number>
<date>20121204</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>63</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>24</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>63</class>
<subclass>B</subclass>
<main-group>69</main-group>
<subgroup>38</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>19</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>463 36</main-classification>
<further-classification>473468</further-classification>
<further-classification>473150</further-classification>
<further-classification>473407</further-classification>
<further-classification>473221</further-classification>
<further-classification>473353</further-classification>
</classification-national>
<invention-title id="d2e43">Trajectory detection and feedback system</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>420788</doc-number>
<kind>A</kind>
<name>Hart</name>
<date>18900200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4160942</doc-number>
<kind>A</kind>
<name>Lynch et al.</name>
<date>19790700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4177994</doc-number>
<kind>A</kind>
<name>Lindquist</name>
<date>19791200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>4337049</doc-number>
<kind>A</kind>
<name>Connelly</name>
<date>19820600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>4545576</doc-number>
<kind>A</kind>
<name>Harris</name>
<date>19851000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473468</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>4565527</doc-number>
<kind>A</kind>
<name>Burchett</name>
<date>19860100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>4893182</doc-number>
<kind>A</kind>
<name>Gautraud et al.</name>
<date>19900100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5039977</doc-number>
<kind>A</kind>
<name>Mele et al.</name>
<date>19910800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5092602</doc-number>
<kind>A</kind>
<name>Witler et al.</name>
<date>19920300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5138322</doc-number>
<kind>A</kind>
<name>Nuttall</name>
<date>19920800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5210603</doc-number>
<kind>A</kind>
<name>Sabin</name>
<date>19930500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5303924</doc-number>
<kind>A</kind>
<name>Kluttz et al.</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5342041</doc-number>
<kind>A</kind>
<name>Agulnek et al.</name>
<date>19940800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5342051</doc-number>
<kind>A</kind>
<name>Rankin et al.</name>
<date>19940800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5365247</doc-number>
<kind>A</kind>
<name>Van der Veen et al.</name>
<date>19941100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>5365427</doc-number>
<kind>A</kind>
<name>Soignet et al.</name>
<date>19941100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>5375832</doc-number>
<kind>A</kind>
<name>Witler et al.</name>
<date>19941200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>5398936</doc-number>
<kind>A</kind>
<name>Kluttz et al.</name>
<date>19950300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>5413345</doc-number>
<kind>A</kind>
<name>Nauck</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>5471383</doc-number>
<kind>A</kind>
<name>Gobush et al.</name>
<date>19951100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>5486001</doc-number>
<kind>A</kind>
<name>Baker</name>
<date>19960100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473266</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>5489099</doc-number>
<kind>A</kind>
<name>Rankin et al.</name>
<date>19960200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>5489886</doc-number>
<kind>A</kind>
<name>Wexler et al.</name>
<date>19960200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>5507485</doc-number>
<kind>A</kind>
<name>Fisher</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473407</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>5542988</doc-number>
<kind>A</kind>
<name>Bogus</name>
<date>19960800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>5697791</doc-number>
<kind>A</kind>
<name>Nashner et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>5768151</doc-number>
<kind>A</kind>
<name>Lowy et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>5798519</doc-number>
<kind>A</kind>
<name>Vock et al.</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>5868578</doc-number>
<kind>A</kind>
<name>Baum</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>5879246</doc-number>
<kind>A</kind>
<name>Gebhardt et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>5938545</doc-number>
<kind>A</kind>
<name>Cooper</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>6073086</doc-number>
<kind>A</kind>
<name>Marinelli</name>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702141</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>6093923</doc-number>
<kind>A</kind>
<name>Vock et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>6095928</doc-number>
<kind>A</kind>
<name>Goszyk</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>6133946</doc-number>
<kind>A</kind>
<name>Cavallaro</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>6142437</doc-number>
<kind>A</kind>
<name>Wilkins, Jr.</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>6179720</doc-number>
<kind>B1</kind>
<name>Rankin et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>6196932</doc-number>
<kind>B1</kind>
<name>Marsh et al.</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473223</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>6285445</doc-number>
<kind>B1</kind>
<name>Winfield et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>6289167</doc-number>
<kind>B1</kind>
<name>Boetje et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>6304665</doc-number>
<kind>B1</kind>
<name>Cavallaro et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>6320173</doc-number>
<kind>B1</kind>
<name>Vock et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>6389368</doc-number>
<kind>B1</kind>
<name>Hampton</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>6396041</doc-number>
<kind>B1</kind>
<name>Vock et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>6398670</doc-number>
<kind>B1</kind>
<name>Engelhardt et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473407</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>6430997</doc-number>
<kind>B1</kind>
<name>French et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>6488591</doc-number>
<kind>B1</kind>
<name>Gobush et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>6500073</doc-number>
<kind>B1</kind>
<name>Gobush et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>6514081</doc-number>
<kind>B1</kind>
<name>Mengoli</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>6520864</doc-number>
<kind>B1</kind>
<name>Wilk</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>6539336</doc-number>
<kind>B1</kind>
<name>Vock et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702182</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>6567116</doc-number>
<kind>B1</kind>
<name>Aman et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>6569336</doc-number>
<kind>B1</kind>
<name>Mouchet et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>6669571</doc-number>
<kind>B1</kind>
<name>Cameron et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>6707487</doc-number>
<kind>B1</kind>
<name>Aman et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>6774345</doc-number>
<kind>B1</kind>
<name>Kenk</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>6774349</doc-number>
<kind>B2</kind>
<name>Vock et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00058">
<document-id>
<country>US</country>
<doc-number>6778866</doc-number>
<kind>B1</kind>
<name>Bettwy</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00059">
<document-id>
<country>US</country>
<doc-number>6781621</doc-number>
<kind>B1</kind>
<name>Gobush et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00060">
<document-id>
<country>US</country>
<doc-number>6816185</doc-number>
<kind>B2</kind>
<name>Harmath</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00061">
<document-id>
<country>US</country>
<doc-number>6839771</doc-number>
<kind>B1</kind>
<name>Bouchier et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00062">
<document-id>
<country>US</country>
<doc-number>7094164</doc-number>
<kind>B2</kind>
<name>Marty et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00063">
<document-id>
<country>US</country>
<doc-number>7101287</doc-number>
<kind>B1</kind>
<name>Wagner</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473207</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00064">
<document-id>
<country>US</country>
<doc-number>7214138</doc-number>
<kind>B1</kind>
<name>Stivers et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00065">
<document-id>
<country>US</country>
<doc-number>7264554</doc-number>
<kind>B2</kind>
<name>Bentley</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00066">
<document-id>
<country>US</country>
<doc-number>7658676</doc-number>
<kind>B2</kind>
<name>Ohta</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00067">
<document-id>
<country>US</country>
<doc-number>7850552</doc-number>
<kind>B2</kind>
<name>Marty et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00068">
<document-id>
<country>US</country>
<doc-number>7854669</doc-number>
<kind>B2</kind>
<name>Marty et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00069">
<document-id>
<country>US</country>
<doc-number>7899307</doc-number>
<kind>B1</kind>
<name>Hughes</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00070">
<document-id>
<country>US</country>
<doc-number>8016688</doc-number>
<kind>B2</kind>
<name>Gobush</name>
<date>20110900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00071">
<document-id>
<country>US</country>
<doc-number>8083617</doc-number>
<kind>B2</kind>
<name>Greenquist et al.</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00072">
<document-id>
<country>US</country>
<doc-number>2001/0023209</doc-number>
<kind>A1</kind>
<name>Yamamoto</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00073">
<document-id>
<country>US</country>
<doc-number>2002/0098898</doc-number>
<kind>A1</kind>
<name>Manwaring</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00074">
<document-id>
<country>US</country>
<doc-number>2002/0119841</doc-number>
<kind>A1</kind>
<name>Foley</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00075">
<document-id>
<country>US</country>
<doc-number>2002/0155896</doc-number>
<kind>A1</kind>
<name>Gobush et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00076">
<document-id>
<country>US</country>
<doc-number>2002/0173367</doc-number>
<kind>A1</kind>
<name>Gobush et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00077">
<document-id>
<country>US</country>
<doc-number>2003/0054905</doc-number>
<kind>A1</kind>
<name>King, Jr.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473467</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00078">
<document-id>
<country>US</country>
<doc-number>2003/0073518</doc-number>
<kind>A1</kind>
<name>Marty et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00079">
<document-id>
<country>US</country>
<doc-number>2003/0109322</doc-number>
<kind>A1</kind>
<name>Funk et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00080">
<document-id>
<country>US</country>
<doc-number>2003/0207718</doc-number>
<kind>A1</kind>
<name>Perlmutter</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473221</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00081">
<document-id>
<country>US</country>
<doc-number>2004/0155962</doc-number>
<kind>A1</kind>
<name>Marks</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00082">
<document-id>
<country>US</country>
<doc-number>2005/0012023</doc-number>
<kind>A1</kind>
<name>Vock et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00083">
<document-id>
<country>US</country>
<doc-number>2005/0215338</doc-number>
<kind>A1</kind>
<name>Miyamoto</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00084">
<document-id>
<country>US</country>
<doc-number>2005/0223799</doc-number>
<kind>A1</kind>
<name>Murphy</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00085">
<document-id>
<country>US</country>
<doc-number>2005/0233815</doc-number>
<kind>A1</kind>
<name>McCreary et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473131</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00086">
<document-id>
<country>US</country>
<doc-number>2006/0100016</doc-number>
<kind>A1</kind>
<name>Hamano et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 36</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00087">
<document-id>
<country>US</country>
<doc-number>2006/0105857</doc-number>
<kind>A1</kind>
<name>Stark</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473353</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00088">
<document-id>
<country>US</country>
<doc-number>2006/0135297</doc-number>
<kind>A1</kind>
<name>Cruciani</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473570</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00089">
<document-id>
<country>US</country>
<doc-number>2006/0189386</doc-number>
<kind>A1</kind>
<name>Rosenberg</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>463 37</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00090">
<document-id>
<country>US</country>
<doc-number>2007/0026974</doc-number>
<kind>A1</kind>
<name>Marty et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00091">
<document-id>
<country>US</country>
<doc-number>2007/0026975</doc-number>
<kind>A1</kind>
<name>Marty et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00092">
<document-id>
<country>US</country>
<doc-number>2007/0129180</doc-number>
<kind>A1</kind>
<name>Levy</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00093">
<document-id>
<country>US</country>
<doc-number>2007/0167247</doc-number>
<kind>A1</kind>
<name>Lindsay</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00094">
<document-id>
<country>US</country>
<doc-number>2007/0167266</doc-number>
<kind>A1</kind>
<name>DeVall</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473505</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00095">
<document-id>
<country>US</country>
<doc-number>2007/0275787</doc-number>
<kind>A1</kind>
<name>Bouchard et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473125</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00096">
<document-id>
<country>US</country>
<doc-number>2008/0015061</doc-number>
<kind>A1</kind>
<name>Klein</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>473447</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00097">
<document-id>
<country>US</country>
<doc-number>2008/0268943</doc-number>
<kind>A1</kind>
<name>Jacob</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00098">
<document-id>
<country>US</country>
<doc-number>2010/0267443</doc-number>
<kind>A1</kind>
<name>Shimamura et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00099">
<document-id>
<country>US</country>
<doc-number>2012/0142416</doc-number>
<kind>A1</kind>
<name>Joutras</name>
<date>20120600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00100">
<document-id>
<country>US</country>
<doc-number>2012/0172126</doc-number>
<kind>A1</kind>
<name>Padovani et al.</name>
<date>20120700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00101">
<document-id>
<country>US</country>
<doc-number>2012/0214594</doc-number>
<kind>A1</kind>
<name>Kirovski et al.</name>
<date>20120800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00102">
<document-id>
<country>US</country>
<doc-number>2012/0225719</doc-number>
<kind>A1</kind>
<name>Nowozin et al.</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00103">
<document-id>
<country>US</country>
<doc-number>2012/0258804</doc-number>
<kind>A1</kind>
<name>Ahmed</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00104">
<document-id>
<country>US</country>
<doc-number>2013/0130845</doc-number>
<kind>A1</kind>
<name>Marty et al.</name>
<date>20130500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00105">
<document-id>
<country>US</country>
<doc-number>2013/0172058</doc-number>
<kind>A1</kind>
<name>Marty et al.</name>
<date>20130700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00106">
<document-id>
<country>EP</country>
<doc-number>0 704 715</doc-number>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00107">
<document-id>
<country>FR</country>
<doc-number>2 710 434</doc-number>
<date>19930900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00108">
<document-id>
<country>WO</country>
<doc-number>WO 98/24242</doc-number>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00109">
<document-id>
<country>WO</country>
<doc-number>WO 01/54781</doc-number>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00110">
<document-id>
<country>WO</country>
<doc-number>WO 01/38898</doc-number>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00111">
<othercit>Office Action dated Aug. 4, 2010 in U.S. Appl. No. 11/508,004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00112">
<othercit>Office Action dated Jun. 10, 2010 in U.S. Appl. No. 11/507,886.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00113">
<othercit>Silverberg et al., &#x201c;Numerical Analysis of the Basketball Shot,&#x201d; Journal of Dynamic Systems, Measurement and Control, Dec. 2003, vol. 125, pp. 531-540.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00114">
<othercit>Tran, &#x201c;Optimal release conditions for the free throw in men's basketball,&#x201d; Journal of Sports Sciences, Sep. 2008; 26(11): 1147-1155.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00115">
<othercit>Okubo et al., &#x201c;Dynamics of basketball-rim interactions,&#x201d; Sports Engineering, (2004) 7, pp. 15-29.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00116">
<othercit>Okubo et al., &#x201c;Effects of basketball free throw release conditions using a dynamic model,&#x201d; The Engineering of Sport 5, vol. 1, 372-378, Central Plain Book Mfg., 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00117">
<othercit>Okubo et al., &#x201c;Dynamics of basketball-rim interactions,&#x201d; The Engineering of Sport: 4, Blackwell Science, Oxford, 2002, pp. 660-666.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00118">
<othercit>Okubo et al., &#x201c;Strategies for Bank Shots and Direct Shots in Basketball,&#x201d; The Engineering of Sport: 6, vol. 3, Springer, New York, 2006, pp. 233-248.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00119">
<othercit>Okubo et al., &#x201c;Dynamics of the basketball shot with application to the free throw,&#x201d; Journal of Sports Sciences, Dec. 2006; 24(12): 1303-1314.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00120">
<othercit>Notice of Allowance and Allowed claims mailed Apr. 5, 2006 from U.S. Appl. No. 10/242,373, 21 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00121">
<othercit>Hawk-Eye-Wikipedia, the free encyclopedia http://en.wikipedia.org/wiki/Hawk-Eye, printed Jan. 10, 2008, pp. 1-4.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00122">
<othercit>U.S. Office Action dated Oct. 3, 2011 from U.S. Appl. No. 11/972,553.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00123">
<othercit>U.S. Office Action dated Jan. 11, 2012 from U.S. Appl. No. 12/127,744.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00124">
<othercit>U.S. Office Action dated Jan. 26, 2012 from U.S. Appl. No. 12/015,445.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00125">
<othercit>U.S. Final Office Action dated Mar. 21, 2012 from U.S. Appl. No. 12/127,744.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00126">
<othercit>U.S. Appl. No. 12/015,445, Non Final Office Action mailed Jan. 26, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00127">
<othercit>U.S. Appl. No. 11/972,553, Final Office Action mailed Dec. 13, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>26</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>13</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12015445</doc-number>
<date>20080116</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8409024</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13693918</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11508004</doc-number>
<date>20060821</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7854669</doc-number>
<date>20101221</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12015445</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10242373</doc-number>
<date>20020911</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7094164</doc-number>
<date>20060822</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11508004</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60880773</doc-number>
<date>20070116</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60323029</doc-number>
<date>20010912</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60348057</doc-number>
<date>20020111</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60395875</doc-number>
<date>20020712</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130095961</doc-number>
<kind>A1</kind>
<date>20130418</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Pillar Vision, Inc.</orgname>
<address>
<city>Menlo Park</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Marty</last-name>
<first-name>Alan W.</first-name>
<address>
<city>Menlo Park</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Edwards</last-name>
<first-name>Thomas A.</first-name>
<address>
<city>Menlo Park</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>McGhee</last-name>
<first-name>Ridge</first-name>
<address>
<city>Redwood City</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Kwan &#x26; Olynick LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Pillar Vision, Inc.</orgname>
<role>02</role>
<address>
<city>Menlo Park</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>D'Agostino</last-name>
<first-name>Paul A</first-name>
<department>3716</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A disclosed device provides a trajectory detection and feedback system. The system is capable of detecting one or more moving objects in free flight, analyzing a trajectory of each object and providing immediate feedback information to a human that has launched the object into flight, and/or one or more observers in the area. In a particular embodiment, a non-intrusive machine vision system that remotely detects trajectories of moving objects may be used to evaluate trajectory parameters for a basketball shot at a basketball hoop by a player. The feedback information, such as a trajectory entry angle into the basketball hoop and/or an entry velocity into the hoop for the shot, may be output to the player in an auditory format using a sound projection device. The system may be operable to be set-up and to operate in a substantially autonomous manner.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="180.42mm" wi="252.39mm" file="US08622832-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="252.73mm" wi="184.91mm" orientation="landscape" file="US08622832-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="256.71mm" wi="189.57mm" orientation="landscape" file="US08622832-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="251.88mm" wi="191.18mm" orientation="landscape" file="US08622832-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="254.17mm" wi="170.69mm" orientation="landscape" file="US08622832-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="266.78mm" wi="166.88mm" file="US08622832-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="254.00mm" wi="182.12mm" file="US08622832-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="229.11mm" wi="174.67mm" file="US08622832-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="249.09mm" wi="178.48mm" orientation="landscape" file="US08622832-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="253.58mm" wi="129.37mm" file="US08622832-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="251.29mm" wi="181.19mm" orientation="landscape" file="US08622832-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims priority under 35 U.S.C. &#xa7;120 and is a Continuation of co-pending U.S. patent application Ser. No. 12/015,445, filed Jan. 16, 2008, which claims priority under 35 U.S.C. &#xa7;119(e) to U.S. Provisional Patent Application No. 60/880,773, filed on Jan. 16, 2007. U.S. patent application Ser. No. 12/015,445 further claims priority under 35 U.S.C. &#xa7;120 and is a Continuation-in-Part application of U.S. patent application Ser. No. 11/508,004, filed Aug. 21, 2006, now U.S. Pat. No. 7,854,669, which is a Continuation-in-Part and claims priority under 35 U.S.C. &#xa7;120 to U.S. patent application Ser. No. 10/242,373, filed Sep. 11, 2002, now U.S. Pat. No. 7,094,164. U.S. patent application Ser. No. 10/242,373 claims priority under 35 U.S.C. &#xa7;119(e) from the following three U.S. Provisional Patent Applications: 60/323,029, filed Sep. 12, 2001; 60/348,057, filed Jan. 11, 2002; and 60/395,875 filed Jul. 12, 2002. Each of the above provisional and non-provisional applications are incorporated herein by reference in their entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">The invention relates to apparatus and methods for sports training. In particular, a trajectory detection, analysis and feedback system is provided for analyzing the trajectory of an object launched by a human and providing feedback information regarding the trajectory to the human.</p>
<p id="p-0004" num="0003">There are many different games of skill played by human for recreational and competitive purposes. In many of these games of skill, such as basketball, soccer, golf, football, baseball, softball, tennis, volleyball, racket ball, water-polo, lacrosse, bowling, shot-put, bowling and javelin, an object is thrown, kicked or struck to launch the object along a trajectory. Often a player's success at the game is contingent upon their skill and consistency at controlling the trajectory of the object used in the game. For instance, a basketball player's success is contingent upon the ability to consistently shoot a basketball into a hoop under a variety of conditions. Thus, a basketball is launched along trajectory by the player with the objective of the trajectory terminating within an area defined by the hoop.</p>
<p id="p-0005" num="0004">Whether the game is played recreationally or professionally, players generally desire to improve their skills to increase their success at the game. There are many approaches that the player may take to improve their performance. These approaches include reading books, watching videotapes, receiving lessons/coaching, practicing and utilizing training devices.</p>
<p id="p-0006" num="0005">Many different types of training devices have been developed for different types of sports that are geared toward improving a player's skill. One drawback of these devices is that typically they are applied in a manner that departs from the actual play of the sport. The departure from normal playing conditions can limit the effectiveness of the device. For instance, training devices can be used that are attached to a player to help them develop a prescribed trajectory control skill. However, these training devices are not used in the actual play of the game and can be a distraction to the player employing the device. Thus, the player may find any training benefits from using the device are outweighed by the intrusiveness of the device.</p>
<p id="p-0007" num="0006">As another example, the training devices can require that objects or equipment not normally used in the play of the game be used, such as special club that is used to improve a player's golf swing or a tee for holding a baseball that is used to improve a baseball swing. Thus, the player may get proficient at using the special equipment and yet not perform well when they are required to use actual equipment in actual playing conditions. As another example, training devices have been developed that must be used in an environment, such as a special room, that is significantly different from the environment where the game is played. Training under these simulated conditions may not translate to performance improvement in actual playing conditions. Further, the devices used in a special environment, are usually difficult to set-up and require another person, besides the player, to operate the device.</p>
<p id="p-0008" num="0007">Another drawback of current training devices is that the player is not provided any feedback that they can use to evaluate their performance or the feedback can be quite detached from the training experience. When a player receives a lesson or coaching, another person watches their performance and can provide immediate feedback that is valuable to the player. With current training devices, the player uses the device and then later can attempt to judge their performance based upon whether they perceive an improvement in their actual play of the game. However, when the player is using the device improperly or training in a less than optimal manner, the devices do not provide any objective feedback that the player can use to evaluate their performance.</p>
<p id="p-0009" num="0008">In view of the above, it is desirable to provide training devices and methods that allow the player to improve their trajectory skills for games requiring such skills where the training devices are 1) non-intrusive, 2) operable in an environment that approximates actual playing conditions, 3) simple to set-up and to operate and 4) provide immediate and objective feedback to the user of the device.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">This invention addresses the needs indicated above by providing a trajectory detection and feedback system. The system is capable of detecting one or more moving objects in free flight, analyzing a trajectory of each object and providing immediate feedback information to a human that has launched the object into flight. The feedback information may include one or more trajectory parameters that the human may use to evaluate their skill at sending the object along a desired trajectory. In a particular embodiment, a non-intrusive machine vision system that detects trajectories of moving objects may be used to evaluate trajectory parameters for a basketball shot at a basketball hoop by a player. The feedback information, such as a trajectory entry angle into the basketball hoop and/or an entry velocity into the hoop for the shot, may be output to the player in an auditory format using a sound projection device. The system may be operable to be set-up and to operate in a substantially autonomous manner. After the system has evaluated a plurality of shots by the player, the system may provide 1) a diagnosis of their shot consistency, 2) a prediction for improvement based upon improving their shot consistency and 3) a prescription of actions for improving their performance.</p>
<p id="p-0011" num="0010">One aspect of the present invention is a device for providing trajectory detection and feedback. The device may be generally characterized as comprising: 1) one or more sensors for detecting physical information used to characterize a trajectory of an object launched along its trajectory by a human; 2) a logic device designed or configured to i) generate trajectory parameters that characterize one or more states of the object along it's trajectory from the physical information and ii) generate feedback information using the trajectory parameters; and 3) one or more feedback output mechanisms for providing the feedback information to the human. The device may be designed to detect information in a non-intrusive manner such that the one or more sensors is not located on the object, on the human or on a device attached to the human or the sensors are not noticed by the human. For ease of use, the device may be capable to be set-up and/or to operate in an autonomous manner. The feedback information may be used by the human to improve their skill at launching the object along a desired trajectory.</p>
<p id="p-0012" num="0011">In particular embodiments, the physical information may be provided via one of an energy signal reflected from the object or an energy signal emitted from a signal source located on the object. The device may include a signal source for emitting energy signals that are detected by the one or more sensors. The energy signals may be electromagnetic energy signals or an acoustic energy signals. For a sensor system including the one or more sensor that is set-up in a particular location, an object that is launched into its trajectory by the human at one of a plurality of locations on a playing surface may be detected and may be analyzed by the system. In one embodiment, the sensor system may be able to detect trajectories for a basketball shot from a number different locations on a basketball court.</p>
<p id="p-0013" num="0012">The one or more sensors may be a camera or charge coupling device. The camera and/or charge coupling device may be part of a machine vision system. Thus, the physical information may be video frame data recorded by a video camera. The camera may also be used to record physical information about the human. The physical information about the human may be analyzed by the system to provide additional feedback information.</p>
<p id="p-0014" num="0013">Prior to its launch, the object may be grasped by the human and forces used to launch the object along its trajectory may be applied via one or both hands. Also, to launch the object along its trajectory, the object may be hit with a hand-held device grasped by the human. The object may be launched by the human as part of game of skill where the objective of the game of skill is to launch the object along a trajectory that terminates within a selected area. In one embodiment, the game of skill is basketball and the selected area is a basketball hoop. A playing area where the trajectory is generated may be the playing area where the game of skill is normally played, such as a basketball court. The one or more sensors may be remote sensors located outside of the playing area or may be non-intrusive sensors located within the playing area that do not affect the play of the game of skill in the playing area.</p>
<p id="p-0015" num="0014">In other embodiments, the logic device may be further designed or configured to generate a curve fit from the physical information that approximates the object's trajectory and the trajectory parameters. In particular, the curve fit may be a parabolic arc. The curve-fit may be used to generate trajectory parameters corresponding to different states along the object's trajectory such as an initial state of the trajectory, a final state of the trajectory or any of the states of the trajectory between the initial state and the final state. However, in some embodiments, the trajectory parameters may be generated without the use of a curve-fit. Some examples of the trajectory parameters may include but are not limited to a speed, a directional velocity component, a position, a rotation rate, one or more axis's of rotation, one or more directional angles and a directional acceleration component.</p>
<p id="p-0016" num="0015">After the trajectory of the object has been detected and characterized, feedback information may be generated and may be provided to the human. The feedback information may be used for performance evaluation or by the human to improve their skill at launching the object along a trajectory that terminates within a selected area. The feedback information may be one of 1) one of the trajectory parameters, 2) a plurality of the trajectory parameter and 3) a feedback parameter generated from a combination of trajectory parameters. The feedback information may be provided to the human in at least one of a visual format, an auditory format, a kinetic format and combinations thereof. In some instances, the feedback information may be provided in an alpha-numeric format which is transmitted to the player via a visual display or through a sound projection device. In various embodiments, the feedback information may be qualitative or quantitative in nature.</p>
<p id="p-0017" num="0016">The feedback information may be provided to the human prior to the object reaching the end of its trajectory. For example, the object may be a basketball and the feedback information may be one of an entry angle that the basketball enters a basketball hoop and a speed that the basketball enters the basketball hoop. This feedback information may be provided to the player before the basketball reaches the basketball hoop or within a short period of time after the basketball passes through the hoop.</p>
<p id="p-0018" num="0017">In particular embodiments, the device may be capable of generating trajectory parameters and providing feedback information for each of a plurality of different trajectories in a trajectory session. The device may further comprise a memory storage device for storing trajectory session information wherein the trajectory session information comprises one or more of 1) physical information, trajectory information and feedback information generated for the plurality of trajectories, 2) a trajectory session time, 3) a trajectory session date, 4) a trajectory session location and combinations thereof. The device may also comprise a database for relating the trajectory session information to human identification information.</p>
<p id="p-0019" num="0018">In a trajectory session, the plurality of trajectories that are detected and analyzed may be generated by a plurality of different players. During the trajectory session, two or more objects may be in flight at a same time. The device may be capable of detecting, analyzing and providing feedback information for the trajectories of two or more objects in flight at the same time. The two or more trajectories that are in flight at the same time may be generated by the same player or may be generated by two or more different players.</p>
<p id="p-0020" num="0019">In a particular embodiment, the device may include session analysis software for one or more of 1) providing a list or a plot of trajectory session information comprising one or more of physical information, trajectory parameters and feedback information for the plurality of trajectories, 2) comparing the trajectory session information from the trajectory session with trajectory session information from one or more different trajectory sessions, 3) generating trajectory session parameters used to characterize a human's performance in the trajectory session, 4) predicting performance improvement as a function of the trajectory session parameters and 5) prescribing actions for improving performance.</p>
<p id="p-0021" num="0020">Another aspect of the present invention provides a device for analyzing a trajectory of a basketball, the device comprising: 1) one or more cameras for recording video frame data used to characterize a trajectory of a basketball shot by a human; 2) a logic device designed or configured to i) to receive the video frame data, ii) generate trajectory parameters that characterize one or more states of the basketball along it's trajectory and iii) generate feedback information using the trajectory parameters; and 3) one or more feedback output mechanisms for providing the feedback information to the human. The feedback information may be used by the human to improve their skill at shooting the basketball. A playing area where the basketball is shot may be one where a basketball game is normally played, such as a gymnasium, arena or outdoor basketball court. For ease of use, the device may be capable of autonomous set-up or autonomous operation.</p>
<p id="p-0022" num="0021">In a particular embodiment, the one or more cameras, the logic device and the one or more feedback output mechanisms may be enclosed in a housing. The housing may be water-proofed for outdoor use. One or more wheels may be attached to the housing to allow it to be easily moved and positioned. At least one input mechanism, such as touch screen display, may be mounted to the housing for configuring and operating the device. The touch screen display may be used to view one or more of configuration information, operational information and session information. The feedback output mechanism may be a sound projection device that can be enclosed within the housing.</p>
<p id="p-0023" num="0022">The device may include an internal power supply for supplying power to the device, such as a re-chargeable battery or a fuel cell. The power supply may be enclosed in the housing. For outdoor models, photocells may be used for supplying power to the device and charging the battery. The device may also include a power interface for connecting the device to an external power source. The external power source may be used to directly power the device or to charge a battery within the device.</p>
<p id="p-0024" num="0023">In other embodiments, a video capture card for digitizing video frame data recorded by the one or more cameras. Using the video frame data, the logic device may be designed to generate a curve-fit of the trajectory of the basketball. Further, the video frame data may include physical information about the human, which may also be processed and analyzed by the logic device. The logic device may be a general purpose computer comprising: a processor, a data storage device, RAM, operating system software, device interfaces, device drivers and trajectory analysis software. A mass storage device may be used for storing the recorded video frame data. Further, video editing software may be used for editing the recorded video frame data stored on the mass storage device.</p>
<p id="p-0025" num="0024">The trajectory analysis device may include a number of communication interfaces for communicating with components of the system and peripheral devices connected to the system. As an example, the system may include a wireless network interface or a wire network interface for connecting the logic device to one of a local area network, a wide area network and the Internet. When connected one of these networks, the system may communicate with various devices also connected to the network. A wireless interface may be used for providing communications between the one or more cameras and the logic device or for providing communications between the logic device and one or more peripheral devices. Examples of peripheral devices that may communicate with the logic device include hand-held computing devices, displays, wearable sound projection devices, kinetic feedback devices and printers.</p>
<p id="p-0026" num="0025">In a particular embodiment, two or more cameras may be used for recording video frame data. The two or more cameras may be mounted to a basketball hoop backboard Infrared light emitters may also be mounted to the backboard. The emitters may be used to illuminate the basketball in infrared light as it approaches the backboard. Thus, the two or more cameras may be capable of detecting infrared light reflected from the basketball.</p>
<p id="p-0027" num="0026">The components of the system may be enclosed in two or more housings and communication interfaces may be used for communications between the components. For instance, a housing may enclose the cameras, light emitters and a communication interface while the logic device and feedback output mechanism may be located in a separate housing. Thus, the communication interface may be used for transmitting one of a) video frame data, b) trajectory parameters, c) feedback information and combinations thereof to the logic device. The housing with the two or more cameras and infrared emitters may be mounted to a backboard. The backboard may be used outside. Therefore, the housing may be water-proofed for outdoor use.</p>
<p id="p-0028" num="0027">The feedback information supplied users of the device may be 1) one of the trajectory parameters, 2) a plurality of the trajectory parameters or 3) a feedback parameter generated from a combination of trajectory parameters. The trajectory parameters may characterize different states of the trajectory such as an initial state of the trajectory, a final state of the trajectory or states of the trajectory between the initial state and the final state. The trajectory parameters used in the feedback information may be selected based upon their benefit to the human in improving their shooting skills. A few examples of trajectory parameters that may be generated for different states along the trajectory include a release height, a release angle, a release velocity, an entry angle into a basketball hoop, an entry velocity into the basketball hoop, an entry position of a center of the basketball relative to a center of the basketball hoop, a transverse velocity of the basketball relative to a normal line drawn through the center of the basketball hoop, a missed shot, a made shot, a rotation rate of the basketball and axis of rotation of the basketball.</p>
<p id="p-0029" num="0028">The feedback information may be provided to the human in at least one of a visual format, an auditory format, a kinetic format and combinations thereof. For instance, the feedback information may be a trajectory parameter, such as release velocity, that is presented in a numeric format. The numeric format may be viewed by the human on a video display or heard by the human from an audio device. In a particular embodiment, the feedback information may be used as input parameters for a video game.</p>
<p id="p-0030" num="0029">The device may be capable of generating trajectory parameters and providing feedback information for each of a plurality of different trajectories in a trajectory session. The plurality of different trajectories may be shot from a plurality of different locations on a basketball court or approximately the same location, such as a free-throw line. The device may include or may be in communication with a memory storage device that is used for storing trajectory session information. The trajectory session information may comprise one or more of 1) digitized video frame data, trajectory information and feedback information generated for the plurality of trajectories, 2) a trajectory session time, 3) a trajectory session date, 4) a trajectory session location and combinations thereof. The device may include a database for relating the trajectory session information to human identification information.</p>
<p id="p-0031" num="0030">In a trajectory session, the plurality of basketball trajectories that are detected and analyzed may be generated by a plurality of different players. During the trajectory session, two or more basketballs may be in flight at a same time. The device may be capable of detecting, analyzing and providing feedback information for the trajectories of two or more basketballs in flight at the same time. The two or more shots that are in flight at the same time may be generated by the same player or may be generated by two or more different players.</p>
<p id="p-0032" num="0031">The device may also include session analysis software. The session analysis software may perform one or more of 1) providing a list or a plot of trajectory session information comprising one or more of physical information, trajectory parameters and feedback information for the plurality of trajectories, 2) comparing the trajectory session information from the trajectory session with trajectory session information from one or more different trajectory sessions, 3) generating trajectory session parameters used to characterize a human's performance in the trajectory session, 4) predicting performance improvement as a function of the trajectory session parameters and 5) prescribing actions for improving performance.</p>
<p id="p-0033" num="0032">Another aspect of the present invention provides a method of providing trajectory detection and analysis for a trajectory of an object launched along its trajectory by a human. The method may be generally characterized as comprising: 1) receiving physical information about the object along its trajectory from one or more sensors; 2) generating trajectory parameters from the physical information; 3) generating feedback information; and 4) providing the feedback information to the human. The feedback information may be provided to the human prior to end of the trajectory of the object or within a short time after the end of the trajectory of the object. The feedback information may be provided in one of a visual format, an auditory format and a kinetic format.</p>
<p id="p-0034" num="0033">The object may be launched by the human as part of game of skill, such as basketball, where the objective of the game is to launch the object along a trajectory that terminates within a selected area. For instance, shooting a basketball into a basketball hoop. A playing area where the trajectory is generated may be the playing area where the game of skill is normally played, such as a basketball court. The one or more sensors may be remote sensors that are located outside of the playing area or the one or more sensors may be non-intrusive sensors located with the playing area that do not affect the play of the game of skill in the playing area.</p>
<p id="p-0035" num="0034">In particular embodiment, the method may comprise one or more of the following: a) recording video frame data wherein the one or more sensors is a camera; determining a position of the object in a plurality of the video frames from the video frame data generating a curve-fit of the trajectory of the object from the determined positions; and generating one or more trajectory parameters from the curve-fit, b) prior to generating the curve fit, digitizing the video frame data, c) prior to determining the position of the object, editing out portions of the video frame data, d) receiving physical information from the one or more sensors from two or more objects in flight at the same time; generating trajectory parameters for the two or more objects; and providing separate feedback information for each of the objects and e) generating a list or plot of trajectory parameters for a plurality of trajectories.</p>
<p id="p-0036" num="0035">In another embodiment, the method may also comprise generating one or more aggregate trajectory parameters from the trajectory parameters from a plurality of different trajectories where the aggregate trajectory parameters characterize the human's consistency. The aggregate trajectory parameters may be a measure of statistical variability of different trajectory parameters. Thus, the method may also comprise predicting performance improvement as a function of the one or more aggregate trajectory parameters and generating a prescription comprising one or more actions for improving performance.</p>
<p id="p-0037" num="0036">Another aspect of the invention pertains to computer program products including a machine-readable medium on which is stored program instructions for implementing any of the methods described above. Any of the methods of this invention may be represented as program instructions and/or data structures, databases, etc. that can be provided on such computer readable media. Yet another embodiment of the present invention is a system for delivering computer readable instructions, such as transmission, over a signal transmission medium, of signals representative of instructions for remotely administering any of the methods as described above.</p>
<p id="p-0038" num="0037">These and other features of the present invention will be presented in more detail in the following detailed description of the invention and the associated figures.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of a trajectory capture and feedback scenario employing a trajectory detection and feedback system of the present invention.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 2</figref>. is a diagram of captured video frame data used to generate a curve-fit for a trajectory of an object.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram of a second trajectory capture and feedback scenario employing a trajectory detection and analysis device of the present invention.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of a trajectory detection and analysis system of the present invention.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. 5A-5C</figref> are perspective drawings of a trajectory detection and analysis system of the present invention.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 6</figref> is an information flow diagram for of a trajectory detection and analysis system of the present invention.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 7</figref> is a shot scatter plot that may be provided by a trajectory detection and analysis system.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 8</figref> is an improvement map that may be provided by a trajectory detection and analysis system.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. 9A and 9B</figref> are flow charts of methods for providing trajectory detection and feedback using a trajectory detection and analysis system.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 10</figref> is a perspective drawing of two embodiments of basketball training systems.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0049" num="0048">The present invention provides methods and apparatus for trajectory detection and analysis for trajectories of objects launched by a human in games of skill. One objective of the methods and apparatus is to generate feedback information that may be used by a participant in the game of skill to improve their performance at the game. In a particular embodiment of the invention, a trajectory device is used to detect and analyze a trajectory of a basketball shot by a human and provide feedback information about the trajectory to the shooter. However, the present invention is not limited to basketball and may be applied to other games of skill that involve object being launched along a trajectory, such as soccer, golf, football, baseball, softball, tennis, volleyball, racquet ball, bowling, water-polo, lacrosse, shot-put and javelin.</p>
<p id="p-0050" num="0049">In <figref idref="DRAWINGS">FIG. 1</figref>, a trajectory detection, analysis and feedback system using a machine vision system with a single camera to detect basketball trajectories is described. In <figref idref="DRAWINGS">FIG. 2</figref>, details of determining trajectory parameters from video frame data captured by the machine vision system is described. In <figref idref="DRAWINGS">FIG. 3</figref>, another embodiment of a trajectory detection, analysis and feedback system using a plurality of cameras and infrared emitters to illuminate a tracked object is described. In <figref idref="DRAWINGS">FIG. 4</figref>, a block diagram with internal components of the trajectory detection, analysis and feedback system is discussed. In <figref idref="DRAWINGS">FIGS. 5A-5C</figref>, perspective diagrams of a trajectory device of the present invention are described. In <figref idref="DRAWINGS">FIG. 6</figref>, details regarding an information flow and processing of data in the trajectory system are provided. In <figref idref="DRAWINGS">FIGS. 7 and 8</figref>, two output formats for basketball trajectory data generated from the trajectory system is described. In <figref idref="DRAWINGS">FIGS. 9A-9B</figref>, methods of gathering trajectory data, providing session data and predictions of improvement to a user of the system are described.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of a trajectory capture and feedback scenario employing a trajectory detection and feedback system of the present invention. In the embodiment shown in the figure, a trajectory detection, analysis and feedback system <b>100</b> uses a machine vision system with a single camera <b>118</b> to detect and to analyze a trajectory <b>102</b> of a basketball <b>109</b> shot towards the basketball hoop <b>103</b> by the shooter <b>112</b>. The camera <b>118</b> may record visible light. A block diagram of the system <b>100</b> is described with respect to <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0052" num="0051">The basketball hoop <b>103</b> may be mounted to a backboard <b>151</b> with a support system to hold it up, such as a pole anchored into the ground, a support anchored into a wall or supports suspended from a ceiling. The basketball hoop <b>103</b> may be of a standard height and the basketball may be a standard men's size basketball. However, trajectories for a basketball of a different size, such as a women's ball, shot at basketball hoop of varying heights may also be detected and analyzed with the present invention.</p>
<p id="p-0053" num="0052">The camera <b>118</b> in the machine vision system records physical information within a detection volume <b>110</b>. The physical information that is recorded is images of objects at a particular time in the detection volume <b>110</b>. The images recorded at a particular time may be stored as a video frame <b>106</b>. The camera <b>118</b> may capture images of the basketball <b>109</b> as it moves in trajectory plane <b>104</b> as well as images of other secondary objects. The secondary objects may be closer to the camera than the basketball <b>109</b> (i.e., between the camera <b>118</b> and the trajectory plane <b>104</b>) or the secondary objects may be farther away from the camera than the basketball <b>109</b> (i.e., beyond the trajectory plane <b>104</b>). The machine vision system may utilize software to distinguish between the movement of secondary objects that may be detected and the movement of the basketball <b>109</b>.</p>
<p id="p-0054" num="0053">The trajectory detection system <b>100</b> may be set-up in a playing area where basketball is normally played, such as a basketball court with playing surface <b>119</b> located in gymnasium or arena. The system <b>100</b> may be positioned on the side of court and remotely detect the trajectories of the shots by shooter <b>112</b> using the machine vision system. Thus, the shooter <b>112</b> and defender <b>114</b> may engage in any of their normal activities on the playing surface <b>119</b> without any interference from the detection system <b>100</b>. In the figure, the shooter <b>112</b> is guarded by a defender <b>114</b>. However, the system <b>100</b> may also be used when the shooter <b>112</b> is unguarded.</p>
<p id="p-0055" num="0054">With a machine vision system that uses a single camera <b>118</b>, the locations where the trajectory <b>102</b> may be accurately analyzed may be limited. In one embodiment, with the set-up of the trajectory detection system <b>100</b> on the side of playing surface <b>119</b>, accurate analysis may require that the shooter <b>112</b> shoot from within the active area <b>108</b>. In this alignment, the trajectory plane <b>104</b> may be nearly normal to the basketball backboard <b>151</b>. Although, the system <b>100</b> may accurately detect and analyze trajectories where the angle between the trajectory plane <b>104</b> and the normal to the backboard <b>151</b> is within a few degrees. The active area <b>108</b> may be different for different systems <b>100</b>. For instance, in <figref idref="DRAWINGS">FIG. 3</figref>, a machine vision system employing three camera's is described where the active area <b>108</b> is essentially any location on the playing surface. Further, the present invention is not limited to machine vision systems for detecting the trajectory of the basketball and other sensor systems may allow for different active areas.</p>
<p id="p-0056" num="0055">The trajectory system <b>100</b> may be set-up in different locations around the playing surface <b>119</b>. By moving the system <b>100</b>, the active area <b>108</b> may be changed. For instance, the trajectory detection may be positioned behind the backboard <b>151</b>. For this set-up, the active area <b>108</b> may be a rectangular area on the playing surface <b>119</b> that is parallel to the backboard <b>151</b>.</p>
<p id="p-0057" num="0056">Although the active area <b>108</b> may be limited with a single camera <b>118</b> in a machine vision system, an advantage of the system is it simple to set-up and to operate. With some multiple camera machine vision systems, the active area may be larger than with a single camera system. However, the set-up and calibration of a multi-camera system may be more time consuming as compared to a single camera system because a known alignment of the cameras relatively to one another and relative to the tracked object is needed to process the data.</p>
<p id="p-0058" num="0057">The single camera system <b>100</b> is simple enough to be capable of autonomous set-up and operation with minimal user input. The system may autonomously calibrate itself using known distance markers, such as the height of the basketball hoop or a distance to a free throw line or 3-point arc, which may be captured in video frame data. In another embodiment, a user may be required to stand within the detection zone of the system, holding a basketball or other object, at a fixed distance from the camera and at a fixed height. After the system is calibrated, a user may use the system <b>100</b> to practice without the help of an additional operator to run to the system <b>100</b>. The system <b>100</b> may accept voice commands allowing the user to adjust the operation of the system from a distance.</p>
<p id="p-0059" num="0058">To analyze a trajectory <b>102</b> of the basketball <b>109</b>, the camera <b>118</b> may record a sequence of video frames in the detection volume <b>110</b> at different times. The number of frames recorded by the camera over a give time period, such as the duration of the ball's trajectory <b>102</b>, may vary according to the refresh rate of camera <b>118</b>. The captured video frames may show a sequence of states of the basketball <b>109</b> at different times along its trajectory <b>102</b>. For instance, the camera <b>118</b> may capture 1) an initial state <b>105</b> of the trajectory shortly after the ball leaves the shooter's hand, 2) a number of states along the trajectory <b>102</b>, such as <b>120</b>, <b>121</b>, <b>122</b> and <b>123</b> at times t<b>1</b>, t<b>2</b>, t<b>3</b> and t<b>4</b> and 3) a termination point <b>107</b> in the basketball hoop <b>103</b>. Although not shown, the system may also be used to generate parameters for characterizing the trajectory of missed shots relating to the rebound flight path, such as but not limited to a rebound height, rebound angle, rebound velocity.</p>
<p id="p-0060" num="0059">The sequence of captured video frames may be converted to digital data by a video capture card for analysis by the CPU <b>116</b>. The analysis of video frame data may require the detection volume <b>110</b> to remain constant during the trajectory <b>102</b>. However, the detection volume <b>110</b> may be adjusted to account for different set-up conditions of a playing area where the system <b>100</b> is employed. For instance, the camera <b>118</b> may be capable of zooming in or out of a particular area and changing its focus. The analysis of the trajectory <b>102</b> using the captured video frame data is described with respect to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0061" num="0060">The series of frames used to capture the trajectory may also capture the shooter <b>112</b> shooting the basketball <b>109</b> including all or a portion of the shooter's <b>112</b> body as well as the defender's body <b>114</b> during the shot. The physical information captured by the camera <b>118</b> regarding the shooter <b>112</b> and the defender <b>114</b> may also be analyzed by the system <b>100</b>. For example, different motions of the shooter <b>112</b> may be analyzed by the system <b>100</b> determine if the shooter is using proper shooting mechanics. As another example, data, such as, a jump height, hang-time, a release point floor position on the playing surface <b>109</b>, a landing position on the playing surface <b>109</b> may be determined using the video frame data captured by the camera <b>118</b> in the machine vision system.</p>
<p id="p-0062" num="0061">After detecting and analyzing the trajectory <b>102</b>, the system <b>100</b> may generate one or more trajectory parameters. The one or more trajectory parameters may be output as feedback information to the shooter <b>112</b> and the defender <b>114</b>. Typically, the system <b>100</b> may provide the feedback information while the shot is in the air or shortly after the shot has reached the hoop <b>103</b>. The feedback information may be provided within less than a second or less than 10 seconds of the initiation of the shot depending on the type of feedback information that is generated. The immediate feedback may increase the training benefits of using the system. The shooter <b>112</b> may use the feedback information to improve their skill at making shots. The defender <b>114</b> may use the feedback information to improve their defense in preventing the shooter from making their shots. A brief description of the methods used to develop the feedback information is described as follows.</p>
<p id="p-0063" num="0062">The shooter <b>112</b> may also use the feedback information for rehabilitative purposes. For instance, after an injury and/or for psychologically reasons, a player's skill at shooting may decline from a previously obtained skill level. In rehabilitative setting, the present invention may be used by the player to regain their previous skill level and even improve upon their previous skill level. For instance, the feedback information provided by the present invention may increase a shooter's confidence which may provide psychological benefits that lead to an improvement in performance.</p>
<p id="p-0064" num="0063">To develop basketball feedback information, the basic nature of a basketball shot is considered with the objectives of 1) informing the player in regards to what are a set of optimal trajectory parameters that they can adjust to increase their probability of making a shot and 2) informing their player about how their shots compare to the optimal. This information is output to the player as feedback information. As an example of this process, the basketball shot by the shooter <b>112</b> is described. However, the system <b>100</b> may be applied to the trajectories of other objects in different sports where optimal trajectory parameters may be different than basketball. Thus, the description is presented for illustrated purposes only.</p>
<p id="p-0065" num="0064">The basketball shot by the shooter <b>112</b> travels in an essentially parabolic arc in the trajectory plane <b>104</b>. The arc is essentially parabolic and the ball <b>109</b> travels in-plane because after the ball is released the dominant force acting on the ball is gravity <b>109</b>. Other forces, such as ball spin, or if the ball is shot outside, wind, may cause the trajectory to deviate from a parabolic arc. But, when the ball is shot inside, these forces cause little deviation from the parabolic trajectory and a parabolic arc is a good approximation of the trajectory <b>102</b>.</p>
<p id="p-0066" num="0065">For each shot by the shooter with an initial release height, there are many different combinations of release velocity and release angles at the initial state <b>105</b> that allow the player to make the shot, i.e., the ball travels through the basket <b>103</b> and then many combinations of release velocity and release angles where the player does not make the shot. When a player shoots the basketball <b>109</b>, the player selects a combination of release velocity and release angle. Typically, the selection of the shot parameters is performed intuitively and the player doesn't consciously think of what release velocity and release angle they are selecting. However, through training, the player may be able to improve their intuitive shot selection.</p>
<p id="p-0067" num="0066">Within the group of the different combinations of release velocity and release angle that may be selected by the shooter, there are combinations of release velocity and release angle that provide the shooter with a greater or lesser margin of error for making the shot. For instance, for a basketball shot in the basket <b>103</b>, an optimal entry angle into the hoop that provides the greatest margin of error is about 43-45 degrees measured from a plane including the basketball hoop <b>103</b>. These optimal trajectories are close to trajectories that allow for the ball to reach to the basket <b>103</b> with a minimal amount of energy applied by the shooter. For perturbations around this optimal entry angle, such as when the defender <b>114</b> causes the shooter <b>112</b> to alter their shot, there are more combinations of release velocity and release angle that allow the shot to be made as compared to other combinations of release velocity and release angle away from the optimal.</p>
<p id="p-0068" num="0067">With the general understanding of basketball trajectories provided above, methods may be developed for providing feedback information that allows for the shooter <b>112</b> to train for an initial state <b>105</b> that provides the greatest margin of energy i.e., a near minimum energy trajectory. In one embodiment of the present invention, an entry angle and an entry velocity of the basketball <b>109</b> near the termination point <b>107</b> are two trajectory parameters that may generated from the physical information recorded by the machine vision system in system <b>100</b>. The entry angle and entry velocity are correlated to the release angle and the release velocity of the shot <b>102</b>. Thus, after the shooter <b>112</b>, releases the shot, the camera <b>118</b> may record a series of video frames with images of the ball <b>109</b> as it approaches the basket <b>103</b>. With this information, the entry angle and the entry velocity of the shot may be generated. One or both of these trajectory parameters may be provided to the player as feedback information.</p>
<p id="p-0069" num="0068">The feedback information may be provided to the shooter <b>112</b> and the defender <b>114</b> in one of a visual format, an audio format and a kinetic format. For instance, in one embodiment, on a visual display, the entry angle and/or entry velocity may be viewed in a numeric format by the players, <b>112</b> and <b>114</b>. In another embodiment, when projected through an audio device, numeric values for these parameters may be heard by the players, <b>112</b> and <b>114</b>. The audio feedback device may be a speaker built into the system <b>100</b>, a speaker connected to the system <b>100</b> or audio devices worn by the players, <b>112</b> and <b>114</b> that receive information from the system <b>100</b>. In yet another embodiment, a kinetic device, such as a bracelet or headband worn by the players may be used to transmit the feedback information in a kinetic format. For instance, the bracelet may vibrate more or less depending on how close the shot is to the optimum or may get hotter or colder depending on how close the shot is the optimum. Multiple feedback output mechanisms may also be employed. For instance, the feedback information may be viewed in a visual format by coaches or other spectators on a display while a sound projection device may be used to transmit the feedback information in an audio format to the players.</p>
<p id="p-0070" num="0069">In general, the parameters may be presented qualitatively or quantitatively. An example of qualitative feedback may be a message such as &#x201c;too high&#x201d; or &#x201c;too low&#x201d; in reference to the entry angle of a shot by the player or &#x201c;too fast&#x201d; or &#x201c;too slow&#x201d; in reference to the entry velocity. An example of qualitative feedback may be the actual entry angle or entry velocity of the shot in an appropriate unit of measurement, such as a message of &#x201c;45 degrees&#x201d; for the entry angle. Again, the qualitative and/or quantitative information may be presented in different formats, such as a visual format, an auditory format, a kinetic format and combinations thereof.</p>
<p id="p-0071" num="0070">With knowledge of what are optimal values of the trajectory parameters transmitted in the feedback information, the shooter <b>112</b> may adjust their next shot to generate a more optimal trajectory. For instance, if the feedback information is an entry angle and their shot is too flat, then the shooter <b>112</b> may adjust their next shot to increase their entry angle. Conversely, with their knowledge of what are the optimal values of the trajectory parameters, the defender <b>114</b> may adjust their defensive techniques to force the shooter <b>112</b> to launch a shot along a less than optimal trajectory <b>102</b>. Thus, the defender <b>114</b> can experiment with different techniques to see which are most effective. In different training methods, the system <b>100</b> may be used to measure a trajectories for a shooter <b>112</b> training without a defender <b>114</b> or as is shown in the figure training with the presence of a defender <b>114</b>.</p>
<p id="p-0072" num="0071">The feedback information may be provided to the player before prior to the ball <b>109</b> reaching the basket or shortly after the ball reaches the basket <b>103</b>. The system <b>100</b> is designed to minimize any waiting time between shots. For each shooter and for different training exercises, there may be an optimal time between when the shooter shoots the ball <b>109</b> and when the shooter <b>112</b> receives the feedback information. The system <b>100</b> may be designed to allow a variable delay time between the shot and the feedback information to suit the preferences of each shooter that uses the system <b>100</b> or to account for different training exercises that may be performed with the system. For instance, a rapid shooting drill may require a faster feedback time than a more relaxed drill, such as a player shooting free throws.</p>
<p id="p-0073" num="0072">The present invention is not limited to providing feedback information for near minimum energy basketball trajectories. For instance, under some conditions, such as when a smaller player shoots over a larger player, it may be desirable for the shooter to shoot with a greater than optimal arc to prevent the larger player from blocking the shot. Thus, the shooter may use the feedback information provided by the system <b>100</b> to train for different conditions that may call for different types of shots, such as shooting over a larger player as compared to a wide-open shot. Further, the trajectory analysis systems of the present invention may be used to train in different types of basketball shots, such as bank shots, hook shots, lay-ups, jump shots, set-shots, free throws and running shots, that may requiring the mastery of different shooting skills and may have different optimal trajectory parameters. Thus, the detection system <b>100</b> may be adjustable to allow for training in different types of shots. Further, for different sports, different trajectory skills may be optimal for improving performance, which may be different than basketball. The different trajectory skills that may be required for different sports may be accounted for in the present invention.</p>
<p id="p-0074" num="0073">A measure of how good a player's shooting skills may be a consistency of their trajectory parameters averaged in some manner over many shots. Typically, it has been determined empirically that better shooters have a lower variability in their trajectory parameters for a given shot, such as a free throw. Thus, to rate a shooter's performance, it may be desirable to generate trajectory parameters for a plurality of trajectories shot by a player in a trajectory session and then calculate a standard deviation for each of the trajectory parameters.</p>
<p id="p-0075" num="0074">The standard deviation (SD) is a measure of the scatter of a particular set of data. It is calculated as,
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>SD=[</i>3(<i>y</i><sub>i</sub><i>&#x2212;y</i><sub>mean</sub>)<sup>2</sup>/(<i>N&#x2212;</i>1)]<sup>1/2 </sup><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where y<sub>mean </sub>is an average value of trajectory parameter, N is the number of trajectories and y<sub>i </sub>is a value of the trajectory parameter for a particular trajectory. There are other types of statistical parameters that may be used to characterize data variability and the present invention is not limited to the standard deviation formula described above.
</p>
<p id="p-0076" num="0075">During a trajectory session where a plurality of trajectories are analyzed by the system <b>100</b>, the trajectory parameters generated for the plurality of trajectories may be stored to a mass storage device contained in the system <b>100</b> or in communication with the system <b>100</b>. After the session, the standard deviation for all the trajectories in the session may be generated. In other embodiments, to provide measures of variability of different data sets representing different playing conditions, the system <b>100</b> may divide the trajectory data into different subsets, such as grouping according to types of shots, locations of shots, shots where the shooter is guarded, shots where the shooter is unguarded, made shots, swished shots, missed shots, shots made earlier in the session versus shots made later in the session, and combinations of these groupings.</p>
<p id="p-0077" num="0076">The statistical variability calculated from the different data sets may be used as a guide by the system for suggesting methods that will improve the player's shooting skills. The system <b>100</b> may include software for suggesting methods based upon the statistical analysis. For instance, the system <b>100</b> may determine that a player's shot variability is greater when they are guarded as opposed to unguarded, thus, exercises may be prescribed to the player that focus and shooting while guarded. As another example, the player's shot variability may be greater later in a session as opposed to earlier in a session or greater in a training session before practice as opposed to after practice, thus, the system may suggest the player work on their aerobic conditioning. In yet another example, the player's shot variability may vary as a function of a distance from the basket and the system may suggest the player concentrate on shots at the distances where the variability is greatest. In <figref idref="DRAWINGS">FIGS. 7 and 8</figref>, plots of data from a trajectory session and predictions of improvement using statistical analysis are described.</p>
<p id="p-0078" num="0077">In some embodiments, the trajectory session data and other information generated by the system <b>100</b> may be viewed via a number of different output mechanisms, such as a hard copy from a printer or a display. For example, a printer connected to the system <b>100</b> may be used to generate print-outs of trajectory session data in different formats. As another example, a display interface in communication with the system <b>100</b> may be used to view trajectory session data in different formats. In particular, the system <b>100</b> (see <figref idref="DRAWINGS">FIGS. 5A-5C</figref>) may include a touch screen interface for viewing trajectory session data and providing input parameters into the system. As another example, the system <b>100</b> (See <figref idref="DRAWINGS">FIG. 4</figref>) may communicate with a portable viewing device capable of interfacing with the system <b>100</b>.</p>
<p id="p-0079" num="0078">Information generated with system <b>100</b>, such as trajectory data from a plurality of trajectories in a trajectory sessions, may be archived. The archival storage system may be a remote storage device in communication with the system <b>100</b> or may be a mass storage device provided with the system <b>100</b>. The archival storage system may include raw data of physical information recorded by the camera <b>118</b>, such as video frame data, as well as, trajectory parameters and other information generated from analysis of the raw data. The archival data may store trajectory session data for a plurality of different trajectory sessions by one or more different players.</p>
<p id="p-0080" num="0079">By accessing the archival data, an improvement over time for a particular parameter generated by the system <b>100</b>, such as a shot variability parameter, may be assessed. Further, the archival data may be used for data mining and video editing purposes. For instance, in a video editing application, the graphic of the player's average trajectory may be integrated with video data of the player shooting. In another example, video clips of two or more different players shooting may be compared or video clips of a single player shooting during different trajectory sessions may be compared to show the player's improvement. In data mining applications, the video data may be further analyzed to characterize a player's shot mechanics. In another application, simulations may be generated to predict gains in team performance based-upon improvements in individual performance on the team. This type of simulation may require archival trajectory session data to be analyzed for a plurality of different players.</p>
<p id="p-0081" num="0080">In some embodiments, the archival data may be accessible via a remote connection. For instance, a password-protected web-site may be used as a portal for accessing archival data generated from system <b>100</b>. The web-site may allow clients, such as players, coaches, or scouts to gain access to the web-site from remote sites, such as home computer connected to the Internet or a portable computer connected to the Internet. The web-site may include a plurality of analysis tools and a graphical interface for viewing graphical data from the applications in different formats. In another embodiment, the archival data may be downloaded to a CD, DVD or other portable storage medium that the player can take with them. Analysis software may also be downloaded with the archival data so that the player can analyze the data on another computer.</p>
<p id="p-0082" num="0081">Information generated during a trajectory session may be stored in a database. The database may relate player identification information, such as a name, an address, a team, a session time, a session location, a session data to raw data recorded during the trajectory session and information generated during the trajectory session. The database may be used for player tracking purposes and targeting services to players that have used the trajectory system.</p>
<p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram of captured video frame data used to generate a curve-fit for a trajectory of an object. As described with respect to <figref idref="DRAWINGS">FIG. 1</figref>, in a machine vision system, images of objects may be recorded by a camera, digitized and converted into frame data. Four captured video frames, <b>200</b>, <b>201</b>, <b>202</b>, <b>203</b> are shown. The digitized frames capture an image of the ball <b>109</b> at times, t<b>1</b>, t<b>2</b>, t<b>3</b> and t<b>4</b> as it approaches the basketball hoop <b>103</b>.</p>
<p id="p-0084" num="0083">Pattern recognition software may be used to determine the location of the ball <b>109</b> from other images that may be captured. In one embodiment, a reference frame is captured without a ball and the reference frame is compared with the frames, such as <b>200</b>, <b>201</b>, <b>202</b>, and <b>203</b> that contain the ball <b>109</b>. In cases where the reference frame is relatively fixed, i.e., the only moving object is the ball <b>109</b>. The ball <b>109</b> can be identified via subtraction of the frames. The system may capable of updating the reference frame as needed to account for new objects that have moved into the frame or have been removed from the frame.</p>
<p id="p-0085" num="0084">When there is a lot of noise in the frame, such as people or other objects moving around in the frames, as well as the basketball, then more complex filtering techniques may be applied. In one embodiment, a data capture zone <b>214</b> may be identified in each frame. The data capture zone <b>214</b> may be used to eliminate any noise sources that may be mistaken for the basketball and may be also be used to reduce the computational resources required to analyze the frame data. For instance, the processing of the video frame data may be limited to the data capture zone or one or more other areas of interest within the captured frame. There are many pattern recognition and filtering techniques that have been developed for robotics, where machine vision is used, that are well known in the arts that may be applied to the present invention. Further, there are many techniques that have developed for signal or pattern recognition in noisy environments, such as those that have been developed for recognizing valid aircraft radar signals and tracking moving objects in commercial or military applications, that are well known in the arts that may be applied with the present invention.</p>
<p id="p-0086" num="0085">Once the position of the object is determined from each frame. A curve-fit for the trajectory may be developed in a computational space <b>205</b> with a coordinate system <b>216</b>. In the figure, for illustrative purposes only, four points, <b>206</b>, <b>207</b>, <b>208</b> and <b>209</b> corresponding to times t<b>1</b>, t<b>2</b>, t<b>3</b> and t<b>4</b> are shown. As needed, additional frames may be used to properly fit the data. For the basketball, the trajectory is assumed to be parabolic and a parabolic curve-fit may be generated using a least squares curve-fit. The parabolic curve-fit accounts for gravitational forces and neglects forces generated from drag and aerodynamic forces resulting from spin. However, more complex trajectory curve-fits may be modeled in the present invention that account for drag and spin. These curve-fits may be more desirable for analyzing the trajectories of objects, such as a baseball, a football, a tennis ball, a soccer ball or a volleyball, where aerodynamic forces due to spin or drag are more important.</p>
<p id="p-0087" num="0086">In one embodiment, curve-fits <b>210</b> for x and y position may be parameterized as a function of time using a time at which each frame was recorded. In another embodiment, a curve-fit of height (y) as a function of distance (x) in the coordinate system <b>216</b> may be generated. Using the curve-fit, trajectory parameters, such as an entry angle <b>211</b> and the entry velocity <b>212</b> of the object as it enters the hoop, is near the hoop or at other states along the trajectory may be generated. For instance, the entry angle <b>211</b> may be generated from the tangent of the curve-fit at the termination point <b>213</b>. The entry velocity <b>212</b> may be generated from derivatives of the parameterized equations <b>210</b> at the time corresponding to the termination point <b>213</b>. If the release time is known, then the release velocity and release angle may also be determined from the parameterized trajectory equations.</p>
<p id="p-0088" num="0087">In one embodiment, trajectory parameters may be generated without curve-fitting the entire trajectory. For instance, with enough position data near a particular location on the trajectory, such as the termination point <b>213</b>, then an entry angle may be calculated by simply fitting a line through available data points near the termination points. As another example, some trajectories may be non-parabolic but a parabolic curve-fit may be sufficient for estimating a trajectory parameter, such a velocity, near a particular location.</p>
<p id="p-0089" num="0088">In some embodiments, trajectory parameters may be generated for a portion of a trajectory captured in video frame data and analyzed in a manner described above. The trajectory parameters may be provided as feedback information to a user of the system. For example, a trajectory system as described with respect to <figref idref="DRAWINGS">FIG. 1</figref>, may be setup on the side of a baseball field and trajectory parameters, such as a release velocity, a release angle, a spin rate and a release height for a thrown baseball, may be generated with the present invention. The trajectory system may only detect and analyze the portion of the trajectory of the baseball near the throwing release point. One or more of the trajectory parameters or a combination of the trajectory parameters generated from the portion of the trajectory that is detected and analyzed may be provided as feedback information to a baseball pitcher trying to improve their throwing skills. The pitcher that has thrown the ball can evaluate the outcome of the pitch according to where it is caught by a catcher.</p>
<p id="p-0090" num="0089">A similar approach could be applied to a football kicker kicking a football or a soccer player kicking a soccer ball. In these instances, a trajectory detection system may be setup on the side of the field. The system may capture video frame data that is used to generate trajectory parameters of the football or soccer ball's trajectory as it leaves the player's foot and provide feedback information. The player kicking the ball can then compare the feedback information to the success of the kick. For instance, how far the ball traveled, whether a field goal was made or whether a soccer goal was made.</p>
<p id="p-0091" num="0090">In another embodiment, trajectory parameters may be generated for two or more trajectory segments that are captured by video frame data and analyzed in the manner described above. For example, as described with respect to <figref idref="DRAWINGS">FIG. 1</figref>, a trajectory detection system may be setup on the side of a tennis court and the system may be used to measure trajectory parameters for a tennis ball tossed by a player to initiate a serve. The toss of the serve is the first trajectory segment. The trajectory detection system may generate trajectory parameters and feedback information for the toss, such as a toss angle and a toss velocity and a release height for the toss. Then, the player may strike the tennis ball with a tennis racket to launch the tennis ball along the trajectory. The trajectory detection system may generate a second set of set of trajectory parameters and feedback information for the second segment, such as, a height at which the ball is struck, an angle at which it leaves the racket, a velocity at which it leaves the racket and a spin on the ball after it leaves the racket.</p>
<p id="p-0092" num="0091">In another example of providing feedback information to two trajectory segments, the trajectory detection system may generate trajectory parameters and feedback information at the release point of a thrown baseball as described above. Then, the trajectory detection system may detect a portion of the baseball trajectory as it crosses the plate and then generate trajectory parameters for this portion of the trajectory, such as a height at which the ball crosses the plate and a velocity as it crosses the plate. These trajectory parameters for the second trajectory segment may be provided as a second set of feedback information to the pitcher.</p>
<p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram of a trajectory capture and feedback scenario employing a trajectory detection and analysis device of the present invention. In this embodiment, a machine vision system employing 3 cameras <b>165</b> and 3 infrared emitters <b>164</b> is mounted above the backboard <b>151</b> and the basketball hoop <b>103</b>. The 3 cameras and 3 infrared emitters may be enclosed within a housing <b>170</b>. In another embodiment, the 3 cameras and 3 emitters may be integrated into the backboard <b>151</b>. Different multiple camera configurations may be used and the present invention is not limited to three infrared cameras mounted in a linear arrangement fairly close together. For instance, one embodiment of the present invention two cameras may be placed on opposite sides of the playing surface <b>109</b>, i.e. across the court from one another. Output from both cameras may be transmitted to a logic device for processing.</p>
<p id="p-0094" num="0093">The backboard <b>151</b> is attached to a basketball pole, which is fixed to the ground. In other embodiments, the machine vision system may be mounted to a backboard <b>151</b> that is attached to a portable supports allowing the basketball goal to be moved around on a playing surface <b>109</b>. The support may also allow for the height of the goal to be adjusted. The machine vision system may be mounted to a backboard <b>151</b> with a hoop <b>103</b> that is located outside. When the trajectory system is used outside, the housing <b>170</b> may be water-proofed to prevent water damage to the system.</p>
<p id="p-0095" num="0094">The infrared emitters <b>164</b> may be used to illuminate objects that enter the detection volume <b>110</b>, such as ball <b>159</b> and ball <b>160</b>. The infrared light reflected from the objects may be detected and recorded by the cameras <b>165</b>. When the cameras record both infrared and visible light, the cameras <b>165</b> may also include filters for minimizing visible light captured in a video frame to enhance the infrared signature of objects. Using video frame data from the three cameras <b>165</b> with the known distances between each camera <b>165</b> and geometric relationships, trajectory parameters may be generated for trajectories of basketball's shot from anywhere on the playing surface. For instance, when the playing surface is a basketball court, then trajectories may be analyzed from basketball's shot anywhere on the court or even from beyond the boundaries of the court. This analysis capability differs from the machine vision system with a single camera that was described with respect to <figref idref="DRAWINGS">FIG. 1</figref>. In the system of <figref idref="DRAWINGS">FIG. 1</figref>, the active area from which a player could shoot a shot and have it detected and accurately analyzed was more limited.</p>
<p id="p-0096" num="0095">An advantage of the infrared system is that the intensity at which an object is illuminated decreases non-linearly according to the distance of the object from the emitters <b>164</b>. Thus, objects close to the emitters are clearly illuminated by objects but background objects that are far away from emitters <b>164</b> are not illuminated. As was described with respect to <figref idref="DRAWINGS">FIG. 2</figref>, with a camera that records in visible light, filtering methods may have to be applied to a series of video frames to distinguish the basketball from the movement from other objects that may be moving in the series of video frames, such as spectators. With the infrared system, since only objects close to the infrared emitters <b>164</b> are clearly illuminated, i.e., objects within the detection volume <b>110</b>, the need to apply complex filtering algorithms to account for the movement of other objects in the video frames may be eliminated. For instance, the infrared system may be able to detect and analyze trajectories of basketballs in an arena or gymnasium where there are many spectators in the field of view of the cameras <b>165</b>.</p>
<p id="p-0097" num="0096">Another advantage of the infrared system is that the basketballs <b>159</b> and <b>160</b> may be marked with invisible infrared marking that are only visible in infrared light. Thus, the players <b>152</b> and <b>153</b> shooting the balls <b>159</b> and <b>160</b> marked with invisible infrared symbols would not be able to distinguish them from unmarked balls. The balls may be marked with a symbol or series of symbols to allow them to be distinguished by the system and associated with a particular player. For instance, ball <b>159</b> may be marked with a plurality of triangles and ball <b>160</b> may be marked with a plurality of squares in invisible ink that either glows under infrared light or absorbs infrared light allowing the symbols to be detected by the machine vision system. In addition, the balls <b>159</b> and <b>160</b> may be marked with visible symbols to allow the players to distinguish between the balls.</p>
<p id="p-0098" num="0097">The invisible infrared marking may also be used to aid in generating trajectory parameters. For instance, each of the seams of the basketballs <b>159</b> and <b>160</b> may be marked with different invisible symbols or patterns allowing the spin rate of the basketball and the orientation of the basketball to be measured. In general, the detection systems of the present invention may be used to measure one or more of the following trajectory parameters for a basketball's trajectory: a release height, a release angle, a release velocity, an entry angle into a basketball hoop, an entry velocity into the basketball hoop, an entry position of a center of the basketball relative to a center of the basketball hoop, a transverse velocity of the basketball relative to a normal line drawn through the center of the basketball hoop, a missed shot, a made shot, a rotation rate of the basketball and axis of rotation of the basketball. Feedback information may include one or more of the trajectory parameters or combinations of the trajectory parameters, such as a ratio of entry velocity to entry angle.</p>
<p id="p-0099" num="0098">The trajectory parameters that are generated may vary from system to system depending on the sensors used in each system. As described in <figref idref="DRAWINGS">FIGS. 1 and 3</figref>, with the present invention, machine vision systems may be employed that use one or more cameras. The use of multiple cameras may provide measurement capabilities not possible with a single camera and hence capabilities to generate different trajectory parameters as compared to a single camera system.</p>
<p id="p-0100" num="0099">Further, the present invention is not limited to machine vision systems for detecting trajectories. Other types of sensor systems may be able to generate different trajectory parameters than the machine vision systems. For instance, there are many types of sensors systems that use different types of emitters and detectors to detect the motion of objects. In these sensor systems, the emitter emits an energy signal and the detector detects a reflected energy signal from the object. These systems may be based on electromagnetic energy signals, such as radar signal or a laser signal, or even acoustic energy signals.</p>
<p id="p-0101" num="0100">As another example, non-intrusive sensors, such as accelerometers or vibration sensors, may be integrated into the object, such as <b>159</b> or <b>160</b>, a device worn by the players, <b>152</b> or <b>153</b>, or other associated equipment, such as the backboard <b>151</b> and the hoop <b>103</b>. Information from these non-intrusive sensors may be utilized by the trajectory detection system. In particular, a small (silicon chip based) sensor system with a Radio Frequency Identification (RFID) tag may be integrated into an object, such as a basketball. The sensor chip may include sensors for measuring accelerations and rotation rates for the object along its trajectory. A microprocessor on the chip may be used to process the sensor data and an antenna may be used to broadcast signals to an RFID tag reader. The sensor chip may be powered by an electromagnetic energy received from the RFID tag reader. As another example, the non-intrusive sensors, such as a sensor chip, may be integrated into items worn by the player, such as player's shoes or integrated into their clothes. These sensors may allow the trajectory system to detect forces that a player's generates while launching an object, such as the directional forces, a player, such as <b>152</b> or <b>154</b>, generates during a basketball jump shot. With this type of information, the player's release time may be correlated to where the player is in their jump, i.e., is the ball released at the peak of their jump, on the way up or on the way down. Also, information, such as whether the player jumps straight up and down, forward or backward or side-to-side may be determined. These types of sensors may be denoted as non-intrusive because a player using a ball with these types of sensors or wearing these types of sensors is not likely to be aware of there presence unless directly told about their presence. However, in general, any type of sensor that does not interfere with the player's normal play of the game may be considered non-intrusive. For instance, a small sensor package worn by the player may be considered non-intrusive if it does not interfere with their play even though the player may be aware of the sensor package.</p>
<p id="p-0102" num="0101">The present invention is not limited to one type of sensor system. For example, in some embodiments, combinations of sensor systems, such as a machine vision system, non-intrusive sensors integrated into the launched object, non-intrusive sensors worn by the player and emitter/detector systems may be used with the trajectory systems of the present invention. Further, the feedback information generated by the system may not be limited to trajectory parameters regarding the object's flight. For instance, as described in the previous paragraph, non-intrusive sensors may be used to measure forces that a player generates while launching an object or a position of the player during and after the launch of an object, such as shooting a basketball. Parameters regarding this information may be generated by the trajectory system and provided as feedback information to a system client, such as <b>152</b>, <b>153</b> and <b>154</b>.</p>
<p id="p-0103" num="0102">Returning to <figref idref="DRAWINGS">FIG. 3</figref>, two players, <b>152</b> and <b>153</b>, are shown shooting two balls, <b>159</b> and <b>160</b>, that are in flight at the same time. The trajectory system may be capable of generating trajectory parameters and feedback information for two or more object with trajectories in flight at the same time, such as <b>161</b> and <b>162</b>. When two objects collide before reaching the basket <b>103</b> and are deflected, the trajectory system may be capable of determining whether a shot would have been made based upon trajectory data measured before the objects collided.</p>
<p id="p-0104" num="0103">Methods may be used by the system to distinguish between two or more players that have shot a ball while using the trajectory system. For instance, as described above, the ball used by each player may be marked in some manner allowing the system to distinguish between which of the two or more players has shot a ball. In another example, non-intrusive sensors worn by the player or markings on clothes worn by the player may allow the system to distinguish between players. The non-intrusive sensors may allow the system to determine when a particular player has shot the ball. The markings on the clothes, such as a different jersey worn by each player using the system, may allow the system to distinguish between players.</p>
<p id="p-0105" num="0104">When the system can distinguish between two or more players using the system simultaneously, trajectory session data may be generated and archived for each player, which may be advantageous. Also, when the system can distinguish between players, the system may be able to provide personal feedback information to each player via feedback interfaces worn by the players. For instance, player <b>152</b> that has shot the ball <b>159</b> is wearing a feedback interface device <b>164</b>, which provides feedback information in a kinetic format and player <b>153</b>, which has shot the ball <b>160</b> is wearing a feedback interface device <b>164</b>, which provides feedback information in an auditory format. In this embodiment, the system detects and analyzes the trajectories of balls, <b>159</b> and <b>160</b>, generates trajectory parameters, determines which player has shot which ball and provides feedback information to each player via their respective feedback interface devices, <b>163</b> and <b>164</b>. The feedback information is sent to each player's feedback interface device via a wireless communication interface used by the trajectory feedback system.</p>
<p id="p-0106" num="0105">In another embodiment of the present invention, to provide feedback information two or more players using the system simultaneously, the trajectory system may use shot location to distinguish between players. The trajectory curve-fits may be used to determine a location where a shot was initiated. Thus, the two or more players may be assigned a particular area on the playing surface <b>109</b> in which to shoot. Then, the system may store data from each shot area that has been assigned to a particular player to a storage area for that player. The players may be assigned a particular communication frequency for their feedback interface device. Since the player is identified from the location from which the shot originated, the proper communication frequency for sending feedback information to each player may be selected.</p>
<p id="p-0107" num="0106">In yet another embodiment, one or more players may shoot from one side of the basket <b>103</b> and one or more players may shoot from the other side of the basket <b>103</b>. A speaker, such as <b>167</b> mounted to backboard <b>151</b> or a speaker located on the playing surface <b>109</b> on the same side of the backboard <b>151</b> as the speaker <b>167</b>, may provide audio feedback information for shots originating from the side of the basket <b>103</b> where the speaker <b>166</b> is located. A speaker, such as <b>167</b> mounted on the other side of the backboard <b>151</b>, may provide feedback information for shots originating from the side of the basket <b>103</b> where this speaker is located. In another embodiment, the players, <b>152</b> and <b>153</b>, may take turns shooting and the speakers <b>166</b> and <b>167</b> may project the same feedback information to the player that has shot the ball. The speakers <b>166</b> and <b>167</b> are optional and all backboard mounted systems may not include backboard mounted speakers, such as <b>166</b> and <b>167</b>.</p>
<p id="p-0108" num="0107">The trajectory system may generate feedback information that is received by system clients other than the shooters. For instance, coaches and spectators may desire feedback information for player's using the system. For instance, a system client <b>154</b>, such as a coach, a scout or a spectator, may receive feedback information via a visual display tablet <b>155</b> via wireless communication <b>156</b> from the trajectory system. When multiple players are using the system, the system client <b>154</b>, may be able to view feedback information for two or more players simultaneously or may be able to select feedback information from an individual player for viewing. For each player, the display tablet may allow the system client to view the feedback information in different formats, to view trajectory session data for the current trajectory session and to view archived trajectory session data from previous trajectory sessions to determine a player's training progress and may be able to view records of a training program that a particular player is following. In general, the system may be able to support simultaneous communications with a plurality of different peripheral devices that may be used by system clients including but not limited to hand-held computing devices, displays, wearable sound projection devices, kinetic feedback devices, printers and remote servers.</p>
<p id="p-0109" num="0108">The functions of the trajectory systems of the present invention may be provided in a device with a single housing or more be divided among a number of different devices with separate housings. In addition, the trajectory system may be constructed in a modular fashion to allow different modules to be added to provide increased functionality. For example, one trajectory system may include the infrared emitters <b>164</b>, cameras <b>165</b>, logic devices for processing the video data and generating feedback information and a wireless communication interface for communicating with the feedback interface devices and other peripheral devices, such as the remote server <b>157</b>. The emitters, cameras, logic device and wireless communication interface may be enclosed in as single housing <b>170</b>. If desired, the trajectory system may be configured to communicate feedback information to additional feedback output mechanisms that may be connected to the system, such as speakers <b>166</b> and <b>167</b>. The devices in the housing <b>170</b> may be configured with a number of different settings. For the backboard mounted system, control inputs may be provided through a feedback interface device with a touch screen or other input controls, such as display tablet <b>156</b>.</p>
<p id="p-0110" num="0109">The system in housing <b>170</b> may not include storage and session analysis capabilities or only limited storage and session capabilities. For instance, it may only store data from a current session and may not archive data in a database containing records for a plurality of different players. However, these features may vary from system to system. In one embodiment, the trajectory detection system component <b>150</b> may comprise a mass storage device, a logic device, a display and a printer for storing, analyzing and outputting trajectory data accumulated over a trajectory session and a database for storing records from a plurality of different players. This device may be added as a modular component to the system in housing <b>170</b>. The plurality of trajectories may be analyzed by the system enclosed in housing <b>170</b> and then transmitted via wireless communication <b>158</b> for storage and analysis to the trajectory detection system component <b>150</b>. A remote server <b>157</b> may provide this functionality. Many trajectory system and component configuration are possible with the present invention and the examples of system modularity and division of functionality between system components has been provided for illustrative purposes only.</p>
<p id="p-0111" num="0110"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of a trajectory detection and analysis system <b>100</b> of the present invention. As was described with respect to <figref idref="DRAWINGS">FIG. 3</figref>, the components of the system <b>100</b> may be enclosed within a single housing or may be divided between a plurality of different housings enclosing different components of the system. Further, the system <b>100</b> may include different components that are not shown, such as the peripheral devices and remote servers described with respect to <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0112" num="0111">Physical information <b>216</b> is input into the system <b>100</b> via sensors <b>212</b>. In one embodiment, a machine vision system may be used where the machine vision system comprises one or more cameras <b>201</b> (e.g., a CCD camera) and a video capture card <b>203</b> for digitizing captured frame data. The video capture card <b>203</b> may capture color pixel data. The camera <b>201</b> may employ a 3.5-8 mm zoom lens and may allow for different lens attachments. In another embodiment, the system may employ a plurality of cameras arranged on a mechanism that allows different type cameras to be rotated or moved into place where only one camera is used at a time to record frame data. The different cameras may allow the detection volume of the system to be adjusted.</p>
<p id="p-0113" num="0112">The digitized frame data from a machine vision system and other sensor data may be processed by a computer <b>202</b>. The computer <b>202</b> may be a modified PC using a 1.6 GHz processor <b>204</b> w/RAM and a CD-RW drive <b>205</b> for inputting and outputting data and software. The computer <b>202</b> may also include a mass storage device, such as hard drive <b>207</b> and various network/device communication interfaces, such as wireless and wired network interfaces, for connecting to a local area network (LAN), wide-area network (WAN) or the Internet. The device communication interfaces may allow the computer to communicate with a plurality of peripheral devices and other remote system components.</p>
<p id="p-0114" num="0113">The computer <b>202</b> may include operating system software <b>206</b> for controlling system resources, such as feedback interfaces <b>213</b> and the system input/output mechanisms <b>215</b>. The computer <b>202</b> may be used to execute analysis software <b>208</b> for analyzing trajectories using the sensor data from sensors <b>212</b> and for generating feedback information <b>217</b>. The analysis software <b>208</b> may include software for providing various services, such as 1) providing a list or a plot of trajectory session information comprising one or more of physical information, trajectory parameters and feedback information for the plurality of trajectories, 2) comparing the trajectory session information from the trajectory session with trajectory session information from one or more different trajectory sessions, 3) generating trajectory session parameters used to characterize a human's performance in the trajectory session, 4) predicting performance improvement as a function of the trajectory session parameters, 5) prescribing actions for improving performance and 6) performing video editing tasks. The computer <b>202</b> may also be used to execute database software for relating physical information <b>216</b> and other information generated by the computer <b>202</b> to player identification information (e.g., name, age, address, team, etc.) and session identification information (e.g., time, data, location, number of trajectories analyzed, types of shots, etc.).</p>
<p id="p-0115" num="0114">Power to the computer <b>202</b> and other devices may be provided from the power supply <b>209</b>. In one embodiment, the power supply <b>209</b> may be a re-chargeable battery or a fuel cell. The power supply <b>209</b> may include one or more power interfaces for receiving power from an external source, such as an AC outlet, and conditioning the power for use by the various system components. In one embodiment, for in-door/outdoor models, the system <b>100</b> may include photocells that are used to provide direct power and charge an internal battery.</p>
<p id="p-0116" num="0115">Feedback information <b>217</b>, used by clients of the system <b>100</b> to improve their trajectory skills, may be output through one or more feedback interface devices <b>213</b>, such as a sound projection device <b>211</b>. In general, the system may be capable of outputting feedback information <b>217</b> to a plurality of different devices simultaneously in a plurality of different formats, such as visual formats, auditory formats and kinetic formats.</p>
<p id="p-0117" num="0116">The system <b>100</b> may support a plurality of different input/output mechanisms <b>215</b> that are used to input/display operational information <b>218</b> for the system <b>100</b>. The operational information <b>218</b> may include calibration and configuration setting inputs for the system and system components. In one embodiment, a touch screen display <b>210</b> may be used to input and display operational information <b>218</b> using a plurality menus. Menus may be available for configuring and setting up the system <b>100</b>, for allowing a player to sign into the system and to select preferred setting for the system <b>100</b> and for viewing session information <b>219</b> in various formats that have been generated by the system. The printer <b>214</b> may be used to output hard copies of the session information <b>219</b> for a player or other client of the system <b>100</b>. The present invention is not limited to a touch screen display as an interface for operational information. Other input mechanisms, such as but not limited, a key board, a mouse, a touch pad, a joystick and a microphone w/voice recognition software may be used to input operation information <b>218</b> into the system.</p>
<p id="p-0118" num="0117"><figref idref="DRAWINGS">FIGS. 5A-5C</figref> are perspective drawings of a trajectory detection and analysis system <b>100</b> for one embodiment of the present invention. A camera <b>201</b> used in a machine vision system, a touch screen display <b>210</b>, a computer <b>202</b> and a sound projection device <b>211</b> are integrated into a housing <b>300</b> with a support chassis <b>301</b>. The system <b>100</b> may also include an amplifier for the speaker <b>211</b> (not shown). Other devices described with respect to <figref idref="DRAWINGS">FIG. 4</figref> that are not shown, such as a power supply, may also be integrated into the housing.</p>
<p id="p-0119" num="0118">Wheels <b>304</b> are attached to the chassis <b>301</b> to allow the system <b>100</b> to be easily moved and positioned for use, such as on the side of a basketball court or another location where the system is employed. In general, the chassis of devices of the present invention may be designed with a weight and a form factor, which may facilitate transport, storage and unobtrusive set-up, calibration and operation of the device. For instance, the device includes a handle <b>303</b> attached to panels <b>300</b> comprising the housing that may be used to move the device and which may aid in set-up and storage of the device.</p>
<p id="p-0120" num="0119">The speaker <b>211</b> takes up a large portion of the internal volume of the system. In one embodiment, a travel system may be used that incorporates a portable computer system such as laptop that is connected to a machine vision system with the camera <b>201</b>. To use the travel system, it may be placed on top of a support platform, such as a tripod, a table, or a chair. The support platform may be positioned on the side of a basketball court. The travel system may provide feedback information via a wireless communication interface to audio device, such as an &#x201c;earbud,&#x201d; worn by the player. In another embodiment, the travel system may generate output signals that may be routed through a portable audio system (e.g., a boom box) for amplification via speakers on the audio system to provide feedback information.</p>
<p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. 6</figref> is an information flow diagram for a trajectory detection and analysis system of the present invention. A sensor system <b>502</b>, which may comprise emitters <b>506</b> and detectors <b>506</b>, receives physical information <b>507</b>. The physical information <b>507</b> may be energy signals reflected from a tracked object <b>508</b>. In the case where sensors are mounted to the tracked object <b>508</b>, then the physical information <b>507</b> may be sent as signals from the sensors to a detector <b>504</b>. Typically, the physical information <b>508</b> is transmitted through a medium such as air.</p>
<p id="p-0122" num="0121">The sensor system <b>502</b> may convert the physical information <b>507</b> to sensor data signals <b>509</b>. For instance, a charge coupling device generates electronic signals in response to photons striking a sensor array. The sensor data signals <b>509</b> may be sent through a wired or wireless connection to a sensor interface <b>510</b>, which provides signal conditioning. The signal conditioning may be needed to allow the sensor data <b>509</b> to be processed. For instance, in the machine vision system described with respect to <figref idref="DRAWINGS">FIGS. 1-4</figref>, prior to analysis, the video frame data is digitized by a video capture card.</p>
<p id="p-0123" num="0122">In <b>513</b>, the conditioned signals <b>511</b> may be processed according to system control software and according to trajectory analysis software <b>513</b> using set-up and control inputs <b>512</b> that have been input into the system. The system control software <b>513</b> may analyze portions of the data <b>511</b> to determine whether the sensor system <b>502</b> is operating properly. Based-upon the analysis of the data <b>511</b>, the system control software may provide calibration instructions and other operational instructions to the sensor system which may be transmitted to the sensors via the sensor interface <b>510</b>.</p>
<p id="p-0124" num="0123">The trajectory analysis software <b>513</b> may be used to process the conditioned signals <b>511</b> and generate trajectory parameters. The trajectory parameters may be used to generate feedback information. The feedback information may be one or more trajectory parameters or a combination of trajectory parameters, such as a ratio of trajectory parameters or a product of trajectory parameters that may be useful to a system client in improving their trajectory skills.</p>
<p id="p-0125" num="0124">Depending such factors as the application (trajectory of a specific type of object), the set-up and components of the system, the environment in which the system is used and what portion of the trajectory of an object the device is used to measure, the present invention may provide feedback to the player nearly immediately, within a second or within 10 seconds as measured from some time state along the trajectory that has been analyzed by the system. For instance, when information on the beginning of the trajectory is directly generated by the system, then the time to provide feedback may be measured from the time when the trajectory is initiated and then first detected by the system. When information on the end of the trajectory is directly measured, then the time to provide feedback may be measure from the time to when the trajectory has neared completion and has been detected by the system.</p>
<p id="p-0126" num="0125">The feedback information may be sent as feedback information parameters <b>516</b> to one or more device interfaces <b>517</b>. The device interfaces <b>517</b> may communicate with a plurality of feedback devices. The device interfaces <b>517</b>, which may include device drivers, may transmit device data/commands <b>518</b> to a feedback device interface <b>519</b> located on each feedback device. The device data/commands <b>518</b> may be used to control the operation of the feedback devices. The output from the feedback device may also be modified using set-up/control inputs <b>520</b> that may vary for each device.</p>
<p id="p-0127" num="0126">The feedback devices may output the feedback information parameters <b>516</b> received as device data <b>518</b> in one of an audio, visual or kinetic format <b>521</b> depending on the capabilities of the feedback device. For example, the device interface <b>517</b> may send device data/commands <b>518</b> to a display that allows a numeric value of a feedback information parameter <b>516</b> to be viewed on the display by one of the system clients <b>522</b>, such as players, coaches and spectators. As another example, a device interface <b>517</b> may send device data/commands <b>518</b> to an audio output device that allows feedback information parameters <b>516</b> to be output in an audio format to one or more of the system clients <b>522</b>.</p>
<p id="p-0128" num="0127">The feedback parameters <b>516</b> generated from the trajectory analysis software <b>513</b> and other raw data generated from the sensor system <b>502</b> may be sent to session storage <b>515</b>. The session storage <b>515</b> may accumulate trajectory data from a plurality of trajectories generated during a trajectory session for one or more players. All of a portion of the trajectory data <b>514</b> may be sent to archival storage <b>525</b> when the session has been completed. For example, only a portion of the raw data, such as video frame data, may be sent to archival storage. Further, the data may be filtered for bad data prior to being sent to archival storage <b>525</b>. The archival storage <b>525</b> may include a database used to relate trajectory data from one or more trajectory sessions to the conditions of the trajectory session, such as time place and location, and player identification information.</p>
<p id="p-0129" num="0128">The archival data <b>524</b> and session data <b>514</b> may be used to provide one or more services <b>523</b> including but not limited to 1) a session record of trajectory parameters (see <figref idref="DRAWINGS">FIG. 7</figref>), 2) session diagnostics, 3) prescription for improvement (see <figref idref="DRAWINGS">FIG. 8</figref>), 4) a history comparison of trajectory data from different sessions, 5) individual/group comparisons of trajectory session data, 6) video analysis and editing tools, 7) simulations (e.g., predicting a team's improvement based upon improving one or more members of the teams shooting skills and 8) entertainment. As an example of entertainment, a player's trajectory average trajectory parameters and variability may be used in trajectory simulations for a video basketball game or another game where the parameters have been measured. Two players that have used the system <b>100</b> may both enter their parameters and compete against one another in the video game. The player may also use the game to see how they match up against professional or collegiate athletes who have had their trajectory parameters defined.</p>
<p id="p-0130" num="0129">Output from the data services <b>523</b> may be converted to a portable record <b>527</b>, such as print-out from a printer, or may be formatted for viewing on a graphical interface <b>528</b>. The graphical interface may also include a storage capacity allowing data to be viewed at a later time. The output from the data services <b>523</b>, such as a portable record <b>527</b> or information viewed on the graphical interface <b>528</b>, may be used by the system clients <b>522</b>. The data services <b>523</b> may also be provided via a data mining interface <b>526</b>. The data mining interface <b>526</b> may include analysis tools and a graphical interface. When the archival storage is remotely accessible, it may be used to access archived data <b>524</b> via a remote connection, such as from the Internet.</p>
<p id="p-0131" num="0130">Information passed between the different components in the system as described with respect to <figref idref="DRAWINGS">FIG. 6</figref> may be transmitted using a number of different wired and wireless communication protocols. For instance, for wire communication, USB compatible, Firewire compatible and IEEE 1394 compatible hardware communication interfaces and communication protocols may be used. For wireless communication, hardware and software compatible with standards such as Bluetooth, IEEE 802.11a, IEEE 802.11b, IEEE 802.11x (e.g. other IEEE 802.11 standards such as IEEE 802.11c, IEEE 802.11d, IEEE 802.11e, etc.), IrDA, WiFi and HomeRF.</p>
<p id="p-0132" num="0131"><figref idref="DRAWINGS">FIG. 7</figref> is a shot scatter plot <b>400</b> that may be provided by a trajectory detection and analysis system. The shot scatter plot <b>400</b> shows entry velocity <b>402</b> (feet per second) versus entry angle <b>404</b> (degrees) for a plurality of different shots that were generated during a trajectory session. As was described with respect to <figref idref="DRAWINGS">FIG. 1</figref>, the entry velocity <b>402</b> and entry angle <b>404</b> are trajectory parameters that may be generated from a trajectory detection system of the present invention and provided as feedback information to the player using the system during the trajectory session.</p>
<p id="p-0133" num="0132">The basketball shots are divided into three categories, swish <b>406</b>, rim-in <b>408</b> and miss <b>410</b>. Swish shots <b>406</b> pass through hoop without touching it. Rim-in shots <b>408</b> hit the rim and then pass through the hoop. Miss shots <b>410</b> do not pass through the hoop. The plot <b>400</b> may be used to provide the player a visual record of how well they did in the session and how much entry angle and entry velocity vary from shot to shot. If the shots were all taken from the same location, such as the free throw line, then a margin error of for the shot may be gauged approximately from the figure. The margin of error can be gauged because the plots shows which combinations of entry velocity and entry angle lead to made shots and which combinations lead to missed shots.</p>
<p id="p-0134" num="0133"><figref idref="DRAWINGS">FIG. 8</figref> is an improvement map <b>420</b> that may be provided by a trajectory detection and analysis system of the present invention. The map <b>420</b> is a function of the release height of the shot, which 9 feet and 6 inches, and the average entry angle, which is 41 degrees. The improvement map <b>420</b> provides contours of a percentage of shots made as a function of velocity variability <b>414</b> and an angle variability <b>412</b>. The velocity variability <b>414</b> and angle variability <b>412</b> may be calculated as a statistical deviation generated from a plurality of shots taken during a trajectory session. As the angle variability <b>412</b> and the velocity variability <b>414</b> approach zero for a particular shot, the shooting percentage approaches 100%.</p>
<p id="p-0135" num="0134">For an initial trajectory session, a baseline <b>416</b> of velocity variability and entry angle variability is about 0.4 and 1.4 respectively. This variability pair provides for a shooting percentage in the range 40-50 percent. The improvement map <b>420</b> predicts that if the player reduces their velocity variability to about 0.2 and their angle variability to about 1, then their expected improvement <b>418</b> will be an increase in shooting percentage to about 70-80 percent from 40-50 percent.</p>
<p id="p-0136" num="0135">Using this improvement map, the player may be prescribed a series of training exercises that will improve their angle variability <b>412</b> and velocity variability <b>414</b>. If the player participates in a plurality of trajectory sessions, then angle variability and velocity variability for each session may also be plotted on the improvement map. Thus, the player can see how they are approaching their goal as a function of time. Further, the player can use the trajectory system to verify that their shooting percentage is actually increasing as their velocity variability and angle variability is decreased. Also, they can compare their actual shooting percentage with the predictions generated in the improvement map <b>420</b>.</p>
<p id="p-0137" num="0136"><figref idref="DRAWINGS">FIGS. 9A and 9B</figref> are flow charts of methods for providing trajectory detection and feedback using a trajectory detection and analysis system. In <figref idref="DRAWINGS">FIG. 9A</figref>, a method of detecting, analyzing and providing feedback information for a trajectory is described. In <b>600</b>, the system receives sensor data, such as video frame data from a camera, from the sensor system regarding the motion of an object along a trajectory. In some embodiments, the system may be capable on analyzing the trajectories of two or more objects simultaneously. In <b>606</b>, using the sensor data <b>606</b>, the system generates one or more trajectory parameters from sensor data that describe an aspect of the object's trajectory. In <b>608</b>, using the trajectory parameters, feedback information is generated. The feedback information may be one or more of the trajectory parameters or a combination of trajectory parameters. In <b>610</b>, the feedback information is provided to one or more system clients, such as a player or coach. The feedback information may be provided to the client via a feedback output mechanism, such as a sound projection device or a visual display device.</p>
<p id="p-0138" num="0137">In another embodiment, the method may also comprise generating one or more aggregate trajectory parameters, such as a statistical deviation, from the trajectory parameters from a plurality of different trajectories where the aggregate trajectory parameters characterize the human's consistency. The aggregate trajectory parameters may be a measure of statistical variability of different trajectory parameters. Thus, the method may also comprise predicting performance improvement as a function of the one or more aggregate trajectory parameters and generating a prescription comprising one or more actions for improving performance.</p>
<p id="p-0139" num="0138">In <figref idref="DRAWINGS">FIG. 9B</figref>, a method of detecting, analyzing and providing feedback information for a trajectory is described using a machine vision system. In <b>601</b>, video frame data of an object along to trajectory is recorded using one or more cameras in a machine vision system. Prior to recording the object along its trajectory, a reference frame without the object may be generated and the machine vision system may be calibrated by recording images of the object at prescribed positions relative to the one or more cameras. In <b>602</b>, the frame data captured from the one or more cameras may be digitized using a video capture card. In <b>603</b>, the position of the object in each of plurality of captured video frames may be determined. Filtering and pattern recognition methods may be applied to pick out the object in the video frames. The position of the object in each frame varies as the object travels along its trajectory. In some embodiments, two or more objects that are in flight at the same time may be captured in the video frame data and the system may be capable of determining trajectories for each of the objects.</p>
<p id="p-0140" num="0139">In <b>604</b>, a trajectory curve-fit may be generated for the object using the position data from the video frames. Using time data from each frame, the curve-fits of the object's trajectory may be generated as a function of time. Also, curve-fits of the object's height as a function of distance may also be generated. In <b>606</b>, using the curve-fits and/or the position data from the frames, trajectory parameters may be generated for the trajectory. In <b>608</b>, using the trajectory parameters, feedback information is generated. In <b>610</b>, the feedback information, via an output mechanism, is provided to one or more system clients, such as a player or coach.</p>
<p id="p-0141" num="0140"><figref idref="DRAWINGS">FIG. 10</figref> is a perspective drawing of two embodiments of basketball training systems, <b>700</b> and <b>702</b>. The basketball training systems of the present invention may use any of the embodiments of the trajectory detection, analysis and feedback systems and devices previously described herein. Thus, in <figref idref="DRAWINGS">FIG. 10</figref>, the particular embodiments of trajectory detection, analysis and feedback systems and their associated devices are provided for illustrative purposes only.</p>
<p id="p-0142" num="0141">The basketball training systems, <b>700</b> and <b>702</b>, may each comprise a playing area <b>109</b>, a basketball hoop <b>103</b>, a backboard <b>151</b> and trajectory detection, analysis and feedback system. In the basketball training system of <b>700</b>, the trajectory detection, analysis and feedback system comprises a camera <b>728</b>, an audio feedback device <b>718</b>, a visual feedback device <b>716</b> and a logic device, such as computer <b>704</b>, for performing trajectory analysis and generating feedback information. In basketball training system <b>702</b>, the trajectory detection, analysis and feedback system comprises a fixed camera <b>724</b> mounted to backboard <b>151</b>, a movable trajectory device <b>722</b> and a visual feedback device <b>716</b>. In particular embodiments, the camera <b>724</b> may be designed to allow it to be mounted in various locations, such as clipped to the backboard or mounted to the wall adjacent to the backboard. The movable trajectory device <b>722</b> may include calibration software and settings that allow different mount locations for camera <b>724</b> to be utilized.</p>
<p id="p-0143" num="0142">In <b>702</b>, the movable trajectory device <b>722</b> may comprise a camera that is used in a machine vision system, a touch screen display, a computer and a sound projection device integrated into a housing, as is described with respect to <figref idref="DRAWINGS">FIGS. 5A-5C</figref>. The sound projection device may be used to provide feedback information to the player. The movable trajectory device <b>722</b> may receive input, such as visual frame data, from the camera <b>724</b>. In one embodiment, the trajectory device <b>722</b> may use the input received from the camera <b>724</b> to determine whether a shot was made or missed.</p>
<p id="p-0144" num="0143">In a particular embodiment, the trajectory device <b>722</b> may allow a user to listen to music of their choice while using the training system. The trajectory device <b>722</b> may include a memory for storing music and programming logic for allowing a user to select music of their choice during a training session. A player's musical preferences and other preferred optional settings on the system may be stored by the system and associated with the player so that a player doesn't have to input their selection each time.</p>
<p id="p-0145" num="0144">In one embodiment, the device may include one or more input ports for downloading music onto the system from a portable device, an interface that allows a user to use a portable music device, e.g., an MP-3 player, such as an IPOD&#x2122; by Apple&#x2122; (Cupertino, Calif.) with the system, an optical disk drive for playing optical disks storing music or a communication interface allowing music to be downloaded from a remote server. During a training session, a player's musical selection may be output via a sound projection device coupled to the training system <b>702</b>. When feedback information is provided in an audio format, the feedback information and any musical output may be integrated to allow both to be discerned. For instance, when audio feedback information is provided, it may be over-laid on top of the musical output the volume of the background music or feedback information may be each adjusted up or down so that the feedback is heard. In another example, the audio feedback information may be output from a separate speaker than the music or from only one channel of a speaker system (e.g., right or left channel) when a stereo system is included.</p>
<p id="p-0146" num="0145">In another particular embodiment, the camera <b>724</b> may be used to provide additional information about a body position and body mechanics of the player utilizing the training system <b>710</b>. The camera <b>724</b> may capture a position or an alignment of a player's torso, head, arms, etc., during and/or after a shot. This information may be combined with information obtained from camera used in device <b>722</b>. The trajectory device <b>722</b> may analyze the player's body position captured from the camera <b>724</b> and/or the camera in device <b>722</b> to provide additional feedback information and/or recommendations that allow a player to improve their shooting skills. The camera <b>724</b> and/or device <b>722</b> may be positioned at different locations to capture different visual data regarding a player's body position while still providing trajectory analysis and feedback. In some embodiments, such as when the camera <b>724</b> is not present, only the camera in device <b>722</b> may be used to gather visual data for an analysis of a player's body mechanics during shooting. In other embodiments, additional cameras, besides the camera <b>724</b> and the camera in device <b>722</b> may be used.</p>
<p id="p-0147" num="0146">In analyzing a player's body mechanics, the trajectory device <b>722</b> may be used to determine a trajectory of one or more parts of the player's body during and after a shot. For example, the trajectory device <b>722</b> may determine an arc of a player's foot/or knee to determine whether the player move upwards in a vertically aligned direction or in a direction off of vertical. In another example, the trajectory device may measure an arc of a player's elbow or hand to determine whether the player's arms is imparting sideways momentum to the ball and to determine whether the player's is properly following through on the shot.</p>
<p id="p-0148" num="0147">In one embodiment, during a training session comprising a number of shots, the body positioning information determined for each shot may be correlated with information characterizing the shot, such as trajectory parameters and the feedback information derived from the trajectory parameters. Thus, after or during a training session, the trajectory device <b>722</b> may analyze the shots, group them in some manner and then determine whether there are characteristics of each group related to a player's body mechanics that distinguish one group from the other group.</p>
<p id="p-0149" num="0148">For example, during a training session, the trajectory device <b>702</b> may group a first number of shots a player has taken as good shots (e.g., shots with an arc within a proscribed range and made) and group a second number of shots as bad shots (e.g., shots with an arc out of a proscribed range that were made or missed). Then, the trajectory device <b>722</b> may compare the player's body mechanics for shots in each group to see if there are any characteristics that distinguish the shots in the good group from the shots in the bad group. For instance, in the bad group, the player may have had a poor follow through that resulted in a bad shot.</p>
<p id="p-0150" num="0149">Information related to their shooting mechanics may be provided in some format to the player. For example, a player may be shown visual output for different shots in a side-by-side manner, in series (one shot, then another shot) or one on top of the other (e.g., overlaid) by making using graphical techniques to make one of the shots semi-transparent. When the shots have been grouped in some manner, then one shot from a first group and one shot from a second group may be shown for comparison. In addition, shot comparison may be shown for two or more shots made by a single player and also for two or more shots made by different players. For instance, a player may be able to compare their shot with the shot of one of their favorite professional players. The shots compared and output by the system may be for shots made during a current or previous training session using the training system.</p>
<p id="p-0151" num="0150">The visual display device <b>716</b> or a display device on <b>722</b> may be used to display a comparison of the different shots. From the comparison, differences in the player's biomechanics between the shots may be evident. When the trajectory device has performed an analysis and determined a biomechanical difference between the shots, such as a poor follow through for shots in one group versus a good follow through for shots in another group, the differences may be illustrated on the display with additional graphics added to the previously captured visual data. For instance, the visual recording of the player's hand or arm may be highlighted with additional graphics, such as an added arc that follows the motion of the player's hand, to illustrate what is good or not good about the player's follow through.</p>
<p id="p-0152" num="0151">The categorization of shots into groups, such as &#x201c;good&#x201d; shots and &#x201c;bad&#x201d; shots, may be also used to illustrate a player's training progress. During a training session or over multiple training sessions, utilizing the feedback information generated by the trajectory device <b>722</b>, a player's biomechanics may naturally improve as they learn what a &#x201c;good&#x201d; shot feels like using the feedback information. Thus, the player may take more &#x201c;bad&#x201d; shots earlier in a session or in previous sessions using the device and then later improve to make more &#x201c;good&#x201d; shots. From a current and/or previous training sessions, the trajectory device <b>722</b> may categorize various shots and then show a comparison of shots from different groups, such as one or more &#x201c;good&#x201d; shots and one or more a &#x201c;bad&#x201d; shots. The player, coach or a trainer may be able to identify an improvement in their mechanics by visually comparing the selected &#x201c;good&#x201d; and &#x201c;bad&#x201d; shots.</p>
<p id="p-0153" num="0152">The trajectory system <b>702</b> may be operable to output the visual comparison to a visual display device coupled to the system or a printer. In addition, the trajectory system may be operable to store visual data to a DVD or some other optical storage device. Further, the trajectory system <b>702</b> may be operable to store it to a local/remote memory for archival purposes, store it to a portable storage device, such as a thumb drive (e.g., portable hard drive or flash drive), to e-mail to a specified e-mail address or the like.</p>
<p id="p-0154" num="0153">The criteria used to group good and bad shots is variable and may depend on one or more different trajectory parameters and their combinations as well as an analysis of a player's shooting mechanics and is not limited to the examples described above, which are provided for illustrative purposes. Thus, in some instances, a made shot with a good arc may be categorized a &#x201c;bad&#x201d; shot because of a player's poor shooting mechanics. Conversely, in other instances, a missed shot may be categorized as a &#x201c;good&#x201d; shot, because the shot had a good arc and the player used good shooting mechanics.</p>
<p id="p-0155" num="0154">As described above, in some instances, the trajectory device <b>722</b> may perform an analysis of the player's biomechanics (shooting mechanics) in each shot an attempt to identify differences that led to the improvement and when the trajectory device <b>722</b> has identified differences, these may be illustrated graphically in some manner as part of the visual output. Further, the trajectory device <b>722</b> may use an analysis of a player's biomechanics to prescribe exercises or drills that could improve a player's shot. For example, the trajectory device <b>722</b> determines a player's biomechanics are off in some manner, such as a player is not following through properly on a shot with their hand or some other part of their body is moving in a less than optimal manner, then the trajectory device may recommend exercises to improve the player's determined deficiency.</p>
<p id="p-0156" num="0155">A prescribed exercise to improve an identified proficiency of a player may or may not involve shooting. In the case of shooting, the trajectory device <b>722</b> may be programmed with various exercises. The programmed exercises may comprise types of shots jump, set or bank, distance of shots (e.g., 5 ft, 10 ft, free throw line, under the rim, from the side, etc.), number of shots, etc. For example, a prescribed shooting exercise might comprise 5 jump shots from the free throw line, followed by 5 set shots from the 3-point line. In regards to systems <b>700</b> and <b>702</b>, details of shooting programs are described in further detail below.</p>
<p id="p-0157" num="0156">Returning to <figref idref="DRAWINGS">FIG. 10</figref>, the trajectory device <b>722</b>, may be coupled via a wired or wireless communication links to the backboard mounted camera <b>724</b> and visual feedback device <b>716</b>. Further, the trajectory device <b>702</b> may include a communication interface or a mechanism for connecting to a communication interface that allows the trajectory device <b>702</b> to communicate with other trajectory detection, analysis and feedback systems, such as the system associated with training system <b>700</b>.</p>
<p id="p-0158" num="0157">Basketball training systems <b>700</b> and <b>702</b> may include bounding structures, such as <b>710</b>, around the circumference of the playing areas <b>109</b>. Although not shown, the bounding structures <b>710</b> may surround the playing areas <b>109</b> on four sides to form a rectangular box-like shape. The structures <b>710</b> may be secured in a fixed location and relatively rigid (e.g., like the walls of a racquet ball court) or removable and flexible made of various suitable materials, including materials that absorb impact. In particular embodiments, removable netting, curtains, partition walls with wheels, may surround a portion of or the entire circumference of the playing areas <b>109</b>. Thus, for example, using movable curtains, a standard size basketball court may be partitioned into many smaller areas to allow the use of multiple basketball training systems and then later converted back to a standard size basketball court for game play.</p>
<p id="p-0159" num="0158">An impact absorbent material may include padding to absorb an impact of a player or when the training system is adaptable for other sports, such as golf or baseball. The material may be designed to absorb impact of these objects, golf balls or baseballs, hitting the wall. Further, the material may designed to prevent ricochets of these objects from hitting the wall and then striking a player.</p>
<p id="p-0160" num="0159">The dimensions, width <b>712</b> and length <b>714</b>, of the basketball training area <b>109</b> may be significantly smaller than the length and width of a standard basketball court which is 84-94 feet long and 50 feet wide. For example, in <figref idref="DRAWINGS">FIG. 10</figref>, the length <b>714</b>, may be proximately 26 feet which allows a pro 3-point shot of 23.75 feet to be taken and the width may be about 14 feet which is wider than the 12 ft lane of a basketball of a standard basketball court. Smaller or larger playing areas <b>109</b> with their associated dimensions may also be used and the present invention is not limited to the previous example. The lines of a standard basketball court, such as the free throw line which is 15 feet from the backboard <b>151</b> and 3 feet from the front of the rim may be also be incorporate as part of the playing areas <b>109</b>.</p>
<p id="p-0161" num="0160">In one embodiment, the width <b>712</b> doesn't have to be centered evenly on each side the basket <b>103</b>. For example, on one side of the basket, the width <b>712</b> may be just larger than the lane, while on the other side of the basket <b>103</b>, the width <b>712</b> may extend to the dimensions of a standard basketball. These asymmetric dimensions may allow shots to be taken from one side of the basket <b>103</b> that are of any length available on a standard basketball court. On the opposite side of the basket <b>103</b> some shots of a length available on a standard basketball court may not be available.</p>
<p id="p-0162" num="0161">In the case where the width <b>712</b> of the playing area is significantly narrower than the width of a standard basketball court, in one embodiment of the present invention, the basketball training systems may include a rotation device <b>720</b>. The rotation device <b>720</b> may be coupled to the backboard and its associated support in a manner that allows the backboard <b>151</b> and basket to be rotated between 0 and 90 degrees in one direction or between 0 and 90 degrees in two directions. The training systems, <b>700</b> and <b>702</b>, may include input devices, such as a touch screen display, that allows an operator to select a shot program that includes or doesn't include a rotation of the backboard <b>151</b> during a training session.</p>
<p id="p-0163" num="0162">The rotation device <b>720</b> may also be coupled to the backboard and its associated support in a manner that allows the backboard <b>151</b> and basket to be rotated between 0 and 90 degrees while keeping the position of the hoop constant, thus having the center of rotation being the center of the hoop. When a player moves around a hoop, the hoop remains in a fixed position. Thus, a better simulation of shooting on full-sized basketball court may be provided by rotating the backboard <b>151</b> in a manner that allows the hoop <b>103</b> to maintain a constant position in space as the backboard rotates. In one embodiment, a rotation through the center of the hoop <b>103</b> may be generated by placing the rotation mechanism <b>720</b> above the backboard with its axis of rotation through a center of the hoop <b>103</b> and then providing a connector bar of some shape from the axis of rotation of the rotation mechanism <b>720</b> to the back board <b>151</b>. In this embodiment, when the rotation mechanism <b>720</b> is engaged, the position of the hoop <b>103</b> will appear to remain constant because the hoop <b>103</b> and the backboard <b>151</b> rotate around the center of the hoop <b>103</b>.</p>
<p id="p-0164" num="0163">The rotation device may be coupled to a logic device utilized by the training systems <b>700</b> and <b>702</b>, such that the backboard <b>151</b> and goal <b>103</b> are rotated automatically during a training session on the training systems. When the backboard and basket are rotate, the training systems are operable to perform trajectory analysis and provide feedback information while accounting for the changing orientation of the backboard <b>151</b> and basket <b>103</b> as a function of time. At start-up and/or during operation, the training systems may perform calibration functions with the backboard and basket <b>103</b> at different positions to check if the system is properly set-up.</p>
<p id="p-0165" num="0164">Besides rotation, the backboard may be capable of vertical motion. For instance, for younger players, the mechanism <b>720</b> may also allow the backboard <b>151</b> and basket <b>103</b> to be lowered. Further, young players may use a smaller ball. Thus, the training systems, <b>700</b> and <b>702</b>, may be operable to provide trajectory analysis and feedback for basketball hoops at various heights, at changing angles and for balls of different sizes.</p>
<p id="p-0166" num="0165">In particular embodiments, the basketball training systems <b>700</b> and <b>702</b> may include ball return mechanisms. The ball return mechanism may be a passive device that alters the momentum but doesn't add to the momentum that the basketball possesses when it reaches the device. For instance, the curved ramp <b>706</b> alters the momentum of a basketball, such as <b>160</b>, such that it is directed away from the basket <b>103</b>. As shown in the figure, the curved ramp <b>706</b> won't typically alter the trajectory of basketball if it is a missed shop. Other passive devices, such as netting, may be employed to direct a ball away from the basket <b>103</b> for missed shots.</p>
<p id="p-0167" num="0166">The ball return mechanism may also be an active device that adds momentum to balls and directs them toward a player. For instance, in training system <b>702</b>, an active ball return device <b>740</b> is used that receives both made and missed shots and then shoots out a basketball. The ball return mechanism <b>740</b> may be operable to hold a plurality of basketballs.</p>
<p id="p-0168" num="0167">The ball return mechanism <b>740</b> is coupled to netting <b>708</b> that directs both missed and made shots to the ball return mechanism. One advantage of using a playing area <b>109</b> that is smaller than a standard basketball court with bounding structures <b>710</b> around the perimeter of the playing area <b>109</b> is that the bounding structures <b>710</b> constrain the balls allowing the netting <b>708</b> to be placed below the backboard <b>151</b>. Without the bounding structures to constrain the balls, such as on a full-size court, the netting <b>710</b> has to be placed higher than the hoop to capture a majority of missed shots. When netting is higher than hoop, it blocks the player's view and it doesn't simulate actual playing conditions which is undesirable to players. Another advantage of a smaller playing area is that it allows more training systems to be utilized in a smaller area, which may be more economically and advantageous for facilities that are space constrained. For example, 4 training systems might be placed in the width of a standard basketball court and its sidelines.</p>
<p id="p-0169" num="0168">In one embodiment, the ball return mechanism may include controls that allow the ball to be returned to different spots on the playing area <b>109</b>. For instance, the device <b>740</b> may be coupled to a motor that allows the device to be rotated and/or elevated to direct balls to different locations. Similar, to the rotation device <b>720</b>, in some embodiments, the location where the ball is passed may be automatically controlled by the training system <b>702</b> as part of a shooting program or the location may be manually adjusted. The active ball return feature may allow the player to perform &#x201c;catch&#x201d; and &#x201c;shoot&#x201d; exercises during their training session where the player receives a &#x201c;pass&#x201d; from the return device <b>740</b> at one or more different locations on the playing area and then shoots after receiving the pass.</p>
<p id="p-0170" num="0169">The training systems, <b>700</b> and <b>702</b>, as part of training session, may be operable to direct a player to particular locations on the playing areas <b>109</b> as part of a shot program. As an example, as part of a shooting program, the trajectory systems, <b>700</b> and <b>702</b>, may direct players to locations <b>730</b>, <b>734</b>, <b>736</b> and <b>738</b>. The player may take one or more shots at each of these locations as part of a shooting program.</p>
<p id="p-0171" num="0170">A number of different methods may be used to direct a player to different locations. In one embodiment, locations on the playing areas <b>109</b> may be marked in some manner, for instance, each of the circles <b>730</b>, <b>734</b>, <b>736</b> and <b>738</b> may be painted a different color or painted with a number and the training system may provide an audio command, such as &#x201c;blue,&#x201d; &#x201c;free throw line,&#x201d; &#x201c;3-point line,&#x201d; or &#x201c;one,&#x201d; to direct a player to a particular location. In another embodiment, a visual display device such as <b>716</b> may include a map of the playing area. When the player is directed to change location, a sound or command, such as &#x201c;change location&#x201d; may be output via a sound projection device and then a location on the map of the playing area may be indicated in some manner.</p>
<p id="p-0172" num="0171">In yet another embodiment, lights may be integrated into the floor of the playing areas <b>109</b>. For example, lights may be integrated at locations <b>730</b>, <b>734</b>, <b>736</b> and <b>738</b>. These lights may light up under control of the training system to indicate different shooting locations. In a particular embodiment, the training systems may include a movable spotlight or a projection device, such as <b>728</b>, that projects visible light or an image to certain locations on the playing area <b>109</b>, such as <b>730</b>, <b>734</b>, <b>736</b> and <b>738</b>. The training systems may automatically control the movable spotlight or projection device(s) as part of a shooting program.</p>
<p id="p-0173" num="0172">The training systems, <b>700</b> and <b>702</b>, may be operable to determine whether a player is shooting from a particular location. For example, when a machine vision system is used for the trajectory analysis and feedback, the machine vision location may be also used to determine from which the location the player has shot on the playing surface. As another example, the playing area may include sensors for detecting a player's location, such as an integrated pressure sensor or a light sensor that is activated when it is partially covered by a player's foot. In addition, the player may wear a device, such as a wireless device that allows their location on the player area <b>109</b> to be determined.</p>
<p id="p-0174" num="0173">The system may also be operable to compare the player's actual location (determined by the system) with a location where the player is supposed to be located as part of a shooting program. The location detection system may look for the player's feet to be within and/or touching a circle of some specified radius. When the player's actual location is different from the location from where they are supposed to be located as part of a shooting program the system may output instructions or information, such as &#x201c;not at specified location.&#x201d; If the system is scoring the player's performance in a shooting program, then shots from incorrect locations may affect the player's score. The locator function may or may not be active as part of a shooting program.</p>
<p id="p-0175" num="0174">As part of a shooting program, a player may be able to compete against one or more players in a tournament. The training systems <b>700</b> and <b>702</b>, which may be systems at the same or different locations, i.e., at the same facility, such as a gym or at different facilities, such as different gyms in different cities, may be operable to send data to other training systems and receive data from other training systems. The training systems <b>700</b> and <b>702</b> may be operable to communicate with one another and other training systems or another device providing remote communications via a local area network or a wide area network, such as the Internet. Thus, in particular embodiments, each system may include a network communication interface that allows for one of a wired or wireless connection to one or more of the local area network or the wide area network.</p>
<p id="p-0176" num="0175">In one embodiment, two or more players may start a shooting program at the same time, which is scored in some manner. For example, a player may be awarded points for shots made as well as an amount of time taken to complete the drill. In <figref idref="DRAWINGS">FIG. 10</figref>, player &#x201c;A&#x201d; using system <b>700</b> is competing against player &#x201c;B&#x201d; using system <b>702</b> and each system is sending data to one another. In the <figref idref="DRAWINGS">FIG. 10</figref>, a time left and a score for their competition is shown on the visual displays <b>716</b>.</p>
<p id="p-0177" num="0176">To generate a competition, two or more players don't necessarily have to use a training system at the same time. For example, a first player may participate in a shooting program where there results are recorded, such score as a function of time. Later, a second player may compete against the first player using their recorded data and the same shooting program that the first player used. As the second player goes through the same shooting program as the first player and generates a score, the first player's scores at corresponding times may also be shown. Using this approach, a player may also compete against themselves by repeating a shooting program and competing against results of the shooting program that they have previously generated.</p>
<p id="p-0178" num="0177">The competition results may be shown on the visual display <b>716</b>. In one embodiment, the system may store an archive of top &#x201c;scores&#x201d; or player's of interest, such as &#x201c;pro&#x201d; players that a player can compete against. Further, the systems may be operable to allow players to compete over time or against one another in a league type format.</p>
<p id="p-0179" num="0178">In other embodiment, the backboard and basketball may be replaced with images projected onto the wall of the bounding structures <b>710</b> and into air, i.e., space between the bounding structures. The system may include blank walls and floors that are suitable for image projection. For projecting into the space between the bounding structures, a number of technologies exist. For instance, IO2 technology (S. San Francisco, Calif.) provides a &#x201c;helio&#x201d; display that allows an image to be displayed on a &#x201c;sheet&#x201d; of compressed air. Thus, various compressors for providing sheets of air at different location may be integrated into the system. A sheet of compressed air at the height of basket <b>103</b> in combination with a projector may be used to generate a projection of a hoop that a player may use as a target. Technology for generating 3-D spots of plasma in air has also been demonstrated by <i>The National Institute of Advanced Industrial Science and Technology</i>, in Japan.</p>
<p id="p-0180" num="0179">Using the &#x201c;helio&#x201d; display or plasma generation technology or some other suitable projection technology, a hoop may be generated in 3-D space and lines on a backboard projected on to one wall. The player may shoot the ball towards this projected hoop where the system is operable to determine whether the ball has passed through the hoop or not. A missed shot may be result in a projection of a rebound from the hoop projected into to space while the &#x201c;physical&#x201d; ball bounces to the ground. Further, an audience may be simulated on the walls and other players to provide a more authentic experience.</p>
<p id="p-0181" num="0180">In another embodiment, a player may where goggles or head gear that project images or lines into space. These images or lines integrated into a player's field of view. Thus, a virtual basketball and backboard may be projected into the player's field of vision and the player may shoot the ball towards the image projected using the goggles. The goggles may be used in conjunction with head and/or eye tracking to provide a player with the proper views. For instance, wearing the goggles, the player may turn away from the virtual basketball hoop and the image of the hoop will no longer be displayed to the player. This type of application may also be referred to as a &#x201c;mixed&#x201d; reality. Mixed Reality is the merging of real world and virtual worlds to produce a new environment where physical and digital objects can co-exist and interact.</p>
<p id="p-0182" num="0181">Using a projection and/or goggle system, the basketball training system may be easily adapted to other sports. For instance, a virtual hoop or hoops could be used as targets for football training system. A similar environment could be used for pitching a baseball, fielding a baseball and throwing to first base, hitting a baseball from a pitching machine, throwing a pass, hitting a tennis serve, hitting a volleyball serve or spike, etc. The first base or running receiver/defenders or tennis net/lines or volleyball net/lines would be 3-D projections. Further, physical games may be played in this generic environment against competitors that are virtual (computer generated or real people over the network.) The trajectory analysis and feedback system may provide the trajectory of the object, thus providing feedback for training or calculating gaming expertise for scoring. The system may allow data to be stored and retrieved or displayed to an audience.</p>
<p id="p-0183" num="0182">Although the foregoing invention has been described in some detail for purposes of clarity of understanding, it will be apparent that certain changes and modifications may be practiced within the scope of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system comprising:
<claim-text>a basketball including a sensor system, disposed within the basketball, for measuring motions of the basketball wherein the sensor system includes a first wireless interface for sending sensor data related to the motions of the basketball to an electronic device;</claim-text>
<claim-text>the electronic device including a processor and a memory and a second wireless interface for receiving the sensor data, said processor configured to 1) receive sensor data for a plurality of repeated motions of the basketball, 2) based upon the received sensor data, generate one or more parameters that characterize the plurality of repeated motions, 3) based upon the one or more parameters, generate feedback information that is used to characterize a skill of a person at generating the repeated motions and 4) output the feedback information wherein, when the repeated motions are a plurality of basketball shots, an angle of the trajectory of each of the plurality of basketball shots relative to a plane of a basketball hoop when the basketball is proximate to the basketball hoop is determined from the received sensor data associated with each shot and the feedback information is based upon the determined angles.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the repeated motions are shots towards a basketball hoop.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor system includes an accelerometer.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor system including one or more sensors for measuring a rotation rate of the basketball.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor system includes a power interface for receiving power wirelessly.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor system includes a microprocessor configured to process the sensor data.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is configured to generate and output the feedback information after a completion of the training exercise.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is configured to receive the sensor data for a portion of the plurality repeated motions while the motions are being performed, generate the one or more parameters based upon only the portion and output the feedback information while the repeated motions are being performed.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein after the sensor data for the portion of the plurality of repeated motions is received, the electronic device is configured to receive additional sensor data and generate the one or more parameters based upon the portion and the additional sensor data.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is configured to receive simultaneously first sensor data from a first basketball and second sensor data from a second basketball, generate first one or more parameters based upon the first sensor data and second one or more parameters based upon the sensor data, generate first feedback information based upon the first one or more parameters and the second feedback information based upon the second one or more parameters.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein during each of the repeated motions, the basketball is in contact with a hand of the person during a first part of the motion and not in contact with the hand of the person during a second part of the motion and wherein the one or more parameters characterize the second part of the motion.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more parameters include an average speed of the basketball during the repeated motions.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more parameters include an average rotation rate of the basketball during the repeated motions.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more parameters include an average angle associated with a direction in which the basketball travels during the repeated motions.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is further configured to generate the one or more parameters and the feedback information based upon on only one of the repeated motions.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is further configured to determine a training exercise for improving their skill at performing the repeated motions and output information related to the training exercise as part of the feedback information.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is further configured to generate a score based upon the one or more parameters wherein the feedback information includes the score.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is configured to generate a trajectory of the basketball during one of the repeated motions and output the trajectory.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising: an image capture device for capturing one or more images of the person while the person is performing the training exercise.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the feedback information is related to how consistent is the person at generating the repeated motions.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising: a display for outputting the feedback information.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The system of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the display is a touch screen display.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the repeated motions are part of a training exercise.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the feedback information includes information for helping the person to improve their skill at generating the repeated motions.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is a portable computer system.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. A system comprising:
<claim-text>a basketball including a sensor system, disposed within the basketball, for measuring motions of the basketball wherein the sensor system includes a first wireless interface for sending sensor data related to the motions of the basketball to an electronic device;</claim-text>
<claim-text>the electronic device including a processor and a memory and a second wireless interface for receiving the sensor data, said processor configured to 1) receive sensor data for a plurality of repeated motions of the basketball, 2) based upon the received sensor data, generate one or more parameters that characterize the plurality of repeated motions, 3) based upon the one or more parameters, generate feedback information that is used to characterize a skill of a person at generating the repeated motions and 4) output the feedback information wherein, when the repeated motions are a plurality of basketball shots, a velocity of the basketball at one or more trajectory locations near the basketball hoop, including trajectory locations after the basketball enters the basketball hoop, is determined from the received sensor data associated with each basketball shot and the feedback information is based upon the determined velocities.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
