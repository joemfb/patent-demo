<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624835-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624835</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12709451</doc-number>
<date>20100219</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>485</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>68</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345156</main-classification>
<further-classification>345173</further-classification>
<further-classification>345175</further-classification>
<further-classification>345157</further-classification>
<further-classification>345179</further-classification>
<further-classification>250221</further-classification>
<further-classification>702153</further-classification>
<further-classification>178 1809</further-classification>
<further-classification>178 1905</further-classification>
</classification-national>
<invention-title id="d2e53">Interactive input system and illumination system therefor</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5448263</doc-number>
<kind>A</kind>
<name>Martin</name>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6141000</doc-number>
<kind>A</kind>
<name>Martin</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6337681</doc-number>
<kind>B1</kind>
<name>Martin</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6747636</doc-number>
<kind>B2</kind>
<name>Martin</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6803906</doc-number>
<kind>B1</kind>
<name>Morrison et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6972401</doc-number>
<kind>B2</kind>
<name>Akitt et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7202860</doc-number>
<kind>B2</kind>
<name>Ogawa</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7232986</doc-number>
<kind>B2</kind>
<name>Worthington et al.</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7236162</doc-number>
<kind>B2</kind>
<name>Morrison et al.</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7274356</doc-number>
<kind>B2</kind>
<name>Ung et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7532206</doc-number>
<kind>B2</kind>
<name>Morrison et al.</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2005/0178953</doc-number>
<kind>A1</kind>
<name>Worthington et al.</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>250221</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2009/0213093</doc-number>
<kind>A1</kind>
<name>Bridger</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345175</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2009/0277694</doc-number>
<kind>A1</kind>
<name>Hansen et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2010/0097353</doc-number>
<kind>A1</kind>
<name>Newton</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345175</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2010/0103143</doc-number>
<kind>A1</kind>
<name>Newton et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345175</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>WO</country>
<doc-number>2004/042648</doc-number>
<kind>A2</kind>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>WO</country>
<doc-number>2009/135313</doc-number>
<kind>A1</kind>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>U.S. Appl. No. 61/294,831, entitled &#x201c;Interactive Input System and Tool Tray Therefor&#x201d;, filed Jan. 13, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>U.S. Appl. No. 61/294,827, entitled &#x201c;Housing Assembly for Interactive Input System and Fabrication Method&#x201d;, filed Jan. 13, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>U.S. Appl. No. 61/294,832, entitled &#x201c;Interactive Input System and Illumination System Therefor&#x201d;, filed Jan. 14, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>Transmittal; Written Opinion of the International Searching Authority; and the International Search Report for international Application No. PCT/CA2011/000037, with a mailing date of.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>24</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345156-157</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345173-179</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345221</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>178 1801- 1809</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>178 1905</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>257 98</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>250221</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>702153</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61294825</doc-number>
<date>20100113</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110169727</doc-number>
<kind>A1</kind>
<date>20110714</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Akitt</last-name>
<first-name>Trevor Mitchell</first-name>
<address>
<city>Calgary</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Akitt</last-name>
<first-name>Trevor Mitchell</first-name>
<address>
<city>Calgary</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Katten Muchin Rosenman LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>SMART Technologies ULC</orgname>
<role>03</role>
<address>
<country>CA</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lao</last-name>
<first-name>Lun-Yi</first-name>
<department>2692</department>
</primary-examiner>
<assistant-examiner>
<last-name>Siddiqui</last-name>
<first-name>MD Saiful A</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An interactive input system includes at least one illumination source emitting radiation into a region of interest; at least one imaging assembly capturing image frames of the region of interest, the at least one illumination source being in the field of view of the at least one imaging assembly; and a controller communicating with the at least one illumination source, the controller controlling the intensity of radiation emitted by the at least one illumination source during image frame capture.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="172.64mm" wi="206.50mm" file="US08624835-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="219.03mm" wi="159.43mm" file="US08624835-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="222.50mm" wi="184.32mm" orientation="landscape" file="US08624835-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="236.22mm" wi="164.68mm" orientation="landscape" file="US08624835-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="222.84mm" wi="155.96mm" file="US08624835-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="227.75mm" wi="176.61mm" orientation="landscape" file="US08624835-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="200.49mm" wi="168.23mm" orientation="landscape" file="US08624835-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="216.58mm" wi="179.41mm" file="US08624835-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="191.35mm" wi="165.78mm" file="US08624835-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims the benefit of U.S. Provisional Application No. 61/294,825 to Akitt filed on Jan. 13, 2010, entitled &#x201c;INTERACTIVE INPUT SYSTEM AND ILLUMINATION SYSTEM THEREFOR&#x201d;, the content of which is incorporated herein by reference in its entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates to an interactive input system and to an illumination method therefor.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Interactive input systems that allow users to inject input (e.g. digital ink, mouse events, etc.) into an application program using an active pointer (e.g., a pointer that emits light, sound or other signal), a passive pointer (e.g., a finger, cylinder or other object) or other suitable input device such as for example, a mouse or trackball, are well known. These interactive input systems include but are not limited to: touch systems comprising touch panels employing analog resistive or machine vision technology to register pointer input such as those disclosed in U.S. Pat. Nos. 5,448,263; 6,141,000; 6,337,681; 6,747,636; 6,803,906; 7,232,986; 7,236,162; 7,274,356; and 7,532,206 assigned to SMART Technologies ULC of Calgary, Alberta, Canada, assignee of the subject application, the contents of which are incorporated by reference in their entirety; touch systems comprising touch panels employing electromagnetic, capacitive, acoustic or other technologies to register pointer input; tablet personal computers (PCs); laptop PCs; personal digital assistants (PDAs); and other similar devices.</p>
<p id="p-0005" num="0004">Above-incorporated U.S. Pat. No. 6,803,906 to Morrison, et al., discloses a touch system that employs machine vision to detect pointer interaction with a touch surface on which a computer-generated image is presented. A rectangular bezel or frame surrounds the touch surface and supports digital imaging devices at its corners. The digital imaging devices have overlapping fields of view that encompass and look generally across the touch surface. The digital imaging devices acquire images looking across the touch surface from different vantages and generate image data. Image data acquired by the digital imaging devices is processed by on-board digital signal processors to determine if a pointer exists in the captured image data. When it is determined that a pointer exists in the captured image data, the digital signal processors convey pointer characteristic data to a master controller, which in turn processes the pointer characteristic data to determine the location of the pointer in (x,y) coordinates relative to the touch surface using triangulation. The pointer coordinates are conveyed to a computer executing one or more application programs. The computer uses the pointer coordinates to update the computer-generated image that is presented on the touch surface. Pointer contacts on the touch surface can therefore be recorded as writing or drawing or used to control execution of application programs executed by the computer.</p>
<p id="p-0006" num="0005">U.S. Pat. No. 6,972,401 to Akitt, et al., assigned to SMART Technologies ULC, the content of which is incorporated herein by reference in its entirety, discloses an illuminated bezel for use in a touch system such as that disclosed in above-incorporated U.S. Pat. No. 6,803,906. The illuminated bezel comprises infrared (IR) light emitting diodes (LEDs) that project infrared light onto diffusers. The diffusers in turn, diffuse the infrared light so that the intensity of backlighting provided over the touch surface by the illuminated bezel is generally even across the surfaces of the diffusers. As a result, the backlight illumination provided by the bezel appears generally continuous to the digital cameras. Although this illuminated bezel works very well, it adds cost to the touch system.</p>
<p id="p-0007" num="0006">U.S. Pat. No. 7,202,860 to Ogawa discloses a camera-based coordinate input device that allows coordinate input using a pointer or finger. The coordinate input device comprises a pair of cameras positioned in the upper left and upper right corners of a display screen. The field of view of each camera extends to a diagonally opposite corner of the display screen in parallel with the display screen. Infrared light emitting diodes are arranged close to the imaging lens of each camera and illuminate the surrounding area of the display screen. An outline frame or bezel is provided on three sides of the display screen. A narrow-width retro-reflection tape is arranged near the display screen on the outline frame. A non-reflective reflective black tape is attached to the outline frame along and in contact with the retro-reflection tape. The retro-reflection tape reflects the light from the infrared light emitting diodes allowing the reflected light to be picked up by the cameras as a strong white signal. When a user's finger is placed proximate to the display screen, the finger appears as a shadow over the image of the retro-reflection tape.</p>
<p id="p-0008" num="0007">U.S. Patent Application Publication No. 2009/0277694 to Hansen, et al., assigned to SMART Technologies ULC, the content of which is incorporated herein by reference in its entirety, discloses an interactive input system comprising a bezel surrounding a region of interest. The bezel has a plurality of adjacent bands with different optical properties, typically at least an IR light absorbing band and an IR retro-reflecting band. Imaging devices look into the region of interest from different vantages and capture images. IR light sources located near the imaging devices provide illumination to the bezel. The IR absorbing bands appear dark to the imaging devices whereas the IR retro-reflecting bands appear bright to the imaging devices. When a pointer is positioned in the region of interest, the pointer appears as a dark region interrupting a generally continuous bright band corresponding to the IR retro-reflecting material. To reduce the effects of unwanted light, the discontinuity of light over both the IR absorbing and the IR retro-reflecting bands is measured to detect the existence of a pointer.</p>
<p id="p-0009" num="0008">Although the above interactive input systems that employ retro-reflecting material work well, problems are encountered when the field of view of one or both of the imaging devices sees the other imaging device and/or its proximate IR light source. This issue worsens when additional imaging devices are employed. As will be appreciated, as additional imaging devices are added, the probability that imaging devices and IR light sources will be within the fields of view of other imaging devices increases. Since the imaging devices appear as dark discontinuities along otherwise bright bands corresponding to the retro-reflective material, a possibility exists that imaging devices may falsely be detected as pointers. Additionally, IR light sources directly visible to an imaging device will saturate pixel values and cause &#x2018;blooming&#x2019; where the values of adjacent pixels will become corrupt. If a pointer happens to move into the field of view of an imaging device across a corrupted region of pixels, the corrupted region of pixels may deform the shape of the pointer causing inaccuracies. As will be appreciated, improvements are desired.</p>
<p id="p-0010" num="0009">It is therefore an object of the present invention to provide a novel interactive input system and illumination method therefor.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0011" num="0010">Accordingly, in one aspect there is provided an interactive input system comprising at least one illumination source emitting radiation into a region of interest; at least one imaging assembly capturing image frames of said region of interest, said at least one illumination source being in the field of view of said at least one imaging assembly; and a controller communicating with said at least one illumination source, said controller controlling the intensity of radiation emitted by said at least one illumination source during image frame capture.</p>
<p id="p-0012" num="0011">In one embodiment, the intensity of radiation emitted by the at least one illumination source during image frame capture is reduced to a level approximating the background in image frames captured by the at least one imaging device. The interactive input system in one form comprises a plurality of imaging assemblies capturing images of the region of interest from different vantages, at least one illumination source adjacent each imaging assembly and a controller for each illumination source. The controller is responsive to its associated imaging assembly during image frame capture thereby to illuminate generally fully the associated illumination source and is responsive to its associated imaging assembly during image frame capture by other imaging assemblies to illuminate the associated illumination source at a reduced level.</p>
<p id="p-0013" num="0012">In one embodiment, the region of interest is generally rectangular, imaging assemblies are positioned adjacent at least two corners of said region of interest, and an illumination source is positioned adjacent each imaging assembly. A retro-reflective bezel surrounds the region of interest.</p>
<p id="p-0014" num="0013">According to another aspect there is provided a method of controlling image capture in an interactive input system, the method comprising causing at least one illumination source to emit radiation into a region of interest; causing at least one imaging assembly to capture image frames of said region of interest, said at least one illumination source being in the field of view of said at least one imaging assembly; and controlling the intensity of radiation emitted by said at least one illumination source during image frame capture.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0015" num="0014">Embodiments will now be described more fully with reference to the accompanying drawings in which:</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic, partial perspective view of an interactive input system.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of the interactive input system of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of an imaging assembly forming part of the interactive input system of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. 4</figref><i>a </i>and <b>4</b><i>b </i>are front and rear perspective views of a housing assembly forming part of the imaging assembly of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a circuit diagram of a strobe circuit forming part of the imaging assembly of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram of a master controller forming part of the interactive input system of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 7</figref><i>a </i>is a simplified exemplary image frame captured by the imaging assembly of <figref idref="DRAWINGS">FIG. 3</figref> when the IR LEDs associated with other imaging assemblies of the interactive input system are in an off state.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 7</figref><i>b </i>is a simplified exemplary image frame captured by the imaging assembly of <figref idref="DRAWINGS">FIG. 3</figref> when the IR LEDs associated with other imaging assemblies of the interactive input system are in a low current on state.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 8</figref> is a timing diagram showing when each imaging assembly of the interactive input system of <figref idref="DRAWINGS">FIG. 1</figref> has its respective illumination sources active in order to capture illuminated image frames.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE EMBODIMENTS</heading>
<p id="p-0025" num="0024">Turning now to <figref idref="DRAWINGS">FIGS. 1 and 2</figref>, an interactive input system that allows a user to inject input such as digital ink, mouse events etc. into an application program executed by a computing device is shown and is generally identified by reference numeral <b>20</b>. In this embodiment, interactive input system <b>20</b> comprises an interactive board <b>22</b> mounted on a vertical support surface such as for example, a wall surface or the like. Interactive board <b>22</b> comprises a generally planar, rectangular interactive surface <b>24</b> that is surrounded about its periphery by a bezel <b>26</b>. An ultra-short throw projector (not shown) such as that sold by SMART Technologies ULC under the name Miata&#x2122; is also mounted on the support surface above the interactive board <b>22</b> and projects an image, such as for example a computer desktop, onto the interactive surface <b>24</b>.</p>
<p id="p-0026" num="0025">The interactive board <b>22</b> employs machine vision to detect one or more pointers brought into a region of interest in proximity with the interactive surface <b>24</b>. The interactive board <b>22</b> communicates with a general purpose computing device <b>28</b> executing one or more application programs via a universal serial bus (USB) cable <b>30</b>. General purpose computing device <b>28</b> processes the output of the interactive board <b>22</b> and adjusts image data that is output to the projector, if required, so that the image presented on the interactive surface <b>24</b> reflects pointer activity. In this manner, the interactive board <b>22</b>, general purpose computing device <b>28</b> and projector allow pointer activity proximate to the interactive surface <b>24</b> to be recorded as writing or drawing or used to control execution of one or more application programs executed by the general purpose computing device <b>28</b>.</p>
<p id="p-0027" num="0026">The bezel <b>26</b> in this embodiment is mechanically fastened to the interactive surface <b>24</b> and comprises four bezel segments <b>40</b>, <b>42</b>, <b>44</b>, <b>46</b>. Bezel segments <b>40</b> and <b>42</b> extend along opposite side edges of the interactive surface <b>24</b> while bezel segments <b>44</b> and <b>46</b> extend along the top and bottom edges of the interactive surface <b>24</b> respectively. In this embodiment, the inwardly facing surface of each bezel segment <b>40</b>, <b>42</b>, <b>44</b> and <b>46</b> comprises a single, longitudinally extending strip or band of retro-reflective material. To take best advantage of the properties of the retro-reflective material, the bezel segments <b>40</b>, <b>42</b>, <b>44</b> and <b>46</b> are oriented so that their inwardly facing surfaces extend in a plane generally normal to the plane of the interactive surface <b>24</b>.</p>
<p id="p-0028" num="0027">A tool tray <b>48</b> is affixed to the interactive board <b>22</b> adjacent the bezel segment <b>46</b> using suitable fasteners such as for example, screws, clips, adhesive etc. As can be seen, the tool tray <b>48</b> comprises a housing <b>48</b><i>a </i>having an upper surface <b>48</b><i>b </i>configured to define a plurality of receptacles or slots <b>48</b><i>c</i>. The receptacles are sized to receive one or more pen tools P and an eraser tool (not shown) that can be used to interact with the interactive surface <b>24</b>. Control buttons <b>48</b><i>d </i>are provided on the upper surface <b>48</b><i>b </i>to enable a user to control operation of the interactive input system <b>20</b>. One end of the tool tray <b>48</b> is configured to receive a detachable tool tray accessory module <b>48</b><i>e </i>while the opposite end of the tool tray <b>48</b> is configured to receive a detachable communications module <b>48</b><i>f </i>for remote device communications. The housing <b>48</b><i>a </i>accommodates a master controller <b>50</b> (see <figref idref="DRAWINGS">FIG. 6</figref>) as will be described. Further specifics of the tool tray <b>48</b> are described in U.S. Provisional Application Ser. No. 61/294,831 to Bolt, et al., entitled &#x201c;INTERACTIVE INPUT SYSTEM AND TOOL TRAY THEREFOR&#x201d; filed Jan. 13, 2010, the content of which is incorporated herein by reference in its entirety.</p>
<p id="p-0029" num="0028">Imaging assemblies <b>60</b> are accommodated by the bezel <b>26</b>, with each imaging assembly <b>60</b> being positioned adjacent a different corner of the bezel. The imaging assemblies <b>60</b> are oriented so that their fields of view overlap and look generally across the entire interactive surface <b>24</b>. In this manner, any pointer such as for example a user's finger, a cylinder or other suitable object, or a pen or eraser tool lifted from a receptacle <b>48</b><i>c </i>of the tool tray <b>48</b>, that is brought into proximity of the interactive surface <b>24</b> appears in the fields of view of the imaging assemblies <b>60</b>. A power adapter <b>62</b> provides the necessary operating power to the interactive board <b>22</b> when connected to a conventional AC mains power supply.</p>
<p id="p-0030" num="0029">Turning now to <figref idref="DRAWINGS">FIG. 3</figref>, one of the imaging assemblies <b>60</b> is better illustrated. As can be seen, the imaging assembly <b>60</b> comprises an image sensor <b>70</b> such as that manufactured by Aptina (Micron) MT9V034 having a resolution of 752&#xd7;480 pixels, fitted with a two element, plastic lens (not shown) that provides the image sensor <b>70</b> with a field of view of approximately 104 degrees. In this manner, the other imaging assemblies <b>60</b> are within the field of view of the image sensor <b>70</b> thereby to ensure that the field of view of the image sensor <b>70</b> encompasses the entire interactive surface <b>24</b>.</p>
<p id="p-0031" num="0030">A digital signal processor (DSP) <b>72</b> such as that manufactured by Analog Devices under part number ADSP-BF522 Blackfin or other suitable processing device, communicates with the image sensor <b>70</b> over an image data bus <b>74</b> via a parallel port interface (PPI). A serial peripheral interface (SPI) flash memory <b>74</b> is connected to the DSP <b>72</b> via an SPI port and stores the firmware required for image assembly operation. Depending on the size of captured image frames as well as the processing requirements of the DSP <b>72</b>, the imaging assembly <b>60</b> may optionally comprise synchronous dynamic random access memory (SDRAM) <b>76</b> to store additional temporary data as shown by the dotted lines. The image sensor <b>70</b> also communicates with the DSP <b>72</b> via a two-wire interface (TWI) and a timer (TMR) interface. The control registers of the image sensor <b>70</b> are written from the DSP <b>72</b> via the TWI in order to configure parameters of the image sensor <b>70</b> such as the integration period for the image sensor <b>70</b>.</p>
<p id="p-0032" num="0031">In this embodiment, the image sensor <b>70</b> operates in snapshot mode. In the snapshot mode, the image sensor <b>70</b>, in response to an external trigger signal received from the DSP <b>72</b> via the TMR interface that has a duration set by a timer on the DSP <b>72</b>, enters an integration period during which an image frame is captured. Following the integration period after the generation of the trigger signal by the DSP <b>72</b> has ended, the image sensor <b>70</b> enters a readout period during which time the captured image frame is available. With the image sensor in the readout period, the DSP <b>72</b> reads the image frame data acquired by the image sensor <b>70</b> over the image data bus <b>74</b> via the PPI. The frame rate of the image sensor <b>70</b> in this embodiment is between about 900 and about 960 frames per second. The DSP <b>72</b> in turn processes image frames received from the image sensor <b>72</b> and provides pointer information to the master controller <b>50</b> at a reduced rate of approximately 120 points/sec. Those of skill in the art will however appreciate that other frame rates may be employed depending on the desired accuracy of pointer tracking and whether multi-touch and/or active pointer identification is employed.</p>
<p id="p-0033" num="0032">Three strobe circuits <b>80</b> communicate with the DSP <b>72</b> via the TWI and via a general purpose input/output (GPIO) interface. The strobe circuits <b>80</b> also communicate with the image sensor <b>70</b> and receive power provided on LED power line <b>82</b> via the power adapter <b>62</b>. Each strobe circuit <b>80</b> drives a respective illumination source in the form of infrared (IR) light emitting diodes (LEDs) <b>84</b><i>a </i>to <b>84</b><i>c</i>, that provides infrared backlighting over the interactive surface <b>24</b> as will be described.</p>
<p id="p-0034" num="0033">The DSP <b>72</b> also communicates with an RS-422 transceiver <b>86</b> via a serial port (SPORT) and a non-maskable interrupt (NMI) port. The transceiver <b>86</b> communicates with the master controller <b>50</b> over a differential synchronous signal (DSS) communications link <b>88</b> and a synch line <b>90</b>. Power for the components of the imaging assembly <b>60</b> is provided on power line <b>92</b> by the power adapter <b>52</b>. DSP <b>72</b> may also optionally be connected to a USB connector <b>94</b> via a USB port as indicated by the dotted lines. The USB connector <b>94</b> can be used to connect the imaging assembly <b>60</b> to diagnostic equipment. Further, by using a similar architecture for each imaging assembly <b>60</b> and the master controller <b>50</b>, the same circuit board assembly and common components may be used for both thus reducing the part count and cost of the interactive input system. Differing components are added to the circuit board assemblies during manufacture dependent upon whether the circuit board assembly is intended for use in an imaging assembly <b>60</b> or in the master controller <b>50</b>. For example, the master controller <b>50</b> may require a SDRAM <b>76</b> whereas the imaging assembly <b>60</b> may not.</p>
<p id="p-0035" num="0034">The image sensor <b>70</b> and its associated lens as well as the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>are mounted on a housing assembly <b>100</b> that is best illustrated in <figref idref="DRAWINGS">FIGS. 4</figref><i>a </i>and <b>4</b><i>b</i>. As can be seen, the housing assembly <b>100</b> comprises a polycarbonate housing body <b>102</b> having a front portion <b>104</b> and a rear portion <b>106</b> extending from the front portion. An imaging aperture <b>108</b> is centrally formed in the housing body <b>102</b> and accommodates an IR-pass/visible light blocking filter <b>110</b>. The filter <b>110</b> has an IR-pass wavelength range of between about 830 nm and about 880 nm. The image sensor <b>70</b> and associated lens are positioned behind the filter <b>110</b> and oriented such that the field of view of the image sensor <b>70</b> looks through the filter <b>110</b> and generally across the interactive surface <b>24</b>. The rear portion <b>106</b> is shaped to surround the image sensor <b>70</b>. Three passages <b>112</b><i>a </i>to <b>112</b><i>c </i>are formed through the housing body <b>102</b>. Passages <b>112</b><i>a </i>and <b>112</b><i>b </i>are positioned on opposite sides of the filter <b>110</b> and are in general horizontal alignment with the image sensor <b>70</b>. Passage <b>112</b><i>c </i>is centrally positioned above the filter <b>110</b>. Each tubular passage receives a light source socket <b>114</b> that is configured to receive a respective one of the IR LEDs <b>84</b>. In particular, the socket <b>114</b> received in passage <b>112</b><i>a </i>accommodates IR LED <b>84</b><i>a</i>, the socket <b>114</b> received in passage <b>112</b><i>b </i>accommodates IR LED <b>84</b><i>b</i>, and the socket <b>114</b> received in passage <b>112</b><i>c </i>accommodates IR LED <b>84</b><i>c</i>. Mounting flanges <b>116</b> are provided on opposite sides of the rear portion <b>106</b> to facilitate connection of the housing assembly <b>100</b> to the bezel <b>26</b> via suitable fasteners. A label <b>118</b> formed of retro-reflective material overlies the front surface of the front portion <b>104</b>. Further specifics concerning the housing assembly and its method of manufacture are described in U.S. Provisional Application Ser. No. 61/294,827 to Liu, et al., entitled &#x201c;HOUSING ASSEMBLY FOR INTERACTIVE INPUT SYSTEM AND FABRICATION METHOD&#x201d; filed on Jan. 13, 2010, the content of which is incorporated herein by reference in its entirety.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 5</figref> better illustrates a portion of one of the strobe circuits <b>80</b>. As can be seen, the strobe circuit <b>80</b> comprises a digital-to-analog converter (DAC) <b>150</b> that receives serial data via input line <b>152</b> and resistor R<b>8</b> and clock input via clock line <b>154</b> and resistor R<b>9</b>. The DAC <b>150</b> provides output to the non-inverting terminal of an operational amplifier <b>156</b>, which in turn provides output to a first terminal of a transistor <b>158</b> via line <b>160</b> and resistor R<b>2</b>. A second terminal of the transistor <b>158</b> is connected to node VLED <b>94</b>. The inverting terminal of the operational amplifier <b>156</b> is connected to the node VLED <b>94</b> via line <b>162</b> and resistor R<b>3</b>. Line <b>160</b> and line <b>162</b> are interconnected by capacitor C<b>1</b>. A third terminal of the transistor <b>158</b> is connected to the LED power line <b>82</b> via one of the IR LEDs <b>84</b> and via Schottky diode <b>164</b>. A storage capacitor <b>166</b> is also connected between the Schottky diode <b>164</b> and ground G.</p>
<p id="p-0037" num="0036">The node VLED <b>94</b> is also connected to a first terminal of a transistor <b>170</b> via resistor R<b>4</b> and to a first terminal of a transistor <b>172</b> via resistor R<b>5</b>. A second terminal of transistor <b>172</b> is connected to ground G and a third terminal of transistor <b>172</b> is connected to a low current enable line <b>175</b> via resistor R<b>7</b>. A second terminal of transistor <b>170</b> is connected to ground G and a third terminal of the transistor <b>170</b> is connected to the output terminal of an AND gate <b>176</b> via resistor R<b>6</b>. One input terminal of the AND gate <b>176</b> is connected to the low current enable line <b>175</b> while the other input terminal of the AND gate <b>176</b> is connected to a high current enable line <b>178</b>. Although not shown, those of skill in the art will appreciate that the strobe circuit comprises similar circuitry to drive the other two IR LEDs.</p>
<p id="p-0038" num="0037">The master controller <b>50</b> better is illustrated in <figref idref="DRAWINGS">FIG. 6</figref>. As can be seen, master controller <b>50</b> comprises a DSP <b>200</b> such as that manufactured by Analog Devices under part number ADSP-BF522 Blackfin or other suitable processing device. A serial peripheral interface (SPI) flash memory <b>202</b> is connected to the DSP <b>200</b> via an SPI port and stores the firmware required for master controller operation. A synchronous dynamic random access memory (SDRAM) <b>204</b> that stores temporary data necessary for system operation is connected to the DSP <b>200</b> via an SDRAM port. The DSP <b>200</b> communicates with the general purpose computing device <b>28</b> over the USB cable <b>30</b> via a USB port. The DSP <b>200</b> communicates through its serial port (SPORT) with the imaging assemblies <b>60</b> via an RS-422 transceiver <b>208</b> over the differential synchronous signal (DSS) communications link <b>88</b>. In this embodiment, as more than one imaging assembly <b>60</b> communicates with the master controller DSP <b>200</b> over the DSS communications link <b>88</b>, time division multiplexed (TDM) communications is employed. The DSP <b>200</b> also communicates with the imaging assemblies <b>60</b> via the RS-422 transceiver <b>208</b> over the camera synch line <b>90</b>. DSP <b>200</b> communicates with the tool tray accessory module <b>48</b><i>e </i>over an inter-integrated circuit I<sup>2</sup>C channel and communicates with the communications accessory module <b>48</b><i>f </i>over universal asynchronous receiver/transmitter (UART), serial peripheral interface (SPI) and I<sup>2</sup>C channels.</p>
<p id="p-0039" num="0038">The general purpose computing device <b>28</b> in this embodiment is a personal computer or other suitable processing device comprising, for example, a processing unit, system memory (volatile and/or non-volatile memory), other non-removable or removable memory (e.g., a hard disk drive, RAM, ROM, EEPROM, CD-ROM, DVD, flash memory, etc.) and a system bus coupling the various computer components to the processing unit. The computer may also comprise a network connection to access shared or remote drives, one or more networked computers, or other networked devices.</p>
<p id="p-0040" num="0039">During operation, the DSP <b>200</b> of the master controller <b>50</b> outputs synchronization signals that are applied to the synch line <b>90</b> via the transceiver <b>208</b>. Each synchronization signal applied to the synch line <b>90</b> is received by the DSP <b>72</b> of each imaging assembly <b>60</b> via transceiver <b>86</b> and triggers a non-maskable interrupt (NMI) on the DSP <b>72</b>. In response to the non-maskable interrupt triggered by the synchronization signal, the DSP <b>72</b> of each imaging assembly <b>60</b> ensures that its local timers are within system tolerances and if not, corrects its local timers to match the master controller <b>50</b>. Using one local timer, the DSP <b>72</b> initiates a pulse sequence via the snapshot line that is used to condition the image sensor to the snapshot mode and to control the integration period and frame rate of the image sensor <b>70</b> in the snapshot mode. The DSP <b>72</b> also initiates a second local timer that is used to provide output on the LED control line <b>174</b> so that the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>are properly powered during the image frame capture cycle.</p>
<p id="p-0041" num="0040">In response to the pulse sequence output on the snapshot line, the image sensor <b>70</b> of each imaging assembly <b>60</b> acquires image frames at the desired image frame rate. In this manner, image frames captured by the image sensor <b>70</b> of each imaging assembly can be referenced to the same point of time allowing the position of pointers brought into the fields of view of the image sensors <b>70</b> to be accurately triangulated. Also, by distributing the synchronization signals for the imaging assemblies <b>60</b>, electromagnetic interference is minimized by reducing the need for transmitting a fast clock signal to each image assembly <b>60</b> from a central location. Instead, each imaging assembly <b>60</b> has its own local oscillator (not shown) and a lower frequency signal (e.g., the point rate, 120 Hz) is used to keep the image frame capture synchronized.</p>
<p id="p-0042" num="0041">During image frame capture, the DSP <b>72</b> of each imaging assembly <b>60</b> also provides output to the strobe circuits <b>80</b> to control the switching of the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>so that the IR LEDs are illuminated in a given sequence that is coordinated with the image frame capture sequence of each image sensor <b>70</b>. In particular, in the sequence the first image frame is captured by the image sensor <b>70</b> when the IR LED <b>84</b><i>c </i>is fully illuminated in a high current mode and the other IR LEDs are off. The next image frame is captured when all of the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>are off. Capturing these successive image frames with the IR LED <b>84</b><i>c </i>on and then off allows ambient light artifacts in captured image frames to be cancelled by generating difference image frames as described in U.S. Application Publication No. 2009/0278794 to McReynolds, et al., assigned to SMART Technologies ULC, the content of which is incorporated herein by reference in its entirety. The third image frame is captured by the image sensor <b>70</b> when only the IR LED <b>84</b><i>a </i>is on and the fourth image frame is captured by the image sensor <b>70</b> when only the IR LED <b>84</b><i>b </i>is on. Capturing these image frames allows pointer edges and pointer shape to be determined as described in U.S. Provisional Application No. 61/294,832 to McGibney, et al., entitled &#x201c;INTERACTIVE INPUT SYSTEM AND ILLUMINATION SYSTEM THEREFOR&#x201d; filed on Jan. 14, 2010, the content of which is incorporated herein by reference in its entirety. The strobe circuits <b>80</b> also control the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>to inhibit blooming and to reduce the size of dark regions in captured image frames that are caused by the presence of other imaging assemblies <b>60</b> within the field of view of the image sensor <b>70</b> as will now be described.</p>
<p id="p-0043" num="0042">During the image capture sequence, when each IR LED <b>84</b> is on, the IR LED floods the region of interest over the interactive surface <b>24</b> with infrared illumination. Infrared illumination that impinges on the retro-reflective bands of bezel segments <b>40</b>, <b>42</b>, <b>44</b> and <b>46</b> and on the retro-reflective labels <b>118</b> of the housing assemblies <b>100</b> is returned to the imaging assemblies <b>60</b>. As a result, in the absence of a pointer, the image sensor <b>70</b> of each imaging assembly <b>60</b> sees a bright band having a substantially even intensity over its length together with any ambient light artifacts. When a pointer is brought into proximity with the interactive surface <b>24</b>, the pointer occludes infrared illumination reflected by the retro-reflective bands of bezel segments <b>40</b>, <b>42</b>, <b>44</b> and <b>46</b> and/or the retro-reflective labels <b>118</b>. As a result, the image sensor <b>70</b> of each imaging assembly <b>60</b> sees a dark region that interrupts the bright band <b>159</b> in captured image frames. The reflections of the illuminated retro-reflective bands of bezel segments <b>40</b>, <b>42</b>, <b>44</b> and <b>46</b> and the illuminated retro-reflective labels <b>118</b> appearing on the interactive surface <b>24</b> are also visible to the image sensor <b>70</b>.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 7</figref><i>a </i>shows an exemplary image frame captured by the image sensor <b>70</b> of one of the imaging assemblies <b>60</b> when the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>associated with the other imaging assemblies <b>60</b> are off during image frame capture. As can be seen, the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>and the filter <b>110</b> of the other imaging assemblies <b>60</b> appear as dark regions that interrupt the bright band <b>159</b>. These dark regions can be problematic as they can be inadvertently recognized as pointers.</p>
<p id="p-0045" num="0044">To address this problem, when the image sensor <b>70</b> of one of the imaging assemblies <b>60</b> is capturing an image frame, the strobe circuits <b>80</b> of the other imaging assemblies <b>60</b> are conditioned by the DSPs <b>72</b> to a low current mode. In the low current mode, the strobe circuits <b>80</b> control the operating power supplied to the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>so that they emit infrared lighting at an intensity level that is substantially equal to the intensity of illumination reflected by the retro-reflective bands on the bezel segments <b>40</b>, <b>42</b>, <b>44</b> and <b>46</b> and by the retro-reflective labels <b>118</b>. <figref idref="DRAWINGS">FIG. 7</figref><i>b </i>shows an exemplary image frame captured by the image sensor <b>70</b> of one of the imaging assemblies <b>60</b> when the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>associated with the other imaging assemblies <b>60</b> are operated in the low current mode. As a result, the size of each dark region is reduced. Operating the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>in this manner also inhibits blooming (i.e., saturation of image sensor pixels) which can occur if the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>of the other imaging assemblies <b>60</b> are fully on during image frame capture. The required levels of brightness for the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>in the low current mode are related to the distance between the image sensor <b>70</b> and the opposing bezel segments <b>40</b>, <b>42</b>, <b>44</b>, and <b>46</b>. Generally, lower levels of brightness are required as the distance between the image sensor <b>70</b> and the opposing bezel segments <b>40</b>, <b>42</b>, <b>44</b>, and <b>46</b> increases due to the light loss within the air as well as inefficient distribution of light from each IR LED towards the bezel segments <b>40</b>, <b>42</b>, <b>44</b>, and <b>46</b>.</p>
<p id="p-0046" num="0045">The sequence of image frames captured by the image sensor <b>70</b> of each imaging assembly <b>60</b> is processed by the DSP <b>72</b> to identify each pointer in each image frame and to obtain pointer shape and contact information as described in above-incorporated U.S. Provisional Application Ser. No. 61/294,832 to McGibney, et al. The DSP <b>72</b> of each imaging assembly <b>60</b> in turn conveys the pointer data to the DSP <b>200</b> of the master controller <b>50</b>. The DSP <b>200</b> uses the pointer data received from the DSPs <b>72</b> to calculate the position of each pointer relative to the interactive surface <b>24</b> in (x,y) coordinates using well known triangulation as described in above-incorporated U.S. Pat. No. 6,803,906 to Morrison. This pointer coordinate data along with pointer shape and pointer contact status data is conveyed to the general purpose computing device <b>28</b> allowing the image data presented on the interactive surface <b>24</b> to be updated.</p>
<p id="p-0047" num="0046">The manner by which each strobe circuit <b>80</b> controls its associated IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>will now be described with particular reference to <figref idref="DRAWINGS">FIGS. 5 and 8</figref>. The strobe circuit <b>80</b> employs two control mechanisms for controlling the flow of current through each of its respective IR LEDs. The first mechanism that is employed to control the flow of current through the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>is via the DSP <b>72</b> which sets the voltage output, Vset, of the digital-to-analog converter <b>84</b> (DAC) by providing appropriate output on the serial data input line <b>152</b> and corresponding clock signal <b>154</b>. The operational amplifier <b>156</b> and the transistor <b>158</b> form a voltage follower circuit such that node VLED <b>94</b> is equal to Vset. In this configuration, the &#x201c;on&#x201d; resistance of the transistor <b>158</b> is automatically adjusted in order to make the current passing through each IR LED constant during operation. The voltage Vset in this embodiment is equal to 1 Volt.</p>
<p id="p-0048" num="0047">The second mechanism to control the flow of current through the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>is represented by the components surrounded by the dotted lines which form a low/high current enable circuit. Referring to <figref idref="DRAWINGS">FIG. 8</figref>, when the LED control line <b>174</b> is high, the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>are active and when the LED control line <b>174</b> is low the IR LEDs are inactive. During a high LED control line <b>174</b> condition, the strobe circuits <b>80</b> are conditioned to operate the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>in the low current mode if the imaging assembly <b>60</b> is not capturing an image frame. The imaging assemblies <b>60</b> capture images in a round-robin fashion by activating the snapshot line <b>78</b> during which time, depending on the position in the image frame capture sequence, the appropriate IR LED <b>84</b> is conditioned to the high current state in order to fully illuminate.</p>
<p id="p-0049" num="0048">The current passing through each IR LED is approximated by the following equation:</p>
<p id="p-0050" num="0049">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
  <msub>
    <mi>I</mi>
    <mi>LEDH</mi>
  </msub>
  <mo>&#x2248;</mo>
  <mrow>
    <mfrac>
      <mrow>
        <mi>R</mi>
        <mo>&#x2062;</mo>
        <mstyle>
          <mspace width="0.3em" height="0.3ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mn>4</mn>
          <mo>&#xb7;</mo>
          <mi>R</mi>
        </mrow>
        <mo>&#x2062;</mo>
        <mstyle>
          <mspace width="0.3em" height="0.3ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mn>5</mn>
      </mrow>
      <mrow>
        <mrow>
          <mi>R</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mn>4</mn>
        </mrow>
        <mo>+</mo>
        <mrow>
          <mi>R</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mn>5</mn>
        </mrow>
      </mrow>
    </mfrac>
    <mo>&#xb7;</mo>
    <mi>Vset</mi>
  </mrow>
</mrow>
</math>
</maths>
</p>
<p id="p-0051" num="0050">for high current operation which can be further approximated by the following equation:</p>
<p id="p-0052" num="0051">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mrow>
  <msub>
    <mi>I</mi>
    <mi>LEDH</mi>
  </msub>
  <mo>&#x2248;</mo>
  <mfrac>
    <mi>Vset</mi>
    <mrow>
      <mi>R</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mn>4</mn>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0053" num="0052">and for low current operation can be further approximated by the following equation:</p>
<p id="p-0054" num="0053">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mrow>
  <msub>
    <mi>I</mi>
    <mi>LEDL</mi>
  </msub>
  <mo>&#x2248;</mo>
  <mfrac>
    <mi>Vset</mi>
    <mrow>
      <mi>R</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mn>5</mn>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0055" num="0054">Capacitor <b>166</b> stores the charge for the respective IR LED <b>84</b> when it is turned on further maintaining constant illumination. Since VDDLED <b>82</b> is used for multiple imaging assemblies <b>60</b>, the Schottky diode <b>164</b> prevents charge from escaping from one imaging assembly <b>60</b> to other imaging assemblies <b>60</b>. The value of VDDLED <b>82</b> is dependant on the size of capacitor <b>166</b>, the forward voltage drop of the IR LED, the voltage between the drain and source of the transistors <b>158</b>, <b>170</b>, and <b>172</b>, the total charge to pass through the IR LED (e.g., the integral of the IR LED current over time), and the source impedance of the VDDLED <b>82</b> supply, etc. In this embodiment, VDDLED <b>82</b> is equal to 12 volts.</p>
<p id="p-0056" num="0055">The low current enable line <b>175</b> is controlled via the LED control line <b>174</b> of the DSP <b>72</b>. When the signal on the LED control line <b>174</b> is high, the transistor <b>172</b> is active allowing current to flow through the low current circuit pathway via the resistor R<b>5</b>. This produces current levels of approximately 13 mA through the IR LED for a Vset of 1 volt. A current level of 13 mA produces between approximately 160 and 320 milliwatts per steradian (mW/sr) of infrared illumination from the IR LED. The high current enable line <b>178</b> is controlled via the LED out line of the image sensor <b>70</b>. When the signal on the high current line <b>178</b> is high, the transistor <b>170</b> is active allowing current to flow through the high current circuit pathway via the resistor R<b>4</b>. The image sensor <b>70</b> times the signal provided on the LED out line that is applied to the high current enable line <b>178</b> to correspond with the integration period for a fully illuminated image frame, in this embodiment 125 &#x3bc;sec, where image data is captured. During this period, the current level passing through the IR LED is approximately 990 mA for a Vset of 1 volt. A current level of 990 mA produces between approximately 8000 and 16,000 mW/sr.</p>
<p id="p-0057" num="0056">Although in the embodiment described above, the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>are in a low current mode during the time period that other imaging assemblies are acquiring image frames, one of ordinary skill in the art will appreciate that the duration of the low current mode may be reduced for imaging assemblies <b>60</b> if they are not within the field of view of the imaging assembly <b>60</b> that is currently capturing image data.</p>
<p id="p-0058" num="0057">Although in the embodiment described above, feedback is not used to control the illumination of the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c</i>, one of ordinary skill in the art will appreciate that feedback may be employed to allow the illumination of the IR LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>more closely to match the illumination reflected by the retro-reflective bands. In order to do so, the imaging data captured from the current image assembly <b>60</b> can be used to adjust the brightness (e.g., the current) of the opposing illumination sources. Such a feedback system may be advantageous to reduce the complexity of image processing algorithms.</p>
<p id="p-0059" num="0058">Those of skill in the art will appreciate that other control mechanisms and circuit designs may be employed to control the IR LEDs.</p>
<p id="p-0060" num="0059">Although the embodiment described herein has a central, synchronized system for coordinating imaging assembly exposures, one of the skill in the art will appreciate that time stamping and interpolation of the images is possible for asynchronous systems.</p>
<p id="p-0061" num="0060">One of skill in the art will also appreciate that calibration may be required in order to match the brightness of the IR LEDs to the illumination reflected by the retro-reflective bands and that calibration parameters may differ from imaging assembly to imaging assembly. One of skill in the art will appreciate that calibration may be performed manually or automatically using feedback from the opposing imaging assemblies. One of skill the art will also appreciate that the brightness of the IR LEDs do not precisely have to match the illumination reflected by the retro-reflective bands.</p>
<p id="p-0062" num="0061">Although the embodiments described herein uses three IR LEDs per imaging assembly, those of skill in the art would know that other numbers of illumination sources may be used. Although in the embodiments described above, the LEDs <b>84</b><i>a </i>to <b>84</b><i>c </i>emit infrared radiation, in other embodiments, visible or other forms of light radiation may alternatively be emitted.</p>
<p id="p-0063" num="0062">Although in embodiments described above, the frame rate of the imaging assemblies is 960 Hz, those of skill in the art will appreciate that the interactive input system is not limited to these frequencies. For example, the image sensors of the imaging assemblies may be capable of very high frame rates, such as those on the order of 10<sup>6 </sup>frames per second, or very low frame rates, such as 30 frames per second.</p>
<p id="p-0064" num="0063">In embodiments described above, the IR LEDs are cycled at a rate that is half of the frame rate. In other embodiments, the IR LEDs may alternatively be cycled at other rates, such as &#x2153;, &#xbc; or 1/100 of the frame rate, for example. In systems using IR LEDs that cycle at rates less than that of the frame rate, such as 1/100 the frame rate, any image frames captured while the IR LEDs are off can be used for analyzing the light intensity of any active pen tools present to identify the pointers and other information such as tip pressure, while image frames captured while the IR LEDs are on can be used for ambient light removal and pointer triangulating.</p>
<p id="p-0065" num="0064">Although the embodiments described herein employ a retro-reflective bezel, one of skill in the art will appreciate that the IR illumination sources need only match the background, even though the background may not be retro-reflective.</p>
<p id="p-0066" num="0065">In the embodiments described above, the imaging assemblies <b>60</b> are described as communicating with the master controller <b>50</b> via a DSS communications link. Other communications links such as a parallel bus, a universal serial bus (USB), an Ethernet connection or other suitable wired connection may however be employed. Alternatively, the imaging assemblies <b>22</b> may communicate with the master controller <b>50</b> over a wireless connection using a suitable wireless protocol such as for example Bluetooth, WiFi, ZigBee, ANT, IEEE 802.15.4, Z-Wave etc. Also, the master controller <b>50</b> is described as communicating with the general purpose computing device <b>28</b> via a USB cable <b>30</b>. Alternatively, the master controller <b>50</b> may communicate with the general purpose computing device <b>28</b> over another wired connection such as for example, a parallel bus, an RS-232 connection, an Ethernet connection etc. or may communicate with the general purpose computing device <b>28</b> over a wireless connection using a suitable wireless protocol such as for example Bluetooth, WiFi, ZigBee, ANT, IEEE 802.15.4, Z-Wave etc.</p>
<p id="p-0067" num="0066">In the embodiments described above, a short-throw projector is used to project an image onto the interactive surface <b>24</b>. As will be appreciated other front projection devices or alternatively a rear projection device may be used to project the image onto the interactive surface <b>24</b>. Rather than being supported on a wall surface, the interactive board <b>22</b> may be supported on an upstanding frame or other suitable support. Still alternatively, the interactive board <b>22</b> may engage a display device such as for example a plasma television, a liquid crystal display (LCD) device etc. that presents an image visible through the interactive surface <b>24</b>.</p>
<p id="p-0068" num="0067">Although a specific processing configuration has been described, those of skill in the art will appreciate that alternative processing configurations may be employed. For example, one of the imaging assemblies may take on the master controller role. Alternatively, the general purpose computing device may take on the master controller role.</p>
<p id="p-0069" num="0068">Although various embodiments have been described, those of skill in the art will appreciate that other variations and modifications may be made with departing from the spirit and scope thereof as defined by the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08624835-20140107-M00001.NB">
<img id="EMI-M00001" he="6.01mm" wi="76.20mm" file="US08624835-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08624835-20140107-M00002.NB">
<img id="EMI-M00002" he="6.01mm" wi="76.20mm" file="US08624835-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08624835-20140107-M00003.NB">
<img id="EMI-M00003" he="6.01mm" wi="76.20mm" file="US08624835-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An interactive input system comprising:
<claim-text>an illumination source associated with each of a plurality of imaging assemblies and configured to emit radiation into a region of interest;</claim-text>
<claim-text>the plurality of imaging assemblies configured to capture image frames of said region of interest, at least one illumination source being in the field of view of at least one of the plurality of imaging assemblies; and</claim-text>
<claim-text>controller structure communicating with each illumination source, said controller structure configured to control the intensity of radiation emitted by each illumination source during image frame capture,</claim-text>
<claim-text>wherein during image frame capture by one of the plurality of imaging assemblies, said controller structure causes the intensity of emitted radiation by its associated illumination source to be at a first illumination level, and</claim-text>
<claim-text>wherein during image frame capture by another of said plurality of imaging assemblies, said controller structure causes the intensity of emitted radiation by the illumination source associated with said one of the plurality of imaging assemblies to be at a second, non-zero, lower illumination level.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The interactive input system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the intensity of emitted radiation at said second lower illumination level approximates backlight illumination provided to said region of interest.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The interactive input system of <claim-ref idref="CLM-00002">claim 2</claim-ref> comprising:
<claim-text>at least one illumination source adjacent each imaging assembly; and</claim-text>
<claim-text>a controller for each illumination source.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The interactive input system of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein each controller is responsive to its associated imaging assembly during image frame capture thereby to illuminate at said first illumination level the associated illumination source, and is responsive to its associated imaging assembly during image frame capture by said another of the plurality of imaging assemblies to illuminate its associated illumination source at the second, lower illumination level.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The interactive input system of <claim-ref idref="CLM-00004">claim 4</claim-ref> comprising a plurality of illumination sources associated with each imaging assembly.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The interactive input system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein each controller is responsive to an image sensor of said associated imaging assembly during image frame capture thereby, and is responsive to a processor of said associated imaging assembly when illuminating the associated at least one illumination source at said second, lower illumination level.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The interactive input system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said region of interest is substantially rectangular, and wherein the imaging assemblies are positioned adjacent at least two corners of said region of interest.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The interactive input system of <claim-ref idref="CLM-00007">claim 7</claim-ref> further comprising a reflective bezel at least partially surrounding the region of interest.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The interactive input system of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein said reflective bezel is retro-reflective.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The interactive input system of <claim-ref idref="CLM-00009">claim 9</claim-ref> wherein an imaging assembly is positioned adjacent each corner of said region of interest.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The interactive input system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising a plurality of illumination sources associated with each imaging assembly.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The interactive input system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said illumination sources comprise infrared sources.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The interactive input system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the intensity of emitted radiation at said second lower illumination level corresponds to backlight illumination provided to said region of interest.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The interactive input system of <claim-ref idref="CLM-00013">claim 13</claim-ref> further comprising a controller for each illumination source, and wherein each controller is responsive to its associated imaging assembly during image frame capture thereby to illuminate at said first illumination level the associated at least one illumination source, and is responsive to its associated imaging assembly during image frame capture by said another of the plurality of imaging assemblies to illuminate the associated at least one illumination source at said second lower illumination level.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The interactive input system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising a plurality of illumination sources associated with each imaging assembly.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The interactive input system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein each controller is responsive to an image sensor of the associated imaging assembly during image frame capture thereby, and is responsive to a processor of the associated imaging assembly when illuminating the associated illumination source at a reduced level.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A method of controlling image capture in an interactive input system, the method comprising:
<claim-text>associating an illumination source with each of a plurality of imaging assemblies;</claim-text>
<claim-text>causing at least one illumination source to emit radiation into a region of interest;</claim-text>
<claim-text>causing the plurality of imaging assemblies to capture image frames of said region of interest, at least one illumination source being in the field of view of at least one imaging assembly and appearing in captured image frames; and</claim-text>
<claim-text>controlling the intensity of radiation emitted by each illumination source during image frame capture by its associated imaging assembly,</claim-text>
<claim-text>wherein during image frame capture by one of the plurality of imaging assemblies, the intensity of emitted radiation by its associated illumination source is controlled to be at a first illumination level, and</claim-text>
<claim-text>wherein during image frame capture by another of said plurality of imaging assemblies, the intensity of emitted radiation by the illumination source associated with said one of the plurality of imaging assemblies is controlled to be at a second, non-zero, lower illumination level.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the second lower illumination level substantially matches backlight illumination provided to said region of interest.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. An interactive input system comprising:
<claim-text>a plurality of imaging assemblies configured to capture image frames of a region of interest from different vantages, said region of interest being at least partially surrounded by a reflective bezel;</claim-text>
<claim-text>at least one illumination source associated with each imaging assembly and configured to emit radiation into said region of interest; and</claim-text>
<claim-text>a controller for each at least one illumination source, each controller configured to cause its associated at least one illumination source to emit radiation into said region of interest at a first intensity level during image frame capture by its associated imaging assembly and configured to reduce the intensity of radiation emitted by its associated at least one illumination source from the first illumination level to a second non-zero lower intensity level during image frame capture by other imaging assemblies so that the intensity of emitted radiation at said second lower illumination level substantially matches the intensity of illumination reflected by said bezel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The interactive input system of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein said region of interest is generally rectangular, and imaging assemblies are positioned adjacent at least two corners of said region of interest.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The interactive input system of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein said reflective bezel is retro-reflective.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The interactive input system of <claim-ref idref="CLM-00020">claim 20</claim-ref> wherein an imaging assembly is positioned adjacent each corner of said region of interest.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The interactive input system of <claim-ref idref="CLM-00019">claim 19</claim-ref> comprising a plurality of illumination sources associated with each imaging assembly.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The interactive input system of <claim-ref idref="CLM-00023">claim 23</claim-ref> wherein said illumination sources are infrared sources. </claim-text>
</claim>
</claims>
</us-patent-grant>
