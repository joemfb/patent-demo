<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622951-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622951</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12135734</doc-number>
<date>20080609</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1366</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>17</main-group>
<subgroup>20</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>007</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>00745</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>F</subclass>
<main-group>2217</main-group>
<subgroup>007</subgroup>
<symbol-position>L</symbol-position>
<classification-value>A</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<classification-national>
<country>US</country>
<main-classification>604 22</main-classification>
<further-classification>606 45</further-classification>
<further-classification>601  2</further-classification>
</classification-national>
<invention-title id="d2e53">Controlling a phacoemulsification system based on real-time analysis of image data</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6155975</doc-number>
<kind>A</kind>
<name>Urich et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600300</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6311540</doc-number>
<kind>B1</kind>
<name>Paltieli et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7040759</doc-number>
<kind>B2</kind>
<name>Chernyak et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7044602</doc-number>
<kind>B2</kind>
<name>Chernyak</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7135016</doc-number>
<kind>B1</kind>
<name>Asia et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7261415</doc-number>
<kind>B2</kind>
<name>Chernyak</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2003/0036751</doc-number>
<kind>A1</kind>
<name>Anderson et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2003/0083536</doc-number>
<kind>A1</kind>
<name>Eshel et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2003/0159141</doc-number>
<kind>A1</kind>
<name>Zacharias</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2004/0146201</doc-number>
<kind>A1</kind>
<name>Sathyanarayana</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2004/0152990</doc-number>
<kind>A1</kind>
<name>Mackool</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2004/0267136</doc-number>
<kind>A1</kind>
<name>Yaguchi et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600459</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2005/0261628</doc-number>
<kind>A1</kind>
<name>Boukhny et al.</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2006/0159319</doc-number>
<kind>A1</kind>
<name>Sathyanarayana</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2008/0058782</doc-number>
<kind>A1</kind>
<name>Frangineas et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>7</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090306581</doc-number>
<kind>A1</kind>
<date>20091210</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Claus</last-name>
<first-name>Michael J.</first-name>
<address>
<city>Newport Coast</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Claus</last-name>
<first-name>Michael J.</first-name>
<address>
<city>Newport Coast</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Abbott Medical Optics Inc.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Abbott Medical Optics Inc.</orgname>
<role>02</role>
<address>
<city>Santa Ana</city>
<country>unknown</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Barham</last-name>
<first-name>Bethany</first-name>
<department>1615</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A design for dynamically adjusting parameters applied to a surgical instrument, such as an ocular surgical instrument, is presented. The method includes detecting surgical events from image data collected by a surgical microscope focused on an ocular surgical procedure, establishing a desired response for each detected surgical event, delivering the desired response to the ocular surgical instrument as a set of software instructions, and altering the surgical procedure based on the desired response received as the set of software instructions.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="242.99mm" wi="178.73mm" file="US08622951-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="254.59mm" wi="194.06mm" orientation="landscape" file="US08622951-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="272.54mm" wi="185.42mm" file="US08622951-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="265.51mm" wi="195.58mm" file="US08622951-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="253.58mm" wi="201.08mm" file="US08622951-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="246.89mm" wi="205.91mm" file="US08622951-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="262.04mm" wi="202.95mm" file="US08622951-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates generally to the field of ocular surgery, and more specifically to real-time control of a medical instrument system during ophthalmic procedures based on detected surgical events.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">Ocular surgery, such as phacoemulsification surgery, requires a surgeon to continuously make decisions while conducting the surgical procedure. To make these decisions, the surgeon may rely on a variety of information originating within the surgical theater environment, which may include the surgeon using her auditory, tactile, and visual senses to ascertain cues during the procedure. The surgeon may use these environmental cues to make decisions regarding adjusting and refining the settings and parameters controlling the medical instrument system to best perform the most effective, efficient and safest possible surgical procedure. One example of an environmental cue is reporting an audible alarm to inform the surgeon that the instrument logic has detected a parameter, such as flow for example, has reached a value outside of a desired operating range.</p>
<p id="p-0006" num="0005">Medical instrument systems incorporate numerous sensors to detect and collect information from the surgical theater environment sensors and provide this information as input to software programs that monitor the medical instrument system. Together with advancements in sensor technologies, surgical monitoring software programs continue to evolve to take advantage of advanced sensor capabilities. One example of the current state of software sensor state of the art is Advanced Medical Optics' &#x201c;occlusion mode&#x201d; functionality provided in certain phacoemulsification systems, wherein a control program monitors vacuum sensors and recognizes vacuum levels exceeding a particular value. Once the control program detects that vacuum levels have exceeded the value, the control program adjusts system parameters accordingly.</p>
<p id="p-0007" num="0006">The current state of the art also entails capturing optical images during the surgical procedure and presenting these optical images with the various instrument settings and sensor readings. One example of such a design is Advanced Medical Optics' &#x201c;Surgical Media Center,&#x201d; aspects of which are reflected in U.S. patent application Ser. No. 11/953,229, &#x201c;DIGITAL VIDEO CAPTURE SYSTEM AND METHOD WITH CUSTOMIZABLE GRAPHICAL OVERLAY,&#x201d; inventors Wayne Wong, et al., filed Dec. 10, 2007, the entirety of which is incorporated herein by reference. The Surgical Media Center provides simultaneous replay of surgical camera video images synchronized with medical instrument system settings and parameters. Video and system settings information can be communicated to other systems and subsystems. Another system related to capturing of optical images, specifically eye position, is reflected in the U.S. Pat. No. 7,044,602 to Chernyak, U.S. Pat. No. 7,261,415 to Chernyak, and U.S. Pat. No. 7,040,759 to Chernyak et al., each assigned to VISX, Incorporated of Santa Clara, Calif.</p>
<p id="p-0008" num="0007">Phacoemulsification instrument systems manufacturers provide products that allow the sensors within the systems to detect information from the surgical environment and pass that data to control programs in order to dynamically generate responses and adjust instrument system settings. In conjunction, manufacturers continue to evolve and improve data analysis programs to recognize certain patterns of information reported from digital video camera imaging data. Image analysis techniques may afford the system the ability to perceive small changes or complex patterns otherwise undetected by a surgeon operating a surgical microscope. Important visual information or cues previously unavailable during a surgical procedure can now be employed during the procedure.</p>
<p id="p-0009" num="0008">Ocular surgical procedures in particular, including phacoemulsification, involve manual procedures selected by the surgeon based on environmental cues originating from instrument sensors. While manual procedures are effective and in wide use, current surgical procedures can be challenging in a surgical environment due to human response time and the ability to perceive very small changes or very complex patterns within environmental cues. It can be difficult for the surgeon to observe available environmental cues, and appropriately respond to these &#x2018;events&#x2019; quickly and accurately by determining and manually implementing new settings and parameters to adjust the surgical instrument. Enhancing a surgeon's ability to perform the surgical procedure is always advantageous.</p>
<p id="p-0010" num="0009">Based on the foregoing, it would be advantageous to provide for a system and method that enhances the ability of the system to accurately detect, report, and quickly respond to surgical events from imaging data, and provide information relating environmental changes previously not perceived by the surgeon for use in medical instrument systems that overcomes drawbacks present in previously known designs.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0011" num="0010">According to one aspect of the present design, there is provided an apparatus configured to control parameters of a surgical instrument employable in a surgical procedure, such as an ocular surgical procedure. The apparatus comprises an image analysis module configured to detect surgical events within an image data stream and an instrument control module configured to receive surgical events detected from at least the image analysis module and generate responses to said detected surgical events. The instrument control module is configured to process said responses and transmit processed responses in the form of an instruction set. The surgical instrument is configured to receive and execute instruction sets communicated from the instrument control module during the surgical procedure.</p>
<p id="p-0012" num="0011">According to another aspect of the present design, there is provided a method for dynamically adjusting parameters applied to a surgical instrument, such as an ocular surgical instrument. The method includes detecting surgical events from image data collected by a surgical microscope focused on an ocular surgical procedure, establishing a desired response for each detected surgical event, delivering the desired response to the ocular surgical instrument as a set of software instructions, and altering the surgical procedure based on the desired response received as the set of software instructions.</p>
<p id="p-0013" num="0012">These and other advantages of the present invention will become apparent to those skilled in the art from the following detailed description of the invention and the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013">The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings in which:</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an exemplary phacoemulsification/vitrectomy system in a functional block diagram to show the components and interfaces for a safety critical medical instrument system that may be employed in accordance with an aspect of the present invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an exemplary surgical system in a functional block diagram to show the components and interfaces for a real-time digital image capture and presentation system that may be employed in accordance with an aspect of the present invention;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram illustrating components and devices for a phacoemulsification instrument control module integrated within the surgical system for real-time surgical instrument control based on detected surgical events in accordance with an aspect of the present invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 4</figref> is a functional block diagram illustrating components for an image analysis software module for detecting surgical events from digital imaging data in accordance with an aspect of the present invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 5</figref> is a functional block diagram illustrating components for an instrument monitoring software module for detecting surgical events from instrument sensor data in accordance with another aspect of the present invention; and</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 6</figref> is a functional block diagram illustrating components for an instrument control software module for assigning an appropriate response to detected events in accordance with another aspect of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0021" num="0020">The following description and the drawings illustrate specific embodiments sufficient to enable those skilled in the art to practice the system and method described. Other embodiments may incorporate structural, logical, process and other changes. Examples merely typify possible variations. Individual components and functions are generally optional unless explicitly required, and the sequence of operations may vary. Portions and features of some embodiments may be included in or substituted for those of others.</p>
<p id="p-0022" num="0021">The present design is directed to mechanized control for adjusting surgical instrument settings and/or parameters, e.g. vacuum, aspiration, etc., based on detected surgical events originating within the surgical operating theater environment. The present design arrangement may include an image analysis component configured to recognize and report surgical events determined from the imaging data, such as imaging data received from a camera or via a surgical microscope. The arrangement typically includes an instrument sensor monitoring and analysis component configured to recognize and report surgical events determined from instrument sensor data. In addition, the arrangement may include a surgical instrument controller configured to generate and transmit responses instructing the surgical instrument to adjust specific settings and/or parameters and alter the course of the remaining surgery. The present design thus provides for dynamic or real-time control of the medical instrument system and/or medical or surgical instrument.</p>
<p id="p-0023" num="0022">In short, the present design provides for real-time control of the medical instrument system, affording alterations to the course of the remaining surgical procedure, realized from real-time analysis of video imaging data. Analysis of the imaging data is typically automated or automatic, i.e. requires zero or minimal user interface. Analysis of instrument sensor data may be employed separately or in combination with image data processing to detect surgical events.</p>
<p id="p-0024" num="0023">Any type of system or software application configured to receive detected events from imaging and sensor data analysis, for example a pilotless flight control application, may benefit from the design presented herein, and such a design is not limited to a phacoemulsification system, surgical system, or even a medical system. The present design may be implemented in, for example, systems including but not limited to phacoemulsification-vitrectomy systems, vitrectomy systems, dental systems, industrial applications, and aerospace applications.</p>
<p id="p-0025" num="0024">The present design may include a graphical user interface to further control automated operations and may include configuration and setup functionality. The system can provide the ability to assign various predetermined settings and parameters in response to specific detected surgical events and show video and instrument sensor data.</p>
<p id="p-0026" num="0025">The present design is intended to provide a reliable, noninvasive, and efficient automatic control mechanism for a medical instrument system for use in dynamically controlling the surgical instrument system in real-time.</p>
<p id="h-0005" num="0000">System Example</p>
<p id="p-0027" num="0026">While the present design may be used in various environments and applications, it will be discussed herein with a particular emphasis on a medical or hospital environment, where a surgeon or health care practitioner performs. For example, one embodiment of the present design is in or with a phacoemulsification surgical system that comprises an independent graphical user interface (GUI) host module, an instrument host module, a GUI device, and a controller module, such as a foot switch, to control the surgical system.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an exemplary phacoemulsification/vitrectomy system <b>100</b> in a functional block diagram to show the components and interfaces for a safety critical medical instrument system that may be employed in accordance with an aspect of the present invention. A serial communication cable <b>103</b> connects GUI host <b>101</b> module and instrument host <b>102</b> module for the purposes of controlling the surgical instrument host <b>102</b> by the GUI host <b>101</b>. Instrument host <b>102</b> may be considered a computational device in the arrangement shown, but other arrangements are possible. An interface communications cable <b>120</b> is connected to instrument host <b>102</b> module for distributing instrument sensor data <b>121</b>, and may include distribution of instrument settings and parameters information, to other systems, subsystems and modules within and external to instrument host <b>102</b> module. Although shown connected to the instrument host <b>102</b> module, interface communications cable <b>120</b> may be connected or realized on any other subsystem (not shown) that could accommodate such an interface device able to distribute the respective data.</p>
<p id="p-0029" num="0028">A switch module associated with foot pedal <b>104</b> may transmit control signals relating internal physical and virtual switch position information as input to the instrument host <b>102</b> over serial communications cable <b>105</b>. Instrument host <b>102</b> may provide a database file system for storing configuration parameter values, programs, and other data saved in a storage device (not shown). In addition, the database file system may be realized on the GUI host <b>101</b> or any other subsystem (not shown) that could accommodate such a file system.</p>
<p id="p-0030" num="0029">The phacoemulsification/vitrectomy system <b>100</b> has a handpiece <b>110</b> that includes a needle and electrical means, typically a piezoelectric crystal, for ultrasonically vibrating the needle. The instrument host <b>102</b> supplies power on line <b>111</b> to a phacoemulsification/vitrectomy handpiece <b>110</b>. An irrigation fluid source <b>112</b> can be fluidly coupled to handpiece <b>110</b> through line <b>113</b>. The irrigation fluid and ultrasonic power are applied by handpiece <b>110</b> to a patient's eye, or affected area or region, indicated diagrammatically by block <b>114</b>. Alternatively, the irrigation source may be routed to eye <b>114</b> through a separate pathway independent of the handpiece. Aspiration is provided to eye <b>114</b> by the instrument host <b>102</b> pump (not shown), such as a peristaltic pump, through lines <b>115</b> and <b>116</b>. A switch <b>117</b> disposed on handpiece <b>110</b> may be utilized to enable a surgeon/operator to select an amplitude of electrical pulses to the handpiece via the instrument host and GUI host. Any suitable input device, such as for example, a foot pedal <b>104</b> switch may be utilized in lieu of switch <b>117</b>.</p>
<p id="p-0031" num="0030">In combination with phacoemulsification system <b>100</b>, the present design surgical system includes image processing in or with the phacoemulsification system and may comprise a surgical microscope, digital video cameras, data storage, video rendering, and user interface to control the image capture and analysis system.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an exemplary surgical system <b>200</b> in a functional block diagram to show the components and interfaces for a real-time digital image capture, distribution, and presentation system that may be employed in accordance with an aspect of the present invention. The surgical system digital image processing design will be discussed herein based on Advanced Medical Optic's surgical media center features and functionality.</p>
<p id="p-0033" num="0032">Surgical system <b>200</b> may include a surgical instrument, for example phacoemulsification instrument <b>102</b>, such as the phacoemulsification/vitrectomy system <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>. Surgical system <b>200</b> may further include a surgical microscope <b>202</b> focused on the surgical procedure, e.g. patients eye, and may involve digital video cameras <b>203</b>, or other device suitable for video recording, and may transfer the resulting image data at <b>204</b>, in analog or digital form, to surgical media center <b>205</b> via communications cable <b>206</b>. Surgical media center <b>205</b> is a processing device that manages the multimedia data recorded by the surgical microscope, and the instrument sensor data <b>121</b> in real-time, including but not limited to vacuum, power, flow, and foot pedal position generated from phacoemulsification instrument <b>102</b> during the surgical procedure. Managing the multimedia data includes synchronizing the temporal relationship between the instrument parameters, settings, and sensor data from phaco instrument <b>102</b> and the optical data from surgical microscope <b>202</b>. In this arrangement, system <b>200</b> may communicate the digital video as an image data stream, representing the optical data from the procedure/surgery, with the medical system instrument parameters, settings, and sensor data reported by phaco instrument <b>102</b> in real-time to other systems and subsystems.</p>
<p id="p-0034" num="0033">The surgical media center may further include a digital video storage device <b>207</b> configured to store the multimedia data recorded. Video storage device <b>207</b> may connect to and be accessed by surgical media center <b>205</b> via communications cable <b>208</b>. In addition, a video display device <b>209</b> may connect to surgical media center <b>205</b> and digital video storage device <b>207</b> via communications cable <b>208</b>.</p>
<p id="p-0035" num="0034">In this configuration, surgical media center <b>205</b> may record and present a video image of the procedure/surgery with the medical system instrument parameters and settings utilized by the phacoemulsification instrument <b>102</b> in real-time. Surgical media center <b>205</b> may synchronize instrument data with the video stream allowing simultaneous display of video data with a graphical overlay showing the corresponding parameters and system settings at each instant of the procedure on a frame-by-frame basis. This cumulative data, i.e. the video data synchronized with the setting and parameter data may be stored and archived in digital video storage device <b>207</b>. During playback, the user may select to show or hide different elements of the instrument data rendered on video display device <b>209</b>.</p>
<p id="h-0006" num="0000">Event Detection and Instrument Control</p>
<p id="p-0036" num="0035">The present design typically includes a real-time surgical instrument control module configured to receive detected surgical events and dynamically adjust instrument parameters and settings to alter the course of the remaining surgery. Detected surgical events may originate from image analysis software, instrument sensor monitoring software, and other software components configured to analyze information collected from the surgical environment. The detected surgical events, including but not limited to commencements of procedures, termination of procedures, changes in system or patient parameters such as pressure applied, pressure available, patient blood pressure, patient temperature, instrument temperature, and so forth, may be electronically communicated to the instrument control module for matching an appropriate response to received events and sending the response(s) to the surgical instrument. The response may include commands or instructions containing information relaying adjustments or changes to in-effect instrument settings and parameters.</p>
<p id="p-0037" num="0036">System</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram illustrating components and devices for an instrument monitor <b>301</b> module with an instrument control module <b>302</b> integrated within surgical system <b>200</b> for real-time surgical instrument control based on detected surgical events in accordance with an aspect of the present invention. From <figref idref="DRAWINGS">FIG. 3</figref>, a surgical microscope configured to capture an optical image of the eye requiring surgery may communicate the optical images to more than one digital video cameras <b>203</b>. In this arrangement, digital video cameras <b>203</b> may convert the optical images received into video images, such as for example a digital image data stream, and provide data streams to one or more image analysis <b>303</b> modules. Image analysis <b>303</b> module may analyze the digital image data streams using &#x2018;logic&#x2019; configured to detect imaging specific surgical events <b>305</b>.</p>
<p id="p-0039" num="0038">In conjunction with the image data streams analysis, phaco instrument monitoring <b>301</b> module may analyze data reported from multiple sensors using &#x2018;logic&#x2019; configured to detect sensor reported specific surgical events <b>306</b>. The present design may communicate detected surgical events <b>305</b> and <b>306</b> from the image analysis <b>303</b> module and from the phaco instrument monitoring <b>301</b> module, respectively, in real-time to phaco instrument control module <b>302</b>. The phaco instrument control module arrangement may be configured to receive and process data and data analysis information realized from software programs configured to detected surgical events. The processing &#x2018;logic&#x2019; may determine from this data appropriate changes to various parameters and settings for phaco instrument <b>102</b> such that implementing these changes may alter the course of the remaining surgery.</p>
<p id="p-0040" num="0039">The present design may communicate changes for instrument settings and parameters from phaco instrument control <b>303</b> module to phaco instrument <b>102</b> for modifying the behavior of the surgical instrument and associated handpiece <b>114</b> in real-time. Examples of settings and parameters available for real-time modification include, but are not limited to controlling: pulse rate and waveform, rate of fluid dispensing, vacuum, aspiration, cutting speed, and combinations thereof.</p>
<p id="p-0041" num="0040">During an ophthalmic surgical procedure, a surgeon may operate surgical microscope <b>202</b> to render optical images of the surgical site. The surgical microscope may include one or more digital cameras configured to convert the optical images of the surgical site into a stream of digital image data. The digital camera(s) may communicate or deliver the data stream(s) to one or more image analysis <b>303</b> modules for processing. Data processing may involve &#x2018;logic&#x2019; configured to detect and report specific surgical events. For example, one image analysis software component may involve an edge detection capabilities and another image analysis software component may involve pattern recognition techniques. The present design may involve these techniques to provide information from imaging data previously not available to the surgeon.</p>
<p id="p-0042" num="0041">The image analysis software may be arranged to accept input from one or more digital cameras. Multiple camera configurations may be positioned to provide for greater depth perception realized by 3D imaging techniques or positioned to provide for multiple viewing angles affording a more complete set of image data. Multiple camera configurations may be arranged to collect non-visible wavelengths such as ultra-violet and infrared and convolve this information with visible wavelength information within the optical images to form a more complete spectrum of light analysis and thus gaining access to new information available for imaging analysis.</p>
<p id="p-0043" num="0042">In conjunction with operating the surgical microscope to observe the ophthalmic procedure, the surgeon may operate phacoemulsification instrument system <b>102</b> to perform activities to complete the procedure.</p>
<p id="p-0044" num="0043">The present design may include one or more software programs arranged to monitor instrument sensors and to control the instrument. Referring to <figref idref="DRAWINGS">FIG. 3</figref>, phaco instrument monitoring <b>301</b> module may be configured to monitor each sensor incorporated in or with the phaco instrument. Phaco instrument control module <b>302</b> may be configured to provide an appropriate response <b>304</b>, in real-time, sufficient for dynamically altering the operating settings and parameters of phaco-instrument <b>102</b> appropriately when specific surgical events are detected. The appropriate responses to a detected surgical event may vary depending on the nature and type of event detected. Appropriate response <b>304</b> may include but is not limited to an auditory signal emitted to alert the surgeon, adjusting an operating parameter such as vacuum or fluid flow, and shutdown of the entire system.</p>
<p id="p-0045" num="0044">Phaco instrument monitoring <b>301</b> module may contain logic identifying when specific surgical events occur based upon recognition of predetermined patterns of readings from a sensor or multiple sensors.</p>
<p id="p-0046" num="0045">Phaco instrument control module <b>302</b> may receive continuous and simultaneous communication of surgical events <b>305</b> originating from and detected by the image analysis and surgical events <b>306</b> originating from and detected by the instrument monitoring module. The present design may be configured to dynamically modify the phaco instrument operating settings and parameters in a predefined manner; affecting a change in the course of the remaining surgery for realizing a safer and more effective ocular procedure. The system may continuously update settings and operating parameters, in an iterative manner, to remove actively reported events. The continuous update may involve a feedback arrangement that continuously adjusts the system until the detected event is addressed or the system is shut-down. In this feedback arrangement, the present design may continue to adjust a parameter or other surgical event, reported out of range, until the event is removed by the parameter being restored to an acceptable in range value. The present arrangement may correlate surgical events detected by image analysis and instrument monitoring software for determining if they are the same event being detected and reported, or if they are unrelated events.</p>
<p id="p-0047" num="0046">In another embodiment, the present design may provide information to the image analysis module for accurate imaging event detection. For example, the image analysis component logic may benefit from knowing the currently selected &#x2018;in-use&#x2019; instrument operating parameters to function correctly. While depicted as multiple elements, the present designs image analysis <b>303</b>, instrument monitoring <b>301</b>, and instrument control module <b>302</b> software may alternatively comprise one or more distributed software modules or entities and may be realized in hardware, software, firmware, and any combinations thereof to fulfill the functionality the disclosed software programs.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 4</figref> is a functional block diagram illustrating components for an image analysis <b>303</b> module for detecting surgical events from digital imaging data in accordance with an aspect of the present invention. Three software components are illustrated within the image analysis module. The present design may include a pattern recognition <b>401</b> component configured to analyze the image data streams for predefined data patterns. One potential pattern recognition logic design for extracting desired patterns from image data suitable for use in the current context is disclosed in &#x201c;Pattern Recognition Systems and Methods&#x201d;, inventor Shashidhar Sathyanarayana, U.S. Patent Publication 2006/0159319, published Jul. 20, 2006, the entirety of which is incorporated herein by reference.</p>
<p id="p-0049" num="0048">The present design may also include an edge detection component <b>402</b> configured to analyze the image data streams for detecting edges of one or more objects within the imaging data. One example of edge detection logic for determining the location of at least one edge of an object from image data suitable for use in the current system is disclosed in &#x201c;System And Method For Edge Detection of an Image&#x201d;, inventor Shashidhar Sathyanarayana, U.S. Patent Publication 2004/0146201, published Jul. 29, 2004, the entirety of which is incorporated herein by reference.</p>
<p id="p-0050" num="0049">The apparatus and method may include an infrared wavelength analysis component <b>403</b> for extracting information from the invisible portion of light spectrum. A stereoscopic imaging component <b>404</b> may combine edge detection, pattern recognition, ultra violet and other functionality arranged to analyze multiple data streams rendering stereoscopic content for detecting surgical events realized within multiple views of the surgical procedure. Although illustrated with three software components, image analysis module <b>303</b> may comprise additional components directed at recovering other types of information from image data <b>204</b> for the purpose of generating additional detected events at point <b>305</b>. The edge detection component <b>402</b> may configure the pattern recognition and edge detection algorithms to identify one or more ocular objects of surgical interest, such as a cataract.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 5</figref> is a functional block diagram illustrating components for an instrument monitoring module <b>301</b> that detects surgical events from instrument sensor data. The present design may include a vacuum sensor analysis component <b>501</b> configured to analyze and monitor vacuum related information from sensor data <b>201</b>. Vacuum sensor analysis component <b>501</b> may monitor sensor data <b>201</b> to determine when the actual vacuum pressure reported by the sensor is within a predetermined range of acceptable values associated with the current stage of the ocular procedure. In the situation where the actual value reported exceeds or drops below the expected predetermined range, the present design may generate detected event <b>306</b> to indicate such a change has occurred.</p>
<p id="p-0052" num="0051">The present design may include a pressure sensor analysis component <b>502</b> configured to analyze and monitor pressure related information from sensor data <b>201</b>. Pressure analysis <b>502</b> may monitor sensor data <b>201</b> for determining if the actual pressure reported by the sensors remains within a predetermined range of values associated with the particular stage of the ocular procedure. In the situation where the actual value reported exceeds or drops below the predetermined range, the present design may generate another detected event <b>306</b> to indicate this change in pressure.</p>
<p id="p-0053" num="0052">In a similar manner, a third instrument monitoring component is illustrated at point <b>503</b> and may be configured to determine whether multiple sensors reported by the surgical instrument remain within a desired range. Although illustrated with three analysis components, instrument monitoring <b>301</b> software module may comprise additional components directed at recovering other types of information from sensor data <b>201</b> for the purpose of detecting additional events <b>306</b>.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 6</figref> is a functional block diagram illustrating components for an instrument control <b>302</b> module to assign an appropriate response <b>304</b> to detected events <b>305</b> and <b>306</b>. The present design may include an image event response <b>601</b> component configured to receive detected events <b>305</b> from image analysis module <b>303</b> and translate each received event into an appropriate response <b>304</b>. The present design may include a sensor event response component <b>602</b> configured to receive detected events <b>306</b> from the instrument monitoring module <b>301</b> and translate each received event into an appropriate response <b>304</b>.</p>
<p id="p-0055" num="0054">In both situations, detected event translation may involve assigning each event type a response. Each response may be converted or mapped to a predetermined set of software instructions. Instrument control module <b>302</b> may communicate commands at point <b>604</b>, responsive to each detected event received, to instrument system <b>100</b> as an appropriate response <b>304</b>. The communicated commands and sets of instructions may be received and executed by instrument system <b>100</b> for adjusting control of instrument host <b>102</b>.</p>
<p id="p-0056" num="0055">A correlated event response component <b>603</b> may be provided to receive both image and sensor detected events. Correlated event response <b>603</b> may involve comparing the received detected events for determining whether they represent the same or different surgical events. In the situation where the detected image and data event types originate from the same surgical event, the present design may assign a further appropriate response in a manner as previously described for correlated events, or may cancel any duplicate responses originating from and associated with the same surgical event.</p>
<p id="p-0057" num="0056">User Interface</p>
<p id="p-0058" num="0057">A user interface device executing within surgical system <b>200</b> may communicate with and enable control of the image analysis, sensor monitoring, and instrument control software for configuration and operational control of the present design's real-time surgical event detection and response automated mode. The user interface device may include, but is not limited to, a touch screen monitor, mouse, keypad, foot pedal switch, and/or a computer monitor. The system <b>200</b> typically includes algorithms, tables, and data relating desired response to detected surgical event(s). The algorithms and data may be resident within surgical system <b>200</b> or realized using external devices and/or software. Graphical user interfaces are generally known in the art, and the graphical user interface may provide, for example, touch screen or button to enable/disable automated instrument control and select from a set of operational mode(s) by the user touching the screen or pressing buttons on the interface. Other user interfaces may be provided, such as a selection device including but not limited to a foot pedal switch as discussed.</p>
<p id="p-0059" num="0058">The user interface device enables the user to select system features, set system parameters, turn functionality on and off, and so forth. As noted, such a graphical user interface may be known in the art and can be engaged by touching the screen, pressing buttons, turning dials, and so forth.</p>
<p id="p-0060" num="0059">Operational Use</p>
<p id="p-0061" num="0060">The present design may adjust instrument settings and parameters based on stored predetermined responses assigned to the particular detected surgical event, either automatically or with user input. For example, the image pattern recognition facility may detect the presence of a cataract and determine the density of the detected cataract. The image pattern recognition facility may communicate cataract density information, in real-time, to the instrument control program. The instrument control software may assign a tailored set of instructions based on the received cataract density information and communicate the set of instructions for real-time execution by the phacoemulsification instrument affecting control of the surgical procedure in the event of a cataract having the specific density encountered. Real-time altering of instrument settings and parameters in this way may enable the surgeon to continue performing the surgical procedure efficiently, i.e. without interruption to manually adjust the instrument controls.</p>
<p id="p-0062" num="0061">In another example, the image pattern recognition facility configuration may detect the presence of a capsular bag and determine the bag's condition, e.g. good, weak, or broken. The capsular bag information may be communicated from the image pattern recognition facility, in real-time, to the instrument control program. The instrument control program may be configured to assign an immediate phaco &#x201c;stop-instruction&#x201d; in the situation when either a weak or broken capsular bag condition is detected. In the situation where a weak or broken capsular bag is indicated, the present design may communicate the &#x201c;stop-instruction&#x201d; to the phacoemulsification instrument for real-time execution. Stopping the instrument in this way may prevent surgical complications and enable the surgeon to complete the procedure in a safe manner.</p>
<p id="p-0063" num="0062">Further examples may include the image analysis software configured to detect a large number of similar surgical events. In this configuration, the present design may allow for assignment of a large number or pattern of similar detected events to a response, such as repeated encounters of excess pressure readings during normal operation, thus affording further refinement in the instruction sets available for controlling the surgical system.</p>
<p id="p-0064" num="0063">In sum, the present design provides an ability to control parameters of a surgical instrument employed in a surgical procedure, such as an ocular surgical procedure. An image analysis module detects surgical events within an image data stream, while an instrument control module receives surgical events detected from the image analysis module and potentially other sources and generates responses to the detected surgical events. The instrument control module processes responses and transmits processed responses in the form of an instruction set. The surgical instrument receives and executes instruction sets communicated from the instrument control module during the surgical procedure.</p>
<p id="p-0065" num="0064">The present design dynamically adjusts parameters applied to a surgical instrument, such as an ocular surgical instrument, detects surgical events from image data collected by a surgical microscope focused on a surgical procedure, establishes a desired response for each detected surgical event, delivers the desired response to the surgical instrument as a set of software instructions, and alters the surgical procedure based on the desired response received as the set of software instructions.</p>
<p id="p-0066" num="0065">The design presented herein and the specific aspects illustrated are meant not to be limiting, but may include alternate components while still incorporating the teachings and benefits of the invention. While the invention has thus been described in connection with specific embodiments thereof, it will be understood that the invention is capable of further modifications. This application is intended to cover any variations, uses or adaptations of the invention following, in general, the principles of the invention, and including such departures from the present disclosure as come within known and customary practice within the art to which the invention pertains.</p>
<p id="p-0067" num="0066">The foregoing description of specific embodiments reveals the general nature of the disclosure sufficiently that others can, by applying current knowledge, readily modify and/or adapt the system and method for various applications without departing from the general concept. Therefore, such adaptations and modifications are within the meaning and range of equivalents of the disclosed embodiments. The phraseology or terminology employed herein is for the purpose of description and not of limitation.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for performing a surgical procedure wherein performing the surgical procedure comprises controlling a surgical instrument, comprising:
<claim-text>detecting surgical images within a surgical environment at multiple time points during a surgical procedure;</claim-text>
<claim-text>analyzing the surgical images detected at the multiple time points during the surgical procedure to recognize and identify surgical events;</claim-text>
<claim-text>obtaining instrument readings using at least one instrument sensor at multiple time points during a surgical procedure;</claim-text>
<claim-text>assigning a desired function to at least one surgical event recognized and identified by the analyzing;</claim-text>
<claim-text>translating each desired function into a software instruction set for subsequent use in performing the surgical procedure; and</claim-text>
<claim-text>communicating sets of instructions to alter remaining portions of the surgical procedure by dynamically adjusting surgical instrument parameters based on the recognized and identified surgical events and the obtained instrument readings.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein detecting images of surgical events comprises processing image data received from a surgical microscope.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein detecting images of surgical events comprises processing data received from at least one instrument sensor.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein detecting images of surgical events further comprises performing edge detection and pattern recognition techniques to determine surgical events.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the surgical procedure comprises an ocular surgical procedure.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the ocular surgical procedure comprises a phacoemulsification procedure.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein assigning the desired function is further based on detecting pressure changes encountered in the surgical procedure. </claim-text>
</claim>
</claims>
</us-patent-grant>
