<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625167-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625167</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12803238</doc-number>
<date>20100622</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2009-148028</doc-number>
<date>20090622</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>674</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>15</main-group>
<subgroup>02</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>358  328</main-classification>
<further-classification>235494</further-classification>
</classification-national>
<invention-title id="d2e73">Image processing, reading or forming apparatus and method for adding specific image data to obtained image data while encrypting details data specifying specific data and adding encrypted details data to obtained image data, and non-transitory recording medium recording program for causing computer to function as the same</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2006/0097062</doc-number>
<kind>A1</kind>
<name>Cheong et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235494</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2007/0177824</doc-number>
<kind>A1</kind>
<name>Cattrone et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382306</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>JP</country>
<doc-number>2009-20746</doc-number>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>JP</country>
<doc-number>2009-116795</doc-number>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00005">
<othercit>K. Ito et al. &#x201c;Paper Document Security&#x201d; <i>Fuji Xerox technical report, </i>No. 15, P. 32-41, 2005; URL:htt.://www/fujixerox.co.jp/company/tr/15/downloadhdf/t4.pdf.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>15</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>358  328</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235494</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>22</number-of-drawing-sheets>
<number-of-figures>29</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100321739</doc-number>
<kind>A1</kind>
<date>20101223</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Amagai</last-name>
<first-name>Takayuki</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Amagai</last-name>
<first-name>Takayuki</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Edwards Wildman Palmer LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Conlin</last-name>
<first-name>David G.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="03" rep-type="attorney">
<addressbook>
<last-name>Tucker</last-name>
<first-name>David A.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sharp Kabushiki Kaisha</orgname>
<role>03</role>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Poon</last-name>
<first-name>King</first-name>
<department>2675</department>
</primary-examiner>
<assistant-examiner>
<last-name>Lam</last-name>
<first-name>Andrew H</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A gradation pattern on the basis of the second data for the security of predetermined image data and the details data showing the detail information of a specific image of the image data is provided to a two-dimensional code on the basis of the first data for the security of the image data so that the data for the security of the image data is efficiently added to the image data in a limited space.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="202.69mm" wi="166.12mm" file="US08625167-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="218.44mm" wi="169.25mm" file="US08625167-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="247.82mm" wi="156.04mm" file="US08625167-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="132.42mm" wi="116.67mm" file="US08625167-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="127.08mm" wi="167.30mm" file="US08625167-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="192.62mm" wi="190.58mm" file="US08625167-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="196.60mm" wi="163.24mm" file="US08625167-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="257.81mm" wi="156.63mm" orientation="landscape" file="US08625167-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="177.97mm" wi="160.27mm" file="US08625167-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="224.20mm" wi="154.86mm" file="US08625167-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="191.26mm" wi="142.66mm" file="US08625167-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="192.11mm" wi="134.54mm" file="US08625167-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="204.98mm" wi="164.00mm" file="US08625167-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="139.19mm" wi="120.82mm" file="US08625167-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="238.17mm" wi="169.33mm" file="US08625167-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="224.45mm" wi="157.14mm" file="US08625167-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="234.02mm" wi="165.52mm" file="US08625167-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="239.95mm" wi="173.48mm" orientation="landscape" file="US08625167-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="206.67mm" wi="167.47mm" file="US08625167-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="230.55mm" wi="180.76mm" orientation="landscape" file="US08625167-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="243.33mm" wi="173.65mm" file="US08625167-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="222.42mm" wi="175.68mm" orientation="landscape" file="US08625167-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="201.59mm" wi="166.96mm" file="US08625167-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This Nonprovisional application claims priority under 35 U.S.C. &#xa7;119(a) on Patent Application No. 2009-148028 filed in Japan on Jun. 22.2009, the entire contents of which are hereby incorporated by reference.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">1. Technical Field</p>
<p id="p-0004" num="0003">The present invention relates to an image processing apparatus for processing image data on the basis of the obtained data, an image reading apparatus having the image processing apparatus, an image forming apparatus having the image processing apparatus, an image processing method for image data on the basis of the obtained data, and a recording medium in which a computer program for processing image data on the basis of the data obtained in a computer.</p>
<p id="p-0005" num="0004">2. Description of Related Art</p>
<p id="p-0006" num="0005">Electronization of information has been largely proceeded as well as printers, copying machines and multi-function printers have been widely spread these days. This results in increasing cases where document data is created on the basis of a document of a sheet-shaped recording medium (hereinafter simply referred to as a document) so as to deliver the created document data.</p>
<p id="p-0007" num="0006">Meanwhile, as a method for adding additional data to a printed matter, a method using a two-dimensional code has been widely spread. An example of the two-dimensional code is a QR (Quick Response) code. Cellular phones now widespread among a large number of people are equipped with a function to read a QR code. Also, a function to create a QR code is provided as a function of a cellular phone in some cases and is provided as software for a computer in other cases.</p>
<p id="p-0008" num="0007">A so-called data embedding technology for embedding additional data into a document while taking the layout into consideration without making the human eye feel the deterioration of the image quality so much without requiring an area to which a code is added separately, unlike the case where a QR code is added to a document (printed material), has been developed. As one such example, microgradation for displaying additional binarized data as a predetermined pattern having a difference in the density in the design pattern, which is a technology for embedding additional data into a design pattern that is the page background of a document, has been disclosed (Kensuke Ito and 4 others, &#x201c;Paper Document Security&#x201d; Fuji Xerox Online Technical Report, searched on Nov. 29, 2008, http://www.fujixerox.co.jp/company/tr/15/download/pdf/t<sub>&#x2014;</sub>4.pd f).</p>
<p id="p-0009" num="0008">Meanwhile, a text hiding technology using visible watermark information in a halftone screen (hereafter, in this invention, we express visible watermark information in a halftone screen technology as visible watermark information technology, for short.) has been known as a method for checking the unauthorized copying of a document. The text hiding technology using visible watermark information in a halftone screen uses the fact that printers have higher resolution than scanners. In further detail, as shown in <figref idref="DRAWINGS">FIG. 21A</figref>, a hidden text &#x201c;Copy Strictly Prohibited&#x201d; is printed with such a resolution that can be read by scanners, and at the same time, a pattern (visible watermark information in a halftone) with such a resolution that cannot be read by scanners is printed on the entire printed surface of the recording medium for the purpose of making it difficult for the human eye to perceive the above described hidden text &#x201c;Copy Strictly Prohibited&#x201d; and thus, the document is complete. As a result, when this document is copied, as shown in <figref idref="DRAWINGS">FIG. 21B</figref>, the visible watermark information in a halftone printed in the document cannot be read by the scanner, and therefore, is not copied so that only the hidden text &#x201c;Copy Strictly Prohibited&#x201d; having such a resolution that can be read by the scanner is copied, and thus, copying can be checked.</p>
<p id="p-0010" num="0009">The visible watermark information technology is a technology for embedding a subtle change that cannot be perceived by the human eye when the document is outputted so that the information can be detected if necessary.</p>
<p id="p-0011" num="0010">In the following, an another example of the visible watermark information technology is described. <figref idref="DRAWINGS">FIGS. 22A and 22B</figref> are diagrams for illustrating visible watermark information. The visible watermark information &#x201c;x&#x201d; characters are embedded in the documents in <figref idref="DRAWINGS">FIGS. 22A and 22B</figref> with a subtle difference in the resolution from the visible watermark information in a halftone, which is difficult for the human eye to perceive. As can be seen from the diagrams showing an enlargement of each visible watermark information &#x201c;x&#x201d; character and its periphery, the visible watermark information &#x201c;x&#x201d; character is made up of dots with a great number of lines (resolution being high), while the visible watermark information in a halftone in its periphery is made up of dots with a small number of lines (resolution being low) in <figref idref="DRAWINGS">FIG. 22A</figref>. The visible watermark information &#x201c;x&#x201d; character is made up of dots with a small number of lines, while the visible watermark information in a halftone and its periphery is made up of dots with a great number of lines in <figref idref="DRAWINGS">FIG. 22B</figref>. The areas with a small number of lines can be detected by scanners, while the areas with a great number of lines cannot be detected by scanners. Accordingly, the visible watermark information &#x201c;x&#x201d; characters having such a resolution that cannot be read by scanners are white in the copy in the case where the document in <figref idref="DRAWINGS">FIG. 22A</figref> is copied, while only the visible watermark information &#x201c;x&#x201d; characters having such a resolution that can be read by the scanner are copied in the case where the document in <figref idref="DRAWINGS">FIG. 22B</figref> is copied, and thus, copying can be checked.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0012" num="0011">However, as for the documents where document data is printed in a recording medium, it is difficult to specify, &#x201c;Who prepared the document?&#x201d; after once the document is released from the hands of the preparer of the document, and in some cases, it is difficult to confirm the contents of the document. Furthermore, a third person who is not authorized by the preparer of the document can easily copy, read and handle the document as described above (document data), and a problem arises in that security is lacking.</p>
<p id="p-0013" num="0012">In the text hiding technology using visible watermark information in a halftone screen, though copying can be checked because a hidden text &#x201c;No Copying&#x201d; appears when copied, the document ends up being copied and a problem arises in that the document cannot be prevented from being copied.</p>
<p id="p-0014" num="0013">In addition, QR codes have a predetermined limitation in the amount of data that can be contained, and there is a problem in that a certain amount of data or more cannot be QR coded. In the case of the QR code standard version 40 (177&#xd7;177), for example, the maximum number of &#x201c;Chinese and Japanese kana&#x201d; characters that can be contained is 1817.</p>
<p id="p-0015" num="0014">Furthermore, as for the micro gradation in Non-Patent Document 1, it is difficult to expect the visible watermark information pattern (set of dots), and in the case where the design pattern includes a high frequency component, it is difficult to read the pattern embedded in the design pattern, and thus, a problem arises in that a complex process is required in order to avoid this.</p>
<p id="p-0016" num="0015">Here, there is a problem with the QR codes and micro gradation such that falsification is easy when a person with malicious intent separates each recording medium (paper, for example) portion where there is a QR code or micro gradation from the rest of the recording medium and pastes it to another document.</p>
<p id="p-0017" num="0016">The present invention is provided in view of the above described situations, and an object thereof is to provide an image processing apparatus, an image processing method, and a recording medium storing a computer program where additional image data for an additional image showing a gradation pattern on the basis of second data concerning the security of the image data and details data showing the detail information of a specific image in a two-dimensional code on the basis of first data concerning the security of the obtained image data, is added to the image data so that a greater number of pieces of data concerning the security can be added to a limited space, and at the same time, security can be enhanced without being affected by a high frequency component, such as of a fine line pattern, during the process of outputting the image data to a sheet, for example, and the falsification of the output can be checked and an illegal process can be prevented as a result of this checking through the matching of the specific image of the output on the basis of the details data after the outputting process.</p>
<p id="p-0018" num="0017">Another object of the present invention is to provide an image processing apparatus, an image processing method, and a recording medium storing a computer program where in the case where the additional image and specific image are added to the obtained image, the first data, second data and the details data showing the detail information of the specific image are separated from the additional image data for the additional image, and thus, the image data is processed on the basis of the results of matching of the first data and second data and/or the details data so that security can be enhanced in the process of the output where the image (image data) is formed in a predetermined recording medium and an unauthorized process can be prevented from being carried out on the output, for example, and the correspondence between the specific image of the output and the details data is matched so that the falsification of an output where each additional image portion of the output is separated from the rest of the recording medium and pasted to another output can be particularly checked.</p>
<p id="p-0019" num="0018">Still another object of the present invention is to provide an image reading apparatus where additional image data of an additional image on the basis of first data and second data concerning the security of the image data and the details data showing the detail information of a specific image is added to the image data read from a document so that a greater number of pieces of data concerning the security can be added to a limited space, and at the same time, security can be enhanced without being affected by a high frequency component during the process of outputting the read image data to a sheet, for example, and the falsification of the output can be checked and an illegal process can be prevented as a result of this checking through the matching of the specific image of the output on the basis of the details data after the outputting process.</p>
<p id="p-0020" num="0019">Yet another object of the present invention is to provide an image reading apparatus where in the case where the additional image and specific image are added to the image data read from a document, the first data, second data and the details data showing the detail information of the specific image are separated from the additional image data for the additional image, and thus, the image data is processed on the basis of the results of matching of the first data and second data and/or the details data so that security can be enhanced in the process for the output where the image data is formed in a predetermined recording medium and an unauthorized process can be prevented from being carried out on the output, for example, and the correspondence between the specific image of the output and the details data is matched so that the falsification of an output where each additional image portion of the output is separated from the rest of the recording medium and pasted to another output can be particularly checked.</p>
<p id="p-0021" num="0020">Still yet another object of the present invention is to provide an image forming apparatus where additional image data of an additional image on the basis of first data and second data concerning the security of the image data and the details data showing the detail information of a specific image added to an image to be formed is added to the image data of the image, and an image on the basis of the image data is formed on a sheet, for example, so that more data concerning the security can be added to a limited space, and at the same time, security can be enhanced during the process of outputting (forming) the image data on a sheet, and the falsification of the output can be checked and an illegal process can be prevented as a result of this checking through the matching of the specific image of the output on the basis of the details data after the output process.</p>
<p id="p-0022" num="0021">Another object of the present invention is to provide an image forming apparatus where in the case where image data of an image to which the additional image and specific image are added is obtained from a document, the first data, second data and the details data showing the detail information of the specific image are separated from the additional image data for the additional image, and thus, the image on the basis of the image data is formed on a sheet on the basis of the results of matching of the first data and second data and/or the details data so that security can be enhanced in the image formation of an image on a sheet on the basis of the image data and an unauthorized image can be prevented from being formed for the image data, and the correspondence between the specific image of the image and the details data is matched so that the falsification of an output where each additional image portion of the document is separated from the rest of the document and pasted to another output can be particularly checked.</p>
<p id="p-0023" num="0022">According to the present invention, in the case where image data is obtained, the code generating section generates the image data of the two-dimensional code on the basis of the first data, and the pattern generating section generates the pattern image data on the basis of the second data encrypted by the encrypting section and the details data. The adding section adds the additional image data of the additional image on the basis of the image data of the generated two-dimensional code and the pattern image data to the image data.</p>
<p id="p-0024" num="0023">According to the present invention, the specific image data selected and received by the selecting and receiving section is obtained from the storage section, and the obtained specific image data is added to the obtained image data.</p>
<p id="p-0025" num="0024">According to the present invention, the specific image is a visible watermark information in a halftone screen image or a watermark image, and the details data showing the detail information of the visible watermark information in a halftone screen image or the watermark image is encrypted by the encrypting section.</p>
<p id="p-0026" num="0025">According to the present invention, the obtaining section obtains image data from the image to which the additional image and specific image generated by the image processing apparatus are added, and the separation section separates the first data, second data and details data from the additional image data. The matching section matches the first data and second data separated by the separation section and carries out a process for the image data on the basis of the results of the matching and/or the details data.</p>
<p id="p-0027" num="0026">According to the present invention, in the case where the determining section determines that the detail information of the specific image on the basis of the image data obtained by the obtaining section corresponds to the details data, a process is carried out on the image data. In the case where the detail information of the specific image is determined not to correspond to the details data, no process is carried out on the image data.</p>
<p id="p-0028" num="0027">According to the present invention, the third data receiving section receives a specific user's name as the third data, for example, and the matching section matches the specific user's name (third data) with the first data or second data so that the following process is carried out on the basis of the results of the matching, for example, on the basis of whether or not the third data is included in the first data or second data.</p>
<p id="p-0029" num="0028">According to the present invention, additional image data of the additional image on the basis of the image data of the two-dimensional code generated by the code generating section in the image processing apparatus and the pattern image data generated by the pattern generating section in the image processing apparatus and the specific image data of the specific image are added to the image data read from a document by the adding section in the image processing apparatus.</p>
<p id="p-0030" num="0029">According to the present invention, in the case where the reading section reads the image data to which the additional image data generated by the image processing apparatus and the specific image data are added, the separation section of the image processing apparatus separates the first data, second data and details data from the additional image data, and the matching section of the image processing apparatus matches the first data and second data. The read image data is processed on the basis of the results of the matching by the matching section and/or the history data.</p>
<p id="p-0031" num="0030">According to the present invention, the image processing apparatus generates out put image data where the additional image data and specific image data are added to predetermined obtained image data, and an image on the basis of the out put image data is formed on a sheet, for example.</p>
<p id="p-0032" num="0031">According to the present invention, in the case where image data to which the additional image data and specific image data are added is obtained, the matching section of the image processing apparatus carries out matching and an image on the basis of the obtained image data is formed on a sheet, for example, on the basis of the results of the matching and/or the details data in the image data.</p>
<p id="p-0033" num="0032">According to the present invention, the recording medium stores the computer program. A computer reads out the computer program from the recording medium so that the image processing apparatus, image reading apparatus, image forming apparatus and image processing method are implemented by the computer.</p>
<p id="p-0034" num="0033">Furthermore, according to the present invention, image data of a two-dimensional code is generated on the basis of the first data for the security of the obtained image data, and the second data for the security of the obtained image data and the details data of the specific image are encrypted so that pattern image data showing a gradation pattern in a cell of the two-dimensional code is generated on the basis of the encrypted second data and details data. In addition, additional image data of an additional image on the basis of the image data of the two-dimensional code and the pattern image data is added to the obtained image data.</p>
<p id="p-0035" num="0034">According to the present invention, image data is obtained from the image to which the additional image and specific image are added, and the first data, second data and details data are separated from the additional image data of the additional image so that a process is carried out on the image data on the basis of the results of the matching of the separated first data and second data and/or the details data.</p>
<p id="p-0036" num="0035">According to the present invention, the gradation pattern on the basis of the second data for the security of a predetermined image data and the details data showing the detail information of the specific image on the basis of the image data is shown in the two-dimensional code on the basis of the first data for the security of the image data, and therefore, more data for the security can be added to a limited space and the security can be enhanced in the process of outputting the image data to a sheet, for example, without being affected by high frequency components, and at the same time, unauthorized copying can be prevented and falsification of the output can be checked through the matching of the specific image in the output on the basis of the details data after the outputting process.</p>
<p id="p-0037" num="0036">According to the present invention, in the case where the additional image and specific image are added to an obtained image, the first data, second data and details data showing the detail information of the specific image are separated from the additional image data of the additional image, and the image data is processed on the basis of the results of the matching of the first data and the second data and/or the details data, and therefore, the security can be enhanced in the process for the output where the image (image data) is formed on a predetermined recording medium, for example, and an unauthorized process can be prevented from being carried out on the output, and the correspondence between the specific image of the output and the details data can be matched so that falsification of the output, particularly by separating each additional image portion of the output from the rest of the recording medium and pasting it to another output, can be prevented.</p>
<p id="p-0038" num="0037">The above and further objects and features will more fully be apparent from the following detailed description with accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS</heading>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a principal configuration of a digital multi-function peripheral according to Embodiment 1;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 2A</figref> to <figref idref="DRAWINGS">FIG. 2D</figref> are diagrams for illustrating the process of detecting overlap;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram illustrating a principal configuration of the code creation section in the digital multi-function peripheral of Embodiment 1 of the present invention;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 4A</figref> and <figref idref="DRAWINGS">FIG. 4B</figref> are diagrams for illustrating micro gradation added by the micro gradation generation section in the digital multi-function peripheral of Embodiment 1 of the present invention;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram for illustrating a case where the data &#x201c;001100,&#x201d; which is an encryption of the second data, is shown in a cell of the QR code in <figref idref="DRAWINGS">FIG. 4A</figref> as a micro gradation;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram illustrating an example of a density value combination table that shows micro gradation data in a cell of the QR code of Embodiment 1 of the present invention;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram for illustrating the configuration and determination of the density value combination table of Embodiment 1 of the present invention;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram for illustrating another example of a density value combination table of Embodiment 1 of the present invention;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of processing executed by the control unit when the digital multi-function peripheral creates a document by adding the image of the gradation QR code and visible watermark information pattern data to an image based on obtained image data in Embodiment 1;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 10A</figref> and <figref idref="DRAWINGS">FIG. 10B</figref> are diagrams illustrating thumbnails for the visible watermark information patterns stored in the storage apparatus in the digital multi-function peripheral of Embodiment 1 of the present invention;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram illustrating an example of the document printed by the image output apparatus;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 12</figref> is a block diagram illustrating a principal configuration of the digital multi-function peripheral of Embodiment 2 of the present invention;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 13</figref> is a functional block diagram illustrating a principal configuration of the document authentication section included in the image processing apparatus of the digital multi-function peripheral of Embodiment 2;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart of copying of a document to which the gradation QR code and visible watermark information pattern are added, by the digital multi-function peripheral of Embodiment 2 of the present invention;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 15</figref> is a flowchart of processing executed by the control unit when the digital multi-function peripheral creates a document by adding the image of the gradation QR code of second data including the name of the authorized persons and visible watermark information pattern data to an image based on obtained image data in Embodiment 3;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 16</figref> is a flow chart showing the process of copying an above described copying authorization-required document in the digital multi-function peripheral of Embodiment 3 of the present invention;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 17</figref> is a functional block diagram illustrating a principal configuration of the digital multi-function peripheral of Embodiment 4 of the present invention;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 18</figref> is a functional block diagram illustrating a principal configuration of the document authorization section in the digital multi-function peripheral of Embodiment 4 of the present invention;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 19</figref> is a functional block diagram illustrating a principal configuration of the image reading apparatus of Embodiment 5 of the present invention;</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 20</figref> is a block diagram illustrating a principal configuration of the digital multi-function peripheral <b>1</b> of Embodiment 6 of the present invention;</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 21</figref> is a diagram for illustrating a conventional text hiding technology using visible watermark information in a halftone screen; and</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 22</figref> is a diagram for illustrating a conventional visible watermark information.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0061" num="0060">In the following, modes of the image processing apparatus, the image reading apparatus, the image forming apparatus, the image processing method, the computer program and the recording medium according to the present invention, which are applied to a digital multi-function peripheral having a copying function, a printing function and the like, are described concretely in reference to the drawings. Here, a QR code is used as an example of a two-dimensional code in order to make the description easy.</p>
<heading id="h-0006" level="1">First Embodiment</heading>
<p id="p-0062" num="0061">In the image forming apparatus of Embodiment 1 of the present invention, a process of adding a visible watermark information pattern (specific image) made of a text and a marking is additionally carried out on an image where the below described gradation QR code on the basis of the data for the security of an image to be outputted (hereinafter referred to as target image) is added to the target image so that an image for output is formed.</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a principal configuration of a digital multi-function peripheral <b>1</b> according to Embodiment 1. The digital multi-function peripheral <b>1</b> of Embodiment 1 includes a control unit <b>100</b>, an image reading apparatus <b>200</b> (reading section), an image processing apparatus <b>400</b>, an image output apparatus <b>700</b>, a storage unit <b>300</b> (storage section), a communication unit <b>600</b> and a control panel <b>500</b> (receiving section).</p>
<p id="p-0064" num="0063">The control unit <b>100</b> includes a CPU <b>101</b> (process section) for controlling the above described hardware and a RAM (not shown) for temporarily storing data required for the control (for example, the below described public key). In addition, the control unit <b>100</b> further includes a visible watermark information pattern receiving section <b>102</b> (selection receiving section) and an overlap detection section <b>103</b>.</p>
<p id="p-0065" num="0064">A predetermined program is downloaded into the control unit <b>100</b> from the storage unit <b>300</b> if necessary so that the downloaded program is run, and thus, the digital multi-function peripheral <b>1</b> operates as the image processing apparatus, the image reading apparatus and the image forming apparatus including the image processing apparatus, and/or the image reading apparatus</p>
<p id="p-0066" num="0065">As described below, the visible watermark information pattern receiving section <b>102</b> receives an instruction to select one or more visible watermark information patterns from among a number (plurality) of visible watermark information patterns stored in the storage unit <b>300</b> from the user from the control panel <b>500</b>.</p>
<p id="p-0067" num="0066">The overlap detection section <b>103</b> detects the overlap of the target image with the visible watermark information of text of the visible watermark information pattern during the process of generating an image for output by adding a visible watermark information pattern to the target image.</p>
<p id="p-0068" num="0067">In the following, detection of the overlap by the overlap detection section <b>103</b> is described. <figref idref="DRAWINGS">FIG. 2A</figref> to <figref idref="DRAWINGS">FIG. 2D</figref> are diagrams for illustrating the process of detecting overlap. <figref idref="DRAWINGS">FIG. 2A</figref> shows an image where a QR code is added to the target image (hereinafter referred to as temporary document image), and the following description relates to an example of a case where a visible watermark information pattern having visible watermark information of text made of a combination of shapes &#x201c;&#x394;, &#x25a1; and x&#x201d; as show in <figref idref="DRAWINGS">FIG. 2B</figref> is added to the temporary document image.</p>
<p id="p-0069" num="0068">The process of detecting overlap is carried out by storing the temporary document image in <figref idref="DRAWINGS">FIG. 2A</figref> and the visible watermark information pattern in <figref idref="DRAWINGS">FIG. 2B</figref> in a frame memory and detecting the overlap of a portion corresponding to &#x201c;&#x394;, &#x25a1; and x&#x201d; (visible watermark information of text) in the visible watermark information pattern or the entire area of the visible watermark information pattern with the temporary document image. This detection is carried out on the basis of the coordinates of the pixels for the image data of the temporary document image and the visible watermark information pattern (visible watermark information of text), for example.</p>
<p id="p-0070" num="0069">In the case where the overlap detection section <b>103</b> detects an overlapping visible watermark information of text, this visible watermark information of text is removed so that a visible watermark information pattern consisting of the remaining visible watermark information of text image (as shown in <figref idref="DRAWINGS">FIG. 2C</figref>) is generated, and the below described details data specifying a state of the visible watermark information pattern is prepared and encrypted. <figref idref="DRAWINGS">FIG. 2D</figref> shows an example of a printed material on the basis of the output image where the visible watermark information pattern in <figref idref="DRAWINGS">FIG. 2B</figref> is added to an image to which the gradation QR code is added.</p>
<p id="p-0071" num="0070">The storage unit <b>300</b> is, for example, a nonvolatile semiconductor memory and stores user names, each user's password and each user's secret key (and public key), which are associated with each other. In addition, image data for image processes, control programs for controlling the hardware sections, programs for generating a secret key used for the encryption of the below described second data or a decoding key, programs for adding image data of the below described gradation QR code, programs for displaying input screens for facilitating the input of a user name and password, programs for displaying a selection screen for receiving a selection whether or not processing is to be continued, and a number of image data of visible watermark information patterns (hereinafter referred to as visible watermark information pattern data) are stored in advance.</p>
<p id="p-0072" num="0071">Furthermore, the control panel <b>500</b> includes function buttons related to significant functions of the digital multi-function peripheral, numeric keys, an enter key, moving keys and a display section <b>501</b>. The function buttons are buttons for instructing execution of &#x201c;transmission of a facsimile&#x201d;, &#x201c;copying&#x201d;, &#x201c;printing&#x201d;, &#x201c;transmission of an e-mail&#x201d; and the like. The enter key is a key for defining a received instruction. The moving keys are keys for specifying a position of a QR code described later. The display section <b>501</b> is a liquid crystal display or the like.</p>
<p id="p-0073" num="0072">The image reading apparatus <b>200</b> optically reads a document to be processed so as to obtain image data of the document. Moreover, the image reading apparatus <b>200</b> includes an optical unit (reading section). The optical unit includes a light source for irradiating a document, such as an image sensor like a CCD (Charge Coupled Device), for reading a document. The image reading apparatus <b>200</b> makes an optical image, which is obtained through reflection from a document set in a prescribed reading position, focus on the image sensor, so as to output analog electric signals of RGB (R: red, G: green and B: blue). The analog electric signals outputted from the image reading apparatus <b>200</b> are inputted to the image processing apparatus <b>400</b>.</p>
<p id="p-0074" num="0073">The communication unit <b>600</b> includes a network card, a modem and the like so as to send image data having been processed by the image processing apparatus <b>400</b> to the external device. For example, the communication unit <b>600</b> sends an e-mail with image data attached to a specified destination.</p>
<p id="p-0075" num="0074">The image output apparatus <b>700</b> forms an image based on image data outputted from the image processing apparatus <b>400</b> by outputting the image onto a sheet such as recording paper or an OHP film. For this purpose, the image output apparatus <b>700</b> includes a photoreceptor, a charger, a laser writing device, a developer, a transferring device and the like (not shown). The charger charges the photoreceptor with a prescribed potential. The laser writing device forms an electrostatic latent image on the photoreceptor by emitting laser beams in accordance with received image data from outside. The developer develops the electrostatic latent image formed on the photoreceptor by supplying a toner. The transferring device transfers a toner image thus formed on the photoreceptor onto paper. The image output apparatus <b>700</b> forms an image desired by a user on a sheet by employing an electrophotographic method. Incidentally, although the image output apparatus <b>700</b> herein includes the laser writing device and forms an image by the electrophotographic method, it may be an apparatus for forming an image by an ink-jet method, a thermal transferring method, a sublimation method or the like.</p>
<p id="p-0076" num="0075">The image processing apparatus <b>400</b> generates image data of digital format on the basis of an analog electrical signal which is inputted through the image reading apparatus <b>200</b>, reads out the image data stored in the storage unit <b>300</b> so as to carry out a process in accordance with the type of image, and generates output image data of an output image. In addition, the image processing apparatus <b>400</b> includes a code creation section <b>410</b>. The code creation section <b>410</b> generates image data of a gradation QR code to be added to target image data of the target image which is inputted through the image reading apparatus <b>200</b>, for example, and adds the image data and the visible watermark information pattern data selected following an instruction received from the control panel <b>500</b> to the target image data. The output image data generated by the image processing apparatus <b>400</b> to which the image data of the gradation QR code and the visible watermark information pattern data are added is outputted to the image output apparatus <b>700</b> or the communication unit <b>600</b>.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram illustrating a principal configuration of the code creation section <b>410</b> in the digital multi-function peripheral <b>1</b> of Embodiment 1 of the present invention. The code creation section <b>410</b> includes a QR code generation section <b>401</b> (code generation section), an encryption section <b>402</b>, a micro gradation generation section <b>403</b> (pattern generation section) and a print position specification section <b>404</b>.</p>
<p id="p-0078" num="0077">The QR code generation section <b>401</b> generates image data of a QR code to be added to the target image data on the basis of the first data for security in printing an image on the basis of the target image data obtained from the image reading apparatus <b>200</b>, and transmitting the target image data together with e-mail as an attachment, or to the outside.</p>
<p id="p-0079" num="0078">The encryption section <b>402</b> encrypts the second data for security in printing an image on the basis of the target image data obtained from the image reading apparatus <b>200</b>, and transmitting the target image data together with e-mail as an attachment, or to the outside, and the details data representing the detail information of the visible watermark information pattern to be added to the target image data, by using the secret key of the person who generated the target image data, for example.</p>
<p id="p-0080" num="0079">The details data encrypted by the encryption section <b>402</b> according Embodiment 1 includes text specifying numbers to specify the visible watermark information of text included in the visible watermark information pattern which does not overlap with the target image, and position data to indicate the position of the visible watermark information of text which does not overlap with the target image, for example. The text specifying numbers are numbers included in a number of visible watermark information patterns stored in the storage unit <b>300</b> and allocated for the respective visible watermark information of texts, for example. Accordingly, by using the numbers, it is possible to specify the visible watermark information of text which is included in the visible watermark information patterns and does not overlap with the target image. Here, the details data is not limited to this above mentioned, and may specify all visible watermark information of texts included in the visible watermark information patterns.</p>
<p id="p-0081" num="0080">The first data and the second data are a name, an ID (IDentification) number, a contact address and the like of a creator or a user of image data and are data by which the creator or the user of the image data may be specified. Furthermore, the first data and the second data are not always identical to each other but may be different from each other.</p>
<p id="p-0082" num="0081">At this point, a secret key and a public key are widely used in a &#x201c;public cryptography&#x201d; in general. Now, procedures in processing of &#x201c;digital signature&#x201d; employing the public cryptography will be simply described.</p>
<p id="p-0083" num="0082">(1) A creator (a sender) of electronic data of a document prepares (creates) a secret key and a public key. (2) The creator (the sender) of the electronic data informs a receiver of the electronic data of the public key by using an e-mail, Web, a letter or the like. (3) The creator (the sender) of the electronic data encrypts the electronic data by using the secret key created in the procedure (1) and sends the encrypted electronic data to the receiver by using an e-mail, FTP (File Transfer Protocol), a printed matter or the like. (4) The receiver having received the encrypted electronic data decodes the encrypted electronic data sent in the procedure (3) by using the public key sent in the procedure (2). (5) When the encrypted electronic data can be decoded in the procedure (4), the creator (the sender) of the electronic data can be specified.</p>
<p id="p-0084" num="0083">Furthermore, RSA (Rivest-Shamir-Adleman) cryptography is generally known about encryption and decode executed by using a secret key and a public key. Now, the outline of the RSA cryptography will be described.</p>
<p id="p-0085" num="0084">A public key of the RSA cryptography is composed of a pair of natural numbers e and n, wherein n is a product of two prime numbers p and q, and e is a positive integer satisfying gcd (e, &#x3c6;(n))=1 (gcd: greatest common divisor). At this point, &#x3c6;(n) is the Euler function and is represented as &#x3c6;(n)=&#x3c6;(p)&#x3c6;(q)=(p&#x2212;1)(q&#x2212;1). It is assumed that there is an inverse element of the number e modulo &#x3c6;(n), which is indicated as d (1&#x2266;d&#x2266;p&#x2212;1). In this case, a relationship of ed&#x2261;1 (mod &#x3c6;(n)) holds. At this point, a relationship of x<sup>ed</sup>&#x2261;x (mod n) holds with respect to x (0&#x2266;x&#x3c;n) in accordance with the Euler's theorem. Accordingly, when the number d is known, x can be obtained on the basis of x<sup>e </sup>owing to the aforementioned properties. In other words, a cipher x<sup>e </sup>is created by encrypting x (0&#x2266;x&#x3c;n) by using the number e (e: encrypting key (secret key)). The cipher x<sup>e </sup>is decoded by using the number d (d: decoding key (a public key)).</p>
<p id="p-0086" num="0085">Incidentally, the secret key thus obtained may be inputted through a keyboard or the like when, for example, the document creator creates the document. Furthermore, the secret key may be precedently stored in the storage unit <b>300</b> in association with identification data of the user. In the following description, it is assumed that the secret key is precedently stored in the storage unit <b>300</b>.</p>
<p id="p-0087" num="0086">The micro gradation generation section <b>403</b> generates image data of a micro gradation (gradation pattern) having a number of regions with different densities which are shown in the cell of the QR code, on the basis of the second data and details data encrypted by the encryption section <b>402</b> (hereinafter referred to as encrypted data).</p>
<p id="p-0088" num="0087">Now, generation of a micro gradation and addition of a QR code executed by the micro gradation generation section <b>403</b> will be described. It is herein assumed that the micro gradation is created on the basis of the encrypted data. <figref idref="DRAWINGS">FIGS. 4A and 4B</figref> are explanatory diagrams explaining addition of the micro gradation performed by the micro gradation generation section <b>403</b> of the digital multi-function peripheral <b>1</b> of Embodiment 1. <figref idref="DRAWINGS">FIG. 4A</figref> and <figref idref="DRAWINGS">FIG. 4B</figref> illustrate an image of a QR code generated, for example, on the basis of a character string &#x201c;This is a test.&#x201d;. <figref idref="DRAWINGS">FIG. 4B</figref> is an enlarged view of a part of the QR code of <figref idref="DRAWINGS">FIG. 4A</figref> (specifically, a circled portion of <figref idref="DRAWINGS">FIG. 4A</figref>). <figref idref="DRAWINGS">FIG. 4B</figref> illustrates information of &#x201c;010101&#x201d; assuming that a white portion indicates &#x201c;0&#x201d; and a black portion indicates &#x201c;1&#x201d;.</p>
<p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. 5</figref> is an exemplary diagram illustrating an exemplary QR code in which information of the respective bits of the encrypted data &#x201c;001100&#x201d; is expressed by micro gradations in cells (that is, areas painted with black or white) of the QR code of <figref idref="DRAWINGS">FIG. 4A</figref>. Each cell of the QR code is divided vertically and laterally by 8 respectively, so as to express, with one cell, 1 bit of the encrypted data. The encrypted data is generated by changing the densities of the respective blocks obtained by finely dividing the cell. Data &#x201c;0&#x201d; and data &#x201c;1&#x201d; are distinguished from each other in accordance with a difference between pattern images. The pattern images include pattern images of data &#x201c;0&#x201d; and &#x201c;1&#x201d; obtained when a cell of a QR code is black and pattern images of data &#x201c;0&#x201d; and &#x201c;1&#x201d; obtained when the cell of the QR code is white. <figref idref="DRAWINGS">FIG. 6</figref> is an exemplary diagram illustrating examples of a table of a combination of densities of micro gradation data expressed in cells of a QR code in Embodiment 1. In <figref idref="DRAWINGS">FIG. 6</figref>, black and white are respectively represented as &#x201c;0&#x201d; and &#x201c;255&#x201d; by using RGB densities, and density distributions of the four kinds of pattern images expressed in cells are illustrated. As a RGB density is smaller, a color corresponding to the RGB density is closer to black, and as the RGB density is larger, a color corresponding to the RGB density is closer to white. <figref idref="DRAWINGS">FIG. 7</figref> is an explanatory diagram illustrating the structure and determination of a table of a combination of densities used in Embodiment 1. In determination of the QR code generated on the basis of the first data, a cell having a density of 195 or more is determined as white, and a cell having a density of 60 or less is determined as black. In the determination of black and white, densities from 60 to 195 correspond to a margin. On the other hand, with respect to a micro gradation based on the encrypted data, when a cell of a QR code is white, a color with a density of 0 through 30 is used for generating the micro gradation, and when a cell of the QR code is black, a color with a density of 225 through 255 is used for generating the micro gradation.</p>
<p id="p-0090" num="0089">When a micro gradation representing information of 1 bit of the encrypted data is generated in one cell of a QR code in this manner, no high frequency component is included as an element of the micro gradation. In other words, since the micro gradation is generated by adding gradation in what is called a solid area, a frequency component of a white line or a black line is never included. Accordingly, the micro gradation can be generated with a very simple structure. Furthermore, since the micro gradation never includes a high frequency component, the micro gradation can be simply read, and there is no need to perform complicated processing for reading it.</p>
<p id="p-0091" num="0090">In <figref idref="DRAWINGS">FIG. 5</figref>, one cell of the QR code expresses the information of 1 bit of the encrypted data. When it is necessary to embed a larger amount of encrypted data, however, the amount of data can be increased by four times by dividing one cell of a QR code vertically and laterally by 16 respectively as illustrated in <figref idref="DRAWINGS">FIG. 8</figref>. Each cell of a QR code is divided by a number corresponding to an integral multiple of 8. (More precisely, a number for dividing a cell depends upon the number of blocks necessary for a micro gradation to express information of 1 bit. In Embodiment 1, since the micro gradation expresses the information of 1 bit by using 8&#xd7;8 blocks, the number for dividing a cell is an integral multiple of 8.) Incidentally, it is assumed in Embodiment 1 that the QR code and the micro gradation are respectively expressed by black and white data (K data).</p>
<p id="p-0092" num="0091">When the output image data is printed, the print position specification section <b>404</b> specifies a position where the QR code with the micro gradation added (hereinafter referred to as the gradation QR code) is to be recorded (hereinafter referred to as the print position) on recording paper. As a method for specifying the print position of a gradation QR code, the creator of the document arbitrarily inputs (specifies) the print position with the moving keys of the control panel <b>500</b> in creating the document. As another method, the gradation QR code is always printed in a constant position (for example, in a position at a right end of a header) by using a program.</p>
<p id="p-0093" num="0092">In the following, in the digital multi-function peripheral <b>1</b> of Embodiment 1, the process of generating the output image data by adding the image data of the gradation QR code on the basis of the first data, second data and details data and the visible watermark information pattern data to the image data obtained by the image reading apparatus <b>200</b>, is described in detail.</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of processing executed by the control unit <b>100</b> when the digital multi-function peripheral <b>1</b> creates a document by adding the image of the gradation QR code and visible watermark information pattern data to an image based on obtained image data in Embodiment 1.</p>
<p id="p-0095" num="0094">For convenience, it is assumed in the following description that the first data and the second data are both a name of a creator of a document. Furthermore, it is also assumed that the image data from a prescribed document is read by image reading apparatus <b>200</b>, and an image on the basis of said image data is printed. It is not limited to this above mentioned. The description may be given on a case where the digital multi-function peripheral <b>1</b> of Embodiment 1 is connected to electric equipment such as a PC (Personal Computer) or a PDA (Personal Digital Assistance) having a function to edit and create image data so as to obtain image data from the electric equipment. Here, the storage unit <b>300</b> stores thumbnails for showing the visible watermark information patterns in <figref idref="DRAWINGS">FIG. 10A</figref> and <figref idref="DRAWINGS">FIG. 10B</figref>, and when a thumbnail is displayed in the display section <b>501</b>, the selection of a visible watermark information pattern is received from the control panel <b>500</b>. <figref idref="DRAWINGS">FIG. 10A</figref> is a diagram showing examples of thumbnails for visible watermark information patterns in the case where the visible watermark information of text is high resolution, and <figref idref="DRAWINGS">FIG. 10B</figref> is a diagram in the case of low resolution.</p>
<p id="p-0096" num="0095">The creator of the document first inputs, before reading a desired document, his/her name and password by operating the control panel <b>500</b>. Thus, the CPU <b>101</b> of the control unit <b>100</b> receives the name (first data) and the password of the document creator through the control panel <b>500</b> (Step S<b>101</b>). At this point, the description is given on a case where the creator of the document is one in number, and in the case where there are a plurality of creators of a document, names of the respective creators may be inputted. Alternatively, a number, a contact address or the like by which an individual can be specified may be inputted instead of the name. Alternatively, another material created by the creator of the document, a reference, update history of the document, a team member name or the like may be inputted.</p>
<p id="p-0097" num="0096">Next, the creator of the document instructs the digital multi-function peripheral <b>1</b> to read a document. The CPU <b>101</b> receives the instruction to read the document through the control panel <b>500</b> and makes the image reading apparatus <b>200</b> read the document. Image data read by the image reading apparatus <b>200</b> is temporarily stored in the storage unit <b>300</b>. After editing such as shrink, magnification, and rotation of the image data, for example, the creator of the document presses the &#x201c;printing&#x201d; button of the control panel <b>500</b> for printing an image (target image) based on the edited image data (obtained image data) on recording paper.</p>
<p id="p-0098" num="0097">The CPU <b>101</b> determines whether or not a printing instruction has been received from the user by, for example, monitoring an operation of the &#x201c;printing&#x201d; button of the control panel <b>500</b> (Step S<b>102</b>). When it is determined that a printing instruction has not been received (Step S<b>102</b>: NO), the CPU <b>101</b> waits for reception of a printing instruction. On the other hand, when it is determined that a printing instruction has been received (Step S<b>102</b>: YES), the CPU <b>101</b> matches the name and the password of the document creator received in Step S<b>101</b> on the basis of the data stored in the storage unit <b>300</b> (Step S<b>103</b>).</p>
<p id="p-0099" num="0098">When the name and the password of the document creator accord with those stored in the storage unit <b>300</b>, the CPU <b>101</b> generates image data of a QR code on the basis of the document creator name received in Step S<b>101</b> (Step S<b>104</b>). This procedure is executed by the CPU <b>101</b> instructing the QR code generation section <b>401</b> of the code creation section <b>410</b> to generate image data of a QR code based on the document creator name.</p>
<p id="p-0100" num="0099">On the other hand, when the name and the password of the document creator do not accord with those stored in the storage unit <b>300</b>, the CPU <b>101</b> displays, on the display section <b>501</b>, an input screen including a text that the name and the password of the document creator do not accord for urging to input the name and the password of the document creator again.</p>
<p id="p-0101" num="0100">Next, the CPU <b>101</b> instructs the print position specification section <b>404</b> to specify a position for adding the gradation QR code which is generated in Step S<b>104</b>, on recording paper (Step S<b>105</b>). For example, in the digital multi-function peripheral <b>1</b> of Embodiment 1, the gradation QR code is printed at a right end of a header in accordance with a prescribed program. Thus, it is possible to generate image data for the temporary document image.</p>
<p id="p-0102" num="0101">After that, the CPU <b>101</b> instructs the visible watermark information pattern receiving section <b>102</b> to receive the selection of a visible watermark information pattern (Step S<b>106</b>). In response to the instruction of the CPU <b>101</b>, the visible watermark information pattern receiving section <b>102</b> reads out the thumbnail for a visible watermark information pattern stored in the storage unit <b>300</b> and displays it on the display section <b>501</b>. The thumbnail is shown together with a text specifying number (see <figref idref="DRAWINGS">FIG. 10</figref>) and the document creator operates the control panel <b>500</b> and presses the number of the desired visible watermark information pattern. Accordingly, the visible watermark information pattern receiving section <b>102</b> can receive the selection of a visible watermark information pattern from the control panel <b>500</b>.</p>
<p id="p-0103" num="0102">Here, it is possible to select more than just one visible watermark information pattern. When multiple visible watermark information patterns are selected, a visible watermark information pattern where the visible watermark information of text of the selected visible watermark information patterns are arranged randomly may be generated, for example.</p>
<p id="p-0104" num="0103">Next, the CPU <b>101</b> determines whether or not the temporary document image generated in Step S<b>105</b> and the visible watermark information of text of the visible watermark information pattern received in Step S<b>106</b> overlap (Step S<b>107</b>). The CPU <b>101</b> instructs the overlap detection section <b>103</b> to detect overlapping, and The determination is based on the results of the overlapping detection by the overlap detection section <b>103</b>. The process of overlapping detection by the overlap detection section <b>103</b> is described above, and the details are not repeated.</p>
<p id="p-0105" num="0104">When it is determined that the temporary document image and the visible watermark information pattern overlap (Step S<b>107</b>: YES), the visible watermark information pattern is modified so as to remove the visible watermark information of text in the overlapping portion (Step S<b>108</b>). The visible watermark information pattern data on which the process of modifying is carried out is temporarily stored in the RAM.</p>
<p id="p-0106" num="0105">When it is determined that the temporary document image and the visible watermark information pattern do not overlap (Step S<b>107</b>: NO), or after the process of modifying the visible watermark information pattern in Step S<b>108</b>, the details data representing the detail information of the visible watermark information pattern is prepared and stored in the storage unit <b>300</b> (Step S<b>109</b>). In the case where the selection of multiple visible watermark information patterns is received in Step S<b>106</b>, for example, and a process of modifying the visible watermark information patterns is carried out in Step S<b>108</b>, the details data represents the text specifying numbers for visible watermark information of text included in the visible watermark information patterns after the modification and the position data for displaying each visible watermark information of text (coordinates).</p>
<p id="p-0107" num="0106">Next, the CPU <b>101</b> instructs the encryption section <b>402</b> of the code creation section <b>410</b> to encrypt the details data and the name of the document creator (second data) (Step S<b>110</b>). In response to the instruction of the CPU <b>101</b>, the encryption section <b>402</b> obtains a secret key corresponding to the name of the document creator (user) from the storage unit <b>300</b> and encrypts the details data and the name of the document creator by using the secret key.</p>
<p id="p-0108" num="0107">Here, the document creator may input the secret key by using the control panel <b>500</b> at the time of preparing the document. In this case, a process of determining whether or not the inputted secret key matches the name and password of the document creator on the basis of the data stored in the storage unit <b>300</b> may need to be carried out.</p>
<p id="p-0109" num="0108">After that, the CPU <b>101</b> generates image data of micro gradation (gradation pattern) on the basis of the details data and the name of the document creator encrypted by the encryption section <b>402</b> (encrypted data) (Step S<b>111</b>). This is achieved when the CPU <b>101</b> instructs the microgradation generation section <b>403</b> to generate image data of micro gradation on the basis of the encrypted data. The process of generating image data of micro gradation by the micro gradation generation section <b>403</b> is described above, and the details are not repeated. As a result of the above described process, micro gradation based on encrypted details data and the name of the document creator is shown in the QR code on the basis of the first data, and image data (additional image data) of the gradation QR code (additional image) is generated.</p>
<p id="p-0110" num="0109">The CPU <b>101</b> (addition section) adds the image data of the gradation QR code to the image data for the target image, so that the gradation QR code is printed in the position specified in Step S<b>105</b> (Step S<b>112</b>), reads the visible watermark information pattern selected and received in Step S<b>106</b> or the visible watermark information pattern on which a modifying process is carried out in Step S<b>108</b> from the storage unit <b>300</b>, and adds it to the image data of the target image. As a result of the process, output image data is generated.</p>
<p id="p-0111" num="0110">Next, the CPU <b>101</b> instructs the image output apparatus <b>700</b> to print an image on recording paper on the basis of the out put image data (Step S<b>113</b>). In response to the instruction of the CPU <b>101</b>, the image output apparatus <b>700</b> prints an image on the basis of the out put image data. A gradation QR is printed on the document prepared by the image output apparatus <b>700</b> at the right end of the header on the basis of the second data and details data. <figref idref="DRAWINGS">FIG. 11</figref> is a diagram illustrating an example of the document printed by the image output apparatus <b>700</b>.</p>
<p id="p-0112" num="0111">Thus, the gradation QR code and the visible watermark information pattern are attached to the document, so that the security can be enhanced, by verifying whether the specific image of the document and the details data and/or the first data and second data correspond during a later process. And illegal falsification of the document by cutting out the gradation QR code portion from a document and pasting it on another document can be prevented. The details are described in the Embodiment 2.</p>
<heading id="h-0007" level="1">Second Embodiment</heading>
<p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. 12</figref> is a block diagram illustrating a principal configuration of the digital multi-function peripheral <b>1</b> of Embodiment 2 of the present invention. Like the digital multi-function peripheral <b>1</b> of Embodiment 1, the digital multi-function peripheral <b>1</b> of Embodiment 2 includes hardware, such as a control unit <b>100</b>, an image reading apparatus <b>200</b>, an image processing apparatus <b>400</b>, an image output apparatus <b>700</b>, a storage unit <b>300</b>, a communication unit <b>600</b> and an control panel <b>500</b>, and forms a digital multi-function peripheral as a whole.</p>
<p id="p-0114" num="0113">Here, the digital multi-function peripheral <b>1</b> of Embodiment 2 is different from the digital multi-function peripheral <b>1</b> of Embodiment 1 in that the control unit <b>100</b> includes a visible watermark information pattern matching section <b>104</b> and the image processing apparatus <b>400</b> includes a document authentication section <b>420</b>, in addition to a code creation section <b>410</b>.</p>
<p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. 13</figref> is a functional block diagram illustrating a principal configuration of the document authentication section <b>420</b> included in the image processing apparatus <b>400</b> of the digital multi-function peripheral <b>1</b> of Embodiment 2. The document authentication section <b>420</b> includes a QR code data obtaining section <b>416</b> (separation section), a micro gradation data obtaining section <b>417</b> (separation section), a decoding section <b>418</b> and a data comparison section <b>419</b> (matching section).</p>
<p id="p-0116" num="0115">The QR code data obtaining section <b>416</b> extracts (separates), for example, from image data of a QR code included in image data of a document read by the image reading apparatus <b>200</b>, first data expressed with a QR code (hereinafter referred to as the QR code data). The QR code data obtaining section <b>416</b> specifies the position of the QR code on the basis of cut-out symbols of the QR code, and extracts and obtains the QR code data.</p>
<p id="p-0117" num="0116">The micro gradation data obtaining section <b>417</b> extracts the encrypted data; that is to say, the second data encrypted, and the details data of the image data of the document from the image data of the gradation QR code obtained from the image data of the document read by the image reading apparatus <b>200</b>, for example.</p>
<p id="p-0118" num="0117">The decoding section <b>418</b> decodes the encrypted data obtained by the micro gradation data obtaining section <b>417</b> by using a public key (or decoding key).</p>
<p id="p-0119" num="0118">The data comparison section <b>419</b> compares (matches), for example, first data and second data with each other. The first data corresponds to the QR code data obtained by the QR code data obtaining section <b>416</b>. The second data corresponds to data obtained by decoding, by the decoding section <b>418</b>, the encrypted second data obtained by the micro gradation data obtaining section <b>417</b>.</p>
<p id="p-0120" num="0119">In addition, the visible watermark information pattern matching section <b>104</b> of the control unit <b>100</b> matches, for example, the visible watermark information pattern of the image data of the document read by the image reading apparatus <b>200</b> and the details data extracted by the micro gradation data obtaining section <b>417</b> and decoded by the decoding section <b>418</b>, and determines whether or not accord with each other.</p>
<p id="p-0121" num="0120">The details data has a text specifying number for specifying visible watermark information of text that does not overlap with the target image of the document, and the coordinates of the display position of the visible watermark information of text corresponding to the text specifying number. Therefore, the visible watermark information pattern matching section <b>104</b> matches the visible watermark information pattern of the image data of the document and the details data on the basis of the details data, and determines whether or not the visible watermark information pattern of the image data of the document correspond to the details data.</p>
<p id="p-0122" num="0121">In addition, the read text specifying data specifying visible watermark information of text in the case where the visible watermark information pattern of the document is read by the image reading apparatus <b>200</b> is stored in the storage unit <b>300</b> of the digital multi-function peripheral <b>1</b> of Embodiment 2 together with the matching text specifying number. That is to say, the image reading apparatus <b>200</b> can read only low resolution images, and therefore, the read text specifying data corresponds to the visible watermark information pattern before it is read by the image reading apparatus <b>200</b> with the high resolution portions removed.</p>
<p id="p-0123" num="0122">In the following, the process for a case where the digital multi-function peripheral <b>1</b> of Embodiment 2 handles the document (image data) printed by the digital multi-function peripheral <b>1</b> of Embodiment 1 to which the gradation QR code and visible watermark information pattern are added is described. For convenience, it is assumed in the following description that a user copies a document printed by the digital multi-function peripheral <b>1</b> of Embodiment 1.</p>
<p id="p-0124" num="0123">Furthermore, in the gradation QR code added to the document, QR code data is data corresponding to a document creator name (first data), and the name of the document creator (second data) and the details data are generated in the cell of the QR code as micro gradation. Incidentally, the storage unit <b>300</b> stores, in the same manner as in Embodiment 1, data in which a user name, a password of each user, a public key of each user are associated with one another.</p>
<p id="p-0125" num="0124"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart of copying of a document to which the gradation QR code and visible watermark information pattern are added, by the digital multi-function peripheral <b>1</b> of Embodiment 2 of the present invention.</p>
<p id="p-0126" num="0125">A user desiring to copy the document to which the gradation QR code and visible watermark information pattern are added places the document on a scanner platen and instructs copying of the document by operating the control panel <b>500</b>.</p>
<p id="p-0127" num="0126">The CPU <b>101</b> of the control unit <b>100</b> receives the copying instruction from the user through the control panel <b>500</b> (Step S<b>201</b>). When the instruction is received from the user, the CPU <b>101</b> displays, on the display section <b>501</b>, an input screen for urging to input a user name and a password by using a program stored in the storage unit <b>300</b>. When the user inputs the user name and the password by operating the control panel <b>500</b>, the CPU <b>101</b> receives the user name and the password through the control panel <b>500</b> (Step S<b>202</b>).</p>
<p id="p-0128" num="0127">When the user name and the password are received, the CPU <b>101</b> matches the user name and the password on the basis of data precedently stored in the storage unit <b>300</b> (Step S<b>203</b>). When the user name and the password accord with the stored data, the CPU <b>101</b> instructs the image reading apparatus <b>200</b> to read an image of the document so as to obtain image data of the document (Step S<b>204</b>).</p>
<p id="p-0129" num="0128">On the other hand, when the user name and the password do not accord with the stored data, the CPU <b>101</b> displays, on the display section <b>501</b>, a text that the user name and the password do not accord and an input screen for urging to input the user name and the password again.</p>
<p id="p-0130" num="0129">Next, the CPU <b>101</b> instructs the QR code data obtaining section <b>416</b> to extract (separate) QR code data from the image data of the document (Step S<b>205</b>). In response to the instruction of the CPU <b>101</b>, the QR code data obtaining section <b>416</b> specifies a position where the QR code is printed on the basis of cutout symbols of the QR code, so as to extract the QR code data from the image data of the document. Through this procedure, it is possible to obtain a document creator name (first data).</p>
<p id="p-0131" num="0130">Thereafter, the CPU <b>101</b> reads a public key (a decoding key) to be used for decoding encrypted data from data stored in the storage unit <b>300</b> on the basis of the document creator name (or password) received in Step S<b>202</b> (Step S<b>206</b>). The method for obtaining the public key is not limited to this method but the public key may be obtained by receiving it from the user through the control panel <b>500</b>. The obtained public key is temporarily stored in the RAM of the control unit <b>100</b>.</p>
<p id="p-0132" num="0131">Next, the CPU <b>101</b> instructs the micro gradation data obtaining section <b>417</b> to extract (separate) micro gradation data generated in the cell of the QR code as micro gradation by specifying a position of the QR code on the basis of cutout symbols of the QR code (Step S<b>207</b>). In response to the instruction of the CPU <b>101</b>, the micro gradation data obtaining section <b>417</b> extracts the micro gradation data of the QR code; that is to say, encrypted data, and can obtain the second encrypted data and details data, which are the encrypted data.</p>
<p id="p-0133" num="0132">The CPU <b>101</b> instructs the decoding section <b>418</b> to decode the micro gradation data extracted in Step S<b>207</b>; that is to say, the encrypted data (Step S<b>208</b>). In response to the instruction of the CPU <b>101</b>, the decoding section <b>418</b> reads the public key stored in the RAM of the control unit <b>100</b> and decodes the encrypted data by using the public key.</p>
<p id="p-0134" num="0133">Next, the CPU <b>101</b> determines whether or not the encrypted data is decoded by the decoding section <b>418</b> (Step S<b>209</b>). When it is determined that the encrypted data is not decoded by the decoding section <b>418</b> (Step S<b>209</b>: NO), the CPU <b>101</b> unauthenticates the document (image data) as an unreliable document (Step S<b>213</b>).</p>
<p id="p-0135" num="0134">On the other hand, when it is determined that the encrypted data is decoded by the decoding section <b>418</b> (Step S<b>209</b>: YES), the CPU <b>101</b> instructs the data comparison section <b>419</b> to compare the second data decoded by the decoding section <b>418</b> with the QR code data (first data) obtained in Step S<b>205</b>. Incidentally, the CPU <b>101</b> determines whether or not the second data and the QR code data (first data) accord with each other in accordance with the comparison result obtained by the data comparison section <b>419</b>. That is to say, in the present embodiment, the first data and the second data are both the name of the document creator, and therefore, the CPU <b>101</b> determines whether or not the name of the document creator matches (Step S<b>210</b>).</p>
<p id="p-0136" num="0135">When it is determined that the second data and the QR code data do not accord with each other; that is to say, when it is determined that the name of the document creator does not match (Step S<b>210</b>: NO), the CPU <b>101</b> unauthenticates the document (image data) as an unreliable document (Step S<b>214</b>). In this case, the CPU <b>101</b> displays the result of the determination saying the document is unreliable and a selection screen for receiving selection whether or not the processing is to be continued on the display section <b>501</b> of the control panel <b>500</b> (Step S<b>215</b>).</p>
<p id="p-0137" num="0136">Thereafter, the CPU <b>101</b> may cancel the copying instruction received in Step S<b>201</b>, discard the image data, inform the creator of the document including the QR code through the communication unit <b>600</b>, or the like. In this manner, damage such as forgery of a document by a malicious third party can be prevented.</p>
<p id="p-0138" num="0137">When it is determined that the second data and the QR code data accord with each other; that is to say, when it is determined that the name of the document creator matches (Step S<b>210</b>: YES), the CPU <b>101</b> (determination section) determines whether or not the detail information of the visible watermark information pattern in the image data of the document read in Step S<b>204</b> corresponds to the details data decoded in Step S<b>208</b> (Step S<b>211</b>). Because the visible watermark information of text included in the visible watermark information pattern of the image data of the document read in Step S<b>204</b> which does not overlap with the target image in the document and the coordinates of said visible watermark information of text can be specified on the basis of the read text specifying data stored in the storage unit <b>300</b>, for example, the visible watermark information of text and its coordinates are matched with the details data decoded in Step S<b>208</b> in the determination.</p>
<p id="p-0139" num="0138">When it is determined that the detail information of the visible watermark information pattern of the image data of the document do not match the details data (Step S<b>211</b>: NO), the CPU <b>101</b> moves the process to Step S<b>214</b> and Step <b>215</b> in sequence. Meanwhile, when it is determined that the detail information of the visible watermark information pattern in the image data of the document match the details data (Step S<b>211</b>: YES), the CPU <b>101</b> determines that the document (image data) is reliable and authorizes it (Step S<b>212</b>), and then processes (copies) the image data of the document.</p>
<p id="p-0140" num="0139">This structure for matching the visible watermark information pattern can prevent illegal falsification of a document where a person with malicious intent cuts and separates the gradation QR code for the document (document) from the rest of the recording paper and pastes it on another document.</p>
<p id="p-0141" num="0140">Like reference numerals are used to refer to like elements used in Embodiment 1 so as to omit the detailed description.</p>
<heading id="h-0008" level="1">Third Embodiment</heading>
<p id="p-0142" num="0141">Processes on the document to which the gradation QR code and the visible watermark information pattern are attached which the document creator does not desire are limited in the Embodiment 3, and this is described below.</p>
<p id="p-0143" num="0142">The digital multi-function peripheral <b>1</b> of Embodiment 3 has the same structure as the image forming apparatus of Embodiment 1 and Embodiment 2, but is characterized by the process in the encryption section <b>402</b> of the code creation section <b>410</b>. In further detail, the encryption section <b>402</b> in the digital multi-function peripheral <b>1</b> of Embodiment 3 encrypts data for limiting use of the printed document (or image data of the document), in addition to the name of the document creator. In the case where the document creator wants to specify persons who are permitted/prohibited use of the document, for example, the data for specifying them is encrypted by the encryption section <b>402</b>. Thus, the micro gradation generation section <b>403</b> generates image data of micro gradation (gradation pattern) on the basis of the data for specifying the persons which is encrypted by the encryption section <b>402</b>. In the following, an example of a case where the encryption section <b>402</b> encrypts the data (name or ID code, for example) for specifying persons who are permitted to copy the document (hereinafter referred to as authorized persons) is described in order to make the description easy.</p>
<p id="p-0144" num="0143"><figref idref="DRAWINGS">FIG. 15</figref> is a flowchart of processing executed by the control unit <b>100</b> when the digital multi-function peripheral <b>1</b> creates a document by adding the image of the gradation QR code of second data including the name of the authorized persons and visible watermark information pattern data to an image based on obtained image data in Embodiment 3.</p>
<p id="p-0145" num="0144">The creator of the document first inputs, before reading a document, his/her name and password by operating the control panel <b>500</b>. Thus, the CPU <b>101</b> of the control unit <b>100</b> receives the name (first data) and the password of the document creator through the control panel <b>500</b> (Step S<b>301</b>).</p>
<p id="p-0146" num="0145">Next, the CPU <b>101</b> receives the instruction to read the document through the control panel <b>500</b> and makes the image reading apparatus <b>200</b> read the document. Image data read by the image reading apparatus <b>200</b> is temporarily stored in the storage unit <b>300</b>. After editing such as shrink, magnification, and rotation of the image data, for example, the creator of the document presses the &#x201c;printing&#x201d; button of the control panel <b>500</b> for printing an image (target image) based on the edited image data (obtained image data) on recording paper.</p>
<p id="p-0147" num="0146">The CPU <b>101</b> determines whether or not a printing instruction has been received from the user by, for example, monitoring an operation of the &#x201c;printing&#x201d; button of the control panel <b>500</b> (Step S<b>302</b>). When it is determined that a printing instruction has not been received (Step S<b>302</b>: NO), the CPU <b>101</b> waits for reception of a printing instruction. On the other hand, when it is determined that a printing instruction has been received (Step S<b>302</b>: YES), the CPU <b>101</b> displays a screen for facilitating input of the name of the authorized person on the display section <b>501</b>, for example. The document creator operates the control panel <b>500</b> so as to input the name of the authorized person. As a result, the CPU <b>101</b> receives the name of the authorized person from the control panel <b>500</b> (Step S<b>303</b>).</p>
<p id="p-0148" num="0147">Next, the CPU <b>101</b> matches the name and the password of the document creator received in Step S<b>301</b> on the basis of the data stored in the storage unit <b>300</b> (Step S<b>304</b>).</p>
<p id="p-0149" num="0148">When the name and the password of the document creator accord with those stored in the storage unit <b>300</b>, the CPU <b>101</b> generates image data of a QR code on the basis of the document creator name received in Step S<b>301</b>, by instructing the QR code generation section <b>401</b> of the code creation section <b>410</b> to generate image data of a QR code based on the document creator name (Step S<b>305</b>).</p>
<p id="p-0150" num="0149">Next, the CPU <b>101</b> instructs the print position specification section <b>404</b> to specify a position for adding the gradation QR code which is generated in Step S<b>305</b>, on recording paper (Step S<b>306</b>). Thus, it is possible to generate image data for the temporary document image.</p>
<p id="p-0151" num="0150">After that, the CPU <b>101</b> receives the selection of a visible watermark information pattern by instructing the visible watermark information pattern receiving section <b>102</b> to receive the selection of a visible watermark information pattern (Step S<b>307</b>).</p>
<p id="p-0152" num="0151">Next, the CPU <b>101</b> instructs the overlap detection section <b>103</b> to detect overlapping, determines whether or not the temporary document image generated in Step S<b>306</b> and the visible watermark information of text of the visible watermark information pattern received in Step S<b>106</b> overlap, on the basis of the overlapping detection result by the overlap detection section <b>103</b> (Step S<b>308</b>)</p>
<p id="p-0153" num="0152">When it is determined that the temporary document image and the visible watermark information pattern overlap (Step S<b>308</b>: YES), the visible watermark information pattern is modified so as to remove the visible watermark information of text in the overlapping portion (Step S<b>309</b>).</p>
<p id="p-0154" num="0153">When it is determined that the temporary document image and the visible watermark information pattern do not overlap (Step S<b>308</b>: NO), or after the process of modifying the visible watermark information pattern in Step S<b>309</b>, the details data of said visible watermark information pattern is prepared and stored in the storage unit <b>300</b> (Step S<b>310</b>).</p>
<p id="p-0155" num="0154">Next, the CPU <b>101</b> encrypts the details data and the second data including the name of the document creator and the name of the authorized person, by instructing the encryption section <b>402</b> of the code creation section <b>410</b> (Step S<b>311</b>). In response to the instruction of the CPU <b>101</b>, the encryption section <b>402</b> encrypts the details data and the second data by using the public key for each authorized person corresponding to the name of the authorized person.</p>
<p id="p-0156" num="0155">After that, the CPU <b>101</b> generates image data of micro gradation (gradation pattern) on the basis of the details data and the second data encrypted by the encryption section <b>402</b> (Step S<b>312</b>). This is achieved when the CPU <b>101</b> instructs the micro gradation generation section <b>403</b> to generate image data of micro gradation on the basis of the encrypted data. As a result of the above described process, micro gradation based on encrypted details data and the second data is shown in the QR code on the basis of the first data, and image data (additional image data) of the gradation QR code (additional image) is generated.</p>
<p id="p-0157" num="0156">The CPU <b>101</b> (addition section) adds the image data of the gradation QR code to the image data for the target image, so that the gradation QR code is printed in the position specified in Step S<b>105</b> (Step S<b>313</b>), reads the visible watermark information pattern selected and received in Step S<b>307</b> or the visible watermark information pattern on which a modifying process is carried out in Step S<b>309</b> from the storage unit <b>300</b>, and adds it to the image data of the target image. As a result of the process, output image data is generated.</p>
<p id="p-0158" num="0157">Next, the CPU <b>101</b> instructs the image output apparatus <b>700</b> to print the image on recording paper on the basis of the out put image data (Step S<b>314</b>).</p>
<p id="p-0159" num="0158">As a result of the process, the micro gradation for the data specifying the authorized person is shown in a cell of the QR code on the basis of the name of the document creator, on the document printed by the digital multi-function peripheral <b>1</b> of Embodiment 3. Documents printed by the digital multi-function peripheral <b>1</b> of Embodiment 3, which need authorization to be copied, as described above, are hereinafter referred to as copying authorization-required documents.</p>
<p id="p-0160" num="0159">Meanwhile, in the case where the digital multi-function peripheral <b>1</b> of Embodiment 3 processes (copies, for example) the image data for a copying authorization-required document that is printed as described above, the copying authorization-required document is copied on the basis of the micro gradation data showing the authorized person.</p>
<p id="p-0161" num="0160">In the following, a case where an above described copying authorization-required document is copied is described as an example of a process for image data of the copying authorization-required document in the digital multi-function peripheral <b>1</b> of Embodiment 3 of the present invention. <figref idref="DRAWINGS">FIG. 16</figref> is a flow chart showing the process of copying an above described copying authorization-required document in the digital multi-function peripheral <b>1</b> of Embodiment 3 of the present invention. An example of a case where a predetermined person copies an above described copying authorization-required document is described in order to make the description easier. Micro gradation for the name of the document creator and authorized persons (second data), as well as details data, is shown in a cell of the QR code on the basis of the name of the document creator (first data) in the copying authorization-required document, and the user name, password and secret key (and public key) for each user are stored together in the storage unit <b>300</b>, as in Embodiment 1 and Embodiment 2.</p>
<p id="p-0162" num="0161">The user who tries to copy a document which is a copying authorization-required document as described above places the document on the scanner platen and operates the control panel <b>500</b> so as to instruct the digital multi-function peripheral to copy the document.</p>
<p id="p-0163" num="0162">The CPU <b>101</b> of the control unit <b>100</b> receives the copying instruction from the user through the control panel <b>500</b> (Step S<b>401</b>). When the instruction is received from the user, the CPU <b>101</b> displays, on the display section <b>501</b>, an input screen for urging to input a user name and a password by using a program stored in the storage unit <b>300</b>. When the user inputs the user name and the password by operating the control panel <b>500</b>, the CPU <b>101</b> receives the user name and the password (third data) through the control panel <b>500</b> (third data receiving section) (Step S<b>402</b>).</p>
<p id="p-0164" num="0163">When the user name and the password are received, the CPU <b>101</b> matches the user name and the password on the basis of data precedently stored in the storage unit <b>300</b> (Step S<b>403</b>). When the user name and the password accord with the stored data, the CPU <b>101</b> (obtaining section) instructs the image reading apparatus <b>200</b> to read an image of the document which is a copying authorization-required document so as to obtain image data of the document (Step S<b>404</b>).</p>
<p id="p-0165" num="0164">Next, the CPU <b>101</b> instructs the QR code data obtaining section <b>416</b> to extract (separate) QR code data from the image data of the document (Step S<b>405</b>), and the QR code data obtaining section <b>416</b> specifies a position where the QR code is printed on the basis of cutout symbols of the QR code, so as to extract the QR code data from the image data of the document. Through this procedure, it is possible to obtain a document creator name (first data).</p>
<p id="p-0166" num="0165">After that, the CPU <b>101</b> reads out the public key (decoding key) used when encrypted data is decoded, as described below, from the data stored in the storage unit <b>300</b> on the basis of the name of the user (or password) received in Step S<b>402</b> (Step S<b>406</b>). The obtained public key is temporarily stored in the RAM of the control unit <b>100</b>.</p>
<p id="p-0167" num="0166">Next, the CPU <b>101</b> instructs the micro gradation data obtaining section <b>417</b> to specify the position of the QR code on the basis of the cutout symbol of the QR code and extracts (separates) micro gradation data generated in a cell of the QR code as micro gradation (Step S<b>407</b>). As a result, the encrypted second data and details data, which are encrypted data, can be obtained.</p>
<p id="p-0168" num="0167">The CPU <b>101</b> instructs the decoding section <b>418</b> to decode the micro gradation data extracted in Step S<b>407</b>; that is to say, the encrypted data (Step S<b>408</b>). Following the instruction from the CPU <b>101</b>, the decoding section <b>418</b> reads out the public key stored in the RAM of the control unit <b>100</b> and decodes the encrypted second data and details data using the public key.</p>
<p id="p-0169" num="0168">Next, the CPU <b>101</b> determines whether or not decoding by the decoding section <b>418</b> was successful (Step S<b>409</b>). In the case where it is determined that the decoding by the decoding section <b>418</b> was not successful (Step S<b>409</b>:NO), the CPU <b>101</b> determines that the document (image data) is unreliable and does not authorize it (Step S<b>415</b>). In this case, the CPU <b>101</b> displays a message saying copying is impossible in the display section <b>501</b> on the control panel <b>500</b> (Step S<b>416</b>).</p>
<p id="p-0170" num="0169">Meanwhile, in the case where it is determined that the decoding by the decoding section <b>418</b> was successful (Step S<b>409</b>:YES), the CPU <b>101</b> instructs the data comparison section <b>419</b> to compare the name of the document creator in the second data decoded by the decoding section <b>418</b> with the QR code data (first data) obtained in Step S<b>405</b>. That is to say, the first data is the name of the document creator in the present embodiment, and therefore, the CPU <b>101</b> determines whether or not the name of the document creator matches (Step S<b>410</b>).</p>
<p id="p-0171" num="0170">In the case where it is determined that the name of the document creator does not match (Step S<b>410</b>:NO), the CPU <b>101</b> determines that the document (image data) is unreliable and does not authorize it (Step S<b>417</b>). In this case, the CPU <b>101</b> displays the results of the determination; that is to say, text that the document is unreliable and a screen for selecting whether or not to continue the process in the display section <b>501</b> on the control panel <b>500</b> (Step S<b>418</b>). Accordingly, damages caused by counterfeiting of the document by a person with malicious intent can be prevented, for example.</p>
<p id="p-0172" num="0171">Meanwhile, in the case where it is determined that the name of the document creator matches (Step S<b>410</b>:YES), it is determined whether or not the detail information of the visible watermark information pattern in the image data of the document read in Step S<b>404</b> correspond to the details data decoded in Step S<b>408</b> (Step S<b>411</b>).</p>
<p id="p-0173" num="0172">In the case where it is determined that the detail information of the visible watermark information pattern in the image data of the document do not correspond to the details data (Step S<b>411</b>:NO), the CPU <b>101</b> moves the process to Step S<b>417</b> and S<b>418</b> in sequence. Meanwhile, in the case where it is determined that the detail information of the visible watermark information pattern in the image data of the document correspond to the details data (Step S<b>411</b>:YES), the document (image data) is determined as reliable and authorized (Step S<b>412</b>).</p>
<p id="p-0174" num="0173">Next, the CPU <b>101</b> instructs the data comparison section <b>419</b> to compare the name of the authorized person in the second data decoded by the decoding section <b>418</b> with the name of the user (third data) received in Step S<b>402</b>. The CPU <b>101</b> determines whether or not the name of the user (third data) is included in the name of the authorized person, which is the second data; that is to say, whether or not the user is an authorized person on the basis of the results of comparison by the data comparison section <b>419</b> (Step S<b>413</b>).</p>
<p id="p-0175" num="0174">In the case where it is determined that the user is not an authorized person (Step S<b>413</b>:NO), the CPU <b>101</b> determines that the user is unreliable and displays a message saying copying is impossible in the display section <b>501</b> on the control panel <b>500</b> (Step S<b>419</b>).</p>
<p id="p-0176" num="0175">Meanwhile, in the case where it is determined that the user name is that of an authorized person (Step S<b>413</b>:YES), the CPU <b>101</b> determines that the user is reliable and carries out the received copy instruction (Step S<b>414</b>).</p>
<p id="p-0177" num="0176">This configuration for matching the visible watermark information pattern prevents illegal falsification of documents where a person with malicious intent cuts and separates the gradation QR code portion in the document (document) from the rest of the recording paper and pastes it on another document, and can prevent processes that are not envisioned by the document creator from being carried out, so that only specific users or specific processes are permitted.</p>
<p id="p-0178" num="0177">Though an example of a case where the second data and the data received from the outside (third data) are matched and a process following the received instruction is carried out on the basis of the results of matching is described in the above, the invention is not limited to this. In the case where the name of the authorized person is QR coded as first data together with the name of the document creator, for example, it is possible for the received process to be carried out on the basis of the results of matching with the first data and the data received from an outside (third data).</p>
<heading id="h-0009" level="1">Fourth Embodiment</heading>
<p id="p-0179" num="0178"><figref idref="DRAWINGS">FIG. 17</figref> is a functional block diagram illustrating a principal configuration of the digital multi-function peripheral <b>1</b> of Embodiment 4 of the present invention, and <figref idref="DRAWINGS">FIG. 18</figref> is a functional block diagram illustrating a principal configuration of the document authentication section <b>420</b> in the digital multi-function peripheral <b>1</b> of Embodiment 4 of the present invention.</p>
<p id="p-0180" num="0179">The digital multi-function peripheral <b>1</b> of Embodiment 4 includes, similarly to the image forming apparatus of Embodiment 2 or 3, hardware such as a control unit <b>100</b>, an image reading apparatus <b>200</b>, an image processing apparatus <b>400</b>, an image output apparatus <b>700</b>, a storage unit <b>300</b>, a communication unit <b>600</b> and a control panel <b>500</b>. The storage unit <b>300</b> stores, in the same manner as in Embodiment 2, data in which a user name, a password of each user, a public key of each user and the like are associated with one another. In addition, similarly to the storage unit <b>300</b> in the digital multi-function peripheral <b>1</b> of Embodiment 2, the read text specifying data, from which the high resolution portion is removed, is stored in the storage unit <b>300</b> in the digital multi-function peripheral <b>1</b> of Embodiment 4 of the present invention.</p>
<p id="p-0181" num="0180">In addition, in the digital multi-function peripheral <b>1</b> of Embodiment 4 of the present invention, a gradation QR code including the second data and the details data of the visible watermark information pattern is attached to the image data read by the image reading apparatus <b>200</b>, for example.</p>
<p id="p-0182" num="0181">The image processing apparatus <b>400</b> includes an A/D (Analog/Digital) conversion section <b>405</b>, a shading correction section <b>406</b>, an input tone correction section <b>407</b>, a document authentication section <b>420</b>, a segmentation process section <b>408</b>, a color correction section <b>409</b>, a black generation and under color removal section <b>411</b>, a zoom process section <b>412</b>, a spatial filter process section <b>413</b>, an output tone correction section <b>414</b>, and a tone reproduction process section <b>415</b>. Furthermore, the image processing apparatus <b>400</b> is connected to the image reading apparatus <b>200</b> and the image output apparatus <b>700</b>.</p>
<p id="p-0183" num="0182">Analog signals of image data read by the image reading apparatus <b>200</b> are transmitted, in the image processing apparatus <b>400</b>, in the order of the A/D conversion section <b>405</b>, the shading correction section <b>406</b>, the input tone correction section <b>407</b>, the document authentication section <b>420</b>, the segmentation process section <b>408</b>, the color correction section <b>409</b>, the black generation and under color removal section <b>411</b>, the zoom process section <b>412</b>, the spatial filter process section <b>413</b>, the output tone correction section <b>414</b> and the tone reproduction process section <b>415</b>. Thereafter, the signals processed by the image processing apparatus <b>400</b> are outputted to the image output apparatus <b>700</b> as CMYK digital color signals.</p>
<p id="p-0184" num="0183">The A/D conversion section <b>405</b> converts analog RGB signals received from the image reading apparatus <b>200</b> into digital RGB signals. The shading correction section <b>406</b> removes, from the digital RGB signals outputted from the A/D conversion section <b>405</b>, various distortion caused during processing executed by the image reading apparatus <b>200</b> such as illumination system, image focusing system and image sensing system.</p>
<p id="p-0185" num="0184">The input tone correction section <b>407</b> adjusts color balance of the RGB signals from which the various distortion has been removed by the shading correction section <b>406</b> (i.e., RGB reflectance signals) and converts the adjusted RGB signals into density signals.</p>
<p id="p-0186" num="0185">Here, the document authentication section <b>420</b> in the digital multi-function peripheral <b>1</b> of Embodiment 4 includes a QR code data obtaining section <b>416</b>, a micro gradation data obtaining section <b>417</b>, a decoding section <b>418</b>, a comparison section <b>421</b>, a visible watermark information pattern matching section <b>422</b> and a copy control section <b>423</b>.</p>
<p id="p-0187" num="0186">The QR code data obtaining section <b>416</b> specifies the position of the gradation QR code on the basis of cut-out symbols of the gradation QR code, and obtains (extracts) QR code data from image data of the gradation QR code included in image data of a document read by the image reading apparatus <b>200</b>.</p>
<p id="p-0188" num="0187">The micro gradation data obtaining section <b>417</b> extracts encrypted data, that is to say, encrypted second data and details data in the image data of the document from the image data of the gradation QR code in the image data of the document read by the image reading apparatus <b>200</b>, for example.</p>
<p id="p-0189" num="0188">The decoding section <b>418</b> decodes the encrypted data obtained by the micro gradation data obtaining section <b>417</b> using a predetermined public key (or decoding key) (the public key may be stored in the storage unit <b>300</b> or may be formed so as to be inputted by the user through the control panel <b>500</b>).</p>
<p id="p-0190" num="0189">The comparison section <b>421</b>, for example, compares (matches) the QR code data (first data) which is obtained by the QR code data obtaining section <b>416</b>, with the second data which is obtained by the micro gradation data obtaining section <b>417</b> and decoded by the decoding section <b>418</b>.</p>
<p id="p-0191" num="0190">In addition, the visible watermark information pattern matching section <b>422</b> matches whether or not the visible watermark information pattern for the image data in the document read by the image reading apparatus <b>200</b> corresponds to the details data extracted by the micro gradation data obtaining section <b>417</b> and decoded by the decoding section <b>418</b>, for example. In the case where the details data has a text specifying number showing a visible watermark information of text and coordinates showing the display position of the visible watermark information of text for the text specifying number, for example, the visible watermark information pattern matching section <b>422</b> matches whether or not the visible watermark information pattern for the image data of the document corresponds to the details data.</p>
<p id="p-0192" num="0191">The copy control section <b>423</b> in the document authentication section <b>420</b> determines whether or not copying is possible, for example, on the basis of whether or not decoding is possible in the decoding section <b>418</b>, the results of comparison by the comparison section <b>421</b> and/or the results of matching by the visible watermark information pattern matching section <b>422</b>. In addition, the invention is not limited to this, and in the case where the second data includes the name of the authorized person as in the Embodiment 3, the name of the user is received from the control panel <b>500</b>, and whether or not copying is possible is determined on the basis of the results of matching of the name of the user and the name of the authorized person.</p>
<p id="p-0193" num="0192">The segmentation process section <b>408</b> receives the RGB signals and separates respective pixels of the inputted image into a text region, a halftone region and a photograph region. Also, the segmentation process section <b>408</b> outputs, in accordance with the result of the separation, a segmentation class signal representing which region each pixel corresponds to the black generation and under color removal section <b>411</b>, the spatial filter process section <b>413</b> and the tone reproduction process section <b>415</b>.</p>
<p id="p-0194" num="0193">The color correction section <b>409</b> removes color impurity, for reproducing colors with fidelity, on the basis of the spectral characteristics of color materials of CMY (C: cyan, M: magenta and Y: yellow) including unnecessary absorbed components.</p>
<p id="p-0195" num="0194">The black generation and under color removal section <b>411</b> generates black (K) signals on the basis of signals of the three colors of CMY resulting from the color correction and generates new CMY signals by subtracting the K signals from the original CMY signals. Thus, the CMY three-color signals are converted into CMYK four-color signals.</p>
<p id="p-0196" num="0195">An example of a method for generating a black (K) signal is a black (K) signal generation method using skeleton black (a general method). In this method, assuming that the input/output characteristic of a skeleton curve is y=f(x), that inputted data are C, M and Y, that outputted data are C&#x2032;, M&#x2032;, Y&#x2032; and K&#x2032;, and that a UCR (Under Color Removal) ratio is &#x3b1; (0&#x3c;&#x3b1;&#x3c;1), a black generation and under color removal process is expressed by the following expressions: K&#x2032;=f{min(C, M, Y)}, C&#x2032;=C&#x2212;&#x3b1;K&#x2032;, M&#x2032;=M&#x2212;&#x3b1;K&#x2032; and Y&#x2032;=Y&#x2212;&#x3b1;K&#x2032;.</p>
<p id="p-0197" num="0196">The zoom process section <b>412</b> executes scaling or the like of the image on the basis of a signal inputted by operating the control panel <b>500</b> included in the image forming apparatus.</p>
<p id="p-0198" num="0197">The spatial filter process section <b>413</b> executes a spatial filtering process using a digital filter on the image data of the CMYK signals inputted from the black generation and under color removal section <b>411</b> in accordance with the segmentation class signals. The spatial filter process section <b>413</b> prevents blur and graininess degradation of an output image by correcting a spatial frequency characteristic. Also the tone reproduction process section <b>415</b> executes a prescribed process on the image data of the CMYK signals in accordance with the segmentation class signals similarly to the spatial filter process section <b>413</b>.</p>
<p id="p-0199" num="0198">For example, in a region separated as a text region by the segmentation process section <b>408</b>, a high frequency component is sharpened through an edge enhancement process executed in the spatial filtering process of the spatial filter process section <b>413</b> so as to improve the reproducibility of a color text and a black text in particular. Simultaneously, the tone reproduction process section <b>415</b> selects a binarizing process or a multi-level dithering process suitable to reproduction of a high frequency in a screen with high resolution and executes the selected process.</p>
<p id="p-0200" num="0199">Alternatively, in a region separated as a halftone region by the segmentation process section <b>408</b>, the spatial filter process section <b>413</b> executes a low-pass filtering process of removing an inputted halftone component.</p>
<p id="p-0201" num="0200">Then, the output tone correction section <b>414</b> executes an output tone correction process on the basis of the output characteristic of a color image output apparatus. Thereafter, in the tone reproduction process section <b>415</b>, the image is ultimately separated into pixels, and a tone reproduction process (halftone generation) is executed so as to reproduce the tone of each pixel. In a region separated as a photograph region by the segmentation process section <b>408</b>, a binarizing or multi-level dithering process is executed in a screen suitable for tone reproducibility.</p>
<p id="p-0202" num="0201">The image data having been subjected to the aforementioned processes is once stored in the storage unit <b>300</b> and is read at prescribed timing to be inputted to the image output apparatus <b>700</b>. The image output apparatus <b>700</b> prints (forms) an image based on the image data on a recording medium (such as paper). Examples of a method for printing the image based on the image data are the electrophotographic method and the ink-jet method. The method for printing the image data is, however, not specified. It is noted that the aforementioned processes are executed by a CPU <b>101</b> (not shown).</p>
<p id="p-0203" num="0202">Like reference numerals are used to refer to like elements used in Embodiment 1 or 2 so as to omit the detailed description.</p>
<p id="p-0204" num="0203">Although a document is copied in the aforementioned exemplary case, the application of the digital multi-function peripheral <b>1</b> of Embodiment 4 is not limited to this. For example, the digital multi-function peripheral <b>1</b> of Embodiment 4 is applicable also when the digital multi-function peripheral <b>1</b> includes a facsimile transmitting function, a scan to e-mail function or the like and obtained image data of a document is to be sent/received to/from an external device.</p>
<p id="p-0205" num="0204">For example, when the digital multi-function peripheral <b>1</b> includes a communication unit having a modem and a network card so as to send data by facsimile, a procedure with a destination for sending is executed by using the modem. When a state ready for sending the facsimile is attained, the digital multi-function peripheral <b>1</b> executes necessary processing such as conversion of the encoding format on image data of a document encoded in a prescribed format (i.e., image data read with a scanner), and successively transmits the image data having been processed to the destination through a communication line.</p>
<p id="p-0206" num="0205">Furthermore, when the digital multi-function peripheral <b>1</b> receives image data, the CPU <b>101</b> executes a communication procedure for receiving image data from a sender. The image data received by the digital multi-function peripheral <b>1</b> is decoded by an encode/decode process section (not shown). A rotation process and a process of converting the resolution are executed on the decoded image data if necessary. Thereafter, output tone correction and tone reproduction are executed on the image data and the executed image data is outputted from the image output apparatus.</p>
<heading id="h-0010" level="1">Fifth Embodiment</heading>
<p id="p-0207" num="0206">Though an example of a case where image data is outputted in such a form as being printed is described in the above, the invention can be applied in cases of facsimile transmission, image transmission such that image data is transmitted to (1) a designated address when attached to an e-mail (scan to e-mail), (2) a folder designated by the user (scan to ftp) and (3) a USB memory attached to an image forming apparatus (scan to usb), and displaying of image data in an image displaying apparatus (for example, a liquid crystal display).</p>
<p id="p-0208" num="0207">In addition, the present invention may be applied to an image reading apparatus, such as a scanner, instead of an image forming apparatus. <figref idref="DRAWINGS">FIG. 19</figref> is a functional block diagram illustrating a principal configuration of the image reading apparatus of Embodiment 5 of the present invention. In the following, an example of a case where the image reading apparatus of Embodiment 5 of the present invention is a color image processing apparatus <b>1</b>A is described.</p>
<p id="p-0209" num="0208">The color image processing apparatus <b>1</b>A of Embodiment 5 of the present invention includes hardware, such as a control section <b>100</b>A, an image reading section <b>200</b>A (reading section), an image process section <b>400</b>A, a display section <b>800</b>A, a storage section <b>300</b>A, a communication section <b>600</b>A and an control panel <b>500</b>A, so as to form the color image processing apparatus <b>1</b>A as a whole. The user name, password, public key and the like for each user are stored together in the storage section <b>300</b>A as in the Embodiment 2. In addition, the read text specifying data, from which the high resolution portion is removed, is stored in the storage section <b>300</b>A in the color image processing apparatus <b>1</b>A of Embodiment 5 of the present invention as in the storage unit <b>300</b> of the digital multi-function peripheral <b>1</b> of Embodiment 2.</p>
<p id="p-0210" num="0209">The image process section <b>400</b>A in the color image processing apparatus <b>1</b>A is formed of an A/D conversion section <b>405</b>, a shading correction section <b>406</b>, an input tone correction section <b>407</b>, a document authentication section <b>420</b> and a display control section <b>430</b>, and this is connected to an image reading section <b>200</b>A so as to form the color image processing apparatus <b>1</b>A as a whole. The processes in these process sections are the same as in the above, and therefore, the descriptions thereof are not repeated. The results of document authorization are outputted from the image process section <b>400</b>A together with image data for RGB and transmitted to the connected computer, multipurpose machine, printer, server or the like from the communication section <b>600</b>A. Here, the control section <b>100</b>A controls the peripheral apparatuses, such as the computer, multipurpose machine, printer, server or the like, to recognize the results of document authorization and carry out a process.</p>
<heading id="h-0011" level="1">Sixth Embodiment</heading>
<p id="p-0211" num="0210"><figref idref="DRAWINGS">FIG. 20</figref> is a block diagram illustrating a principal configuration of a digital multi-function peripheral <b>1</b> according to Embodiment 6. In the digital multi-function peripheral <b>1</b> of Embodiment 6, a program for executing processing can be provided in the form of a portable recording medium A such as a CD-ROM (Compact Disc Read-Only Memory) through an external recording medium I/F <b>800</b>. Furthermore, in the digital multi-function peripheral <b>1</b> of Embodiment 6, a computer program can be downloaded from an external device (not shown) through a communication unit <b>600</b>. This embodiment will now be described in detail.</p>
<p id="p-0212" num="0211">The digital multi-function peripheral <b>1</b> of Embodiment 6 includes an externally (or internally) provided recording medium reading apparatus (not shown). In the digital multi-function peripheral <b>1</b> of Embodiment 6, the portable recording medium A storing programs described later and the like is inserted into the recording medium reading unit, so as to install the programs on, for example, a storage unit <b>300</b>. The programs stored in the portable memory medium A are, for example, a program for allowing the digital multi-function peripheral <b>1</b> to receive the first data and second data for the security of the obtained image data, to generate image data of a two-dimensional code having a number of cells on the basis of the first data, to encrypt the second data and the details data representing the detail information of the specific image, to generate pattern image data expressing a gradation pattern in each cell of the two-dimensional code on the basis of the encrypted second data and details data, to add additional image data of the additional image on the basis of the image data and pattern image data of the generated two-dimensional code to the obtained image data, to obtain image data from an image to which an additional image and a specific image are added, to separate the first data, second data and details data from the additional image data of the additional image, to match the first data and second data, to determine whether or not the detail information of the specific image on the basis of the image data corresponds to the details data, to carry out a process for the image data on the basis of the results of matching and/or the results of determination. These programs are executed by loading them on a RAM of a control unit <b>100</b>. As a result, the digital multi-function peripheral <b>1</b> of Embodiment 6 functions as the image forming apparatus of Embodiments 1 through 4.</p>
<p id="p-0213" num="0212">The recording medium may be a memory (not shown) necessary for executing processing by a microcomputer, such as a program medium like a ROM. Alternatively, the recording medium may be a medium fixedly storing a program code, such as a tape, a magnetic disc, an optical disc, a card or a semiconductor memory. Examples of the tape are a magnetic tape and a cassette tape. Examples of the magnetic disc are a flexible disc and hard disc. Examples of the optical disc are a CD-ROM, an MO (MagnetoOptic disc), an MD (Magnetic Disc) and a DVD (Digital Versatile Disc). Examples of the card are an IC (Integrated Circuit) card (including a memory card) and an optical card. Examples of the semiconductor memory are a mask ROM, an EPROM (Erasable Programmable Read-Only Memory), an EEPROM (Electrically Erasable and Programmable Read-Only Memory), and a flash ROM (Read-Only Memory).</p>
<p id="p-0214" num="0213">The recording medium may be a medium on which a program code is downloaded through the communication unit <b>600</b> from a communication network so as to fluidally store the program code. Incidentally, when a program is downloaded from a communication network, a program for the download should be precedently stored in a main part of the apparatus or should be installed from a recording medium. It is noted that the present invention may be practiced also by a digital multi-function peripheral that receives an electronically sent program code and executes the program in accordance with computer data signals embedded in carriers.</p>
<p id="p-0215" num="0214">Like reference numerals are used to refer to like elements used in Embodiment 1 or 2 so as to omit the detailed description.</p>
<p id="p-0216" num="0215">Though the above described embodiments are described using an example of a visible watermark information in a halftone design is added as a specific image, the invention is not limited to this. The specific image may be made up of visible text, instead of visible watermark information of text. The invention is possible as long as such a specific image can be specified as details data for the visible watermark information pattern.</p>
<p id="p-0217" num="0216">As this description may be embodied in several forms without departing from the spirit of essential characteristics thereof, the present embodiment is therefore illustrative and not restrictive, since the scope is defined by the appended claims rather than by the description preceding them, and all changes that fan within metes and bounds of the claims, or equivalence of such metes and bounds thereof are therefore intended to be embraced by the claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing apparatus for carrying out a process of adding specific image data of a specific image to obtained image data, comprising:
<claim-text>a receiving section for receiving first data and second data concerning the security of the obtained image data;</claim-text>
<claim-text>a code generation section for generating image data for a two-dimensional code having a number of cells on the basis of said first data;</claim-text>
<claim-text>an encryption section for encrypting said second data and details data identifying said specific image;</claim-text>
<claim-text>a pattern generation section for generating pattern image data showing a gradation pattern in a cell of said two-dimensional code on the basis of the encrypted second data and details data; and</claim-text>
<claim-text>an addition section for adding additional image data of an additional image based on the generated image data of the two-dimensional code and the pattern image data, and the specific image data to said obtained image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>a storage section for storing a number of pieces of specific image data; and</claim-text>
<claim-text>a selection receiving section for selecting and receiving one or more pieces of specific image data to be added to said obtained image data from among said number of pieces of specific image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said specific image is a visible watermark information in a halftone screen image or a watermark image.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. An image processing apparatus, comprising:
<claim-text>an obtaining section for obtaining image data from an image to which additional image data of an additional image and specific image data of a specific image are added by means of the image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>;</claim-text>
<claim-text>a separation section for separating the first data, second data and details data from the additional image data of said additional image;</claim-text>
<claim-text>a matching section for determining whether there is a relationship between the first data and second data separated by said separation section; and</claim-text>
<claim-text>a process section for carrying out a process for said image data on the basis of the results of a determination by the matching section and/or said details data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image processing apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising
<claim-text>a determination section for determining whether or not detail information of the specific image on the basis of the image data obtained by said obtaining section corresponds to the details data separated by said separation section, wherein said process section carries out a process for said image data on the basis of the results of a determination by the determination section.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The image processing apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising
<claim-text>a third data receiving section for receiving third data different from the first data and second data,
<claim-text>wherein said matching section carries out a determination of whether there is a relationship between said third data and said first data or second data, and</claim-text>
<claim-text>said process section carries out a process for said image data on the basis of the results of the determination by said matching section.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An image reading apparatus, comprising the image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image processing apparatus adds additional image data and specific image data to image data obtained from a document.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An image reading apparatus, comprising:
<claim-text>the image processing apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>; and</claim-text>
<claim-text>a reading section for reading image data from a document, wherein</claim-text>
<claim-text>in the case where image data to which additional image data and specific image data have been added is obtained from said reading section by the image processing apparatus, the separation section of said image processing apparatus separates the first data, second data and details data from said additional image data so that a process for said obtained image data can be carried out on the basis of the results of a determination by the matching section of said image processing apparatus and/or said details data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. An image forming apparatus, comprising the image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein an image is formed on a sheet on the basis of the image data to which additional image data and specific image data have been added by the image processing apparatus.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An image forming apparatus, comprising the image processing apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein in the case where image data to which additional image data and specific image data have been added is obtained, an image on the basis of the obtained image data is formed on a sheet on the basis of the results of a determination by the matching section of said image processing apparatus and/or said details data.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An image processing method for carrying out a process of adding specific image data of a specific image to obtained image data, comprising:
<claim-text>a receiving step of receiving first data and second data for the security of the obtained image data;</claim-text>
<claim-text>a generating step of generating image data of a two-dimensional code having a number of cells on the basis of said first data;</claim-text>
<claim-text>an encrypting step of encrypting said second data and details data identifying said specific image;</claim-text>
<claim-text>a pattern generating step of generating pattern image data showing a gradation pattern in a cell of said two-dimensional code on the basis of the encrypted second data and details data; and</claim-text>
<claim-text>an adding step of adding additional image data of an additional image based on the generated image data of the two-dimensional code and the pattern image data, and the specific image data to said obtained image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An image processing method, comprising:
<claim-text>an obtaining step of obtaining image data from an image to which an additional image and a specific image have been added in accordance with the image processing method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>;</claim-text>
<claim-text>a separating step of separating the first data, second data and details data from the additional image data of said additional image;</claim-text>
<claim-text>a matching step of determining whether there is a relationship between the first data and the second data separated in said separating step;</claim-text>
<claim-text>a determining step of determining whether or not detail information of the specific image on the basis of the image data obtained in said obtaining step corresponds to the details data separated in said separating step; and</claim-text>
<claim-text>a processing step of carrying out a process for said image data on the basis of the results of a determination in said matching step and/or the results of a determination in said determining step.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A non-transitory recording medium, whereon a computer program for causing a computer to carry out a process of adding specific image data of a specific image to obtained image data is recorded and which can be read by a computer, said computer program comprising:
<claim-text>a step of causing said computer to receive first data and second data for the security of the obtained image data;</claim-text>
<claim-text>a step of causing said computer to generate image data of a two-dimensional code having a number of cells on the basis of the first data;</claim-text>
<claim-text>a step of causing said computer to encrypt the second data and details data identifying said specific image;</claim-text>
<claim-text>a step of causing said computer to generate pattern image data expressing a gradation pattern in each cell of the two-dimensional code on the basis of the encrypted second data and details data; and</claim-text>
<claim-text>a step of causing said computer to add additional image data of an additional image based on the generated image data of the two-dimensional code and the pattern image data, and the specific image data to said obtained image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A non-transitory recording medium whereon a computer program is recorded which can be read by a computer, said computer program comprising:
<claim-text>an obtaining step of causing said computer to obtain image data from an image to which an additional image and a specific image have been added using a computer program recorded on a recording medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>;</claim-text>
<claim-text>a separation step of causing said computer to separate the first data, second data and details data from the additional image data of the additional image;</claim-text>
<claim-text>a matching step of causing said computer to determine whether there is a relationship between the first data and second data separated in the separating step;</claim-text>
<claim-text>a determining step of causing said computer to determine whether or not detail information of the specific image on the basis of the image data obtained in the obtaining step corresponds to the details data separated in the separating step; and</claim-text>
<claim-text>a step of causing said computer to carry out a process for the image data on the basis of the results of a determination in the matching step and/or the results of a determination in the determining step.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pattern generation section generates a pattern image data representing at least a kind of gradation pattern in each cell of said two-dimensional code on the basis of the encrypted second data and details data.</claim-text>
</claim>
</claims>
</us-patent-grant>
