<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625149-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625149</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13918359</doc-number>
<date>20130614</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2009-058652</doc-number>
<date>20090311</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>393</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>409</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>15</main-group>
<subgroup>12</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>387</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>40</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>46</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>62</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>15</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>B</section>
<class>41</class>
<subclass>J</subclass>
<main-group>2</main-group>
<subgroup>47</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>03</class>
<subclass>G</subclass>
<main-group>15</main-group>
<subgroup>23</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>3873</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>3935</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>40068</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>409</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>4609</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>6201</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>15</main-group>
<subgroup>1223</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>15</main-group>
<subgroup>1843</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>15</main-group>
<subgroup>1872</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>B</section>
<class>41</class>
<subclass>J</subclass>
<main-group>2</main-group>
<subgroup>473</subgroup>
<symbol-position>L</symbol-position>
<classification-value>A</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>03</class>
<subclass>G</subclass>
<main-group>15</main-group>
<subgroup>23</subgroup>
<symbol-position>L</symbol-position>
<classification-value>A</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<classification-national>
<country>US</country>
<main-classification>358  12</main-classification>
<further-classification>358  17</further-classification>
<further-classification>358  324</further-classification>
<further-classification>358  326</further-classification>
<further-classification>347233</further-classification>
</classification-national>
<invention-title id="d2e61">Apparatus and method controlling zooming process at laser device for high-speed high-resolution double-sided printing without wide-ranged image degradation or banding</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5450208</doc-number>
<kind>A</kind>
<name>Murata</name>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358296</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6781718</doc-number>
<kind>B2</kind>
<name>Sato</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  19</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7342679</doc-number>
<kind>B2</kind>
<name>Nakashige et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  12</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7843604</doc-number>
<kind>B2</kind>
<name>Higashiyama et al.</name>
<date>20101100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>8159722</doc-number>
<kind>B2</kind>
<name>Higashiyama et al.</name>
<date>20120400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>8305637</doc-number>
<kind>B2</kind>
<name>Shinohara</name>
<date>20121100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>8320024</doc-number>
<kind>B2</kind>
<name>Kawai et al.</name>
<date>20121100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>8384958</doc-number>
<kind>B2</kind>
<name>Kondoh</name>
<date>20130200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2008/0309951</doc-number>
<kind>A1</kind>
<name>Kishi et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2009/0066981</doc-number>
<kind>A1</kind>
<name>Kaima et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2009/0213401</doc-number>
<kind>A1</kind>
<name>Higashiyama et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2009/0231606</doc-number>
<kind>A1</kind>
<name>Kawai et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2010/0231940</doc-number>
<kind>A1</kind>
<name>Kaima</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2010/0253981</doc-number>
<kind>A1</kind>
<name>Higashiyama et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2011/0007120</doc-number>
<kind>A1</kind>
<name>Motoi et al.</name>
<date>20110100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>347116</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2011/0157607</doc-number>
<kind>A1</kind>
<name>Saito</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  12</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2011/0222085</doc-number>
<kind>A1</kind>
<name>Takesue et al.</name>
<date>20110900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2012/0140013</doc-number>
<kind>A1</kind>
<name>Komai et al.</name>
<date>20120600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2012/0147116</doc-number>
<kind>A1</kind>
<name>Kinoshita et al.</name>
<date>20120600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>4-265069</doc-number>
<kind>A</kind>
<date>19920900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>3373266</doc-number>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>JP</country>
<doc-number>2004-104625</doc-number>
<kind>A</kind>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>JP</country>
<doc-number>2008-238590</doc-number>
<kind>A</kind>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>JP</country>
<doc-number>2009-83472</doc-number>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>Japanese Office Action issued Aug. 20, 2013 in Patent Application No. 2009-058652.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>8</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>358  12</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  17</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  19</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  324</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  326</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358451</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358528</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358463</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382190</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382195</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382205</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382209</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382217</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382218</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382254</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382256</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382257</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382258</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382267</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382269</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382275</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382286</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382291</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382292</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382293</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382298</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382299</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>347129-133</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>347233-238</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>19</number-of-drawing-sheets>
<number-of-figures>25</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12721012</doc-number>
<date>20100310</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8493613</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13918359</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130278946</doc-number>
<kind>A1</kind>
<date>20131024</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kaima</last-name>
<first-name>Nobuyoshi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kaima</last-name>
<first-name>Nobuyoshi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oblon, Spivak, McClelland, Maier &#x26; Neustadt, L.L.P.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Ricoh Company, Limited</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Rogers</last-name>
<first-name>Scott A</first-name>
<department>2673</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image forming apparatus includes a positioning unit that acquires a misalignment amount of a pixel in a main-scanning direction and a sub-scanning direction, the pixel as a reference pixel for zooming image data, and decides a position of a pixel as a correction target, based on the misalignment amount; a correcting unit that corrects the pixel; a zooming unit that controls the positioning unit and the correcting unit so as to repeatedly perform the positioning process and the correction process on a pixel line; a pattern recognition unit that performs pattern matching on a predetermined pattern and a predetermined pixel line; and a pixel position changing unit that shifts the decided pixel position in the sub-scanning direction, wherein the zooming unit performs the zooming process on the pixel line of the sub-scanning direction including the pixel that is located at shifted pixel position.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="144.02mm" wi="175.34mm" file="US08625149-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="245.87mm" wi="168.66mm" orientation="landscape" file="US08625149-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="260.18mm" wi="177.21mm" file="US08625149-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="163.24mm" wi="177.21mm" file="US08625149-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="266.78mm" wi="174.92mm" file="US08625149-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="264.50mm" wi="167.89mm" file="US08625149-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="140.04mm" wi="179.15mm" file="US08625149-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="213.70mm" wi="172.97mm" file="US08625149-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="155.53mm" wi="174.16mm" file="US08625149-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="274.91mm" wi="190.42mm" orientation="landscape" file="US08625149-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="253.24mm" wi="146.56mm" file="US08625149-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="215.22mm" wi="171.79mm" file="US08625149-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="236.56mm" wi="122.51mm" file="US08625149-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="255.19mm" wi="192.36mm" orientation="landscape" file="US08625149-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="254.00mm" wi="194.31mm" orientation="landscape" file="US08625149-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="173.74mm" wi="184.57mm" file="US08625149-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="161.71mm" wi="178.39mm" file="US08625149-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="258.66mm" wi="159.00mm" file="US08625149-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="260.18mm" wi="119.04mm" file="US08625149-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="241.22mm" wi="138.09mm" file="US08625149-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 12/721,012, filed Mar. 10, 2010, and is based upon and claims the benefit of priority from prior Japanese Patent Application No. 2009-058652, filed Mar. 11, 2009, the entire contents of both of which are incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to image forming. More particularly, the present invention relates to an image forming apparatus and an image forming method that form a multi-beam latent image.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Along with the improvement of function of an image forming apparatus, an image forming speed (PPM: prints per minutes) per a unit time of the image forming apparatus also increases. In recent years, an image forming apparatus that utilizes a surface emitting laser (hereinafter, VCSEL (Vertical Cavity Surface Emitting LASER)) to perform multi-beam exposure is proposed to form an image at higher speed and with higher resolution. Moreover, an image forming apparatus that performs duplex printing is provided in response to the request of resource saving.</p>
<p id="p-0007" num="0006">For this reason, along with the improvement of an imaging speed, an automatic duplex printing apparatus has a trend that a time interval from the record of the first surface to the record of the second surface of paper is shortened. For example, a high-speed model can perform the print of the first surface and the print of the second surface within ten seconds. Because a carrying distance from heat fixing corresponding to the record of the first surface of paper to the record of the second surface is likely to be shortened in conjunction with the miniaturization of the image forming apparatus, a time for which the paper is not exposed to a high-temperature portion is shortened. Besides a time interval, printing paper further comes under thermal influence and thus is hard to get cold.</p>
<p id="p-0008" num="0007">When two-sided recording is performed in such a situation, it is known that images that are printed on the first and second surfaces, which are both sides of paper, have the difference of magnification of 0.2% to 0.4% due to the change of heat and moisture when a sheet of premium grade paper having the thickness of about 80 micrometers is used as printing paper.</p>
<p id="p-0009" num="0008">In regard to the problem described above, a technology for providing a sub-scanning magnification zooming function to an image forming apparatus, and performing reduction print by the thinning of sub-scanning image data and expansion print by the addition of image data have been conventionally known as disclosed in, for example, Japanese Patent No. 3373266.</p>
<p id="p-0010" num="0009">The fluctuation of magnification might be able to be cancelled by the method disclosed in Japanese Patent No. 3373266. However, along with the high resolution of an image to be formed, a periodic image that forms, for example, one line in every five lines has problem occurring globally such image defect as concentration unevenness or moire when a single line is thinned or added from or to the image for correcting the fluctuation of magnification.</p>
<p id="p-0011" num="0010">Moreover, it is necessary to prevent banding caused by the number of screen lines, the interference of the magnification, and the like along with the cancellation process of the fluctuation of magnification.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0012" num="0011">It is an object of the present invention to at least partially solve the problems in the conventional technology.</p>
<p id="p-0013" num="0012">According to an aspect of the present invention, there is provided an image forming apparatus including: a positioning unit configured to acquire a misalignment amount of a pixel in a main-scanning direction and a misalignment amount of the pixel in a sub-scanning direction from a position of the main-scanning direction, the pixel being used as a reference pixel for zooming image data, and the image data being consisted of a plurality of pixels, and to decide a position of a pixel, the pixel being to be a correction target, as a target pixel based on the misalignment amount in the main-scanning direction and on the misalignment amount in the sub-scanning direction, as a positioning process; a correcting unit configured to correct the pixel located at the pixel position, as a correction process; a zooming unit configured to control the positioning unit and the correcting unit for zooming the image data so as to repeatedly perform the positioning process and the correction process on a pixel line of the sub-scanning direction including the pixel located at the pixel position and to repeatedly perform the positioning process and the correction process, which are performed on the pixel line of the sub-scanning direction, in the main-scanning direction, as a zooming process; a pattern recognition unit configured to perform pattern matching on a predetermined pattern and a predetermined pixel line of the image data; and a pixel position changing unit configured to shift the decided pixel position in the sub-scanning direction, when the pixel line of the sub-scanning direction including the pixel of the pixel position decided by the positioning unit is identical with the pattern, wherein the zooming unit performs the zooming process on the pixel line of the sub-scanning direction including the pixel that is located at shifted pixel position shifted by the pixel position changing unit.</p>
<p id="p-0014" num="0013">According to anther aspect of the present invention, there is provided an image forming apparatus including: a pattern recognition unit configured to perform pattern matching between a predetermined pattern and a predetermined pixel line of image data consisting of a plurality of pixels; a positioning unit configured to performs a positioning process for deciding a position of a pixel that is to be a correction target based on a position of a main-scanning direction of a pixel that becomes a reference pixel for zooming the image data, on a misaligned amount in a sub-scanning direction from the position of the main-scanning direction, and on a result of the pattern matching; a correcting unit configured to correct the pixel located at the pixel position, as a correction process; and a zooming unit configured to control the positioning unit and the correcting unit to perform a zooming process for zooming the image data so as to repeatedly perform the positioning process and the correction process on a pixel line of the sub-scanning direction including the pixel located at the pixel position and to repeatedly perform the positioning process and the correction process, which are performed on the pixel line of the sub-scanning direction, in the main-scanning direction.</p>
<p id="p-0015" num="0014">According to still another aspect of the present invention, there is provided an image forming method in an image forming apparatus, the image forming method including: acquiring a misalignment amount of a pixel in a main-scanning direction and a misalignment amount of the pixel in a sub-scanning direction from a position of the main-scanning direction, the pixel being used as a reference pixel for zooming image data, and the image data being consisted of a plurality of pixels by a positioning unit; deciding a position of a pixel, the pixel being to be a correction target, as a target pixel based on the misalignment amount in the main-scanning direction and on the misalignment amount in the sub-scanning direction, as a positioning process by the positioning unit; correcting the pixel located at the pixel position, as a correction process by a correcting unit; controlling the positioning unit and the correcting unit for zooming the image data so as to repeatedly perform the positioning process and the correction process on a pixel line of the sub-scanning direction including the pixel located at the pixel position and to repeatedly perform the positioning process and the correction process, which are performed on the pixel line of the sub-scanning direction, in the main-scanning direction, as a zooming process by a zooming unit; performing pattern matching on a predetermined pattern and a predetermined pixel line of the image data by a pattern recognition unit; and shifting the decided pixel position in the sub-scanning direction, when the pixel line of the sub-scanning direction including the pixel of the pixel position decided by the positioning unit is identical with the pattern by a pixel position changing unit, wherein the zooming includes performing the zooming process on the pixel line of the sub-scanning direction including the pixel that is located at shifted pixel position shifted by the pixel position changing unit.</p>
<p id="p-0016" num="0015">The above and other objects, features, advantages and technical and industrial significance of this invention will be better understood by reading the following detailed description of presently preferred embodiments of the invention, when considered in connection with the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating an embodiment of an image forming apparatus;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating an example of a case where a light source unit consists of a semiconductor laser array or a surface emitting laser;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic perspective diagram illustrating a case where an optical device including VCSEL exposes a photo conductor drum;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic functional block diagram illustrating a control unit of the image forming apparatus;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 5</figref> is a detailed functional block diagram of GAVD;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6</figref> is a functional block diagram of an image processing unit according to a first embodiment;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 7A</figref> is a schematic diagram illustrating an example of an image matrix;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7B</figref> is a schematic diagram illustrating a pattern example of a recognizing pixel column;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 8</figref> is a schematic diagram explaining an operation of an address translating unit;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 9</figref> is a schematic diagram explaining an operation when a white pixel is identical to an addition/deletion position according to a zooming process;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 10A</figref> is a diagram illustrating an operation example of an image path selector when a pixel bit is not appended;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 10B</figref> is a diagram illustrating an operation example (a first scan to a third scan) of the image path selector when a pixel bit is appended;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 11A</figref> is a diagram illustrating an example of a relation between image data and R and F addresses;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 11B</figref> is a diagram illustrating an example of a relation between a unit pixel and a laser spot;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 12</figref> is a diagram illustrating an example of a case where four-time dense image data is generated in a main-scanning direction and a sub-scanning direction, or four-time dense image data is generated only in a sub-scanning direction;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart illustrating the procedure of a zooming process according to the first embodiment;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 14</figref> is an explanation diagram illustrating an addition/deletion position before position correction, and an addition/deletion position after position correction of a pixel;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 15</figref> is an explanation diagram illustrating an example of an image that is obtained by performing a zooming process on the addition/deletion position before position correction, and the addition/deletion position after position correction of a pixel;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 16</figref> is a block diagram illustrating the functional configuration of an image processing unit according to a second embodiment;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 17</figref> is a block diagram illustrating the functional configuration of an image processing unit according to a third embodiment;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 18</figref> is a schematic diagram illustrating an example of a case where pixel deletion performed by a reduction process affects to a 1200 dpi black 1 pixel portion and a pixel becomes thinner;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 19</figref> is a schematic diagram illustrating an image correction example when pixel addition performed by an expansion process affects to a 1200 dpi black 1 pixel portion;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 20</figref> is a schematic diagram illustrating a pattern matching example according to the third embodiment;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 21</figref> is a schematic diagram illustrating a pattern matching example according to the third embodiment; and</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 22</figref> is a flowchart illustrating the procedure of a zooming process according to the third embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0042" num="0041">Exemplary embodiments of the present invention will be explained in detail below with reference to the accompanying drawings. However, the present invention is not limited to these embodiments.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram illustrating mechanical configuration of an image forming apparatus <b>100</b> according to a first embodiment. The image forming apparatus <b>100</b> of the present embodiment includes an optical device <b>102</b> including optical elements such as a VCSEL (Vertical Cavity Surface Emitting LASER) <b>200</b> (see <figref idref="DRAWINGS">FIG. 2</figref> and <figref idref="DRAWINGS">FIG. 3</figref>) or a polygon mirror <b>102</b><i>a</i>, an image forming unit <b>112</b> including a photo conductor drum, a charging device, a developing device, and the like, and a transfer unit <b>122</b> including an intermediate transfer belt and the like. The optical device <b>102</b> includes the VCSEL <b>200</b> as a semiconductor laser. In the embodiment illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, light beams projected from the VCSEL <b>200</b> (not illustrated in <figref idref="DRAWINGS">FIG. 1</figref>) are once condensed by a first cylindrical lens (not illustrated) and are deflected by the polygon mirror <b>102</b><i>a </i>to a reflecting mirror <b>102</b><i>b. </i></p>
<p id="p-0044" num="0043">The VCSEL <b>200</b> is a plane-emission semiconductor laser in which a plurality of light sources (semiconductor lasers) is arranged on a same chip in a reticular pattern. There are known various technologies for an image forming apparatus that employs the VCSEL <b>200</b>. The optical device <b>102</b> of the image forming apparatus <b>100</b> according to the present embodiment includes the VCSEL <b>200</b> by employing the configuration similar to these well-known technologies.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 2</figref> is a configuration diagram of the VCSEL <b>200</b> that is incorporated in the optical device <b>102</b> of the present embodiment. As illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, the VCSEL <b>200</b> of the present embodiment constitutes a semiconductor laser array in which a plurality of light sources <b>1001</b> (a plurality of semiconductor lasers) are arranged in a reticular pattern. In this case, the plurality of light sources <b>1001</b> are provided in such a manner that their array directions are inclined against the rotation axis of the polygon mirror <b>102</b><i>a</i>, which functions as a deflector, at a predetermined angle &#x3b8;.</p>
<p id="p-0046" num="0045">In <figref idref="DRAWINGS">FIG. 2</figref>, it is assumed that the vertical array direction of the light source is &#x201c;a&#x201d; to &#x201c;c&#x201d; and the transversal array direction thereof is &#x201c;1&#x201d; to &#x201c;4&#x201d;. For example, the light source <b>1001</b> illustrated at an upper-left side of <figref idref="DRAWINGS">FIG. 2</figref> is indicated as &#x201c;a1&#x201d;. Because the light sources <b>1001</b> are arranged to be inclined at a polygon mirror angle &#x3b8;, a light source a1 and a light source a2 expose different scanning positions. It is considered that one pixel is constituted by the two light sources, in other words, one pixel is realized by two light sources in <figref idref="DRAWINGS">FIG. 2</figref>. For example, assuming that the two light sources a1 and a2 constitute one pixel, and two light sources a3 and a4 constitute one pixel, pixels as illustrated in the right-hand edge of <figref idref="DRAWINGS">FIG. 2</figref> are formed by the light sources illustrated in the diagram. When it is assumed that the vertical (longitudinal) direction of the diagram is a sub-scanning direction, it is assumed that the center distance of pixels constituted by two light sources corresponds to 600 dpi. At this time, an interval between centers of two light sources constituting one pixel corresponds to 1200 dpi. Thus, a light-source density has a two-time density as compared with one single pixel density. Therefore, the barycenter position of a pixel can be shifted in a sub-scanning direction, and high-accuracy image forming can be realized by changing the light amount ratio of light sources constituting one pixel.</p>
<p id="p-0047" num="0046">The image forming apparatus <b>100</b> includes the post-object type optical device <b>102</b> that does not use an f&#x3b8; lens. In the illustrated embodiment, light beams L are generated by a quantity corresponding to all colors of cyan (C), magenta (M), yellow (Y), and black (K), are reflected by the reflecting mirror <b>102</b><i>b</i>, are again condensed by a second cylindrical lens <b>102</b><i>c</i>, and then exposes photo conductor drums <b>104</b><i>a</i>, <b>106</b><i>a</i>, <b>108</b><i>a</i>, and <b>110</b><i>a. </i></p>
<p id="p-0048" num="0047">Because the irradiations of the light beams L are performed by using the plurality of optical elements as described above, timing synchronizations are performed with respect to a main-scanning direction and a sub-scanning direction. Hereinafter, a main-scanning direction is defined as the scanning direction of light beam and a sub-scanning direction is defined as a direction perpendicular to the main-scanning direction.</p>
<p id="p-0049" num="0048">Each of the photo conductor drums <b>104</b><i>a</i>, <b>106</b><i>a</i>, <b>108</b><i>a</i>, and <b>110</b><i>a </i>includes a photoconductive layer that has at least a charge generating layer and a charge transporting layer on a conductive drum such as aluminum. The photoconductive layers are respectively arranged in correspondence with the photo conductor drums <b>104</b><i>a</i>, <b>106</b><i>a</i>, <b>108</b><i>a</i>, and <b>110</b><i>a</i>. Surface charges are given to the photoconductive layers by charging devices <b>104</b><i>b</i>, <b>106</b><i>b</i>, <b>108</b><i>b</i>, and <b>110</b><i>b </i>of which each includes a corotron, scorotron, or a charged roller.</p>
<p id="p-0050" num="0049">Electrostatic charges that are given by the charging devices <b>104</b><i>b</i>, <b>106</b><i>b</i>, <b>108</b><i>b</i>, and <b>110</b><i>b </i>on the photo conductor drums <b>104</b><i>a</i>, <b>106</b><i>a</i>, <b>108</b><i>a</i>, and <b>110</b><i>a </i>are exposed by the light beams L to form an image and thus an electrostatic latent image is formed. The electrostatic latent image formed on the photo conductor drums <b>104</b><i>a</i>, <b>106</b><i>a</i>, <b>108</b><i>a</i>, and <b>110</b><i>a </i>is developed by developing devices <b>104</b><i>c</i>, <b>106</b><i>c</i>, <b>108</b><i>c</i>, and <b>110</b><i>c </i>including a developing sleeve, a developer supplying roller, a regulatory blade, and the like so that a developer image is formed.</p>
<p id="p-0051" num="0050">The each developer carried on each of the photo conductor drum <b>104</b><i>a</i>, <b>106</b><i>a</i>, <b>108</b><i>a</i>, and <b>110</b><i>a </i>is transferred on an intermediate transfer belt <b>114</b> that moves in the direction of an arrow A by carrying rollers <b>114</b><i>a</i>, <b>114</b><i>b</i>, and <b>114</b><i>c</i>. The intermediate transfer belt <b>114</b> is carried to a secondary transfer unit in a state where the intermediate transfer belt is carrying C, M, Y, and K developer. The secondary transfer unit includes a secondary transfer belt <b>118</b> and carrying rollers <b>118</b><i>a </i>and <b>118</b><i>b</i>. The secondary transfer belt <b>118</b> is carried in the direction of an arrow B by the carrying rollers <b>118</b><i>a </i>and <b>118</b><i>b</i>. The secondary transfer unit is supplied with an image receiving member <b>124</b> such as premium grade paper or plastic sheet from an image-receiving-member accommodating unit <b>128</b>, which is a paper feeding cassette by using a carrying roller <b>126</b>.</p>
<p id="p-0052" num="0051">The secondary transfer unit applies a secondary transfer bias to transfer a multicolor developer image carried on the intermediate transfer belt <b>114</b> to the image receiving member <b>124</b> that is adsorbed and held on the secondary transfer belt <b>118</b>. The image receiving member <b>124</b> is supplied to a fixing device <b>120</b> along with the transportation of the secondary transfer belt <b>118</b>. The fixing device <b>120</b> includes a fixing member <b>130</b> such as a fixing roller including silicone rubber, fluorine rubber, or the like. The fixing device <b>120</b> pressurizes and heats the image receiving member <b>124</b> and the multicolor developer image and outputs the heated member to the outside of the image forming apparatus <b>100</b> as a printed matter <b>132</b>. The intermediate transfer belt <b>114</b> after transferring the multicolor developer image is supplied to the next image formation process after post-transfer remaining developer is removed by a cleaning unit <b>116</b> including a cleaning blade.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic perspective diagram illustrating the configuration where the optical device <b>102</b> including the VCSEL <b>200</b> exposes the photo conductor drum <b>104</b><i>a</i>. The light beams L projected from the VCSEL <b>200</b> are condensed by a first cylindrical lens <b>202</b> that is used to shape the bundle of light beams, pass through a reflecting mirror <b>204</b> and an imaging lens <b>206</b>, and then are deflected by the polygon mirror <b>102</b><i>a</i>. The polygon mirror <b>102</b><i>a </i>is driven to rotate by a spindle motor or the like that rotates at several thousand to several ten-thousand rotations. The light beams L reflected by the polygon mirror <b>102</b><i>a </i>are again reflected by the reflecting mirror <b>102</b><i>b </i>and then are reshaped by the second cylindrical lens <b>102</b><i>c </i>to expose an upper surface of the photo conductor drum <b>104</b><i>a. </i></p>
<p id="p-0054" num="0053">Moreover, a reflecting mirror <b>208</b> is arranged to synchronize scan start timing in the sub-scanning direction of the light beams L. The reflecting mirror <b>208</b> reflects the light beams L to a synchronization detecting device <b>210</b> that includes a photodiode and the like before starting the scanning in the sub-scanning direction. When detecting the light beams, the synchronization detecting device <b>210</b> generates a synchronizing signal to start sub-scanning and synchronizes a process for generating a drive control signal to the VCSEL <b>200</b> and the like.</p>
<p id="p-0055" num="0054">The VCSEL <b>200</b> is driven by a pulse signal sent from a GAVD <b>310</b>, as described below, to expose the light beams L at positions corresponding to the predetermined image bits of image data and form an electrostatic latent image on the photo conductor drum <b>104</b><i>a. </i></p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic functional block diagram illustrating a control unit <b>300</b> of the image forming apparatus <b>100</b>. The control unit <b>300</b> includes a scanner unit <b>302</b>, a printer unit <b>308</b> and, a main control unit <b>330</b>. The scanner unit <b>302</b> functions as a means for reading an image that includes a VPU <b>304</b> and an IPU <b>306</b>. The VPU <b>304</b> performs analog-to-digital conversion on a signal read by a scanner and performs black offset correction, shading compensation, and pixel position correction on the converted signal. The IPU <b>306</b> performs image processing for digital-converting mainly the acquired image of an RGB color coordinate system into the image data of a CMYK color coordinate system. The reading image acquired by the scanner unit <b>302</b> is sent to the printer unit <b>308</b> as digital data.</p>
<p id="p-0057" num="0056">The printer unit <b>308</b> includes the GAVD <b>310</b>, an LD driver <b>312</b>, and the VCSEL <b>200</b>. The GAVD <b>310</b> functions as a control means for performing the drive control of the VCSEL <b>200</b>. The LD driver <b>312</b> supplies currents for driving semiconductor laser devices to the semiconductor laser devices in response to a drive control signal generated by the GAVD <b>310</b>. The VCSEL <b>200</b> mounts thereon the semiconductor laser devices that are arranged in a two-dimensional manner. The GAVD <b>310</b> of the present embodiment divides pixel data and carries out a high-resolution process for the image data sent from the scanner unit <b>302</b> in such a manner that the pixel data corresponds to the spatial size of the semiconductor laser devices projected by the VCSEL <b>200</b>.</p>
<p id="p-0058" num="0057">Moreover, the scanner unit <b>302</b> and the printer unit <b>308</b> are connected to the main control unit <b>330</b> via a system bus <b>316</b> and are controlled for image reading and image forming in accordance with the command of the main control unit <b>330</b>. The main control unit <b>330</b> includes a central processing unit (hereinafter, &#x201c;CPU&#x201d;) <b>320</b> and a RAM <b>322</b> that provides a process space that is used for the process of the CPU <b>320</b>. The CPU <b>320</b> can use any CPU that has been known till now. For example, the CPU <b>320</b> can use CISC (Complex Instruction Set Computer) such as the PENTIUM (registered trademark) series or a compatible CPU thereof, RISC (Reduced Instruction Set Computer) such as MIPS, or the like. The CPU <b>320</b> accepts a command from a user via an interface <b>328</b> and calls a program module that executes a process corresponding to the command to execute a process such as copy, facsimile, scanning, or image storage. The main control unit <b>330</b> further includes a ROM <b>324</b> that stores therein the initial setting data of the CPU <b>320</b>, control data, a program, and the like to be able to be used by the CPU <b>320</b>. An image storage <b>326</b> is configured as a fixed or removable memory device such as a hard disk drive, an SD card, or a USB memory and stores therein image data acquired by the image forming apparatus <b>100</b> to be able to be used for various types of processes by the user.</p>
<p id="p-0059" num="0058">When the printer unit <b>308</b> is driven to output an image on the photo conductor drum <b>104</b><i>a </i>as an electrostatic latent image by using the image data acquired by the scanner unit <b>302</b>, the CPU <b>320</b> carries out main-scanning direction control and sub-scanning position control of an image receiving member such as premium grade paper or plastic film. When starting the scanning of the sub-scanning direction, the CPU <b>320</b> outputs a start signal to the GAVD <b>310</b>. When the GAVD <b>310</b> receives the start signal, the IPU <b>306</b> starts a scanning process. After that, the GAVD <b>310</b> receives image data stored in a buffer memory or the like, processes the received image data, and outputs the processed image data to the LD driver <b>312</b>. When receiving the image data from the GAVD <b>310</b>, the LD driver <b>312</b> generates the drive control signal of the VCSEL <b>200</b>. After that, the LD driver <b>312</b> transmits the drive control signal to the VCSEL <b>200</b> to turn on the VCSEL <b>200</b>. In addition, the LD driver <b>312</b> drives the semiconductor laser devices by using PWM control and the like. The VCSEL <b>200</b> explained in the present embodiment includes 8-channel semiconductor laser device. However, the number of channels of the VCSEL <b>200</b> is not limited to this.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 5</figref> is a detailed functional block diagram of the GAVD <b>310</b>. The GAVD <b>310</b> includes a memory <b>340</b> such as a FIFO buffer that stores therein the image data sent from the IPU <b>306</b> and hands over the image data sent from the IPU <b>306</b> to an image processing unit <b>342</b> in a first-in and first-out method by receiving a synchronizing signal. The image processing unit <b>342</b> reads the image data from the memory <b>340</b> and carries out the resolution conversion of image data, the assignment of semiconductor laser device channel, and an addition/deletion process (or, correction process of image data) of image bit (or, correction pixel for zooming image data). A position at which the image data is exposed on the photo conductor drum <b>104</b><i>a </i>is defined by a main-scanning line address value defined in a main-scanning direction and a sub-scanning line address value defined in a sub-scanning direction. Hereinafter, in the present embodiment, address coordinates are defined as the set of each address value that gives a specific image bit when image data is designated by a main-scanning line address value (R address value) and a sub-scanning line address value (F address value). These address values are decided by an address generating unit <b>354</b> as described below. Moreover, these address coordinates are decided for pixels (or, pixel column) that are arrayed at lines located in the main-scanning and sub-scanning directions. An image path selector <b>358</b> (described later) performs, every pixel column, a correction process for inserting a pixel bit on a pixel located at the address (or, pixel position) of coordinates designated by the R address value and the F address value by the address generating unit <b>354</b> to be described below.</p>
<p id="p-0061" num="0060">An output data control unit <b>344</b> converts the F address value and sub-scanning speed of output data that is expected to be a writing signal corresponding to the image data generated by the image processing unit <b>342</b> into a time-series drive pulse. The output data control unit <b>344</b> further generates a synchronous control signal for giving a synchronizing signal to the synchronization detecting device <b>210</b>. The generated drive control signal is transmitted to the LD driver <b>312</b> to drive VCSEL (not illustrated). Moreover, the output data control unit <b>344</b> is supplied with the synchronizing signal output from the synchronization detecting device <b>210</b> to synchronize the transmission of the drive control signal to the LD driver <b>312</b>. In addition, the processes performed by the memory <b>340</b>, the image processing unit <b>342</b>, and the output data control unit <b>344</b> are synchronized with an operating clock by a PLL <b>346</b>.</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 6</figref> is a functional block diagram of the image processing unit <b>342</b> illustrated in <figref idref="DRAWINGS">FIG. 5</figref>. As illustrated in <figref idref="DRAWINGS">FIG. 6</figref>, the image processing unit <b>342</b> includes a resolution converting unit <b>350</b>, a sub-scanning zooming unit <b>352</b>, and the address generating unit <b>354</b>.</p>
<p id="p-0063" num="0062">The resolution converting unit <b>350</b> divides the image data acquired from the memory <b>340</b> to create unit pixels corresponding to the number of channels and the size of the VCSEL <b>200</b> and creates divided pixels. After that, the resolution converting unit <b>350</b> performs, on the divided pixel, the assignment of the channel of laser device that irradiates the pixel. Moreover, when high resolution process is performed, the resolution converting unit <b>350</b> selects a 2n double-density process (n is a positive integer) or a 2n-line process and decides the drive assignment of the channel of laser device.</p>
<p id="p-0064" num="0063">The address generating unit <b>354</b> decides an address value of which the image bit is appended or deleted by a sub-scanning zooming process. The address generating unit <b>354</b> includes a reference address generating unit <b>354</b><i>a</i>, an address translating unit <b>354</b><i>b</i>, and a pattern recognition unit <b>354</b><i>c. </i></p>
<p id="p-0065" num="0064">The reference address generating unit <b>354</b><i>a </i>decides an address value (F address) to be appended or deleted. The address translating unit <b>354</b><i>b </i>determines whether the image bit of the address value to be appended or deleted determined by the reference address generating unit <b>354</b><i>a </i>is a correction target based on &#x201c;match&#x201d; data (described later) output from the pattern recognition unit <b>354</b><i>c</i>. When it is determined that the image bit is a correction target, the address translating unit <b>354</b><i>b </i>shifts the address value to be appended or deleted in a sub-scanning direction.</p>
<p id="p-0066" num="0065">The pattern recognition unit <b>354</b><i>c </i>stores an image matrix. The pattern recognition unit <b>354</b><i>c </i>pattern-matches the image matrix with the pixel column and outputs the matching result as &#x201c;match&#x201d; data. <figref idref="DRAWINGS">FIG. 7A</figref> is a schematic diagram illustrating an example of an image matrix. In the image matrix illustrated in <figref idref="DRAWINGS">FIG. 7A</figref>, a pixel surrounded with a central rectangle indicates a target pixel.</p>
<p id="p-0067" num="0066">In the present embodiment, the pattern matching performed by the pattern recognition unit <b>354</b><i>c </i>is carried out before a writing resolution conversion process. However, the present invention is not limited to this. The pattern matching may be carried out after the writing resolution conversion process.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 7B</figref> is a schematic diagram illustrating the pattern example of a recognizing pixel column. The pattern recognition unit <b>354</b><i>c </i>determines whether pixels are black or white by using the image matrix and outputs &#x201c;match&#x201d; data when each is identical with the corresponding pattern. In the example illustrated in <figref idref="DRAWINGS">FIG. 7B</figref>, the pattern recognition unit <b>354</b><i>c </i>outputs &#x201c;match&#x201d;=1 when one black pixel is present before and after the target pixel. When the pixels are not identical with any pattern, the pattern recognition unit <b>354</b><i>c </i>outputs &#x201c;match&#x201d;=0.</p>
<p id="p-0069" num="0068">Next, will be explained in detail the address translating unit <b>354</b><i>b</i>. <figref idref="DRAWINGS">FIG. 8</figref> is a schematic diagram explaining the operation of the address translating unit <b>354</b><i>b</i>. Will be explained the case where the address translating unit <b>354</b><i>b </i>is supplied with &#x201c;match&#x201d;=1 and F address=4n indicating an addition/deletion position.</p>
<p id="p-0070" num="0069">The pattern matching by the pattern recognition unit <b>354</b><i>c </i>in the present embodiment is a main/sub 1200 dpi image just before the resolution conversion process. On the other hand, because the zooming is processed by a pixel unit after the resolution conversion process, pattern matching data and an address have a relation illustrated in <figref idref="DRAWINGS">FIG. 8</figref>.</p>
<p id="p-0071" num="0070">In other words, when &#x201c;match&#x201d;=1 and addition/deletion position (F address)=4n+1, the address translating unit <b>354</b><i>b </i>determines that the addition/deletion position is 1200 dpi ldot black and shifts the position to the rear end of the sub-scanning direction like &#x201c;F address=F address+4=4n+5&#x201d;.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 9</figref> is a schematic diagram explaining an operation when a white pixel is identical to an addition/deletion position according to a zooming process. The &#x201c;match=4&#x201d; indicates white pixel ldot. When the F address=4n is the addition/deletion position, the address translating unit <b>354</b><i>b </i>shifts the position to the rear end of the sub-scanning direction like &#x201c;F address=F address+8=4n+8&#x201d;.</p>
<p id="p-0073" num="0072">In this case, a shift amount in the sub-scanning direction is previously determined and saved for each &#x201c;match&#x201d; value. As an example, a relation between the &#x201c;match&#x201d; data and the shift amount to the sub-scanning direction is as follows. However, the present invention is not limited to this.</p>
<p id="p-0074" num="0073">match=0: sub-scanning shift amount=0</p>
<p id="p-0075" num="0074">match=1: sub-scanning shift amount=4</p>
<p id="p-0076" num="0075">match=2: sub-scanning shift amount=4</p>
<p id="p-0077" num="0076">match=3: sub-scanning shift amount=8</p>
<p id="p-0078" num="0077">match=4: sub-scanning shift amount=8</p>
<p id="p-0079" num="0078">match=5: sub-scanning shift amount=8</p>
<p id="p-0080" num="0079">match=6: sub-scanning shift amount=12</p>
<p id="p-0081" num="0080">Returning to <figref idref="DRAWINGS">FIG. 6</figref>, the sub-scanning zooming unit <b>352</b> includes the image path selector <b>358</b> and a shift holding memory <b>356</b>. The sub-scanning zooming unit <b>352</b> receives the F and R addresses that are used to form an image from the address generating unit <b>354</b> and determines whether an address value to be processed includes an address value of which the image bit is appended or deleted. The sub-scanning zooming unit <b>352</b> generates zooming command signals such as an addition flag or a deletion flag with respect to an address of which the image bit is appended and deleted and hands over the zooming command signals to the image path selector <b>358</b> and the shift holding memory <b>356</b>. The shift holding memory <b>356</b> stores therein a shift amount by which an image bit is shifted and counts and holds the zooming command signals. The image path selector <b>358</b> sets the data of the image bit to white data and shifts subsequent image data by one bit when an image is being expanded and the zooming command signal is set. When the zooming command signal is not set, the image path selector <b>358</b> selects and outputs input data from the resolution converting unit <b>350</b> based on the shift amount output from the shift holding memory <b>356</b>. In the present embodiment, when the 8-channel VCSEL <b>200</b> is used as a semiconductor laser, a signal indicating a position to be appended and deleted and a signal indicating a shift amount are assigned by 8 channels to be used to drive the VCSEL <b>200</b>. In addition, a calculation part for appending and deleting an image bit can be configured as a dedicated module or can be configured as a part of another module if the calculation part is an appropriate function part of the image processing unit <b>342</b>. In addition, the reason for counting the zooming command signals is, for example, to append an image bit at the step of a first scanning and then specify a position at which an image bit is appended at the beginning of the second scanning when shifting an image bit.</p>
<p id="p-0082" num="0081">With reference to <figref idref="DRAWINGS">FIGS. 10A and 10B</figref>, will be explained an operation of the image path selector <b>358</b>. Target data <b>602</b> of <figref idref="DRAWINGS">FIGS. 10A and 10B</figref> indicates a bit value for one pixel. Data for one pixel is indicated by secondary coordinates for 8 channels and is bit data assigned at a specific main-scanning coordinate position. As input data <b>600</b>, the target data <b>602</b> and zooming data for designating a shifting unit for sub-scanning zooming are always read from the memory <b>340</b> in the preceding-stage. The same process is performed on all lines and then the processed data are input into the resolution converting unit <b>350</b>. Because a zooming command signal is not set at the time of unzooming illustrated in <figref idref="DRAWINGS">FIG. 10A</figref>, it is considered that a shift amount from the shift holding memory <b>356</b> is zero (shift=0), and the image data of the target data <b>602</b> is handed over as output data <b>604</b> that is considered as a writing signal in the case of the embodiment as illustrated in <figref idref="DRAWINGS">FIG. 10A</figref>.</p>
<p id="p-0083" num="0082">Next, will be explained an operation when a zooming command signal is set with reference to <figref idref="DRAWINGS">FIG. 10B</figref>. In <figref idref="DRAWINGS">FIG. 10B</figref>, in the case of a first scanning (A), white is appended to the secondary coordinates 1 of the target data <b>602</b>. A signal indicating the addition of an image bit is set to an address value corresponding to CH<b>1</b>. The bit data of CH<b>1</b> is replaced to correspond to a white pixel and is set in the CH<b>1</b> of output data <b>606</b> as data. Then, a count value 1 that corresponds to addition corresponding to CH<b>1</b> is registered in the shift holding memory <b>356</b>.</p>
<p id="p-0084" num="0083">The data of CH<b>2</b> to CH<b>7</b> are shifted by secondary-coordinate values that are obtained by employing a channel shift amount-1 as the values of the secondary coordinates of the output data <b>606</b>. At this time, the image path selector <b>358</b> can assign the bit data of the target data of the channels corresponding to the channel shift amount-1 to the CH<b>2</b> to CH<b>7</b> of the output data <b>606</b> to append an image bit. An image bit corresponding to white is appended to the output data <b>606</b> in regard to the target data. The output data <b>606</b> is used as a writing signal. The output data control unit <b>344</b> serially converts the writing signal and generates the drive pulse of the VCSEL <b>200</b> to form an image. The process described above is performed in a main-scanning unit. Data is sequentially read from the memory <b>340</b> for the next pixel of the main-scanning direction and image forming is performed in the main-scanning direction.</p>
<p id="p-0085" num="0084">As described above, because the secondary-coordinate values of the CH<b>1</b> to CH<b>7</b> of the output data <b>606</b> are shifted by appending a white pixel in the first scanning (A), the secondary-coordinate values of CH<b>8</b> to CH<b>15</b> of the output data <b>606</b> are shifted by &#x2212;1 in the second scanning (B) as illustrated in <figref idref="DRAWINGS">FIG. 10B</figref> even if a white pixel is not appended. Furthermore, when a white pixel is appended similarly to the first scanning in the third scanning (C), the secondary-coordinate values of CH<b>16</b> to CH<b>23</b> of the output data <b>606</b> are shifted by &#x2212;2 as illustrated in <figref idref="DRAWINGS">FIG. 10B</figref>.</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIGS. 11A and 11B</figref> illustrate a relation between image data, an R address, and an F address and a relation between a unit pixel and a laser spot according to the VCSEL <b>200</b>. <figref idref="DRAWINGS">FIG. 11A</figref> illustrates a relation between image data and each address. <figref idref="DRAWINGS">FIG. 11B</figref> illustrates a relation between a unit pixel and a laser spot. As illustrated in <figref idref="DRAWINGS">FIG. 11A</figref>, an R address <b>702</b> decides the pixel position of the main-scanning direction for image data <b>700</b> and is a value corresponding to a writable range in the feeding direction of the image receiving member. Moreover, an F address <b>704</b> is a value for deciding the pixel position of the sub-scanning direction for the image data <b>700</b>. The feed of the main-scanning direction and the lighting control of the VCSEL <b>200</b> are performed in correspondence with these address values. The light beams scan over the photo conductor drum to form an electrostatic latent image on which a zooming control is performed.</p>
<p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. 11B</figref> illustrates laser spots <b>708</b> by which a pixel area <b>706</b> is irradiated. In the present embodiment, the VCSEL <b>200</b> includes 8-channel semiconductor laser device. The laser spots <b>708</b> of the semiconductor laser devices are formed by two lines of which each has 4 channels. Moreover, the laser spots <b>708</b> constituting a line are arranged to have the interval of 2.4 micrometers in the sub-scanning direction and to have the interval of 30 micrometers in the main-scanning direction. In other words, the pixel area <b>706</b> is irradiated with the laser spots <b>708</b> illustrated in <figref idref="DRAWINGS">FIG. 11B</figref> with resolution in which a unit pixel is divided into 16 areas by dividing the pixel area <b>706</b> into 4 areas in the sub-scanning direction and into 4 areas in the main-scanning direction. In the embodiment of <figref idref="DRAWINGS">FIG. 11B</figref>, a laser modulation pitch (beam pitch) in the sub-scanning direction is &#xbc; of the read pixel resolution. Specifically, when the input resolution of pixel is 1200 dpi (dots per inch), a latent image can be formed at a 4800 dpi beam pitch as effective resolution.</p>
<p id="p-0088" num="0087">The (a) part of <figref idref="DRAWINGS">FIG. 12</figref> is a schematic diagram explaining an example of a high-resolution process executed by the resolution converting unit <b>350</b>. The resolution converting unit <b>350</b> converts 2-bit image data <b>808</b> with input resolution 1200 dpi of unit pixel <b>800</b> into 16 1-bit divided pixel data <b>802</b> with output resolution 4800 dpi illustrated in the example of the (a) part of <figref idref="DRAWINGS">FIG. 12</figref> in order to perform a high-resolution process in which a so-called four-time dense process is carried out in the main-scanning direction and sub-scanning direction. The channel of the semiconductor laser device that performs exposure is assigned to each of the divided pixel data <b>802</b>, which is used to generate a drive control signal.</p>
<p id="p-0089" num="0088">In the present embodiment, although performed is the high-resolution process for converting the 2-bit image data <b>808</b> with input resolution 1200 dpi of the unit pixel <b>800</b> into the divided pixel data <b>802</b> illustrated in the (a) part of <figref idref="DRAWINGS">FIG. 12</figref>, the present invention is not limited to this process. For example, the resolution converting unit <b>350</b> may be configured in such a manner that a high-resolution process for converting the 2-bit image data <b>808</b> with input resolution 1200 dpi of the unit pixel <b>800</b> into divided pixel data illustrated in the (b) part of <figref idref="DRAWINGS">FIG. 12</figref> is performed.</p>
<p id="p-0090" num="0089">In the example illustrated in the (b) part of <figref idref="DRAWINGS">FIG. 12</figref>, resolution has 1 bit and 1200 dpi in the main-scanning direction and 4800 dpi in the sub-scanning direction. Therefore, divided pixel data <b>804</b> are illustrated as a 4 lines of 1200 dpi&#xd7;4 bits. In other words, the resolution converting unit <b>350</b> may be configured in such a manner that a high-resolution process for converting the 2-bit image data <b>808</b> with input resolution 1200 dpi of the unit pixel <b>800</b> into the divided pixel data <b>804</b> illustrated in the (b) part of <figref idref="DRAWINGS">FIG. 12</figref> is performed. Also in this case, the channel of the semiconductor laser device that performs the exposure of each divided pixel data is assigned to be provided to generate a drive control signal. The high-resolution process for converting image data into divided pixel data illustrated in the (a) part or (b) part of <figref idref="DRAWINGS">FIG. 12</figref> can be preferably utilized to cancel comprehensive image defect caused by such as moire of sub-scanning direction or knurling of edge. Furthermore, in the case of the high-resolution process illustrated in the (b) part of <figref idref="DRAWINGS">FIG. 12</figref>, the burden of the subsequent process can be reduced because the number of divided pixels can be reduced to &#xbc;.</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart illustrating the procedure of a zooming process performed by the image forming apparatus <b>100</b> according to the first embodiment. In the zooming process illustrated in <figref idref="DRAWINGS">FIG. 13</figref>, the reference address generating unit <b>354</b><i>a </i>first sets an R address value (Step S<b>11</b>). Then, the reference address generating unit <b>354</b><i>a </i>calculates an F address value to be appended or deleted by using the R address in the zooming method that is used in the image processing unit <b>342</b> (Step S<b>12</b>).</p>
<p id="p-0092" num="0091">Next, the pattern recognition unit <b>354</b><i>c </i>determines whether image data is a target pattern by performing pattern matching on between an image matrix and a pixel line of which the target pixel is pixels indicated by the F address value and the R address value as described above, and outputs the matching result as &#x201c;match&#x201d; data. Then, the address translating unit <b>354</b><i>b </i>shifts and changes the F address value of which the pixel is appended or deleted by using the &#x201c;match&#x201d; data (Step S<b>13</b>).</p>
<p id="p-0093" num="0092">Next, the image path selector <b>358</b> carries out rewriting by increasing or deleting the R address value that is set at Step S<b>11</b> and the F address value after the F address that is calculated at Step S<b>13</b> by one line, and sets an image bit at a pixel given by the address of (the R address value, the F address value) of the sub-scanning line corresponding to the calculated F address (Step S<b>14</b>). In other words, the image path selector <b>358</b> performs a correction process on the pixels located at the R address value and the F address value. Moreover, in the case of the addition of sub-scanning line, the insertion of sub-scanning line can be performed without rewriting the F address values in descending order in correspondence with the addition of sub-scanning line. For example, F address values to be appended are generated by using the values of two sub-scanning lines before and after the line to be appended as an index and are handed over to the output data control unit <b>344</b>.</p>
<p id="p-0094" num="0093">Next, the image path selector <b>358</b> reads out bit data in an F address range to be processed and transfers the bit data to the output data control unit <b>344</b> (Step S<b>15</b>). The output data control unit <b>344</b> generates a pulse signal at a timing corresponding to a pixel position, sends the pulse signal to the LD driver <b>312</b>, and drives the semiconductor laser device.</p>
<p id="p-0095" num="0094">In the process of Step S<b>14</b>, a value corresponding to 1200 dpi can be assigned for one line. Furthermore, in a state where the value of F address corresponding to 4800 dpi that is the resolving power of the sub-scanning direction of the VCSEL <b>200</b> for the F address will be previously assigned, high-resolution zooming control can be realized by using controlling the drive of the semiconductor laser device of the VCSEL <b>200</b> at the 4800 dpi level.</p>
<p id="p-0096" num="0095">Then, the image path selector <b>358</b> determines whether the transfer of pixel data in the default F address range that is assigned at 1200 dpi has been terminated based on the comparison of F address values or based on the reception of termination character bit (Step S<b>16</b>). When it is determined that the scanning in the sub-scanning range is terminated (Step S<b>16</b>: Yes), the reference address generating unit <b>354</b><i>a </i>sets the next R address value (Step S<b>17</b>). After that, the sub-scanning zooming unit <b>352</b> determines whether the scanning in the main-scanning range has been terminated (Step S<b>18</b>). When the scanning performed in the main-scanning direction is not terminated (Step S<b>18</b>: No), the process control moves to Step S<b>12</b> to repeat the process of Steps S<b>12</b> to S<b>18</b>.</p>
<p id="p-0097" num="0096">On the other hand, when the image path selector <b>358</b> determines that the scanning in the sub-scanning range is not terminated at Step S<b>16</b> (Step S<b>16</b>: No), the process control moves to Step S<b>12</b> to repeat the process of Steps S<b>12</b> to S<b>16</b> until the F address values in the scanning range are terminated. When it is finally determined that the scanning in the address range that should be processed on the image receiving member is terminated at Step S<b>18</b> (Step S<b>18</b>: Yes), the sub-scanning zooming unit <b>352</b> terminates the process.</p>
<p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. 14</figref> is an explanation diagram illustrating an addition/deletion position before position correction and an addition/deletion position after position correction of a pixel. In the example illustrated in <figref idref="DRAWINGS">FIG. 14</figref>, the pixels of coordinates (0, 16) and (4, 16) are identical with a black pixel and thus zooming process pixels are moved to coordinates (0, 19) and (4, 19).</p>
<p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. 15</figref> is an explanation diagram illustrating an example of an image that is obtained by performing a zooming process on the addition/deletion position before position correction and a zooming process on the addition/deletion position after position correction of a pixel. In <figref idref="DRAWINGS">FIG. 15</figref>, three-pixel black lines occur as surrounded by circles before the position correction. However, an image that is obtained by performing a zooming process at the addition/deletion position after position correction has four-pixel black lines and thus a negative effect such as banding can be reduced.</p>
<p id="p-0100" num="0099">In this way, in the present embodiment, the pattern recognition unit <b>354</b><i>c </i>recognizes a thin black line or a thin white line by using matching. When the addition/deletion position according to the zooming process is identical with the thin black line or the thin white line by the address translating unit <b>354</b><i>b</i>, the thin black line or the thin white line can become thinner to reduce the thickness and the generation of banding can be prevented because the addition/deletion position is shifted.</p>
<p id="p-0101" num="0100">Moreover, in the present embodiment, because the pattern recognition unit <b>354</b><i>c </i>recognizes a pattern for which dithering is considered, a negative effect to dithering as well as screen tone can be reduced.</p>
<p id="p-0102" num="0101">In the present embodiment, because a position is shifted by a predetermined amount in the sub-scanning direction and then writing is performed, a circuit configuration can be simplified and a circuit scale can be reduced.</p>
<p id="p-0103" num="0102">Next, will be explained a second embodiment. The mechanical configuration of an image forming apparatus of the present embodiment is similar to that of the first embodiment. <figref idref="DRAWINGS">FIG. 16</figref> is a block diagram illustrating functional configuration of an image processing unit according to the second embodiment. As illustrated in <figref idref="DRAWINGS">FIG. 16</figref>, the image processing unit of the present embodiment mainly includes the resolution converting unit <b>350</b>, the sub-scanning zooming unit <b>352</b>, and an address generating unit <b>1654</b>. The function and configuration of the resolution converting unit <b>350</b> and the sub-scanning zooming unit <b>352</b> are similar to those of the first embodiment.</p>
<p id="p-0104" num="0103">The address generating unit <b>1654</b> of the present embodiment includes the reference address generating unit <b>354</b><i>a</i>, the address translating unit <b>354</b><i>b</i>, the pattern recognition unit <b>354</b><i>c</i>, and a bit converting unit <b>354</b><i>d</i>. The function and configuration of the reference address generating unit <b>354</b><i>a</i>, the address translating unit <b>354</b><i>b</i>, and the pattern recognition unit <b>354</b><i>c </i>are similar to those of the first embodiment.</p>
<p id="p-0105" num="0104">The bit converting unit <b>354</b><i>d </i>binarizes input image data when the input image data is two bits. For example, the bit converting unit <b>354</b><i>d </i>converts 11 (binary number) into 1, 10 (binary number) into 1, 01 (binary number) into 1, and 00 (binary number) into 0. In the case of pattern matching performed by the pattern recognition unit <b>354</b><i>c</i>, it is determined that 1 is black and 0 is white.</p>
<p id="p-0106" num="0105">Moreover, the bit converting unit <b>354</b><i>d </i>may be configured to convert 2-bit multi-valued data into three values. In this case, the bit converting unit <b>354</b><i>d </i>converts 11 (binary number) into 2, 10 (binary number) into 1, 01 (binary number) into 1, and 00 (binary number) into 0. In this case, in the case of pattern matching performed by the pattern recognition unit <b>354</b><i>c</i>, it is determined that 2 is black, 1 is half tone, and 0 is white.</p>
<p id="p-0107" num="0106">According to the zooming process of the present embodiment, in the zooming process explained in <figref idref="DRAWINGS">FIG. 13</figref>, the bit conversion process performed by the bit converting unit <b>354</b><i>d </i>is performed between Step S<b>12</b> and Step S<b>13</b>.</p>
<p id="p-0108" num="0107">In this way, in the present embodiment, because the bit conversion process of input image data is performed on the input image of multi-valued data before the pattern matching process by the pattern recognition unit <b>354</b><i>c</i>, a negative effect such as banding according to a zooming process can be reduced.</p>
<p id="p-0109" num="0108">Next, will be explained a third embodiment. The mechanical configuration of an image forming apparatus of the present embodiment is similar to that of the first embodiment. <figref idref="DRAWINGS">FIG. 17</figref> is a block diagram illustrating the functional configuration of an image processing unit according to the third embodiment. As illustrated in <figref idref="DRAWINGS">FIG. 17</figref>, the image processing unit of the present embodiment mainly includes the resolution converting unit <b>350</b>, a sub-scanning zooming unit <b>1758</b>, a pattern recognition unit <b>1754</b><i>c</i>, and an image correcting unit <b>360</b>. The function and configuration of the resolution converting unit <b>350</b> is similar to those of the first embodiment.</p>
<p id="p-0110" num="0109">As illustrated in <figref idref="DRAWINGS">FIG. 17</figref>, the sub-scanning zooming unit <b>1758</b> includes a reference address generating unit <b>1754</b><i>a</i>, the shift holding memory <b>356</b>, and the image path selector <b>358</b>.</p>
<p id="p-0111" num="0110">The reference address generating unit <b>1754</b><i>a </i>decides an address value of which the image bit is appended or deleted according to a sub-scanning zooming process similarly to the first embodiment. The image path selector <b>358</b> carries out the addition or deletion of an image and shifts image data in accordance with the address value determined by the reference address generating unit <b>1754</b><i>a. </i></p>
<p id="p-0112" num="0111">The pattern recognition unit <b>1754</b><i>c </i>performs pattern matching on the image data on which the sub-scanning zooming process is performed by using an image matrix similar to that of the first embodiment. Then, when the image data is identical with the pattern of a predetermined correction target, the pattern recognition unit <b>1754</b><i>c </i>outputs the image data of a target pixel to the image correcting unit <b>360</b> and the image correcting unit <b>360</b> converts the input image data into predetermined lighting data.</p>
<p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. 18</figref> is a schematic diagram illustrating an example of the case where pixel deletion performed by a reduction process is onto a 1200 dpi black 1 pixel portion, whose pixel has become thinner. When the target pixel is identical with the pattern illustrated at the left side of <figref idref="DRAWINGS">FIG. 18</figref>, the pattern recognition unit <b>1754</b><i>c </i>outputs &#x201c;match&#x201d; data=1. When &#x201c;match&#x201d; data=1, the image correcting unit <b>360</b> converts the target pixel into F[hex] indicating a black pixel.</p>
<p id="p-0114" num="0113">Image conversion performed by the image correcting unit <b>360</b> is as described below.</p>
<p id="p-0115" num="0114">match=0&#x2192;without correction</p>
<p id="p-0116" num="0115">match=1&#x2192;F[hex] (black pixel)</p>
<p id="p-0117" num="0116">match=2&#x2192;0[hex] (white pixel)</p>
<p id="p-0118" num="0117"><figref idref="DRAWINGS">FIG. 19</figref> is a schematic diagram illustrating an image correction example when pixel addition performed by an expansion process is onto a 1200 dpi black 1 pixel portion. When line width correction is not performed, a white pixel appended by the expansion process is broken on electrophotography and one black pixel seems to become thick. In the present embodiment, to perform image correction as illustrated in <figref idref="DRAWINGS">FIG. 19</figref>, pattern matching is performed by the pattern recognition unit <b>1754</b><i>c </i>and the image data of a target pixel is corrected by the image correcting unit <b>360</b> as illustrated in <figref idref="DRAWINGS">FIGS. 20 and 21</figref>.</p>
<p id="p-0119" num="0118"><figref idref="DRAWINGS">FIG. 22</figref> is a flowchart illustrating the procedure of a zooming process according to the third embodiment. The processes of Steps S<b>31</b> and S<b>32</b> are performed similarly to those of the first embodiment.</p>
<p id="p-0120" num="0119">The image path selector <b>358</b> increases or deletes the R address value that was set at Step S<b>31</b> and an F address value after the F address was calculated at Step S<b>32</b> by one line to carry out rewriting, and sets an image bit at a pixel given by the address (of the R address value, the F address value) on the sub-scanning line corresponding to the calculated F address (Step S<b>33</b>). In other words, the image path selector <b>358</b> performs a correction process on a pixel located at the R address value and the F address value.</p>
<p id="p-0121" num="0120">Then, the pattern recognition unit <b>1754</b><i>c </i>performs pattern matching on the image data on which sub-scanning zooming is performed. When it is determined that the image data falls on a target pattern, the image correcting unit <b>360</b> converts the image data into predetermined image data (Step S<b>34</b>).</p>
<p id="p-0122" num="0121">After that, the processes of Steps S<b>35</b> to S<b>38</b> are performed similarly to those of Steps S<b>15</b> to S<b>18</b> of the zooming process according to the first embodiment.</p>
<p id="p-0123" num="0122">In this way, according to the present embodiment, because the F address and the R address are calculated to perform the addition/deletion of a pixel, pattern matching is performed, and image correction is performed based on the result, the generation of banding can be prevented similarly to the first embodiment.</p>
<p id="p-0124" num="0123">In addition, according to the present embodiment, although pattern matching is carried out by binary image data and the result is converted into F[hex] or 0[hex], the present invention can be configured that pattern matching is performed on half-tone image data and the result is converted.</p>
<p id="p-0125" num="0124">The image forming method described above is executed by a computer mounted on the image forming apparatus and is described by a programming language such as an assembler or a C language. Furthermore, the image forming method can be realized by a computer-readable program and can be stored in a computer-readable recording medium that records the program.</p>
<p id="p-0126" num="0125">As described above, according to an aspect of the present invention, a zooming process can be controlled at a level of a semiconductor laser device, high-speed printing and high-resolution image forming when printing double-sided can be realized without wide-ranged image degradation such as moire caused by the zooming process, and the generation of banding can be prevented.</p>
<p id="p-0127" num="0126">Although the invention has been described with respect to specific embodiments for a complete and clear disclosure, the appended claims are not to be thus limited but are to be construed as embodying all modifications and alternative constructions that may occur to one skilled in the art that fairly fall within the basic teaching herein set forth.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image forming apparatus comprising:
<claim-text>a zooming unit configured to zoom image data that is input by adding or removing a pixel to or from a designated pixel position in the input image data;</claim-text>
<claim-text>a pattern recognition unit configured to recognize whether a pixel line including a pixel at the designated pixel position in a sub-scanning direction matches a pattern that is predetermined; and</claim-text>
<claim-text>a pixel position changing unit configured to shift the designated pixel position by a predetermined amount defined by the pattern in the sub-scanning direction, when the pixel line is recognized to match the pattern.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the designated pixel position indicates a position of a pixel after processing,
<claim-text>the procession being a double density procession that makes density increase for a pixel included in the input image data before the double density processing</claim-text>
<claim-text>wherein the pattern is of a pattern of the pixel line formed of the pixel before the processing, and</claim-text>
<claim-text>wherein the pattern recognizing unit recognizes whether the pixel line in the sub-scanning direction, formed of the pixel before the processing which corresponds to the pixel after the procession of which location is indicated by the designated pixel position, matches the pattern.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image forming apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the pattern includes
<claim-text>a black pixel, and</claim-text>
<claim-text>white pixels that are adjacent to the black pixel,</claim-text>
<claim-text>wherein the pixel position changing unit, when the pixel line matches the pattern, shifts the designated pixel position in the sub-scanning direction by a shift amount that is defined by the pattern that matches and by a shift amount that corresponds to one or more pixels that are before the processing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The image forming apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the pattern includes a white pixel and black pixels that are adjacent to the white pixel,
<claim-text>wherein the pixel position changing unit, when the pixel line matches the pattern, shifts the designated pixel position in the sub-scanning direction by a shift amount that is defined by the pattern that matches and by a shift amount that corresponds to two or more pixels that are before the processing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pixel position changing unit comprises a binarizing unit that binarizes multi-valued image data as the input image data, and
<claim-text>wherein the pattern recognition unit recognizes whether the pattern matches the pixel line in the sub-scanning direction including a pixel at the designated pixel position in the binarized image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pixel position changing unit comprises ternarizing unit that ternarizes multi-valued image data as the input image data, and
<claim-text>wherein the pattern recognition unit recognizes whether the pattern matches the pixel line in the sub-scanning direction including a pixel at the designated pixel position in the ternarized image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An image forming method for an image forming apparatus that includes a zooming unit configured to zoom image data that is input by adding or removing a pixel to or from a designated pixel position in the input image data, the method comprising:
<claim-text>recognizing whether a pixel line including a pixel at the designated pixel position in a sub-scanning direction matches a pattern that is predetermined; and</claim-text>
<claim-text>shifting the designated pixel position by a predetermined amount defined by the pattern in the sub-scanning direction, when the pixel line is recognized to match the pattern.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An image forming apparatus comprising:
<claim-text>a zooming means for zooming image data that is input by adding or removing a pixel to or from a designated pixel position in the input image data;</claim-text>
<claim-text>a pattern recognition means for recognizing whether a pixel line including a pixel at the designated pixel position in a sub-scanning direction matches a pattern that is predetermined; and</claim-text>
<claim-text>a pixel position changing means for shifting the designated pixel position by a predetermined amount defined by the pattern in the sub-scanning direction, when the pixel line is recognized to match the pattern.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
