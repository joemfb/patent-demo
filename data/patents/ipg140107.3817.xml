<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624883-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624883</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13088369</doc-number>
<date>20110417</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>114</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>038</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345204</main-classification>
<further-classification>345212</further-classification>
</classification-national>
<invention-title id="d2e55">Devices, systems and methods of capturing and displaying appearances</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7948481</doc-number>
<kind>B2</kind>
<name>Vilcovsky</name>
<date>20110500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345204</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2002/0196333</doc-number>
<kind>A1</kind>
<name>Gorischek</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2003/0085866</doc-number>
<kind>A1</kind>
<name>Bimber et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2005/0018140</doc-number>
<kind>A1</kind>
<name>Ishizaki et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2006/0178902</doc-number>
<kind>A1</kind>
<name>Vicars et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2009/0091710</doc-number>
<kind>A1</kind>
<name>Huebner</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>DE</country>
<doc-number>199 43 355</doc-number>
<kind>A1</kind>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>DE</country>
<doc-number>100 31 965</doc-number>
<kind>A1</kind>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>EP</country>
<doc-number>1 372 092</doc-number>
<kind>A1</kind>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>EP</country>
<doc-number>1 376 207</doc-number>
<kind>A1</kind>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>WO</country>
<doc-number>00/22955</doc-number>
<kind>A1</kind>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>International Search Report and Written Opinion for PCT/IL06/00281 mailed on Jun. 12, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>European Search Report for EP 06711263.1 mailed on Aug. 18, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>International Preliminary Report on Patentability for PCT/IL2006/000281 mailed on Sep. 20, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Non-final Office Action for U.S. Appl. No. 11/817,411 mailed on Jul. 21, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345204-215</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>34833301</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434395</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11817411</doc-number>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7948481</doc-number>
</document-id>
</parent-grant-document>
<parent-pct-document>
<document-id>
<country>WO</country>
<doc-number>PCT/IL2006/000281</doc-number>
<date>20060301</date>
</document-id>
</parent-pct-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13088369</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60656884</doc-number>
<date>20050301</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60656885</doc-number>
<date>20050301</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110199294</doc-number>
<kind>A1</kind>
<date>20110818</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Vilcovsky</last-name>
<first-name>Nissi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Vilcovsky</last-name>
<first-name>Nissi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Nixon Peabody LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Bach, Esq.</last-name>
<first-name>Joseph</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<examiners>
<primary-examiner>
<last-name>Shankar</last-name>
<first-name>Vijay</first-name>
<department>2697</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Some demonstrative embodiments of the invention include systems, devices and/or methods enabling appearance comparison. The system, according to some demonstrative embodiments, may include at least one interactive imaging and display station. The station may include, for example, a mirror-display device capable of selectably operating in either or both a mirror mode or a display mode; an imaging device to capture one or more appearances appearing in a field of view in front of the mirror-display device; and/or an image control unit to select the mode of operation of the mirror-display device according to a user command. Other embodiments are described and claimed.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="133.77mm" wi="349.17mm" file="US08624883-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="256.71mm" wi="184.91mm" file="US08624883-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="264.67mm" wi="183.98mm" file="US08624883-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="255.61mm" wi="178.73mm" orientation="landscape" file="US08624883-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="207.60mm" wi="107.61mm" file="US08624883-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a Continuation Application of U.S. application Ser. No. 11/817,411, filed Aug. 30, 2007, which is a National Phase Application of PCT International Application No. PCT/IL06/000281, International Filing Date Mar. 1, 2006, which in turn claims priority from and the benefit of U.S. Provisional Application No. 60/656,884, filed Mar. 1, 2005; and U.S. Provisional Application No. 60/656,885, filed Mar. 1, 2005, the entire disclosures of all of which are incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The invention relates generally to imaging and display systems and, more particularly, to interactive displays, e.g., in retail and/or service environments.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Customers may shop for consumer articles, for example, apparel such as clothes, e.g., shirts, pants, coats and other garments, as well as shoes, glasses, and/or any other items or products, such as cosmetics, furniture and the like. Shopping normally takes place at a shopping facility, for example, retail stores. Prior to making a decision which article to buy a customer may try on various articles (e.g., apparel, cosmetics) and/or pose with other articles (e.g., furniture), and may view for each trial a user-appearance in front of a mirror, which may be located, for example, at a trial area of the retail store. For example, the customer may try on a first article, e.g., a suit, and view for that first trial his/her user-appearance in front of the mirror. Then, the customer may try on a second article, e.g., another suit. The customer may then need to memorize his/her user-appearance from the first trial in order to perform a mental comparison between the first article and the second article, thereby to evaluate which of the two articles might be a better fit for the customer.</p>
<p id="p-0005" num="0004">Unfortunately, since the customer may try on numerous articles and/or since the second trial may take place a considerable amount of time after the first trial, the customer may not be able to recall his/her appearance for each trial and may therefore be required to repeatedly retry articles, e.g., items of apparels, previously tried on. This may result in a frustrating and inefficient shopping experience.</p>
<heading id="h-0004" level="1">SUMMARY OF SOME EMBODIMENTS OF THE INVENTION</heading>
<p id="p-0006" num="0005">Some demonstrative embodiments of the invention include devices, systems and/or methods enabling appearance comparison.</p>
<p id="p-0007" num="0006">According to some demonstrative embodiments of the invention, a system enabling appearance comparison may include at least one interactive imaging and display station. The station may include, for example, a mirror display device capable of operating in either or both a mirror or a display mode; an imaging device to capture one or more appearances from a field of view in front of the mirror-display device; and/or an image control unit to select the mode of operation the mirror display device according to a user command.</p>
<p id="p-0008" num="0007">According to some demonstrative embodiments of the invention the image control unit may include an input device to receive the user command.</p>
<p id="p-0009" num="0008">According to some demonstrative embodiments of the invention, the image control unit may include a storage device to store data of one or more images which may correspond to one or more appearances.</p>
<p id="p-0010" num="0009">According to some demonstrative embodiments of the invention, the mirror-display device may be capable of being partitioned into at least first and second simultaneously-displayable frames. The first frame may be selectably operable, for example, both in a mirror mode and a display mode. The second frame may be operable, for example, in a mirror mode.</p>
<p id="p-0011" num="0010">According to some demonstrative embodiments of the invention, the imaging device may be capable of capturing three-dimensional images of appearances.</p>
<p id="p-0012" num="0011">According to some demonstrative embodiments of the invention, the mirror-display device may be capable of displaying images of appearances at predefined sequences.</p>
<p id="p-0013" num="0012">According to some demonstrative embodiments of the invention, the image control unit may be able to selectively enable a user access to images of appearances authorized to the user, e.g., based on user-identifying data received from the user.</p>
<p id="p-0014" num="0013">According to some demonstrative embodiments of the invention, the at least one interactive imaging and display system may include two or more interactive imaging and display stations able to communicate over a network. For example, the two or more stations may be able to communicate between each other data representing images of appearances.</p>
<p id="p-0015" num="0014">According to some demonstrative embodiments of the invention, the image control unit may control the mirror-display device to display, e.g., during the display mode, one or more images corresponding to the appearances. The one or more images may include, for example, one or more mirrored appearances.</p>
<p id="p-0016" num="0015">According to some demonstrative embodiments of the invention, a method enabling appearance comparison may comprise using a mirror mode of operation of a mirror-display device capable of being selectably operated in either a mirror or a display mode; capturing an image corresponding to an appearance of a first trial in front of the mirror-display device; storing the image of the first trial; selecting the display mode of operation of the mirror-display device; and/or retrieving the image of the first trial and displaying the image on the mirror-display device.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0017" num="0016">The subject matter regarded as the invention is particularly pointed out and distinctly claimed in the concluding portion of the specification. The invention, however, both as to organization and method of operation, together with features and advantages thereof, may best be understood by reference to the following detailed description when read with the accompanied drawings in which:</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic illustration of an interactive system enabling appearance comparison in accordance with some demonstrative embodiments of the invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. 2A and 2B</figref> are schematic illustrations of two, sequential, stages of appearances comparison using an interactive system in accordance with some demonstrative embodiments of the invention; and</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIGS. 3A</figref>, <b>3</b>B and <b>3</b>C are schematic illustrations of three, sequential, stages of appearances comparison using an interactive system in accordance with some demonstrative embodiments of the invention; and</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic flow chart of a method enabling comparison of one or more user-appearances in accordance with some demonstrative embodiments of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0022" num="0021">It will be appreciated that for simplicity and clarity of illustration, elements shown in the figures have not necessarily been drawn accurately or to scale. For example, the dimensions of some of the elements may be exaggerated relative to other elements for clarity or several physical components included in one element. Further, where considered appropriate, reference numerals may be repeated among the figures to indicate corresponding or analogous elements. It will be appreciated that these figures present examples of embodiments of the present invention and are not intended to limit the scope of the invention.</p>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF SOME DEMONSTRATIVE EMBODIMENTS OF THE INVENTION</heading>
<p id="p-0023" num="0022">In the following description, various aspects of the present invention will be described. For purposes of explanation, specific configurations and details are set forth in order to provide a thorough understanding of the present invention. However, it will be apparent to one skilled in the art that the present invention may be practiced without the specific details presented herein. Furthermore, some features of the invention relying on principles and implementations known in the art may be omitted or simplified to avoid obscuring the present invention.</p>
<p id="p-0024" num="0023">Some demonstrative embodiments of the invention may include an interactive system enabling a user to compare one or more appearances, for example, to compare between different appearances, e.g., as described in detail below.</p>
<p id="p-0025" num="0024">The term &#x201c;user-appearance&#x201d; as used herein may relate to the appearance of a customer while trying a consumer article. The article may include, for example, apparel, such as clothing, shoes, glasses, garments, ties, and the like; an article, e.g., furniture, located in the vicinity of the customer; as well as other items, articles, designs or products such as, for example, cosmetics, headdresses, hair cuts.</p>
<p id="p-0026" num="0025">According to some demonstrative embodiments of the invention, the system may include an imaging device able to capture user-appearances and a mirror-display device, able to operate selectably as a mirror or as a display. When in the mirror mode, the mirror-display device may enable the user to evaluate and/or view a user-appearance of a current trial of a consumer article. When in the display mode, the mirror-display device may enable the user to evaluate and/or view one or more user-appearances, e.g., as captured by the imaging device, of a previous trial, e.g., as described in detail below.</p>
<p id="p-0027" num="0026">Reference is made to <figref idref="DRAWINGS">FIG. 1</figref>, which schematically illustrates an interactive system <b>100</b> in accordance with some demonstrative embodiments of the invention.</p>
<p id="p-0028" num="0027">According to some demonstrative embodiments of the invention, system <b>100</b> may include an interactive imaging and display station <b>110</b>, which may include an image control unit <b>120</b>, an imaging device <b>130</b>, and a mirror-display device <b>140</b>. Image control unit <b>120</b> may include a controller <b>121</b>, a network interface <b>122</b>, a storage device <b>123</b>, an input device <b>124</b>, all of which elements are described in detail below.</p>
<p id="p-0029" num="0028">Aspects of the invention are described herein in the context of demonstrative embodiments of an imaging device, e.g., imaging device <b>130</b>, a mirror-display device, e.g., mirror-display device <b>140</b>, and/or an image control unit, e.g., image control unit <b>120</b>, being separate units of an appearance comparison system, e.g., system <b>100</b>. However, it will be appreciated by those skilled in the art that the invention is not limited in this respect, and that according to other embodiments of the invention, the system may include any suitable configuration, combination, and/or arrangement of the imaging device, the mirror-display device, and/or the image control unit. For example, the system may include an integrated module including the mirror-display device, the imaging device and/or the image control unit. For example, the imaging device and/or the image control unit may be implemented as part of the mirror-display device.</p>
<p id="p-0030" num="0029">According to some demonstrative embodiments of the invention, mirror-display device <b>140</b> may be configured and/or may include components and mechanisms allowing mirror-display device <b>140</b> to operate selectably in two modes of operation. In a first mode of operation (the &#x201c;mirror-mode&#x201d;), mirror-display device <b>140</b> may operate as a mirror. In a second mode of operation (the &#x201c;display mode&#x201d;), mirror-display device <b>140</b> may operate as a display. When mirror-display device <b>140</b> operates in the mirror-mode, a user <b>111</b> of system <b>100</b> may evaluate and/or view a user-appearance of a first trial of a consumer article, as may be reflected by mirror-display device <b>140</b>. Imaging device <b>130</b> may capture an image of the user-appearance of the first trial. The captured image may be stored, for example, by storage device <b>123</b>, e.g., as described below. User <b>111</b> may then pose in front of mirror-display device <b>140</b> trying a second article, and imaging device <b>130</b> may capture a second image of the user-appearance of the second trial. When in the display mode, mirror-display <b>140</b> may be controlled to display one or more of previously captured images. By virtue of the capability of mirror-display device <b>140</b> to operate selectably in the mirror or display mode, user <b>111</b> may be able to compare simultaneously or sequentially between the user-appearances of the first and second trials, as described in detail below. In some demonstrative embodiments of the invention, e.g., as shown in <figref idref="DRAWINGS">FIGS. 1</figref>, <b>2</b>A, <b>2</b>B, <b>3</b><i>a</i>, and/or <b>3</b>B, controller <b>121</b> may control device <b>140</b> to display, during the display mode of operation, a mirror-image of the appearances. However, it will be appreciated by those of ordinary skill in the art that the invention is not limited in this respect, and that in other embodiments the controller may control device <b>140</b> to display, during the display mode of operation, any other image corresponding to the appearance, e.g., a rotated appearance, a revered appearance, a substantially non-altered, e.g., frontal, appearance, a rendered appearance, and the like, e.g., as described below.</p>
<p id="p-0031" num="0030">Device <b>140</b> may include any suitable configuration and/or mechanism to enable selectably operating mirror-display device <b>140</b> in the first and second modes of operation. For example, in one embodiment device <b>140</b> may include an array of liquid crystal (LC) elements, which may change their optical attributes such as, e.g., reflectivity, refractive index and the like, depending on, for example, a voltage applied to the liquid crystals. For example, applying a first voltage may result in changing the optical attributes of the liquid crystals such that mirror-display device <b>140</b> may operate as a mirror; and a second voltage may result in changing the optical attributes of the liquid crystals such that mirror-display device <b>140</b> may operate as a liquid crystal display.</p>
<p id="p-0032" num="0031">In another embodiment of the invention, for example, mirror-display device <b>140</b> may include a liquid crystal display (LCD) device embedded in a semi-reflective or one-directional mirror. Accordingly, if the LCD is switched to an inactive mode of operation, mirror-display <b>140</b> may passively reflect sufficient light incident thereon to enable the user to view user-appearances at reasonable quality and brightness. In contrast, when the LCD is turned to an active mode of operation, mirror-display device <b>140</b>, images displayed by the LCD device may be viewed by user <b>111</b> because they may be significantly brighter than residual reflections from the surface of the mirror-display.</p>
<p id="p-0033" num="0032">According to some demonstrative embodiments of the invention, mirror display device <b>140</b> may be implemented by a LCD HD ready mirror TV such as, for example, model No. 32PM8822/10 available from Royal Philips Electronics, e.g., as described at the Internet site &#x3c;http://www.research.philips.com/newscenter/archive/2003/mirrortv.html&#x3e;. Such a device may include, for example, a polymer-based organic light-emitting display (OLED). Mirror-display device <b>140</b> may include any other suitable device implementing any suitable display technology. For example, device <b>140</b> may include a nano-emissive display (NED); a plasma display panel (PDP); a cathode ray tube display (CRT); a Digital Light Processing (DLP) display; a surface conduction electron emitter display (SED); a Tablet screen; a flat-panel SED; an Organic electronic display; electronic paper; a 3-Dimensional display, e.g., a Hologram display; a thin film resistor (TFT) display; an optical TFT; a Dot Matrix LED screen; an LCD having CCD capabilities, e.g., such that mirror-display <b>140</b> may be capable of performing the functionality of imaging device <b>130</b>; a paintable LCD; a surface-conduction electron-emitter (SED) display; a high definition television (HDTV) display; a rear projector display device, and the like.</p>
<p id="p-0034" num="0033">According to some demonstrative embodiments of the invention, imaging device <b>130</b> may be adapted to capture one or more appearances from a Field-of-View (FOV) in front of mirror-display device <b>140</b>. The FOV in front of mirror-display device <b>140</b> may include, for example, a field, area, scene, zone, and/or region in front of mirror-display device <b>140</b>. For example, the FOV may include at least part of a field, area, scene, zone, and/or region captured by mirror-display device <b>140</b> when in the mirror mode.</p>
<p id="p-0035" num="0034">Although the scope of the present invention is not limited in this respect, imaging device <b>130</b> may be or may include, for example, a CCD camera, a video camera, a camera and/or camera set-up enabling capturing of 3D-images, e.g., a stereoscopic camera and the like. A stereoscopic camera may be adapted, for example, to capture a 3-D image of the user-appearance. The stereoscopic camera may include, for example, two lenses having a distance between each other that may correspond to a distance between two human eyes. Accordingly, the stereo camera may be able to simulate human binocular vision, also known as Stereophotography, thereby being able to capture a 3D-image.</p>
<p id="p-0036" num="0035">According to some demonstrative embodiments of the invention, station <b>110</b> may be a stand alone unit, which may be located at an appearance-comparison area of a desired location, for example, an office, a home, or a retail store, e.g., apparel store.</p>
<p id="p-0037" num="0036">According to other demonstrative embodiments of the invention, station <b>110</b> may be connected, e.g., via network interface <b>122</b>, to a network, for example, a network <b>150</b>, thereby enabling communication between station <b>110</b> and one or more other stations affiliated with network <b>150</b> such as, for example, station <b>160</b> and/or station <b>170</b>.</p>
<p id="p-0038" num="0037">According to some demonstrative embodiments of the invention, station <b>110</b> may include a network interface <b>122</b>, which may be adapted to interact with network <b>150</b>, to send and receive information from other stations in network <b>150</b>, as described herein. Such information may include but is not limited to data corresponding to images of users captured at various stations of system <b>100</b>, for example, station <b>160</b> and/or <b>170</b>, as well as identifying information of the users to enable secure access to the system, as described in more detail below. Network <b>150</b> may include, for example, a local area network (LAN), a wide area network (WAN), a global communication network, e.g., the Internet, a wireless communication network such as, for example, a wireless LAN (WLAN) communication network, a Bluetooth network, a wireless virtual private network (VPN), a cellular communication network, for example, a 3<sup>rd </sup>Generation Partnership Project (3GPP), such as, for example, Frequency Domain Duplexing (FDD) network, a Global System for Mobile communications (GSM) network, a Wideband Code Division Multiple Access (WCDMA) cellular communication network, and the like.</p>
<p id="p-0039" num="0038">According to some demonstrative embodiments of the invention, one or more of stations <b>160</b> and <b>170</b> may be portable devices. Non-limiting examples of such portable devices may include a mobile telephone, a laptop computer, a notebook computer, a mobile computer, a Personal Communication Systems (PCS) device Personal Digital Assistants (PDA), a wireless communication device, a PDA device which incorporates a wireless communication device, a cellular telephone, a wireless telephone, a smart card, a token, a memory card, a memory unit, and the like. In some embodiments of the invention, one or more of stations <b>160</b> and <b>170</b> may be non-portable devices such as, for example, a desktop computer, a tablet computer, a television set, a server computer, and the like.</p>
<p id="p-0040" num="0039">According to some embodiments of the invention, system <b>100</b> may also include a control center <b>190</b>, which may be connected to stations <b>110</b>, <b>160</b> and/or <b>170</b>, e.g., via network <b>150</b>. Control center <b>190</b> may receive and store data, which may represent, for example, data and/or images of user-appearances, received from one or more of stations <b>110</b>, <b>160</b> and/or <b>170</b>.</p>
<p id="p-0041" num="0040">According to some embodiments of the invention, stations <b>110</b>, <b>160</b> and/or <b>170</b> may be located at different locations such as, for example, different stores of a retail chain. In addition, stations <b>110</b>, <b>160</b> and/or <b>170</b> may be located at different locations within a building, e.g., different floors, different sections at the same floor and the like. Such locations may include, for example, clothing stores, shoe stores, points of sale, concept showrooms, exhibitions, shopping malls, eyewear stores, cosmetic stores, sport clubs, health institutes, fitness centers, airports, train stations, coffee shops, restaurants, hotels, homes, and the like. One or more of stations <b>110</b>, <b>160</b> and <b>170</b> may also be used for interactive billboard signs. For example, imaging device <b>130</b> may, for example, capture images which may be displayed on a billboard sign (not shown). System <b>100</b> may enable user <b>111</b> to choose an image to be displayed on the billboard sign out of a plurality of images of, for example, various previous trials of apparel.</p>
<p id="p-0042" num="0041">According to some demonstrative embodiments of the invention, images of user appearances may be viewed at different locations. For example, imaging device <b>130</b> may capture an image of the first trial. The image may then be sent from network interface <b>122</b> via network <b>150</b> using signals <b>151</b> and <b>152</b>, for example, to station <b>160</b>. Accordingly, user <b>111</b> may be able to view the image of the first user-appearance at station <b>160</b>. Therefore, user <b>111</b> may be able to view, for example, the user-appearance of the first trial in a first store of a retail store chain, e.g., a store associated with station <b>110</b>; and may compare the user-appearance of the first trial with a user-appearance of a second trial, which may take place at a second store of the same or an affiliated chain, e.g., a store associated with station <b>160</b>; and/or at a different time, e.g., one or more hours, days or weeks after the first trial.</p>
<p id="p-0043" num="0042">According to another demonstrative embodiment of the invention, imaging device <b>130</b> may capture an image of a user-appearance of a first trial, and send the image via network interface <b>122</b> over network <b>150</b> to control center <b>190</b>, where the image may be stored for later retrieval. Accordingly, user <b>111</b> may gain access to the images of the first trial by accessing any station, e.g., station <b>160</b>, connected over network <b>150</b> with control center <b>190</b>.</p>
<p id="p-0044" num="0043">According to some demonstrative embodiments of the invention, storage device <b>123</b> may include, for example, a hard disk drive, a floppy disk drive, a Compact Disk (CD) drive, a CD-ROM drive, a Digital Versatile Disc (DVD) drive, or other suitable removable or non-removable storage units.</p>
<p id="p-0045" num="0044">According to some demonstrative embodiments of the invention, controller <b>121</b> may be or may include, for example, a Central Processing Unit (CPU), a Digital Signal Processor (DSP), a microprocessor, a controller, a chip, a microchip, an Integrated Circuit (IC), or any other suitable multi-purpose or specific processor or controller, e.g., as are known in the art.</p>
<p id="p-0046" num="0045">Input device <b>124</b> may include, for example, a keyboard; a remote control; a motion sensor; a pointer device such as, for example, a laser pointer; a mouse; a touch-pad; a touch screen, which may be embedded, for example, in mirror-display device <b>140</b>, or may be implemented by any other suitable unit, e.g., separate from device <b>140</b>; a biometric input device, e.g., a fingerprint scanner, and/or a camera for scanning a face; and/or any other suitable pointing device or input device. Input device <b>124</b> may be adapted to receive user-identifying data, for example, to enable, access, e.g., secure access, of user <b>111</b> to system <b>100</b>, as described in detail below.</p>
<p id="p-0047" num="0046">According to some demonstrative embodiments of the invention, user <b>111</b> may provide user commands to input device <b>124</b> for operating the imaging device <b>130</b>. Input device <b>124</b> may include, for example, an interface to enable user <b>111</b> of system <b>100</b> to define operational parameters of imaging device <b>130</b>. Controller <b>121</b> may receive the inputs from user <b>111</b> via signals <b>131</b> and control the operation of imaging device <b>130</b> accordingly. The user commands may include, for example, commands relating to the timing for capturing an image, the positioning of imaging device <b>130</b>, e.g., according to an automatic tracking algorithm which may follow, for example, the position of user <b>111</b>, and/or imaging attributes such as focus, camera position, capturing angle, dynamic range and the like. The user commands may also include commands to define image capturing operating modes of imaging device <b>130</b> such as, for example, a video capturing mode, a photographic mode and the like. According to some embodiments of the invention, imaging device <b>130</b> may include a sound input device, for example, a microphone and/or a sound output device, for example, a loudspeaker. Accordingly, imaging device may receive audio signals, e.g., voice signals generated by user <b>111</b>, which may be recorded and stored, e.g., in storage device <b>123</b> and reproduce the audio signals through the sound output device. The sound output device may be able to reproduce any other kind of audio signals such as, radio programs, compact disc records and the like.</p>
<p id="p-0048" num="0047">According to some demonstrative embodiments of the invention, controller <b>121</b> may, for example, set the mode of operation of mirror-display device <b>140</b> according to the command received from user <b>111</b>. For example, if mirror-display device <b>140</b> operates in the mirror mode, the user of system <b>100</b> may provide input device with a switching command, e.g., by pressing a designated button at input device <b>124</b>, for switching mirror-display device <b>140</b> to the display mode. Controller <b>121</b> may receive the input from input device <b>124</b> and may control device <b>140</b> to switch to the display mode of operation, e.g., using signals <b>141</b>.</p>
<p id="p-0049" num="0048">According to some demonstrative embodiments of the invention, imaging device <b>130</b> may be mounted in various positions such as, for example, on top, below, or on the side of mirror-display device <b>140</b>, thereby capturing an image of a user-appearance which may be an image of a given trial of apparel, an image of user <b>111</b> with various articles, e.g., furniture and/or posing with different garments and the like. In some embodiments of the invention, imaging device <b>130</b> may capture a user-appearance as it appears in mirror-display device <b>140</b>, i.e., a mirror-image of the user-appearance. In other embodiments, imaging device <b>130</b> may capture the appearance, and controller <b>121</b> may generate a mirror-image corresponding to the appearance captured by imaging device <b>130</b>. For example, storage <b>123</b> may store instructions that when executed by controller may result in any suitable method or algorithm of rotating, reversing, and/or mirroring the appearance captured by imaging device <b>130</b>, thereby to generate image data representing rotated, reversed, and/or mirrored image of the image captured by device <b>130</b>. According to these embodiments, controller <b>121</b> may control mirror-display device <b>140</b> to display, during the display mode of operation, the rotated, reversed, and/or mirrored image. In other embodiments, controller <b>121</b> may control mirror-display device <b>140</b> to display, during the display mode of operation, an image corresponding to the image captured by device <b>130</b>, e.g., a non-mirrored, non-rotated, and/or non-reversed image. In some embodiments, imaging device <b>130</b> may not be visible to user <b>111</b>, may be located behind display device <b>140</b>, and/or may be embedded in mirror-display device <b>140</b>, which may be or may include, for example, a LCD-CCD device capable of both displaying and capturing images. For example, in one demonstrative embodiment of the invention, device <b>140</b> may include an array, screen or surface, e.g., including liquid crystals, to perform the mirror-display functionality, e.g., as described above, as well as the imaging functionality of imaging device <b>130</b>, e.g., device <b>140</b> may include a mirror-imaging-display device.</p>
<p id="p-0050" num="0049">In some demonstrative embodiments of the invention, one or more of stations <b>110</b>, <b>160</b> and/or <b>170</b> may not include image capturing device <b>130</b>; and/or one or more of stations <b>110</b>, <b>160</b> and/or <b>170</b> may not include mirror-display <b>140</b>. For example, a first station of system <b>100</b> may include only imaging device <b>130</b>, and may not include, e.g., mirror-display device <b>140</b>. User <b>111</b> may use the first station to capture the image of the first trial of the user-appearance, e.g., without being able to view at the first station the resultant image of the first trial. User <b>111</b> may later view the captured image of the first trial at another station of system <b>100</b>, which may include mirror-display device <b>140</b>.</p>
<p id="p-0051" num="0050">According to some demonstrative embodiments of the invention, imaging device <b>130</b> may be positioned in a manner enabling capturing of an image and/or a sequence of images, videos or the like, of a scene taking place in front of mirror-display device <b>140</b>. Additionally or alternatively, imaging device <b>130</b> may positioned in a manner enabling capturing an image reflected from mirror-display device <b>140</b>. For example, imaging device <b>130</b> may be able to capture an image of user <b>111</b> posing in front of mirror-display device <b>140</b>. While posing in front of mirror-display device <b>140</b>, user <b>111</b> may check his appearance of, e.g., a first fitting trial of clothes. According to an input provided by user <b>111</b> at input device <b>124</b>, imaging device <b>130</b> may capture the image of the user-appearance which may be, for example, a given trial of apparel, e.g., a garment and the like. It may be noted that trials by user <b>111</b> may also include user <b>111</b> engaging with various subjects, which may be located in the vicinity of user <b>111</b> such as, furniture, studio set-up and the like. Accordingly, imaging device <b>130</b> may capture images of user-appearances of, for example, a first trial, a second trial, etc., and may send the respective captured images to storage device <b>123</b> via signals <b>131</b> and signals <b>30</b>. User <b>111</b> may be able to retrieve the captured image of, e.g., the first trial, at a later time, e.g., following the second or other subsequent trials, and may compare between the first and second or other trial, e.g., as described below with reference to <figref idref="DRAWINGS">FIGS. 2A</figref>, <b>2</b>B and <b>2</b>C.</p>
<p id="p-0052" num="0051">According to some demonstrative embodiments of the invention, storage device <b>123</b> may be adapted to receive data representing images captured by imaging device <b>130</b>, and to store images of appearances and, more specifically, user-appearances of, for example, given trials of apparel, captured by imaging device <b>130</b>. Images of given trials of user-appearances may be retrieved from storage device <b>123</b>, e.g., by controller <b>121</b>, and displayed by display <b>140</b>. User <b>111</b> may compare between the displayed images, e.g., as described in detail below.</p>
<p id="p-0053" num="0052">According to some demonstrative embodiments of the invention, storage device <b>123</b> may include data representing, e.g., software algorithms, requiring and/or verifying user identifying data such as user-ID, password, login-time, bio-metric data and the like to enable secure access to station <b>110</b>, as described in detail below. For example, controller <b>121</b> may control mirror-display device <b>140</b> to display images corresponding to an identity of user <b>111</b>, e.g., based on the identity data provided by user <b>111</b>. For example, user <b>111</b> may provide input <b>124</b> with user-identifying input, which may include, for example, a biometric input such as face recognition, a hand print, a finger print, an eye print, voice recognition and the like. The user-identifying input may include any other suitable input, for example, a credit card, a personal identification number (PIN), a password, a smart card, a customer card, a club card, or the like. Controller <b>121</b> check, e.g., based on any suitable method and/or algorithm, whether the user-identifying input provided at input device <b>124</b> matches with user-identifying data which may be stored, e.g., in storage device <b>123</b> or in control center <b>190</b>. Software having the capability of verifying a biometric input may be, for example, &#x201c;Active ID FaceVision Technology&#x201d;&#xae; provided by Geometric Inc. If controller <b>121</b> matches the input of user <b>111</b> with the stored user-identifying data, controller <b>121</b> may enable user <b>111</b> to access data representing, for example, images of previous user-appearances of user <b>111</b>.</p>
<p id="p-0054" num="0053">According to some demonstrative embodiments of the invention, storage device <b>123</b> may include data representing, e.g., software algorithms enabling additional system features such as, for example, rendering virtual effects on mirror-display device <b>140</b>. For example, controller <b>121</b> may be able to render an image at mirror-display device <b>140</b> of user-appearances engaged and/or combined with virtual articles such as, for example, clothes, collections, headdresses, hair cuts, furniture and the like. In addition, controller <b>121</b> may be able to render an image at mirror-display device <b>140</b> of user-appearances having different body shapes for simulating, e.g., weight loss, weight gain of user <b>111</b> and the like. For example, user <b>111</b> may choose in a first trial a specific article, such as a suit out of a collection and controller <b>121</b> may virtually adjust the collection to an image of user <b>111</b> appearing in mirror-display device <b>140</b>. Controller <b>121</b> may store the image of the first trial in storage device <b>123</b> and may perform the same step at a second trial. Accordingly, user <b>111</b> of system <b>100</b> may be able to compare between user-appearances of the first and a second trials of the collection.</p>
<p id="p-0055" num="0054">According to some demonstrative embodiments of the invention, controller <b>121</b> may provide, for example, image and/or video browsing capabilities, image and/or video replay functions, which capabilities and functions may be predefined by system <b>100</b> or may be defined, e.g., on-the-fly, according to one or more user commands received from user <b>111</b> via input device <b>124</b>. For example, controller <b>121</b> may be able to retrieve one or more images of previous user-appearances and display the images on mirror-display device <b>140</b> at various sequences. For example, images from previous trials may be displayed in a substantially continuous forward, backwards, or mixed, e.g., randomly-accessible, sequence, and/or may be a stepwise sequence or in any other sequence. Furthermore, images from previous trials may be displayed simultaneously at mirror-display device <b>140</b>, e.g., as described below. Controller <b>121</b> may also be able to delete previously captured user-appearances, limit the amount of data which may be saved in storage device <b>123</b> and the like, and may further control a shape, size, color, etc., of the image displayed on mirror-display device <b>140</b>.</p>
<p id="p-0056" num="0055">According to some demonstrative embodiments of the invention, user <b>111</b> may use a portable storage device <b>180</b> able to store one or more of the captured images. The portable storage device may include any suitable portable storage device, e.g., a smartcard, a disk-on-key device, and the like. User <b>111</b> may download, for example, images represented by, .e.g., signals <b>50</b>, of a first trial of user-appearances from storage device <b>123</b>, e.g., via a storage interface <b>125</b> or via any other suitable data connection. User <b>111</b> may then upload at a later time the image of, e.g., the first trial, to another location, e.g., a home of user <b>111</b>, or another station of system <b>100</b>, e.g., station <b>170</b>.</p>
<p id="p-0057" num="0056">In some embodiments of the invention, station <b>110</b> may include more than one mirror-display device or may include a mirror-display device <b>140</b>, which may be partitioned simultaneously into two frames as described hereinafter with reference to <figref idref="DRAWINGS">FIGS. 2A and 2B</figref>.</p>
<p id="p-0058" num="0057">According to some demonstrative embodiments of the invention, controller <b>121</b> may record or store, e.g., in storage <b>123</b>, parameters characterizing user <b>111</b>. For example, system <b>100</b> may include a weighing machine, connected to, e.g., storage device <b>123</b> via controller <b>121</b>. Controller <b>121</b> may be able to record, for example, a weight of user <b>111</b> during, for example, a trial of an article. Accordingly, user <b>111</b> may later retrieve the parameter which may be, for example, the weight of user <b>111</b>.</p>
<p id="p-0059" num="0058">Reference is now made to <figref idref="DRAWINGS">FIGS. 2A and 2B</figref>, which schematically illustrate stages of comparing between appearances using an interactive system in accordance some demonstrative embodiments of the invention.</p>
<p id="p-0060" num="0059">According to some demonstrative embodiments of the invention, mirror-display device <b>140</b> may be partitioned into two frames, wherein one frame may operate as a mirror frame <b>192</b> and another frame <b>191</b> may operate selectably as a mirror and as a display frame. As shown in <figref idref="DRAWINGS">FIG. 2A</figref>, user <b>111</b> may pose in front of mirror frame <b>192</b> a first trial, which may be captured by imaging device <b>130</b> and stored in storage device <b>123</b>. Henceforward, as indicated in <figref idref="DRAWINGS">FIG. 2B</figref>, user <b>111</b> may view simultaneously in frame <b>191</b> the image of the user-appearance of the first trial and/or any other user-appearances, e.g., user-appearances stored in storage device <b>123</b> and/or received over network <b>150</b> (<figref idref="DRAWINGS">FIG. 1</figref>), side-by-side with the normal mirror appearance of a second trial in frame <b>192</b>, and compare between the first and the second trial.</p>
<p id="p-0061" num="0060">Reference is now made to <figref idref="DRAWINGS">FIGS. 3A</figref>, <b>3</b>B and <b>3</b>C, which schematically illustrate three, sequential, stages of comparing between appearances using an interactive system in accordance some demonstrative embodiments of the invention.</p>
<p id="p-0062" num="0061">As shown in <figref idref="DRAWINGS">FIG. 3A</figref>, the user of system <b>100</b> may view a first trial of a user-appearance in mirror-display device <b>140</b> operating in its mirror mode. Controller <b>121</b> may receive, e.g., from input device <b>124</b>, a user input, which may include a request to use imaging device <b>130</b> for capturing a first trial of the user-appearance. As a result, imaging device <b>130</b> may capture an image of the first trial of the user-appearance and storage device <b>123</b> may store the captured image.</p>
<p id="p-0063" num="0062">As shown in <figref idref="DRAWINGS">FIG. 3B</figref>, user <b>111</b> may view a second trial of his user-appearance in mirror-display device <b>140</b>, which may operate in the mirror mode of operation. Then, when user <b>111</b> desires to view a previous appearance, e.g., for comparison, controller <b>121</b> may receive a user input via input device <b>124</b> requesting to view the first trial. At this point, as shown in <figref idref="DRAWINGS">FIG. 3C</figref>, controller <b>121</b> may change the operational mode of mirror-display device <b>140</b> to the display mode using signals <b>141</b>. Controller <b>121</b> may also control device <b>140</b> to display the first trial. Therefore, by switching between operating modes of mirror-display device <b>140</b>, user <b>111</b> may compare the user-appearance of the second trial with the user-appearance of the first trial and/or any other user-appearances previously stored in storage device <b>123</b>.</p>
<p id="p-0064" num="0063">Reference is now made to <figref idref="DRAWINGS">FIG. 4</figref>, which schematically illustrates a flow-chart of a method enabling comparing between one or more various appearances in accordance with some demonstrative embodiments of the invention. Although the invention is not limited in this respect, one or more operations of the method of <figref idref="DRAWINGS">FIG. 4</figref> may be performed by one or more elements of system <b>100</b> (<figref idref="DRAWINGS">FIG. 1</figref>).</p>
<p id="p-0065" num="0064">As indicated at block <b>410</b>, the method may include, for example, setting the operating mode of a mirror-display device. For example, user <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may initially set the operating mode of mirror-display device <b>140</b> (<figref idref="DRAWINGS">FIG. 1</figref>) to the mirror mode. Alternatively, display <b>140</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may be designed to operate in the mirror mode by default whenever a new user logs into system <b>100</b> (<figref idref="DRAWINGS">FIG. 1</figref>).</p>
<p id="p-0066" num="0065">As indicated at block <b>420</b>, the method may also include, for example, posing in front of the mirror-display device. For example, user <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may pose in front of mirror-display device <b>140</b> (<figref idref="DRAWINGS">FIG. 1</figref>) and check the user-appearance of a first trial of e.g., clothing, shoes and/or any other apparel.</p>
<p id="p-0067" num="0066">As indicated at block <b>430</b>, the method may also include, for example, capturing an image of the user-appearance of the first trial. For example, user <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may provide user command to device <b>120</b> (<figref idref="DRAWINGS">FIG. 1</figref>) commanding imaging device <b>130</b> (<figref idref="DRAWINGS">FIG. 1</figref>) to capture an image of the user-appearance of the first trial.</p>
<p id="p-0068" num="0067">As indicated at block <b>440</b>, the method may also include, for example, posing in front of the mirror-display device in a different user-appearance. For example, user <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may change one or more items of environment such as, for example, furniture and/or apparel, pose once again in front of mirror-display device <b>140</b> which may operate in mirror mode, and view a second user-appearance.</p>
<p id="p-0069" num="0068">As indicated at block <b>450</b>, the method may also include, for example, switching between operating modes of the mirror-display device. For example, user <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may switch mirror-display device <b>140</b> (<figref idref="DRAWINGS">FIG. 1</figref>) between the mirror and the display mode. Accordingly, user <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may be able to compare between the user-appearance of the first trial, and/or any other user-appearances, e.g., user-appearances stored in storage device <b>123</b> and/or received over network <b>150</b> (<figref idref="DRAWINGS">FIG. 1</figref>), and the user-appearance of the second trial.</p>
<p id="p-0070" num="0069">According to some demonstrative embodiments of the invention, user <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may indicate, and/or station <b>110</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may be able to store, e.g., automatically, for each trial parameters, e.g., including shopping parameters, such as, for example, name of store, address of store, price, time and/or date of trial of apparel, name of salesperson, and the like. User <b>111</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may, for example, store the captured images of user-appearances in a removable or portable storage device, e.g., as described above with reference to <figref idref="DRAWINGS">FIG. 1</figref>, and may later review images of user-appearances while being able to ascribe every image to, e.g., a specific store and the like. In addition, user <b>111</b> may define, and/or controller <b>121</b> (<figref idref="DRAWINGS">FIG. 1</figref>) may be able to generate, and/or store in storage device <b>123</b> reminders, for example, alarms about, e.g., discounts, end of season sales and the like.</p>
<p id="p-0071" num="0070">While certain features of the invention have been illustrated and described herein, many modifications, substitutions, changes, and equivalents may occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the true spirit of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system to enable appearance comparison, the system comprising:
<claim-text>at least one interactive imaging and display station connected to a network, the station comprising:
<claim-text>a mirror-display device capable of selectably operating in mirror mode, a display mode, or both a mirror and a display mode;</claim-text>
<claim-text>an imaging device to capture video of one or more appearances from a field-of-view in front of said mirror-display device;</claim-text>
<claim-text>a storage device to store the video; and</claim-text>
<claim-text>an image control unit to select the mode of operation of said mirror-display device according to a user command, and to display a mirrored image of the video retrieved from the storage device.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image control unit includes an input device to receive said user command from a user.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image control unit includes an interface for downloading the video to a mobile storage device.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said mirror-display device is capable of being partitioned into at least first and second simultaneously-displayable frames, the first frame selectably operable both in a mirror mode and a display mode, and the second frame operable in a mirror mode.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said imaging device is capable of capturing three-dimensional images of said appearances.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said mirror-display device is capable of displaying images of appearances at predefined sequences.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image control unit is able to selectively enable a user to access images of appearances authorized to said user, based on user-identifying input received from said user.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said at least one interactive imaging and display station comprises two or more interactive imaging and display stations able to communicate over the network.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said two or more stations are able to communicate between each other data representing images of appearances.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said mirror-display device is embedded in a semi-reflective mirror.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mirror-display device comprises a high definition television.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A method to enable appearance comparison, the method comprising:
<claim-text>providing a mirror-display device capable of being selectably operated in either a mirror mode or a display mode;</claim-text>
<claim-text>capturing a video from a field-of-view in front of said mirror-display device;</claim-text>
<claim-text>storing said video;</claim-text>
<claim-text>selecting the display mode of operation of said mirror-display device;</claim-text>
<claim-text>retrieving said video and displaying a mirrored image of the video on said mirror-display device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising sending the video via a network interface to a control center.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising downloading the video onto a portable storage device.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising downloading discounts onto the portable storage device.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising verifying a user using face recognition.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising rendering virtual effects on the mirror-display device.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said imaging device comprises a camera for scanning a face and performing face recognition.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a biometric input device.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said imaging device comprises a stereoscopic camera. </claim-text>
</claim>
</claims>
</us-patent-grant>
