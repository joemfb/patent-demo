<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626502-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626502</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13648845</doc-number>
<date>20121010</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>L</subclass>
<main-group>21</main-group>
<subgroup>02</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>704226</main-classification>
<further-classification>704228</further-classification>
<further-classification>381 711</further-classification>
<further-classification>381 941</further-classification>
</classification-national>
<invention-title id="d2e43">Improving speech intelligibility utilizing an articulation index</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4475230</doc-number>
<kind>A</kind>
<name>Fukuyama et al.</name>
<date>19841000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381321</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5125030</doc-number>
<kind>A</kind>
<name>Nomura et al.</name>
<date>19920600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704222</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5729658</doc-number>
<kind>A</kind>
<name>Hou et al.</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704270</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6108415</doc-number>
<kind>A</kind>
<name>Andrea</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37943303</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6317613</doc-number>
<kind>B1</kind>
<name>Brown, Jr.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455570</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6912289</doc-number>
<kind>B2</kind>
<name>Vonlanthen et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381312</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7379866</doc-number>
<kind>B2</kind>
<name>Gao</name>
<date>20080500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704220</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7660716</doc-number>
<kind>B1</kind>
<name>Cohen et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704249</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7716046</doc-number>
<kind>B2</kind>
<name>Nongpiur et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>8015002</doc-number>
<kind>B2</kind>
<name>Li et al.</name>
<date>20110900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>8046218</doc-number>
<kind>B2</kind>
<name>Allen et al.</name>
<date>20111000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704233</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>8150682</doc-number>
<kind>B2</kind>
<name>Nongpiur et al.</name>
<date>20120400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704207</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>8296136</doc-number>
<kind>B2</kind>
<name>Nongpiur</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704228</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>8306821</doc-number>
<kind>B2</kind>
<name>Nongpiur et al.</name>
<date>20121100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704268</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>8326616</doc-number>
<kind>B2</kind>
<name>Li et al.</name>
<date>20121200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2004/0071284</doc-number>
<kind>A1</kind>
<name>Abutalebi et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37940608</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2005/0078842</doc-number>
<kind>A1</kind>
<name>Vonlanthen et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381312</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2005/0114127</doc-number>
<kind>A1</kind>
<name>Rankovic</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704233</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2006/0116874</doc-number>
<kind>A1</kind>
<name>Samuelsson et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704228</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2009/0304187</doc-number>
<kind>A1</kind>
<name>Dittberner</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381 231</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>D M Rasetshwane, &#x201c;Use of the Articulation Index to Design a Wavelet Packet-Based Method for Improving Speech Intelligibility&#x201d;, 15th International Conference on Digital Signal Processing, 2007, Jul. 1-4, 2007, pp. 643 to 646.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>704205</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704208</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704214</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704226</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704228</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 942</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 943</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 711</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 941</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11940920</doc-number>
<date>20071115</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8296136</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13648845</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130035934</doc-number>
<kind>A1</kind>
<date>20130207</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>QNX Software Systems Limited</orgname>
<address>
<city>Kanata</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Nongpiur</last-name>
<first-name>Rajeev</first-name>
<address>
<city>Vancouver</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Brinks Gilson &#x26; Lione</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>QNX Software Systems Limited</orgname>
<role>03</role>
<address>
<city>Kanata, Ontario</city>
<country>CA</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lerner</last-name>
<first-name>Martin</first-name>
<department>2657</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Background noise is modeled from an input signal comprising a desired signal and a plurality of undesired signals. At least one of the signals that comprise the input is processed to generate a signal-to-noise ratio. An articulation index is generated for the at least one of the signals that is processed. A spectrum of a speech segment is generated to improve intelligibility and quality of the speech segment based on the articulation index. A shaping logic may adjust the spectrum of the speech segment based on a comparison of the articulation index to a plurality of predetermined thresholds. Modeling of the background noise comprises modeling a tilt of the background noise.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="68.33mm" wi="158.75mm" file="US08626502-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="220.47mm" wi="137.08mm" orientation="landscape" file="US08626502-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="193.04mm" wi="146.81mm" orientation="landscape" file="US08626502-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="152.48mm" wi="130.81mm" orientation="landscape" file="US08626502-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="145.80mm" wi="74.93mm" orientation="landscape" file="US08626502-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="146.73mm" wi="86.02mm" orientation="landscape" file="US08626502-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="145.29mm" wi="94.32mm" orientation="landscape" file="US08626502-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="145.80mm" wi="76.54mm" orientation="landscape" file="US08626502-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="219.37mm" wi="159.51mm" orientation="landscape" file="US08626502-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="233.93mm" wi="121.33mm" orientation="landscape" file="US08626502-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="141.22mm" wi="99.40mm" orientation="landscape" file="US08626502-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="141.56mm" wi="100.92mm" orientation="landscape" file="US08626502-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">PRIORITY CLAIM</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 11/940,920, filed on Nov. 15, 2007, now U.S. Pat. No. 8,296,136 issued 23 Oct. 2012, the entire disclosure of which is hereby incorporated by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">TECHNICAL FIELD</heading>
<p id="p-0003" num="0002">This disclosure relates to speech enhancement, and more particularly to enhancing speech delivered through a hands-free interface.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">Speech enhancement in a vehicle is a challenge. Some systems are susceptible to interference. Interference may come from many sources including engines, fans, road noise, and rain. Reverberation and echo may further interfere, especially in hands-free systems.</p>
<p id="p-0005" num="0004">When used in a vehicle, a microphone may be positioned within an interior to receive sound from a driver or a passenger. When positioned away from a speaker, the desired signal strength received by the microphone decreases. As the distance increases the signal becomes more susceptible to noise and distortion.</p>
<p id="p-0006" num="0005">When focusing on cost, a vehicle manufacturer may limit the number of microphones used in cars and limit the processing power of the devices that process their output. A manufacturer's desire to keep costs down may reduce the quality and intelligibility to a point that is much lower than their customers' expectations. There is room for improvement for a speech enhancement system, especially in vehicle interiors. There is a need for a system that is sensitive, accurate, has minimal latency, and enhances speech at a low computational cost.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0007" num="0006">A system improves the speech intelligibility and the speech quality of a signal. The system includes a dynamic controller that detects a background noise from an input by modeling a portion of a background noise signal. A variable gain amplifier adjusts the variable gain of the amplifier in response to an output of a dynamic controller. A shaping filter adjusts the spectral shape of the speech signal by tilting portions of the speech signal in response to the dynamic controller.</p>
<p id="p-0008" num="0007">Other systems, methods, features, and advantages will be, or will become, apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems, methods, features and advantages be included within this description, be within the scope of the invention, and be protected by the following claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0009" num="0008">The system may be better understood with reference to the following drawings and description. The components in the figures are not necessarily to scale, emphasis instead being placed upon illustrating the principles of the invention. Moreover, in the figures, like referenced numerals designate corresponding parts throughout the different views.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 1</figref> is a dynamic controller in communication with a hands-free interface.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 2</figref> is the dynamic controller of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 3</figref> is an exemplary filter response.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 4</figref> is an exemplary filter response that may maximize speech intelligibility.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 5</figref> is an exemplary shape of a linear approximation of a background noise.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 6</figref> is an exemplary shape of the inverse spectrum of <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 7</figref> is an exemplary desired filter response.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 8</figref> are exemplary dynamic responses of a shaping filter.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 9</figref> is an exemplary method that improves speech intelligibility and speech quality.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 10</figref> is a hands-free-device or communication system or audio system in communication with a speech enhancement logic.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 11</figref> is a vehicle having a dynamic controller in communication with a speech enhancement logic.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0021" num="0020">Hands-free systems and phones in vehicles are susceptible to noisy environments. The spatial, linear, and non-linear properties of noise may suppress or distort speech. A speech enhancement system improves speech quality and intelligibility by dynamically controlling the gain and spectral shape of a speech signal. The speech enhancement system estimates a spectral signal-to-noise ratio (SNR) of a received speech signal. The system derives an index used to adjust spectral shapes and/or signal amplitudes. A dynamic spectral-shaping filter may adjust the spectral shape on the basis of the estimated tilt of the background noise spectrum and the derived index. Various spectral shapes may be realized by a processor or a controller that models a combination of filter responses. The system requires low computational power, improves intelligibility in real-time, and has a low processing latency.</p>
<p id="p-0022" num="0021">A dynamic controller <b>102</b> in communication with a hands-free system <b>100</b> is shown in <figref idref="DRAWINGS">FIG. 1</figref>. The dynamic controller <b>102</b> receives a receive-side signal after it is processed by an automatic gain control <b>104</b> x(n). The dynamic controller <b>102</b> also receives the receive-side signal after gain adjustment and spectral shaping, x<sub>dc</sub>(n), and receives a send-side signal, y(n). In <figref idref="DRAWINGS">FIG. 1</figref> the receive-side signal comprises one or more signals that that pass through some or all of the processing circuits or logic that are in communication with a loudspeaker <b>112</b>. The send-side signal comprises the signal or signals received at an input device <b>114</b> that may convert the send-side audio signals into analog or digital operating signals.</p>
<p id="p-0023" num="0022">To compensate for varying audio levels, an automatic gain control <b>104</b> regulates the gain through an internal amplifier. By boosting or lowering the gain of the incoming receive-side signal, the automatic gain control <b>104</b> may maintain a maximum value of a speech segment at a predetermined level. The automatic gain control <b>104</b> may maintain a maximum absolute value of the receive-side signal within a desired range. The upper limit of the range may allow the signal to be further amplified without introducing distortion or clipping content.</p>
<p id="p-0024" num="0023">The gain of the amplified signal may be further adjusted by a second amplifier <b>106</b>. Portions of the frequency spectrum of that signal may then be enhanced or suppressed by a shaping filter <b>108</b> or dynamic filter. The signal may then pass through unknown logic or circuits <b>110</b>. In some systems, the unknown logic or circuits <b>110</b> may comprise an audio amplifier that has a variable or a static transfer function.</p>
<p id="p-0025" num="0024">A send-side signal y(n) is captured by the input device <b>114</b>. The send-side signal y(n) may comprise a converted speech segment received from near-end speaker, s(n) and background noise &#x3b7;(n) heard or detected in an enclosure (e.g., within an interior of a vehicle, for example). When the receive-side signal is converted into sound, the send-side signal y(n) may also include a receive-side speech segment (or far-end speech), x<sub>m</sub>(n).</p>
<p id="p-0026" num="0025">The dynamic controller <b>102</b> may estimate the gain of the second amplifier <b>106</b> and the desired filter response of the shaping filter <b>108</b> by processing multiple incoming signals. The incoming signals may include the automatic-gain-controlled receive side signal x(n), the gain-adjusted and spectrum-modified receive-side signal x<sub>dc</sub>(n), and the send-side signal, y(n). A spectral estimator <b>202</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> estimates the spectral signal-to-noise ratio (SNR) of a far-end signal segment x<sub>m</sub>(n) by processing an output of a voice activity detector <b>204</b>, a coherence estimator <b>206</b>, and the send-side signal, y(n). The voice activity detector <b>204</b> determines if a segment of the send-side signal, y(n), represents voiced, unvoiced, or a silent segment. Voice sounds may be periodic in nature and may contain more energy than unvoiced sounds. Unvoiced sounds may be more noise-like and may have more energy than silence. Silence may have the lowest energy and may represent the energy detected in the background noise. In <figref idref="DRAWINGS">FIG. 2</figref>, the background noise may be identified by a separate background noise estimator circuit or logic <b>208</b>.</p>
<p id="p-0027" num="0026">The spectral energy of x<sub>m</sub>(n) may be determined by isolating the speech portions in y(n) that corresponds to the far-end signal segment x<sub>m</sub>(n). The voice activity detector <b>204</b> may identify speech endpoints that identify speech portions in the send-side signal y(n). A coherence estimator <b>206</b> may estimate the spectral coherence between the amplified receive side signal x(n) and the send-side signal, y(n). The spectral coherence may be a parameter that quantifies the quality of interference between the amplified receive-side signal x(n) and the send-side signal, y(n). The degree of coherence may measure how perfectly the receive side signal x(n) and the send-side signal, y(n) may cancel depending on the relative phase between them. A high coherence value may indicate the presence of the modified received side signal x<sub>m</sub>(n).</p>
<p id="p-0028" num="0027">To compensate for the variability in coherence that occurs when the background noise changes, the coherence estimator <b>206</b> may normalize the coherence values with respect to the background noise spectrum in some systems. To ensure more reliability, the maximum and minimum delay lags between the amplified receive side signal x(n) and the far-end signal segment x<sub>m</sub>(n) for a particular enclosure or vehicle may be determined and the coherence value estimated within delay lags. Delay-lag values may be determined from an echo canceller or a residual-echo suppressor when used.</p>
<p id="p-0029" num="0028">Using the signal-to-noise ratio (SNR) of the far-end signal segment x<sub>m</sub>(n), an articulation estimator <b>210</b> may measure the intelligibility of the modified received side signal x<sub>m</sub>(n). The signal may be divided into frequency bands, which are given weights based on predetermined contributions to intelligibility. The articulation index may comprise a linear measure that ranges between about 0 and about 1 (where 1 corresponds to the upper limit of intelligibility). An exemplary application may break up the spectral signal-to-noise ratio (SNR) of a far-end signal segment x<sub>m</sub>(n) into five octave bands that may have center frequencies occurring at about 0.25, about 0.5, about 1, about 2, and about 4 kHz.</p>
<p id="p-0030" num="0029">If &#x3c3;<sub>xm</sub>(i) [dB] is an A-weighted average signal-to-noise ratio (SNR) of the far-end signal segment x<sub>m</sub>(n) in octave band i, the articulation index (AI) of the far-end signal segment x<sub>m</sub>(n) may given by equation 1.</p>
<p id="p-0031" num="0030">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>AI</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <msub>
              <mi>x</mi>
              <mi>m</mi>
            </msub>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <mn>30</mn>
          </mfrac>
          <mo>&#x2062;</mo>
          <mrow>
            <munderover>
              <mo>&#x2211;</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mn>5</mn>
            </munderover>
            <mo>&#x2062;</mo>
            <mrow>
              <msub>
                <mi>w</mi>
                <mi>i</mi>
              </msub>
              <mo>&#x2062;</mo>
              <mrow>
                <mrow>
                  <msub>
                    <mover>
                      <mi>&#x3c3;</mi>
                      <mo>^</mo>
                    </mover>
                    <mi>xm</mi>
                  </msub>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>i</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&#x2061;</mo>
                <mrow>
                  <mo>[</mo>
                  <mi>dB</mi>
                  <mo>]</mo>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where &#x3c3;<sub>xm</sub>(i) [dB] is the clipped A-weighted signal-to-noise ratio (SNR) given by equation 2,
</p>
<p id="p-0032" num="0031">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mrow>
            <msub>
              <mover>
                <mi>&#x3c3;</mi>
                <mo>^</mo>
              </mover>
              <mi>xm</mi>
            </msub>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mi>i</mi>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>[</mo>
            <mi>dB</mi>
            <mo>]</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mo>{</mo>
          <mtable>
            <mtr>
              <mtd>
                <mn>18</mn>
              </mtd>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>if</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mrow>
                      <mrow>
                        <msub>
                          <mi>&#x3c3;</mi>
                          <mi>xm</mi>
                        </msub>
                        <mo>&#x2061;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mi>i</mi>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>&#x2061;</mo>
                      <mrow>
                        <mo>[</mo>
                        <mi>dB</mi>
                        <mo>]</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>&#x2265;</mo>
                  <mn>18</mn>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mo>-</mo>
                  <mn>12</mn>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>if</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mrow>
                      <mrow>
                        <msub>
                          <mi>&#x3c3;</mi>
                          <mi>xm</mi>
                        </msub>
                        <mo>&#x2061;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mi>i</mi>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>&#x2061;</mo>
                      <mrow>
                        <mo>[</mo>
                        <mi>dB</mi>
                        <mo>]</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>&#x2265;</mo>
                  <mrow>
                    <mo>-</mo>
                    <mn>12</mn>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <msub>
                    <mi>&#x3c3;</mi>
                    <mi>xm</mi>
                  </msub>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>i</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mtd>
              <mtd>
                <mi>otherwise</mi>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>2</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
and w<sub>i </sub>is the weight given to octave band i, according to exemplary Table 1.
</p>
<p id="p-0033" num="0032">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE I</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>WEIGHING FACTORS FOR EACH OCTAVE BAND</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="77pt" align="center"/>
<colspec colname="2" colwidth="56pt" align="center"/>
<colspec colname="3" colwidth="84pt" align="center"/>
<tbody valign="top">
<row>
<entry>Octave Bands</entry>
<entry>Centre Frequency</entry>
<entry>Weighing Factor</entry>
</row>
<row>
<entry>(i)</entry>
<entry>(Hz)</entry>
<entry>(w<sub>i</sub>)</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="77pt" align="center"/>
<colspec colname="2" colwidth="56pt" align="char" char="."/>
<colspec colname="3" colwidth="84pt" align="center"/>
<tbody valign="top">
<row>
<entry>1</entry>
<entry>250</entry>
<entry>0.072</entry>
</row>
<row>
<entry>2</entry>
<entry>500</entry>
<entry>0.144</entry>
</row>
<row>
<entry>3</entry>
<entry>1000</entry>
<entry>0.222</entry>
</row>
<row>
<entry>4</entry>
<entry>2000</entry>
<entry>0.327</entry>
</row>
<row>
<entry>5</entry>
<entry>4000</entry>
<entry>0.234</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0034" num="0033">To estimate the gain factor for the far-end signal segment x<sub>m</sub>(n), multiple inputs may be processed by gain estimator <b>212</b>. The articulation index (AI) of the far-end signal segment x<sub>m</sub>(n) and the estimated maximum value of the amplified and adaptively filtered receive-side signal x<sub>dc</sub>(n) are processed. An estimator <b>214</b> may estimate a maximum value of the amplified and adaptively filtered receive-side signal x<sub>dc</sub>(n) designated &#x3bb;<sub>xdc</sub>, by equation 3.</p>
<p id="p-0035" num="0034">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>&#x3bb;</mi>
          <mi>xdc</mi>
        </msub>
        <mo>=</mo>
        <mrow>
          <munder>
            <mi>max</mi>
            <mi>i</mi>
          </munder>
          <mo>&#x2062;</mo>
          <mrow>
            <mo>&#xf603;</mo>
            <mrow>
              <msub>
                <mi>Speech</mi>
                <mi>xdc</mi>
              </msub>
              <mo>&#x2061;</mo>
              <mrow>
                <mo>(</mo>
                <mi>i</mi>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>&#xf604;</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where Speech<sub>xdc</sub>(i) is the i element of a vector that holds the last M samples of detected speech portions in x<sub>dc</sub>(n). The parameter &#x3bb;<sub>xdc </sub>may be constantly adjusted in real-time or after a delay (that may depend on the application) so that it lies between certain maximum and minimum values. For example, if &#x3bb;<sub>xdc </sub>falls below a certain minimum threshold, &#x3b3;<sub>min</sub>, such as between about 0 and about 0.3 the gain of the amplifier <b>106</b> may be gradually increased. If &#x3bb;<sub>xdc </sub>rises above a certain maximum threshold, &#x3b3;<sub>max</sub>, such as about 0.7, the gain of amplifier <b>106</b> may be reduced.
</p>
<p id="p-0036" num="0035">When &#x3bb;<sub>xdc </sub>lies between &#x3b3;<sub>min </sub>and &#x3b3;<sub>max</sub>, the gain estimator may process the output of the articulation estimator <b>210</b>. When articulation index (AI) is greater than a certain maximum threshold, t<sub>max</sub>, the intelligibility may be assumed to be very good and the gain factor of amplifier <b>106</b> may be reduced by &#x3b4;<sub>fall </sub>dB. When the articulation index (AI) is less than a predetermined minimum threshold t<sub>min</sub>, the intelligibility may be low and the gain factor of amplifier <b>106</b> may be increased by &#x3b4;<sub>rise </sub>dB. When the articulation index (AI) lies between about t<sub>min </sub>and about t<sub>max</sub>, the gain factor of amplifier <b>106</b> may not change. The gain factor, G, may be expressed by equation 4.</p>
<p id="p-0037" num="0036">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>G</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>[</mo>
            <mi>dB</mi>
            <mo>]</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mi>G</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>[</mo>
              <mi>dB</mi>
              <mo>]</mo>
            </mrow>
          </mrow>
          <mo>+</mo>
          <mrow>
            <mo>{</mo>
            <mrow>
              <mtable>
                <mtr>
                  <mtd>
                    <msub>
                      <mi>&#x3b2;</mi>
                      <mi>rise</mi>
                    </msub>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mrow>
                        <mi>if</mi>
                        <mo>&#x2062;</mo>
                        <mstyle>
                          <mspace width="0.8em" height="0.8ex"/>
                        </mstyle>
                        <mo>&#x2062;</mo>
                        <msub>
                          <mi>&#x3bb;</mi>
                          <mi>xdc</mi>
                        </msub>
                      </mrow>
                      <mo>&#x2264;</mo>
                      <msub>
                        <mi>&#x393;</mi>
                        <mi>min</mi>
                      </msub>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mrow>
                      <mo>-</mo>
                      <msub>
                        <mi>&#x3b2;</mi>
                        <mi>fall</mi>
                      </msub>
                    </mrow>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mrow>
                        <mi>if</mi>
                        <mo>&#x2062;</mo>
                        <mstyle>
                          <mspace width="0.8em" height="0.8ex"/>
                        </mstyle>
                        <mo>&#x2062;</mo>
                        <msub>
                          <mi>&#x3bb;</mi>
                          <mi>xdc</mi>
                        </msub>
                      </mrow>
                      <mo>&#x2265;</mo>
                      <msub>
                        <mi>&#x393;</mi>
                        <mi>max</mi>
                      </msub>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mi>&#x3b3;</mi>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mi>if</mi>
                      <mo>&#x2062;</mo>
                      <mstyle>
                        <mspace width="0.8em" height="0.8ex"/>
                      </mstyle>
                      <mo>&#x2062;</mo>
                      <mi>otherwise</mi>
                    </mrow>
                  </mtd>
                </mtr>
              </mtable>
              <mo>&#x2062;</mo>
              <mstyle>
                <mtext>
</mtext>
              </mstyle>
              <mo>&#x2062;</mo>
              <mi>where</mi>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>&#x3b3;</mi>
        <mo>=</mo>
        <mrow>
          <mo>{</mo>
          <mrow>
            <mrow>
              <mrow>
                <mtable>
                  <mtr>
                    <mtd>
                      <msub>
                        <mi>&#x3b4;</mi>
                        <mi>rise</mi>
                      </msub>
                    </mtd>
                    <mtd>
                      <mrow>
                        <mrow>
                          <mi>if</mi>
                          <mo>&#x2062;</mo>
                          <mstyle>
                            <mspace width="0.8em" height="0.8ex"/>
                          </mstyle>
                          <mo>&#x2062;</mo>
                          <mrow>
                            <mi>AI</mi>
                            <mo>&#x2061;</mo>
                            <mrow>
                              <mo>(</mo>
                              <mrow>
                                <msub>
                                  <mi>x</mi>
                                  <mi>m</mi>
                                </msub>
                                <mo>&#x2061;</mo>
                                <mrow>
                                  <mo>(</mo>
                                  <mi>n</mi>
                                  <mo>)</mo>
                                </mrow>
                              </mrow>
                              <mo>)</mo>
                            </mrow>
                          </mrow>
                        </mrow>
                        <mo>&#x2264;</mo>
                        <msub>
                          <mi>t</mi>
                          <mi>min</mi>
                        </msub>
                      </mrow>
                    </mtd>
                  </mtr>
                  <mtr>
                    <mtd>
                      <mrow>
                        <mo>-</mo>
                        <msub>
                          <mi>&#x3b4;</mi>
                          <mi>fall</mi>
                        </msub>
                      </mrow>
                    </mtd>
                    <mtd>
                      <mrow>
                        <mrow>
                          <mi>if</mi>
                          <mo>&#x2062;</mo>
                          <mstyle>
                            <mspace width="0.8em" height="0.8ex"/>
                          </mstyle>
                          <mo>&#x2062;</mo>
                          <mrow>
                            <mi>AI</mi>
                            <mo>&#x2061;</mo>
                            <mrow>
                              <mo>(</mo>
                              <mrow>
                                <msub>
                                  <mi>x</mi>
                                  <mi>m</mi>
                                </msub>
                                <mo>&#x2061;</mo>
                                <mrow>
                                  <mo>(</mo>
                                  <mi>n</mi>
                                  <mo>)</mo>
                                </mrow>
                              </mrow>
                              <mo>)</mo>
                            </mrow>
                          </mrow>
                        </mrow>
                        <mo>&#x2265;</mo>
                        <msub>
                          <mi>t</mi>
                          <mi>max</mi>
                        </msub>
                      </mrow>
                    </mtd>
                  </mtr>
                  <mtr>
                    <mtd>
                      <mn>0</mn>
                    </mtd>
                    <mtd>
                      <mi>otherwise</mi>
                    </mtd>
                  </mtr>
                </mtable>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mtext>
</mtext>
                </mstyle>
                <mo>&#x2062;</mo>
                <mn>0</mn>
              </mrow>
              <mo>&#x3c;</mo>
              <msub>
                <mi>t</mi>
                <mi>min</mi>
              </msub>
              <mo>&#x3c;</mo>
              <msub>
                <mi>t</mi>
                <mi>max</mi>
              </msub>
              <mo>&#x3c;</mo>
              <mi>.7</mi>
            </mrow>
            <mo>,</mo>
            <mrow>
              <mrow>
                <mi>and</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.8em" height="0.8ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msub>
                  <mi>&#x393;</mi>
                  <mi>min</mi>
                </msub>
              </mrow>
              <mo>&#x3c;</mo>
              <msub>
                <mi>&#x393;</mi>
                <mi>max</mi>
              </msub>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>5</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0038" num="0037">When the shaping filter <b>108</b> comprises a Finite Impulse Response (FIR) filter, the filter coefficients may be estimated on the basis of the articulation index (AI) of the far-end signal segment x<sub>m</sub>(n) and the background noise spectrum of &#x3b7;(n). In some applications, the filter coefficients are selected so that they maximize the intelligibility of speech without increasing the overall energy of the signal. If the intelligibility is sufficiently high, the coefficients may be programmed to improve speech quality.</p>
<p id="p-0039" num="0038">To select the filter coefficients, the articulation index (AI) of the far-end signal segment x<sub>m</sub>(n) may be processed by the filter coefficient estimator <b>216</b> to determine if it is high or close to 1. If the speech intelligibility is sufficiently high, the dynamic controller <b>102</b> may adjust the filter coefficients of the shaping filter <b>108</b> so that the tilt of the response approximates an estimated tilt of the background noise spectrum. An alternative system may normalize the speech spectrum so that the average long-term speech spectrum matches the standard speech-spectrum.</p>
<p id="p-0040" num="0039">When the articulation index (AI) of the far-end signal segment x<sub>m</sub>(n) is small or close to about 0, the dynamic controller <b>102</b> may improve speech intelligibility through constrained optimization logic and the optimization hardware programmed to optimize equation 6.</p>
<p id="p-0041" num="0040">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <munder>
            <mi>max</mi>
            <mi>h</mi>
          </munder>
          <mo>&#x2062;</mo>
          <mrow>
            <mi>AI</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <msub>
                    <mi>x</mi>
                    <mi>m</mi>
                  </msub>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>n</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>*</mo>
                <mrow>
                  <mi>h</mi>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>n</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
        <mo>&#x2062;</mo>
        <mstyle>
          <mtext>
</mtext>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mrow>
            <mi>subject</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>to</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mtext>:</mtext>
            </mstyle>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mrow>
              <mi>E</mi>
              <mo>&#x2061;</mo>
              <mrow>
                <mo>[</mo>
                <msup>
                  <mrow>
                    <mo>&#xf603;</mo>
                    <mrow>
                      <mrow>
                        <msub>
                          <mi>x</mi>
                          <mi>m</mi>
                        </msub>
                        <mo>&#x2061;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mi>n</mi>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>*</mo>
                      <mrow>
                        <mi>h</mi>
                        <mo>&#x2061;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mi>n</mi>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mrow>
                    <mo>&#xf604;</mo>
                  </mrow>
                  <mn>2</mn>
                </msup>
                <mo>]</mo>
              </mrow>
            </mrow>
          </mrow>
          <mo>=</mo>
          <mrow>
            <mi>E</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>[</mo>
              <msup>
                <mrow>
                  <mo>&#xf603;</mo>
                  <mrow>
                    <msub>
                      <mi>x</mi>
                      <mi>m</mi>
                    </msub>
                    <mo>&#x2061;</mo>
                    <mrow>
                      <mo>(</mo>
                      <mi>n</mi>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>&#xf604;</mo>
                </mrow>
                <mn>2</mn>
              </msup>
              <mo>]</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>6</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where * denotes convolution, h(n) is the impulse response of the shaping filter, and h is a vector of the impulse response and given by matrix <b>7</b>.
</p>
<p id="p-0042" num="0041">
<maths id="MATH-US-00006" num="00006">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>h</mi>
        <mo>=</mo>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mi>h</mi>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mn>0</mn>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mi>h</mi>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mn>1</mn>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>&#x22ee;</mi>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mi>h</mi>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>N</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>7</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
where N is the length of the shaping filter.
</p>
<p id="p-0043" num="0042">In an alternative speech enhancement system <b>100</b>, the articulation index (AI) of the far-end signal segment x<sub>m</sub>(n) may be used to determine the filter coefficients of the shaping filter <b>108</b>. When the articulation index has a low value (AI) (e.g., close to about 0), the filter coefficients of the shaping filter <b>108</b> may be programmed to enhance the speech intelligibility of the receive-side signal. As the articulation index (AI) increases or begins to get closer to about 1, the amplitude response may begin to improve speech quality. To process the various spectral shapes, an adaptive Finite Impulse Response (FIR) shaping filter such as the filter disclosed in U.S. patent application Ser. No. 11/809,952, now U.S. Pat. No. 7,912,729, issued 22 Mar. 2011, entitled &#x201c;High-Frequency Bandwidth Extension in the Time Domain&#x201d; filed on Jun. 4, 2007, which is incorporated by reference, may be used. The output response of the shaping filter <b>108</b> may be described by equation 8
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>h</i>(<i>k</i>)=&#x3b2;<sub>1</sub>(<i>k</i>)<i>h</i><sub>1</sub>+&#x3b2;<sub>2</sub>(<i>k</i>)<i>h</i><sub>2</sub>+ . . . +&#x3b2;<sub>L</sub>(<i>k</i>)<i>h</i><sub>L </sub>&#x2003;&#x2003;8<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where h<sub>1</sub>, h<sub>2</sub>, . . . , h<sub>L </sub>are the L basis filter-coefficient vectors, h(k) is the updated filter coefficient vector, and &#x3b2;<sub>1</sub>(k), &#x3b2;<sub>2</sub>(k), . . . , &#x3b2;<sub>L</sub>(k) are the L scalar coefficients that are updated every N samples as expressed in equation 9.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x3b2;<sub>1</sub>(k)=f<sub>i</sub>(AI(x<sub>m</sub>(n)), &#x3b7;(n)) &#x2003;&#x2003;(9)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0044" num="0043">The basis filter coefficients may be pre-programmed so that they may be linearly combined to approximately model most of the noise spectrums and an inverse noise-spectrum that may be encountered in an enclosure such as in the interior of a vehicle. The noises encountered in a vehicle environment may have spectrums with a greater low-frequency energy that gradually tapers down as the frequency increases. A basis coefficient vector with an amplitude response that maximizes the intelligibility of speech in a high white-noise environment that may be detected in a vehicle may be programmed so that the vector has an amplitude-response shape that may be similar to the response shown in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0045" num="0044">While the system may improve speech intelligibility in a high noise condition and speech quality in a low noise condition, <figref idref="DRAWINGS">FIG. 4</figref> illustrates an exemplary simulated shaping filter <b>108</b> response in a high noise condition. To attain a high intelligibility of the receive side signal in the noise condition shown in exemplary <figref idref="DRAWINGS">FIG. 5</figref>, the amplitude response of the shaping filter <b>108</b> is programmed to generate the exemplary response shown in <figref idref="DRAWINGS">FIG. 4</figref>. The slope of the inverse background spectrum represented by exemplary <figref idref="DRAWINGS">FIG. 6</figref> is derived by approximating a linear relationship to the background noise shown in exemplary <figref idref="DRAWINGS">FIG. 5</figref>. The shaping filter <b>108</b> response is adjusted by tilting the response by approximating an inverse linear relationship to the background spectrum as shown in exemplary <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0046" num="0045">When the estimated articulation index (AI) of the far-end signal is high or approaching <b>1</b>, the speech intelligibility is assumed to be high and the filter coefficients are programmed to improve the quality of the receive side signal x<sub>m</sub>(n). Under these conditions, the amplitude response of the shaping filter shown by example in <figref idref="DRAWINGS">FIG. 4</figref> is adjusted by tilting the filter response by the approximated slope of the background spectrum as shown in exemplary <figref idref="DRAWINGS">FIG. 8</figref>. <figref idref="DRAWINGS">FIG. 8</figref>, shown only for illustrative purposes, illustrates how the amplitude response of the shaping filter <b>108</b> may change as the articulation index (AI) of the receive side signal x<sub>m</sub>(n) may change within a range between about 0 and about 1. A more accurate mapping between the articulation index (AI) and the filter shape may vary with shape or contour of an enclosure such as a vehicle interior and may comprise a non-linear or other approximation or function.</p>
<p id="p-0047" num="0046">The speech enhancement system improves speech intelligibility and/or speech quality near the position of a listener's ears. The filter coefficient adjustments and gain adjustments may be made in real-time based on signals received from an input device such as a vehicle microphone or loudspeaker. Since the distance between the listener's ears and the microphone may vary, the signal-to-noise ratio of the receive-side signal at two positions may not coincide or may not be exactly the same. This may occur when prominent vehicle noises are detected that do not have a highly diffused field. These noises may be generated by a fan or a defroster. To compensate for these conditions, the speech enhancement system may communicate with other noise detectors that detect and compensate for these conditions. The system may apply additional compensation factors to the receive-side signal x<sub>m</sub>(n) through a spectral signal-to-noise estimator such the gain estimator <b>212</b>. The gain estimator <b>212</b> may communicate with a system that suppresses wind noise from a voiced or unvoiced signal such as the system described in U.S. patent application Ser. No. 10/688,802, under US Attorney's Docket Number 11336/592, now U.S. Pat. No. 7,895,036, issued 22 Feb. 2011, entitled &#x201c;System for Suppressing Wind Noise&#x201d; filed on Oct. 16, 2003, which is incorporated by reference.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 9</figref> is an exemplary real-time or delayed method <b>900</b> that improves speech intelligibility and/or speech quality. At <b>902</b> a spectral signal-to-noise ratio (SNR) of a receive-side signal is estimated. Based on the spectral signal-to-noise ratio (SNR) of the receive-side signal, an articulation index (AI) is derived at <b>904</b>. If the articulation index (AI) is below a certain pre-determined threshold such as about 0.3, (<b>906</b>) for example, the gain and/or the spectral shape of portions of the receive-side signal are adjusted so that intelligibility of the receive-side signal is increased <b>912</b>. In one method, the amplitude of portions of the receive-side signal is adjusted by tilting portions of the amplitude of the receive-side signal to an estimated inverse relationship (<b>908</b>) or inverse slope. The adjustment may fit a line to a background noise spectrum and derive an estimated inverse function (<b>910</b>) or inverse slope of the background noise. When the articulation index (AI) is above a predetermined threshold such as about. 7, (<b>906</b>) the intelligibility of the signal and the gain and the spectrum of the receive-side signal may be adjusted at <b>916</b> based on an alternative relationship <b>914</b>. In one method, portions of the receive-side signal are adjusted by tilting portions of the amplitude of the receive-side signal to an estimated linear or non-linear relationship. A linear relationship may be derived by estimating the slope of a background noise. The methods described have a low computational requirement. The method (and systems described in the system descriptions) may operate in the time-domain and may have low propagation latencies.</p>
<p id="p-0049" num="0048">The method of <figref idref="DRAWINGS">FIG. 9</figref> may be encoded in a signal bearing medium, a computer readable medium such as a memory that may comprise logic, programmed within a device such as one or more integrated circuits, or processed by a controller or a computer. If the methods are performed by software, the software or logic may reside in a memory resident to or interfaced to one or more processors or controllers, a wireless communication interface, a wireless system, an entertainment and/or comfort controller of a vehicle or any other type of non-volatile or volatile memory interfaced or resident to a speech enhancement system. The memory may include an ordered listing of executable instructions for implementing logical functions. A logical function may be implemented through digital circuitry, through source code, through analog circuitry, or through an analog source such through an analog electrical, or audio signals. The software may be embodied in any computer-readable medium or signal-bearing medium, for use by, or in connection with an instruction executable system, apparatus, device, resident to a hands-free system or communication system or audio system shown in <figref idref="DRAWINGS">FIG. 10</figref> and also may be within a vehicle as shown in <figref idref="DRAWINGS">FIG. 11</figref>. Such a system may include a computer-based system, a processor-containing system, or another system that includes an input and output interface that may communicate with an automotive or wireless communication bus through any hardwired or wireless automotive communication protocol or other hardwired or wireless communication protocols.</p>
<p id="p-0050" num="0049">A &#x201c;computer-readable medium,&#x201d; &#x201c;machine-readable medium,&#x201d; &#x201c;propagated-signal&#x201d; medium, and/or &#x201c;signal-bearing medium&#x201d; may comprise any means that contains, stores, communicates, propagates, or transports software for use by or in connection with an instruction executable system, apparatus, or device. The machine-readable medium may selectively be, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, device, or propagation medium. A non-exhaustive list of examples of a machine-readable medium would include: an electrical connection &#x201c;electronic&#x201d; having one or more wires, a portable magnetic or optical disk, a volatile memory such as a Random Access Memory &#x201c;RAM&#x201d; (electronic), a Read-Only Memory &#x201c;ROM&#x201d; (electronic), an Erasable Programmable Read-Only Memory (EPROM or Flash memory) (electronic), or an optical fiber (optical). A machine-readable medium may also include a tangible medium upon which software is printed, as the software may be electronically stored as an image or in another format (e.g., through an optical scan), then compiled, and/or interpreted or otherwise processed. The processed medium may then be stored in a computer and/or machine memory.</p>
<p id="p-0051" num="0050">The system may dynamically control the gain and spectral shape of the receive-side signal in an enclosure or an automobile communication device such as a hands-free system. In an alternative system, the spectral signal-to-noise ratio (SNR) of the receive signal may be estimated by a signal-to-noise ratio processor and the articulation index (AI) derived or approximated by an articulation index (AI) processor. Based on the output of the articulation index processor and an estimated linear or non-linear relationship of the background modeled by the background noise processor, the gain and filter response for a shaping filter may be rendered by a shaping processor or a programmable filter and amplifier. In a high noise or low noise conditions, the spectrum of the signal may be adjusted to the method described in <figref idref="DRAWINGS">FIG. 9</figref> so that intelligibility and signal quality is improved. In an alternative system, the adjustment of the spectral shape of a speech segment may be processed through a spectral-shaping technique. A Finite Impulse Response Filter (FIR) that may operate in the time domain and does not require high order (e.g., an order of around about <b>10</b> may be sufficient) may be used. The filter may have a low latency and low computational complexity. When the processors are a unitary (e.g., single) or integrated devices, the system may require very little board space.</p>
<p id="p-0052" num="0051">The speech enhancement system improves speech quality and intelligibility by dynamically controlling the gain and spectral shape of a speech signal. The speech enhancement system (also referred to as speech enhancement logic) estimates a spectral signal-to-noise ratio (SNR) of a received speech signal. The system derives an index used to adjust spectral shapes and/or signal amplitudes. The estimated tilt of the background noise spectrum and a dynamic spectral-shaping filter may adjust the spectral shape. Various spectral shapes may be realized. In high noise conditions, the spectrum of the receive-side signal may be adjusted so that intelligibility is improved. In low noise conditions, the spectrum of the receive-side signal may be adjusted so that the quality of the signal is improved. The gain of the receive-side is allowed to vary within a certain range and may adjust the signal level on the basis of the intelligibility of a speech segment.</p>
<p id="p-0053" num="0052">While various embodiments of the invention have been described, it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the invention. Accordingly, the invention is not to be restricted except in light of the attached claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08626502-20140107-M00001.NB">
<img id="EMI-M00001" he="8.81mm" wi="76.20mm" file="US08626502-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08626502-20140107-M00002.NB">
<img id="EMI-M00002" he="11.26mm" wi="76.20mm" file="US08626502-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08626502-20140107-M00003.NB">
<img id="EMI-M00003" he="4.91mm" wi="76.20mm" file="US08626502-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US08626502-20140107-M00004.NB">
<img id="EMI-M00004" he="34.54mm" wi="76.20mm" file="US08626502-20140107-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US08626502-20140107-M00005.NB">
<img id="EMI-M00005" he="9.14mm" wi="76.20mm" file="US08626502-20140107-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00006" nb-file="US08626502-20140107-M00006.NB">
<img id="EMI-M00006" he="15.49mm" wi="76.20mm" file="US08626502-20140107-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system that improves speech intelligibility and speech quality of a speech segment comprising:
<claim-text>one or more processors or circuits including:</claim-text>
<claim-text>a background noise processor programmed to detect and model a background noise from an input comprising a plurality of signals;</claim-text>
<claim-text>a signal-to-noise processor programmed to approximate a signal-to-noise ratio of at least one of the plurality of signals; and</claim-text>
<claim-text>an articulation index processor programmed to approximate an articulation index of the at least one of the plurality of signals processed by the signal-to-noise processor;</claim-text>
<claim-text>wherein a shaping processor adjusts a spectrum of the at least one of the plurality of signals, based on a comparison of the articulation index to a plurality of predetermined thresholds.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the shaping processor is programmed to adjust the spectrum of a speech segment to improve an intelligibility and quality of the speech segment.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref> where the shaping processor, the articulation index processor, the signal-to-noise processor, and the background noise processor, comprises a unitary device.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> where the articulation index processor, the signal-to-noise processor, and the background noise processor, comprises a unitary device.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> where the model comprises fitting a line to the detected background noise.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref> where the model comprises approximating an inverse linear relationship.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> where the model comprises approximating an inverse linear relationship.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> where the model comprises approximating a non-linear relationship.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A non-transitory computer readable medium having software that improves a speech intelligibility and speech quality that models a speech segment based on a detected background comprising:
<claim-text>a modeling logic that represents the background noise detected from an input signal comprising a desired signal and a plurality of undesired signals;</claim-text>
<claim-text>a signal-to-noise logic that approximate a signal-to-noise ratio of at least one of the signals that comprise the input signal;</claim-text>
<claim-text>an articulation logic that approximates an articulation index of the at least one of the signals that is processed by the signal-to-noise processor; and</claim-text>
<claim-text>shaping logic that adjusts the spectrum of the speech segment to improve an intelligibility and quality of the speech segment, wherein the articulation index measures the intelligibility of the speech segment, and the shaping logic adjusts the spectrum of the speech segment based on a comparison of the articulation index to a plurality of predetermined thresholds.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The non-transitory computer readable medium of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising a memory linked to a plurality of articulation indexes.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The non-transitory computer readable medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, where at least some of the plurality of articulation indexes are customized to an interior of an enclosure.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The non-transitory computer readable medium of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the modeling logic includes voice activity detection that identifies whether the input signal comprises a speech signal, an unvoiced signal, or a background noise.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the desired signal comprises the speech signal and the undesired signals comprises at least one of the unvoiced signal or the background noise.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The non-transitory computer readable medium of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the modeling logic comprises a coherence estimation that estimates a spectral coherence between at least one of the undesired signals and the desired signal by quantifying the quality of interference between at least one of the undesired signals and the desired signal.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The non-transitory computer readable medium of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the articulation index measures the intelligibility of the speech segment, and the shaping logic adjusts the spectrum of the speech signal based on a comparison of the articulation index to a plurality of predetermined thresholds.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A method for improving speech comprising:
<claim-text>in one or more computing devices:
<claim-text>modeling background noise from an input signal comprising a desired signal and a plurality of undesired signals;</claim-text>
<claim-text>processing at least one of the signals that comprise the input to generate a signal-to-noise ratio;</claim-text>
<claim-text>generating an articulation index of the at least one of the signals that is processed; and</claim-text>
<claim-text>adjusting a spectrum of a speech segment to improve an intelligibility and quality of the speech segment based on the articulation index;</claim-text>
<claim-text>wherein a shaping logic adjusts the spectrum of the speech segment based on a comparison of the articulation index to a plurality of predetermined thresholds.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref> wherein the modeling background noise comprises modeling a tilt of the background noise.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref> wherein a signal-to-noise processor approximates the signal-to-noise ratio and an articulation index processor is programmed to approximate an articulation index.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref> wherein the articulation index measures intelligibility of the speech segment.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein the spectrum of the speech signal is adjusted based on a comparison of the articulation index to a plurality of predetermined thresholds.</claim-text>
</claim>
</claims>
</us-patent-grant>
