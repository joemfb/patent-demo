<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626387-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626387</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13676390</doc-number>
<date>20121114</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>7</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>041</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>701 36</main-classification>
<further-classification>701 45</further-classification>
<further-classification>701 49</further-classification>
<further-classification>345173</further-classification>
</classification-national>
<invention-title id="d2e43">Displaying information of interest based on occupant movement</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6996460</doc-number>
<kind>B1</kind>
<name>Krahnstoever et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7352355</doc-number>
<kind>B2</kind>
<name>Troxell</name>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>8180370</doc-number>
<kind>B2</kind>
<name>Kim</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2003/0105559</doc-number>
<kind>A1</kind>
<name>Avenel</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701  2</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2008/0215240</doc-number>
<kind>A1</kind>
<name>Howard</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2009/0225026</doc-number>
<kind>A1</kind>
<name>Sheba</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2010/0214112</doc-number>
<kind>A1</kind>
<name>Ishihara et al.</name>
<date>20100800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3406861</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2011/0141063</doc-number>
<kind>A1</kind>
<name>Grundmann et al.</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345175</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2011/0205162</doc-number>
<kind>A1</kind>
<name>Waller et al.</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2012/0105349</doc-number>
<kind>A1</kind>
<name>Hauschild et al.</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2012/0123649</doc-number>
<kind>A1</kind>
<name>Eggers et al.</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701 49</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2012/0320080</doc-number>
<kind>A1</kind>
<name>Giese et al.</name>
<date>20121200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345619</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2013/0009900</doc-number>
<kind>A1</kind>
<name>Pryor</name>
<date>20130100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2013/0079985</doc-number>
<kind>A1</kind>
<name>Wolf et al.</name>
<date>20130300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701 36</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>16</number-of-claims>
<us-exemplary-claim>10</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>701  2</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701 36</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701 45</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701 49</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345156-184</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Toyota Motor Engineering &#x26; Manufacturing North America, Inc.</orgname>
<address>
<city>Erlanger</city>
<state>KY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Nagata</last-name>
<first-name>Katsumi</first-name>
<address>
<city>Dearborn</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Dinsmore &#x26; Shohl LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Toyota Motor Engineering &#x26; Manufacturing North America, Inc.</orgname>
<role>02</role>
<address>
<city>Erlanger</city>
<state>KY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Cheung</last-name>
<first-name>Mary</first-name>
<department>3667</department>
</primary-examiner>
<assistant-examiner>
<last-name>Butler</last-name>
<first-name>Rodney</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method of displaying information of interest to an occupant of a vehicle is provided. The method includes detecting movement of a hand of the occupant toward a physical control using a sensor and the sensor sending a signal from the sensor to a processor in the vehicle when the hand is detected. The method determines information of interest based on the signal using the processor and then displays the information of interest on a display device.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="255.10mm" wi="186.61mm" file="US08626387-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="232.16mm" wi="189.15mm" orientation="landscape" file="US08626387-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="258.15mm" wi="192.79mm" orientation="landscape" file="US08626387-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="258.49mm" wi="190.33mm" file="US08626387-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="241.98mm" wi="186.69mm" file="US08626387-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="236.14mm" wi="190.92mm" orientation="landscape" file="US08626387-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="261.54mm" wi="201.34mm" orientation="landscape" file="US08626387-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="223.01mm" wi="133.77mm" file="US08626387-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD</heading>
<p id="p-0002" num="0001">The disclosure relates to vehicle user interfaces that determine information of interest to display on a display device based on sensors that detect the physical movement of a vehicle occupant.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Vehicle display devices can be used to display information to vehicle occupants. Information may include navigation data, current temperature, or vehicle system settings. Since the information can usually be shown to occupants while a vehicle is in motion, vehicle manufacturers attempt to minimize the lag between an occupant's desire to see information on the display device, and the actual display of the information on the display device so as to minimize any distraction from operation of the vehicle.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0004" num="0003">In one embodiment, a method of displaying information of interest to an occupant of a vehicle is provided. The method includes detecting movement of a hand of the occupant toward a physical control using a sensor and the sensor sending a signal from the sensor to a processor in the vehicle when the hand is detected. The method determines information of interest based on the signal using the processor and then displays the information of interest on a display device.</p>
<p id="p-0005" num="0004">In another embodiment, a method of controlling a vehicle system is provided. The method includes detecting movement of a hand of an occupant toward a physical control using a sensor, where the physical control allows user control of a vehicle system. The sensor sends a signal from the sensor to a processor in the vehicle when the hand is detected and displays information of interest for the vehicle system. This allows the occupant to control the vehicle system using the display device.</p>
<p id="p-0006" num="0005">In another embodiment, a vehicle user interface system includes a display device, a physical control, a processor, and a sensor. The sensor detects movement of a hand of an occupant toward the physical control and provides a signal to the processor upon detecting movement of the hand toward the physical control. The processor determines information of interest to display based on the signal and instructs the display device to display the information of interest.</p>
<p id="p-0007" num="0006">These and additional features provided by the embodiments described herein will be more fully understood in view of the following detailed description, in conjunction with the drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007">The embodiments set forth in the drawings are illustrative and exemplary in nature and not intended to limit the subject matter defined by the claims. The following detailed description of the illustrative embodiments can be understood when read in conjunction with the following drawings, where like structure is indicated with like reference numerals and in which:</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic illustration of a vehicle user interface including physical controls, sensors communicating with a processor, and the processor communicating with a display device according to one or more embodiments described herein;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a dash console of the vehicle including the vehicle user interface according to one or more embodiments described herein;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a close-up view of the dash console shown in <figref idref="DRAWINGS">FIG. 2</figref> along with a hand of an occupant reaching toward a physical control;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 4</figref> is a close-up view of the dash console shown in <figref idref="DRAWINGS">FIG. 2</figref> along with a hand of an occupant touching a display device;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 5</figref> includes a steering wheel of a vehicle for use in the vehicle user interface according to one or more embodiments described herein;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 6</figref> includes a close-up of the dash console shown in <figref idref="DRAWINGS">FIG. 2</figref> along with a hand of an occupant touching the dash console; and</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 7</figref> illustrates a method of displaying information of interest to an occupant of a vehicle and controlling a vehicle system according to one or more embodiments described herein.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0016" num="0015">Embodiments described herein are generally directed to vehicle user interfaces that may be included in vehicles. The vehicle user interfaces include display devices that may be used to display information of interest including vehicle system settings, applications, and the like. A sensor may be used to detect movement of a hand of an occupant toward a physical control and/or contact between the hand and the physical control and send a signal to a processor. The processor may then determine information of interest to be displayed on the display device based on the signal. Various embodiments of vehicle user interfaces are described in detail below.</p>
<p id="p-0017" num="0016">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, a vehicle <b>100</b> includes a dash console <b>102</b>. The dash console <b>102</b> includes a variety of physical control devices <b>104</b>, and various configurations of sensors <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>that detect movement or proximity of a vehicle occupant's <b>120</b> hand <b>122</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>). The sensors <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>can be placed on or near the physical controls <b>104</b>. When any of the sensors <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>detect movement, physical contact or proximity of the vehicle occupant's <b>120</b> hand <b>122</b> within a predetermined range, the respective sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>is activated. Once the sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>is activated, the sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>sends an identification signal to a processor <b>112</b>. Based upon the configuration of the sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g</i>, the identification signal that is sent by the sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>can be either unique to that particular sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>or shared by multiple sensors <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g</i>. The identification signal associates the sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g </i>with information of interest <b>114</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>), which can include vehicle system control options. When the processor <b>112</b> receives the identification signal from the sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>, <b>113</b><i>b</i>, <b>150</b><i>a</i>-<i>g</i>, the processor <b>112</b> determines the association between the identification signal and the information of interest <b>114</b>. The processor <b>112</b> can instruct a display device <b>116</b> to display the information of interest <b>114</b> and/or vehicle system control options. This allows the information of interest <b>114</b> to be displayed on the display device <b>116</b> before or soon after the occupant <b>120</b> has made physical contact with the physical control <b>104</b>. If there is more than one display device <b>116</b> in the vehicle <b>100</b>, such as a second display device <b>117</b>, the occupant <b>120</b> can select the display device <b>116</b>, <b>117</b> the information of interest <b>114</b> should be displayed on, or the information of interest <b>114</b> can be displayed on more than one display device <b>116</b>,<b>117</b>.</p>
<p id="p-0018" num="0017">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, multiple sensors <b>150</b><i>a</i>-<i>g </i>with shared identification signals can be used with multiple physical controls <b>104</b>. For example, a column of buttons <b>108</b><i>a </i>can contain seven buttons <b>109</b><i>a</i>-<i>g</i>, along with seven sensors <b>150</b><i>a</i>-<i>g</i>. In this example, each of the sensors <b>150</b><i>a</i>-<i>g </i>may have a shared identification signal. Therefore, when any of the sensors <b>150</b><i>a</i>-<i>g </i>is activated, the sensor <b>150</b><i>a</i>-<i>g </i>sends the same identification signal to the processor <b>112</b>. The processor <b>112</b> may determine information of interest <b>114</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) accordingly. This exemplary embodiment may be used when several physical controls <b>104</b> pertain to the same vehicle system. An example of this shared signal configuration is illustrated in <figref idref="DRAWINGS">FIG. 3</figref>. Although the sensors <b>150</b><i>a</i>-<i>g </i>are illustrated on the buttons <b>109</b><i>a</i>-<i>g</i>, the sensors <b>150</b><i>a</i>-<i>g </i>may be located anywhere on or near the buttons <b>109</b><i>a</i>-<i>g</i>, depending, for example, on the range of the sensors <b>150</b><i>a</i>-<i>g. </i></p>
<p id="p-0019" num="0018">Also shown in <figref idref="DRAWINGS">FIG. 1</figref> is another configuration in which multiple physical controls <b>104</b> have a single sensor <b>113</b><i>b</i>. For example, a column of buttons <b>108</b><i>b </i>may have seven buttons <b>111</b><i>a</i>-<i>g</i>, yet only a single sensor <b>113</b><i>b</i>. In this instance, the sensor <b>113</b><i>b </i>will have a unique identification signal that it will send to the processor <b>112</b> when the sensor <b>113</b><i>b </i>is activated. The identification signal allows the processor <b>112</b> to determine that the sensor <b>113</b><i>b </i>is associated with the information of interest <b>114</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) related to the column of seven buttons <b>108</b><i>b</i>, and instruct the display device <b>116</b> to display the information of interest <b>114</b> accordingly. Thus, when an occupant <b>120</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) reaches towards any of the seven buttons <b>111</b><i>a</i>-<i>g</i>, the sensor <b>113</b><i>b </i>may be activated and the sensor <b>113</b><i>b </i>will send its unique identification signal to the processor <b>112</b>. While the sensor <b>113</b><i>b </i>is illustrated near button <b>111</b><i>d</i>, the sensor <b>113</b><i>b </i>may be located on or near any of the buttons <b>111</b><i>a</i>-<i>g</i>, similar to sensors <b>150</b><i>a</i>-<i>g</i>. An example of this multiple physical controls per sensor configuration is illustrated in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0020" num="0019">Another configuration shown in <figref idref="DRAWINGS">FIG. 1</figref> is multiple physical controls <b>104</b> and multiple sensors <b>110</b><i>a</i>, <b>110</b><i>b </i>with unique identification signals. For example, the physical controls <b>104</b> may consist of two rotatable knobs <b>106</b><i>a</i>, <b>106</b><i>b</i>. Each rotatable knob <b>106</b><i>a</i>, <b>106</b><i>b </i>may have an individual sensor <b>110</b><i>a</i>, <b>110</b><i>b</i>. The first rotatable knob <b>106</b><i>a </i>may have a first sensor <b>110</b><i>a</i>, and the second rotatable knob <b>106</b><i>b </i>may have a second sensor <b>110</b><i>b</i>, and the first sensor <b>110</b><i>a </i>and second sensor <b>110</b><i>b </i>can each have a unique identification signal. When either of the sensors <b>110</b><i>a</i>, <b>110</b><i>b </i>are activated, the processor <b>112</b> can determine which sensor <b>110</b><i>a</i>, <b>110</b><i>b </i>was activated based on the unique identification signal received, and determine information of interest <b>114</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) accordingly. This configuration can be used when a single sensor <b>110</b><i>a </i>has associated information of interest <b>114</b> that is different than information of interest <b>114</b> associated with a different sensor <b>110</b><i>b</i>. An example of this multiple physical controls and multiple sensors configuration is illustrated in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0021" num="0020">Referring to <figref idref="DRAWINGS">FIG. 2</figref>, the vehicle <b>100</b> and dash console <b>102</b> are shown. The dash console <b>102</b> includes a variety of physical controls <b>104</b>, such as rotatable knobs <b>106</b><i>a</i>, <b>106</b><i>b </i>and pressable button columns <b>108</b><i>a</i>, <b>108</b><i>b</i>. Any other suitable physical control device may be used, such as include levers, switches, dials, etc. These physical controls <b>104</b> can be used to control a variety of vehicle systems or vehicle functions, such as air conditioning, radio station presets, and navigation controls. For example, the rotatable knobs <b>106</b><i>a</i>, <b>106</b><i>b </i>can be used to adjust climate control settings and radio volume, while the pressable button columns <b>108</b><i>a</i>, <b>108</b><i>b </i>may be used to select radio station presets and to control a navigation unit. The dash console <b>102</b> may have multiple sensors <b>110</b><i>a</i>, <b>110</b><i>b</i>, as there can be one sensor <b>110</b><i>a</i>, <b>110</b><i>b </i>or multiple sensors for each physical control <b>104</b>, as discussed above. The location of the sensors <b>110</b><i>a</i>, <b>110</b><i>b </i>can be on or near the physical controls <b>104</b>. For example, the sensor <b>110</b><i>a </i>can be located at the center of or elsewhere on the rotatable knob <b>106</b><i>a</i>, as shown in <figref idref="DRAWINGS">FIG. 2</figref>, or can otherwise be located near the rotatable knob <b>106</b><i>a</i>, as long as the rotatable knob <b>106</b><i>a </i>is within the detection range of the sensor <b>110</b><i>a</i>. The detection range of the sensor <b>110</b><i>a </i>is determined by the type of sensor <b>110</b><i>a </i>used. For example, if the sensor <b>110</b><i>a </i>is a proximity sensor, the sensor <b>110</b><i>a </i>may have a detection range of about 0.1-1 inch, such as 0.5 inch, and may be placed within about 0.5 inch or less of a physical control <b>104</b>. The sensor <b>110</b><i>a </i>may also be a motion detection sensor or capacitive sensor, and the detection range will vary accordingly.</p>
<p id="p-0022" num="0021">The sensor <b>110</b><i>a </i>in <figref idref="DRAWINGS">FIG. 2</figref> detects movement and/or contact by the hand <b>122</b> of the occupant <b>120</b> of the vehicle <b>100</b>. The sensor <b>110</b><i>a </i>may be activated when the hand <b>122</b> comes within the detection range of the sensor <b>110</b><i>a</i>, which may include physical contact with the hand <b>122</b>. When the sensor <b>110</b><i>a </i>is activated, the sensor <b>110</b><i>a </i>will send its unique identification signal to the processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>). The identification signal allows the processor <b>112</b> to determine which physical control <b>104</b> the occupant <b>120</b> is interested in, and the processor <b>112</b> is able to determine information of interest <b>114</b> or vehicle system control options accordingly, and instruct the display device <b>116</b> to display the information of interest <b>114</b>. For example, the dash console <b>102</b> may have the physical control <b>104</b> that is the rotatable knob <b>106</b><i>b </i>labeled &#x201c;Climate Control&#x201d; located thereon. The sensor <b>110</b><i>b </i>positioned at or near the &#x201c;Climate Control&#x201d; rotatable knob <b>106</b><i>b </i>can have a unique identification signal that is sent to the processor <b>112</b> when the sensor <b>110</b><i>b </i>is activated. The processor <b>112</b> can determine information of interest <b>114</b> saved in its memory that is relevant to vehicle functions related to the &#x201c;Climate Control&#x201d; rotatable knob <b>106</b><i>b </i>and instruct the display device <b>116</b> to display the information of interest <b>114</b>.</p>
<p id="p-0023" num="0022">The display device <b>116</b> can be a touchscreen device, which allows the occupant <b>120</b> of the vehicle <b>100</b> to make changes to the vehicle systems or vehicle settings using the display device <b>116</b> rather than the physical control <b>104</b>. By showing information of interest <b>114</b> on the display device <b>116</b>, vehicle setting control options, vehicle functions, features, or information being sought by the occupant <b>120</b> can be adjusted or delivered through the display device <b>116</b> as well as the physical control <b>104</b>. In <figref idref="DRAWINGS">FIG. 2</figref>, the hand <b>122</b> of the occupant <b>120</b> is shown reaching toward the rotatable knob <b>106</b><i>b </i>labeled &#x201c;Climate Control.&#x201d; When the hand <b>122</b> activates the sensor <b>110</b><i>b</i>, the sensor <b>110</b><i>b </i>sends its unique signal to the processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>). The processor <b>112</b>, knowing the unique signal of the sensor <b>110</b><i>b </i>is associated with the climate control vehicle system, instructs the display device <b>116</b> to display information of interest <b>114</b> relevant to the climate control vehicle system, such as options to adjust temperature and fan speed, along with a label of &#x201c;Climate Control&#x201d; appearing on the display device <b>116</b>. The occupant <b>120</b> can now use inputs of the display device <b>116</b> to change the climate control settings (shown in <figref idref="DRAWINGS">FIG. 4</figref>). The processor <b>112</b> then receives input from the display device <b>116</b> when the occupant <b>120</b> uses the display device <b>116</b> to change a vehicle system setting. In some instances, the vehicle <b>100</b> may have more than one display device <b>116</b>, such as the second display device <b>117</b> located in an instrument cluster or elsewhere. In this case, if the occupant <b>120</b> wants to use the particular display device <b>116</b>, <b>117</b> for a certain purpose, the occupant <b>120</b> can select the certain display device <b>116</b>, <b>117</b> using the specific physical control <b>104</b> on the dash console <b>102</b> or the steering wheel <b>140</b>. The processor <b>112</b> may also display information of interest <b>114</b> on each of the display devices <b>116</b>, <b>117</b>.</p>
<p id="p-0024" num="0023">In <figref idref="DRAWINGS">FIG. 3</figref>, the physical controls <b>104</b> are pressable buttons <b>109</b><i>a</i>, <b>109</b><i>b </i>that are located in pressable button column <b>108</b><i>a </i>nearer a driver's side <b>130</b> of the dash console <b>102</b> and pressable buttons <b>111</b><i>a</i>, <b>111</b><i>b </i>located in pressable button column <b>108</b><i>b </i>nearer a passenger's side <b>132</b> of the dash console <b>102</b>. There is a sensor <b>150</b><i>a </i>and <b>150</b><i>b </i>for the pressable buttons <b>109</b><i>a </i>and <b>109</b><i>b </i>and a sensor <b>151</b><i>a </i>and <b>151</b><i>b </i>for the pressable buttons <b>111</b><i>a </i>and <b>111</b><i>b</i>. When multiple physical controls <b>104</b> with multiple sensors <b>150</b><i>a</i>, <b>150</b><i>b </i>are related to the same vehicle system or vehicle information, the processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>) can be provided with logic to determine the same information of interest <b>114</b> to display when any of the sensors <b>150</b><i>a</i>, <b>150</b><i>b </i>is activated. In the instance where each sensor <b>150</b><i>a</i>, <b>150</b><i>b </i>has a unique identification signal, the processor <b>112</b> can be provided with logic to place the unique identification signals into groups, wherein any identification signal received by the processor <b>112</b> from a certain group will result in the processor <b>112</b> determining the same information of interest <b>114</b>. In the instance where each sensor <b>150</b><i>a</i>, <b>150</b><i>b </i>has a shared identification signal, the processor <b>112</b> will determine the same information of interest <b>114</b> regardless of which sensor <b>150</b><i>a</i>, <b>150</b><i>b </i>was activated.</p>
<p id="p-0025" num="0024">For example, in <figref idref="DRAWINGS">FIG. 3</figref>, each sensor <b>150</b><i>a</i>, <b>150</b><i>b </i>may send a shared identification signal to the processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>) when any of the sensors <b>150</b><i>a</i>, <b>150</b><i>b </i>is activated. In other embodiments, each sensor <b>150</b><i>a</i>, <b>150</b><i>b </i>may send a unique identification signal to the processor <b>112</b>, and if the sensors <b>150</b><i>a</i>, <b>150</b><i>b </i>are associated with the same vehicle system, such as radio controls in <figref idref="DRAWINGS">FIG. 3</figref>, the unique identification signals from the sensor <b>150</b><i>a</i>, <b>150</b><i>b </i>may be grouped by the processor <b>112</b> and the processor <b>112</b> may determine the same information of interest <b>114</b> for any identification signal received by the processor <b>112</b> in the group. In this example, when the sensor <b>150</b><i>a </i>located at or on the pressable button <b>109</b><i>a </i>labeled &#x201c;Radio Presets&#x201d; is activated, the processor <b>112</b> will determine the same information of interest <b>114</b> to display on the display device <b>116</b> as when the sensor <b>150</b><i>b </i>located at or on the pressable button <b>109</b><i>b </i>labeled &#x201c;CD Player&#x201d; is activated. This is because both sensors <b>150</b><i>a </i>and <b>150</b><i>b </i>may send unique identification signals to the processor <b>112</b>, and the processor <b>112</b> can group the unique identification signals, as they control the same vehicle audio system.</p>
<p id="p-0026" num="0025">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, a multiple physical controls and single sensor embodiment is shown where the physical controls <b>104</b> are pressable button columns <b>108</b><i>a</i>, <b>108</b><i>b</i>. There is one sensor <b>113</b><i>a</i>, <b>113</b><i>b </i>per pressable button column <b>108</b><i>a</i>, <b>108</b><i>b</i>, or multiple physical controls <b>104</b>. When the sensor <b>113</b><i>a </i>is activated by detecting the hand <b>122</b> of the occupant <b>120</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) within the detection range of the sensor <b>113</b><i>a</i>, the sensor <b>113</b><i>a </i>sends a unique identification signal to the processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>). Using this signal, the processor <b>112</b> determines information of interest <b>114</b> to show on a display device <b>116</b>. The same information of interest <b>114</b> will be shown for each of the buttons <b>109</b><i>a </i>and <b>109</b><i>b </i>because the same sensor <b>113</b><i>a </i>will be activated for each of the buttons <b>109</b><i>a </i>and <b>109</b><i>b</i>. If another sensor <b>113</b><i>b </i>is activated, the processor <b>112</b> determines different information of interest <b>114</b> to display, as the sensor <b>113</b><i>b </i>can have a unique identification signal and can therefore be associated with different vehicle systems. The occupant <b>120</b> can then manipulate a vehicle <b>100</b> system using the display device <b>116</b>.</p>
<p id="p-0027" num="0026">Referring to <figref idref="DRAWINGS">FIG. 5</figref>, while physical controls <b>104</b> on the dash console <b>102</b> are described above, sensors may be used at other locations. For example, a steering wheel <b>140</b> of vehicle <b>100</b> is shown. The steering wheel <b>140</b> includes at least one steering wheel button <b>142</b><i>a</i>, <b>142</b><i>b </i>and a corresponding steering wheel sensor <b>144</b><i>a</i>, <b>144</b><i>b </i>located at or near the steering wheel button <b>142</b><i>a</i>, <b>142</b><i>b</i>. For example, the steering wheel <b>140</b> may have climate control buttons <b>142</b><i>a </i>or volume buttons <b>142</b><i>b </i>on the steering wheel <b>140</b>. Any sensor <b>144</b><i>a</i>, <b>144</b><i>b </i>located on the steering wheel <b>140</b> can be used in a manner similar to the sensors <b>110</b><i>a</i>, <b>110</b><i>b </i>located on the dash console <b>102</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) of the vehicle <b>100</b>. Behind the steering wheel <b>140</b> is a steering column <b>146</b> that extends into the vehicle <b>100</b>. The steering column <b>146</b> may include a steering wheel column stick <b>148</b>. The steering wheel column stick <b>148</b> may include buttons or may be manipulated along intersecting axes to activate functions such as cruise control or windshield wipers. The steering wheel column stick <b>148</b> can include a sensor <b>149</b>, which provides a unique identification signal to the processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>) when it is activated by the hand <b>122</b> of an occupant <b>120</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>). The steering wheel <b>140</b> may also include controls or buttons <b>142</b><i>a</i>, <b>142</b><i>b </i>that allow the occupant <b>120</b> to select a particular display device <b>116</b>, <b>117</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) to display certain information of interest <b>114</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>), or to toggle information of interest <b>114</b> between display devices <b>116</b>, <b>117</b>.</p>
<p id="p-0028" num="0027">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, the dash console <b>102</b> of vehicle <b>100</b> is shown. Pressable button columns <b>108</b><i>a</i>, <b>108</b><i>b </i>may be located on either side of the display device <b>116</b>. The pressable button columns <b>108</b><i>a</i>, <b>108</b><i>b </i>may have a sensor <b>150</b><i>a</i>, <b>150</b><i>e </i>located on each pressable button <b>109</b><i>a</i>, <b>109</b><i>e</i>. In this case, the occupant's hand <b>122</b> may activate more than one sensor <b>150</b><i>a</i>, <b>150</b><i>e </i>within a short time. For example, as shown in <figref idref="DRAWINGS">FIG. 6</figref>, the hand <b>122</b> may first activate the sensor <b>150</b><i>a </i>located at a first button <b>109</b><i>a </i>labeled &#x201c;Radio Presets&#x201d;, and then activate the sensor <b>150</b><i>e </i>located at a second button <b>109</b><i>e </i>labeled &#x201c;NAV&#x201d; shortly after. The processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>) can include priority logic to filter multiple sensor <b>150</b><i>a</i>, <b>150</b><i>e </i>activations by instructing the display device <b>116</b> to display information of interest <b>114</b> for the sensor <b>150</b><i>e </i>that was activated last. In this embodiment, the priority logic is based on timing. As shown, the display device <b>116</b> is displaying information of interest <b>114</b> that is relevant to the &#x201c;NAV&#x201d; pressable button <b>150</b><i>e</i>. The occupant <b>120</b> can now make selections such as select &#x201c;Directions&#x201d; <b>156</b> or enter a &#x201c;New Address&#x201d; <b>158</b> as shown on the display device <b>116</b>. As another example, the priority logic may be based on position of the physical controls <b>104</b>. In the case where a sensor <b>150</b><i>a </i>nearer the driver's side <b>130</b> and a sensor <b>151</b><i>a </i>nearer the passenger's side <b>132</b> of the dash console <b>102</b> are both activated at the same time or within a predetermined time, the processor <b>112</b> (shown in <figref idref="DRAWINGS">FIG. 1</figref>) can be configured to give priority to the sensor <b>150</b><i>a </i>located on the driver's side <b>130</b> of the dash console <b>102</b>. In other embodiments, the processor <b>112</b> can be configured to give priority to the sensor <b>151</b><i>a </i>located on the passenger's side <b>132</b>, or to give priority to the sensor <b>150</b><i>a</i>, <b>151</b><i>a </i>pressed first.</p>
<p id="p-0029" num="0028">Referring to <figref idref="DRAWINGS">FIG. 7</figref>, a method <b>200</b> of displaying information to an occupant of a vehicle is illustrated by first detecting movement using a sensor at step <b>210</b>. At step <b>220</b>, the sensor sends a signal to the processor when the sensor is activated. At step <b>230</b>, the processor checks whether multiple signals have been received within a predetermined time frame, such as about one second or less, such as about 0.5 second or less, or about 0.2 second or less. If multiple signals have been received, the processor determines a priority for the signals at step <b>240</b>. After the processor determines priorities, or if multiple signals have not been received, the processor determines information of interest to display based on the signal from the sensor at step <b>250</b>. At step <b>260</b> the information of interest is displayed on a display device, and at step <b>270</b> the occupant is allowed to control the vehicle system using the display device.</p>
<p id="p-0030" num="0029">The above-described information of interest <b>114</b> based on occupant <b>120</b> movement and methods for controlling vehicle <b>100</b> systems allows the occupant <b>120</b> of a vehicle <b>100</b> to be delivered information of interest <b>114</b> on the display device <b>116</b> in the vehicle <b>100</b> that is relevant to what the occupant <b>120</b> is looking for in a timely manner and allows the occupant <b>120</b> to make several choices or modify several settings at once. By using the sensor <b>110</b><i>a </i>to determine when the occupant's hand <b>122</b> is near, the time required for the information of interest <b>114</b> to be displayed on the display device <b>116</b> is minimized, and the occupant <b>120</b> spends less time distracted from the operation of the vehicle <b>100</b>.</p>
<p id="p-0031" num="0030">It should now be understood that embodiments described herein are directed toward vehicle user interfaces that determine information of interest to display on a display device based on sensors that detect the physical movement of an occupant. At least one sensor located at or near a physical control is activated by an occupant's hand and sends a signal to a processor. The processor determines information of interest to display on a display device based on the signal, and the display device displays the information of interest.</p>
<p id="p-0032" num="0031">While particular embodiments have been illustrated and described herein, it should be understood that various other changes and modifications may be made without departing from the spirit and scope of the claimed subject matter. Moreover, although various aspects of the claimed subject matter have been described herein, such aspects need not be utilized in combination. It is therefore intended that the appended claims cover all such changes and modifications that are within the scope of the claimed subject matter.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of displaying information to an occupant of a vehicle, the method comprising:
<claim-text>detecting the presence of a hand of the occupant within a preselected distance of a first physical control device using a first sensor at or near the first physical control device, where the first physical control device is used to modify operation of a first vehicle system;</claim-text>
<claim-text>detecting the presence of the hand of the occupant within a preselected distance of a second physical control device using a second sensor at or near the second physical control device, where the second physical control device is used to modify operation of a second vehicle system;</claim-text>
<claim-text>sending a signal from the first sensor or second sensor to a processor in the vehicle when presence of the hand is detected within the preselected distance of the first physical control device or the preselected distance of the second physical control device;</claim-text>
<claim-text>based on the signal, determining information of interest associated with the first vehicle system or the second vehicle system to display on a display device;</claim-text>
<claim-text>displaying the information of interest on the display device; and</claim-text>
<claim-text>modifying the information of interest being displayed on the display device based on occupant manipulation of the first physical control device or the second physical control device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first sensor is a proximity sensor.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising modifying operation of the first vehicle system associated with the first physical control device or the second vehicle system associated with the second physical control device using inputs of the display device.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the display device is a touchscreen display, the touchscreen display comprising inputs configured to modify operation of the first vehicle system or the second vehicle system.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first physical control device is located on a steering wheel or steering wheel column, or dash console.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first sensor is a capacitive sensor.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising determining information of interest associated with the first vehicle system or the second vehicle system to display on the display device based on the signal sent by the sensor activated last when both the first sensor and the second sensor are activated within a predetermined time period.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the predetermined time period is less than or equal to one second.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the preselected distance of the first physical control device is within about 0.5 inch.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A vehicle user interface system comprising:
<claim-text>a display device;</claim-text>
<claim-text>a first physical control device operable to modify operation of a first vehicle system;</claim-text>
<claim-text>a second physical control device operable to modify operation of a second vehicle system;</claim-text>
<claim-text>a processor electrically coupled to the display device and the first and second physical control devices;</claim-text>
<claim-text>a first sensor at or near the first physical control device that detects the presence of a hand of an occupant within a preselected distance of the first physical control device and provides a signal to the processor upon detecting presence of the hand within the preselected distance of the first physical control device; and</claim-text>
<claim-text>a second sensor at or near the second physical control device that detects the presence of a hand of an occupant within a preselected distance of the second physical control device and provides a signal to the processor upon detecting presence of the hand within the preselected distance of the second physical control device;</claim-text>
<claim-text>wherein the processor:
<claim-text>determines information of interest associated with the vehicle system to display on the display device based on the signal provided by the first sensor or the second sensor;</claim-text>
<claim-text>instructs the display device to display the information of interest; and</claim-text>
<claim-text>modifies the information of interest displayed on the display device based on occupant manipulation of the first physical control device or the second physical control device.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first sensor is a proximity sensor.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the display device is a touchscreen display, the touchscreen display comprising inputs configured to modify the information of interest displayed on the touchscreen display.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the inputs of the touchscreen display are configured to modify operation of the vehicle system.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first physical control is located on a steering wheel or steering wheel column, or dash console.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the preselected distance of the first physical control device is within about 0.5 inch.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first sensor is a capacitive sensor. </claim-text>
</claim>
</claims>
</us-patent-grant>
