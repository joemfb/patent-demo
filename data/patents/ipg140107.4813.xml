<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625906-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625906</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13142812</doc-number>
<date>20091228</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2008-335779</doc-number>
<date>20081229</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>148</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>62</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>54</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382224</main-classification>
<further-classification>382305</further-classification>
</classification-national>
<invention-title id="d2e71">Image classification standard update method, program, and image classification device</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5526258</doc-number>
<kind>A</kind>
<name>Bacus</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382129</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7113628</doc-number>
<kind>B1</kind>
<name>Obara et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7634141</doc-number>
<kind>B2</kind>
<name>Hayashi et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>8176050</doc-number>
<kind>B2</kind>
<name>Inakoshi et al.</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707737</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2005/0152592</doc-number>
<kind>A1</kind>
<name>Kasai</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0025611</doc-number>
<kind>A1</kind>
<name>Kanda et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382149</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>08-021803</doc-number>
<kind>A</kind>
<date>19960100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>2001-156135</doc-number>
<kind>A</kind>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>2005-185560</doc-number>
<kind>A</kind>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2005-309535</doc-number>
<kind>A</kind>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>Written Opinion of the International Searching Authority (PCT/ISA/237) issued in PCT/JP2009/071774 with English Translation dated Mar. 23, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>International Search Report issued in PCT/JP2009/071774 dated Mar. 23, 2010 with English Translation.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>18</number-of-claims>
<us-exemplary-claim>15</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382141</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382149</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382224</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382294</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382305</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>13</number-of-drawing-sheets>
<number-of-figures>15</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110274362</doc-number>
<kind>A1</kind>
<date>20111110</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Isomae</last-name>
<first-name>Yuya</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Endo</last-name>
<first-name>Fumiaki</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Funakoshi</last-name>
<first-name>Tomohiro</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Konishi</last-name>
<first-name>Junko</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sakai</last-name>
<first-name>Tsunehiro</first-name>
<address>
<city>Mito</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Isomae</last-name>
<first-name>Yuya</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Endo</last-name>
<first-name>Fumiaki</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Funakoshi</last-name>
<first-name>Tomohiro</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Konishi</last-name>
<first-name>Junko</first-name>
<address>
<city>Hitachinaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Sakai</last-name>
<first-name>Tsunehiro</first-name>
<address>
<city>Mito</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>McDermott Will &#x26; Emery LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hitachi High-Technologies Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Mariam</last-name>
<first-name>Daniel</first-name>
<department>2665</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP2009/071774</doc-number>
<kind>00</kind>
<date>20091228</date>
</document-id>
<us-371c124-date>
<date>20110629</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2010/076882</doc-number>
<kind>A </kind>
<date>20100708</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The objective is to improve a classification standard. Classification standard data, in which is registered image data information that is the standard when image data is classified, and classification data, in which is registered image data information that is the result when newly input image data is classified using the classification standard data, are stored in a storage unit. An image classification device is characterized in that when any image data information of the image data that is registered in the classification data is selected by means of an input unit, and an instruction to additionally register the selected image data information in the classification standard data is input by means of the input unit, the selected image data information is additionally registered in the classification standard data.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="98.81mm" wi="140.21mm" file="US08625906-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="211.75mm" wi="144.95mm" file="US08625906-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="110.41mm" wi="141.39mm" file="US08625906-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="186.61mm" wi="151.05mm" file="US08625906-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="187.54mm" wi="130.89mm" file="US08625906-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="237.74mm" wi="154.77mm" file="US08625906-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="218.27mm" wi="156.63mm" orientation="landscape" file="US08625906-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="217.51mm" wi="161.04mm" orientation="landscape" file="US08625906-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="220.30mm" wi="159.51mm" orientation="landscape" file="US08625906-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="200.32mm" wi="154.77mm" file="US08625906-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="228.77mm" wi="131.23mm" file="US08625906-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="217.17mm" wi="159.43mm" orientation="landscape" file="US08625906-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="226.40mm" wi="156.55mm" orientation="landscape" file="US08625906-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="230.97mm" wi="157.82mm" orientation="landscape" file="US08625906-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is the U.S. National Phase under 35 U.S.C. &#xa7;371 of International Application No. PCT/JP2009/071774, filed on Dec. 28, 2009, which in turn claims the benefit of Japanese Application No. 2008-335779, filed on Dec. 29, 2008, the disclosures of which Applications are incorporated by reference herein.</p>
<heading id="h-0002" level="1">TECHNICAL FIELD</heading>
<p id="p-0003" num="0002">The present invention relates to a technology of a method and a program for updating an image classification standard, and relates to an image classification device.</p>
<heading id="h-0003" level="1">BACKGROUND ART</heading>
<p id="p-0004" num="0003">During a process of manufacturing semiconductor products, it is concerned that short circuit may occur on a formed circuit pattern because foreign matter or the like is generated, or a defect such as breaking of wire, and a defect due to a problematic of conditions of a manufacturing process, and the like. In order to improve the product yield ratio, it is necessary to identify the root cause of such a defect at an early stage and to take countermeasures. For this purpose, it is necessary to inspect the semiconductor wafer for foreign matter adhered on a wafer surface and pattern defects formed on the wafer surface by using a device for inspecting foreign matter on semiconductor wafers or a visual inspection device for semiconductor wafers, and thereby continuously monitor occurrence of such defects and take measures to find the causes of such defects, based on inspection results.</p>
<p id="p-0005" num="0004">Conventionally, such inspection has been carried out visually by a person. Accordingly, classification of detects of observation objects is biased, depending on an inspector. In order to solve this problem, in recent years, technologies for ADR (automatic defect review) and ADC (automatic defect classification), in which a device automatically performs determination of the size, the shape, the kind, and the like of a defect using an image processing technology, have come to be introduced. For example, in order to observe, in another word, review inspected parts (for example, patterns formed on wafers) by using an SEM (scanning electron microscopy) review device, a system that efficiently performs a task while reducing the workload of a user is proposed.</p>
<p id="p-0006" num="0005">As a method for extracting information included in an inspection image as characteristic amounts and performing automatic classification based on the characteristic amounts, a method using a neural network is disclosed (for example, refer to Patent Document 1). Further, in order to reduce effects of inappropriate characteristic amounts on the classification performance in learning (weighting of respective characteristic amounts) for creating a classification standard for performing automatic classification, a method that automatically selects characteristic amounts that are effective for classification is disclosed (for example, refer to Patent Document 2).</p>
<heading id="h-0004" level="1">PRIOR ART DOCUMENTS</heading>
<heading id="h-0005" level="1">Patent Documents</heading>
<p id="p-0007" num="0000">
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0006">Patent Document 1: JP H08-021803 A</li>
    <li id="ul0001-0002" num="0007">Patent Document 2: JP 2005-309535 A</li>
</ul>
</p>
<heading id="h-0006" level="1">DISCLOSURE OF INVENTION</heading>
<heading id="h-0007" level="1">Technical Problem</heading>
<p id="p-0008" num="0008">In the technology described in Patent Document 1, a classification standard for automatic defect classification using a neural network learns based on visual classification by human eyes. Consequently, if an inspector makes a classification error, there may be a contradiction in the classification standard, resulting in a drop in the classification performance for automatic defect classification. That is, learning is performed via a neural network, based on a classification standard as a result of visual classification, which causes problems that a classification standard with errors is created, and a learning result outputs a result with errors.</p>
<p id="p-0009" num="0009">Furthermore, in some cases, a desirable classification cannot be performed, since a defect having one type of characteristic may have another type of characteristic if a semiconductor-manufacturing process varies after a currently effective classification standard was created. That is, it is necessary to perform learning each time when a defect of a type that has not been registered in a classification standard is detected.</p>
<p id="p-0010" num="0010">The technology described in Patent Document 2 does not include a technology for updating a once-created classification standard and thereby improving the classification standard.</p>
<p id="p-0011" num="0011">The present invention has been developed in view of the foregoing background, and an object of the invention is to improve a classification standard.</p>
<heading id="h-0008" level="1">Technical Solution</heading>
<p id="p-0012" num="0012">In order to solve the above-described problem, the present invention is a method for updating an image classification standard by using an image classification device for classifying image data, wherein a storage section stores classification standard data in which information on image data to be a standard for classifying image data is registered, and classification data in which information on image data as a result of classification of newly input image data using the classification standard data is registered, and wherein, when information on arbitrary image data is selected via an input section from the image data registered in the classification data, and an instruction is input via the input section to additionally register the selected information on image data into the classification standard data, the image classification device additionally registers the selected information on image data into the classification standard data.</p>
<p id="p-0013" num="0013">Other solutions will be described later in embodiments.</p>
<heading id="h-0009" level="1">Advantageous Effects</heading>
<p id="p-0014" num="0014">The present invention can improve a classification standard.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0010" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0015" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram showing an example of the configuration of a semiconductor wafer manufacturing system in the present embodiment;</p>
<p id="p-0016" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram showing the flow of data in a semiconductor wafer manufacturing system in the present embodiment;</p>
<p id="p-0017" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram showing an example of the configuration of a review device in the present embodiment;</p>
<p id="p-0018" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram showing an example of classification standard data and classification data;</p>
<p id="p-0019" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram showing an example of standard characteristic amount data and characteristic amount data;</p>
<p id="p-0020" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart showing the procedure of a process for creating a classification standard in the present embodiment;</p>
<p id="p-0021" num="0021"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart showing the procedure of a process for self-checking in the present embodiment;</p>
<p id="p-0022" num="0022"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram showing an example of a self-check screen (initial screen) in the present embodiment;</p>
<p id="p-0023" num="0023"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram showing an example of a self-check screen (image comparison) in the present embodiment;</p>
<p id="p-0024" num="0024"><figref idref="DRAWINGS">FIG. 10</figref> is a diagram showing an example of a self-check screen (characteristic comparison) in the present embodiment;</p>
<p id="p-0025" num="0025"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing the procedure of a process executed upon newly obtaining defect image data;</p>
<p id="p-0026" num="0026"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing the procedure of a check process in the present embodiment;</p>
<p id="p-0027" num="0027"><figref idref="DRAWINGS">FIG. 13</figref> is a diagram showing an example of a check screen (image comparison) in the present embodiment;</p>
<p id="p-0028" num="0028"><figref idref="DRAWINGS">FIG. 14</figref> is a diagram showing an example of a check screen (characteristic amount comparison) in the present embodiment; and</p>
<p id="p-0029" num="0029"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram showing an example of a check screen (simulation) in accordance with the present embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0011" level="1">BEST MODES FOR CARRYING OUT THE INVENTION</heading>
<p id="p-0030" num="0030">Modes for carrying out the present invention (referred to as &#x201c;embodiments&#x201d;) will be described below, referring to the drawings, as appropriate. In the preset embodiment, an example will be described where an image classification device is applied to a semiconductor wafer manufacturing system Z, however, the invention is not limited thereto and is applicable to systems that perform defect inspection using images, such as image inspection of foods.</p>
<p id="p-0031" num="0031"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram showing an example of the configuration of a semiconductor wafer manufacturing system in the present embodiment.</p>
<p id="p-0032" num="0032">Manufacturing devices <b>4</b> for manufacturing semiconductor wafers are normally set in a clean room <b>7</b> where clean environment is maintained. Further, semiconductor wafers manufactured on the line of the manufacturing devices <b>4</b> are subjected to a conduction test by a probe inspection device <b>5</b>.</p>
<p id="p-0033" num="0033">In the clean room <b>7</b>, there are provided appearance inspection devices <b>2</b> for detecting appearance defects of produced wafers, and review devices <b>1</b> (image classification device) for observation of the appearance defects, in another word, reviewing, based on data from the appearance inspection devices <b>2</b>. Further, outside the clean room <b>7</b>, provided is a data processing device <b>3</b> that performs processing of image data having been obtained by the appearance inspection devices <b>2</b> or the review devices <b>1</b>. The appearance inspection device <b>2</b>, the review device <b>1</b>, the probe inspection device <b>5</b>, and the data processing device <b>3</b> are connected with each other via a communication line <b>6</b>.</p>
<p id="p-0034" num="0034"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram showing the flow of data in the semiconductor wafer manufacturing system in the present embodiment. In <figref idref="DRAWINGS">FIG. 2</figref>, elements same as those in <figref idref="DRAWINGS">FIG. 1</figref> are given with the same symbols, and description will be omitted.</p>
<p id="p-0035" num="0035">The review device <b>1</b> includes a plurality of optical review devices <b>1</b><i>a </i>and a plurality of SEM review devices <b>1</b><i>b</i>. The optical review devices <b>1</b><i>a </i>obtain defect image data, that are data of defect images on semiconductor wafers, obtained by a digital camera connected with an optical microscope, and analyze the defect image data. The SEM review devices <b>1</b><i>b </i>obtain defect image data captured by an electronic microscope, and analyze the defect image data. The appearance inspection devices <b>2</b>, the optical review devices <b>1</b><i>a</i>, and the SEM review devices <b>1</b><i>b </i>are respectively arranged in plural number, and plural defect image data can be simultaneously obtained.</p>
<p id="p-0036" num="0036">Semiconductor wafers, which are to become products, flow by lot unit through a plurality of manufacturing devices <b>4</b> (<figref idref="DRAWINGS">FIG. 1</figref>). After completion of a process in which appearance inspection of semiconductor wafers is scheduled in advance, a worker or a conveying machine conveys the semiconductor wafers to the appearance inspection device <b>2</b>, and appearance inspection processing is performed. The appearance inspection device <b>2</b> captures the images of the appearance of the semiconductor wafers, and if an appearance defect is detected, the appearance inspection device <b>2</b> obtains the coordinates of the position of the detected appearance defect as defect data, and transmits the obtained defect data to the data processing device <b>3</b> (S<b>101</b>).</p>
<p id="p-0037" num="0037">Because the amount of defect data that the appearance inspection device <b>2</b> outputs is huge, the data processing device <b>3</b> transmits defect data having been filtered by a filter function to an optical review devices <b>1</b><i>a </i>or an SEM review devices <b>1</b><i>b </i>via the communication line <b>6</b> (S<b>102</b>, S<b>103</b>). The filtering function includes, for example, extraction of a predetermined number of pieces of detect information at random.</p>
<p id="p-0038" num="0038">The optical review devices <b>1</b><i>a </i>or the SEM review devices <b>1</b><i>b </i>capture the images at the coordinate positions according to the transmitted defect information by using an optical microscope or an electronic microscope, and obtain the images of the semiconductor wafers at the portions of the detected defects (defect image data) of the semiconductor wafers. The optical review devices <b>1</b><i>a </i>and the SEM review devices <b>1</b><i>b </i>perform classification of defects by using an ADC function implemented therein. Information on results of such defect classification is transmitted as ADR/ADC information via the communication line <b>6</b> to the data processing device <b>3</b> (S<b>104</b>, S<b>105</b>). In the present embodiment, described is a technology related to a review device <b>1</b> (optical review devices <b>1</b><i>a</i>, SEM review devices <b>1</b><i>b</i>).</p>
<p id="p-0039" num="0039"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram showing an example of the configuration of a review device in the present embodiment. In the present embodiment, an example is shown where an SEM review device <b>1</b><i>b </i>is assumed to be a review device <b>1</b>, however, the invention is not limited thereto, and may be applied to an optical review device <b>1</b><i>a. </i></p>
<p id="p-0040" num="0040">A review device <b>1</b> includes an input section <b>13</b>, such as a keyboard or a mouse, a display section <b>14</b>, such as a display, a transmitting/receiving section <b>15</b>, such as a communication interface card, a processing section <b>11</b> for processing information, and a storage section <b>12</b> for storing information.</p>
<p id="p-0041" num="0041">The processing section <b>11</b> includes a display processing section <b>111</b>, an input processing section <b>112</b>, an automatic defect classification section <b>113</b>, a characteristic amount extraction section <b>114</b>, and a data obtaining section <b>115</b>. The display processing section <b>111</b> has a function of processing information and display the processed information on the display section <b>14</b>. The input processing section <b>112</b> has a function of processing the information having been input from the input section <b>13</b>. The automatic defect classification section <b>113</b> has a function of classifying defect image data by using ADC. The characteristic amount extraction section <b>114</b> has a function of extracting the characteristic amounts of respective defect image data. The data obtaining section <b>115</b> has a function of obtaining data from the transmitting/receiving section <b>15</b>.</p>
<p id="p-0042" num="0042">The processing section <b>11</b> and the respective sections <b>111</b> to <b>115</b> are realized by executing a program stored in a ROM (read only memory), not shown, or a HD (hard disk), not shown, is loaded into a RAM (random access memory), not shown, by a CPU (central processing unit), not shown.</p>
<p id="p-0043" num="0043">The storage section <b>12</b> stores classification standard data <b>121</b>, classification data <b>122</b>, a defect image data group <b>123</b>, standard characteristic amount data <b>124</b>, and characteristic amount data <b>125</b>. The classification standard data <b>121</b>, the classification data <b>122</b>, the standard characteristic amount data <b>124</b>, and the characteristic amount data <b>125</b> will be described later, referring to <figref idref="DRAWINGS">FIGS. 4 and 5</figref>. The defect image data group <b>123</b> are defect image data captured by the review device <b>1</b>.</p>
<p id="h-0012" num="0000">Various Data</p>
<p id="p-0044" num="0044"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram showing an example of classification standard data and classification data. Herein, the classification standard data <b>121</b> are data created by a process, which will be described later with reference to <figref idref="DRAWINGS">FIG. 6</figref>, and the classification data <b>122</b> are data created by a process, which will be described later with reference to <figref idref="DRAWINGS">FIG. 11</figref>. Although the classification standard data <b>121</b> and the classification data <b>122</b> are different in terms of stored data, the formats are similar to each other and will be commonly described below, referring to <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0045" num="0045">As shown in <figref idref="DRAWINGS">FIG. 4</figref>, the classification standard data <b>121</b> and the classification data <b>122</b> have a field for categories categorized by user, a field for categories categorized by ADC, and a field for the names of defect image data. The categories by user refer to categories classified by a user in S<b>202</b> in <figref idref="DRAWINGS">FIG. 6</figref> (or later-described S<b>403</b> in <figref idref="DRAWINGS">FIG. 11</figref>). The categories by ADC are those classified by ADC processing in later-described S<b>205</b> in <figref idref="DRAWINGS">FIG. 6</figref> (or later-described S<b>401</b> in <figref idref="DRAWINGS">FIG. 11</figref>). In the example shown in <figref idref="DRAWINGS">FIG. 4</figref>, it is shown that defect image data having been determined to be &#x201c;C<b>1</b>: particle&#x201d; by a user and determined to be &#x201c;C<b>1</b>: particle&#x201d; also by ADC processing are &#x201c;A<b>1</b>.jpg, A<b>2</b>.jpg, A<b>3</b>.jpg, . . . &#x201d;. Further, it is shown that there is no defect image data that has been determined to be &#x201c;C<b>1</b>: particle&#x201d; by the user and determined to be &#x201c;C<b>2</b>: scratch&#x201d; by ADC processing. Further, it is shown that defect image data that has been determined to be &#x201c;C<b>2</b>: scratch&#x201d; by the user and determined to be &#x201c;C<b>1</b>: particle&#x201d; by ADC processing is &#x201c;A<b>10</b>.jpg&#x201d;.</p>
<p id="p-0046" num="0046">Herein, &#x201c;C<b>1</b>&#x201d;, &#x201c;C<b>2</b>&#x201d;, and the like are identification numbers assigned to categories. In the present embodiment, &#x201c;C<b>1</b>&#x201d; represents particle, &#x201c;C<b>2</b>&#x201d; represents scratch, &#x201c;C<b>3</b>&#x201d; represents pattern short, &#x201c;C<b>4</b>&#x201d; represents pattern open, and &#x201c;C<b>5</b>&#x201d; represents no defect. In the present embodiment, these identification numbers will be used, as appropriate, instead of category names. In addition to these, it is possible to freely set categories, such as to be critical foreign matter, non-critical foreign matter, and false information, without particularly considering image processing or a characteristic amount. That is, the user can freely set category names.</p>
<p id="p-0047" num="0047">The classification standard data <b>121</b> and the classification data <b>122</b> may include data related to every possible combination of categories by a user and by ADC, or may include only data related to combinations of categories in which corresponding defect image data actually exists. That is, for example, as shown in line <b>2</b> in <figref idref="DRAWINGS">FIG. 4</figref>, records having no corresponding defect image may be omitted. Further, each defect image data may have a format to which information of a category by user and information of a category by ADC are added.</p>
<p id="p-0048" num="0048"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram showing an example of standard characteristic amount data and characteristic amount data. Herein, the standard characteristic amount data <b>124</b> is data created by a later-described process with reference to <figref idref="DRAWINGS">FIG. 6</figref>, and the characteristic amount data <b>125</b> is data created by a later-described process with reference to <figref idref="DRAWINGS">FIG. 11</figref>. Although the standard characteristic amount data <b>124</b> and the characteristic amount data <b>125</b> are different from each other in terms of data to be stored, their formats are the same; therefore, these data will be explained referring to <figref idref="DRAWINGS">FIG. 5</figref>. As shown in <figref idref="DRAWINGS">FIG. 5</figref>, the standard characteristic amount data <b>124</b> and the characteristic amount data <b>125</b> each having a defect image data name have characteristic amounts of flatness, brightness, circularity, size, etc.</p>
<p id="p-0049" num="0049">The process for creating a classification standard will be explained below, based on <figref idref="DRAWINGS">FIG. 6</figref>, referring to <figref idref="DRAWINGS">FIGS. 3</figref>, <b>4</b> and <b>5</b>.</p>
<p id="p-0050" num="0050"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart showing the process for creating a classification standard in the present embodiment. In the process for creating a classification standard as shown in <figref idref="DRAWINGS">FIG. 6</figref> is a process for creating the classification standard data <b>121</b>.</p>
<p id="p-0051" num="0051">First, the processing section <b>11</b> reads defect image data for creating a classification standard, from the defect image data group <b>123</b> in the storage section <b>12</b> (S<b>201</b>).</p>
<p id="p-0052" num="0052">Then, the user classifies the defect image data obtained via the input section <b>13</b> (S<b>202</b>). For example, the user visually classifies the defect image data one by one into kinds, such as particle, scratch, and the like. By the process in S<b>202</b>, initial classification standard data <b>121</b> is created.</p>
<p id="p-0053" num="0053">In the step of S<b>202</b>, only the column of categories by the user is filled in, while the column of categories by ADC is blank.</p>
<p id="p-0054" num="0054">Subsequent to S<b>202</b>, the characteristic amount extraction section <b>114</b> automatically adjusts defect recognition parameters (for example, detection sensitivity, noise removing threshold, protrusion/recession threshold) for extracting characteristic amounts from the defect image data (S<b>203</b>). Herein, the following operation is performed. In recognizing a defect portion and extracting a characteristic amount, the characteristic amount extraction section <b>114</b> compares normal image data with defect image data, and then extracts the defect portion. In this state, in order not to erroneously extract a noise on an image as a defect portion, the characteristic amount extraction section <b>114</b> removes a noise at a certain level, and in order not to erroneously extract a portion that appears bright due to light as a defect portion, the characteristic amount extraction section <b>114</b> adjusts the detection sensitivity. The process in S<b>203</b> is a technology described in JP 2007-198968 A and others, and accordingly description will be omitted.</p>
<p id="p-0055" num="0055">Then, after extracting defect potions, the characteristic amount extraction section <b>114</b> extracts the characteristic amounts of these defect patterns, and determines how to weight the extracted characteristic amounts when performing ADC (S<b>204</b>). Extracting the characteristic amounts means calculating physical characteristics having been set and quantified in advance for each defect image data. As the physical characteristics, flatness, brightness, circularity, size, as described above, and in addition, height, shape, color, texture, defect, background, and the like can be considered. The characteristic amount extraction section <b>114</b> stores the extracted characteristic amounts in the storage section <b>12</b> as standard characteristic amount data <b>124</b>.</p>
<p id="p-0056" num="0056">Subsequent to S<b>204</b>, the automatic defect classification section <b>113</b> performs ADC processing (S<b>205</b>) by using the characteristic amounts extracted in S<b>204</b> and the determined weight, and classifies the defect image data by ADC. The ADC process is a technology described in JP H09-101970 and the like, and description in detail will be omitted.</p>
<p id="p-0057" num="0057">Then, the automatic defect classification section <b>113</b> reflects a result of the ADC process into the classification standard data <b>121</b> (<figref idref="DRAWINGS">FIG. 4</figref>) (S<b>206</b>). The automatic defect classification section <b>113</b> registers the result of the classification in S<b>205</b> into the column, which was blank at the step of S<b>202</b>, as a category by ADC. More specifically, the automatic defect classification section <b>113</b> further classifies the classification made at the step of S<b>202</b> for more details. For example, it will be assumed that &#x201c;A<b>20</b>.jpg&#x201d;, &#x201c;A<b>21</b>.jpg&#x201d;, and &#x201c;A<b>22</b>.jpg&#x201d;, not shown in the drawings, had been determined to be &#x201c;C<b>3</b>: pattern short&#x201d; in S<b>202</b> (classification by the user), however, in S<b>205</b> (classification by ADC), &#x201c;A<b>20</b>.jpg&#x201d; has been determined to be &#x201c;C<b>1</b>: particle&#x201d;, and &#x201c;A<b>21</b>.jpg&#x201d; and &#x201c;A<b>22</b>.jpg&#x201d; have been determined to be&#x201c;C<b>3</b>: pattern short&#x201d;. In this case, &#x201c;A<b>20</b>.jpg&#x201d; is classified to be &#x201c;C<b>3</b>: pattern short&#x201d; as category determined by the user and to be &#x201c;C<b>1</b>: particle&#x201d; as category by ADC, while &#x201c;A<b>21</b>.jpg&#x201d; and &#x201c;A<b>22</b>.jpg&#x201d; are classified to be &#x201c;C<b>3</b>: pattern short&#x201d; as category by the user, and to be &#x201c;C<b>3</b>: pattern short&#x201d; as category by ADC.</p>
<p id="p-0058" num="0058">Incidentally, in case that the classification standard data <b>121</b> is not a type as shown in <figref idref="DRAWINGS">FIG. 4</figref>, but a type in which a category names are given to each image data, it is merely required to add the category names as a result of classification in S<b>205</b> to the corresponding defect image data.</p>
<p id="p-0059" num="0059">Then, the display processing section <b>111</b> displays a self-check screen <b>200</b>, shown in <figref idref="DRAWINGS">FIG. 8</figref>, on the display section <b>14</b> (S<b>207</b>), and the user performs self-check via the self-check screen <b>200</b> (S<b>208</b>). Self-check will be described later, referring to <figref idref="DRAWINGS">FIGS. 8 to 10</figref>.</p>
<p id="p-0060" num="0060">Then, from a result of the self-check, the user determines as to whether or not the classification of the classification standard data <b>121</b> is adequate (S<b>209</b>).</p>
<p id="p-0061" num="0061">As a result of S<b>209</b>, if it is determined to be inadequate (determined that the classification of the classification standard data <b>121</b> is inappropriate) (S<b>209</b>&#x2192;No), a change is reflected into the classification standard data <b>121</b> and then the process returns to S<b>203</b> to extract characteristic amounts. Then, the display processing section <b>111</b> again performs ADC processing, and displays a result as a self-check screen.</p>
<p id="p-0062" num="0062">As a result of S<b>209</b>, if it is determined to be adequate (determined that the classification of the classification standard data <b>121</b> is appropriate) (S<b>209</b>&#x2192;Yes), then the process is terminated.</p>
<p id="p-0063" num="0063">The procedure of a self-check process will be described below, based on <figref idref="DRAWINGS">FIG. 7</figref> and referring to <figref idref="DRAWINGS">FIG. 3</figref> and <figref idref="DRAWINGS">FIGS. 8 to 10</figref>.</p>
<p id="p-0064" num="0064"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart showing the process for self-checking in the present embodiment.</p>
<p id="p-0065" num="0065">The process, shown in <figref idref="DRAWINGS">FIG. 7</figref>, is a process corresponding to S<b>207</b> to S<b>209</b> in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0066" num="0066">First, the display processing section <b>111</b> generates a confusion matrix <b>211</b> (association information between categories), and displays a self-check screen <b>200</b><i>a </i>(<figref idref="DRAWINGS">FIG. 8</figref>) including the generated confusion matrix <b>211</b> (S<b>301</b>).</p>
<p id="p-0067" num="0067"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram showing an example of a self-check screen (initial screen) in the present embodiment.</p>
<p id="p-0068" num="0068">The self-check screen <b>200</b><i>a </i>(<b>200</b>) includes a confusion matrix display area <b>201</b>, a defect image list display area <b>202</b>, and a defect image confirmation area <b>203</b>, which are displayed in the same window.</p>
<p id="p-0069" num="0069">In the confusion matrix display area <b>201</b>, a confusion matrix <b>211</b> is displayed. The confusion matrix <b>211</b> is a table that indicates the numbers of images in the respective categories according to the classification by the user (represented by &#x201c;Manual&#x201d; in <figref idref="DRAWINGS">FIG. 8</figref>), and the respective categories according to the classification by ADC (represented by &#x201c;ADC&#x201d; in <figref idref="DRAWINGS">FIG. 8</figref>).</p>
<p id="p-0070" num="0070">Symbols C<b>1</b> to C<b>5</b> are, as described above, category identification numbers, wherein &#x201c;C<b>1</b>&#x201d; represents particle, &#x201c;C<b>2</b>&#x201d; represents scratch, &#x201c;C<b>3</b>&#x201d; represents pattern short, &#x201c;C<b>4</b>&#x201d; represents pattern open, and &#x201c;C<b>5</b>&#x201d; represents no defect.</p>
<p id="p-0071" num="0071">In the example in <figref idref="DRAWINGS">FIG. 8</figref>, the vertical axis represents categories according to classification by the user (&#x201c;Manual&#x201d;), and the horizontal axis represents categories according to classification by ADC.</p>
<p id="p-0072" num="0072">For example, regarding line <b>1</b> of the confusion matrix <b>211</b>, 38 (34+4) defect image data are determined to be C<b>1</b> (particle) according to the classification (&#x201c;Manual&#x201d;) by the user, while <b>34</b> defect image data among them are determined to be C<b>1</b> (particle) and <b>4</b> defect image data among them are determined to be C<b>3</b> (pattern short) according to the classification by ADC. A correct result ratio is the ratio of a classification result by ADC that agrees with a classification result by user, to the classification result by the user. For example, the correct result ratio of line <b>1</b> is 34/38&#xd7;100&#x2245;89 (%).</p>
<p id="p-0073" num="0073">Likewise, regarding row <b>1</b> in the confusion matrix <b>211</b> in <figref idref="DRAWINGS">FIG. 8</figref>, it is recognized that 37 (34+1+2) defect image data are determined to be C<b>1</b> (particle) by ADC, while one defect image data is determined to be C<b>2</b> (scratch) and two defect image data are determined to be C<b>5</b> (no defect) by the user. A purity ratio is the agreement ratio of a result of classification by user to a result of classification by ADC. For example, the purity ratio of row <b>1</b> is 34/37&#xd7;100&#x2245;92 (%).</p>
<p id="p-0074" num="0074">The elements having a reference symbol <b>212</b> (the central oblique line) in the confusion matrix <b>211</b> represent the numbers of defect image data in which classification by user conforms with classification by ADC for the respective categories. Further, symbol <b>213</b> represents the ratio of the number of defect image data, in which classification by user conforms with classification by ADC, to the total number of all defect image data.</p>
<p id="p-0075" num="0075">When a matrix button <b>214</b> in the input section <b>13</b> is selected and entered, the display processing section <b>111</b> counts the numbers of defect image data in the respective categories, referring to the classification standard data <b>121</b>, shown in <figref idref="DRAWINGS">FIG. 4</figref>, and displays the counted numbers in the confusion matrix <b>211</b>.</p>
<p id="p-0076" num="0076">Herein, the display processing section <b>111</b> monitors whether or not a cell of the confusion matrix <b>211</b> has been selected (S<b>302</b> in <figref idref="DRAWINGS">FIG. 7</figref>).</p>
<p id="p-0077" num="0077">When no cell is selected (S<b>302</b>&#x2192;No), the display processing section <b>111</b> forwards the process to S<b>304</b>. In <figref idref="DRAWINGS">FIG. 7</figref> and in <figref idref="DRAWINGS">FIG. 12</figref>, if the process moves forward to the step No. Sm when no selection input is made in step No. Sn, it means that the processing section <b>11</b> determines nothing and executes the process of the step Sm. This is because, the steps in <figref idref="DRAWINGS">FIG. 7</figref> and <figref idref="DRAWINGS">FIG. 12</figref> are actually image processing steps, and each step is executed when an instruction is input, regardless of the order of the steps shown in the drawings.</p>
<p id="p-0078" num="0078">If the user selects one of the cells in the confusion matrix <b>211</b> (S<b>302</b>&#x2192;Yes, in <figref idref="DRAWINGS">FIG. 7</figref>), then a defect image corresponding to the selected cell is displayed in the defect image list display area <b>202</b> (S<b>303</b> in <figref idref="DRAWINGS">FIG. 7</figref>).</p>
<p id="p-0079" num="0079">For example, if a cell <b>215</b>, whose category is C<b>3</b> (pattern short) according to classification by user (&#x201c;Manual&#x201d;) and is also C<b>3</b> (pattern short) according to Classification by ADC, is selected and entered via the input section <b>13</b>, then the display processing section <b>111</b> obtains, from the classification standard data <b>121</b> in <figref idref="DRAWINGS">FIG. 4</figref>, the names of defect image data stored in the records of both categories by the user and ADC &#x201c;C<b>3</b>: pattern short&#x201d;. Then, the display processing section <b>111</b> obtains, from the defect image data group <b>123</b> (<figref idref="DRAWINGS">FIG. 3</figref>) in the storage section <b>12</b>, image data corresponding to the obtained name of defect image data, and displays the obtained image data in the defect image list display area <b>202</b>.</p>
<p id="p-0080" num="0080">Incidentally, in <figref idref="DRAWINGS">FIG. 8</figref>, as &#x201c;12&#x201d; is described in cell <b>215</b>, the number of images displayed in the defect image list display area <b>202</b> is also 12. The user can refer to 12 images by moving the slide bar in the defect image list display area <b>202</b> shown in <figref idref="DRAWINGS">FIG. 8</figref>.</p>
<p id="p-0081" num="0081">In the defect image confirmation area <b>203</b>, nothing is displayed at the step of S<b>303</b>. A save button <b>205</b> and a delete button <b>206</b> will be described later.</p>
<p id="p-0082" num="0082">In order to create accurate classification standard data <b>121</b> and thereby improve the accuracy of classification by ADC, it is necessary to improve the purity ratio and the correct result ratio in the confusion matrix <b>211</b>.</p>
<p id="p-0083" num="0083">A method for updating the classification standard data <b>121</b> for improving the purity ratio and the correct result ratio will be described below, referring to <figref idref="DRAWINGS">FIGS. 9 and 10</figref>. Incidentally, in <figref idref="DRAWINGS">FIGS. 9 and 10</figref>, elements that are similar to those in <figref idref="DRAWINGS">FIG. 8</figref> are given with the same symbols, and description will be omitted.</p>
<p id="p-0084" num="0084"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram showing an example of a self-check screen (image comparison) according to the present embodiment.</p>
<p id="p-0085" num="0085">In <figref idref="DRAWINGS">FIG. 9</figref>, an example is shown where, in the confusion matrix <b>211</b>, a cell <b>301</b> whose classification by user (&#x201c;Manual&#x201d;) is &#x201c;C<b>1</b>: particle&#x201d; and whose classification by ADC (&#x201c;ADC&#x201d;) is &#x201c;C<b>3</b>: pattern short&#x201d; is selectively input.</p>
<p id="p-0086" num="0086">The display processing section <b>111</b> determines whether or not a defect image displayed in the defect image list display area <b>202</b> has been selected (S<b>304</b> in <figref idref="DRAWINGS">FIG. 7</figref>). If no defect image has been selected (S<b>304</b>&#x2192;No), then the display processing section <b>111</b> proceeds the process to S<b>307</b> in <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0087" num="0087">If the user drags and drops a defect image <b>311</b><i>a </i>from defect images displayed in the defect image list display area <b>202</b> to the defect image confirmation area <b>203</b> (S<b>304</b>&#x2192;Yes, in <figref idref="DRAWINGS">FIG. 7</figref>), then the dragged and dropped defect image <b>311</b><i>a </i>is copied to an object image display area <b>330</b> in a image comparison area <b>320</b> in the defect image confirmation area <b>203</b>, and enlarged and displayed as a defect image <b>311</b><i>b. </i></p>
<p id="p-0088" num="0088">Further, in a comparison image display area <b>340</b>, defect images <b>342</b>, which belong to a category selected via a category selection pull-down menu <b>341</b>, are displayed. A category which is selected via the category selection pull-down-menu <b>341</b> is a category according to classification by user. If the user wishes to compare images in a category with images in another category, the user selects said another category by using the category selection pull-down-menu <b>341</b> via the input section <b>13</b>.</p>
<p id="p-0089" num="0089">More specifically, the display processing section <b>111</b> determines whether or not a category has been selected by the category selection pull-down-menu <b>341</b> (S<b>305</b> in <figref idref="DRAWINGS">FIG. 7</figref>). If no category has been selected (S<b>305</b>&#x2192;No), then the display processing section <b>111</b> proceeds the process to S<b>307</b>.</p>
<p id="p-0090" num="0090">If a category is selected by the category selection pull-down-menu <b>341</b> (S<b>305</b>&#x2192;Yes, in <figref idref="DRAWINGS">FIG. 7</figref>), then the display processing section <b>111</b> refers to the classification standard data <b>121</b> in <figref idref="DRAWINGS">FIG. 4</figref>, with a key of the selected category, and thereby obtains the names of defect image data stored in all records corresponding to the selected category with classification by user. Then, the display processing section <b>111</b> obtains defect image data corresponding to the obtained names of defect image data from the defect image data group <b>123</b> (<figref idref="DRAWINGS">FIG. 3</figref>) in the storage section <b>12</b>, and displays the obtained defect image data in the comparison image display area <b>340</b> as comparison images in the corresponding category (S<b>306</b> in <figref idref="DRAWINGS">FIG. 7</figref>).</p>
<p id="p-0091" num="0091">A characteristic amount display area <b>400</b> (<figref idref="DRAWINGS">FIG. 10</figref>) is hidden at the back of the image comparison area <b>320</b>, and the characteristic amount display area <b>400</b> (<figref idref="DRAWINGS">FIG. 10</figref>) is displayed in front by selectively inputting &#x201c;analysis tab&#x201d; via the input section <b>13</b>.</p>
<p id="p-0092" num="0092">That is, the display processing section <b>111</b> determines whether or not &#x201c;analysis tab&#x201d; has been selectively input (selected) (S<b>307</b> in <figref idref="DRAWINGS">FIG. 7</figref>), and if the analysis tab has not been selected (S<b>307</b>&#x2192;No), the display processing section <b>111</b> proceeds the process to S<b>310</b> in <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0093" num="0093">If the analysis tab has been selected (S<b>307</b>&#x2192;Yes), then the display processing section <b>111</b> displays the characteristic amount display area <b>400</b> shown in <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0094" num="0094"><figref idref="DRAWINGS">FIG. 10</figref> is a diagram showing an example of a self-check screen (for comparing characteristic amounts) according to the present embodiment.</p>
<p id="p-0095" num="0095">If the user drags and drops an arbitrary defect image <b>401</b><i>a </i>displayed in the defect image list display area <b>202</b> on the self-check screen <b>200</b><i>c </i>(<b>200</b>), to the characteristic amount display area <b>400</b>, then the dragged and dropped defect image <b>401</b><i>a </i>is copied and displayed in the characteristic amount display area <b>400</b> as a defect image <b>401</b><i>b. </i></p>
<p id="p-0096" num="0096">The display processing section <b>111</b> determines whether or not a category whose characteristic amounts the user intends to display has been selected via a characteristic amount selection pull-down-menu <b>402</b>, <b>403</b> (S<b>308</b> in <figref idref="DRAWINGS">FIG. 7</figref>), and if not selected (S<b>308</b>&#x2192;No), the display processing section <b>111</b> proceeds the process to S<b>310</b> in <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0097" num="0097">If a category whose characteristic amounts the user intends to display has been selected via the characteristic amount selection pull-down-menu <b>402</b>, <b>403</b> (S<b>308</b>&#x2192;Yes, in <figref idref="DRAWINGS">FIG. 7</figref>), then the display processing section <b>111</b> generates a histogram representing the distribution of the respective characteristic amounts in the selected category, and displays the generated histogram in a characteristic amount distribution display area <b>411</b> (S<b>309</b> in <figref idref="DRAWINGS">FIG. 7</figref>). A category selected via the characteristic amount selection pull-down-menu <b>402</b>, <b>403</b> is a category classified by user.</p>
<p id="p-0098" num="0098">In graphs displayed in the characteristic amount distribution display area <b>411</b>, the horizontal axis represents the values of respective characteristic amounts and the vertical axis represents the numbers of defect image data with the respective values. In the characteristic amount distribution display area <b>411</b>, the characteristic amount distribution of a category selected via the characteristic amount selection pull-down-menu <b>402</b> is displayed as a hollow histogram, and the characteristic amount distribution of a category selected via the characteristic amount selection pull-down-menu <b>403</b> is displayed as a hatched histogram. Further, a portion where the characteristic amount distribution of a category selected via the characteristic amount selection pull-down-menu <b>402</b> and the characteristic amount distribution of a category selected via the characteristic amount selection pull-down-menu <b>403</b> overlap with each other is displayed as a black solid histogram. In the example, shown in <figref idref="DRAWINGS">FIG. 10</figref>, the characteristic amount distribution of &#x201c;C<b>1</b>: particle&#x201d; is displayed by a hollow histogram, and the characteristic amount distribution of &#x201c;C<b>2</b>: scratch&#x201d; is displayed by a hatched histogram. The percentage displayed in the right top portion of a characteristic amount distribution display area <b>411</b> represents the separation degree that is the ratio of the non-overlapped distribution portion to the entire characteristic distribution in two categories. That is, the percentage represents the ratio of the histograms which are not black-solid to the entire characteristic amount distribution. It is shown that if the separation degree is larger, the difference is the greater between the characteristic amount distributions of two categories.</p>
<p id="p-0099" num="0099">A histogram representing characteristic amount distribution is created in the following procedure. First, the display processing section <b>111</b> searches a category by the user in the classification standard data <b>121</b> in <figref idref="DRAWINGS">FIG. 4</figref> by using the category name selected via the characteristic amount selection pull-down-menu <b>402</b> as a key, and obtains the names of defect image data included in all corresponding records.</p>
<p id="p-0100" num="0100">Then, the display processing section <b>111</b> searches in the standard characteristic amount data <b>124</b> in <figref idref="DRAWINGS">FIG. 5</figref> by using the obtained defect image data names as a key, refers to the values of the respective characteristic amounts corresponding to the defect image data names, and counts the number of defect image data with the same characteristic amount on each individual characteristic. For example, in the example in <figref idref="DRAWINGS">FIG. 5</figref>, assuming that &#x201c;A<b>1</b>.jpg&#x201d; and &#x201c;A<b>2</b>.jpg&#x201d; are objects of processing, the display processing section <b>111</b> first refers to record &#x201c;A<b>1</b>.jpg&#x201d; and counts &#x201c;flatness: <b>50</b>&#x201d; by +1, and counts &#x201c;brightness: <b>60</b>&#x201d; by +1. The display processing section <b>111</b> likewise counts &#x201c;circularity&#x201d; and &#x201c;size&#x201d; of this record as well.</p>
<p id="p-0101" num="0101">Then, the display processing section <b>111</b> refers to record &#x201c;A<b>2</b>.jpg&#x201d;, and counts &#x201c;flatness: <b>40</b>&#x201d; by +1, and counts &#x201c;brightness: <b>60</b>&#x201d; by +1 (&#x201c;brightness: <b>60</b>&#x201d; thereby becomes &#x201c;2&#x201d;). The display processing section <b>111</b> likewise counts &#x201c;circularity&#x201d; and &#x201c;size&#x201d; of this record as well.</p>
<p id="p-0102" num="0102">The display processing section <b>111</b> performs this process on all the obtained names of defect image data, thereafter further performs the same process also on the category selected via the characteristic amount selection pull-down-menu <b>403</b>, and calculates the histograms of characteristic amounts for the respective characteristics.</p>
<p id="p-0103" num="0103">Further, bars <b>412</b> in the characteristic amount distribution display area <b>411</b> represent the respective values of the characteristic amounts of the defect image <b>401</b><i>b</i>. The display processing section <b>111</b> obtains the values of characteristic amounts from the standard characteristic amount data <b>124</b> in <figref idref="DRAWINGS">FIG. 5</figref>, by using the name of the defect image data of the defect image <b>401</b><i>b </i>as a key, and displays bars <b>412</b> at positions representing the respective characteristic amounts corresponding to the values obtained by the display processing section <b>111</b>.</p>
<p id="p-0104" num="0104">In a separation degree list display area <b>431</b>, the above-described separation degrees are listed in the descending order.</p>
<p id="p-0105" num="0105">Radio buttons <b>421</b>, <b>422</b> are used to indicate characteristic amounts which are currently used in performing classification by ADC processing. In the example in <figref idref="DRAWINGS">FIG. 10</figref>, &#x201c;flatness&#x201d;, &#x201c;brightness&#x201d;, and &#x201c;circularity&#x201d;, for which the radio buttons <b>421</b>, <b>422</b> are &#x201c;ON&#x201d;, are characteristic amounts which are currently used in the ADC process. By switching &#x201c;On/Off&#x201d; of the radio buttons <b>421</b>, <b>422</b>, the user can set effectiveness/ineffectiveness of characteristic amounts to be used in the ADC process. For example, when the user determines that &#x201c;brightness&#x201d; and &#x201c;circularity&#x201d; are ineffective characteristic amounts, the user can set the usage of these characteristic amounts in the ADC process to be ineffective by selecting and entering the corresponding radio buttons <b>412</b>, <b>422</b>. Further, on the contrary, when the user determines that &#x201c;size&#x201d; is valid characteristic amount, the user can set the usage of this characteristic amount in the ADC process to be effective by selecting and entering the corresponding radio buttons <b>421</b>, <b>422</b>.</p>
<p id="p-0106" num="0106">By determining whether or not a move button <b>332</b> (<figref idref="DRAWINGS">FIG. 9</figref>) has been selected and entered, the display processing section <b>111</b> determines whether or not to move corresponding defect image data from the current category to another category (S<b>310</b> in <figref idref="DRAWINGS">FIG. 7</figref>), and if not to move (S<b>310</b>&#x2192;No), the processing section <b>11</b> terminates the process. Herein, &#x201c;not to move&#x201d; refers to a case, for example, where a delete button <b>206</b> is selected and entered, or the user closes the self-check screen <b>200</b> in a state that the move button <b>332</b> has not been selected and entered. Incidentally, S<b>310</b> corresponds to the process in S<b>209</b> in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0107" num="0107">If the user intends to move the current defect image from the current category to another category, the user selects a moving destination category via a moving-destination-category selection pull-down menu <b>331</b> and selects and enters the move button <b>332</b> (<figref idref="DRAWINGS">FIG. 9</figref>) (S<b>310</b>&#x2192;Yes, in <figref idref="DRAWINGS">FIG. 7</figref>), and thereupon the display processing section <b>111</b> moves the data name of the defect image <b>311</b><i>b </i>displayed in the object image display area <b>330</b> (<figref idref="DRAWINGS">FIG. 9</figref>) to the selected moving destination category. More specifically, the display processing section <b>111</b> moves the name of the defect image data corresponding to the defect image <b>311</b><i>b </i>to a record of the selected moving destination category selected by the user in the classification standard data <b>121</b>, and thereby updates the classification standard data <b>121</b> (S<b>311</b> in <figref idref="DRAWINGS">FIG. 7</figref>).</p>
<p id="p-0108" num="0108">Further, if a defect image displayed in the object image display area <b>330</b> is an inappropriate (for example, a case where the image of a defect is not correctly captured) image for creating the classification standard data <b>121</b>, then the delete button <b>206</b> is selected and entered via the input section <b>13</b>, and thereupon, the display processing section <b>111</b> can delete the name of this defect image data from the classification standard data <b>121</b>.</p>
<p id="p-0109" num="0109">When the user has moved a defect image data name to be used for learning to another category by selecting and entering the move button <b>332</b> (<figref idref="DRAWINGS">FIG. 9</figref>), when the user has deleted defect image data from the classification standard data <b>121</b> by selecting and entering the delete button <b>206</b>, or when the user has switched effectiveness/ineffectiveness of a characteristic amount to be used for ADC processing, it is possible to update the confusion matrix <b>211</b> by selecting and entering the matrix button <b>214</b> each time. Further, the classification standard data <b>121</b> in this state can be overwritten or saved with another name by selecting and entering the save button <b>205</b>.</p>
<p id="p-0110" num="0110">The classification standard data <b>121</b> having been created in such a manner is used as a classification standard for ADC processing in the review device <b>1</b>, and the review device <b>1</b> automatically classifies defects on semiconductor wafers and transfers identification numbers of categories in respective results to the data processing device <b>3</b>. On the other hand, the defect image data group <b>123</b> determined to be defect images by ADC is stored in the storage section <b>12</b> of the review device <b>1</b> for respective wafers.</p>
<p id="p-0111" num="0111">Through the process up to here, a classification standard data <b>121</b> has been created and adjusted for classification of defect images by ADC. A process to be performed when new defect image data is transmitted to the review device <b>1</b> after the classification standard data <b>121</b> is created will be described below, referring to <figref idref="DRAWINGS">FIGS. 10 to 14</figref>. The transmitted new defect image data is stored in the defect image data group <b>123</b> in the storage section <b>12</b>.</p>
<p id="p-0112" num="0112"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing the process executed when defect image data is obtained anew.</p>
<p id="p-0113" num="0113">First, when the review device <b>1</b> captures new defect image data after the process in <figref idref="DRAWINGS">FIG. 6</figref>, the characteristic amount extraction section <b>114</b> automatically adjusts the defect recognition parameters, thereafter extracts characteristic amounts, and the automatic defect classification section <b>113</b> performs ADC processing of the captured defect image data (S<b>401</b>) and thereby classifies defect images. A result of ADC processing is registered in the classification data <b>122</b> shown in <figref idref="DRAWINGS">FIG. 4</figref>. Automatic adjustment of defect recognition parameters and extraction of characteristic amounts are similar to the processes in S<b>203</b>, S<b>204</b> in <figref idref="DRAWINGS">FIG. 6</figref>, and description will be accordingly omitted.</p>
<p id="p-0114" num="0114">Then, when an instruction of classification by the user is entered via the input section <b>13</b>, the input processing section <b>112</b> reads the newly input defect image data from the defect image data group <b>123</b> in the storage section <b>12</b>, based on the information on update date-and-time and the like (S<b>402</b>).</p>
<p id="p-0115" num="0115">At this moment, the display processing section <b>111</b> also reads the classification data <b>122</b>, in <figref idref="DRAWINGS">FIG. 4</figref>, and displays a result of classification by ADC in which a result of ADC processing and defect images are associated with each other on the display section <b>14</b>. The user refers to the displayed classification result and confirms whether the classification has been correctly made by the ADC processing, and, if there are errors in classification, the user performs reclassification into appropriate categories (S<b>403</b>). The input processing section <b>112</b> reflects a result of the reclassification into the classification data <b>122</b> in <figref idref="DRAWINGS">FIG. 4</figref> (S<b>404</b>). The order of reflection is similar to that in S<b>206</b>, in <figref idref="DRAWINGS">FIG. 6</figref>, except that the order &#x201c;classification by user&#x2192;classification by ADC&#x201d; has changed to &#x201c;classification by ADC&#x2192;classification by user&#x201d;, and detailed description will be accordingly omitted.</p>
<p id="p-0116" num="0116">Then, the display processing section <b>111</b> generates a confusion matrix <b>211</b><i>a </i>(<figref idref="DRAWINGS">FIG. 13</figref>), based on the classification data <b>122</b>, and displays a check screen <b>500</b> (<figref idref="DRAWINGS">FIG. 13</figref>) including this confusion matrix <b>211</b><i>a </i>(S<b>405</b>). The procedure of generating the confusion matrix <b>211</b><i>a</i>, based on the classification data <b>122</b>, is similar to the procedure described above with reference to <figref idref="DRAWINGS">FIG. 8</figref>, and detailed description will be accordingly omitted.</p>
<p id="p-0117" num="0117">Then, the user determines whether or not the current classification result is appropriate, referring to the displayed check screen <b>500</b> (<figref idref="DRAWINGS">FIG. 13</figref>) (S<b>406</b>).</p>
<p id="p-0118" num="0118">As a result of S<b>406</b>, if it is determined to be adequate (i.e., the classification result is appropriate.) (S<b>406</b>&#x2192;Yes), then the process is terminated.</p>
<p id="p-0119" num="0119">As a result of S<b>406</b>, if it is determined to be inadequate (i.e., the classification result is inappropriate.) (S<b>406</b>&#x2192;No), then the display processing section <b>111</b> copies defect image data selected via the check screen <b>500</b> as image data for additional learning (S<b>407</b>).</p>
<p id="p-0120" num="0120">Then, the display processing section <b>111</b> updates the classification standard data <b>121</b> (S<b>408</b>); the characteristic amount extraction section <b>114</b> performs automatic adjustment of the defect reorganization parameters and extraction of characteristic amounts; and the automatic defect classification section <b>113</b> thereafter performs ADC processing, based on the updated classification standard data <b>121</b> (S<b>409</b>). S<b>407</b> and S<b>408</b> will be described later.</p>
<p id="p-0121" num="0121">Subsequently, the processing section <b>11</b> returns the process to S<b>405</b>.</p>
<p id="p-0122" num="0122">The procedure of a check process will be described below, based on <figref idref="DRAWINGS">FIG. 12</figref> and referring to <figref idref="DRAWINGS">FIGS. 3</figref>, and <b>13</b> to <b>15</b>, as appropriate. The process shown in <figref idref="DRAWINGS">FIG. 12</figref> corresponds to S<b>405</b> to S<b>408</b> in <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0123" num="0123"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing the procedure of a check process according to the present embodiment.</p>
<p id="p-0124" num="0124">First, the display processing section <b>111</b> displays a check screen <b>500</b><i>a </i>(<b>500</b>), shown in <figref idref="DRAWINGS">FIG. 13</figref>, and a check screen <b>500</b><i>b </i>(<b>500</b>), shown in <figref idref="DRAWINGS">FIG. 14</figref>, and performs an image comparison process/characteristic amount comparison process (S<b>501</b>). S<b>501</b> is a process similar to the process shown in <figref idref="DRAWINGS">FIG. 6</figref> except that classification data <b>122</b> is used instead of classification standard data <b>121</b>, and detailed description will be accordingly omitted.</p>
<p id="p-0125" num="0125"><figref idref="DRAWINGS">FIG. 13</figref> is a diagram showing an example of a check screen (image comparison) according to the present embodiment.</p>
<p id="p-0126" num="0126">In the check screen <b>500</b><i>a </i>(<b>500</b>), the symbols <b>201</b><i>a</i>, <b>202</b><i>a</i>, <b>203</b><i>a</i>, <b>205</b><i>a</i>, <b>206</b><i>a</i>, <b>211</b><i>a</i>, <b>214</b><i>a</i>, <b>320</b><i>a</i>, <b>330</b><i>a</i>, <b>331</b><i>a</i>, <b>332</b><i>a</i>, <b>340</b><i>a</i>, <b>341</b><i>a</i>, and <b>342</b><i>a </i>are similar to the symbols <b>201</b>, <b>202</b>, <b>203</b>, <b>205</b>, <b>206</b>, <b>211</b>, <b>214</b>, <b>320</b>, <b>330</b>, <b>331</b>, <b>332</b>, <b>340</b>, <b>341</b>, and <b>342</b> in <figref idref="DRAWINGS">FIG. 9</figref>, except that the symbols in the check screen <b>500</b><i>a </i>(<b>500</b>) are created, based on classification data <b>122</b>, while the symbols in <figref idref="DRAWINGS">FIG. 9</figref> are created, based on classification standard data <b>121</b>, and description will be accordingly omitted. Further, although &#x201c;analysis tab&#x201d; in <figref idref="DRAWINGS">FIG. 9</figref> is replaced by &#x201c;analysis <b>1</b> tab&#x201d; in the check screen <b>500</b><i>a </i>(<b>500</b>), these functions are similar. A copy button <b>501</b> will be described later.</p>
<p id="p-0127" num="0127">In the example in <figref idref="DRAWINGS">FIG. 13</figref>, when a cell <b>502</b> in the confusion matrix <b>211</b><i>a </i>created based on the classification data <b>122</b> is selected via the input section <b>13</b>, the display processing section <b>111</b> displays corresponding defect images <b>511</b> in the defect image list display area <b>202</b><i>a</i>. One defect image <b>512</b><i>a </i>among the defect images <b>511</b> is copied by drag and drop into an object image display area <b>330</b><i>a </i>and displayed as a defect image <b>512</b><i>b. </i></p>
<p id="p-0128" num="0128">A move button <b>332</b><i>a</i>, in <figref idref="DRAWINGS">FIG. 13</figref>, is a button for moving the data of the selected defect image <b>512</b><i>b </i>to another category in the same classification data <b>122</b>.</p>
<p id="p-0129" num="0129"><figref idref="DRAWINGS">FIG. 14</figref> is a diagram showing an example of a check screen (characteristic amount comparison) according to the present embodiment.</p>
<p id="p-0130" num="0130">In the check screen <b>500</b><i>b </i>(<b>500</b>), the symbols <b>201</b><i>a</i>, <b>202</b><i>a</i>, <b>203</b><i>a</i>, <b>205</b><i>a</i>, <b>206</b><i>a</i>, <b>211</b><i>a</i>, <b>214</b><i>a</i>, <b>400</b><i>a</i>, <b>402</b><i>a</i>, <b>403</b><i>a</i>, <b>411</b><i>a</i>, <b>412</b><i>a</i>, <b>421</b><i>a</i>, <b>422</b><i>a</i>, and <b>431</b><i>a </i>are similar to the symbols <b>201</b>, <b>202</b>, <b>203</b>, <b>205</b>, <b>206</b>, <b>211</b>, <b>214</b>, <b>400</b>,<b>402</b>, <b>403</b>, <b>411</b>, <b>412</b>, <b>421</b>, <b>422</b>, and <b>431</b> in <figref idref="DRAWINGS">FIG. 10</figref>, except that the symbols in the check screen <b>500</b><i>b </i>(<b>500</b>) are created, based on classification data <b>122</b>, while the symbols in <figref idref="DRAWINGS">FIG. 10</figref> are created, based on classification standard data <b>121</b>, and description will be accordingly omitted.</p>
<p id="p-0131" num="0131">In the example in <figref idref="DRAWINGS">FIG. 14</figref>, one (symbol <b>601</b><i>a</i>) among defect images displayed in the defect image list display area <b>202</b><i>a </i>is copied by drag and drop into a characteristic amount display area <b>400</b><i>a </i>and displayed as a defect image <b>601</b><i>b. </i></p>
<p id="p-0132" num="0132">Returning to <figref idref="DRAWINGS">FIG. 12</figref>, subsequent to S<b>501</b>, the display processing section <b>111</b> determines whether or not &#x201c;analysis <b>2</b> tab&#x201d; in <figref idref="DRAWINGS">FIG. 13</figref> or <b>14</b> has been selected and entered (whether or not selected) (S<b>502</b>).</p>
<p id="p-0133" num="0133">As a result of S<b>502</b>, if &#x201c;analysis <b>2</b> tab&#x201d; has not been selected (S<b>502</b>&#x2192;No), the display processing section <b>111</b> proceeds the process to S<b>505</b>.</p>
<p id="p-0134" num="0134">As a result of S<b>502</b>, if &#x201c;analysis <b>2</b> tab&#x201d; has been selected (S<b>502</b>&#x2192;Yes), the display processing section <b>111</b> displays a check screen <b>500</b><i>c </i>(<b>500</b>), shown in <figref idref="DRAWINGS">FIG. 15</figref>.</p>
<p id="p-0135" num="0135"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram showing an example of a check screen (simulation) according to the present embodiment</p>
<p id="p-0136" num="0136">In <figref idref="DRAWINGS">FIG. 15</figref>, elements similar to those in <figref idref="DRAWINGS">FIGS. 13 and 14</figref> are given with the same symbols, and description will be omitted.</p>
<p id="p-0137" num="0137">In the check screen <b>500</b><i>c </i>(<b>500</b>), a simulate area <b>700</b> is displayed in the defect image confirmation area <b>203</b><i>a</i>. The simulate area <b>700</b> includes a characteristic amount display area <b>710</b>, a defect image display area <b>720</b>, and a simulate execution area <b>730</b>.</p>
<p id="p-0138" num="0138">The display processing section <b>111</b> determines whether or not a category has been selected via a category selection pull-down menu <b>711</b> in the characteristic amount display area <b>710</b> (S<b>503</b> in <figref idref="DRAWINGS">FIG. 12</figref>). If not selected (S<b>503</b>&#x2192;No), the display processing section <b>111</b> proceeds the process to S<b>505</b> in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0139" num="0139">If a category has been selected via the category selection pull-down menu <b>711</b> (S<b>503</b>&#x2192;Yes) and further a characteristic amount type is selected via a characteristic amount type selection pull-down-menu <b>712</b>, then the display processing section <b>111</b> generates a histogram representing characteristic amount distribution, based on the classification standard data <b>121</b> and the classification data <b>122</b>, and displays the generated histogram in a characteristic amount distribution display area <b>713</b> (S<b>504</b>).</p>
<p id="p-0140" num="0140">The histogram displayed in the characteristic amount distribution display area <b>713</b> is different from the histogram displayed in <figref idref="DRAWINGS">FIG. 10</figref> or <b>14</b>, and represents the characteristic amount distribution of the classification standard data <b>121</b> and the characteristic amount distribution of the newly added defect image data group <b>123</b>, with respect to the same category and characteristic amount type.</p>
<p id="p-0141" num="0141">In the example in <figref idref="DRAWINGS">FIG. 15</figref>, the histogram at the time of creation of the classification standard (namely the classification standard data <b>121</b>) for the category &#x201c;C<b>1</b>: particle&#x201d; and the characteristic amount type &#x201c;brightness&#x201d; is displayed as a hollow histogram, and the histogram of the group of additional images (namely the classification data <b>122</b>) is displayed as a hatched histogram. The portion where the two histograms are overlapped with each other is black solid.</p>
<p id="p-0142" num="0142">The procedure of creating histograms is as follows. First, the display processing section <b>111</b> refers to the categories selected by user of the classification standard data <b>121</b> by using the category name selected via the category selection pull-down menu <b>711</b> as a key, and obtains all corresponding defect image data names. Then, the display processing section <b>111</b> refers to the characteristic amount type, in the standard characteristic amount data <b>124</b>, selected via the characteristic amount type selection pull-down-menu <b>712</b>, by using all the obtained defect image data names as a key, and counts the numbers of defect image data for the respective values of characteristic amounts. The display processing section <b>111</b> performs a similar process on the classification data <b>122</b>.</p>
<p id="p-0143" num="0143">By histograms created in this manner, the user can visually recognize the difference between the characteristic amount distribution of the classification standard data <b>121</b> and the characteristic amount distribution of the classification data <b>122</b>. For example, from the characteristic amount distribution display area <b>713</b>, regarding the category (the category classified by the user) of &#x201c;C<b>1</b>: particle&#x201d; and the characteristic amount type of &#x201c;brightness&#x201d;, it is observed that the characteristic amount distribution of the group of additional images concentrate in lower values (the left side of the graph) compared with that at the time of creation of the classification standard (classification standard data <b>121</b>). Therefore, it is found to be appropriate to supplement data having the lower values in the characteristic amount distribution to the classification standard data <b>121</b>.</p>
<p id="p-0144" num="0144">Then, if a bar <b>714</b> is moved via the input section <b>13</b>, the display processing section <b>111</b> obtains defect image data of the value at which this bar <b>714</b> is located and displays the defect image data in the defect image display area <b>720</b>. In the example in <figref idref="DRAWINGS">FIG. 15</figref>, as the bar <b>714</b> indicates the value at the leftmost side of the histogram, defect images <b>721</b>, <b>722</b> with this value of brightness and of category &#x201c;C<b>1</b>: particle&#x201d; are displayed.</p>
<p id="p-0145" num="0145">More specifically, upon reading the value of the characteristic amount indicated by the bar <b>714</b>, the display processing section <b>111</b> searches the value of the characteristic amount type selected via the characteristic amount type selection pull-down-menu <b>712</b> in the characteristic amount data <b>125</b> in <figref idref="DRAWINGS">FIG. 5</figref> by using the read value as a key, and obtains defect image data names having this value. The display processing section <b>111</b> refers to the user categories of the classification data <b>122</b> by using the obtained defect image date names as a key, and obtains image data names corresponding to the category selected via the category selection pull-down menu <b>711</b> from the obtained defect image data names. Then, the display processing section <b>111</b> obtains defect image data from the defect image data group <b>123</b>, by using the obtained defect image data names as a key, and displays the obtained defect image data in the defect image display area <b>720</b>. Incidentally, as an example of a default arrangement, the value at the leftmost of the histogram may be selected unless the user moves the bar <b>714</b>.</p>
<p id="p-0146" num="0146">When the characteristic amount distribution at the time of creating the classification standard (classification standard data <b>121</b>) and the characteristic amount distribution of the group of the additional images (classification data <b>122</b>) are superimposed with each other, the characteristic amount type selection pull-down-menu <b>712</b> may display the characteristic amount types in ascending order of lower agreement ratio (i.e., in descending order of higher separation degree).</p>
<p id="p-0147" num="0147">Then, the display processing section <b>111</b> determines whether or not a defect image displayed in the defect image display area <b>720</b> has been dragged and dropped into the simulate execution area <b>730</b> via the input section <b>13</b>, and thereby determines whether or not a defect image has been selected (S<b>505</b> in <figref idref="DRAWINGS">FIG. 12</figref>).</p>
<p id="p-0148" num="0148">As a result of S<b>505</b>, if a defect image has not been selected (S<b>505</b>&#x2192;No), the display processing section <b>111</b> proceeds the process to S<b>508</b> in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0149" num="0149">As a result of <b>505</b>, if a defect image has been selected (S<b>505</b>&#x2192;Yes), the display processing section <b>111</b> displays the dragged and dropped defect image in the simulate execution area <b>730</b> in <figref idref="DRAWINGS">FIG. 15</figref>.</p>
<p id="p-0150" num="0150">In the example in <figref idref="DRAWINGS">FIG. 15</figref>, among the defect images <b>721</b>, <b>722</b> displayed in the defect image display area <b>720</b>, the defect image <b>722</b> has been dragged and dropped (selected) and is displayed in the simulate execution area <b>730</b> as a defect image <b>722</b><i>a</i>, however, it is possible to select a plurality of defect images.</p>
<p id="p-0151" num="0151">Then, the user selects as to which category (category by user in the classification standard data <b>121</b>) the defect image <b>722</b><i>a </i>displayed in the simulate execution area <b>730</b> is to be moved, via a category selection pull-down menu <b>731</b>, and the display processing section <b>111</b> thereafter determines whether or not an execution button <b>732</b> has been selected and thereby determines whether or not to execute simulation (S<b>506</b> in <figref idref="DRAWINGS">FIG. 12</figref>).</p>
<p id="p-0152" num="0152">As a result of S<b>506</b>, if simulation is not to be executed (S<b>506</b>&#x2192;No), the display processing section <b>111</b> proceeds the process to S<b>508</b>.</p>
<p id="p-0153" num="0153">As a result of S<b>506</b>, if simulation is to be executed (S<b>506</b>&#x2192;Yes), the characteristic amount extraction section <b>114</b> performs simulation on what a generated confusion matrix <b>211</b><i>a </i>will be like if the defect image <b>722</b><i>a </i>displayed in the simulate execution area <b>730</b> is added to the classification standard data <b>121</b>, and displays a result in the display section <b>14</b> (S<b>507</b> in <figref idref="DRAWINGS">FIG. 12</figref>). More specifically, the automatic defect classification section <b>113</b> uses temporary classification standard data <b>121</b>, to which the defect image <b>722</b><i>a </i>is added, to perform reclassification of the defect image data group <b>123</b> with the newly added defect image data; and thereby creates a temporary classification data <b>122</b>. Then, the display processing section <b>111</b> generates a confusion matrix <b>211</b><i>a </i>from the temporary classification data <b>122</b> by a method similar to the above-described procedure, and then displays this confusion matrix <b>211</b><i>a </i>in the confusion matrix display area <b>201</b><i>a</i>, thereby updating the confusion matrix <b>211</b><i>a. </i></p>
<p id="p-0154" num="0154">At the moment of S<b>507</b>, the data of the defect image <b>722</b><i>a </i>has not actually been added to the classification standard data <b>121</b>, and only simulation is performed on what a generated confusion matrix <b>211</b><i>a </i>will be like if the data of the defect image <b>722</b><i>a </i>is added to the classification standard data <b>121</b>. As a result of simulation (defect image data to be added, category, confusion matrix <b>211</b><i>a</i>, temporary classification standard data <b>121</b>, temporary classification data <b>122</b>, etc.) may be held by the display processing section <b>111</b> in the storage section <b>12</b> as history. In this case, if the user selects a history via a history selection pull-down menu <b>734</b>, then the display processing section <b>111</b> displays the state at that time (defect image data to be added, category, confusion matrix <b>211</b><i>a</i>, temporary classification standard data <b>121</b>, temporary classification data <b>122</b>, etc.) on the check screen <b>500</b>.</p>
<p id="p-0155" num="0155">Referring to the confusion matrix <b>211</b><i>a </i>updated as a result of the simulation, the user determines whether or not it is appropriate to add the defect image <b>722</b><i>a </i>displayed in the simulate execution area <b>730</b> to the classification standard data <b>121</b>. If determined to be appropriate, a copy button <b>701</b> is selected and entered via the input section <b>13</b>. That is, the display processing section <b>111</b> determines whether or not the copy button <b>701</b> has been selected and entered, and thereby determines whether or not to copy the defect image <b>722</b><i>a </i>to the classification standard data <b>121</b> (S<b>508</b> in <figref idref="DRAWINGS">FIG. 12</figref>). The process in S<b>508</b> corresponds to S<b>406</b> in <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0156" num="0156">If determined not to copy (S<b>508</b>&#x2192;No), the processing section <b>11</b> terminates the process.</p>
<p id="p-0157" num="0157">If determined to copy (S<b>508</b>&#x2192;Yes), the display processing section <b>111</b> copies the corresponding defect image <b>722</b><i>a </i>to the classification standard data <b>121</b> (S<b>509</b> in <figref idref="DRAWINGS">FIG. 12</figref>). Actually, the display processing section <b>111</b> copies a defect image data name corresponding to the defect image <b>722</b><i>a </i>displayed in the simulate execution area <b>730</b> to the classification standard data <b>121</b>. The process in S<b>509</b> is corresponding to S<b>407</b> in <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0158" num="0158">Subsequently, the display processing section <b>111</b> determines whether or not an application button <b>733</b> has been selected and entered, and thereby determines whether or not to apply copy (S<b>510</b> in <figref idref="DRAWINGS">FIG. 12</figref>).</p>
<p id="p-0159" num="0159">If determined not to apply copy (S<b>510</b>&#x2192;No), the processing section <b>11</b> terminates the process. A case of not applying copy refers to a case that the application button <b>733</b> has not been selected and entered for a certain time after application of the copy button <b>701</b>, a case that a delete button <b>206</b><i>a </i>has been selected and entered, a case that the check screen <b>500</b> has been closed, and other cases.</p>
<p id="p-0160" num="0160">In a case of applying copy (S<b>510</b>&#x2192;Yes), the display processing section <b>111</b> additionally registers the data name of the defect image <b>722</b><i>a </i>displayed in the simulate execution area <b>730</b> into the classification standard data <b>121</b>, and updates the classification standard data <b>121</b> (fixes the classification standard data <b>121</b>: S<b>511</b> in <figref idref="DRAWINGS">FIG. 12</figref>).</p>
<p id="p-0161" num="0161">Alternatively, by retrieving the history of simulation via the history selection pull-down menu <b>734</b> and selecting and entering the application button <b>733</b>, a state corresponding to the history of simulation may be reflected and fixed into the classification standard data <b>121</b>. Incidentally, the copy button <b>701</b> may be omitted, and the process in S<b>508</b> may be omitted. In this case, if the application button <b>733</b> is selected and entered, then the defect image data name is copied into the classification standard data <b>121</b> and simultaneously subjected to applying processing.</p>
<p id="p-0162" num="0162">In the present invention, a histogram showing characteristic amount distribution is displayed, however, the invention is mot limited thereto. For example, it is also possible to display characteristic amount distribution by a scatter diagram or the like.</p>
<p id="p-0163" num="0163">According to the present invention, the classification standard data <b>121</b> used for ADC can be created or updated by comparing respective defect images, comparing characteristic amount distributions, moving image data names in the classification standard data <b>121</b> as a result of these comparisons, and copying defect image data names in classification data <b>122</b> into the classification standard data <b>121</b>. As a result, it is possible to prevent the classification performance of a classification standard from being reduced due to inappropriate learning, and improve the classification accuracy of ADC. Furthermore, a user can effectively determine appropriateness/inappropriateness of classification of defect images because it is possible to effectively display and modify characteristic amounts between categories to be objects of classification, such as displaying defect images and characteristic amount distributions. That is, as a device for automatic classification of detects, it is possible to improve the operability in creating a classification standard, improve the user-friendliness, and more quickly and accurately create and adjust a classification standard. Accordingly, it is possible to more accurately feed back the occurrence state of detect type to which attention is paid, to a line, and thereby improve the yield ratio of the line.</p>
<p id="p-0164" num="0164">In addition, even when a defect of a type which is not registered in a classification standard is detected, flexible measures can be taken.</p>
<heading id="h-0013" level="1">REFERENCE NUMERALS</heading>
<p id="p-0165" num="0000">
<ul id="ul0002" list-style="none">
    <li id="ul0002-0001" num="0165"><b>1</b> review device (image classification device)</li>
    <li id="ul0002-0002" num="0166"><b>1</b><i>a </i>optical review device</li>
    <li id="ul0002-0003" num="0167"><b>1</b><i>b </i>SEM review device.</li>
    <li id="ul0002-0004" num="0168"><b>11</b> processing section</li>
    <li id="ul0002-0005" num="0169"><b>12</b> storage section</li>
    <li id="ul0002-0006" num="0170"><b>13</b> input section</li>
    <li id="ul0002-0007" num="0171"><b>14</b> display section</li>
    <li id="ul0002-0008" num="0172"><b>15</b> transmitting/receiving section</li>
    <li id="ul0002-0009" num="0173"><b>111</b> display processing section</li>
    <li id="ul0002-0010" num="0174"><b>112</b> input processing section</li>
    <li id="ul0002-0011" num="0175"><b>113</b> automatic defect classification section</li>
    <li id="ul0002-0012" num="0176"><b>114</b> characteristic amount extraction section</li>
    <li id="ul0002-0013" num="0177"><b>115</b> data obtaining section</li>
    <li id="ul0002-0014" num="0178"><b>121</b> classification standard data</li>
    <li id="ul0002-0015" num="0179"><b>122</b> classification data</li>
    <li id="ul0002-0016" num="0180"><b>123</b> defect image data group</li>
    <li id="ul0002-0017" num="0181"><b>124</b> standard characteristic amount data</li>
    <li id="ul0002-0018" num="0182"><b>125</b> characteristic amount data</li>
    <li id="ul0002-0019" num="0183"><b>200</b>, <b>200</b><i>a</i>, <b>200</b><i>b</i>, <b>200</b><i>c </i>self-check screen</li>
    <li id="ul0002-0020" num="0184"><b>211</b>, <b>211</b><i>a </i>confusion matrix (association information between categories)</li>
    <li id="ul0002-0021" num="0185">Z semiconductor wafer manufacturing system</li>
</ul>
</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for updating an image classification standard by an image classification device automatically classifying image data, comprising the steps of:
<claim-text>storing in a storage section of the image classification device:</claim-text>
<claim-text>classification standard data which includes information on image data used as a standard for automatically classifying the image data, and</claim-text>
<claim-text>classification data which includes information on image data of newly input image data automatically classified using the classification standard data; and</claim-text>
<claim-text>updating the classification standard data by adding information on image data selected by a user from the image data included in the classification data into the classification standard data</claim-text>
<claim-text>when an instruction is input via an input section of the image classification device to add the information on image data selected by the user from the image data included in the classification data into the classification standard data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method for updating an image classification standard according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step, carried out by the image classification device, of
<claim-text>displaying an image corresponding to the information on image data in the classification standard data and an image corresponding to the information on image data in the classification data, in the same window.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method for updating an image classification standard according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the steps, carried out by the image classification device, of: storing in the storage section:
<claim-text>standard characteristic amount data that is data of characteristic amounts related to the information on image data in the classification standard data, and</claim-text>
<claim-text>characteristic amount data that is data of characteristic amounts related to the information on image data in the classification data; and</claim-text>
<claim-text>displaying distribution of characteristic amounts in the standard characteristic amount data and distribution of characteristic amounts in the characteristic amount data, in the same window.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method for updating an image classification standard according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>the method further comprising the steps, carried out by the image classification device, of:</claim-text>
<claim-text>simulating reclassification of the information on the newly input image data, by using the classification standard data which the information on the image data selected by the user has been added; and</claim-text>
<claim-text>displaying the result of the simulation on a display section of the image classification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method for updating an image classification standard according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>the method further comprising the steps, carried out by the image classification device, of:</claim-text>
<claim-text>adding information on image data newly input into the classification data into categories into which information on image data is classified by a user and categories into which information on image data is automatically classified using the classification standard data;</claim-text>
<claim-text>generating association information between categories in which image data belonging to each of the categories classified by the user in the classification data is matched with image data belonging to each of the categories automatically classified by the image classification device in the classification data; and</claim-text>
<claim-text>displaying the generated association information between categories on a display section of the image classification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method for updating an image classification standard according to <claim-ref idref="CLM-00005">claim 5</claim-ref>,
<claim-text>the method further comprising the steps, carried out by the image classification device, of:</claim-text>
<claim-text>displaying the association information between categories on the display section in a matrix having a plurality of cells, each cell showing a number of image data in the association information between categories,</claim-text>
<claim-text>displaying image data on the display section when one of the cells showing the corresponding number of the image data in the association information between categories is selected.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method for updating an image classification standard according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image data is a defect image of a semiconductor wafer.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A non-transitory computer-readable medium storing a program for executing, on a computer, the method for updating an image classification standard according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method for updating an image classification standard by an image classification device automatically classifying image data, comprising the steps of:
<claim-text>storing in a storage section of the image classification device classification standard data which includes information on image data used as a standard for automatically classifying image data,</claim-text>
<claim-text>and the image data classified in respective categories; and</claim-text>
<claim-text>updating the classification standard data by moving image data selected by a user from the image data in the classification standard data, from a category in which the image data selected by the user is classified, to a different category in the classification standard data,</claim-text>
<claim-text>when an instruction is inputted via an input section of the image classification device to move the image data selected by the user, from the category in which the image data selected by the user is classified, to the different category in the classification standard data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method for updating an image classification standard according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising the step, carried out by the image classification device, of
<claim-text>displaying image data in the different category in the classification standard data in the same window with the image data selected by the user on a display section of the image classification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method for updating an image classification standard according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising the steps, carried out by the image classification device, of:
<claim-text>storing in each of the categories in the storage section standard characteristic amount data that is data of characteristic amounts of the image data in the classification standard data; and</claim-text>
<claim-text>displaying distributions of the characteristic amounts of two categories selected by a user from the standard characteristic amount data in distinguishable figure in the same graph on a display section of the image classification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method for updating an image classification standard according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising the steps, carried out by the image classification device, of:
<claim-text>storing the image data in the classification standard data in each of categories into which the image data is classified by a user and each of categories into which the image data is automatically classified using the classification standard data,</claim-text>
<claim-text>generating association information between categories in which image data belonging to each of the categories classified by the user in the classification standard data is matched with image data belonging to each of the categories automatically classified by the image classification device in the classification standard data; and</claim-text>
<claim-text>displaying the generated association information between categories on a display section of the image classification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method for updating an image classification standard according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising the steps, carried out by the image classification device, of:
<claim-text>displaying the association information between categories on the display section in a matrix having a plurality of cells, each cell showing a number of image data in the association information between categories;</claim-text>
<claim-text>selecting one of the cells showing a number of image data in the association information between categories; and</claim-text>
<claim-text>displaying the corresponding image data on the display section.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method for updating an image classification standard according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the image data are defect images of semiconductor wafers.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An image classification device automatically classifying image data, comprising:
<claim-text>a storage section that stores classification standard data which includes information on image data used as a standard for automatically classifying the image data, and</claim-text>
<claim-text>classification data which includes information on image data of newly input image data automatically classified using the classification standard data; and</claim-text>
<claim-text>a processing section that updates the classification standard data by adding information on image data selected by a user from image data included in the classification data into the classification standard data when an instruction is input via an input section of the image classification device to add the information on the image data selected by the user into the classification standard data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. An image classification device automatically classifying image data, comprising:
<claim-text>a storage section that stores classification standard data which includes image data being classified in respective categories and</claim-text>
<claim-text>information on the image data used as a standard for automatically classifying image data; and</claim-text>
<claim-text>a processing section that updates the classification standard data by moving image data selected by a user from the image data in the classification standard data, from a category in which the image data selected by the user is classified to a different category in the classification standard data</claim-text>
<claim-text>when an instruction is input via an input section of the image classification device to move the image data selected by the user, from the category in which the image data selected by the user is classified to the different category.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The image classification device according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein
<claim-text>the image data is stored in the classification standard data in each of categories into which the image data is classified by a user and each of categories into which the image data is automatically classified using the classification standard data; and</claim-text>
<claim-text>processing section generates association information between categories in which image data belonging to each of the categories classified by a user in the classification standard data is matched with image data belonging to each of the categories automatically classified by the image classification device in the classification standard data, and</claim-text>
<claim-text>displays the generated association information between categories on a display section of the image classification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The image classification device according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein
<claim-text>the association information between categories is displayed on the display section in a matrix having a plurality of cells, each cell showing a number of image data in the association information between categories; and</claim-text>
<claim-text>the processing section displays image data in the association information between categories on the display section when one of the cells corresponding to the image data. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
