<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625002-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625002</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13111267</doc-number>
<date>20110519</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2010-124175</doc-number>
<date>20100531</date>
</priority-claim>
<priority-claim sequence="02" kind="national">
<country>JP</country>
<doc-number>2011-065787</doc-number>
<date>20110324</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>204</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>76</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>92</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>3482313</main-classification>
<further-classification>386337</further-classification>
</classification-national>
<invention-title id="d2e90">Image processing apparatus and control method thereof for use in multiplexing image data and additional information</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2004/0141070</doc-number>
<kind>A1</kind>
<name>Chiku et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34823199</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2007/0035639</doc-number>
<kind>A1</kind>
<name>Aridome et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482313</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2009/0052875</doc-number>
<kind>A1</kind>
<name>Morimoto et al.</name>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386131</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2009/0322906</doc-number>
<kind>A1</kind>
<name>Watanabe</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34823199</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>CN</country>
<doc-number>1799257</doc-number>
<kind>A</kind>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>CN</country>
<doc-number>101373624</doc-number>
<kind>A</kind>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>2009-049726</doc-number>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00008">
<othercit>The above references were cited in a Jun. 4, 2013 Chinese Office Action, which is enclosed with an English Translation, that issued in Chinese Patent Application No. 201110145308.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>9</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>34823199</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482312</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482313</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482315</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482316</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>34833302</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386328</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386337</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386338</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>16</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110292250</doc-number>
<kind>A1</kind>
<date>20111201</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Nakajima</last-name>
<first-name>Hirofumi</first-name>
<address>
<city>Chigasaki</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Nakajima</last-name>
<first-name>Hirofumi</first-name>
<address>
<city>Chigasaki</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Cowan, Liebowitz &#x26; Latman, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Canon Kabushiki Kaisha</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Jerabek</last-name>
<first-name>Kelly L</first-name>
<department>2662</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image processing apparatus controls such that a plurality of additional information of image data are classified into a plurality of objects in accordance with update periods thereof and data of the additional ingenerateation corresponding to each of the classified objects is generated and output in accordance with the corresponding update period of each object, thereby multiplexing the data of the additional information corresponding to each object which is generated and output in accordance with update period thereof, to the input image data. The image processing apparatus demultiplexes the multiplexed data into the image data and the additional information, generates updated image data of the object to be updated from the demultiplexed additional information, and superimposes it to the video image corresponding to the image data.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="106.85mm" wi="240.45mm" file="US08625002-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="247.31mm" wi="126.75mm" orientation="landscape" file="US08625002-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="215.98mm" wi="171.70mm" orientation="landscape" file="US08625002-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="228.85mm" wi="138.94mm" orientation="landscape" file="US08625002-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="233.68mm" wi="147.83mm" orientation="landscape" file="US08625002-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="235.71mm" wi="136.91mm" orientation="landscape" file="US08625002-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="275.25mm" wi="109.64mm" orientation="landscape" file="US08625002-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="251.38mm" wi="163.49mm" file="US08625002-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="196.85mm" wi="155.28mm" file="US08625002-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="239.10mm" wi="162.81mm" file="US08625002-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="282.70mm" wi="132.84mm" orientation="landscape" file="US08625002-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="251.38mm" wi="121.92mm" orientation="landscape" file="US08625002-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="251.38mm" wi="116.50mm" file="US08625002-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="199.56mm" wi="175.77mm" file="US08625002-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="218.02mm" wi="175.09mm" file="US08625002-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates to an image processing apparatus of image data photographed by a digital video camera or the like and, more particularly, to an image processing technique for superimposing bit map data to moving image stream data.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">There is a recording apparatus such as a video camera or the like for recording, together with moving image data, additional information such as date and time of a moving image photographing and photographing camera information onto a recording medium such as digital versatile disk (DVD), hard disk drive (HDD), memory card, or the like.</p>
<p id="p-0006" num="0005">In such a recording apparatus, the moving image data is compression-encoded by using a method such as MPEG2, H.264, or the like and recorded.</p>
<p id="p-0007" num="0006">The additional information is generated as bit map data and then is run-length encoded.</p>
<p id="p-0008" num="0007">The encoded moving image data and bit map data are multiplexed into an MPEG-TS (transport stream) generateat and recorded onto the recording medium as a steam file of the TS format.</p>
<p id="p-0009" num="0008">Since the additional information is overlay bit map data (caption data) which has been multiplexed into the stream of the TS format, it can be reproduced and displayed by a reproducing apparatus which conforms with a display rule of the overlay bit map data.</p>
<p id="p-0010" num="0009">From such a situation, in the Official Gazette of Japanese Patent Application Laid-Open No. 2009-49726, such a technique that the additional information recorded in the stream as meta data in accordance with a unique rule is converted into overlay bit map data and recorded has been proposed. By such a technique, such additional information can be reproduced and displayed even in the reproducing apparatus which conforms with the display rule of the overlay bit map data.</p>
<p id="p-0011" num="0010">However, since the bit map data is very large data, there is such a problem that unless a bit rate of the moving image data is not reduced, a bit rate of the whole moving image processing system cannot be maintained, when a large amount of additional information is multiplexed.</p>
<p id="p-0012" num="0011">It is, therefore, an object of the invention to provide an image processing apparatus which can efficiently multiplex bit map data to image data in a moving image processing for multiplexing an overlay bit map to a moving image.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0013" num="0012">To solve the above problem, according to an aspect of the invention, an image processing apparatus comprises: an input unit configured to input image data; a data generation unit configured to generate data of a plurality of additional information regarding the image data; an image processing unit configured to generate stream data by multiplexing the data of the additional information generated by the data generation unit and the image data which is input by the input unit; and a control unit configured to control the data generation unit such that the plurality of additional information are classified into a plurality of objects in accordance with update periods thereof and the data of the additional information corresponding to each of the classified objects is generated and output in accordance with the update period of each object, wherein the image processing unit multiplexes to the image data the data of the additional information corresponding to each object which is output from the data generation unit in accordance with the update period thereof.</p>
<p id="p-0014" num="0013">According to the invention, in the moving image processing for multiplexing an overlay bit map to the moving image, an affect on a bit rate of the image data, caused by the multiplexing, can be reduced as much as possible. Therefore, a stream in which the additional information is multiplexed can be generated while keeping high picture quality of the moving image.</p>
<p id="p-0015" num="0014">Further features of the present invention will become apparent from the following description of exemplary embodiments with reference to the attached drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a recording apparatus having an image processing apparatus according to the first embodiment of the invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. 2A and 2B</figref> are diagrams for describing a construction of a stream of a TS format which is generated in accordance with the first embodiment of the invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> are diagrams illustrating an example of a display of bit map data according to the first embodiment of the invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. 4A</figref>, <b>4</b>B, <b>4</b>C and <b>4</b>D are conceptual diagrams of an AV stream according to the first embodiment of the invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram of a reproducing apparatus having an image processing apparatus according to the second embodiment of the invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram illustrating contents in a buffer memory in the reproducing operation according to the second embodiment of the invention.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart of the operation of a bit map data generation unit in the reproducing operation according to the second embodiment of the invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 8A</figref>, <b>8</b>B, <b>8</b>C and <b>8</b>D are diagrams illustrating contents in a buffer memory of the bit map data generation unit in the reproducing operation according to the second embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DESCRIPTION OF THE EMBODIMENTS</heading>
<p id="p-0024" num="0023">Subsequently, exemplary embodiments of the invention will be described in detail hereinbelow with reference to the drawings. The embodiments which will be described hereinbelow are examples for realizing the invention and should be properly modified or changed in accordance with a construction of an apparatus to which the invention is applied and various kinds of conditions. In this meaning, the invention is not limited to the following embodiments.</p>
<heading id="h-0005" level="1">First Embodiment</heading>
<p id="p-0025" num="0024">First, an outline of a stream of the MPEG2-TS format (hereinbelow, TS stream) regarding the first embodiment of the invention will be described with reference to <figref idref="DRAWINGS">FIGS. 2A and 2B</figref>.</p>
<p id="p-0026" num="0025">In the TS stream of the embodiment, as illustrated in <figref idref="DRAWINGS">FIG. 2A</figref>, image data and bit map data are multiplexed. In more detail, each of them is multiplexed as packetized data to a TS packet.</p>
<p id="p-0027" num="0026">The image data is constructed by data V (hereinbelow, VIDEO TS packet V) obtained by packetizing the data encoded by using an encoding method such as MPEG2, H.264, or the like. The bit map data is constructed by data B (hereinbelow, BITMAP TS packet B) obtained by packetizing the data in which the additional information of the image data is encoded by a run-length encoding.</p>
<p id="p-0028" num="0027">The bit map data itself has been multiplexed as illustrated in <figref idref="DRAWINGS">FIG. 2A</figref> and is constructed by a start unit, a data unit, and an end unit.</p>
<p id="p-0029" num="0028">As illustrated in <figref idref="DRAWINGS">FIG. 2B</figref>, besides a unit identifier showing the start unit, the number of objects, an ID of each object, a position on a display screen in the horizontal direction of each object, and a position on the display screen in the vertical direction of each object are recorded in the start unit. Besides a unit identifier showing the data unit, a width in the horizontal direction of each object, a length in the vertical direction of each object, and run-length data are recorded in the data unit. A unit identifier showing the end unit is recorded in the end unit. Based on those data, a template (area data) defining a display area of each object and data (update data) to be displayed are provided as shown in <figref idref="DRAWINGS">FIG. 3A</figref>.</p>
<p id="p-0030" num="0029">Subsequently, the first embodiment in which the invention is applied to a moving image recording apparatus will be described with reference to <figref idref="DRAWINGS">FIG. 1</figref>. <figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a construction of the moving image recording apparatus.</p>
<p id="p-0031" num="0030">A control unit <b>100</b> having a computer such as a CPU or the like controls the whole recording apparatus.</p>
<p id="p-0032" num="0031">A camera unit <b>101</b> has an image pickup sensor such as charge coupled device (CCD), complementary metal-oxide semiconductor (CMOS), or the like for converting an image which is input through a lens into an electric signal. The camera unit <b>101</b> outputs the photographed video image as digital data (image data) to an encoder/decoder (codec) <b>102</b>. At the same time, as camera information regarding control of the photographing operation, the camera unit <b>101</b> outputs focus information and exposure information to the control unit <b>100</b>.</p>
<p id="p-0033" num="0032">The encoder/decoder (codec) <b>102</b> encodes or decodes the input image data. The encoding method is MPEG2, H.264, or the like.</p>
<p id="p-0034" num="0033">A bit map data generation unit <b>103</b> generates bit map data obtained by run-length encoding an image (additional information) to be superimposed onto the photographed video image. The bit map data generation unit <b>103</b> also has a function for decoding the bit map data which was generated by run-length encoding.</p>
<p id="p-0035" num="0034">A TS multiplexing unit <b>104</b> TS packetizes the image data encoded by the codec <b>102</b> and the bit map data encoded by the bit map data generation unit <b>103</b> and multiplexes the obtained TS packets, thereby generating a TS stream. The TS multiplexing unit <b>104</b> also has a function for demultiplexing the multiplexed TS stream.</p>
<p id="p-0036" num="0035">A buffer memory <b>105</b> temporarily stores the TS stream which is output from the TS multiplexing unit <b>104</b> and is used as a buffer for writing into a recording medium <b>107</b> or a work memory of the control unit <b>100</b>.</p>
<p id="p-0037" num="0036">A recording medium control unit <b>106</b> controls the writing of the TS stream from the buffer memory <b>105</b> to the recording medium <b>107</b> in the recording mode. The recording medium control unit <b>106</b> controls the reading of the TS stream from the recording medium <b>107</b> into the buffer memory <b>105</b> in the reproducing mode.</p>
<p id="p-0038" num="0037">The recording medium <b>107</b> is constructed by a flash memory or the like for storing the TS stream.</p>
<p id="p-0039" num="0038">A GPS (Global Positioning System) unit <b>108</b> obtains GPS information.</p>
<p id="p-0040" num="0039">A display unit <b>109</b> displays the image photographed by the camera unit <b>101</b>, the video image reproduced from the recording medium <b>107</b>, or the like. The display unit <b>109</b> also displays various kinds of necessary images such as a setting display screen and the like under control of the control unit <b>100</b>.</p>
<p id="p-0041" num="0040">In addition to the above construction, a communication interface (not shown) for transmitting the generated TS stream to an external apparatus may be provided.</p>
<p id="p-0042" num="0041">Subsequently, the recording operation of the moving image will described. The recording operation is performed by loading a control program which has previously been installed in a memory (not shown) into the control unit <b>100</b> and executing it.</p>
<p id="p-0043" num="0042">When a recording instruction is received from a user interface (not shown), the moving image recording apparatus in <figref idref="DRAWINGS">FIG. 1</figref> starts the moving image recording operation. The control unit <b>100</b> drives the camera unit <b>101</b>. First, the camera unit <b>101</b> converts the photographed image into digital data (image data) and outputs to the codec <b>102</b>.</p>
<p id="p-0044" num="0043">Thus, the codec <b>102</b> is driven by the control unit <b>100</b> and encodes the image data which is input from the camera unit <b>101</b> and outputs the encoded data to the TS multiplexing unit <b>104</b>.</p>
<p id="p-0045" num="0044">At the same time, the bit map data generation unit <b>103</b> is driven by the control unit <b>100</b> and generates and encodes the bit map data which is superimposed onto the photographed image and outputs the encoded data to the TS multiplexing unit <b>104</b>. The bit map data which is generated will be described hereinafter.</p>
<p id="p-0046" num="0045">The TS multiplexing unit <b>104</b> generates the TS packets by packetizing the data encoded by the codec <b>102</b> and the data generated and encoded by the bit map data generation unit <b>103</b>. The TS multiplexing unit <b>104</b> multiplexes those TS packets into one TS stream and stores into the buffer memory <b>105</b>.</p>
<p id="p-0047" num="0046">Subsequently, the control unit <b>100</b> controls the recording medium control unit <b>106</b> and records the TS stream data stored in the buffer memory <b>105</b> to the recording medium <b>107</b> as an Audio-Visual (AV) stream file.</p>
<p id="p-0048" num="0047">From the TS stream data recorded in the recording medium <b>107</b>, the image data and the bit map data can be reproduced by the operation processing which reversely performs the recording processing operation mentioned above. In this case, a demultiplexer circuit for executing the processing opposite to the multiplexing is a well-known technique and the decoding can be realized by a decoding function of the codec <b>102</b>.</p>
<p id="p-0049" num="0048">Subsequently, the bit map data which is generated by the bit map data generation unit <b>103</b> will be described. In the present embodiment, photography date and time, GPS information, a photographer, a time code, focus information, and exposure information are generated as bit map data (a plurality of additional information). The bit map data generation unit <b>103</b> obtains the information regarding the photography date and time and the time code serving as a foundation of the bit map data from a calendarial function unit and a time management unit (not shown) held in the control unit <b>100</b>. The generation unit <b>103</b> obtains GPS information which is the basis of the bit map data, from the GPS unit <b>108</b>. The generation unit <b>103</b> also obtains the focus information and the exposure information serving as a foundation of the bit map data from the camera unit <b>101</b>. The information of the photographer serving as a foundation of the bit map data is determined on the basis of setting information instructed by the user through a setting display screen displayed in the display unit <b>109</b>.</p>
<p id="p-0050" num="0049">In the invention, the bit map data is classified every object as follows.</p>
<p id="p-0051" num="0050">Classification into data having a high correlation with a moving image frame and data having a low correlation therewith
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0051">Data having a high frame correlation: photography date and time, GPS information, and photographer</li>
        <li id="ul0002-0002" num="0052">Data having a low frame correlation: time code, focus information, and exposure information</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0052" num="0053">The data having a low frame correlation is classified every frame into data which needs to be updated and data which does not need to be updated.
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0054">Updating is necessary every frame: time code (frame), focus information, and exposure information</li>
        <li id="ul0004-0002" num="0055">Updating is unnecessary every frame: time code (hour, minute, second)</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0053" num="0056">Further, the data whose updating is unnecessary every frame is classified every I-picture (encoding type) and every hour (photographing time).
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0000">
    <ul id="ul0006" list-style="none">
        <li id="ul0006-0001" num="0057">Every I-picture: time code (minute, second)</li>
        <li id="ul0006-0002" num="0058">Every time: time code (hour)</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0054" num="0059">Thus, the bit map data is classified into the following five objects in accordance with the update period.
<ul id="ul0007" list-style="none">
    <li id="ul0007-0001" num="0000">
    <ul id="ul0008" list-style="none">
        <li id="ul0008-0001" num="0060">Photography date and time, photographer, and GPS information&#x2014;object <b>1</b>&#x2014;every photographing scene</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0055" num="0061">Focus information and exposure information&#x2014;object <b>2</b>&#x2014;every frame
<ul id="ul0009" list-style="none">
    <li id="ul0009-0001" num="0000">
    <ul id="ul0010" list-style="none">
        <li id="ul0010-0001" num="0062">Time code <b>1</b> (frame)&#x2014;object <b>3</b>&#x2014;every frame</li>
        <li id="ul0010-0002" num="0063">Time code <b>2</b> (second, minute)&#x2014;object <b>4</b>&#x2014;every I-Picture</li>
        <li id="ul0010-0003" num="0064">Time code <b>3</b> (hour)&#x2014;object <b>5</b>&#x2014;every hour</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0056" num="0065"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> illustrate an example of a display of the bit map data superimposed onto the moving image. This display can be performed by reproducing and displaying, for example, the TS stream recorded on the recording medium <b>107</b> under control of the control unit <b>100</b>.</p>
<p id="p-0057" num="0066"><figref idref="DRAWINGS">FIG. 3A</figref> illustrates a template adapted to specify a display position of the bit map data of each object and a data display format in the display area. <figref idref="DRAWINGS">FIG. 3B</figref> illustrates an example of a display screen at the time when the bit map data is superimposed onto the image data. The display format of <figref idref="DRAWINGS">FIG. 3A</figref> is preset or can be properly selected from a plurality of settings by the control unit <b>100</b> and a user interface and the like (not shown). The bit map data which is superimposed and displayed is updated by the following construction.</p>
<p id="p-0058" num="0067"><figref idref="DRAWINGS">FIGS. 4A and 4D</figref> illustrate a conceptual diagram of an AV stream to be recorded onto the recording medium <b>107</b>. <figref idref="DRAWINGS">FIG. 4A</figref> shows the AV stream, and <figref idref="DRAWINGS">FIGS. 4B to 4D</figref> show the bit map data of the objects to be superimposed on respective frames of the AV stream.</p>
<p id="p-0059" num="0068">As illustrated in <figref idref="DRAWINGS">FIGS. 4A to 4D</figref>, the bit map data of all of the objects <b>1</b> to <b>5</b> shown in <figref idref="DRAWINGS">FIG. 4B</figref> are superimposed onto the start frame <b>400</b> and <b>404</b> shown in <figref idref="DRAWINGS">FIG. 4A</figref>. The bit map data of the object <b>5</b> is superimposed onto the subsequent frames every hour, the bit map data of the objects <b>2</b> to <b>4</b> shown in <figref idref="DRAWINGS">FIG. 4D</figref> are superimposed every I-picture frame <b>402</b>, <b>403</b> and <b>405</b> shown in <figref idref="DRAWINGS">FIG. 4A</figref>, and the bit map data of the objects <b>2</b> and <b>3</b> shown in <figref idref="DRAWINGS">FIG. 4C</figref> are superimposed every frame <b>401</b> shown in <figref idref="DRAWINGS">FIG. 4A</figref>.</p>
<p id="p-0060" num="0069">The information of the photographer is preset by a user interface using the display unit <b>109</b> and is saved into an area of the buffer memory <b>105</b>, which is used as a work memory of the control unit <b>100</b>.</p>
<p id="p-0061" num="0070">The ingenerateation of the photography date and time is obtained from the calendarial function unit held in the control unit <b>100</b> and is saved into the area of the buffer memory <b>105</b>, which is used as a work memory of the control unit <b>100</b>.</p>
<p id="p-0062" num="0071">At the start of the recording, the GPS information is obtained from the GPS unit <b>108</b> in response to an instruction from the control unit <b>100</b> and is saved into the area of the buffer memory <b>105</b>, which is used as a work memory of the control unit <b>100</b> of the buffer memory <b>105</b>.</p>
<p id="p-0063" num="0072">As for the focus information and the exposure information (photographing condition), the information which is generated by the camera unit <b>101</b> and output to the control unit <b>100</b> is sent to the bit map data generation unit <b>103</b> every frame.</p>
<p id="p-0064" num="0073">The time code is generated by the control unit <b>100</b> and sent to the bit map data generation unit <b>103</b> every frame.</p>
<p id="p-0065" num="0074">After the start of the recording, the control unit <b>100</b> sends a generating instruction of the object <b>1</b> to the bit map data generation unit <b>103</b> at the timing when the head frame is encoded by the codec <b>102</b>.</p>
<p id="p-0066" num="0075">At the same time, the control unit <b>100</b> sends photography date and time, the address and size of the buffer memory <b>105</b> in which the data of the photographer is held, and the GPS information. The bit map data generation unit <b>103</b> reads out the photography date and time and the information of the photographer from the buffer memory, generates the object <b>1</b> from those data and the data sent from the GPS unit <b>108</b> and encodes it.</p>
<p id="p-0067" num="0076">Similarly, the control unit <b>100</b> sends a generating instruction of the objects <b>2</b> and <b>3</b> to the bit map data generation unit <b>103</b> at the timing when each frame of the image data is encoded by the codec <b>102</b>. At the same time, the data of the frame portion of the time code generated in the control unit <b>100</b> is sent to the bit map data generation unit <b>103</b>. The bit map data generation unit <b>103</b> uses the information which is output from the camera unit <b>101</b> to the control unit <b>100</b> as focus information and exposure information, uses the information generated in the control unit <b>100</b> as a time code, generates the objects <b>2</b> and <b>3</b> so as to superimpose them every frame, and encodes them.</p>
<p id="p-0068" num="0077">Similarly, the control unit <b>100</b> sends a generating instruction of the object <b>4</b> to the bit map data generation unit <b>103</b> at the timing when the image data is I-picture encoded by the codec <b>102</b>. At the same time, the data of second and minute of the time code generated in the control unit <b>100</b> is sent to the bit map data generation unit <b>103</b>. The bit map data generation unit <b>103</b> generates the object <b>4</b> so as to superimpose it every I-Picture of the image data on the basis of the sent data, and encodes it.</p>
<p id="p-0069" num="0078">Similarly, the control unit <b>100</b> sends a generating instruction of the object <b>5</b> to the bit map data generation unit <b>103</b> at the timing when the frame is encoded by the codec <b>102</b> every unit time. At the same time, the control unit <b>100</b> sends the time data of the time code to the bit map data generation unit <b>103</b>. The bit map data generation unit <b>103</b> generates the object <b>5</b> so as to superimpose it every unit time on the basis of the sent data, and encodes it.</p>
<p id="p-0070" num="0079">After that, the stream generated by the foregoing multiplexing processing is recorded onto the recording medium <b>107</b> as described before.</p>
<p id="p-0071" num="0080">According to the embodiment of the invention described above, the additional information of the image data is classified in accordance with the update period and the overlay bit map data of each of the classified information can be multiplexed on the image data at the update period thereof. Thus, since a data amount of the additional ingenerateation which is multiplexed every frame of the moving image can be decreased, an affect on the bit rate caused by the increase in data amount of the image data, can be reduced. Therefore, while maintaining resolution of the moving image, the moving image stream can be generated with the necessary additional information being added.</p>
<p id="p-0072" num="0081">In the foregoing embodiment, the image processing of the invention has been described with respect to the recording data processing of the moving image recording apparatus. However, the image processing of the invention is not limited to the recording processing. For example, the processing of the invention can be applied even to a processing for displaying the photographed moving image and the additional information as illustrated in <figref idref="DRAWINGS">FIGS. 3A and 3B</figref> or a processing for transmitting the stream to an external apparatus. Also in this case, a decrease in processing speed can be avoided and a smooth display and a transmission rate can be maintained. Information other than the foregoing information can be also used as additional information.</p>
<p id="p-0073" num="0082">Further, even in the case where the stream data recorded or transmitted by using the invention is displayed, since the data amount of the multiplexed additional information per frame is small, an advantage similar to that of the stream generating processing can be obtained.</p>
<heading id="h-0006" level="1">Second Embodiment</heading>
<p id="p-0074" num="0083">Subsequently, the reproducing operation of the AV stream file recorded by the moving image recording apparatus having the image processing apparatus according to the first embodiment will be described as a second embodiment of the invention with reference to <figref idref="DRAWINGS">FIGS. 5 and 6</figref>. <figref idref="DRAWINGS">FIG. 5</figref> is a block diagram of a reproducing apparatus having an image processing apparatus according to the second embodiment of the invention and illustrates a block construction along a processing flow. <figref idref="DRAWINGS">FIG. 6</figref> is a diagram illustrating the contents in the buffer memory <b>105</b> in the operation of the reproducing apparatus in <figref idref="DRAWINGS">FIG. 5</figref>. In the construction illustrated in <figref idref="DRAWINGS">FIG. 5</figref>, the same blocks as those illustrated in <figref idref="DRAWINGS">FIG. 1</figref> are denoted by the same reference numerals. That is, since the blocks <b>101</b> to <b>109</b> illustrated in <figref idref="DRAWINGS">FIG. 5</figref> are the same as the blocks shown by the same reference numerals in <figref idref="DRAWINGS">FIG. 1</figref>, their description is omitted here.</p>
<p id="p-0075" num="0084">Since the reproducing operation in the embodiment is the reproducing operation of the TS stream recorded by the recording operation described in the first embodiment, it can be realized by reversely performing the recording operation as mentioned above. The reproducing operation in the present embodiment is also realized by loading a control program which is previously installed in the memory (not shown) to the control unit <b>100</b> and executing it in a manner similar to the first embodiment.</p>
<p id="p-0076" num="0085">The reproducing operation in the embodiment will be described in detail hereinbelow with reference to the drawings.</p>
<p id="p-0077" num="0086">When the reproducing apparatus receives a reproducing instruction from a user interface (not shown), the reproducing operation is started.</p>
<p id="p-0078" num="0087">The control unit <b>100</b> controls the recording medium control unit <b>106</b>, reads out the AV stream file recorded on the recording medium <b>107</b>, and writes as TS stream data into the buffer memory <b>105</b> (A in <figref idref="DRAWINGS">FIG. 6</figref>).</p>
<p id="p-0079" num="0088">Subsequently, the control unit <b>100</b> instructs the TS multiplexing unit <b>104</b> to read out the TS stream data written in the buffer memory <b>105</b>. The TS multiplexing unit <b>104</b> which received the instruction reads out the TS stream data from the buffer memory <b>105</b>, separates it into the encoded image data and the encoded bit map data by demultiplexing, and subsequently writes back those data into the buffer memory <b>105</b> (B in <figref idref="DRAWINGS">FIG. 6</figref>).</p>
<p id="p-0080" num="0089">Subsequently, the control unit <b>100</b> issues an instruction to the codec <b>102</b> to read out the encoded image data written back to the buffer memory <b>105</b>. Further, the control unit <b>100</b> issues an instruction to the bit map data generation unit <b>103</b> to read out the encoded bit map data written back to the buffer memory <b>105</b>. At this time, if the encoded bit map data is not updated with respect to each frame of the encoded image data which is read out, the control unit <b>100</b> notifies the bit map data generation unit <b>103</b> that the data is not updated. When the AV stream in <figref idref="DRAWINGS">FIGS. 4A to 4D</figref> are generated, the control unit <b>100</b> instructs the updating timing of the bit map data to the bit map data generation unit <b>103</b> for every object. That is, since the bit map data has been generated and multiplexed for every object at the update timing, the bit map data is not multiplexed with respect to the frame in which the object to be updated does not exist.</p>
<p id="p-0081" num="0090">In response to the instruction of the control unit <b>100</b>, the codec <b>102</b> reads out the encoded image data from the buffer memory <b>105</b>, decodes it, and writes back again the decoded data as digital image data into the buffer memory <b>105</b> (C in <figref idref="DRAWINGS">FIG. 6</figref>). Under the control of the control unit <b>100</b>, if the encoded bit map data is updated, the bit map data generation unit <b>103</b> reads out the encoded bit map data from the buffer memory <b>105</b>, decodes it, and writes back again the decoded data into the buffer memory <b>105</b> (C in <figref idref="DRAWINGS">FIG. 6</figref>).</p>
<p id="p-0082" num="0091">As illustrated in C in <figref idref="DRAWINGS">FIG. 6</figref>, the bit map data generation unit <b>103</b> uses the buffer memory <b>105</b> as a frame memory and develops the bit map data to a memory position corresponding to the display position of the display image when it is written back to the buffer memory <b>105</b>.</p>
<p id="p-0083" num="0092">Subsequently, the control unit <b>100</b> issues an instruction to the display unit <b>109</b> to read out the digital image data written in the buffer memory <b>105</b> and the decoded bit map data. The display unit <b>109</b> which received the instruction reads out the digital image data and the decoded bit map data from the buffer memory <b>105</b>, superimposes them to one image, and displays the image.</p>
<p id="p-0084" num="0093">By repetitively executing the foregoing processings to each frame, the additional information is reproduced and displayed together with the moving image.</p>
<p id="p-0085" num="0094">Subsequently, the operation of the bit map data generation unit <b>103</b> in the reproducing mode will be described in detail with reference to <figref idref="DRAWINGS">FIGS. 7 and 8A</figref> to <b>8</b>D. <figref idref="DRAWINGS">FIG. 7</figref> is a flowchart for the operation of the bit map data generation unit <b>103</b> and <figref idref="DRAWINGS">FIGS. 8A to 8D</figref> illustrate the contents in the buffer memory in C in <figref idref="DRAWINGS">FIG. 6</figref>. When the control unit <b>100</b> instructs the bit map data generation unit <b>103</b> to read out the encoded bit map data from the buffer memory <b>105</b>, the processing in <figref idref="DRAWINGS">FIG. 7</figref> is executed by the bit map data generation unit <b>103</b> in response to such an instruction. The AV stream file which is reproduced is the file generated by the recording operation in the invention (<figref idref="DRAWINGS">FIG. 4</figref>).</p>
<p id="p-0086" num="0095">When the control unit <b>100</b> instructs so as to read out the encoded bit map data written in the buffer memory <b>105</b>, the processing of the present embodiment is started in step S<b>701</b>.</p>
<p id="p-0087" num="0096">In step S<b>702</b>, the presence or absence of the data updating notification from the control unit <b>100</b> is discriminated. When the absence of the updating is ingenerated by the data updating notification, the processing routine advances to step S<b>708</b> and the processing is finished. In this case, as for the display of the bit map data, since the display in the previous frame is not updated, the contents same as those in the previous frame are displayed.</p>
<p id="p-0088" num="0097">In step S<b>703</b>, a unit identifier of the encoded bit map data which is read out of the buffer memory <b>105</b> is discriminated based on an identifier showing the start unit. If the start unit identifier is discriminated as a result of the discrimination, in step S<b>704</b>, the corresponding position is reserved in a buffer memory <b>1</b> (frame memory for developing) in accordance with the horizontal and vertical positions on the display screen of the objects of the number as many as the number of objects included in the start unit which is read in (<figref idref="DRAWINGS">FIG. 8A</figref>). In the embodiment, as illustrated in <figref idref="DRAWINGS">FIGS. 8A to 8D</figref>, two frame memories <b>1</b> and <b>2</b> for writing back are prepared in the buffer memory <b>105</b>. One (frame memory <b>1</b>) of the frame memories <b>1</b> and <b>2</b> is used to develop the object and the other (frame memory <b>2</b>) is used to display the object. As mentioned above, the start position of the object is reserved for the frame memory <b>1</b> for developing. <figref idref="DRAWINGS">FIGS. 8A to 8D</figref> illustrate an example of the reproduction processing at the time when only the time code (frame) of the object <b>3</b> recorded in the first embodiment is updated.</p>
<p id="p-0089" num="0098">Subsequently, in step S<b>705</b>, the identifier of the encoded bit map data which is read in is discriminated by an identifier showing the data unit. If the data unit is discriminated as a result of the discrimination, in step S<b>706</b>, an area having corresponding width and length from the position reserved in step S<b>704</b> is reserved in the frame memory <b>1</b> for developing in accordance with a width and a length of each object included in the data unit (<figref idref="DRAWINGS">FIG. 8B</figref>).</p>
<p id="p-0090" num="0099">In step S<b>707</b>, the data included in the data unit is decoded and the bit map data is developed into the area reserved in the frame memory <b>1</b> for developing (<figref idref="DRAWINGS">FIG. 8C</figref>).</p>
<p id="p-0091" num="0100">The processings until now are executed to the objects of the number as many as the number of objects included in the start unit.</p>
<p id="p-0092" num="0101">In step S<b>708</b>, the unit identifier of the encoded bit map data which is read out of the buffer memory <b>105</b> is discriminated by an identifier showing the end unit. If the end unit is discriminated as a result of the discrimination, in step S<b>709</b>, the data developed in the frame memory <b>1</b> for developing is developed into the frame memory <b>2</b> for displaying. Thus, only the data of the objects developed in the frame memory <b>1</b> for developing is written (updated) among the bit map data stored in the frame memory for displaying.</p>
<p id="p-0093" num="0102">In step S<b>710</b>, the processing is finished.</p>
<p id="p-0094" num="0103">As described above, only the updated object in the bit map data which is superimposed into the reproduced moving image is rewritten and the data of the other objects which are not updated remain unchanged so that the same data as that of the previous frame are retained. The bit map data developed in the frame memory <b>2</b> for displaying is superimposed onto the image data decoded in the codec <b>102</b> and displayed by the display unit <b>109</b> as illustrated in, for example, <figref idref="DRAWINGS">FIG. 3B</figref>.</p>
<p id="p-0095" num="0104">According to the second embodiment as described above, the reproduction processing of the additional information of the image data can be executed as an updating processing of only the updated object in accordance with its update period. Thus, since the load of the reproduction processing of the additional information which is multiplexed every frame of the moving image can be decreased, the affect on the bit rate, caused by the increase in data amount of the image data, can be reduced. Therefore, the moving image stream to which the necessary additional information is added can be reproduced while maintaining the resolution of the moving image.</p>
<p id="p-0096" num="0105">Although the image processing of the invention has been described above with respect to the data reproduction display processing of the moving image reproducing apparatus, the invention can be also applied to a processing for receiving the transmitted stream and displaying it. Also in this case, since a data amount of the multiplexed additional information per frame is reduced, the decrease in processing speed can be avoided and the received image data can be smoothly displayed.</p>
<p id="p-0097" num="0106">Further, information other than the foregoing information can be also used as additional information.</p>
<p id="p-0098" num="0107">Although the invention has been described in detail above with respect to the exemplary embodiments, the invention is not limited to those specific embodiments but various modifications in a range without departing from the essence of the invention are also incorporated in the invention.</p>
<p id="p-0099" num="0108">Naturally, the object of the invention is also accomplished by supplying a program code to a system or an apparatus from a storage medium in which the program code of software for realizing the functions of the embodiments mentioned above has been recorded. That is, the object of the invention is accomplished by a method whereby a computer (or a CPU or MPU) of the system or apparatus reads out the program code stored in the storage medium and executes processings based on the program code.</p>
<p id="p-0100" num="0109">In this case, the program code itself read out of the storage medium realizes the functions of the embodiments mentioned above, and the program code itself and the storage medium in which the program code has been stored construct the invention.</p>
<p id="p-0101" num="0110">As a storage medium for supplying the program code, for example, a flexible disk, a hard disk, an optical disk, a magnetooptic disk, a CD-ROM, a CD-R, a magnetic tape, a non-volatile memory card, a ROM, or the like can be used.</p>
<p id="p-0102" num="0111">The invention also incorporates a case where an OS (basic system or operating system) or the like which is operating on a computer executes a part or all of actual processings on the basis of instructions of the program code read out by the computer, so that the functions of the embodiments mentioned above are realized.</p>
<p id="p-0103" num="0112">Further, the invention also incorporates a case where the program code read out of the storage medium is written into a memory provided for a function expanding board inserted in a computer or a function expanding unit connected to the computer and is executed after that. That is, the invention also incorporates a case where a CPU or the like provided for the function expanding board or the function expanding unit executes a part or all of actual processings on the basis of instructions of the program code in the memory and the functions of the embodiments mentioned above are realized by those processings.</p>
<p id="p-0104" num="0113">While the present invention has been described with reference to exemplary embodiments, it is to be understood that the invention is not limited to the disclosed exemplary embodiments. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures and functions.</p>
<p id="p-0105" num="0114">This application claims the benefit of Japanese Patent Applications No. 2010-124175 filed on May 31, 2010 and No. 2011-065787 filed on Mar. 24, 2011, which are hereby incorporated by reference herein in their entirety.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing apparatus comprising:
<claim-text>an input unit configured to input image data;</claim-text>
<claim-text>a data generation unit configured to generate data of a plurality of additional information regarding the image data input by the input unit;</claim-text>
<claim-text>an image processing unit configured to generate stream data by multiplexing the data of the additional information generated by the data generation unit and the image data; and</claim-text>
<claim-text>a control unit configured to control the data generation unit such that the plurality of additional information are classified into a first object which has a first update period and a second object which has a second update period different from the first update period, the data of the additional information corresponding to the first object is generated and output with the first update period, and the data of the additional information corresponding to the second object is generated and output with the second update period,</claim-text>
<claim-text>wherein the image processing unit multiplexes to the image data the data of the additional information corresponding to each of the first and second objects which is output from the data generation unit with update period of the each of the first and second objects.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data generation unit generates encoded bit map data with respect to each of the plurality of additional information.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of additional information include at least one or more of photography date and time, GPS information, a photographer, a time code, focus information, and exposure information, and wherein the control unit classifies the additional information by using as the first and second update periods a scene of the image data, a frame, an encoding type of the frame, and a photographing time.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control unit supplies each of the plurality of additional information to the data generation unit with the first and second update periods.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a photographing unit configured to generate the image data, and wherein the photographing unit supplies information regarding a photographing condition to the control unit.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data of the additional information which is generated by the data generation unit includes area data showing an area of each of the first and second objects to be updated, on an image corresponding to the image data, and updated data of each of the first and second objects, and the image processing apparatus further comprises a recording unit configured to record the stream data generated by the image processing unit onto a recording medium.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a display unit configured to display a moving image corresponding to the stream data which is output from the image processing unit, and wherein the control unit controls the display unit such that the additional information is superimposed to the moving image and displayed.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A control method of an image processing apparatus having an input unit configured to input image data and a data generation unit configured to generate data of a plurality of additional information regarding the image data input by the input unit, comprising:
<claim-text>generating stream data by multiplexing the data of the additional information generated by the data generation unit and the image data; and</claim-text>
<claim-text>controlling the data generation unit such that the plurality of additional information are classified into a first object which has a first update period and a second object which has a second update period different from the first update period, the data of the additional information corresponding to the first object is generated and output with the first update period, and the data of the additional information corresponding to the second object is generated and output with the second update period,</claim-text>
<claim-text>wherein in the image processing step, the data of the additional information corresponding to each of the first and second objects which is output from the data generation unit with update period of each of the first and second objects is multiplexed to the image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A non-transitory computer readable storage medium storing a program comprising a code for causing a computer to execute the control method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>.</claim-text>
</claim>
</claims>
</us-patent-grant>
