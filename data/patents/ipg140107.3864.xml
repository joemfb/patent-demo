<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624931-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624931</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12274619</doc-number>
<date>20081120</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2007-317721</doc-number>
<date>20071207</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>473</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345676</main-classification>
<further-classification>345678</further-classification>
<further-classification>345681</further-classification>
</classification-national>
<invention-title id="d2e71">Information processing apparatus, information processing method, and program</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5801699</doc-number>
<kind>A</kind>
<name>Hocker et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715837</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7274379</doc-number>
<kind>B2</kind>
<name>Beaumont</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345630</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7589749</doc-number>
<kind>B1</kind>
<name>De Laurentis et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345676</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7589750</doc-number>
<kind>B1</kind>
<name>Stratton</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345677</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2004/0143627</doc-number>
<kind>A1</kind>
<name>Dietl</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709203</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2005/0073585</doc-number>
<kind>A1</kind>
<name>Ettinger et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348155</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>10-207907</doc-number>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>11-219369</doc-number>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>2002-21644</doc-number>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2003-288352</doc-number>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>2006-146729</doc-number>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2007-310890</doc-number>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Office Action issued Nov. 15, 2011, in Japanese Patent Application No. 2007-317721.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>21</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345630-677</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>19</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090147027</doc-number>
<kind>A1</kind>
<date>20090611</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Miyashita</last-name>
<first-name>Ken</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Matsuda</last-name>
<first-name>Kouichi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Miyashita</last-name>
<first-name>Ken</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Matsuda</last-name>
<first-name>Kouichi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oblon, Spivak, McClelland, Maier &#x26; Neustadt, L.L.P.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Tung</last-name>
<first-name>Kee M</first-name>
<department>2677</department>
</primary-examiner>
<assistant-examiner>
<last-name>Cain, II</last-name>
<first-name>Leon T</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">There is provided an information processing apparatus that classifies objects having the respective attribute information which are disposed on a display screen of a graphical user interface, the apparatus including an operation information acquisition unit that acquires operation information containing movement information which indicates a position of a movement destination of the object on the display screen, an instructive request estimate unit that estimates an instructive request for classification processing on the object based on the attribute information and the movement information of the object, a classification processing unit that classifies the object based on the estimated instructive request, and a display control unit that controls display of the object on the display screen. Thus, the user can easily classify the objects without explicitly specifying classification conditions or instructing the performing of the classification processing.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="177.97mm" wi="173.65mm" file="US08624931-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="195.33mm" wi="173.40mm" file="US08624931-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="194.23mm" wi="159.94mm" orientation="landscape" file="US08624931-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="237.24mm" wi="171.03mm" file="US08624931-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="231.48mm" wi="136.48mm" file="US08624931-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="234.53mm" wi="142.07mm" file="US08624931-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="232.16mm" wi="139.70mm" file="US08624931-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="228.43mm" wi="138.18mm" file="US08624931-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCES TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present invention contains subject matter related to Japanese Patent Application JP 2007-317721 filed in the Japan Patent Office on Dec. 7, 2007, the entire contents of which being incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<heading id="h-0003" level="1">Field of the Invention</heading>
<p id="p-0003" num="0002">The present invention relates to an information processing apparatus, an information processing method, and a program.</p>
<p id="p-0004" num="0003">In the case of classifying information which is expressed as an object or the like in a graphical user interface (GUI) by using an information processing apparatus such as a computer, typically, the user specifies classification conditions explicitly and instructs the information processing apparatus to perform classification processing so that this information processing apparatus may perform the classification processing based on the classification conditions specified by the user.</p>
<p id="p-0005" num="0004">In this case, the user needs to abstract desired classification conditions and explicitly specify the classification conditions so that the information processing apparatus can perform the classification processing. For example, in order to extract an object of photos taken in summer of 2007 from among a plurality of photo objects, the user needs to specify an abstracted condition expression such as &#x201c;(&#x2018;2007-07&#x2019;&#x3c;=$year) &#x26;&#x26; ($year&#x3c;=&#x2018;2007-09&#x2019;).&#x201d; Further, the user needs to explicitly instruct the performing of classification processing in accordance with an operation procedure predetermined by the information processing apparatus or an application which is executed in it.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0006" num="0005">However, in some cases, the typical user finds it difficult to work out such an abstracted condition expression as given above. Further, in the case of utilizing an information processing apparatus having a lot of functions, the user sometimes finds it difficult also to remember an operation procedure in accordance with which the user would instruct the information processing apparatus to perform classification processing.</p>
<p id="p-0007" num="0006">It is desirable to provide an information processing apparatus, an information processing method, and a program that can easily classify objects disposed on the display screen of a graphical user interface.</p>
<p id="p-0008" num="0007">According to a first embodiment of the present invention, there is provided an information processing apparatus that classifies objects having the respective attribute information which are disposed on a display screen of a graphical user interface, the apparatus including an operation information acquisition unit that acquires operation information containing movement information which indicates a position of a movement destination of the object on the display screen, an instructive request estimate unit that estimates an instructive request for classification processing on the object based on the attribute information and the movement information of the object, a classification processing unit that classifies the object based on the estimated instructive request, and a display control unit that controls display of the object on the display screen.</p>
<p id="p-0009" num="0008">According to this configuration, an instructive request for classification processing on an object is estimated based on the attribute information and movement information of the object, so that the object is classified based on the estimated instructive request. Thus, the user can easily classify the objects without explicitly specifying classification conditions or instructing the performing of the classification processing.</p>
<p id="p-0010" num="0009">It further includes an object group setting unit that sets an object group which includes a plurality of objects having attribute information common to them and which has classification conditions corresponding to the common attribute information and position information indicating a position on the display screen, in which the classification processing unit causes the object group setting unit to set the object group targeted by the classification processing as a target object group and classifies the unclassified target object having the attribute information that matches the classification conditions of the target object group based on the classification conditions of the target object group. Thus, a plurality of objects having attribute information common to them are set as an object group that has classification conditions which correspond to the attribute information, while an object group targeted by classification processing is set as a target object group. Then, an unclassified target object having the attribute information that matches the classification conditions of the target object group undergoes the classification processing. Accordingly, an unclassified target object is classified based on the classification conditions of a target object group, so that the user can easily classify the objects without explicitly specifying the classification conditions or instructing the performing of the classification processing.</p>
<p id="p-0011" num="0010">Further, the operation information acquisition unit acquires first movement information about a first object and then acquires second movement information about a second object different from the first object, and if having determined that the first and second objects are disposed close to each other from the first and second movement information and also that the first and second objects have attribute information common to them, the instructive request estimate unit may estimate an instructive request for start of classification processing which uses the common attribute information as the classification conditions. In such a manner, if a first object and a second object have been moved by the user so as to be disposed close to each other and also do they have attribute information common to them, an instructive request is estimated for the classification conditions to be employed in classification processing and the start of the classification processing. Therefore, the user can start classification processing on the objects without explicitly specifying the classification conditions or instructing the performing of the classification processing.</p>
<p id="p-0012" num="0011">Further, the classification processing unit can cause the object group setting unit to set first and second objects as a target object group, thus starting classification processing based on the classification conditions of the target object group. In such a manner, a plurality of objects moved by the user can be set as a target object group then the classification processing based on the classification conditions of the target object group starts. Therefore, the user can start classification processing on the objects without explicitly setting a target object group or instructing the performing of the classification processing.</p>
<p id="p-0013" num="0012">Further, the operation information acquisition unit acquires movement information about objects, and if having determined that the objects and an object group have been disposed close to each other from position information of the object group and the movement information of the objects and also the attribute information of the objects matches classification conditions of the object group, the instructive request estimate unit may estimate an instructive request for the start of classification processing. In such a manner, if objects and an object group have been moved by the user so as to be disposed close to each other and also the attribute information of the objects matches the classification conditions of the object group, an instructive request is estimated for the start of the classification processing. Therefore, the user can start classification processing on the objects without explicitly instructing the performing of the classification processing.</p>
<p id="p-0014" num="0013">Further, the classification processing unit can cause the object group setting unit to set an object group including objects as a target object group, thus starting classification processing based on the classification conditions of the target object group. In such a manner, an object group including object moved by the user is set as a target object group then the classification processing based on the classification conditions of the target object group starts. Therefore, the user can start classification processing on the objects without explicitly setting a target object group or instructing the performing of the classification processing.</p>
<p id="p-0015" num="0014">Further, the classification processing unit may move a target object toward a target object group at a constant movement speed, while the display control unit may control display so that the target object may move toward the target object group at the constant movement speed. Accordingly, display is provided so that the target object may move toward a target object group at a constant movement speed. Therefore, the user can confirm an instructive request estimated by the information processing apparatus.</p>
<p id="p-0016" num="0015">Further, if a target object has moved close to a target object group, the classification processing unit may cause the object group setting unit to set the target object group as a target object group that includes the target object. In such a manner, if a target object has moved close to a target object group, the target object group is set as a target object group that includes the target object. Therefore, the user can easily classify objects without explicitly specifying classification conditions or instructing the performing of the classification processing.</p>
<p id="p-0017" num="0016">Further, the operation information acquisition unit may acquire movement information which indicates the position of a movement destination of a target object on the display screen, while the instructive request estimate unit may estimate an instructive request for classification processing based on the movement information of the target object. In such a manner, an instructive request for classification processing is estimated based on the movement information of a target object. Therefore, the user can easily transmit to the information processing apparatus an instructive request for the classification processing of the object.</p>
<p id="p-0018" num="0017">Further, if having determined that a target object is prompted to move from the position information of the target object group and the movement information of the target object, the instructive request estimate unit may estimate an instructive request for the continuation of classification processing. In such a manner, if a target object is prompted to move, an instructive request for the continuation of classification processing is estimated. Therefore, the user can easily transmit to the information processing apparatus an instructive request for the continuation of the classification processing.</p>
<p id="p-0019" num="0018">Further, if an instructive request for the continuation of classification processing is estimated by the instructive request estimate unit, the classification processing unit may increase the movement speed of a target object, while the display control unit may control display so that the target object may move toward the target object group at an increased movement speed. Accordingly, if an instructive request for the continuation of classification processing is estimated, display is provided so that the target object may move at an increased movement speed. Therefore, the user can confirm that an instructive request for the continuation of the classification processing has been transmitted to the information processing apparatus and, further, speed up the progress of the classification processing.</p>
<p id="p-0020" num="0019">Further, if having determined that a target object is inhibited from moving from the position information of the target object group and the movement information of the target object, the instructive request estimate unit may estimate an instructive request for the stoppage of classification processing. In such a manner, if a target object is inhibited from moving, an instructive request for the stoppage of classification processing is estimated. Therefore, the user can easily transmit to the information processing apparatus an instructive request for the stoppage of the classification processing.</p>
<p id="p-0021" num="0020">Further, if an instructive request for the stoppage of classification processing is estimated by the instructive request estimate unit, the classification processing unit may stop the movement of a target object, while the display control unit may control display so that the movement of the target object may be stopped. Accordingly, if an instructive request for the stoppage of classification processing is estimated, display is provided so that the target object may stop its movement. Therefore, the user can confirm that an instructive request for the stoppage of the classification processing has been transmitted to the information processing apparatus.</p>
<p id="p-0022" num="0021">Further, if an instructive request for the stoppage of classification processing is estimated by the instructive request estimate unit, the classification processing unit may cause the object group setting unit to set the target object group as an object group. Accordingly, if an instructive request for the stoppage of classification processing is estimated, the target object group is set as an object group. Therefore, the user can stop the classification processing by the information processing apparatus without explicitly instructing the stoppage of the classification processing.</p>
<p id="p-0023" num="0022">Further, the operation information acquisition unit may acquire setting cancellation information which indicates an instruction to cancel the setting of a specific object group, while the classification processing unit may cause the object group setting unit to set cancellation of the setting of the specific object group based on the setting cancellation information. In such a manner, the setting of a specific object group is canceled based on setting cancellation information. Therefore, the user can change and modify the results of classification processing by the information processing apparatus.</p>
<p id="p-0024" num="0023">Further, the display control unit may control display so that the target object group can be distinguished from the other object groups than itself. Accordingly, display is provided so that the target object group may be distinguished from the other target object groups than itself. Therefore, the user can easily confirm the progress status of object classification processing.</p>
<p id="p-0025" num="0024">Further, the display control unit may control display so that a target object can be distinguished from the other target objects than itself. Accordingly, display is provided so that a target object may be distinguished from the other objects than itself. Therefore, the user can easily confirm a target object which undergoes classification processing.</p>
<p id="p-0026" num="0025">According to a second embodiment of the present invention, there is provided an information processing method of classifying objects having the respective attribute information which are disposed on a display screen of a graphical user interface, the method including the steps of: acquiring operation information containing movement information which indicates a position of a movement destination of the object on the display screen; estimating an instructive request for classification processing on the object based on the attribute information and the movement information of that object; classifying the object based on the estimated instructive request; and controlling display of the object on the display screen.</p>
<p id="p-0027" num="0026">According to a third embodiment of the present invention, there is provided a program that causes a computer to perform the information processing method according to the second embodiment of the present invention described above.</p>
<p id="p-0028" num="0027">According to the embodiments of the present invention described above, there can be provided an information processing apparatus, an information processing method, and a program that can easily classify objects disposed on the display screen of a graphical user interface.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing main functional components of an information processing apparatus according to one embodiment of the present invention;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart showing a flow of classification processing by the information processing apparatus;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart showing a flow of classification processing by the information processing apparatus;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 4A</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 4B</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 4C</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 4D</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 5A</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 5B</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 5C</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 5D</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 6A</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 6B</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 6C</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 6D</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 7A</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 7B</figref> is a schematic diagram explaining the classification processing by the information processing apparatus;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 7C</figref> is a schematic diagram explaining the classification processing by the information processing apparatus; and</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 7D</figref> is a schematic diagram explaining the classification processing by the information processing apparatus.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0048" num="0047">Hereinafter, preferred embodiments of the present invention will be described in detail with reference to the appended drawings. Note that, in the specification and the appended drawings, structural elements that have substantially the same function and structure are denoted with the same reference numerals, and repeated explanation of these structural elements is omitted.</p>
<p id="p-0049" num="0048">(Functional Components of Information Processing Apparatus)</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing main functional components of an information processing apparatus <b>100</b> according to one embodiment of the present invention.</p>
<p id="p-0051" num="0050">The information processing apparatus <b>100</b> may be, for example, a personal computer, a personal digital assistance (PDA), or a cellular phone and has a display screen integrally provided on it or a connection to a display screen provided separately from it. It is to be noted that although the following will describe a case where a display screen is provided integrally on the information processing apparatus <b>100</b>, the present invention is similarly applicable also to a case where it is provided separately.</p>
<p id="p-0052" num="0051">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the information processing apparatus <b>100</b> includes an operation information acquisition unit <b>102</b>, a storage unit <b>104</b>, a display unit <b>106</b>, and a control processing unit <b>110</b>.</p>
<p id="p-0053" num="0052">The operation information acquisition unit <b>102</b> acquires operation information entered by the user through a keyboard, a pointing device, and the like. The operation information contains movement information which indicates the position of a movement destination of an object on the display screen. It is to be noted that although the following will describe a case where operation information is entered through a mouse, the operation information may be entered through any other input device such as a touch panel.</p>
<p id="p-0054" num="0053">The storage unit <b>104</b> is constituted of a storage memory such as a RAM or a ROM and stores information about programs used to make the information processing apparatus <b>100</b> operative, and objects. The display unit <b>106</b> is constituted of a display, a monitor, or the like which has a display screen and displays a plurality of pieces of information expressed as an object or the like on the display screen.</p>
<p id="p-0055" num="0054">The control processing unit <b>110</b> includes such function units as a user instruction estimate unit (instructive request estimate unit) <b>112</b>, a classification processing unit <b>114</b>, an object group setting unit <b>116</b>, and a display control unit <b>118</b> and manages overall control processing on the information processing apparatus <b>100</b>, including control processing by use of these function units.</p>
<p id="p-0056" num="0055">The user instruction estimate unit <b>112</b> estimates a user's instruction for classification processing on an object based on attribute information and movement information of the object. The classification processing unit <b>114</b> classifies the object based on the user's instruction estimated by the user instruction estimate unit <b>112</b>. The object group setting unit <b>116</b> sets an object group which includes a plurality of objects having attribute information common to them and which has classification conditions corresponding to the common attribute information and position information indicating a position of the object group on the display screen. The display control unit <b>118</b> controls the display unit <b>106</b>, which displays objects on the display screen.</p>
<p id="p-0057" num="0056">Of these function components, the operation information acquisition unit <b>102</b>, the user instruction estimate unit <b>112</b>, the classification processing unit <b>114</b>, the object group setting unit <b>116</b>, and the display control unit <b>118</b> can be realized in the information processing apparatus <b>100</b> as hardware and/or software such as a dedicated electronic circuit or a program which is executed by a CPU.</p>
<p id="p-0058" num="0057">An object may be various kinds of information that can be a target of classification processing by the information processing apparatus <b>100</b>, such as content data including image, video, and voice, icon in a graphical user interface (GUI), etc. An object has identification information that can identify the object, at least one piece of attribute information, and position information.</p>
<p id="p-0059" num="0058">The attribute information of an object contains information assigned by the user and information automatically assigned by the information processing apparatus <b>100</b> etc. In a case where the object is a photo content, the attribute information contains information of, for example, a date and time when the photo was taken, a place where the photo was taken, a person who took the photo, etc.</p>
<p id="p-0060" num="0059">The position information of an object is set in order to specify a position and a range where the object is displayed on the display screen. The position information is set as two-dimensional coordinate information in a case where an object is disposed in a two-dimensional coordinate plane and as three-dimensional coordinate information in a case where an object is disposed in a three-dimensional coordinate space.</p>
<p id="p-0061" num="0060">A plurality of objects classified based on attribute information common to them can make up an object group. An object group has identification information that can identify the object group, classification conditions, position information, group information, and flag information.</p>
<p id="p-0062" num="0061">The classification conditions for an object group correspond to attribute information common to a plurality of objects that make up an object group. Classification conditions are set as at least one piece of attribute information in order to classify the objects and used as composite conditions if set as a plurality of pieces of attribute information.</p>
<p id="p-0063" num="0062">Similar to the position information of objects, the position information of an object group is set in order to specify a position and a range where the object group is displayed on the display screen.</p>
<p id="p-0064" num="0063">The group information of an object group is a set of the identification information of a plurality of objects that make up the object group and set in order to specify the objects classified in the object group.</p>
<p id="p-0065" num="0064">The flag information of an object group is set in order to specify whether the object group corresponds to the target object group or an ordinary object group. Here, although described in detail later, the target object group means an object group that is handled as a target of classification processing by the information processing apparatus <b>100</b>.</p>
<p id="p-0066" num="0065">The information processing apparatus <b>100</b> according to the present embodiment is operative to classify objects having the respective attribute information which are disposed on the display screen of a GUI. The following will describe classification processing of the object by the information processing apparatus <b>100</b>.</p>
<p id="p-0067" num="0066">(Classification Processing by Information Processing Apparatus)</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIGS. 2 and 3</figref> are a flowchart showing the flow of classification processing by the information processing apparatus <b>100</b>. <figref idref="DRAWINGS">FIGS. 4A to 4D</figref>, <figref idref="DRAWINGS">FIGS. 5A to 5D</figref>, <figref idref="DRAWINGS">FIGS. 6A to 6D</figref>, and <figref idref="DRAWINGS">FIGS. 7A to 7D</figref> are schematic diagrams explaining the classification processing by the information processing apparatus <b>100</b>. It is to be noted that in <figref idref="DRAWINGS">FIGS. 4A to 4D</figref>, <figref idref="DRAWINGS">FIGS. 5A to 5D</figref>, <figref idref="DRAWINGS">FIGS. 6A to 6D</figref>, and <figref idref="DRAWINGS">FIGS. 7A to 7D</figref>, an object, an object group, and a target object group are indicated as a square icon, a pile of square icons, and a hatched pile respectively.</p>
<p id="p-0069" num="0068">First, assume a case in which a plurality of objects <b>211</b> and <b>212</b> are disposed on a display screen of the information processing apparatus <b>100</b> in a condition where they are not classified as shown in <figref idref="DRAWINGS">FIG. 4A</figref>.</p>
<p id="p-0070" num="0069">The user moves a pointer <b>200</b> on the display screen through moving operations of a mouse and clicks the mouse in a condition where the pointer <b>200</b> is disposed on a specific object, thereby specifying the specific object. If the object is specified, the operation information acquisition unit <b>102</b> acquires position information that indicates a position of the pointer <b>200</b> on the display screen so that the specified object is specified based on the position information of the pointer <b>200</b> and the position information of the object.</p>
<p id="p-0071" num="0070">The user moves the pointer <b>200</b> on the display screen through press-and-drag operations in a condition where the object is specified, thereby moving the object in a condition where its movement is interlocked with that of the pointer <b>200</b>. If the object is moved, the operation information acquisition unit <b>102</b> acquires movement information that indicates a position of the pointer <b>200</b> on the display screen so that the movement information of the object may be changed as needed. Then, based on the movement information changed as needed, the display control unit <b>118</b> controls display of the object on the display screen.</p>
<p id="p-0072" num="0071">Next, as shown in <figref idref="DRAWINGS">FIG. 4B</figref>, the user releases the press-and-drag operations in a condition where the object <b>211</b> is moved to an arbitrary position on the display screen, thereby completing the movement of the object <b>211</b>. If the movement of the object <b>211</b> is completed, the operation information acquisition unit <b>102</b> acquires movement information that indicates a position to which the pointer <b>200</b> is moved on the display screen so that the position information of the object <b>211</b> may be updated based on this movement information. Then, based on the updated position information, the display control unit <b>118</b> controls display of the object <b>211</b> on the display screen.</p>
<p id="p-0073" num="0072">Here, assume a case where the user has moved the first object <b>211</b> and then moved the second object <b>212</b> different from the first object <b>211</b> so that it is disposed close to the first object <b>211</b> on the display screen as shown in <figref idref="DRAWINGS">FIG. 4C</figref>. In this case, as described above, the operation information acquisition unit <b>102</b> acquires the first movement information about the first object <b>211</b> and the second movement information about the second object <b>212</b> (step S<b>102</b>). Then, based on the first and second movement information, the display control unit <b>118</b> controls display of the first and second objects <b>211</b> and <b>212</b>.</p>
<p id="p-0074" num="0073">If the movement information is acquired, the user instruction estimate unit <b>112</b> determines whether the first and second objects <b>211</b> and <b>212</b> are disposed close to each other based on the movement information of the first and second object <b>211</b> and <b>212</b> (S<b>104</b>).</p>
<p id="p-0075" num="0074">In this case, if a plurality of objects are overlapped with each other or otherwise disposed within a predetermined distance, the user instruction estimate unit <b>112</b> determines that they are disposed close to each other. If having determined that the objects <b>211</b> and <b>212</b> are disposed close to each other, the user instruction estimate unit <b>112</b> determines whether the first and second objects <b>211</b> and <b>212</b> have common attribute information based on the attribute information of the first and second objects <b>211</b> and <b>212</b> (S<b>106</b>).</p>
<p id="p-0076" num="0075">If having determined that the first and second objects <b>211</b> and <b>212</b> have common attribute information, the user instruction estimate unit <b>112</b> estimates that the user has given an instruction to the effect that classification processing using the common attribute information as classification conditions should be started. This enables the user to start object classification processing without explicitly specifying classification conditions or instructing the performing of the classification processing.</p>
<p id="p-0077" num="0076">On the other hand, if having determined that the first and second objects <b>211</b> and <b>212</b> have no common attribute information, the user instruction estimate unit <b>112</b> estimates that the user has not given an instruction to the effect that the classification processing should be started. In such a case, the information processing apparatus <b>100</b> may notify the user of a alarm, for example, to the effect that objects having different attribute information are going to be classified.</p>
<p id="p-0078" num="0077">It is to be noted that if the condition determination at step S<b>102</b> or S<b>106</b> comes up with &#x201c;NO&#x201d;, the processing by the information processing apparatus <b>100</b> returns to step S<b>102</b>, to wait for acquisition of movement information from the user.</p>
<p id="p-0079" num="0078">If it is estimated that the user has instructed the start of classification processing, the classification processing unit <b>114</b> causes the object group setting unit <b>116</b> to set an object group <b>231</b> made up by the first and second objects <b>211</b> and <b>212</b> (S<b>108</b>). In this case, the object group setting unit <b>116</b> assigns unique identification information to the object group <b>231</b>. The object group setting unit <b>116</b> sets as classification conditions the attribute information common to the first and second objects <b>211</b> and <b>212</b> and sets as a group information a set of the identification information of the first and second objects <b>211</b> and <b>212</b>.</p>
<p id="p-0080" num="0079">Further, the object group setting unit <b>116</b> sets position information of the object group <b>231</b> based on the position information of the first and second objects <b>211</b> and <b>212</b> and flag information by which the object group <b>231</b> is defined as the target object group <b>241</b> to be classified (S<b>110</b>).</p>
<p id="p-0081" num="0080">If the objects are thus set completely by the object group setting unit <b>116</b>, the classification processing unit <b>114</b> starts classification processing based on the classification conditions. Thus, the user can start classification processing on objects without explicitly setting a target object group or instructing the performing of the classification processing.</p>
<p id="p-0082" num="0081">On the other hand, as shown in <figref idref="DRAWINGS">FIG. 4D</figref>, the display control unit <b>118</b> controls display so that the target object group <b>241</b> may be distinguished from the other object groups. It is to be noted that the target object group <b>241</b> may be displayed as distinguished from the other object groups by utilizing, for example, rotation, uplifting, spotlighting, or blinking. Thus, the user can easily confirm the progress status of the object classification processing.</p>
<p id="p-0083" num="0082">In the second place, assume a case where there are object groups <b>232</b> and <b>233</b> on the display screen other than the target object group as shown in <figref idref="DRAWINGS">FIG. 5A</figref>. In this case, if the user has moved the object <b>213</b> so that it might be disposed close to the object group <b>233</b> as shown in <figref idref="DRAWINGS">FIG. 5B</figref>, the operation information acquisition unit <b>102</b> acquires movement information about the object <b>213</b> (S<b>102</b>). Then, based on the movement information, the display control unit <b>118</b> controls display of the object <b>213</b>.</p>
<p id="p-0084" num="0083">If the movement information is acquired, the user instruction estimate unit <b>112</b> determines whether the object <b>213</b> and the object groups <b>232</b> and <b>233</b> are disposed close to each other based on the movement information of the object <b>213</b> and the position information of the object groups <b>232</b> and <b>233</b> (S<b>112</b>). In this case, if the object <b>213</b> and the object groups <b>232</b> and <b>233</b> are disposed within a predetermined distance, the user instruction estimate unit <b>112</b> determines that the object <b>213</b> and the object groups <b>232</b> and <b>233</b> are disposed close to each other.</p>
<p id="p-0085" num="0084">If having determined that the object <b>213</b> and the object group <b>233</b> are disposed close to each other, the user instruction estimate unit <b>112</b> determines whether attribute information of the object <b>213</b> matches classification conditions of the object group <b>233</b> based on the attribute information and the classification conditions (S<b>114</b>). If having determined that the attribute information matches the classification conditions, the user instruction estimate unit <b>112</b> estimates that the user has given an instruction to the effect that classification processing should be started. This enables the user to start object classification processing without explicitly instructing the performing of the classification processing.</p>
<p id="p-0086" num="0085">Then, the display control unit <b>118</b> controls display so that the object <b>213</b> may be taken into the object group <b>233</b> as shown in <figref idref="DRAWINGS">FIG. 5C</figref>. For example, the object <b>213</b> may be uplifted over the object group <b>233</b> once and then displayed as taken into the object group <b>233</b>.</p>
<p id="p-0087" num="0086">On the other hand, if having determined that the attribute information does not match the classification conditions, the user instruction estimate unit <b>112</b> estimates that the user has not given an instruction to the effect that the classification processing should be started. In such a case, the information processing apparatus <b>100</b> may notify the user of a alarm, for example, to the effect that objects that do not match the classification conditions are going to be classified.</p>
<p id="p-0088" num="0087">It is to be noted that if the condition determination at step S<b>112</b> or S<b>114</b> comes up with &#x201c;NO&#x201d;, the processing by the information processing apparatus <b>100</b> returns to step S<b>102</b>, to wait for acquisition of movement information from the user.</p>
<p id="p-0089" num="0088">If it is estimated that the user has instructed the start of classification processing, the classification processing unit <b>114</b> causes the object group setting unit <b>116</b> to set an object group <b>233</b> as the object group <b>233</b> including the object <b>213</b> (S<b>116</b>). In this case, the object group setting unit <b>116</b> adds the identification information of the object <b>213</b> to the group information, and sets the flag information by which the object group <b>233</b> is defined as a target object group <b>242</b> (S<b>110</b>).</p>
<p id="p-0090" num="0089">If the objects are thus set completely by the object group setting unit <b>116</b>, the classification processing unit <b>114</b> starts classification processing based on the classification conditions. Thus, the user can start classification processing on objects without explicitly setting a target object group or instructing the performing of the classification processing.</p>
<p id="p-0091" num="0090">On the other hand, as shown in <figref idref="DRAWINGS">FIG. 5D</figref>, the display control unit <b>118</b> controls display so that the target object group <b>242</b> may be distinguished from the other object groups. Thus, the user can easily confirm the progress status of the object classification processing.</p>
<p id="p-0092" num="0091">In the third place, if a target object group <b>243</b> is set as shown in <figref idref="DRAWINGS">FIG. 6A</figref>, the classification processing unit <b>114</b> starts classification processing based on classification conditions of the target object group <b>243</b>. First, the classification processing unit <b>114</b> extracts objects that have attribute information matching the classification conditions and that are not included in the target object group <b>243</b> or any other object groups, as target objects <b>221</b> and <b>222</b> of classification processing (S<b>122</b>). It is to be noted that if there are not target objects on the display screen, the classification processing unit <b>114</b> stops the classification processing on the target object group <b>243</b>.</p>
<p id="p-0093" num="0092">On the other hand, the display control unit <b>118</b> controls display so that the target objects <b>221</b> and <b>222</b> may be distinguished from the other objects. The target objects <b>221</b> and <b>222</b> may be displayed as distinguished from the other objects by utilizing, for example, rotation, uplifting, spotlighting, or blinking. Thus, the user can easily confirm a target object of classification processing.</p>
<p id="p-0094" num="0093">If the target objects <b>221</b> and <b>222</b> are extracted, the classification processing unit <b>114</b> moves the target objects <b>221</b> and <b>222</b> toward the target object group <b>243</b> at a constant movement speed (S<b>124</b>). The display control unit <b>118</b> controls display so that the target objects <b>221</b> and <b>222</b> move toward the target object group <b>243</b> at the constant movement speed. In this case, the movement of the target objects <b>221</b> and <b>222</b> is expressed by changing the position information of the target objects <b>221</b> and <b>222</b> so that it nears the position information of the target object group <b>243</b> at a constant rate. Therefore, the user can confirm an instruction of the user estimated by the information processing apparatus <b>100</b>.</p>
<p id="p-0095" num="0094">If the target objects <b>221</b> and <b>222</b> start moving, the classification processing unit <b>114</b> determines whether the target objects <b>221</b> and <b>222</b> have moved in such a manner as to be disposed close to the target object group <b>243</b>, based on the position information of the target objects <b>221</b> and <b>222</b> and the position information of the target object group <b>243</b> (S<b>126</b>). In this case, if the target objects <b>221</b> and <b>222</b> and the target object group <b>243</b> are disposed within a predetermined distance, the classification processing unit <b>114</b> determines that both of them are disposed close to each other.</p>
<p id="p-0096" num="0095">If having determined that both are disposed close to each other as shown in <figref idref="DRAWINGS">FIG. 6B</figref>, the classification processing unit <b>114</b> causes the object group setting unit <b>116</b> to set the target object group <b>243</b> as the target object group <b>243</b> including the target object <b>221</b> (S<b>128</b>). In this case, the object group setting unit <b>116</b> adds the identification information of the target object <b>221</b> to the group information. Thus, the user can easily classify objects without explicitly specifying classification conditions or instructing the performing of classification processing. Then, the display control unit <b>118</b> controls display so that the target object <b>221</b> may be taken into the target object group <b>243</b> as shown in <figref idref="DRAWINGS">FIG. 6C</figref>.</p>
<p id="p-0097" num="0096">If the target object <b>221</b> is set as part of the target object group <b>243</b>, the classification processing unit <b>114</b> determines whether there are any other target objects yet to be classified (S<b>130</b>). If there are no other target objects, the classification processing unit <b>114</b> stops the classification processing on the target object group <b>243</b>, and the processing by the information processing apparatus <b>100</b> returns to step S<b>102</b>, to wait for acquisition of movement information from the user. On the other hand, if there are any other target objects, the classification processing unit <b>114</b> continues with the following processing.</p>
<p id="p-0098" num="0097">If the user moves the target objects <b>221</b> and <b>222</b> in motion on the screen in a condition where the target objects <b>221</b> and <b>222</b> have started moving, the operation information acquisition unit <b>102</b> acquires movement information about the target objects <b>221</b> and <b>222</b>, based on which movement information the display control unit <b>118</b> controls display of the target objects <b>221</b> and <b>222</b>. The user instruction estimate unit <b>112</b> estimates a user's instruction for classification processing based on the movement information of the target objects <b>221</b> and <b>222</b> as described below. Thus, the user can easily transmit an instruction for object classification processing to the information processing apparatus <b>100</b>.</p>
<p id="p-0099" num="0098">The user instruction estimate unit <b>112</b> determines whether the target objects <b>221</b> and <b>222</b> are prompted to move or inhibited from moving, based on the movement information of the target objects <b>221</b> and <b>222</b> (S<b>132</b>, S<b>136</b>). In this case, it determines that the target objects <b>221</b> and <b>222</b> are prompted to move if the target object <b>222</b> is moved toward the target object group <b>243</b> as shown in <figref idref="DRAWINGS">FIG. 7A</figref> and, if the target object <b>222</b> is moved away from the target object group <b>243</b> or stopped in motion as shown in <figref idref="DRAWINGS">FIG. 7C</figref>, determines that the target objects <b>221</b> and <b>222</b> are inhibited from moving.</p>
<p id="p-0100" num="0099">It is to be noted that if the condition determination at step S<b>132</b> and S<b>136</b> comes up with &#x201c;NO&#x201d;, the processing by the classification processing unit <b>114</b> returns to step S<b>124</b>, to continue with the movement of the target objects <b>221</b> and <b>222</b>.</p>
<p id="p-0101" num="0100">If having determined that the target object <b>222</b> is prompted to move, the user instruction estimate unit <b>112</b> estimates that the user has given an instruction to the effect that the classification processing under way should be continued. Thus, the user can easily transmit a continuation instruction for classification processing to the information processing apparatus <b>100</b>. On the other hand, if having determined that the target object <b>222</b> is inhibited from moving, the user instruction estimate unit <b>112</b> estimates that the user has given an instruction to the effect that the classification processing under way should be stopped. Thus, the user can easily transmit a stoppage instruction for classification processing to the information processing apparatus <b>100</b>.</p>
<p id="p-0102" num="0101">If the user's instruction is estimated for continuation of the classification processing, the classification processing unit <b>114</b> increases the movement speed of the target objects <b>221</b> and <b>222</b> (S<b>134</b>). Then, the display control unit <b>118</b> controls display so that the target objects <b>221</b> and <b>222</b> may move toward the target object group <b>243</b> at an increased movement speed as shown in <figref idref="DRAWINGS">FIG. 7D</figref>. Thus, the user can confirm that an instruction for the continuation of classification processing is transmitted to the information processing apparatus <b>100</b> and, further, speed up the progress of the classification processing.</p>
<p id="p-0103" num="0102">On the other hand, if the user's instruction is estimated for stoppage of the classification processing, the classification processing unit <b>114</b> stops the movement of the target objects <b>221</b> and <b>222</b> (S<b>138</b>). In this case, the object group setting unit <b>116</b> sets flag information in which the target object group <b>243</b> is defined as an ordinary object group <b>233</b> (S<b>140</b>). Thus, the user can stop classification processing by the information processing apparatus <b>100</b> without explicitly instructing stoppage of the classification processing. Then, the display control unit <b>118</b> controls display so that the target objects <b>221</b> and <b>222</b> are stopped in motion and displayed as ordinary objects <b>214</b> and <b>215</b> respectively as shown in <figref idref="DRAWINGS">FIG. 7D</figref>. Thus, the user can confirm that an instruction for the stoppage of classification processing is transmitted to the information processing apparatus <b>100</b>.</p>
<p id="p-0104" num="0103">If the user's instruction is estimated for the continuation of classification processing, the processing by the information processing apparatus <b>100</b> returns to step S<b>124</b> to continue with the movement of the target objects <b>221</b> and <b>222</b>. On the other hand, if the user's instruction is estimated for the stoppage of the classification processing, the processing by the information processing apparatus <b>100</b> returns to step S<b>102</b> to wait for acquisition of movement information from the user.</p>
<p id="p-0105" num="0104">In order to, for example, change or modify the results of classification processing by the information processing apparatus <b>100</b>, the user can specify a specific object group, for example, through moving operations of the mouse and cancel the setting of the object group through menu operations. In this case, if the operation information acquisition unit <b>102</b> has acquired setting cancellation information for the object group, the classification processing unit <b>114</b> causes the object group setting unit <b>116</b> to establish such setting as to cancel the setting of the object group.</p>
<p id="p-0106" num="0105">The object group setting unit <b>116</b> specifies an object included in an object group based on identification information of the object contained in classification information of the object group and transmits information of the object to the display control unit <b>118</b>. The display control unit <b>118</b> in turn controls display so that the objects displayed as the object group may be displayed as an ordinary object, based on the identification information of the object. Further, the object group setting unit <b>116</b> invalidates the identification information, the position information, the group information, and the flag information of the object group. Thus, the user can change and modify the results of classification processing by the information processing apparatus <b>100</b> by, for example, reclassifying objects once classified, in accordance with the different classification conditions.</p>
<p id="p-0107" num="0106">An object group has identification information of its objects classified in accordance with classification conditions, as group information. This enables the user to move an object group on the display screen as in the case of objects, thereby permitting the information processing apparatus <b>100</b> to perform various kinds of processing on a plurality of objects as a target. For example, in a case where processing icons are disposed on the display screen for the performing of processing items such as saving, deleting, converting of objects, those items of processing can be performed on a target of a plurality of the objects by moving a group of the objects so that the group is disposed close to the processing icons.</p>
<p id="p-0108" num="0107">As described above, by the information processing apparatus <b>100</b> according to the present embodiment, a user's instruction for classification processing on an object is estimated based on attribute information and movement information of the object, and the object is classified based on the estimated user's instruction. Thus, the user can easily classify the objects without explicitly specifying classification conditions or instructing the performing of the classification processing.</p>
<p id="p-0109" num="0108">In particular, objects having the common attribute information are set as an object group having classification conditions that correspond to the attribute information, while an object group to be targeted by classification processing is set as a target object group. Then, classification processing will be performed on target objects which are yet to be classified and have the attribute information matching the classification conditions of the target object group. Target objects yet to be classified will be classified based on the classification conditions of a target object group, so that the user can easily classify the objects without explicitly specifying classification conditions or instructing the performing of the classification processing.</p>
<p id="p-0110" num="0109">Although a preferred embodiment of the present invention is described in the foregoing with reference to the drawings, the present invention is not limited thereto. It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An information processing apparatus having a central processing unit that classifies objects associated with the respective attribute information and associated with position information representing a position where the objects are disposed on a display screen, the apparatus comprising:
<claim-text>a display control unit that controls display of the object on the display screen, wherein the display control unit further comprises an object position control unit that acquires a movement instruction provided by a user and performs movement of the object on the display screen based on the movement instruction;</claim-text>
<claim-text>an operation information acquisition unit that acquires operation information of an object containing movement information, which indicates a movement destination position of the object on the display screen resulting from the movement of the object on the display screen by the object position control unit;</claim-text>
<claim-text>an instructive request estimate unit implemented by the central processing unit that determines, based on whether a compatibility level between the attribute information of the object and attribute information of a resultant proximate object is greater than a predetermined threshold, whether or not the movement of the object on the display screen by the object position control unit is a classification processing request for the object;</claim-text>
<claim-text>a classification processing unit that classifies the object based on a result of the determination by the instructive request estimate unit,</claim-text>
<claim-text>wherein the attribute information of the object is distinct from the operation information and a position of the object on the display screen resulting from movement of the object on the display screen by the object position control unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructive request estimate unit further compares the attribute information of the object with classification conditions of a target object group and, in response to obtaining a positive result from the comparison with regard to compatibility, concludes that the movement of the object is a classification processing request for the object, the target object group including a plurality of objects having a common attribute information and having the classification conditions corresponding to the common attribute information and position information indicating a position on the display screen.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein
<claim-text>the operation information acquisition unit acquires the movement information about a plurality of objects, and</claim-text>
<claim-text>in response to having determined that the objects and a first object group are disposed close to each other from the position information of the first object group and the movement information of the objects and having determined that the attribute information of the objects matches the classification conditions of the first object group, the instructive request estimate unit determines that the movement of the objects is a classification processing request for adding the objects to the first object group.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The information processing apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the classification processing unit sets the first object group including the objects as the target object group, thus starting classification processing based on the classification conditions of the first object group.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein
<claim-text>the classification processing unit initiates movement of a target object toward the target object group at a constant movement speed, and</claim-text>
<claim-text>the display control unit controls display so that the target object moves toward the target object group at the constant movement speed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The information processing apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein in response to the target object being permitted to move close to the target object group, the classification processing unit includes the target object in the target object group.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The information processing apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein
<claim-text>the operation information acquisition unit acquires movement information of the target object, which indicates a movement destination position of the target object on the display screen resulting from movement of the target object, and</claim-text>
<claim-text>the instructive request estimate unit determines, based on the movement information of the target object, whether or not the movement of the target object is a classification processing request for the target object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The information processing apparatus according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein in response to having determined that the target object is prompted to move from the position information of the target object group and from the movement information of the target object, the instructive request estimate unit determines whether or not the movement of the target object resulting from the prompt is a request for continuation of the classification processing.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The information processing apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein
<claim-text>in response to a determination by the instructive request estimate unit that the movement of the target object is the request for the continuation of the classification processing, the classification processing unit initiates an increase in the movement speed of the target object, and</claim-text>
<claim-text>the display control unit controls display so that the target object moves toward the target object group at the increased movement speed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The information processing apparatus according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein in response to having determined that the target object is inhibited from moving from the position information of the target object group and the movement information of the target object, the instructive request estimate unit determines that the movement of the target object is not a request for the classification processing.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The information processing apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein
<claim-text>in response to the instructive request estimating unit determining that the movement is not the request for the classification processing, the classification processing unit initiates cessation of movement of the target object, and</claim-text>
<claim-text>the display control unit controls display so that the target object is stopped in motion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The information processing apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein in response to the instructive request estimating unit determining that the movement is not the request for the classification processing, the classification processing unit sets the target object group as a non-targeted object group.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The information processing apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the display control unit controls display so that the target object is displayed in way such that the target object is distinguishable from objects other than the target object.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein
<claim-text>the operation information acquisition unit acquires setting cancellation information which indicates an instruction to cancel targeting of a specific object group, and</claim-text>
<claim-text>the classification processing unit cancels targeting of the specific object group based on the setting cancellation information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the display control unit controls display so that the target object group is displayed in way such that the target object group is distinguishable from object groups other than the target object group.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the operation information acquisition unit acquires the movement information about the movement of the object and then acquires second movement information about a movement of a second object different from the object, and</claim-text>
<claim-text>in response to having determined that the object and second object are disposed close to each other from the movement information and the second movement information and having determined that the object and the second object have common attribute information, the instructive request estimate unit determines that the movement of the object and the movement of the second object is a classification processing request for classifying the object and the second object into a common new object group.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The information processing apparatus according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the classification processing unit groups the object and the second object the new object group, thus starting the new object group based on classification conditions of the common attribute information of the object and the second object.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. An information processing method, implemented by a information processing apparatus having a central processing unit, of classifying objects associated with the respective attribute information and associated with position information representing a position where the objects are disposed on a display screen, the method comprising the steps of:
<claim-text>controlling display of the object on the display screen, the controlling further comprising
<claim-text>acquiring a movement instruction provided by a user, and</claim-text>
<claim-text>performing movement of the object on the display screen based on the movement instruction;</claim-text>
</claim-text>
<claim-text>acquiring operation information containing movement information of an object, which indicates a movement destination position of the object on the display screen resulting from the movement of the object on the display screen by the performing;</claim-text>
<claim-text>determining, based on whether a compatibility level between the attribute information of the object and attribute information of a resultant proximate object is greater than a predetermined threshold using the central processing unit, whether or not the movement of the object on the display screen by the performing is a classification processing request for the object, the attribute information of the object being distinct from the operation information and a position of the object on the display screen resulting from movement of the object on the display screen by the performing; and</claim-text>
<claim-text>classifying the object based on a result of the determination by the determining.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A non-transitory computer readable medium having stored thereon a program that when executed by a computer causes the computer to perform an information processing method of classifying objects associated with the respective attribute information and associated with position information representing a position where the objects are disposed on a display screen, the information processing method comprising the steps of:
<claim-text>controlling display of the object on the display screen, the controlling further comprising
<claim-text>acquiring a movement instruction provided by a user, and</claim-text>
<claim-text>performing movement of the object on the display screen based on the movement instruction;</claim-text>
</claim-text>
<claim-text>acquiring operation information containing movement information of an object, which indicates a movement destination position of the object on the display screen resulting from movement of the object on the display screen by the performing;</claim-text>
<claim-text>determining, based on whether a compatibility level between the attribute information of the object and attribute information of a resultant proximate object is greater than a predetermined threshold, whether or not the movement of the object on the display screen by the performing is a classification processing request for the object, the attribute information of the object being distinct from the operation information and a position of the object on the display screen resulting from movement of the object on the display screen by the performing;</claim-text>
<claim-text>classifying the object based on a result of the determination by the determining; and</claim-text>
<claim-text>controlling display of the object on the display screen.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the attribute information of the object is distinct from the position of the object on the display screen resulting from movement of the object.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the attribute information is distinct from an appearance of the object on the display screen. </claim-text>
</claim>
</claims>
</us-patent-grant>
