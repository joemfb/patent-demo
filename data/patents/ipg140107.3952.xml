<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625020-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625020</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13111227</doc-number>
<date>20110519</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2010-0053223</doc-number>
<date>20100607</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>204</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>222</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>34833306</main-classification>
<further-classification>34833302</further-classification>
</classification-national>
<invention-title id="d2e71">Method and apparatus for operating camera function in portable terminal</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2007/0004451</doc-number>
<kind>A1</kind>
<name>Anderson</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4555561</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2007/0070184</doc-number>
<kind>A1</kind>
<name>Kim et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1402</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2008/0002963</doc-number>
<kind>A1</kind>
<name>Chuang et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396310</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2008/0036876</doc-number>
<kind>A1</kind>
<name>Kaneda et al.</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482301</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2010/0149398</doc-number>
<kind>A1</kind>
<name>Gayer</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34833301</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>34833301-33312</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348373</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>21</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110298940</doc-number>
<kind>A1</kind>
<date>20111208</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Cheong</last-name>
<first-name>Cheol-Ho</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Dong-Hoon</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Cheong</last-name>
<first-name>Cheol-Ho</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Dong-Hoon</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Cha &#x26; Reiter, LLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Samsung Electronics Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Suwon-si, Gyeonggi-do</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Jerabek</last-name>
<first-name>Kelly L</first-name>
<department>2662</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and an apparatus for operating a camera function in a portable terminal are provided. State information representing at least one of a direction and a rotation state of the portable terminal is obtained, and at least one of a sequence of reading an image from a camera sensor and an appropriate user interface is determined depending on the state information. Thus, the camera function is performed depending on the determined sequence or user interface.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="250.36mm" wi="173.14mm" file="US08625020-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="139.45mm" wi="158.50mm" file="US08625020-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="231.82mm" wi="177.29mm" orientation="landscape" file="US08625020-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="97.79mm" wi="141.73mm" file="US08625020-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="249.34mm" wi="172.30mm" file="US08625020-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="146.98mm" wi="107.61mm" file="US08625020-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="242.99mm" wi="177.12mm" file="US08625020-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="247.73mm" wi="161.97mm" orientation="landscape" file="US08625020-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="219.96mm" wi="162.81mm" file="US08625020-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="246.21mm" wi="181.86mm" orientation="landscape" file="US08625020-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="247.73mm" wi="186.61mm" orientation="landscape" file="US08625020-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CLAIM OF PRIORITY</heading>
<p id="p-0002" num="0001">This application claims the benefit under 35 U.S.C. &#xa7;119 of a Korean patent application filed in the Korean Intellectual Property Office on Jun. 7, 2010 and assigned Serial No. 10-2010-0053223, the entire disclosure of which is hereby incorporated by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to a method and an apparatus for operating a camera function in a portable terminal based on a sensor.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Recently, as users' interest in a digital camera rapidly increases, portable terminals mounting a plurality of cameras therein are being provided. These cameras are used for capturing images at different angles or for a different purpose. For example, as illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, cameras <b>101</b>, <b>103</b>, and <b>105</b> are typically provided in a folder inner portion, a front side, and a rear side, respectively. The camera <b>101</b> mounted in the folder inner portion is used for video communication, the camera <b>103</b> mounted in the front side is used for capturing images of the user, and the camera <b>105</b> mounted in the rear side is used for capturing a different object.</p>
<p id="p-0007" num="0006">Most of cameras mounted in the conventional portable terminal are fixed at a specific position, thus have some drawbacks. In operation, the orientation of captured image may be changed due to the user's motion of rotating the portable terminal. For example, as illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, when a user rotates a portable terminal mounting a camera unit therein by 90 degrees, 180 degrees, and 270 degrees and captures an image, the direction of an image displayed on a lens or a Liquid Crystal Display (LCD) screen and the direction of an image actually stored in the portable terminal are different from each other. That is, even when the direction of the portable terminal changes, the user cannot recognize the changed direction through the screen or lens, but the captured result image is rotated according to the direction of the portable terminal and stored or transferred to a different apparatus.</p>
<p id="p-0008" num="0007">Meanwhile, since most of portable terminals are configured for right-handed users, left-handed users have an inconvenience in using the portable terminal. For example, a portable terminal has a shutter button for capturing at a position that is easy to use with a right hand, and accordingly, a left-handed user has an inconvenience of having to press the shutter button located at the position that is difficult to press with a left hand, or press the shutter button with an unfamiliar right hand.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">An aspect of the present invention is to address at least the above-mentioned problems and/or disadvantages and to provide at least the advantages described below. Accordingly, an aspect of the present invention is to provide a method and an apparatus for operating a camera function based on a sensor in a portable terminal.</p>
<p id="p-0010" num="0009">Another aspect of the present invention is to provide a method and an apparatus for operating a multi-camera according to state information of a terminal based on a sensor in the portable terminal.</p>
<p id="p-0011" num="0010">Still another aspect of the present invention is to provide a method and an apparatus for a user interface according to state information of a terminal based on a sensor in the portable terminal.</p>
<p id="p-0012" num="0011">Yet another aspect of the present invention is to provide a method and an apparatus for displaying and storing a captured image according to state information of a terminal based on a sensor in the portable terminal.</p>
<p id="p-0013" num="0012">Further yet another aspect of the present invention is to provide a method and an apparatus for providing various capturing techniques using a multi-camera in a portable terminal.</p>
<p id="p-0014" num="0013">In accordance with an aspect of the present invention, a method for operating a camera function in a portable terminal includes executing a camera application, obtaining state information representing at least one of a direction and a rotation state of the portable terminal, determining at least one of a sequence of reading an image from a camera sensor and a user interface depending on the state information, and performing the camera function depending on the determined sequence or user interface.</p>
<p id="p-0015" num="0014">In accordance with another aspect of the present invention, an apparatus for operating a camera function in a portable terminal includes a state information recognizer for, when a camera application is executed, obtaining state information representing at least one of a direction and a rotation state of the portable terminal, and a controller for determining at least one of a sequence of reading an image from a camera sensor and a user interface depending on the state information, and controlling the camera function depending on the determined sequence or user interface.</p>
<p id="p-0016" num="0015">Other aspects, advantages and salient features of the invention will become apparent to those skilled in the art from the following detailed description, which, taken in conjunction with the annexed drawings, discloses exemplary embodiments of the invention.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0017" num="0016">The above and other aspects, features and advantages of certain exemplary embodiments of the present invention will be more apparent from the following description taken in conjunction with the accompanying drawings in which:</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a view illustrating a portable terminal mounting a multi-camera therein;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> shows views illustrating result images captured according to a rotation state of a terminal in the conventional portable terminal;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating a portable terminal according to an exemplary embodiment of the present invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating a procedure for performing a camera function depending on a rotation state in a portable terminal according to an exemplary embodiment of the present invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating a procedure for displaying an image depending on a rotation state in a portable terminal according to an exemplary embodiment of the present invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating a procedure for operating a multi-camera and capturing an image in a portable terminal according to an exemplary embodiment of the present invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 7A to 7D</figref> are views illustrating result images captured according to a rotation state of a terminal in the portable terminal according to an exemplary embodiment of the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. 8A and 8B</figref> are views illustrating a user interface depending on a rotation state in a portable terminal according to an exemplary embodiment of the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 9A to 9D</figref> are views illustrating a sequence of reading an image depending on a rotation state in a portable terminal according to an exemplary embodiment of the present invention; and</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. 10A and 10B</figref> are views illustrating an example of operating a multi-camera and capturing an image in a portable terminal according to an exemplary embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0028" num="0027">Throughout the drawings, like reference numerals will be understood to refer to like parts, components and structures.</p>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0029" num="0028">The following description with reference to the accompanying drawings is provided to assist in a comprehensive understanding of exemplary embodiments of the invention as defined by the claims and their equivalents. Also, descriptions of well-known functions and constructions are omitted for clarity and conciseness.</p>
<p id="p-0030" num="0029">Hereinafter, a case where the camera is fixedly mounted on a predetermined position of a portable terminal is exemplarily described. Accordingly, in the following description, the state information, i.e., the direction or rotation state of the portable terminal denotes the direction or rotation state of the camera mounted in the portable terminal.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating a portable terminal according to an exemplary embodiment of the present invention.</p>
<p id="p-0032" num="0031">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, the portable terminal includes a controller <b>300</b>, a camera unit <b>310</b>, a storage unit <b>320</b>, a state information recognizer <b>330</b>, a display unit <b>340</b>, an input unit <b>350</b>, and a communication unit <b>360</b>.</p>
<p id="p-0033" num="0032">The controller <b>300</b> controls an overall operation of the portable terminal. More particularly, the controller <b>300</b> determines a capture camera depending on the state information of the portable terminal, determines and changes a user interface for controlling a camera function, determines an output sequence of an image signal input from a camera sensor to control and process a function for displaying and storing an image in the normal direction. Here, the state information of the portable terminal denotes the direction or rotation state of the portable terminal.</p>
<p id="p-0034" num="0033">In operation, when the portable terminal has two or more cameras, the controller <b>300</b> may determine a camera to be used for capturing among the two or more cameras depending on the rotation state of the portable terminal. The controller <b>300</b> may determine the camera to be used depending on the type of an application executed by a user. In addition, the controller <b>300</b> controls a function for changing a user interface (for example, a shutter key/icon, a zoom control key/icon, and a capture key/icon) depending on the rotation state of the portable terminal. Moreover, the controller <b>300</b> determines an output sequence of an image signal input from a camera sensor depending on the rotation state of the portable terminal and displays an input image on the screen in the normal direction as illustrated in <figref idref="DRAWINGS">FIGS. 7A to 7D</figref>, and simultaneously, controls and processes a function for storing the input image in the normal direction. Here, the output sequence of the input image signal denotes a sequence in which the controller <b>300</b> reads an image from the camera sensor.</p>
<p id="p-0035" num="0034">Furthermore, the controller <b>300</b> controls a function for displaying an image such that the captured image stored in the storage unit <b>320</b> is displayed in the normal direction when the user views the image. In addition, the controller <b>300</b> controls a function for capturing an image in a Picture In Picture (PIP) mode using a plurality of cameras.</p>
<p id="p-0036" num="0035">The controller <b>300</b> controls and processes various functions for performing operations illustrated in <figref idref="DRAWINGS">FIGS. 4 to 6</figref>.</p>
<p id="p-0037" num="0036">The camera unit <b>310</b> includes at least one camera, drives a camera for capturing under control of the controller <b>300</b>, and provides an image signal input via a sensor of the driven camera to the controller <b>300</b>. The camera unit <b>310</b> provides an image signal input via the sensor to the controller <b>300</b> according to an image signal output sequence determined by the controller <b>300</b>. That is, when the output sequence determined by the controller <b>300</b> is a sequence corresponding to the normal direction, the camera unit <b>310</b> provides pixel information input from the camera sensor in the sequence of (0,0), (0,1), (0,2), . . . , (0,n&#x2212;1), (1,0), (1,1), . . . , (m&#x2212;1,n&#x2212;2), (m&#x2212;1,n&#x2212;1) to the controller <b>300</b> as illustrated in <figref idref="DRAWINGS">FIG. 9A</figref>. When the output sequence determined by the controller <b>300</b> is a sequence corresponding to a 180-degree direction, the camera unit <b>310</b> provides pixel information input from the camera sensor in the sequence of (m&#x2212;1,n&#x2212;1), (m&#x2212;1,n&#x2212;2), (m&#x2212;1,n&#x2212;3), . . . , (m&#x2212;2,n&#x2212;1), (m&#x2212;2,n&#x2212;2), . . . , (0,2), (0,1), (0,0) to the controller <b>300</b> as illustrated in <figref idref="DRAWINGS">FIG. 9C</figref>.</p>
<p id="p-0038" num="0037">The storage unit <b>320</b> stores various programs and data for an overall operation of the portable terminal, and stores a captured image under control of the controller <b>300</b>. Here, the size of a memory map for storing the captured image in the storage unit <b>320</b> may correspond to a maximum number of the horizontal pixels of the camera. For example, when a maximum number of horizontal pixels of the camera is m, the memory map of the camera has a size of m.times.m for preventing an angle of view from being lost depending on the rotation state of the portable terminal. For example, when the size of the memory map storing the captured image is fixed according to the horizontal direction of the portable terminal, when the portable terminal performs a vertical capturing operation, since a horizontal-to-vertical ratio becomes different, this configuration of the memory map size prevents an angle of view from being lost. That is, when a camera memory map is fixed to 320.times.240 according to the horizontal direction of the portable terminal, when the portable terminal performs a vertical capturing operation, the horizontal-to-vertical ratio of a captured image changes to 240.times.320, and consequently, the captured image is reduced to 240.times.160 according to the horizontal-to-vertical ratio of fixed memory map. The configuration of the memory map size prevents this loss in the angle of view.</p>
<p id="p-0039" num="0038">The state information recognizer <b>330</b> detects state information representing the direction or rotation state of the portable terminal, and provides the state information to the controller <b>300</b>. Here, the state information recognizer <b>330</b> may detect the state information of the portable terminal using one of an accelerometer sensor, a gyroscope sensor, a horizontal angle measuring sensor, a touch sensor, and a user interface. That is, the state information recognizer <b>330</b> may detect the direction or rotation state of the portable terminal by measuring an angular velocity when the portable terminal rotates from a reference position using the accelerometer sensor. In addition, the state information recognizer <b>330</b> may detect the rotation state by measuring a horizontal angle of the portable terminal using the horizontal sensor. In addition, the state information recognizer <b>330</b> may detect the direction or rotation state of the portable terminal by recognizing applied pressure or static electricity using the touch sensor mounted on the surface of the portable terminal when a user of the portable terminal grips the portable terminal and analyzing the pattern of the surface contacted by the user's hand. In addition, the state information recognizer <b>330</b> may obtain state information of the portable terminal through an icon provided as a user interface or direction information selected or input by the user. Here, the state information recognizer <b>330</b> may use the above-described two or more methods in order to accurately detect the state information of the portable terminal.</p>
<p id="p-0040" num="0039">The display unit <b>340</b> displays various state information, numbers, letters, and images occurring during an operation of the portable terminal. More particularly, the display unit <b>340</b> displays an image signal input from the camera unit <b>310</b> on a screen in real-time and displays a captured image stored in advance on the screen in the normal direction under control of the controller <b>300</b>.</p>
<p id="p-0041" num="0040">In addition, the display unit <b>340</b> may display information regarding a change in a user interface according to the state information of the portable terminal under control of the controller <b>300</b>. That is, when the portable terminal performs an image capturing operation using a key, the display unit <b>340</b> may display to show that the function of each key has changed. When the portable terminal uses a touch screen, the display unit <b>340</b> may change and display capturing functions displayed on the screen depending on the rotation state of the portable terminal. For example, as illustrated in <figref idref="DRAWINGS">FIG. 8A</figref>, while the terminal does not rotate, the display unit <b>340</b> may display that a key A performs a shutter function and a key B performs a zoom function on a screen. When the terminal rotates by 180 degrees, the display unit <b>340</b> may display that the key B performs the shutter function and the key A performs the zoom function on the screen. In addition, as illustrated in <figref idref="DRAWINGS">FIG. 8B</figref>, while the portable terminal does not rotate, the display unit <b>340</b> may display a shutter icon on the right upper end of the screen. When the portable terminal rotates by 180 degrees, the display unit <b>340</b> may display the shutter icon on the left upper end of the screen. Further, the display unit <b>340</b> may display an image in a Picture In Picture (PIP) mode under control of the controller <b>300</b> as illustrated in <figref idref="DRAWINGS">FIGS. 10A and 10B</figref>.</p>
<p id="p-0042" num="0041">The input unit <b>350</b> has at least one function key or touch sensor to provide data input by a user to the controller <b>300</b>. That is, the input unit <b>350</b> provides data corresponding to a key pressed by a user to the controller <b>300</b> or provides the coordinate of a position touched by the user to the controller <b>300</b>.</p>
<p id="p-0043" num="0042">The communication unit <b>360</b> transmits/receives a signal to/from an external apparatus via a wired line or wirelessly under control of the controller <b>300</b>. For example, the communication unit <b>360</b> may transmit a captured image to a different portable terminal connected wirelessly and may transmit a captured image to a computer system connected via a wired line under control of the controller <b>300</b>.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating the process for performing a camera function depending on a rotation state in a portable terminal according to an exemplary embodiment of the present invention.</p>
<p id="p-0045" num="0044">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, in step <b>401</b>, the portable terminal determines whether an application that requires a camera operation is executed, and if so, the portable terminal obtains the state information of the portable terminal, i.e., information representing the direction or rotation state through the state information recognizer <b>330</b> in step <b>403</b>. Here, the rotation state of the portable terminal may be divided into a 0-degree rotation state, a 90-degree rotation state, a 180-degree rotation state, and a 270-degree rotation state. Accordingly, each rotation state includes &#xb1;45 degree. That is, when the portable terminal has a rotation state between 45 degrees and 135 degrees, the rotation state of the portable terminal may be determined as the 90 degrees. According to an exemplary embodiment of the present invention, description is made on the assumption that the case illustrated in <figref idref="DRAWINGS">FIG. 7A</figref> is a normal state of the portable terminal, i.e., a 0-degree rotate state.</p>
<p id="p-0046" num="0045">When the state information of the portable terminal is obtained, the portable terminal proceeds to step <b>405</b> to determine a camera to be used for executing the application. For example, when the portable terminal includes a horizontal mode camera and a vertical mode camera, when the portable terminal rotates by 0 degree or 180 degrees, the portable terminal determines the horizontal mode camera. In contrast, when the portable terminal rotates by 90 degrees or 270 degrees, the portable terminal may determine the vertical mode camera. The horizontal mode camera has more horizontal pixels than vertical pixels, and therefore horizontal mode camera is more suitable for the images in which horizontal length is greater than vertical length. The vertical mode camera has more vertical pixels than horizontal pixels, and therefore vertical mode camera is more suitable for the images in which vertical length is greater than horizontal length. In addition, the portable terminal may determine the camera with consideration of whether the folder or slide of the portable terminal is opened and the executed application, and may simply determine the camera selected by the user through a key button or an icon provided to the portable terminal in step <b>405</b>.</p>
<p id="p-0047" num="0046">When the camera is determined, the portable terminal determines a user interface corresponding to state information of the portable terminal and an output sequence of an input image in step <b>407</b>. That is, as illustrated in <figref idref="DRAWINGS">FIGS. 8A and 8B</figref>, the portable terminal determines the user interface used for capturing depending on the rotation state of the portable terminal. For example, as illustrated in <figref idref="DRAWINGS">FIG. 8A</figref>, while the portable terminal rotates by 0 degree, the portable terminal determines the user interface such that the key A performs the shutter function and the key B performs the zoom function. In contrast, when the portable terminal rotates by 180 degrees, the portable terminal determines the user interface such that the key B performs the shutter function and the key A performs the zoom function. In addition, as illustrated in <figref idref="DRAWINGS">FIG. 8B</figref>, while the portable terminal rotates by 0 degree, the portable terminal determines the user interface such that a shutter icon exists on the right upper end of the screen. In contrast, when the portable terminal rotates by 180 degrees, the portable terminal may determine the user interface such that the shutter icon exists on the left upper end of the screen. Further, the portable terminal determines a sequence in which an input image from the camera sensor is output on the screen. For example, when the portable terminal rotates by 0 degree, the portable terminal determines a normal direction sequence so that pixel information input from the camera sensor is output on the screen in the sequence of (0,0), (0,1), (0,2), . . . , (0,n&#x2212;1), (1,0), (1,1), . . . , (m&#x2212;1,n&#x2212;2), (m&#x2212;1,n&#x2212;1) as illustrated in <figref idref="DRAWINGS">FIG. 9A</figref>. When the portable terminal rotates by 180, the portable terminal determines a 180-degree direction sequence so that pixel information input from the camera sensor is output on the screen in the sequence of (m&#x2212;1,n&#x2212;1), (m&#x2212;1,n&#x2212;2), (m&#x2212;1,n&#x2212;3), . . . , (m&#x2212;2,n&#x2212;1), (m&#x2212;2,n&#x2212;2), . . . , (0,2), (0,1), (0,0) as illustrated in <figref idref="DRAWINGS">FIG. 9C</figref>.</p>
<p id="p-0048" num="0047">The portable terminal drives the determined camera in step <b>409</b>, and displays an input image on the screen according to the determined output sequence and displays the determined user interface on the screen in step <b>411</b>.</p>
<p id="p-0049" num="0048">The portable terminal determines whether the state information of the portable terminal changes in step <b>413</b>. That is, the portable terminal determines whether the portable terminal rotates according to the user's motion while the portable terminal drives the camera and performs a screen display operation.</p>
<p id="p-0050" num="0049">When the state information of the portable terminal changes, the portable terminal proceeds to step <b>415</b> to determine a user interface and an input image output sequence depending on the changed state information and returns to step <b>411</b>.</p>
<p id="p-0051" num="0050">In contrast, when the state information of the portable terminal does not change, the portable terminal proceeds to step <b>417</b> to determine whether an image capture event occurs. For example, the portable terminal determines whether a shutter key or a shutter icon is input, or whether a predetermined automatic capture condition is met. When the image capture event does not occur, the portable terminal returns to step <b>413</b> to re-perform subsequent steps.</p>
<p id="p-0052" num="0051">When the image capture event occurs, the portable terminal proceeds to step <b>419</b> to store a relevant image according to the determined input image output sequence. For example, as illustrated in <figref idref="DRAWINGS">FIGS. 9A to 9D</figref>, the portable terminal stores a relevant image in the storage unit <b>320</b> according to the image output sequence determined depending on the rotation state of the portable terminal. Therefore, as illustrated in <figref idref="DRAWINGS">FIGS. 7A to 7D</figref>, the portable terminal may store a captured image such that the image is always stored in the normal direction even when the portable terminal captures the image in a rotated state.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating the process for displaying an image depending on a rotation state in a portable terminal according to an exemplary embodiment of the present invention.</p>
<p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIG. 5</figref>, the portable terminal determines whether an event for displaying a captured image occurs in step <b>501</b>. For example, the portable terminal determines whether a view menu for viewing a captured image stored in the portable terminal is selected.</p>
<p id="p-0055" num="0054">When the event for displaying the captured image occurs, the portable terminal obtains the state information of the portable terminal, i.e., information representing the direction or rotation state in step <b>503</b>.</p>
<p id="p-0056" num="0055">The portable terminal determines an output sequence of a relevant captured image depending on the state information in step <b>505</b>. For example, when the state information represents 0-degree rotation state, the portable terminal determines output on the screen in the sequence of (0,0), (0,1), (0,2), . . . , (0,n&#x2212;1), (1,0), (1,1), . . . , (m&#x2212;1,n&#x2212;2), (m&#x2212;1,n&#x2212;1) as illustrated in <figref idref="DRAWINGS">FIG. 9A</figref>. When the state information represents 180-degree rotation state, the portable terminal determines output on the screen in the sequence of (m&#x2212;1,n&#x2212;1), (m&#x2212;1,n&#x2212;2), (m&#x2212;1,n&#x2212;3), . . . , (m&#x2212;2,n&#x2212;1), (m&#x2212;2,n&#x2212;2), . . . , (0,2), (0,1), (0,0) as illustrated in <figref idref="DRAWINGS">FIG. 9C</figref>, and the portable terminal reads the relevant captured image from the storage unit <b>320</b> and displays the same on the screen according to the determined output sequence in step <b>507</b>. Accordingly, the user may view a captured image displayed in the normal direction even when the portable terminal rotates.</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating the process for operating a multi-camera and capturing an image in a portable terminal according to an exemplary embodiment of the present invention.</p>
<p id="p-0058" num="0057">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, the portable terminal determines whether an application that requires operations of two cameras is executed in step <b>601</b>. For example, the portable terminal determines whether a PIP mode capture menu is selected.</p>
<p id="p-0059" num="0058">When the application that requires the operations of the two cameras is executed, the portable terminal determines two cameras to be used for the application in step <b>603</b>. Here, the portable terminal may determine the two cameras with consideration of the state information of the portable terminal, whether a folder or a slide is opened, and the executed application. Alternatively, the portable terminal may simply determine a camera(s) selected by a user through a key button or an icon provided to the portable terminal.</p>
<p id="p-0060" num="0059">Thereafter, the portable terminal determines the purposes of the two cameras in step <b>605</b>. For example, as illustrated in <figref idref="DRAWINGS">FIG. 10B</figref>, the portable terminal may determine one of the two cameras for the purpose of a background image capturing, and may determine the other camera for the purpose of a sub image capturing. Such purposes of the cameras may be automatically determined depending on a camera position mounted on the portable terminal, or may be manually selected by a user. That is, the portable terminal may determine a camera mounted in the rear side for the purpose of a background image capturing, and may determine a camera mounted in the front side for the purpose of a sub image capturing.</p>
<p id="p-0061" num="0060">The portable terminal determines a first camera image display region and a second camera image display region in step <b>607</b>. Here, the two camera image display regions may be automatically determined according to a predetermined scheme, and may be manually determined by a user. The portable terminal drives the first camera to display an image input from the first camera on the first camera image display region, and drives the second camera to display an image input from the second camera on the second camera image display region in step <b>609</b>. For example, the portable terminal determines a camera mounted in the front side of the portable terminal as a camera for a sub capturing, determines a camera mounted in the rear side of the portable terminal as a camera for a background capturing, displays an image input from the camera for the background capturing as a background image of the screen, and displays an image input from the camera for the sub capturing on a predetermined region of the background image as illustrated in <figref idref="DRAWINGS">FIG. 10A</figref>. Here, as illustrated in <figref idref="DRAWINGS">FIG. 4</figref>, the portable terminal may configure a user interface depending on the state information of the portable terminal, and may determine an output sequence of an image signal input from each camera sensor depending on the state information of the portable terminal.</p>
<p id="p-0062" num="0061">The portable terminal determines whether an image capture event occurs in step <b>611</b>. For example, the portable terminal determines whether a shutter key or a shutter icon is input, or whether an automatic capture condition set in advance is met. When the image capture event does not occur, the portable terminal determines whether an event for changing an image display region occurs according to user manipulation in step <b>615</b>. When the display region change event does not occur, the portable terminal returns to step <b>611</b>. When the display region change event occurs, the portable terminal proceeds to step <b>617</b> to change the first camera image display region and the second camera image display region and display an image input from each camera according to the user manipulation, and then returns to step <b>611</b>.</p>
<p id="p-0063" num="0062">When the image capture event occurs, the portable terminal proceeds to step <b>613</b> to store a relevant image according to the determined input image output sequence, and ends the algorithm according to an exemplary embodiment of the present invention.</p>
<p id="p-0064" num="0063">In the above, a method for maintaining an image in the normal direction by controlling a sequence of reading an image from a camera sensor depending on the rotation state of the portable terminal has been described using a case where a camera is fixedly mounted in the portable terminal as an example. However, when the camera mounted in the portable terminal is not fixed, a predetermined pendulum is mounted such that the center of mass is directed to the lower portion of a camera module, and the camera module is made rotatable, so that the camera always maintains a horizontal state and thus maintains an image in the normal direction even when the sequence of reading an image from the camera sensor is not controlled.</p>
<p id="p-0065" num="0064">Note that the above-described methods according to the present invention can be realized in hardware or as software or computer code that can be stored in a recording medium such as a CD ROM, an RAM, a floppy disk, a hard disk, or a magneto-optical disk or downloaded over a network, so that the methods described herein can be executed by such software using a general purpose computer, or a special processor or in programmable or dedicated hardware, such as an ASIC or FPGA. As would be understood in the art, the computer, the processor or the programmable hardware include memory components, e.g., RAM, ROM, Flash, etc. that may store or receive software or computer code that when accessed and executed by the computer, processor or hardware implement the processing methods described herein.</p>
<p id="p-0066" num="0065">Exemplary embodiments of the present invention provide effects of detecting the rotation state of a camera and automatically changing a camera image in the normal direction to provide the same to a user and store the same, thus providing a more convenient interface to the user depending on the rotation state of the camera. This is achieved by operating a camera function depending on the state information of a sensor-based portable terminal in the portable terminal. In addition, exemplary embodiments may be usefully utilized for even the case of using a web cam function that uses a camera of the portable terminal, and may be usefully utilized for the case of synthesizing a screen using a plurality of cameras. Further, even when a cable, a memory card, and USB devices are mounted in the portable terminal and so an installation direction of the camera is limited due to space constraints, the direction of the portable terminal may be changed and used, so that usability improves.</p>
<p id="p-0067" num="0066">Although the invention has been shown and described with reference to certain exemplary embodiments thereof, it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the spirit and scope of the invention as defined by the appended claims and their equivalents. Therefore, the scope of the present invention should not be limited to the above-described embodiments but should be determined by not only the appended claims but also the equivalents thereof.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for operating a camera function in a portable device, the method comprising:
<claim-text>obtaining state information representing at least one of a direction and a rotation state of the portable device;</claim-text>
<claim-text>determining a sequence of reading an image from a camera sensor, and a user interface, depending on the state information, wherein an image capturing function of a user interface key is changed from a camera shutter function to a zoom function in response to a change in the state information; and</claim-text>
<claim-text>performing the camera function depending on the user interface.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the state information is obtained using at least one of an accelerometer sensor, a gyroscope sensor, a horizontal angle measuring sensor, a touch sensor, and a user interface.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the performing of the camera function depending on the determined sequence comprises:
<claim-text>displaying an image input from the camera sensor on a screen according to the determined sequence; and</claim-text>
<claim-text>storing a relevant image according to the determined sequence.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining of the user interface depending on the state information comprises changing a region for displaying at least one capture icon displayed on a screen depending on the state information.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining at least one camera to operate among a plurality of cameras mounted in the portable device using at least the state information of the portable device.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the state information represents one of a horizontal orientation mode, a vertical orientation mode, a 0-degree rotation state, a 90-degree rotation state, a 180-degree rotation state and a 270-degree rotation state.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sequence of reading an image from a camera sensor is selectively determined based on the state information so that an orientation of an input image is stored and displayed in the portable device is in the same direction.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the user interface key is a first key disposed at a top portion of the portable device when the portable device is in a first orientation, the first key operative as a shutter key in the first orientation of the portable device;</claim-text>
<claim-text>the portable device comprises a second user interface key disposed at a bottom portion thereof and operative as a zoom key when the portable device is in the first orientation; and</claim-text>
<claim-text>when an orientation of the portable device is detected in a second orientation, the first key is operative as a zoom key and the second key is operative as a shutter key.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein:
<claim-text>when the portable device is in the first orientation, the first key is disposed at an upper right portion of the portable device and the second key is disposed at a lower left portion of the portable device; and</claim-text>
<claim-text>the second orientation is a 180&#xb0; rotation with respect to the first orientation, such that in the second orientation, the second key is disposed at an upper right portion of the portable device and the first key is disposed at a lower left portion of the portable device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A method for operating a camera function in a portable device comprising at least two cameras, the method comprising:
<claim-text>obtaining state information representing at least one of a direction and a rotation state of the portable device;</claim-text>
<claim-text>determining a sequence of reading an image from a camera sensor, and a user interface, depending on the state information, wherein an image capturing function of a user interface key is changed from a first function to a second function in response to a change in the state information; and</claim-text>
<claim-text>performing the camera function depending on the user interface;</claim-text>
<claim-text>activating a picture in picture (PIP) mode responsive to at least one of a change in the state information of the portable device, a change in an open/closed position of a folder or responsive to a slide of the portable device;</claim-text>
<claim-text>wherein in the PIP mode, a region is determined for displaying input images of each of the cameras, and an image input from each camera is displayed in the determined region.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A portable device, comprising:
<claim-text>a state information recognizer for obtaining state information representing at least one of a direction and a rotation state of the portable device; and</claim-text>
<claim-text>a controller for determining a sequence of reading an image from a camera sensor and a user interface depending on the state information, and controlling the camera function for capturing, storing and displaying an input image depending on the sequence and user interface;</claim-text>
<claim-text>wherein an image capturing function of a user interface key is changed from a camera shutter function to a zoom function in response to a change in the state information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The portable device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the state information is obtained using at least one of an accelerometer sensor, a gyroscope sensor, a horizontal angle measuring sensor, a touch sensor, and a user interface.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The portable device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the controller displays an image input from the camera sensor on a screen according to the determined sequence and stores a relevant image according to the determined sequence.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The portable device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein a memory map for storing the input image from the camera sensor has a size corresponding to a maximum number of horizontal pixels of the portable device.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The portable device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the controller changes a region for displaying at least one capture icon displayed on a screen from a right side region in a first orientation of the portable device to a left side region in a second orientation of the portable device that is 180&#xb0; rotated with respect to the first orientation as determined from the state information.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The portable device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising a plurality of cameras, wherein the controller determines at least one camera to operate among the plurality of cameras using at least the state information of the portable device.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The portable device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the sequence of reading the input image from a camera sensor is selectively determined based on the state information so that an orientation of an input image is stored and displayed in the portable device is in the same direction.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A portable device, comprising:
<claim-text>at least two cameras;</claim-text>
<claim-text>a state information recognizer for obtaining state information representing at least one of a direction and a rotation state of the portable device; and</claim-text>
<claim-text>a controller for determining a sequence of reading an image from a camera sensor and a user interface depending on the state information, controlling the camera function for capturing, storing and displaying an input image depending on the sequence and user interface, and activating a picture in picture (PIP) mode responsive to at least one of a change in the state information of the portable device, a change in an open/closed position of a folder or responsive to a slide of the portable device;</claim-text>
<claim-text>wherein an image capturing function of a user interface key is changed from a first function to a second function in response to a change in the state information, and</claim-text>
<claim-text>wherein in the PIP mode, a region is determined for displaying input images of each of the cameras, and an image input from each camera is displayed in the determined region.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A method for operating a camera function in a portable device comprising at least two cameras, the method comprising:
<claim-text>obtaining state information representing at least one of a direction and a rotation state of the portable device;</claim-text>
<claim-text>determining each of a sequence of reading an image from a camera sensor, and a user interface, according to the state information; and</claim-text>
<claim-text>activating a picture in picture (PIP) mode responsive to at least one of a change in the state information of the portable device, a change in an open/closed position of a folder or responsive to a slide of the portable device;</claim-text>
<claim-text>wherein in the PIP mode, a region is determined for displaying input images of each of the cameras, and an image input from each camera is displayed in the determined region. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
