<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627250-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627250</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13933934</doc-number>
<date>20130702</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>455</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>50</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>716108</main-classification>
<further-classification>716106</further-classification>
<further-classification>716113</further-classification>
<further-classification>716134</further-classification>
</classification-national>
<invention-title id="d2e43">Method and system for high speed and low memory footprint static timing analysis</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7725856</doc-number>
<kind>B1</kind>
<name>Govig et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>716124</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>716108</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12451308</doc-number>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8504960</doc-number>
</document-id>
</parent-grant-document>
<parent-pct-document>
<document-id>
<country>WO</country>
<doc-number>PCT/US2008/006283</doc-number>
<date>20080516</date>
</document-id>
</parent-pct-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13933934</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60931367</doc-number>
<date>20070522</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130298098</doc-number>
<kind>A1</kind>
<date>20131107</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Synopsys, Inc.</orgname>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Maor</last-name>
<first-name>Guy</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Chang</last-name>
<first-name>Chin-Wei Jim</first-name>
<address>
<city>Fremont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Kukimoto</last-name>
<first-name>Yuji</first-name>
<address>
<city>Fremont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Li</last-name>
<first-name>Haobin</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Fenwick &#x26; West LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Synopsys, Inc.</orgname>
<role>02</role>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Siek</last-name>
<first-name>Vuthe</first-name>
<department>2825</department>
</primary-examiner>
<assistant-examiner>
<last-name>Lee</last-name>
<first-name>Eric</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The invention provides a method and system for performing Static Timing Analysis on SoC (System on a Chip) designs. The invention solves a longstanding problem with timing analysis of designs, namely, the ability to multi-thread the design under analysis. The invention provides for slicing a design into levels, further decomposing each level into gates, and the multi-threaded processing of gates so that the solution of large design analysis is generated significantly faster than current approaches. Further, the invention provides that only one level exists in the RAM at any time. Once the arrival time on the level is computed, the data is saved to disk immediately. Because the memory footprint is sub-linear to the size of the design, entire system-on-a chip designs may be run on inexpensive, off-the-shelf hardware.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="221.40mm" wi="140.46mm" file="US08627250-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="227.33mm" wi="111.00mm" file="US08627250-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="186.18mm" wi="175.26mm" file="US08627250-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="185.17mm" wi="145.63mm" file="US08627250-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="163.75mm" wi="173.31mm" file="US08627250-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="221.40mm" wi="139.70mm" file="US08627250-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of co-pending U.S. application Ser. No. 12/451,308, filed Nov. 5, 2009, which is a national stage application of PCT Application No. PCT/US/2008/006283, which claims priority from U.S. provisional application 60/931,367 of the same title, filed May 22, 2007, the entirety of which are incorporated by reference as if fully set forth herein.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">GOVERNMENT FUNDING</heading>
<p id="p-0003" num="0002">N/A</p>
<heading id="h-0003" level="1">FIELD OF USE</heading>
<p id="p-0004" num="0003">The invention relates to statistical timing analysis, and more particularly to timing analysis of large designs, including &#x201c;System-on-a-Chip&#x201d; (SoC) designs.</p>
<heading id="h-0004" level="1">BACKGROUND</heading>
<p id="p-0005" num="0004">A digital circuit can be represented as a set of interconnected logic gates. Static Timing Analysis (STA) is a method of computing the expected timing of a digital circuit without requiring expensive simulation. To perform static timing analysis, the arrival time at all the primary inputs are first annotated. Then the arrival time is propagated forward by adding delays along the interconnects and gates. This process continues until all primary outputs are reached.</p>
<p id="p-0006" num="0005">In current approaches, data generated during the arrival time propagation is all stored in the computer's random-access memory (RAM). The application's memory footprint is proportional to the size of the design. For modern system-on-a-chip (SoC) designs, traditional static timing analysis requires on the order of 30 GB (gigabytes) or more of memory. Owing to the memory needed, the hardware requirement can be prohibitively expensive. What is needed is a method and system for static timing analysis that operates using substantially less than 30 GB, even when the design is a SoC design.</p>
<p id="p-0007" num="0006">Moreover, current approaches to static timing analysis process or execute only one thread at a time (<figref idref="DRAWINGS">FIG. 1A</figref>). Single threaded execution&#x2014;executing a single thread at a time&#x2014;makes, as current trend favors larger designs, for a correspondingly lengthy analysis time. Those of average skill in the relevant art are familiar with &#x201c;gate&#x201d; as a unit of design, and &#x201c;thread&#x201d; as a unit of execution.</p>
<p id="p-0008" num="0007">Commencing with design input <b>11</b>, all gates are levelized into a single sequential order <b>13</b>. Beginning at a first gate <b>15</b>, the gate is processed <b>17</b> and the analysis then proceeds to the next gate <b>19</b>, until the last gate is reached <b>20</b> and the design analysis is done <b>21</b>. It can be appreciated, then, that data flow requires significant RAM, as all the data for the entire design ins in RAM, all associated calculations&#x2014;the results of the analysis&#x2014;must all be accommodated in RAM.</p>
<p id="p-0009" num="0008">What is needed is a method of performing static timing analysis such that the amount of required RAM does not increase as the size of the design under analysis increases. Further, what is needed is a faster approach to design analysis, including static timing analysis.</p>
<heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">The invention satisfies at least all of the above-mentioned unmet needs. The invention provides a means to multi-thread the design under analysis, enabling high speed static timing analysis with a low memory footprint.</p>
<p id="p-0011" num="0010">A system according to the invention, as sketched in <figref idref="DRAWINGS">FIG. 2A</figref>, includes an input means for a design under analysis <b>23</b>, a master central processing unit or CPU <b>25</b> and a plurality of dependent CPUs <b>27</b>, where each dependent CPU is connected to a Master CPU <b>25</b>, a quantity of RAM (random access memory) <b>31</b> and output to a disk storage medium or Disk <b>33</b>.</p>
<p id="p-0012" num="0011">The invention provides uniquely effective implementation of inexpensive disk storage, random access memory (RAM) and a plurality of &#x201c;off the shelf&#x201d; CPUs (i.e. execution units). The invention provides a means for faster performance of timing analysis with reduced hardware expense.</p>
<p id="p-0013" num="0012">The invention provides a method including partitioning the design under analysis into a set of levels. A level may be understood as a set of gates not interdependent either before or after each other; and gates are sent from the master CPU to additional CPUs for solution. In the preferred embodiment, each gate, is sent to one of a plurality of dependent CPUs for solution, such that which CPU is solving a given gate is and the solution of a given gate is independent of other gates. The plurality of dependent CPUs send the gate solutions to the Master CPU, which in turn, saves the solutions set for the level, and sends the level solution from random access memory (RAM) to a storage medium, such as a disk, for storage. Solution of the next level then commences, and the process is repeated until the entire set of levels comprising the design has been solved.</p>
<p id="p-0014" num="0013">It can be appreciated by those of skill in the art that by partitioning the design into levels, less memory is required for the analysis of the design. Further cutting levels into gates, and the multi threading of the gate computation, provides a faster solution of the design as a whole. Thus the inventive method and system require less memory and less time to perform STA on large designs.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1A</figref> depicts prior art method of design analysis.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2A</figref> depicts a system according to the invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2B</figref> depicts data flow view according to the invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> C depicts an example of a structural view according to the inventions.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of an embodiment of the inventive method.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
<p id="p-0020" num="0019">The inventive method and system can be further appreciated and understood by means of the figures accompanying the specification.</p>
<p id="p-0021" num="0020">The invention provides a method of multi-threading analysis of a digital circuit design, said method including partitioning the design under analysis into a set of levels. A level may be understood as a set of gates not interdependent either before or after each other. From the master CPU, gates are sent to for solution to additional CPUs. The gates or tasks are solved independently, and the master CPU receives solutions from the dependent CPUs. When the entire level has been solved, the master CPU saves the solutions set for the level, and sends the level solution from random access memory (RAM) to a disk for storage. Solution of the next level then commences, and the process is repeated until the entire set of levels comprising the design has been solved.</p>
<p id="p-0022" num="0021">Referring to <figref idref="DRAWINGS">FIG. 2A</figref>, a system according to the invention includes an input means for a design under analysis, a master CPU (central processing unit) and a plurality of dependent CPUs connected to the master CPU, a quantity of RAM (random access memory) and output to a storage medium. In the preferred embodiment, the dependent CPUs are multicore microprocessors. For designs of 40 million gates, four CPUs may be sufficient to achieve process time of less than one hour. Those of skill in the relevant arts can appreciate the significant improvement afforded by the invention taught herein, as current approaches typically require many hours to run a static timing analysis (STA) on a 40 million gate design.</p>
<p id="p-0023" num="0022">Again referring to <figref idref="DRAWINGS">FIG. 2A</figref>, a system according to the invention includes an input means for a design under analysis (User) <b>23</b>, a master CPU <b>25</b> and a plurality of dependent CPUs <b>27</b>, where each dependent CPU is connected to a Master CPU <b>25</b>, a quantity of RAM (random access memory) <b>31</b> and output to a disk storage medium or Disk <b>33</b>.</p>
<p id="p-0024" num="0023">According to traditional data flow, all data required for design analysis is completely loaded from disk into physical memory. It is only after all data is in RAM (physical memory) that the CPU commences to perform analysis on the design under analysis. Sufficient RAM must exist to accommodate not only the data required for the design under analysis, but also all the results of the analysis. When the entire design analysis is completed, the results are sent from the RAM/CPU to a storage device. This approach requires sufficient RAM to contain the entire design as a whole as well as all the computed results. The larger the design, the more RAM required, and the cost increases as the amount of RAM required increases.</p>
<p id="p-0025" num="0024">Referring to the example of five gates depicted in <figref idref="DRAWINGS">FIG. 2C</figref>, the traditional approach provides that all data is loaded into physical memory during analysis. Thus, gate 0, gate 1, gate 2, gate 3, gate 4, gate n are all loaded into RAM, even though gate 3 can only be computed after g0 and g1 are finished.</p>
<p id="p-0026" num="0025">Referring now to <figref idref="DRAWINGS">FIG. 2B</figref> depicting data flow according to an embodiment of the inventions, illustrates the manner in which threads work independently of each other with minimal synchronization, depending on the queue status (i.e. the job queue and result queue).</p>
<p id="p-0027" num="0026">A pre-fetch thread <b>1000</b> loads data from disk <b>100</b> and saves the prepared data into a Job Queue. The term &#x201c;job&#x201d; as used herein, means all the data needed to perform gate computations in a particular level. For each job, the execution threads <b>2000</b> compute the arrival time, transition time, and crosstalk for all gates in the level. The computation results are saved to the Result Queue <b>3000</b>.</p>
<p id="p-0028" num="0027">It is important to note that at such time as a job is deposited to the Job Queue <b>1050</b> the pre fetch thread <b>1000</b> can immediately load the data for the next level, and so on until all the levels of the design under analysis have been deposited as jobs in the Job Queue. The prefetch thread does not need to wait for the execution threads (see <b>2000</b>) to consume the job, i.e pull from <b>1000</b> and send to <b>3000</b>. In this manner, the pre-fetch thread <b>1000</b> works independently of the execution threads <b>2000</b>.</p>
<p id="p-0029" num="0028">Moreover, the execution threads can proceed with the next job in the Job Queue without waiting for the results to be physically saved to disk. A Save thread <b>3000</b> removes each job from the Result Queue and saves each job to disk. When all the gate computations for every level have been completed, and saved to disk, the design analysis is complete. It can be appreciated that the data flow of the inventive embodiment is significantly faster than single threaded or even currently employed so-called multithreaded approaches. In addition embodiments according to the invention use significantly smaller memory footprints than currently employed approaches.</p>
<p id="p-0030" num="0029">To further appreciate the inventive approach, it is useful to consider the inventive approach to levelization of a design under analysis. Referring now to <figref idref="DRAWINGS">FIG. 2C</figref> in which a five gate structure is depicted. In the levelization the inventive approach differs from current practice. Those of average skill in the relevant art understand &#x201c;levelization&#x201d; to mean a traversal assigning a level to each gate such that if a gate B is at the fanout cone of gate A, then the level of A is smaller than the level of B.</p>
<p id="p-0031" num="0030">In current approaches, levelization of the structure in <figref idref="DRAWINGS">FIG. 2C</figref> would yield:</p>
<p id="h-0008" num="0000">Ex: prior art levelization</p>
<p id="p-0032" num="0031">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="1" colwidth="49pt" align="center"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="56pt" align="center"/>
<colspec colname="4" colwidth="28pt" align="center"/>
<colspec colname="5" colwidth="56pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
<row>
<entry>g0</entry>
<entry>g1</entry>
<entry>g2</entry>
<entry>g3</entry>
<entry>g4</entry>
</row>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Level 1</entry>
<entry>Level 2</entry>
<entry>Level 3</entry>
<entry>Level 4</entry>
<entry>Level 5</entry>
</row>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
<br/>
However, according to the invention, levelization accomplishes &#x201c;maximum packing&#x201d; such that where there is no dependency, the level is reduced as much as possible. The labels L1, L 2 and L3 depict the concept of &#x201c;maximum packing&#x201d; so the levels yield:
<br/>
Ex: Maximum Packing Levelization
</p>
<p id="p-0033" num="0032">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="1" colwidth="49pt" align="center"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="56pt" align="center"/>
<colspec colname="4" colwidth="28pt" align="center"/>
<colspec colname="5" colwidth="56pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
<row>
<entry>g0</entry>
<entry>g1</entry>
<entry>g2</entry>
<entry>g3</entry>
<entry>g4</entry>
</row>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Level 1</entry>
<entry>Level 2</entry>
<entry>Level 1</entry>
<entry>Level 3</entry>
<entry>Level 3</entry>
</row>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0034" num="0033">Note that in the example, g2 can be reduced from level 3 to level 1, g3 reduced from level 4 to level 3, and g4 can be reduce from level 5 to level 3.</p>
<p id="p-0035" num="0034">One of skill in the relevant art further appreciates that a variety of mathematical approaches may be taken to analyze a design so as to cut it into levels, and accomplish maximum packing. Any of these are intended to be included if performed in embodiments of the invention described herein.</p>
<p id="p-0036" num="0035">Referring now to <figref idref="DRAWINGS">FIG. 3</figref>, the method according to the invention comprises the steps of: inputting design <b>35</b>, partitioning the design into levels and analyzing for crosstalk <b>37</b>; beginning process first level <b>39</b>; decompose level into gates <b>41</b>; retrieve data from Job Queue <b>43</b> including data necessary to compute crosstalk; send gates to CPUs <b>45</b>; save output of gate computation <b>47</b> to Results Queue <b>48</b>; advance to next level <b>49</b>; determine if last level <b>50</b>; if not the last, return to next level and repeat steps <b>41</b> through <b>50</b>; when last level completed, then process is complete <b>52</b>.</p>
<p id="p-0037" num="0036">Current methods require sufficient memory to accommodate the entire design (i.e. all the gates) as well as the computations for all the gates. In embodiments according to the invention, as a consequence of partitioning the design and through levelization techniques such as maximum packing, it is only necessary to accommodate a sub set of the design in memory at any time, and in the preferred embodiment, only one level of the design at any time. Therefore the memory required is a function of the size of the largest level, not the size of the design. Further, as a practical matter, packing heuristic determines level size and it has been empirically determined that the desired level size is a level comprised of several hundred gates. For a SoC design where the system uses multicore CPUs, a level of about 500 gates realizes best performance speed. The level size optimization my vary depending on hardware, and levelization algorithm employed.</p>
<p id="p-0038" num="0037">It can be appreciated by those of skill in the art that by cutting the design into levels, less memory is required to analyze and store the design. Further cutting levels into gates provides a faster solution. Thus the inventive method and system require less memory and less time to perform STA on large designs. In the preferred embodiment, a level generally is comprised of several hundred gates, ensuring that the level is neither to large or too small for optimal STA performance.</p>
<p id="p-0039" num="0038">The inventive method and system taught herein can provide crosstalk analysis on a design under analysis. Crosstalk complicates a timing analysis of a design because crosstalk creates an even greater number of dependencies. The inventive approach is effective in performing crosstalk analysis. In the preferred embodiment, because retrieval of stored data is required in a crosstalk analysis, a preliminary analysis informs and directs a storage protocol whereby later needed data is rapidly retrieved from disk storage.</p>
<p id="p-0040" num="0039">The preliminary analysis analyzes the design topology to determine how to save gates, in light of dependencies, so as to render the saved data amenable to rapid retrieval.</p>
<p id="p-0041" num="0040">In a further embodiment, where it is desirable to vary parameters, the data design input can branch out and run simultaneously on the hardware as described hereinabove. This obviates sequential running of the design multiple times, and provides faster results. This is especially useful for multi-corner multi-mode analysis.</p>
<p id="p-0042" num="0041">In a system and method according to the preferred embodiment, only one level exists in the RAM at any time. Once the arrival time on the level is computed, the data is saved to disk immediately. Accordingly, the inventive method is extremely efficient in use of available RAM. Because the memory footprint is sub-linear to the size of the design, entire system-on-a chip (SoC) designs may be run on inexpensive, off-the-shelf hardware. Designs of, for example, 50 million gates, can be accommodated according to the inventions, as well as larger designs owing to the scalability of the invention.</p>
<p id="p-0043" num="0042">Moreover, owing to the inventive decomposition of the design into levels, and further decomposition into gates and the multiple processing of gates, the solution of large design analysis is generated significantly faster than current approaches.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>We claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer-implemented method for performing static timing analysis of a circuit design comprising:
<claim-text>partitioning a circuit design into a plurality of levels of gates including at least a first level of gates and a second level of gates, each of the gates in the first level having an input independent of outputs of other gates in the first level, each of the gates in the second level having an input independent of outputs of other gates in the second level;</claim-text>
<claim-text>using a processor, performing a first static timing analysis on the first level of gates responsive to loading the first level of gates into a first memory of a computing device;</claim-text>
<claim-text>storing results of the first static timing analysis into a second memory of the computing device responsive to performing the static timing analysis on the first level of gates; and</claim-text>
<claim-text>responsive to loading the second level of gates into the first memory, performing a second static timing analysis on the second level of gates using the results of the first static timing analysis as arrival times of inputs for the second level of gates.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising storing results of the second static timing analysis into the second memory.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising removing the first level of gates from the first memory before loading the second level of gates into the first memory.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first memory has a first access speed and the second memory has a second access speed, the first access speed faster than the second access speed.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first level of gates is stored in a job queue, and before one or more execution threads have pulled the first level of gates from the job queue, the second level of gates is stored in the job queue.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second static timing analysis starts before the results of the first static timing analysis is stored in the second memory.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein partitioning the circuit design into a plurality of levels includes reducing the level of a gate of a specific level responsive to the gate having inputs independent of outputs of gates in a previous level.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the circuit design is partitioned into the plurality of levels based on one of a number of cores of a central processing unit (CPU), and a size of the first memory.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein performing the first static timing analysis comprises:
<claim-text>determining arrival times of inputs of the first level of gates;</claim-text>
<claim-text>determining transition times of signals through the first level of gates; and</claim-text>
<claim-text>performing crosstalk analysis for the first level of gates.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein performing the first static timing analysis further comprises:
<claim-text>assigning a plurality of execution threads to a plurality of processors in the computing devices;</claim-text>
<claim-text>assigning one or more gates from the first level of gates to each of the execution threads; and</claim-text>
<claim-text>determining, by each of the threads, transition times of signals through the gates assigned to the thread.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein performing the first static timing analysis further comprises assigning a save thread separate from the plurality of execution threads to store the results of the first static timing analysis in the second memory.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A non-transitory computer readable medium configured to store instructions, the instructions when executed by a processor cause the processor to:
<claim-text>partition a circuit design into a plurality of levels of gates including at least a first level of gates and a second level of gates, each of the gates in the first level having an input independent of outputs of other gates in the first level, each of the gates in the second level having an input independent of outputs of other gates in the second level;</claim-text>
<claim-text>perform a first static timing analysis on the first level of gates responsive to loading the first level of gates into a first memory of a computing device;</claim-text>
<claim-text>store results of the first static timing analysis into a second memory of the computing device responsive to performing the static timing analysis on the first level of gates; and</claim-text>
<claim-text>responsive to loading the second level of gates into the first memory, perform a second static timing analysis on the second level of gates using the results of the first static timing analysis as arrival times of inputs for the second level of gates.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising instructions that cause the processor to store results of the second static timing analysis into the second memory.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising instructions that cause the processor to remove the first level of gates from the first memory before loading the second level of gates into the first memory.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the first memory has a first access speed and the second memory has a second access speed, the first access speed faster than the second access speed.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the first level of gates is stored in a job queue, and before one or more execution threads have pulled the first level of gates from the job queue, the second level of gates is stored in the job queue, and wherein the second timing analysis starts before the results of the first static timing analysis is stored in the second memory.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein partitioning the circuit design into a plurality of levels includes reducing the level of a gate of a specific level responsive to the gate having inputs independent of outputs of gates in a previous level.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the instructions to perform the first static timing analysis comprise instruction that cause the processor to:
<claim-text>determine arrival times of inputs of the first level of gates;</claim-text>
<claim-text>determine transitory times of signals through the first level of gates; and</claim-text>
<claim-text>perform crosstalk analysis for the first level of gates.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The non-transitory computer readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the instructions to perform the first static timing analysis further comprises instructions that causes the processor to:
<claim-text>assign a plurality of execution threads to a plurality of processors in the computing device;</claim-text>
<claim-text>assign one or more gates from the first level of gates to each of the execution threads; and</claim-text>
<claim-text>determine, by each of the threads, transition times of signals through the gates assigned to the thread.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
