<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625154-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625154</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11636640</doc-number>
<date>20061211</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2005-0120905</doc-number>
<date>20051209</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1011</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>1</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>358  19</main-classification>
<further-classification>358518</further-classification>
<further-classification>382165</further-classification>
<further-classification>382276</further-classification>
</classification-national>
<invention-title id="d2e71">Apparatus and method for reproducing optimized preference color using candidate images and natural languages</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5377013</doc-number>
<kind>A</kind>
<name>Oka et al.</name>
<date>19941200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358501</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5495539</doc-number>
<kind>A</kind>
<name>Sieverding</name>
<date>19960200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382276</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6262812</doc-number>
<kind>B1</kind>
<name>Chan et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2001/0035988</doc-number>
<kind>A1</kind>
<name>Semba et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358518</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2002/0081024</doc-number>
<kind>A1</kind>
<name>Park et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382165</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2004/0227964</doc-number>
<kind>A1</kind>
<name>Fujino</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  19</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>11-194866</doc-number>
<kind>A</kind>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>11194866</doc-number>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-cpc-text>G06F 3/00</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>2003-259138</doc-number>
<kind>A</kind>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2005-085149</doc-number>
<kind>A</kind>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>KR</country>
<doc-number>10-2004-0003225</doc-number>
<kind>A</kind>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>26</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>358  19</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358518</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382165</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382276</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070133024</doc-number>
<kind>A1</kind>
<date>20070614</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kang</last-name>
<first-name>Byoung-ho</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Se-eun</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Choh</last-name>
<first-name>Heui-keun</first-name>
<address>
<city>Seongnam-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kang</last-name>
<first-name>Byoung-ho</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Se-eun</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Choh</last-name>
<first-name>Heui-keun</first-name>
<address>
<city>Seongnam-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sughrue Mion, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Samsung Electronics Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Haskins</last-name>
<first-name>Twyler</first-name>
<department>2672</department>
</primary-examiner>
<assistant-examiner>
<last-name>Burleson</last-name>
<first-name>Michael</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An apparatus and method are provided for reproducing an optimized preference color using candidate images and natural languages, in which user-oriented optimized picture quality can be provided through a printer. The apparatus includes a preference color-natural language information memory which stores characteristic information of a preference color mapped on a natural language, a candidate image provider module which provides candidate images having characteristic information applied to original images, and a candidate preference image input module which inputs one image, which satisfies a user's preference, among the candidate images.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="223.18mm" wi="192.79mm" file="US08625154-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="239.27mm" wi="175.09mm" file="US08625154-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="117.52mm" wi="144.02mm" file="US08625154-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="280.84mm" wi="171.53mm" orientation="landscape" file="US08625154-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="248.07mm" wi="184.57mm" file="US08625154-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="174.84mm" wi="166.96mm" file="US08625154-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="247.57mm" wi="146.73mm" file="US08625154-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="231.31mm" wi="191.77mm" file="US08625154-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="210.40mm" wi="149.94mm" file="US08625154-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="194.14mm" wi="138.51mm" file="US08625154-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application is based on and claims priority from Korean Patent Application No. 10-2005-0120905, filed on Dec. 9, 2005 in the Korean Intellectual Property Office, the disclosure of which is incorporated herein in its entirety by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">Apparatuses and methods consistent with the present invention relate to reproducing an optimized preference color using candidate images and natural languages and, more particularly, reproducing an optimized preference color using candidate images and natural languages, in which characteristic information of a preference color mapped on a natural language is applied to an original image to provide candidate images, a preference image among the candidate images is inputted, and color information of the input preference image can be corrected.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Digital imaging devices, which reproduce colors, such as monitors, scanners, and printers, have various functions and high quality to fulfill users' various demands. Also, the digital imaging devices use different color spaces or different color models depending on their respective fields of use. Examples of the color models include a device dependent color model and a device independent color model. The device dependent color model includes an RGB color model corresponding to an additive color space model, and a CMYK color model corresponding to a subtractive color space model. The device independent color model includes a CIE L*a*b* model, a CIE XYZ model, and a CIE LUV model. The CMYK color model is used in the field of printing, while the RGB color model is used in the field of computer monitors, such as Internet graphics.</p>
<p id="p-0007" num="0006">When a user views images from a printer that outputs digital video images or a display device that displays images, a color, which stimulates a user's visual perception and is preferred by the user in a color gamut is referred to as a preference color. The preference color affects the performance of an output device such as a printer. To allow a user to obtain a preference color, related art techniques for reproducing and converting a preference color have been discussed. Examples of such related art techniques include a technique for automatically converting a color gamut of flesh-color or sky-blue using a previously defined matrix, and a technique for automatically converting a skin color to a previously defined preference color.</p>
<p id="p-0008" num="0007">However, such related art techniques have a problem in that they do not allow a user to execute image conversion by previously providing a preference image or to correct a converted image.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">Exemplary embodiments of the present invention overcome the above disadvantages and other disadvantages not described above. Also, the present invention is not required to overcome the disadvantages described above, and an exemplary embodiment of the present invention may not overcome any of the problems described above.</p>
<p id="p-0010" num="0009">The present invention provides an apparatus and method for reproducing an optimized preference color using candidate images and natural languages, in which characteristic information of a preference color mapped on a natural language is applied to an original image to provide candidate images, a preference image among the candidate images is inputted, and color information of the input preference image can be corrected.</p>
<p id="p-0011" num="0010">The present invention also provides an apparatus and method for generating characteristic information of a preference color, which generates characteristic information for reproducing a preference color that corresponds to the preference color, characteristics of the preference color expressed by natural languages, and target coordinates corresponding to the characteristics.</p>
<p id="p-0012" num="0011">According to an aspect of the present invention, there is provided an apparatus for reproducing an optimized preference color using candidate images and natural languages, which includes a preference color-natural language information memory which stores characteristic information of a predetermined preference color mapped on a natural language, a candidate image provider module which provides candidate images having characteristic information applied to original images, and a candidate preference image input module which inputs one image, which satisfies a user's preference, among the candidate images.</p>
<p id="p-0013" num="0012">In another aspect of the present invention, there is provided an apparatus for generating characteristic information of a preference color, which includes a preference color selection module which selects one preference color of skin, sky-blue, and green grass, a characteristic selection module which selects one of a plurality of characteristics of the selected preference color expressed by natural languages, a target coordinate calculation module which calculates target coordinates corresponding to the selected characteristic, and a characteristic information generation module which generates characteristic information for reproducing the preference color, corresponding to the preference color, the characteristic, and the target coordinates.</p>
<p id="p-0014" num="0013">In still another aspect of the present invention, there is provided a method of reproducing an optimized preference color using candidate images and natural languages, which includes storing characteristic information of a predetermined preference color mapped on a natural language, providing candidate images having characteristic information applied to original images, and inputting one image, which satisfies a user's preference, among the candidate images.</p>
<p id="p-0015" num="0014">In further still another aspect of the present invention, there is provided a method of generating characteristic information of a preference color, which includes selecting one preference color of skin, sky-blue, and green grass, selecting one of a plurality of characteristics of the selected preference color expressed by natural languages, calculating target coordinates corresponding to the selected characteristic, and generating characteristic information for reproducing the preference color, corresponding to the preference color, the characteristic, and the target coordinates.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015">The above and other aspects of the present invention will become more apparent from the following detailed description of exemplary embodiments taken in conjunction with the accompanying drawings, in which:</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> is a view illustrating the whole configuration of an apparatus for reproducing an optimized preference color using candidate images and natural languages in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> is a view illustrating the construction of a candidate image provider module of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3</figref> is a view illustrating a process of adjusting a preference color to target coordinates using an image conversion function;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 4</figref> is a view illustrating a graphic user interface that provides an original image and a plurality of candidate images having characteristic information;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 5</figref> is a view illustrating the construction of a color information correction module of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6</figref> is a view illustrating a graphic user interface that corrects color information;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 7</figref> is a view illustrating the construction of an apparatus for generating characteristic information for a preference color in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 8</figref> is a table illustrating preference colors, characteristics of preference colors, and target coordinates;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating a method of reproducing an optimized preference color using candidate images and natural images in accordance with an exemplary embodiment of the present invention; and</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart illustrating a method of generating characteristic information of a preference color in accordance with an exemplary embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS OF THE INVENTION</heading>
<p id="p-0027" num="0026">Hereinafter, exemplary embodiments of the present invention will be described in detail with reference to the accompanying drawings. The aspects and features of the present invention and methods for achieving the aspects and features will be apparent by referring to exemplary embodiments to be described in detail with reference to the accompanying drawings. However, the present invention is not limited to the exemplary embodiments disclosed hereinafter, but can be implemented in diverse forms. The matters defined in the description, such as the detailed construction and elements, are provided to assist those of ordinary skill in the art in a comprehensive understanding of the invention, and the present invention is only defined within the scope of the appended claims and their legal equivalents. In the entire description of the present invention, the same drawing reference numerals are used for the same elements across various figures.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 1</figref> is a view illustrating the whole configuration of an apparatus for reproducing an optimized preference color using candidate images and natural languages in accordance with an exemplary embodiment of the present invention. Referring to <figref idref="DRAWINGS">FIG. 1</figref>, the apparatus for reproducing an optimized preference color using candidate images and natural languages includes a preference color-natural language information memory <b>100</b>, a candidate image provider module <b>200</b>, a candidate preference image input module <b>300</b>, and a color information correction module <b>400</b>.</p>
<p id="p-0029" num="0028">The preference color-natural language information memory <b>100</b> stores characteristic information of a predetermined preference color mapped on a natural language, wherein the preference color effectively responds to a user's perception and includes a skin color, a sky-blue color, and a green grass color. The preference color greatly affects the picture quality of a printed image. In <figref idref="DRAWINGS">FIG. 1</figref>, N<sub>skin </sub>is a natural expression of characteristics of a skin color, N<sub>sky </sub>is a natural expression of characteristics of a sky-blue color, and N<sub>grass </sub>is a natural expression of characteristics of a green grass color. Meanwhile, for original images expressed in <figref idref="DRAWINGS">FIG. 1</figref>, lightness showing brightness of color is expressed as L<sub>i</sub>*, chroma or saturation showing definition of color is expressed as C<sub>i</sub>*, and hue showing name of color is expressed as h<sub>i</sub>.</p>
<p id="p-0030" num="0029">The candidate image provider module <b>200</b> is provided with characteristic information from the preference color-natural language information memory <b>100</b>, wherein the characteristic information is mapped on natural languages N<sub>skin</sub>, N<sub>sky</sub>, and N<sub>grass</sub>. The candidate image provider module <b>200</b> is also provided with the original images of L<sub>i</sub>*, C<sub>i</sub>* and h<sub>i</sub>. Thus, the candidate image provider module <b>200</b> serves to provide candidate images obtained by applying the characteristic information to the original images. Since lightness L<sub>i</sub>*, chroma C<sub>i</sub>*, and hue h<sub>i </sub>of the original images are controlled through processing steps by the candidate image provider module <b>200</b>, L<sub>i</sub>* is expressed as L<sub>ip</sub>*, C<sub>i</sub>* is expressed as C<sub>ip</sub>*, and h<sub>i </sub>is expressed as h<sub>ip</sub>.</p>
<p id="p-0031" num="0030">If the user selects one candidate image, which satisfies its preference, among the candidate images provided from the candidate image provider module <b>200</b>, the candidate preference image input module <b>300</b> inputs the selected image. Finally, the color information correction module <b>400</b> corrects the color information of the input image to display an output image. In this case, it is noted that lightness, chroma and hue of the output image are respectively expressed as L<sub>o</sub>*, C<sub>o</sub>* and h<sub>o</sub>.</p>
<p id="p-0032" num="0031">The characteristic information used in <figref idref="DRAWINGS">FIG. 1</figref> includes the preference color, a plurality of characteristics of the preference color expressed by natural languages, and target coordinates corresponding to the plurality of characteristics. The characteristic information is used in a broader range than &#x201c;characteristic.&#x201d;</p>
<p id="p-0033" num="0032">Hereinafter, the apparatus for reproducing an optimized preference color using candidate images and natural languages in accordance with an exemplary embodiment of the present invention will be described in more detail with reference to <figref idref="DRAWINGS">FIGS. 2-6</figref>.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 2</figref> is a view illustrating the construction of the candidate image provider module <b>200</b> of <figref idref="DRAWINGS">FIG. 1</figref>. The candidate image provider module <b>200</b> includes an adjustment module <b>210</b> and a provider module <b>220</b>.</p>
<p id="p-0035" num="0034">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, the adjustment module <b>210</b> adjusts the preference colors constituting the original images to colors corresponding to the target coordinates using a predetermined image conversion function. <figref idref="DRAWINGS">FIG. 3</figref> is a view illustrating a process of adjusting the preference colors to the target coordinates by using the image conversion function.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 3</figref> shows an L*a*b* color space of a CIE color model decided by the International Commission on Illumination (ICI), which decides the standard of lighting apparatuses. The adjustment module <b>210</b> reflects five kinds of characteristics selected by the user in the skin color, the sky-blue color, and the green grass color to move the colors to the target coordinates {circle around (1)} to {circle around (5)} corresponding to the respective characteristics. In <figref idref="DRAWINGS">FIG. 3</figref>, the numbers {circle around (1)} to {circle around (5)} correspond to five kinds of characteristics in a table as shown in <figref idref="DRAWINGS">FIG. 8</figref>.</p>
<p id="p-0037" num="0036">The provider module <b>220</b> provides the plurality of candidate images comprised of the preference colors such as skin, sky-blue and grass, moved for adjustment to the target coordinates {circle around (1)} to {circle around (5)} corresponding to the respective characteristics. The provider module <b>220</b> can provide the plurality of candidate images using soft-proofing. Soft-proofing uses software to simulate a printed result in a display device. This is shown in <figref idref="DRAWINGS">FIG. 4</figref> which is a view illustrating a graphic user interface that provides the plurality of candidate images and the original image having the characteristic information. Referring to <figref idref="DRAWINGS">FIG. 4</figref>, an upper image at the left is the original image, and images corresponding to Preview <b>1</b> through Preview <b>5</b> allow the user to preview the results adjusted to the target coordinates corresponding to the five kinds of characteristics of the skin color, i.e., {circle around (1)} &#x201c;clean&#x201d;, {circle around (2)} &#x201c;brilliant&#x201d;, {circle around (3)} &#x201c;bright&#x201d;, {circle around (4)} &#x201c;mild&#x201d;, and {circle around (5)} &#x201c;healthy.&#x201d; A &#x201c;Set Color&#x201d; box of an upper right-hand side in <figref idref="DRAWINGS">FIG. 4</figref> displays an interface for selecting one preference color among three kinds of preference colors, such as skin, sky-blue and green grass. An &#x201c;Execution&#x201d; box of a lower right-hand side in <figref idref="DRAWINGS">FIG. 4</figref> includes a &#x201c;Preview&#x201d; button, an &#x201c;Apply to Image&#x201d; button that allows a selected characteristic to be applied to the original image, a &#x201c;RGB2RGBLUT&#x201d; button that allows conversion of RGB information, and a &#x201c;Cancel&#x201d; button that allows cancellation of execution.</p>
<p id="p-0038" num="0037">The user can select one image, which satisfies its preference, among the plurality of candidate images to which the respective characteristics are applied by the interface, as illustrated in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 5</figref> is a view illustrating the construction of the color information correction module <b>400</b> of <figref idref="DRAWINGS">FIG. 1</figref>. The color information correction module <b>400</b> corrects color information of the input image to display an output image. The color information correction module <b>400</b> includes a preference color input module <b>410</b> and a color component correction module <b>420</b>.</p>
<p id="p-0040" num="0039">The preference color input module <b>410</b> inputs a target preference color to be corrected, among preference colors constituting the input image. The color component correction module <b>420</b> corrects a color component of the input preference color and displays an image of the corrected result using soft-proofing. Preferably, but not necessarily, the color component includes color information, such as lightness, chroma and hue, accustomed to general users.</p>
<p id="p-0041" num="0040">The process of selecting the preference color to be corrected and correcting the color component of the selected preference color is shown in <figref idref="DRAWINGS">FIG. 6</figref>. <figref idref="DRAWINGS">FIG. 6</figref> is a view illustrating a graphic user interface that corrects the color information. Referring to <figref idref="DRAWINGS">FIG. 6</figref>, an image of an upper left-hand side is the image (having the characteristic information) inputted by the candidate preference image input module <b>300</b>, and an image of a lower left-hand side is a preview image after being corrected by the color information correction module <b>400</b>. An upper right-hand side in <figref idref="DRAWINGS">FIG. 6</figref> displays a &#x201c;Preference Choices&#x201d; box that allows the user to select a region to be corrected, and a &#x201c;Preferences&#x201d; box that allows the preference color input module <b>410</b> to input the preference color. It is noted from <figref idref="DRAWINGS">FIG. 6</figref> that &#x201c;skin&#x201d; is marked to correct the skin color. A portion for correcting the color component is displayed in the &#x201c;Reference Point&#x201d; box below the &#x201c;Preferences&#x201d; box, wherein the user can input numerical values of lightness, saturation and hue to designate correction values. It is noted from <figref idref="DRAWINGS">FIG. 6</figref> that the color component is corrected in the range of lightness of 58, saturation of 40, and hue of 59. Then, a &#x201c;Color Control&#x201d; interface allows the user to again adjust lightness, saturation and hue using an adjustment slider. An &#x201c;Execution&#x201d; interface of the lower right-hand corner includes a &#x201c;Candidates&#x201d; button that allows the user to again select the candidate image, an &#x201c;LUT Gen.&#x201d; button that allows a look-up table of lightness, saturation and hue to be displayed, a &#x201c;To Image&#x201d; button that displays a correction image, and a &#x201c;Cancel&#x201d; button that allows cancellation of execution. Also, an &#x201c;Original &#x26; Control Color&#x201d; interface of the lower left-hand corner displays a color of the original image and a color of the corrected image to allow the user to identify the two colors at a glance.</p>
<p id="p-0042" num="0041">Hereinafter, an apparatus for generating characteristic information, which is required to carry out the aforementioned apparatus of the present invention, will be described with reference to <figref idref="DRAWINGS">FIG. 7</figref> and <figref idref="DRAWINGS">FIG. 8</figref>.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 7</figref> is a view illustrating the construction of an apparatus for generating characteristic information of a preference color in accordance with an exemplary embodiment of the present invention, and <figref idref="DRAWINGS">FIG. 8</figref> is a table illustrating preference colors, characteristics of the preference colors, and target coordinates. Referring to <figref idref="DRAWINGS">FIG. 7</figref>, the apparatus <b>500</b> for generating characteristic information of the preference color includes a preference color selection module <b>510</b>, a characteristic selection module <b>520</b>, a target coordinate calculation module <b>530</b>, and a characteristic information generation module <b>540</b>.</p>
<p id="p-0044" num="0043">The preference color selection module <b>510</b> selects one of preference colors, such as skin, sky-blue, and green glass, which constitute an image to be converted.</p>
<p id="p-0045" num="0044">The characteristic selection module <b>520</b> allows the user to select characteristics to be converted for the selected preference color. In other words, the characteristic selection module <b>520</b> selects one of a plurality of characteristics expressed by natural languages for the selected preference color.</p>
<p id="p-0046" num="0045">The target coordinate calculation module <b>530</b> calculates target coordinates corresponding to the selected characteristic.</p>
<p id="p-0047" num="0046">The characteristic information generation module <b>540</b> generates characteristic information for reproducing a preference color, corresponding to the preference color, the characteristic and the target coordinates.</p>
<p id="p-0048" num="0047">It is noted that characteristics of each preference color expressed by natural languages and YCbCr values of target coordinates corresponding to the characteristics are exemplarily shown in <figref idref="DRAWINGS">FIG. 8</figref>. Referring to <figref idref="DRAWINGS">FIG. 8</figref>, characteristics of skin, sky-blue and green grass expressed by five kinds of natural language interfaces are shown. The user can select five kinds of characteristics of the skin color, such as {circle around (1)} &#x201c;clean&#x201d;, {circle around (2)} &#x201c;brilliant&#x201d;, {circle around (3)} &#x201c;bright&#x201d;, {circle around (4)} &#x201c;mild&#x201d;, and {circle around (5)} &#x201c;healthy,&#x201d; and five kinds of characteristics of the sky-blue color, such as {circle around (1)} &#x201c;bright&#x201d;, {circle around (2)} &#x201c;clear&#x201d;, {circle around (3)} &#x201c;limpid&#x201d;, {circle around (4)} &#x201c;deep blue&#x201d;, and {circle around (5)} &#x201c;purplish.&#x201d; Likewise, the user can select five kinds of characteristics of the green grass color, such as {circle around (1)} &#x201c;bright&#x201d;, {circle around (2)} &#x201c;deep blue&#x201d;, {circle around (3)} &#x201c;light&#x201d;, {circle around (4)} &#x201c;vivid&#x201d;, and {circle around (5)} &#x201c;natural.&#x201d; Color perception of the table of <figref idref="DRAWINGS">FIG. 8</figref> describes the concept of each characteristic. For example, the characteristic {circle around (1)} &#x201c;clean&#x201d; of the skin color increases lightness and decreases saturation, the characteristic {circle around (1)} &#x201c;bright&#x201d; of the sky-blue color increases lightness, and the characteristic {circle around (1)} &#x201c;bright&#x201d; of the green grass color increases lightness and decreases shadow. It is noted from the right of the table of <figref idref="DRAWINGS">FIG. 8</figref> that YCbCr values of the target coordinates corresponding to the characteristics are calculated and mapped.</p>
<p id="p-0049" num="0048">In exemplary embodiments of the present invention, the term &#x201c;unit&#x201d;, that is, &#x201c;module&#x201d; or &#x201c;table&#x201d;, as used herein, means, but is not limited to, a software or hardware component, such as a Field Programmable Gate Array (FPGA) or Application Specific Integrated Circuit (ASIC), which performs certain tasks. A module may advantageously be configured to reside on the addressable storage medium and execute on one or more processors. Thus, a module may include, by way of example, components, such as software components, object-oriented software components, class components and task components, processes, functions, attributes, procedures, subroutines, segments of program code, drivers, firmware, microcode, circuitry, data, databases, data structures, tables, arrays, and variables. The functionality provided for in the components and modules may be combined into fewer components and modules or further separated into additional components and modules. In addition, the components and modules may be implemented so as to execute one or more CPUs in a device.</p>
<p id="p-0050" num="0049">A method of reproducing an optimized preference color will now be described with reference to <figref idref="DRAWINGS">FIG. 9</figref>. In particular, <figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating a method of reproducing an optimized preference color using candidate images and natural images in accordance with an exemplary embodiment of the present invention.</p>
<p id="p-0051" num="0050">First, the preference color-natural language information memory <b>100</b> stores characteristic information of a predetermined preference color mapped on a natural language (S<b>100</b>). The preference color greatly affects the picture quality of a printed image and effectively responds to the user's perception. Examples of the preference color include skin, sky-blue, and green grass. The characteristic information includes the preference color, a plurality of characteristics of the preference color expressed by natural languages, and target coordinates corresponding to the plurality of characteristics. The characteristic information is used in a broader range than &#x201c;characteristic.&#x201d;</p>
<p id="p-0052" num="0051">The candidate image provider module <b>200</b> provides candidate images obtained by applying the characteristics information to the original images (S<b>200</b>). In more detail, operation S<b>200</b> includes adjusting the preference colors constituting the original images to colors corresponding to the target coordinates using an image conversion function and providing the plurality of candidate images of the adjusted preference colors. The candidate image provider module <b>200</b> can provide the candidate images using soft-proofing.</p>
<p id="p-0053" num="0052">The candidate preference image input module <b>300</b> inputs one image, which satisfies the user's preference, among the candidate images (S<b>300</b>).</p>
<p id="p-0054" num="0053">Additionally, the color information correction module <b>400</b> can correct color information of the input image (S<b>400</b>). In more detail, the operation <b>400</b> includes inputting the preference color to be corrected among the preference colors constituting the input image, and correcting the color component of the input preference color. The operation of correcting the color component of the input preference color can include displaying the image of the corrected result of the color component using soft-proofing. Preferably, but not necessarily, the color component includes color information, such as lightness, chroma and hue, accustomed to general users.</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart illustrating a method of generating the characteristic information of the preference color in accordance with an exemplary embodiment of the present invention.</p>
<p id="p-0056" num="0055">Referring to <figref idref="DRAWINGS">FIG. 10</figref>, the preference color selection module <b>510</b> selects one of the preference colors such as skin, sky-blue and green grass (S<b>510</b>). The characteristic selection module <b>520</b> selects one of a plurality of characteristics of the selected preference color expressed by natural languages (S<b>500</b>). The target coordinate calculation module <b>530</b> calculates the target coordinates corresponding to the selected characteristic (S<b>530</b>). Finally, the characteristic information generation module <b>540</b> generates characteristic information for reproducing the preference color, corresponding to the preference color, the characteristic and the target coordinates (S<b>540</b>).</p>
<p id="p-0057" num="0056">Meanwhile, it is apparent to those skilled in the art that the scope of the apparatus for reproducing an optimized preference color using candidate images and natural languages according to exemplary embodiments of the present invention is extended to a computer programmable recording medium that can record the aforementioned method using a computer.</p>
<p id="p-0058" num="0057">As described above, the apparatus and method for reproducing an optimized preference color using candidate images and natural languages according to the exemplary embodiments of the present invention have the following advantages.</p>
<p id="p-0059" num="0058">The characteristic information of the preference color mapped on the natural language is applied to the original images to provide the candidate images, and a preference of one of the candidate images is inputted, and color information of the input image can be corrected.</p>
<p id="p-0060" num="0059">Also, in the apparatus and method for generating characteristic information of a preference color, the preference color, characteristics of the preference color expressed by the natural languages, and the target coordinates corresponding to the characteristics correspond to characteristic information for reproducing the preference color.</p>
<p id="p-0061" num="0060">Accordingly, it is possible to provide user-oriented optimized picture quality through a printer to which exemplary embodiments of the present invention are applied.</p>
<p id="p-0062" num="0061">The exemplary embodiments of the present invention have been described for illustrative purposes, and those skilled in the art will appreciate that various modifications, additions and substitutions are possible without departing from the scope and spirit of the invention as disclosed in the accompanying claims. Therefore, the scope of the present invention should be defined by the appended claims and their legal equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An apparatus for reproducing an optimized preference color using candidate images and natural language, the apparatus comprising:
<claim-text>a preference color-natural language information memory which stores characteristic information of a preference color mapped on a natural language;</claim-text>
<claim-text>a candidate image provider module which provides a plurality of candidate images obtained by applying the characteristic information to an original image; and</claim-text>
<claim-text>a candidate preference image input module which inputs one image, which satisfies a user's preference, among the plurality of candidate images,</claim-text>
<claim-text>wherein the characteristic information includes the preference color, and a plurality of characteristics expressed by the natural language for the preference color.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a color information correction module which corrects color information of the input image.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the color information correction module comprises:
<claim-text>a preference color input module which inputs a preference color to be corrected among preference colors constituting the input image; and</claim-text>
<claim-text>a color component correction module which corrects a color component of the input preference color.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the color component correction module displays an image of the corrected result of the color component using soft-proofing.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the color component is one of lightness, chroma, and hue.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the preference color is one of skin, blue and green.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the plurality of characteristics expressed by the natural language for the skin preference color comprises one of clean, brilliant, bright, mild and healthy.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the plurality of characteristics expressed by the natural language for the blue preference color comprises one of bright, clear, limpid, deep-blue and purplish.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the plurality of characteristics expressed by the natural language for the green preference color comprises one of bright, deep-blue, light, vivid and natural.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the characteristic information further includes target coordinates corresponding to the plurality of characteristics.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the candidate image provider module comprises:
<claim-text>an adjustment module which adjusts preference colors constituting original images to colors corresponding to the target coordinates using an image conversion function; and</claim-text>
<claim-text>a provider module which provides the plurality of candidate images comprised of the adjusted preference colors.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the provider module provides the plurality of candidate images using soft-proofing.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of candidate images are displayed on a screen for preview by the user.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the plurality of candidate images are displayed on the screen at same time.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each of the plurality of candidate images are obtained at same time.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the applying of the characteristic information to the original image is based on the preference color selected by the user from a plurality of preference color expressed in the natural language, and
<claim-text>wherein each of the plurality of preference color includes the plurality of characteristics expressed by the natural language.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A method of reproducing an optimized preference color using candidate images and natural language, the method comprising:
<claim-text>storing characteristic information of a preference color mapped on a natural language;</claim-text>
<claim-text>providing a plurality of candidate images obtained by applying the characteristic information to an original image; and</claim-text>
<claim-text>inputting one image, which satisfies a user's preference, among the plurality of candidate images,</claim-text>
<claim-text>wherein the characteristic information includes the preference color, and a plurality of characteristics expressed by the natural language for the preference color.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising correcting color information of the input image.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein correcting the color information comprises: inputting a preference color to be corrected among preference colors constituting the input image; and correcting a color component of the input preference color.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein correcting the color component comprises displaying an image of the corrected result of the color component using soft-proofing.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the color component is one of lightness, chroma, and hue.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the preference color is one of skin, blue and green.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The apparatus of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the characteristic information further includes target coordinates corresponding to the plurality of characteristics.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein providing the candidate images comprises:
<claim-text>adjusting preference colors constituting original images to colors corresponding to the target coordinates using an image conversion function; and</claim-text>
<claim-text>providing the plurality of candidate images, which comprise the adjusted preference colors.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein providing the plurality of candidate images further comprises using soft-proofing.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. A computer-readable recording medium recorded with a program code for a computer to execute a method of reproducing an optimized preference color using candidate images and natural language, the method comprising:
<claim-text>storing characteristic information of a preference color mapped on a natural language;</claim-text>
<claim-text>providing a plurality of candidate images obtained by applying the characteristic information to an original image; and</claim-text>
<claim-text>inputting one image, which satisfies a user's preference, among the plurality of candidate images,</claim-text>
<claim-text>wherein the characteristic information includes the preference color, and a plurality of characteristics expressed by the natural language for the preference color. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
