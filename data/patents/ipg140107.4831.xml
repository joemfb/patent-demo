<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625924-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625924</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12373623</doc-number>
<date>20070713</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>P2006-193671</doc-number>
<date>20060714</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1149</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>40</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382268</main-classification>
<further-classification>382232</further-classification>
</classification-national>
<invention-title id="d2e71">Image deblocking based on complexity</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5229864</doc-number>
<kind>A</kind>
<name>Moronaga et al.</name>
<date>19930700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382261</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5543848</doc-number>
<kind>A</kind>
<name>Murakami et al.</name>
<date>19960800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5657015</doc-number>
<kind>A</kind>
<name>Nakajima et al.</name>
<date>19970800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>341 61</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6041145</doc-number>
<kind>A</kind>
<name>Hayashi et al.</name>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6064776</doc-number>
<kind>A</kind>
<name>Kikuchi et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382260</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7050504</doc-number>
<kind>B2</kind>
<name>Joch et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524026</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2002/0118399</doc-number>
<kind>A1</kind>
<name>Estevez et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>35842607</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2003/0053708</doc-number>
<kind>A1</kind>
<name>Kryukov et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382261</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2004/0208392</doc-number>
<kind>A1</kind>
<name>Raveendran et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382268</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2004/0247034</doc-number>
<kind>A1</kind>
<name>Zhong et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524029</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0024651</doc-number>
<kind>A1</kind>
<name>Yu et al.</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  19</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2005/0100241</doc-number>
<kind>A1</kind>
<name>Kong et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382268</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2005/0152450</doc-number>
<kind>A1</kind>
<name>Ueno et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524003</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2005/0265623</doc-number>
<kind>A1</kind>
<name>Estevez et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382268</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2005/0276505</doc-number>
<kind>A1</kind>
<name>Raveendran</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382268</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2006/0013299</doc-number>
<kind>A1</kind>
<name>Sato et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524003</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2006/0104349</doc-number>
<kind>A1</kind>
<name>Joch et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524003</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2006/0104357</doc-number>
<kind>A1</kind>
<name>Burazerovic et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524015</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2006/0110056</doc-number>
<kind>A1</kind>
<name>Gambhire</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382233</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2006/0257044</doc-number>
<kind>A1</kind>
<name>Chiu</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382261</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2006/0294171</doc-number>
<kind>A1</kind>
<name>Bossen et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>708300</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2007/0189392</doc-number>
<kind>A1</kind>
<name>Tourapis et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524021</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2007/0223575</doc-number>
<kind>A1</kind>
<name>Wang et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3752401</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2009/0074070</doc-number>
<kind>A1</kind>
<name>Yin et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2009/0080535</doc-number>
<kind>A1</kind>
<name>Yin et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524026</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2009/0207919</doc-number>
<kind>A1</kind>
<name>Yin et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524025</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2010/0158110</doc-number>
<kind>A1</kind>
<name>Pandit et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524012</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2011/0110427</doc-number>
<kind>A1</kind>
<name>Teng et al.</name>
<date>20110500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>AU</country>
<doc-number>5186293</doc-number>
<date>19940700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>BR</country>
<doc-number>406808</doc-number>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>BR</country>
<doc-number>0406808</doc-number>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>CN</country>
<doc-number>1739298</doc-number>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>EP</country>
<doc-number>603878</doc-number>
<date>19940600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>EP</country>
<doc-number>0 772 365</doc-number>
<date>19970500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>EP</country>
<doc-number>1588565</doc-number>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>JP</country>
<doc-number>02 235491</doc-number>
<date>19900900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>JP</country>
<doc-number>6 38197</doc-number>
<date>19940200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>JP</country>
<doc-number>6 311506</doc-number>
<date>19941100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>JP</country>
<doc-number>9 187008</doc-number>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>JP</country>
<doc-number>10 66082</doc-number>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>JP</country>
<doc-number>3489735</doc-number>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>JP</country>
<doc-number>2006 517362</doc-number>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>WO</country>
<doc-number>WO 2004 066634</doc-number>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>10</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382268</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382232</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090263032</doc-number>
<kind>A1</kind>
<date>20091022</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Tanaka</last-name>
<first-name>Junichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sato</last-name>
<first-name>Kazushi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yagasaki</last-name>
<first-name>Yoichi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ishigaya</last-name>
<first-name>Kazuhiro</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Tanaka</last-name>
<first-name>Junichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Sato</last-name>
<first-name>Kazushi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Yagasaki</last-name>
<first-name>Yoichi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Ishigaya</last-name>
<first-name>Kazuhiro</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Frommer Lawrence &#x26; Haug LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Frommer</last-name>
<first-name>William S.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Chen</last-name>
<first-name>Wenpeng</first-name>
<department>2665</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP2007/063948</doc-number>
<kind>00</kind>
<date>20070713</date>
</document-id>
<us-371c124-date>
<date>20090113</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2008/007757</doc-number>
<kind>A </kind>
<date>20080117</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image processing apparatus capable of improving image quality, includes a deblocking filter that adjusts a plurality of parameters related to deblocking processing on the basis of activity of an image calculated by an activity calculation section, the total sum of orthogonal transformation coefficients of the image calculated by an orthogonal transformation section, complexity of the image calculated by the rate control unit, or the total sum of prediction errors of the image calculated by a prediction error addition unit.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="169.08mm" wi="249.26mm" file="US08625924-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="251.54mm" wi="170.69mm" orientation="landscape" file="US08625924-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="237.49mm" wi="118.03mm" file="US08625924-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="242.74mm" wi="120.90mm" file="US08625924-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="124.38mm" wi="100.41mm" file="US08625924-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="204.13mm" wi="147.24mm" orientation="landscape" file="US08625924-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to an image processing apparatus, method, and program, and to an image processing apparatus, method, and program that are capable of improving image quality.</p>
<heading id="h-0002" level="1">BACKGROUND ART</heading>
<p id="p-0003" num="0002">A factor that causes degradation in the image quality of images encoded by an MPEG-2 (Moving Picture Experts Group phase 2) method is block noise. Thus, in an apparatus that encodes images by an MPEG-4 (Moving Picture Experts Group phase 4) method or an H.264/AVC (Advanced Video Coding) method, a deblocking filter that performs deblocking processing for removing block noise is provided (for example, see Patent Document 1). By such deblocking processing, even for, in particular, images at low bit rates, degradation in the image quality can be suppressed.
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0003">Patent Document 1: Japanese Patent No. 3489735</li>
</ul>
</p>
<heading id="h-0003" level="1">DISCLOSURE OF INVENTION</heading>
<heading id="h-0004" level="1">Technical Problem</heading>
<p id="p-0004" num="0004">However, since in deblocking processing, low-pass filtering processing is performed for boundaries between blocks, there is a problem in that block noise can be removed whereas detailed information on the design and the like (hereinafter, also referred to as texture) of an image is lost.</p>
<p id="p-0005" num="0005">The present invention has been designed in view of the above-described circumstances and aims to improve image quality by performing deblocking processing properly.</p>
<heading id="h-0005" level="1">Technical Solution</heading>
<p id="p-0006" num="0006">An image processing apparatus according to an aspect of the present invention includes a deblocking filter that performs deblocking processing on a decoded image obtained by decoding a second image that is used for motion estimation of a first image in a case where the first image is encoded and that is encoded prior to the first image, and feature quantity calculation means for calculating a feature quantity representing the complexity of the second image. The deblocking filter controls whether or not the deblocking processing is to be applied to the decoded image or controls the degree to which the deblocking processing is to be applied to the decoded image, on the basis of the feature quantity.</p>
<p id="p-0007" num="0007">The feature quantity calculation means can calculate the coding difficulty of the second image as the feature quantity.</p>
<p id="p-0008" num="0008">In a case where the second image is an image encoded by using inter-frame prediction, the feature quantity calculation means can set, as the feature quantity, a value obtained by normalizing the coding difficulty of the second image by using the coding difficulty of a third image encoded by using intra-frame prediction prior to the encoding of the second image.</p>
<p id="p-0009" num="0009">The feature quantity calculation means can divide the second image that has not been encoded into a plurality of blocks, and calculate the feature quantity on the basis of dispersion of pixel values for each of the blocks.</p>
<p id="p-0010" num="0010">The feature quantity calculation means can divide the second image that has not been encoded into a plurality of blocks, and calculate the feature quantity on the basis of a transformation coefficient obtained by performing orthogonal transformation for each of the blocks.</p>
<p id="p-0011" num="0011">The feature quantity calculation means can calculate the feature quantity on the basis of a prediction error, which is a difference between a predicted image for the second image predicted by inter-frame prediction and the second image that has not been encoded.</p>
<p id="p-0012" num="0012">The image processing apparatus can encode an image by an H.264/AVC (Advanced Video Coding) method. The deblocking filter can control whether or not the deblocking processing is to be applied to the decoded image or control the degree to which the deblocking processing is to be applied to the decoded image by adjusting a value of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, or slice_beta_offset_div2.</p>
<p id="p-0013" num="0013">The image processing apparatus can encode an image by an MPEG-4 (Moving Picture Coding Experts Group phase 4), H.264/AVC (Advanced Video Coding), or VC-1(Video Codec 1) method.</p>
<p id="p-0014" num="0014">An image processing method or program according to an aspect of the present invention includes the steps of calculating a feature quantity representing the complexity of a second image that is used for motion estimation of a first image in a case where the first image is encoded and that is encoded prior to the first image, and controlling whether or not deblocking processing is to be applied to a decoded image obtained by decoding the second image or controlling the degree to which the deblocking processing is to be applied to the decoded image, on the basis of the feature quantity.</p>
<p id="p-0015" num="0015">In an aspect of the present invention, a feature quantity representing the complexity of a second image that is used for motion estimation of a first image in a case where the first image is encoded and that is encoded prior to the first image is calculated, and control of whether or not deblocking processing is to be applied to a decoded image obtained by decoding the second image or control of the degree to which the deblocking processing is to be applied to the decoded image is performed on the basis of the feature quantity.</p>
<heading id="h-0006" level="1">Advantageous Effects</heading>
<p id="p-0016" num="0016">According to an aspect of the present invention, deblocking processing can be performed properly in accordance with the feature of an image. In addition, according to an aspect of the present invention, image quality can be improved.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0007" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0017" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing an embodiment of an image processing apparatus to which the present invention is applied.</p>
<p id="p-0018" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart for explaining an encoding process performed by the image processing apparatus in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0019" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart for explaining a first embodiment of a deblocking control process performed by the image processing apparatus in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0020" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart for explaining a second embodiment of a deblocking control process performed by the image processing apparatus in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0021" num="0021"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart for explaining a third embodiment of a deblocking control process performed by the image processing apparatus in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0022" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart for explaining a fourth embodiment of a deblocking control process performed by the image processing apparatus in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0023" num="0023"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram showing an example of the configuration of a personal computer.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0008" level="1">EXPLANATION OF REFERENCE NUMERALS</heading>
<p id="p-0024" num="0024"><b>101</b> image processing apparatus, <b>113</b> feature quantity calculation unit, <b>114</b> adder, <b>115</b> orthogonal transformation unit, <b>119</b> rate control unit, <b>120</b> prediction error addition unit, <b>124</b> deblocking filter, <b>126</b> intra-prediction unit, <b>127</b> motion estimation and compensation unit, <b>141</b> activity calculation section, <b>142</b> orthogonal transformation section</p>
<heading id="h-0009" level="1">BEST MODES FOR CARRYING OUT THE INVENTION</heading>
<p id="p-0025" num="0025">Hereinafter, embodiments of the present invention will be described with reference to the drawings.</p>
<p id="p-0026" num="0026"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing the configuration of an embodiment of an image processing apparatus to which the present invention is applied.</p>
<p id="p-0027" num="0027">An image processing apparatus <b>101</b> is an apparatus for encoding an input image by an H.264/AVC (Advanced Video Coding) method and outputting the encoded image to, for example, a recording apparatus or a transmission path, which is not illustrated, in the subsequent stage.</p>
<p id="p-0028" num="0028">The image processing apparatus <b>101</b> is configured to include an A/D (Analog/Digital) conversion unit <b>111</b>, a screen rearrangement buffer <b>112</b>, a feature quantity calculation unit <b>113</b>, an adder <b>114</b>, an orthogonal transformation unit <b>115</b>, a quantization unit <b>116</b>, a lossless coding unit <b>117</b>, a storage buffer <b>118</b>, a rate control unit <b>119</b>, a prediction error addition unit <b>120</b>, a dequantization unit <b>121</b>, an inverse orthogonal transformation unit <b>122</b>, an adder <b>123</b>, a deblocking filter <b>124</b>, a frame memory <b>125</b>, an intra-prediction unit <b>126</b>, and a motion estimation and compensation unit <b>127</b>. In addition, the feature quantity calculation unit <b>113</b> is configured to include an activity calculation section <b>141</b> and an orthogonal transformation section <b>142</b>.</p>
<p id="p-0029" num="0029">The A/D conversion unit <b>111</b> analog-to-digital converts an analog image input from the outside into a digital image, and supplies the converted digital image (hereinafter, also referred to as an original image, where appropriate) to the screen rearrangement buffer <b>112</b>.</p>
<p id="p-0030" num="0030">The screen rearrangement buffer <b>112</b> rearranges original images supplied from the A/D conversion unit <b>111</b> on the basis of a GOP (Group Of Pictures) structure, and sequentially supplies the original images to the feature quantity calculation unit <b>113</b>.</p>
<p id="p-0031" num="0031">The feature quantity calculation unit <b>113</b> calculates a feature quantity representing the complexity of an original image. In addition, the feature quantity calculation unit <b>113</b> supplies, to the adder <b>114</b>, the intra-prediction unit <b>126</b>, and the motion estimation and compensation unit <b>127</b>, the original image for which calculation of the feature quantity has been completed.</p>
<p id="p-0032" num="0032">Among the elements constituting the feature quantity calculation unit <b>113</b>, the activity calculation section <b>141</b> divides an original image into a plurality of blocks, and calculates the feature quantity of the original image on the basis of dispersion of pixel values for each block, as described later with reference to <figref idref="DRAWINGS">FIG. 4</figref>. The activity calculation section <b>141</b> supplies information indicating the calculated feature quantity to the deblocking filter <b>124</b>.</p>
<p id="p-0033" num="0033">In addition, as described later with reference to <figref idref="DRAWINGS">FIG. 5</figref>, the orthogonal transformation section <b>142</b> divides an original image into a plurality of blocks, and calculates the feature quantity of the original image on the basis of a transformation coefficient obtained by performing orthogonal transformation for each of the blocks. The orthogonal transformation section <b>142</b> supplies information indicating the calculated feature quantity to the deblocking filter <b>124</b>.</p>
<p id="p-0034" num="0034">For each macroblock, the adder <b>114</b> obtains, from the intra-prediction unit <b>126</b> or the motion estimation and compensation unit <b>127</b>, one of an intra-predicted image predicted by using intra prediction (intra-frame prediction) and an inter-predicted image predicted by using inter prediction (inter-frame prediction, motion compensation prediction) for an original image. The adder <b>114</b> calculates, for each macroblock, a difference between the original image and the intra-predicted image or the inter-predicted image, and supplies, to the orthogonal transformation unit <b>115</b> and the prediction error addition unit <b>120</b>, a difference image formed from prediction errors obtained by calculation of the difference.</p>
<p id="p-0035" num="0035">The orthogonal transformation unit <b>115</b> performs orthogonal transformation, such as discrete cosine transform or Karhunen-Loeve transform, on a difference image for each block having a predetermined size, and supplies the thus obtained transformation coefficients to the quantization unit <b>116</b>.</p>
<p id="p-0036" num="0036">The quantization unit <b>116</b> quantizes the transformation coefficients supplied from the orthogonal transformation unit <b>115</b> by using quantizer scales controlled by the rate control unit <b>119</b>, and supplies the quantized transformation coefficients to the lossless coding unit <b>117</b> and the dequantization unit <b>121</b>.</p>
<p id="p-0037" num="0037">The lossless coding unit <b>117</b> obtains information on intra prediction from the intra-prediction unit <b>126</b> and obtains information on inter prediction from the motion estimation and compensation unit <b>127</b>. The lossless coding unit <b>117</b> arranges quantized transformation coefficients, information on intra prediction, information on inter prediction, and the like in a predetermined order, and performs lossless coding processing, such as variable-length coding such as CAVLC (Context-Adaptive Variable Length Coding) or arithmetic coding such as CABAC (Context-Adaptive Binary Arithmetic Coding), on the arranged data. The lossless coding unit <b>117</b> supplies the encoded data to the storage buffer <b>118</b> to be stored therein.</p>
<p id="p-0038" num="0038">The storage buffer <b>118</b> outputs, as an image encoded by the H.264/AVC method, data supplied from the lossless coding unit <b>117</b>, for example, to a recording apparatus or a transmission path, which is not illustrated, in the subsequent stage.</p>
<p id="p-0039" num="0039">The rate control unit <b>119</b> controls, on the basis of the code amount of an image stored in the storage buffer <b>118</b>, a bit rate, which is the code amount per time assigned to an image to be encoded.</p>
<p id="p-0040" num="0040">For example, the rate control unit <b>119</b> controls, by using a rate control method defined by MPEG-2 TestModel 5 (TM5), the bit rate by controlling the value of a quantizer scale, which is a value dividing a transformation coefficient when the quantization unit <b>116</b> performs quantization. In addition, as described later with reference to <figref idref="DRAWINGS">FIG. 3</figref>, the rate control unit <b>119</b> calculates the coding difficulty as the feature quantity representing the complexity of an original image, and supplies the calculated coding difficulty to the deblocking filter <b>124</b>.</p>
<p id="p-0041" num="0041">The prediction error addition unit <b>120</b> calculates, as described later with reference to <figref idref="DRAWINGS">FIG. 6</figref>, the feature quantity representing the complexity of an image on the basis of prediction errors forming a difference image supplied from the adder <b>114</b>. The prediction error addition unit <b>120</b> supplies information indicating the calculated feature quantity to the deblocking filter <b>124</b>.</p>
<p id="p-0042" num="0042">The dequantization unit <b>121</b> dequantizes transformation coefficients supplied from the quantization unit <b>116</b> and supplies the dequantized transformation coefficients to the inverse orthogonal transformation unit <b>122</b>.</p>
<p id="p-0043" num="0043">The inverse orthogonal transformation unit <b>122</b> performs inverse orthogonal transformation, such as inverse discrete cosine transform or inverse Karhunen-Loeve transform, on the transformation coefficients supplied from the dequantization unit <b>121</b>. Thus, a difference image is obtained by decoding. The inverse orthogonal transformation unit <b>122</b> supplies the decoded difference image to the adder <b>123</b>.</p>
<p id="p-0044" num="0044">The adder <b>123</b> obtains, from the intra-prediction unit <b>126</b> or the motion estimation and compensation unit <b>127</b>, an intra-predicted image or an inter-predicted image that has been used for generation of a difference image, and adds the difference image and the obtained intra-predicted image or inter-predicted image together. Thus, an original image is obtained by decoding. The adder <b>123</b> supplies the decoded image (hereinafter, referred to as a decoded image, where appropriate) to the deblocking filter <b>124</b>.</p>
<p id="p-0045" num="0045">The deblocking filter <b>124</b> performs deblocking processing for removing block noise on a decoded image. Note that, as described later with reference to <figref idref="DRAWINGS">FIGS. 3 to 6</figref>, the deblocking filter <b>124</b> controls whether or not deblocking processing is to be applied to the decoded image or controls the degree to which the deblocking processing is to be applied to the decoded image, on the basis of the feature quantity obtained from the rate control unit <b>119</b>, the prediction error addition unit <b>120</b>, the activity calculation section <b>141</b>, or the orthogonal transformation section <b>142</b>. The deblocking filter <b>124</b> supplies a decoded image that has been subjected to deblocking processing to the frame memory <b>125</b>. In addition, the deblocking filter <b>124</b> directly supplies, as an image to be used for intra prediction, a decoded image that has not been subjected to deblocking processing, to the frame memory <b>125</b>.</p>
<p id="p-0046" num="0046">The frame memory <b>125</b> stores, as an image to be referred to in a case where intra prediction or inter prediction is performed (hereinafter, referred to as a reference image, where appropriate), a decoded image supplied from the deblocking filter <b>124</b>.</p>
<p id="p-0047" num="0047">The intra-prediction unit <b>126</b> performs, for each macroblock, by using an encoded pixel adjacent to the corresponding macroblock within the same frame stored in the frame memory <b>125</b>, intra prediction for generating a predicted image for an original image. Note that, as described above, a pixel of a decoded image that has not been subjected to deblocking processing is used for intra prediction.</p>
<p id="p-0048" num="0048">The motion estimation and compensation unit <b>127</b> detects, for each macroblock, by using a reference image in a different frame stored in the frame memory <b>125</b>, a motion vector of an original image with respect to the reference image, and performs motion compensation on the reference image by using the detected motion vector. Accordingly, the motion estimation and compensation unit <b>127</b> performs inter prediction for generating an inter-predicted image for the original image.</p>
<p id="p-0049" num="0049">In addition, a prediction mode to be applied to each macroblock is determined, for example, by a mode determination unit, which is not illustrated, using a Low Complexity Mode (high-speed mode) method. In a case where an applied prediction mode is a prediction mode for intra prediction, as shown in <figref idref="DRAWINGS">FIG. 1</figref>, the frame memory <b>125</b> and the intra-prediction unit <b>126</b> are connected together and the intra-prediction unit <b>126</b>, the adder <b>114</b>, and the adder <b>123</b> are connected together. The intra-prediction unit <b>126</b> generates an intra-predicted image on the basis of the selected prediction mode, and supplies the generated intra-predicted image to the adder <b>114</b> and the adder <b>123</b>. In addition, the intra-prediction unit <b>126</b> supplies, as information on intra prediction of a macroblock for which intra prediction has been performed, information on the applied prediction mode and the like to the lossless coding unit <b>117</b>.</p>
<p id="p-0050" num="0050">In addition, in a case where the applied prediction mode is a prediction mode for inter prediction, although not shown in <figref idref="DRAWINGS">FIG. 1</figref>, the frame memory <b>125</b> and the motion estimation and compensation unit <b>127</b> are connected together and the motion estimation and compensation unit <b>127</b>, the adder <b>114</b>, and the adder <b>123</b> are connected together. The motion estimation and compensation unit <b>127</b> generates an inter-predicted image on the basis of the selected prediction mode, and supplies the generated inter-predicted image to the adder <b>114</b> and the adder <b>123</b>. In addition, the intra-prediction unit <b>126</b> supplies, as information on inter prediction of a macroblock for which inter prediction has been performed, information on the applied prediction mode, a detected motion vector, the number of an image (picture) referred to, and the like to the lossless coding unit <b>117</b>.</p>
<p id="p-0051" num="0051">Next, an encoding process performed by the image processing apparatus <b>101</b> in <figref idref="DRAWINGS">FIG. 1</figref> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. 2</figref>. Note that this process is started, for example, when inputting of an image from the outside to the image processing apparatus <b>101</b> is started.</p>
<p id="p-0052" num="0052">In step S<b>1</b>, the image processing apparatus <b>101</b> starts encoding of an image. That is, by start of the operations described above with reference to <figref idref="DRAWINGS">FIG. 1</figref> by individual units of the image processing apparatus <b>101</b>, encoding of an input image by the H.264/AVC method is started. In addition, a deblocking control process, which will be described later with reference to <figref idref="DRAWINGS">FIGS. 3 to 6</figref>, is also started.</p>
<p id="p-0053" num="0053">In step S<b>2</b>, the image processing apparatus <b>101</b> determines whether all the images have been encoded. Encoding of images is performed until it is determined in step S<b>2</b> that all the images input from the outside have been encoded. In a case where it is determined that all the images input from the outside have been encoded, the encoding process ends.</p>
<p id="p-0054" num="0054">Next, a first embodiment of a deblocking control process performed by the image processing apparatus <b>101</b> in the process of the encoding process, which has been described above with reference to <figref idref="DRAWINGS">FIG. 2</figref>, will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0055" num="0055">In step S<b>21</b>, the rate control unit <b>119</b> calculates Complexity. Specifically, the rate control unit <b>119</b> obtains an encoded image (picture) from the storage buffer <b>118</b>. The rate control unit <b>119</b> calculates a coding difficulty Complexity as a feature quantity representing the complexity of the image, by using the following equation (1):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Complexity=PictureGeneratedBis&#xd7;PictureAverageQuant&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0056" num="0056">Here, PictureGeneratedBis represents the generated code amount of the image. In addition, PictuerAverageQuant represents the average of quantizer scales applied to the image and is calculated by the following equation (2):</p>
<p id="p-0057" num="0057">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mo>[</mo>
        <mrow>
          <mi>Expression</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mn>1</mn>
        </mrow>
        <mo>]</mo>
      </mrow>
    </mtd>
    <mtd>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>PictureAverageQuant</mi>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <mi>MBNum</mi>
          </mfrac>
          <mo>&#x2062;</mo>
          <mrow>
            <munderover>
              <mo>&#x2211;</mo>
              <mrow>
                <mi>k</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mi>MBNum</mi>
            </munderover>
            <mo>&#x2062;</mo>
            <msub>
              <mi>Quant</mi>
              <mi>k</mi>
            </msub>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>2</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0058" num="0058">Here, MBNum represents the number of macroblocks of the image. In addition, Quantk represents a quantizer scale applied to a kth macroblock within the image and is calculated by the following equation (3):</p>
<p id="p-0059" num="0059">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mo>[</mo>
        <mrow>
          <mi>Expression</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mn>2</mn>
        </mrow>
        <mo>]</mo>
      </mrow>
    </mtd>
    <mtd>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>Quant</mi>
          <mi>k</mi>
        </msub>
        <mo>=</mo>
        <msup>
          <mn>2</mn>
          <mfrac>
            <msub>
              <mi>QP</mi>
              <mi>k</mi>
            </msub>
            <mn>6</mn>
          </mfrac>
        </msup>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0060" num="0060">Here, QPk represents a quantization parameter of the kth macroblock within the image.</p>
<p id="p-0061" num="0061">That is, Complexity calculated by equation (1) is a value obtained by multiplexing the generated code amount of the image with the average of quantizer scales. Thus, Complexity becomes smaller as the motion of an image is decreased. In addition, Complexity becomes greater as the motion of an image is increased.</p>
<p id="p-0062" num="0062">In step S<b>22</b>, the deblocking filter <b>124</b> adjusts parameters regarding deblocking processing. Specifically, the rate control unit <b>119</b> supplies information indicating the calculated Complexity to the deblocking filter <b>124</b>. The deblocking filter <b>124</b> adjusts the values of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, and slice_beta_offset_div2 in accordance with the value of Complexity of an image to be subjected to deblocking processing.</p>
<p id="p-0063" num="0063">Disable_deblocking_filter_idc is a parameter for setting whether or not deblocking processing is to be applied and can be set for each slice. Disable_deblocking_filter_idc is set to 0 in a case where deblocking processing is applied, set to 1 in a case where deblocking processing is not applied, and set to 2 in a case where deblocking processing is not applied at a boundary between slices.</p>
<p id="p-0064" num="0064">Slice_alpha_c0_offset_div2 is a parameter for adjusting the degree to which deblocking processing is applied to a boundary between blocks in a case where a slice is divided into blocks of 4&#xd7;4 pixels and can be set for each slice. Slice_alpha_c0_offset_div2 can be set within a range from &#x2212;6 to +6. As the value is decreased, the degree to which deblocking processing is applied becomes lower. As the value is increased, the degree to which deblocking processing is applied becomes higher.</p>
<p id="p-0065" num="0065">Slice_beta_offset_div2 is a parameter for adjusting the degree to which deblocking processing is applied to a pixel within a block in a case where a slice is divided into blocks of 4&#xd7;4 pixels and can be set for each slice. Slice_beta_offset_div2 can be set within a range from &#x2212;6 to +6. As the value is decreased, the degree to which deblocking processing is applied becomes lower. As the value is increased, the degree to which deblocking processing is applied becomes higher.</p>
<p id="p-0066" num="0066">In step S<b>22</b>, for example, in a case where Complexity is less than a predetermined threshold Thc, disable_deblocking_filter_idc is set to 1. That is, for an image in which only slight block noise is generated and very little motion occurs, deblocking processing is not applied.</p>
<p id="p-0067" num="0067">In addition, for example, in a case where Complexity is equal to or more than the threshold Thc, the values of slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are adjusted in accordance with the value of Complexity. For example, as the value of Complexity becomes smaller, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to &#x2212;6. In addition, as the value of Complexity becomes greater, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to +6. That is, for an image in which block noise is less likely to be generated and a small amount of motion occurs, the degree to which deblocking processing is applied is decreased. In addition, for an image in which block noise is more likely to be generated and a great amount of motion occurs, the degree to which deblocking processing is applied is increased.</p>
<p id="p-0068" num="0068">In step S<b>23</b>, the deblocking filter <b>124</b> performs deblocking processing, and the deblocking control process ends. A decoded image that has been subjected to deblocking processing is stored as a reference image in the frame memory <b>125</b>. Note that in a case where disable_deblocking_filter_idc is set to 1, deblocking processing is not performed.</p>
<p id="p-0069" num="0069">As described above, in accordance with Complexity, deblocking processing is properly performed on a decoded image, and a reference image from which block noise has been removed is generated while texture is maintained. Thus, the image quality of an image that is subjected to inter-prediction coding by using the reference image can be improved.</p>
<p id="p-0070" num="0070">Note that the value of the threshold Thc may be changed in accordance with the type of image, that is, in accordance with whether the image is an I-picture, a P-picture, or a B-picture.</p>
<p id="p-0071" num="0071">In addition, the coding difficulties of a P-picture and a B-picture, which are images encoded by using inter-frame prediction, may be normalized by using Complexity of an I-picture, which is an image encoded by using intra-frame prediction prior to the image, and deblocking processing may be controlled on the basis of the normalized values (Norm_Complexity). Norm_ComplexityPpic, which is obtained by normalizing Complexity of a P-picture, and Norm_ComplexityBpic, which is obtained by normalizing Complexity of a B-picture, are calculated by the following equations (4) to (8):</p>
<p id="p-0072" num="0072">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>ComplexityIpic</mi>
        <mo>=</mo>
        <mrow>
          <mi>PictureGeneratedBisIpic</mi>
          <mo>&#xd7;</mo>
          <mi>PictureAverageQuantIpic</mi>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>ComplexityPpic</mi>
        <mo>=</mo>
        <mrow>
          <mi>PictureGeneratedBisPpic</mi>
          <mo>&#xd7;</mo>
          <mi>PictureAverageQuantPpic</mi>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>5</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>ComplexityBpic</mi>
        <mo>=</mo>
        <mrow>
          <mi>PictureGeneratedBisBpic</mi>
          <mo>&#xd7;</mo>
          <mi>PictureAverageQuantBpic</mi>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>6</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>Norm_ComplexityPpic</mi>
          <mo>=</mo>
          <mrow>
            <mi>ComplexityPpic</mi>
            <mo>&#xf7;</mo>
            <mi>ComplexityIpic</mi>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>7</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>Norm_ComplexityBpic</mi>
          <mo>=</mo>
          <mrow>
            <mi>ComplexityBpic</mi>
            <mo>&#xf7;</mo>
            <mi>ComplexityIpic</mi>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>8</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0073" num="0073">Note that ComplexityIpic, PictureGeneratedBisIpic, and PictureAverageQuantIpic represent the coding difficulty, the generated code amount, and the average of quantizer scales of an I-picture, respectively. In addition, ComplexityPpic, PictureGeneratedBisPpic, and PictureAverageQuantPpic represent the coding difficulty, the generated code amount, and the average of quantizer scales of a P-picture, respectively. In addition, ComplexityBpic, PictureGeneratedBisBpic, and PictureAverageQuantIBic represent the coding difficulty, the generated code amount, and the average of quantizer scales of a B-picture, respectively.</p>
<p id="p-0074" num="0074">For example, in a case where an image to be subjected to deblocking processing is a P-picture or a B-picture, if Norm_Complexity is less than a predetermined threshold Thcn, disable_deblocking_filter_idc is set to 1. That is, for an image in which only slight block noise is generated and very little motion occurs, deblocking processing is not applied.</p>
<p id="p-0075" num="0075">In addition, for example, in a case where Norm_Complexity is equal to or more than the threshold Thcn, the values of slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are adjusted in accordance with the value of Norm_Complexity. For example, as the value of Norm_Complexity becomes smaller, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to &#x2212;6. In addition, as the value of Norm_Complexity becomes greater, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to +6. That is, for an image in which block noise is less likely to be generated and a small amount of motion occurs, the degree to which deblocking processing is applied is decreased. In addition, for an image in which block noise is more likely to be generated and a great amount of motion occurs, the degree to which deblocking processing is applied is increased.</p>
<p id="p-0076" num="0076">Since Norm_ComplexityPpic and Norm_ComplexityBpic represent the motion of a P-picture and a B-picture in a case where the motion of an I-picture is set to 1 and the complexity of the motion of each picture can thus be extracted more accurately, deblocking processing can be performed more properly. Thus, the image quality of an image that is subjected to inter-prediction coding can be further improved.</p>
<p id="p-0077" num="0077">Note that the value of the threshold Thcn may be changed in accordance with the type of image, that is, in accordance with whether the image is a P-picture or a B-picture.</p>
<p id="p-0078" num="0078">In addition, it is preferable that an I-picture to be used for normalization be an I-picture that was most recently encoded prior to the image or an I-picture referred to in encoding of the image.</p>
<p id="p-0079" num="0079">In addition, for an I-picture, deblocking processing is controlled on the basis of Complexity, as described above.</p>
<p id="p-0080" num="0080">Next, a second embodiment of a deblocking control process performed by the image processing apparatus <b>101</b> in the process of the encoding process, which has been described above with reference to <figref idref="DRAWINGS">FIG. 2</figref>, will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0081" num="0081">In step S<b>41</b>, the activity calculation section <b>141</b> calculates Activity. Specifically, the activity calculation section <b>141</b> calculates Activity as a feature quantity representing the complexity of an image to be encoded, by using the following equation (9):</p>
<p id="p-0082" num="0082">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mo>[</mo>
        <mrow>
          <mi>Expression</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mn>3</mn>
        </mrow>
        <mo>]</mo>
      </mrow>
    </mtd>
    <mtd>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>Activity</mi>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <mi>MBNum</mi>
          </mfrac>
          <mo>&#x2062;</mo>
          <mrow>
            <munderover>
              <mo>&#x2211;</mo>
              <mrow>
                <mi>k</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mi>MBNum</mi>
            </munderover>
            <mo>&#x2062;</mo>
            <msub>
              <mi>act</mi>
              <mi>k</mi>
            </msub>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>9</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0083" num="0083">Here, actk represents the activity of a kth macroblock of the image and is calculated by the following equation (10):</p>
<p id="p-0084" num="0084">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mo>[</mo>
        <mrow>
          <mi>Expression</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mn>4</mn>
        </mrow>
        <mo>]</mo>
      </mrow>
    </mtd>
    <mtd>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>act</mi>
          <mi>k</mi>
        </msub>
        <mo>=</mo>
        <mrow>
          <mn>1</mn>
          <mo>+</mo>
          <mrow>
            <munder>
              <mi>min</mi>
              <mrow>
                <mrow>
                  <mi>sblk</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mo>,</mo>
                <mn>8</mn>
              </mrow>
            </munder>
            <mo>&#x2062;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>var</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.6em" height="0.6ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <mi>sblk</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>10</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0085" num="0085">Here, one macroblock is divided into four sub-blocks formed by 8&#xd7;8 pixels and var sblk represents a value indicating dispersion of pixel values of a divided sub-block and is calculated by the following equations (11) and (12):</p>
<p id="p-0086" num="0086">
<maths id="MATH-US-00006" num="00006">
<math overflow="scroll">
  <mrow>
    <mo>[</mo>
    <mrow>
      <mi>Expression</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.8em" height="0.8ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mn>5</mn>
    </mrow>
    <mo>]</mo>
  </mrow>
</math>
</maths>
<maths id="MATH-US-00006-2" num="00006.2">
<math overflow="scroll">
  <mtable>
    <mtr>
      <mtd>
        <mrow>
          <mrow>
            <mi>var</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.6em" height="0.6ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>sblk</mi>
          </mrow>
          <mo>=</mo>
          <mrow>
            <mfrac>
              <mn>1</mn>
              <mn>64</mn>
            </mfrac>
            <mo>&#x2062;</mo>
            <mrow>
              <munderover>
                <mo>&#x2211;</mo>
                <mrow>
                  <mi>k</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mn>64</mn>
              </munderover>
              <mo>&#x2062;</mo>
              <msup>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <msub>
                      <mi>P</mi>
                      <mi>k</mi>
                    </msub>
                    <mo>-</mo>
                    <mover>
                      <mi>P</mi>
                      <mi>_</mi>
                    </mover>
                  </mrow>
                  <mo>)</mo>
                </mrow>
                <mn>2</mn>
              </msup>
            </mrow>
          </mrow>
        </mrow>
      </mtd>
      <mtd>
        <mrow>
          <mo>(</mo>
          <mn>11</mn>
          <mo>)</mo>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd>
        <mrow>
          <mover>
            <mi>P</mi>
            <mi>_</mi>
          </mover>
          <mo>=</mo>
          <mrow>
            <mfrac>
              <mn>1</mn>
              <mn>64</mn>
            </mfrac>
            <mo>&#x2062;</mo>
            <mrow>
              <munderover>
                <mo>&#x2211;</mo>
                <mrow>
                  <mi>k</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mn>64</mn>
              </munderover>
              <mo>&#x2062;</mo>
              <msub>
                <mi>P</mi>
                <mi>k</mi>
              </msub>
            </mrow>
          </mrow>
        </mrow>
      </mtd>
      <mtd>
        <mrow>
          <mo>(</mo>
          <mn>12</mn>
          <mo>)</mo>
        </mrow>
      </mtd>
    </mtr>
  </mtable>
</math>
</maths>
</p>
<p id="p-0087" num="0087">Here, Pk represents the pixel value of a kth pixel within a sub-block.</p>
<p id="p-0088" num="0088">In addition, var sblk is obtained for each sub-block in two cases, a frame DCT encoding mode and a field DCT encoding mode, and minsblk=1,8(var sblk) in equation (10) represents the minimum value of the obtained var sblk.</p>
<p id="p-0089" num="0089">That is, Activity calculated by equation (9) is an average of the activities of individual macroblocks in the image and is a value, for example, to be used for rate control defined by MPEG-2 TestModel 5 (TM5). Thus, Activity becomes smaller as a change in pixel values is decreased. In addition, Activity becomes greater as a change in pixel values is increased.</p>
<p id="p-0090" num="0090">In step S<b>42</b>, the deblocking filter <b>124</b> adjusts parameters regarding deblocking processing. Specifically, the activity calculation section <b>141</b> supplies information indicating the calculated Activity to the deblocking filter <b>124</b>. The deblocking filter <b>124</b> adjusts the values of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, and slice_beta_offset_div2 in accordance with the value of Activity of an image to be subjected to deblocking processing.</p>
<p id="p-0091" num="0091">For example, in a case where Activity is less than a predetermined threshold Tha, disable_deblocking_filter_idc is set to 1. That is, for a plain image in which only slight block noise is generated and a very small amount of change occurs in pixel values, deblocking processing is not applied.</p>
<p id="p-0092" num="0092">In addition, for example, in a case where Activity is equal to or more than the threshold Tha, the values of slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are adjusted in accordance with the value of Activity. For example, as the value of Activity becomes smaller, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to &#x2212;6. In addition, as the value of Activity becomes greater, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to +6. That is, for an image in which block noise is less likely to be generated and a small amount of change occurs in pixel values, the degree to which deblocking processing is applied is decreased. In addition, for a complicated image in which block noise is more likely to be generated and a great amount of change occurs in pixel values, the degree to which deblocking processing is applied is increased.</p>
<p id="p-0093" num="0093">In step S<b>43</b>, as in the above-described processing of step S<b>23</b> in <figref idref="DRAWINGS">FIG. 3</figref>, deblocking processing is performed, and the deblocking control process ends.</p>
<p id="p-0094" num="0094">As described above, in accordance with Activity, deblocking processing is properly performed on a decoded image, and a reference image from which block noise has been removed is generated while texture is maintained. Thus, the image quality of an image that is subjected to inter-prediction coding by using the reference image can be improved.</p>
<p id="p-0095" num="0095">In addition, in a case where Activity is used, before an image is encoded, a feature quantity representing the complexity of the image can be obtained.</p>
<p id="p-0096" num="0096">Furthermore, as described above, since Activity is a value used in rate control defined by MPEG-2 TestModel 5 (TM5), for example, Activity can be calculated by the rate control unit <b>119</b>.</p>
<p id="p-0097" num="0097">In addition, instead of the above-described Activity, that is, the average of the activities of individual macroblocks, a value reflecting the size of dispersion of pixel values of the image, such as, for example, the total value of the activities of the individual macroblocks, may be used.</p>
<p id="p-0098" num="0098">A third embodiment of a deblocking control process performed by the image processing apparatus <b>101</b> in the process of the encoding process, which has been described above with reference to <figref idref="DRAWINGS">FIG. 2</figref>, will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0099" num="0099">In step S<b>61</b>, the orthogonal transformation section <b>142</b> calculates the total sum of orthogonal transformation coefficients. Specifically, the orthogonal transformation section <b>142</b> divides an image to be encoded into blocks having a predetermined size. Note that, hereinafter, an example in which division into blocks of 4&#xd7;4 pixels is performed and Hadamard transform is employed as orthogonal transformation will be described. The orthogonal transformation section <b>142</b> performs Hadamard transform of each block by using the following equation (13):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>P&#x2032;=HTPH&#x2003;&#x2003;(13)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0100" num="0100">Here, P represents a pixel matrix of 4&#xd7;4 pixels before Hadamard transform is performed, and P&#x2032; represents a matrix of 4&#xd7;4 transformation coefficients after Hadamard transform is performed. In addition, H represents a fourth-order Hadamard matrix represented by the following equation (14), and HT represents a transposed matrix of a fourth-order Hadamard matrix.</p>
<p id="p-0101" num="0101">
<maths id="MATH-US-00007" num="00007">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mo>[</mo>
        <mrow>
          <mi>Expression</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mn>6</mn>
        </mrow>
        <mo>]</mo>
      </mrow>
    </mtd>
    <mtd>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>H</mi>
          <mn>4</mn>
        </msub>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <msqrt>
              <mn>4</mn>
            </msqrt>
          </mfrac>
          <mo>&#x2062;</mo>
          <mrow>
            <mo>(</mo>
            <mtable>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>14</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0102" num="0102">The orthogonal transformation section <b>142</b> calculates, for each block, the sum Ph of the absolute values of transformation coefficients other than a transformation coefficient of coordinates (0,0) of the transformation coefficient matrix P&#x2032; (a transformation coefficient of a DC (direct-current) component). That is, Ph represents the sum of the absolute values of transformation coefficients of AC (alternating-current) components that are correlated with respect to the code amount from among transformation coefficients within a block after Hadamard transform is performed. Furthermore, the orthogonal transformation section <b>142</b> calculates the total sum DCtotal of Ph of the entire blocks in the image. Note that a smaller DCtotal is obtained as an image becomes simpler, in which frequency components are concentrated. In addition, a larger DCtotal is obtained as an image becomes complicated, in which frequency components are dispersed.</p>
<p id="p-0103" num="0103">In step S<b>62</b>, the deblocking filter <b>124</b> adjusts parameters regarding deblocking processing. Specifically, the orthogonal transformation section <b>142</b> supplies information indicating the calculated DCtotal to the deblocking filter <b>124</b>. The deblocking filter <b>124</b> adjusts the values of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, and slice_beta_offset_div2 in accordance with the value of DCtotal of an image to be subjected to deblocking processing.</p>
<p id="p-0104" num="0104">For example, in a case where DCtotal is less than a predetermined threshold Thd, disable_deblocking_filter_idc is set to 1. That is, for a very simple image in which only slight noise is generated and frequency components are concentrated, deblocking processing is not applied.</p>
<p id="p-0105" num="0105">In addition, for example, in a case where DCtotal is equal to or more than the threshold Thd, the values of slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are adjusted in accordance with the value of DCtotal. For example, as the value of DCtotal becomes smaller, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to &#x2212;6. In addition, as the value of DCtotal becomes greater, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to +6. That is, for a simple image in which block noise is less likely to be generated and frequency components are concentrated, the degree to which deblocking processing is applied is decreased. In addition, for a complicated image in which block noise is more likely to be generated and frequency components are dispersed, the degree to which deblocking processing is applied is increased.</p>
<p id="p-0106" num="0106">In step S<b>63</b>, as in the above-described processing of step S<b>23</b> in <figref idref="DRAWINGS">FIG. 3</figref>, deblocking processing is performed, and the deblocking control process ends.</p>
<p id="p-0107" num="0107">Note that, although in the above description, an example in which Hadamard transform is employed as orthogonal transformation has been described, other types of orthogonal transformation, such as, for example, DCT (discrete cosine transform), may be employed.</p>
<p id="p-0108" num="0108">In addition, irrespective of the type of orthogonal transformation, the sizes of blocks to be obtained by division are not limited to the above-described 4&#xd7;4 pixels. For example, the sizes of the blocks can be set to desired sizes, such as, for example, 8&#xd7;8 pixels.</p>
<p id="p-0109" num="0109">As described above, in accordance with DCtotal, deblocking processing is properly performed on a decoded image, and a reference image from which block noise has been removed is generated while texture is maintained. Thus, the image quality of an image that is subjected to inter-prediction coding by using the reference image can be improved.</p>
<p id="p-0110" num="0110">In addition, since DCtotal is the total sum of transformation coefficients resolved into frequency components by application of orthogonal transformation, the correlation with respect to the coding difficulty of the image is increased. Thus, the complexity of an image can be expressed with a high accuracy compared to Activity.</p>
<p id="p-0111" num="0111">Furthermore, in a case where DCtotal is used, before an image is encoded, a feature quantity representing the complexity of the image can be obtained.</p>
<p id="p-0112" num="0112">In addition, instead of the orthogonal transformation section <b>142</b>, by using the orthogonal transformation unit <b>115</b>, orthogonal transformation coefficients can be calculated.</p>
<p id="p-0113" num="0113">Furthermore, instead of the above-described DCtotal, that is, the total sum of orthogonal transformation coefficients of AC components, values reflecting the sizes of the orthogonal transformation coefficients of the AC components of the image, such as, for example, the average of the orthogonal transformation coefficients of the AC components, may be used.</p>
<p id="p-0114" num="0114">A fourth embodiment of a deblocking control process performed by the image processing apparatus <b>101</b> in the process of the encoding process, which has been described above with reference to <figref idref="DRAWINGS">FIG. 2</figref>, will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0115" num="0115">In step S<b>81</b>, the prediction error addition unit <b>120</b> calculates the total sum of prediction errors. Specifically, in a case where an image to be encoded, that is, an image for which a difference is calculated by the adder <b>114</b>, is a P-picture or a B-picture, the prediction error addition unit <b>120</b> adds, for one picture, prediction errors supplied from the adder <b>114</b>. Thus, the total sum Et of the prediction errors is calculated. Note that, the more easily the motion of an image is predicted, that is, the smaller and simpler the motion of the image is, the smaller Et is. In addition, the more difficultly the motion of an image is predicted, that is, the greater and more complicated the motion of the image is, the greater Et is.</p>
<p id="p-0116" num="0116">In step S<b>82</b>, the deblocking filter <b>124</b> adjusts parameters regarding deblocking processing. Specifically, the prediction error addition unit <b>120</b> supplies, to the deblocking filter <b>124</b>, information indicating the calculated total sum Et of the prediction errors. The deblocking filter <b>124</b> adjusts the values of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, and slice_beta_offset_div2 in accordance with the value of Et.</p>
<p id="p-0117" num="0117">For example, in a case where Et is less than a predetermined threshold The, disable_deblocking_filter_idc is set to 1. That is, for an image in which only slight block noise is generated and very little motion occurs, deblocking processing is not applied.</p>
<p id="p-0118" num="0118">In addition, for example, in a case where Et is equal to or more than the threshold The, the values of slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are adjusted in accordance with the value of Et. For example, as the value of Et becomes smaller, slice_alpha_c0_offset_div2 and slice_beta_offset_div2 are set to values nearer to &#x2212;6. In addition, as the value of Et becomes greater, and slice_beta_offset_div2 are set to values nearer to +6. That is, for a simple image in which block noise is less likely to be generated and a small amount of motion occurs, the degree to which deblocking processing is applied is decreased. In addition, for a complicated image in which block noise is more likely to be generated and a great amount of motion occurs, the degree to which deblocking processing is applied is increased.</p>
<p id="p-0119" num="0119">In step S<b>83</b>, as in the above-described processing of step S<b>23</b> in <figref idref="DRAWINGS">FIG. 3</figref>, deblocking processing is performed, and the deblocking control process ends.</p>
<p id="p-0120" num="0120">As described above, in accordance with Et, deblocking processing is properly performed on a decoded image, and a reference image from which block noise has been removed is generated while texture is maintained. Thus, the image quality of an image that is subjected to inter-prediction coding by using the reference image can be improved.</p>
<p id="p-0121" num="0121">In addition, in a case where Et is used, before an image is encoded, a feature quantity representing the complexity of the image can be obtained.</p>
<p id="p-0122" num="0122">Furthermore, instead of the above-described Et, that is, the total sum of prediction errors, values reflecting the sizes of the prediction errors for the image, such as, for example, the average of orthogonal transformation coefficients, may be used.</p>
<p id="p-0123" num="0123">As described above, in accordance with the feature of an image, deblocking processing can be performed properly. As a result, the subjective image quality of the image can be improved.</p>
<p id="p-0124" num="0124">Note that, although in the above description, an example in which any one of Complexity, Activity, DCtotal, and Et is individually used so that the values of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, and slice_beta_offset_div2 can be adjusted has been described, the complexity of the image may be determined by using a plurality of values so that the values of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, and slice_beta_offset_div2 can be adjusted on the basis of the result.</p>
<p id="p-0125" num="0125">In addition, although in the above description, an example in which encoding is performed by the H.264/AVC method has been described, the present invention is also applicable to a case where encoding is performed by an encoding method using an in-loop deblocking filter, such as, for example, an MPEG-4 (Moving Picture Coding Experts Group phase 4) or VC-1 (Video Codec 1) method.</p>
<p id="p-0126" num="0126">The above-described series of processing can be performed by hardware or software. In a case where the series of processing is performed by software, a program constituting the software is installed from a program recording medium into a computer built in dedicated hardware or, for example, a general-purpose personal computer capable of performing various functions on the basis of various programs installed thereon.</p>
<p id="p-0127" num="0127"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram showing an example of the configuration of a personal computer <b>300</b> that performs the above-described series of processing by a program. A CPU (Central Processing Unit) <b>301</b> performs various types of processing in accordance with a program stored in a ROM (Read Only Memory) <b>302</b> or a recording unit <b>308</b>. A program to be performed by the CPU <b>301</b>, data, and the like are stored in a RAM (Random Access Memory) <b>303</b>, where appropriate. The CPU <b>301</b>, the ROM <b>302</b>, and the RAM <b>303</b> are connected to each other via a bus <b>304</b>.</p>
<p id="p-0128" num="0128">An input/output interface <b>305</b> is connected to the CPU <b>301</b> through the bus <b>304</b>. An input unit <b>306</b> constituted by a keyboard, a mouse, a microphone, and the like and an output unit <b>307</b> constituted by a display, a speaker, and the like are connected to the input/output interface <b>305</b>. The CPU <b>301</b> performs various types of processing in accordance with instructions input by the input unit <b>306</b>. The CPU <b>301</b> outputs a processing result to the output unit <b>307</b>.</p>
<p id="p-0129" num="0129">The recording unit <b>308</b> connected to the input/output interface <b>305</b> is constituted by, for example, a hard disk. The recording unit <b>308</b> stores a program to be performed by the CPU <b>301</b> and various data. A communication unit <b>309</b> communicates with an external apparatus via a network, such as the Internet or a local area network.</p>
<p id="p-0130" num="0130">In addition, a program may be obtained through the communication unit <b>309</b> and stored in the recording unit <b>308</b>.</p>
<p id="p-0131" num="0131">When a removable medium <b>311</b>, such as a magnetic disk, an optical disk, a magneto-optical disk, or a semiconductor memory, is installed in a drive <b>310</b> connected to the input/output interface <b>305</b>, the drive <b>310</b> drives the removable medium <b>311</b> and obtains a program and data recorded in the removable medium <b>311</b>. The obtained program and data are transferred to and stored in the recording unit <b>308</b> when necessary.</p>
<p id="p-0132" num="0132">A program recording medium that is installed on a computer and that stores a program executable by the computer is constituted by the removable medium <b>311</b>, which is a package medium, such as a magnetic disk (including a flexible disk), an optical disk (including a CD-ROM (Compact Disc-Read Only Memory) or a DVD (Digital Versatile Disc)), a magneto-optical disk, or a semiconductor memory, the ROM <b>302</b> in which a program is temporarily or permanently stored, or the hard disk forming the recording unit <b>308</b>, as shown in <figref idref="DRAWINGS">FIG. 7</figref>. A program is stored into the program recording medium by using a wired or wireless communication medium, such as a local area network, the Internet, or digital satellite broadcasting, via the communication unit <b>309</b>, which is an interface, such as a router or a modem, when necessary.</p>
<p id="p-0133" num="0133">Note that in this specification, steps describing a program stored in the program recording medium include not only processing performed in time series in accordance with the written order but also processing performed in parallel or independently, the processing being not necessarily performed in time series.</p>
<p id="p-0134" num="0134">Furthermore, an embodiment of the present invention is not limited to the above-described embodiments, and various changes can be made without departing from the gist of the present invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08625924-20140107-M00001.NB">
<img id="EMI-M00001" he="14.14mm" wi="76.20mm" file="US08625924-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08625924-20140107-M00002.NB">
<img id="EMI-M00002" he="10.24mm" wi="76.20mm" file="US08625924-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08625924-20140107-M00003.NB">
<img id="EMI-M00003" he="31.07mm" wi="76.20mm" file="US08625924-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US08625924-20140107-M00004.NB">
<img id="EMI-M00004" he="14.14mm" wi="76.20mm" file="US08625924-20140107-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US08625924-20140107-M00005.NB">
<img id="EMI-M00005" he="10.24mm" wi="76.20mm" file="US08625924-20140107-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00006 MATH-US-00006-2" nb-file="US08625924-20140107-M00006.NB">
<img id="EMI-M00006" he="25.40mm" wi="76.20mm" file="US08625924-20140107-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00007" nb-file="US08625924-20140107-M00007.NB">
<img id="EMI-M00007" he="20.15mm" wi="76.20mm" file="US08625924-20140107-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing apparatus comprising:
<claim-text>a deblocking filter that performs deblocking processing on a decoded image obtained by decoding a second image that is used for motion estimation of a first image in a case where the first image is encoded and that is encoded prior to the first image; and</claim-text>
<claim-text>a feature quantity calculation unit configured to calculate a feature quantity representing the complexity of the second image, the feature quantity being obtained based on a generated code amount of the second image and an average of quantizer scales applied to the second image,</claim-text>
<claim-text>wherein the deblocking filter controls whether or not the deblocking processing is to be applied to the decoded image or controls the degree to which the deblocking processing is to be applied to the decoded image, on the basis of the feature quantity.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the feature quantity calculation unit is configured to calculate a coding difficulty of the second image as the feature quantity.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,
<claim-text>wherein in a case where the second image is an image encoded by using inter-frame prediction, the feature quantity calculation unit is configured to set, as the feature quantity, a value obtained by normalizing the coding difficulty of the second image by using a coding difficulty of a third image encoded by using intra-frame prediction prior to the encoding of the second image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the feature quantity calculation unit is configured to divide the second image that has not been encoded into a plurality of blocks, and to calculate the feature quantity on the basis of dispersion of pixel values for each of the blocks.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the feature quantity calculation unit is configured to divide the second image that has not been encoded into a plurality of blocks, and to calculate the feature quantity on the basis of a transformation coefficient obtained by performing orthogonal transformation for each of the blocks.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the feature quantity calculation unit is configured to calculate the feature quantity on the basis of a prediction error, which is a difference between a predicted image for the second image predicted by inter-frame prediction and the second image that has not been encoded.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein an image is encoded by an H.264/AVC (Advanced Video Coding) method, and</claim-text>
<claim-text>wherein the deblocking filter controls whether or not the deblocking processing is to be applied to the decoded image or controls the degree to which the deblocking processing is to be applied to the decoded image, by adjusting a value of disable_deblocking_filter_idc, slice_alpha_c0_offset_div2, or slice_beta_offset_div2.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein an image is encoded by an MPEG-4 (Moving Picture Coding Experts Group phase 4), H.264/AVC (Advanced Video Coding), or VC-1 (Video Codec 1) method.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. An image processing method comprising the steps of:
<claim-text>calculating a feature quantity representing the complexity of a second image that is used for motion estimation of a first image in a case where the first image is encoded and that is encoded prior to the first image, the feature quantity being obtained based on a generated code amount of the second image and an average of quantizer scales applied to the second image; and</claim-text>
<claim-text>controlling whether or not deblocking processing is to be applied to a decoded image obtained by decoding the second image or controlling the degree to which the deblocking processing is to be applied to the decoded image, on the basis of the feature quantity.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A non-transitory computer-readable recording medium storing a commuter program that when executed on a computer performs image processing, the program comprising the steps of:
<claim-text>calculating a feature quantity representing the complexity of a second image that is used for motion estimation of a first image in a case where the first image is encoded and that is encoded prior to the first image, the feature quantity being obtained based on a generated code amount of the second image and an average of quantizer scales applied to the second image; and</claim-text>
<claim-text>controlling whether or not deblocking processing is to be applied to a decoded image obtained by decoding the second image or controlling the degree to which the deblocking processing is to be applied to the decoded image, on the basis of the feature quantity.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
