<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627320-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627320</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12771931</doc-number>
<date>20100430</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>323</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>46</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>R</subclass>
<main-group>31</main-group>
<subgroup>08</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>718102</main-classification>
<further-classification>718104</further-classification>
<further-classification>370230</further-classification>
</classification-national>
<invention-title id="d2e55">Systems and methods for scheduling applications</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5519689</doc-number>
<kind>A</kind>
<name>Kim</name>
<date>19960500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370232</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5680323</doc-number>
<kind>A</kind>
<name>Barnard</name>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715720</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5745767</doc-number>
<kind>A</kind>
<name>Rosen et al.</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717124</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6031841</doc-number>
<kind>A</kind>
<name>Woundy</name>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6223222</doc-number>
<kind>B1</kind>
<name>Fijolek et al.</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6275843</doc-number>
<kind>B1</kind>
<name>Chorn</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6412000</doc-number>
<kind>B1</kind>
<name>Riddle et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6457051</doc-number>
<kind>B1</kind>
<name>Riddle et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6519636</doc-number>
<kind>B2</kind>
<name>Engel et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6590885</doc-number>
<kind>B1</kind>
<name>Jorgensen</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6591299</doc-number>
<kind>B2</kind>
<name>Riddle et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6636485</doc-number>
<kind>B1</kind>
<name>Fijolek et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6640248</doc-number>
<kind>B1</kind>
<name>Jorgensen</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6647419</doc-number>
<kind>B1</kind>
<name>Mogul</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6687222</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6917614</doc-number>
<kind>B1</kind>
<name>Laubach et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>7185094</doc-number>
<kind>B2</kind>
<name>Marquette et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>7216348</doc-number>
<kind>B1</kind>
<name>DeCarmo</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>7281043</doc-number>
<kind>B1</kind>
<name>Davie</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>7444407</doc-number>
<kind>B2</kind>
<name>Thomas</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2002/0075875</doc-number>
<kind>A1</kind>
<name>Dravida et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2002/0143939</doc-number>
<kind>A1</kind>
<name>Riddle et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2003/0005144</doc-number>
<kind>A1</kind>
<name>Engel et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2003/0103527</doc-number>
<kind>A1</kind>
<name>Beser</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2003/0142690</doc-number>
<kind>A1</kind>
<name>Beser</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2004/0243999</doc-number>
<kind>A1</kind>
<name>Taivalsaari</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718  1</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Co-pending U.S. Appl. No. 10/283,216, filed Oct. 30, 2002 entitled &#x201c;Systems and Methods for Scheduling Applications&#x201d; by Nurettin Burcak Beser, 72 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Cisco 7920 Wireless IP Phone Design and Deployment Guide, Chapter 6&#x2014;&#x201c;Quality of Service&#x201d; (Oct. 2005).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>Sunkad, Ph.D., &#x201c;Quality-of-Service: A DOCSIS/PacketCable&#x2122; Perspective&#x2014;Part I,&#x201d; cablelabs.com/about<sub>&#x2014;</sub>cl/SPECS/MayJune2000/news.pgs/sotry5.html, Jul. 17, 2002 print date, pp. 1-7.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>&#x201c;PacketCable&#x2122; Dynamic Quality-of-Service Specification,&#x201d; PKT-SP-DQOS-I103-020116, Copyright 1999-2000 Cable Television Laboratories, Inc., Jan. 16, 2002, 233 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>21</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>16</number-of-drawing-sheets>
<number-of-figures>16</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10283216</doc-number>
<date>20021030</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7748002</doc-number>
<date>20100629</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12771931</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60334727</doc-number>
<date>20011031</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100235512</doc-number>
<kind>A1</kind>
<date>20100916</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Beser</last-name>
<first-name>Nurettin Burcak</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Beser</last-name>
<first-name>Nurettin Burcak</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Harrity &#x26; Harrity, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Juniper Networks, Inc.</orgname>
<role>02</role>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Truong</last-name>
<first-name>Camquy</first-name>
<department>2196</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system allocates resources in a network. The system receives an allocation request for a first flow and a second flow from an application and identifies the application based on the allocation request. The system schedules resources for the first flow based on the identification of the application and the second flow.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="149.10mm" wi="185.50mm" file="US08627320-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="239.86mm" wi="133.77mm" orientation="landscape" file="US08627320-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="207.60mm" wi="157.31mm" orientation="landscape" file="US08627320-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="208.79mm" wi="171.03mm" orientation="landscape" file="US08627320-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="187.11mm" wi="154.94mm" orientation="landscape" file="US08627320-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="218.86mm" wi="163.15mm" orientation="landscape" file="US08627320-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="200.66mm" wi="112.61mm" orientation="landscape" file="US08627320-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="243.33mm" wi="171.70mm" orientation="landscape" file="US08627320-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="246.30mm" wi="169.16mm" orientation="landscape" file="US08627320-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="240.71mm" wi="180.26mm" orientation="landscape" file="US08627320-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="231.82mm" wi="176.28mm" orientation="landscape" file="US08627320-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="230.21mm" wi="176.36mm" orientation="landscape" file="US08627320-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="234.36mm" wi="184.57mm" orientation="landscape" file="US08627320-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="233.60mm" wi="196.09mm" orientation="landscape" file="US08627320-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="189.23mm" wi="163.15mm" orientation="landscape" file="US08627320-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="155.87mm" wi="158.50mm" orientation="landscape" file="US08627320-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="200.91mm" wi="154.94mm" orientation="landscape" file="US08627320-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 10/283,216, filed Oct. 30, 2002, now U.S. Pat. No. 7,748,002, issued Jun. 29, 2010, which claims priority under 35 U.S.C. &#xa7;119 based on U.S. Provisional Application No. 60/334,727, filed Oct. 31, 2001, the disclosures of which are incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to communications systems and, more particularly, to systems and methods for scheduling resources in a cable modem network.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Recently, there has been an explosive demand for services, such as data, voice, and video, to be delivered over broadband communications systems. Cable modem technology is one method of providing such broadband services to subscribers. Cable modem technology competes with technologies such as Asymmetric Digital Subscriber Lines (ADSL) and Integrated Services Digital Network (ISDN). Many in the industry forecast that cable modem systems will become the prevailing technology for providing broadband services since cable television is already widely in use.</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a simplified diagram of a conventional cable modem system. The DOCSIS (Data Over Cable Service Interface Specifications) Radio Frequency Interface Standard specifies the transfer of Internet Protocol (IP) traffic, between the cable headend system and customer locations, over an all-coaxial or a hybrid-fiber/coax (HFC) cable network <b>52</b>. The transmission path includes a Cable Modem Termination System (CMTS) <b>50</b> at the headend, and a Cable Modem (CM) <b>56</b> at each customer location. The DOCSIS standard defines a single transmitter (i.e., CMTS <b>50</b>) for each downstream channel and many receivers (i.e., CMs <b>56</b>). All CMs <b>56</b> listen to all frames transmitted on the downstream channel upon which they are registered and accept those where the destinations match CM <b>56</b> itself or CPEs (Customer Premises Equipment) <b>58</b> connected to CM <b>56</b>. CMs <b>56</b> communicate with other CMs <b>56</b> through the CMTS <b>50</b>.</p>
<p id="p-0006" num="0005">The upstream channel is characterized by many transmitters (i.e., CMs <b>56</b>) and one receiver (i.e., CMTS <b>50</b>). Time in the upstream channel is slotted, providing for time division multiple access (TDMA) at regulated time intervals. CMTS <b>50</b> provides the time reference and controls the allowed usage for each interval. Intervals may be granted for transmission by particular CMs <b>56</b>, or for contention by all CMs <b>56</b>. CMs <b>56</b> may contend to request transmission time. To a limited extent, CMs <b>56</b> may also contend to transmit actual data. In both cases, collisions can occur and retry techniques may be used.</p>
<p id="p-0007" num="0006">The upstream Physical Media Dependent (PMD) sublayer uses a Frequency Division Multiple Access (FDMA)/TDMA burst modulation format that provides five symbol rates and two modulation formats (Quadrature Phase Shift Keying (QPSK) and 16-QAM (Quadrature Amplitude Modulation)). The PMD sublayer format includes a variable-length modulated burst with precise timing beginning at boundaries spaced at integer multiples of 6.25 microseconds apart (which is 16 symbols at the highest data rate). Each burst supports a flexible modulation, symbol rate, preamble, randomization of the payload, and programmable FEC (Forward Error Correction) encoding. All of the upstream transmission parameters associated with burst transmission outputs from CM <b>56</b> are configurable by CMTS <b>50</b> via Media Access Controller (MAC) messaging.</p>
<p id="p-0008" num="0007">The concept of service flows is central to the operation of DOCSIS upstream transmissions. Service flows provide a mechanism for upstream Quality of Service (QoS) management. In particular, service flows play a part in bandwidth allocation. A service flow identifier (ID) defines a particular unidirectional mapping between a CM <b>56</b> and CMTS <b>50</b>. Active upstream service flow IDs also have associated Service IDs or SIDs. CMTS <b>50</b> allocates upstream bandwidth to SIDs, and hence to CMs <b>56</b>. SIDs provide the mechanism by which upstream QoS is implemented.</p>
<p id="p-0009" num="0008">In a basic cable modem implementation, two service flows (one upstream, one downstream) could be used, for example, to offer best-effort IP service. However, the service flow concept allows for more complex cable modems to be developed that support multiple service classes while supporting interoperability with more basic modems. With these more complex cable modems, it is possible that certain service flows may be configured in such a way that they cannot carry all types of traffic. That is, service flows may have a maximum packet size limitation or be restricted to small, fixed size, unsolicited grants. Furthermore, it might not be appropriate to send other kinds of data on service flows that are being used for Constant Bit Rate (CBR)-type applications.</p>
<p id="p-0010" num="0009">Even in these complex modems, it may be desirable to be able to send certain upstream packets needed for MAC management, SNMP management, key management, etc. For the network to function properly, all cable modems should support at least one upstream and one downstream service flow. All service flow IDs are unique within the upstream. The mapping of a unicast SID to an active/admitted service flow is unique within a single upstream. The length of the service flow ID is 32 bits. The length of the SID is 14 bits.</p>
<p id="p-0011" num="0010">As shown in <figref idref="DRAWINGS">FIG. 2</figref>, the upstream transmission time-line is divided into intervals by the upstream bandwidth allocation mechanism. Each interval is an integral number of mini-slots. A &#x201c;mini-slot&#x201d; is the unit of granularity for upstream transmission opportunities. There is no implication that any packet data unit (PDU) can actually be transmitted in a single mini-slot. Each interval may be labeled with a usage code that defines both the type of traffic that can be transmitted during that interval and the physical-layer modulation encoding. A mini-slot is a power-of-two multiple of 6.25 microseconds increments (i.e., 2, 4, 8, 16, 32, 64, or 128 times 6.25 microseconds). Since the upstream channel is modeled as a stream of mini-slots, CMTS <b>50</b> generates the time reference for identifying these slots. CMTS <b>50</b> also controls access to these slots by CMs <b>56</b>. For example, CMTS <b>50</b> may grant some number of contiguous slots to a CM <b>56</b> for it to transmit a data PDU. CM <b>56</b> times its transmission such that that CMTS <b>50</b> receives it in the time slot specified. A bandwidth allocation MAP is used for assigning bandwidth.</p>
<p id="p-0012" num="0011">The bandwidth allocation MAP is a MAC Management message transmitted by CMTS <b>50</b> on the downstream channel that describes, for some interval of time, the uses to which the upstream frequency will be used by a given CM <b>56</b>. A given MAP may describe some time slots as grants for particular CMs <b>56</b> to transmit data, other time slots as available for contention transmission, and other slots as an opportunity for new CMs <b>56</b> to join the link. <figref idref="DRAWINGS">FIG. 3</figref> illustrates a MAC Header and MAC Management Message Header Fields.</p>
<p id="p-0013" num="0012">The upstream bandwidth allocation MAP may include a fixed-length header followed by a variable number of information elements (IEs) as shown in <figref idref="DRAWINGS">FIG. 4</figref>. The upstream bandwidth allocation MAP message header may contain the following information:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0013">Upstream Channel ID: The identifier of the upstream channel to which this message refers.</li>
        <li id="ul0002-0002" num="0014">UCD Count: Matches the value of the Configuration Change Count of the Upstream Channel Descriptor (UCD) that describes the burst parameters that apply to this map.</li>
        <li id="ul0002-0003" num="0015">Number of Elements: Number of IEs in the map.</li>
        <li id="ul0002-0004" num="0016">Alloc Start Time: Effective start time from CMTS initialization (in mini-slots) for assignments within this map.</li>
        <li id="ul0002-0005" num="0017">Ack Time: Latest time, from CMTS initialization, (mini-slots) processed in upstream. This time is used by the CMs for collision detection purposes.</li>
        <li id="ul0002-0006" num="0018">Ranging Backoff Start: Initial back-off window for initial ranging contention, expressed as a power of two. Values range 0-15 (the highest order bits may be unused and set to 0).</li>
        <li id="ul0002-0007" num="0019">Ranging Backoff End: Final back-off window for initial ranging contention, expressed as a power of two. Values range 0-15 (the highest order bits may be unused and set to 0).</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0014" num="0020">The number of transmit opportunities associated with a particular IE in a MAP is dependent on the total size of the region as well as the allowable size of an individual transmission. As an example, assume a request (REQ) IE defines a region of 12 mini-slots. If the UCD defines a REQ Burst Size that fits into a single mini-slot, then there are 12 transmit opportunities associated with this REQ IE (i.e., one for each mini-slot). If the UCD defines a REQ that fits in two mini-slots, then there are six transmit opportunities and a REQ can start on every other mini-slot. Table 1 illustrates interval usage codes and their corresponding IE names.</p>
<p id="p-0015" num="0021">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>The Interval Usage Codes</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="105pt" align="center"/>
<colspec colname="2" colwidth="112pt" align="left"/>
<tbody valign="top">
<row>
<entry>Interval Usage Code</entry>
<entry>Information Element Name</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
<row>
<entry>1</entry>
<entry>Request</entry>
</row>
<row>
<entry>2</entry>
<entry>REQ/Data</entry>
</row>
<row>
<entry>3</entry>
<entry>Initial Maintenance</entry>
</row>
<row>
<entry>4</entry>
<entry>Station Maintenance</entry>
</row>
<row>
<entry>5</entry>
<entry>Short Data Grant</entry>
</row>
<row>
<entry>6</entry>
<entry>Long Data Grant</entry>
</row>
<row>
<entry>7</entry>
<entry>Null IE</entry>
</row>
<row>
<entry>8</entry>
<entry>Data Acknowledge</entry>
</row>
<row>
<entry>9-14</entry>
<entry>Reserved</entry>
</row>
<row>
<entry>15&#x2002;</entry>
<entry>Expanded IUC</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0016" num="0022">As another example, assume a REQ/Data IE defines a 24 mini-slot region. If the REQ/Data IE is sent with a SID of 0x3FF4, then CM <b>56</b> can potentially start a transmit session on every fourth mini-slot. This IE contains a total of six transmit opportunities (TX OP). Similarly, a SID of 0x3FF6 implies four TX OPs; 0x3FF8 implies three TX OPs; and 0x3FFC implies two TX OPs.</p>
<p id="p-0017" num="0023">For an Initial Maintenance IE, CM <b>56</b> starts its transmission in the first mini-slot of the region; therefore, CM <b>56</b> has a single transmit opportunity. The remainder of the region may be used to compensate for the round trip delays since CM <b>56</b> has not yet been ranged. Station Maintenance IEs, Short/Long Data Grant IEs, and unicast Request IEs are unicast and thus are not typically associated with contention transmit opportunities. They represent a single dedicated, or reservation based, transmit opportunity.</p>
<p id="p-0018" num="0024">Each IE consists of a 14-bit SID, a 4-bit type code, and a 14-bit starting offset. <figref idref="DRAWINGS">FIG. 5</figref> illustrates the structure of a MAP IE. Since all CMs <b>56</b> will scan all IEs, it is critical that IEs be short and relatively fixed format. IEs within the MAP are strictly ordered by starting offset. For most purposes, the duration described by the IE is inferred by the difference between the IE's starting offset and that of the following IE. For this reason, a Null IE terminates the list.</p>
<p id="p-0019" num="0025">Types of Information Elements (IEs)</p>
<p id="h-0004" num="0000">DOCSIS defines four types of SIDs:</p>
<p id="p-0020" num="0026">1. 0x3FFF&#x2014;broadcast, intended for all CMs.</p>
<p id="p-0021" num="0027">2. 0x2000-0x3FFE&#x2014;multicast, purpose is defined administratively.</p>
<p id="p-0022" num="0028">3. 0x0001-0x1FFF&#x2014;unicast, intended for a particular CM or a particular service within that CM.</p>
<p id="p-0023" num="0029">4. 0x0000&#x2014;null address, addressed to no CM.</p>
<p id="h-0005" num="0000">All of the IEs defined are supported by CMs <b>56</b>. CMTS <b>50</b> uses any of these IEs when creating Bandwidth Allocation MAPs.</p>
<p id="h-0006" num="0000">The Request (REQ) IE</p>
<p id="p-0024" num="0030">The Request IE provides an upstream interval in which requests can be made for bandwidth for upstream data transmission. The character of this IE changes depending on the class of SID. If broadcast, this is an invitation for all CMs <b>56</b> to contend for requests. If unicast, this is an invitation for a particular CM <b>56</b> to request bandwidth.</p>
<p id="p-0025" num="0031">A small number of Priority Request SIDs is defined in DOCSIS. These allow contention for Request IEs to be limited to service flows of a given traffic priority. The Request/Data IE provides an upstream interval in which requests for bandwidth or short data packets may be transmitted. This IE is distinguished from the Request IE in that it provides a means by which allocation algorithms may provide for &#x201c;immediate&#x201d; data contention under light loads, and a means by which this opportunity can be withdrawn as network loading increases.</p>
<p id="p-0026" num="0032">Multicast SIDs are used to specify maximum data length, as well as allowed random starting points within the interval. For example, a particular multicast SID may specify a maximum of 64-byte data packets, with transmit opportunities every fourth slot.</p>
<p id="h-0007" num="0000">Short and Long Data Grant IEs</p>
<p id="p-0027" num="0033">The Short and Long Data Grant IEs provide an opportunity for CM <b>56</b> to transmit one or more upstream PDUs. These IEs are issued either in response to a request from CM <b>56</b>, or because of an administrative policy providing some amount of bandwidth to a particular CM <b>56</b> (see class-of-service discussion below). These IEs can also be used with an inferred length of zero mini slots (a zero length grant), to indicate that a request has been received and is pending (a Data Grant pending).</p>
<p id="p-0028" num="0034">Short Data Grants are used with intervals less than or equal to the maximum burst size for this usage specified in the Upstream Channel Descriptor (UCD). If Short Data burst profiles are defined in the UCD, then all Long Data Grants are for a larger number of mini-slots than the maximum for Short Data. The distinction between Long and Short Data Grants may be exploited in physical-layer forward-error-correction coding; otherwise, it is not meaningful to the bandwidth allocation process.</p>
<p id="p-0029" num="0035">If this IE is a Data Grant Pending (a zero length grant), it will follow the NULL IE. This allows CMs <b>56</b> to process all actual allocations first, before scanning the MAP for data grants pending and data acknowledgments.</p>
<p id="h-0008" num="0000">Data Acknowledge IE</p>
<p id="p-0030" num="0036">The Data Acknowledge IE acknowledges that a data PDU was received. CM <b>56</b> may request this acknowledgment within the data PDU (normally this would be done for PDUs transmitted within a contention interval in order to detect collisions). This IE will follow the NULL IE. This allows CMs <b>56</b> to process all actual interval allocations first, before scanning the MAP for data grants pending and data acknowledgments.</p>
<p id="p-0031" num="0037">Requests</p>
<p id="p-0032" num="0038">Requests refer to the mechanism that CMs <b>56</b> use to indicate to CMTS <b>50</b> that it needs upstream bandwidth allocation. A transmission request may come as a stand-alone Request Frame transmission or it may come as a piggyback request in the EHDR of another Frame transmission.</p>
<p id="p-0033" num="0039">The Request Frame may be transmitted during any of the following intervals:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0040">Request IE,</li>
        <li id="ul0004-0002" num="0041">Request/Data IE,</li>
        <li id="ul0004-0003" num="0042">Short Data Grant IE, and</li>
        <li id="ul0004-0004" num="0043">Long Data Grant IE.
<br/>
A piggyback request may be contained in the following Extended Headers (EHs):
</li>
        <li id="ul0004-0005" num="0044">Request EH element,</li>
        <li id="ul0004-0006" num="0045">Upstream Privacy EH element, and</li>
        <li id="ul0004-0007" num="0046">Upstream Privacy EH element with Fragmentation.
<br/>
The request includes:
</li>
        <li id="ul0004-0008" num="0047">The SID making the request, and</li>
        <li id="ul0004-0009" num="0048">The number of mini-slots requested.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0034" num="0049">The number of mini-slots requested may be the total number that is desired by CM <b>56</b> at the time of the request (including any physical layer overhead), subject to UCD <b>2</b> and administrative limits. CM <b>56</b> may request a number of mini-slots corresponding to one complete frame, except in the case of fragmentation in Piggyback Mode.</p>
<p id="p-0035" num="0050">CM <b>56</b> may have one request outstanding at a time per SID. If CMTS <b>50</b> does not immediately respond with a Data Grant, CM <b>56</b> may unambiguously determine that its request is still pending because CMTS <b>50</b> will continue to issue a Data Grant Pending in every MAP for as long as a request is unsatisfied. In MAPs, CMTS <b>50</b> cannot make a data grant greater than 255 mini-slots to any assigned SID. This puts an upper bound on the grant size CM <b>56</b> has to support.</p>
<p id="p-0036" num="0051">The allocation MAP transmitted in time to propagate across the physical cable may be received and handled by receiving CMs <b>56</b>. As such, it may be transmitted considerably earlier than its effective time. The components of the delay are:
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0000">
    <ul id="ul0006" list-style="none">
        <li id="ul0006-0001" num="0052">Worst-case round-trip propagation delay&#x2014;may be network-specific, but on the order of hundreds of microseconds;</li>
        <li id="ul0006-0002" num="0053">Queuing delays within the CMTS&#x2014;implementation-specific;</li>
        <li id="ul0006-0003" num="0054">Processing delays within the CMs will allow a minimum processing time by each CM; and</li>
        <li id="ul0006-0004" num="0055">PMD-layer FEC interleaving.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0037" num="0056">Within these constraints, vendors may wish to minimize this delay so as to minimize latency of access to the upstream channel. The number of mini-slots described vary from MAP to MAP. At a minimum, a MAP describes a single mini-slot. This would be wasteful in both downstream bandwidth and in processing time within CMs <b>56</b>. At maximum, a MAP may stretch to tens of milliseconds. Such a MAP would provide poor upstream latency, however.</p>
<p id="p-0038" num="0057">Allocation algorithms vary the size of the MAPs over time to provide a balance of network utilization and latency under varying traffic loads. A MAP would contain at least two IEs: one to describe an interval and a null IE to terminate the list. At the most, a MAP is bounded by a limit of 240 IEs. MAPs are also bounded in that they will not describe more than 4096 mini-slots into the future. The latter limit is intended to bound the number of future mini-slots that each CM <b>56</b> is required to track. CM <b>56</b> is able to support multiple outstanding MAPs. Even though multiple MAPs may be outstanding, the sum of the number of mini-slots they describe may not exceed 4096. The set of all MAPs, taken together, describes every mini-slot in the upstream channel. If CM <b>56</b> fails to receive a MAP describing a particular interval, it will not transmit during that interval.</p>
<p id="p-0039" num="0058"><figref idref="DRAWINGS">FIG. 6</figref> illustrates a protocol exchange between CM <b>56</b> and CMTS <b>50</b>. This example illustrates the interchange between CM <b>56</b> and CMTS <b>50</b> when CM <b>56</b> has data to transmit. If CM <b>56</b> has a data PDU available for transmission, then the following steps occur:</p>
<p id="p-0040" num="0059">1. At time t<sub>1</sub>, CMTS <b>50</b> transmits a MAP having an effective starting time of t<sub>3</sub>. Within this MAP is a Request IE that starts at t<sub>5</sub>. The difference between t<sub>1 </sub>and t<sub>3 </sub>is needed to allow for:
<ul id="ul0007" list-style="none">
    <li id="ul0007-0001" num="0000">
    <ul id="ul0008" list-style="none">
        <li id="ul0008-0001" num="0060">Downstream propagation delay (including FEC interleaving) to allow all CMs <b>56</b> to receive the MAP;</li>
        <li id="ul0008-0002" num="0061">Processing time at the CM <b>56</b> (allows CMs <b>56</b> to parse the MAP and translate it into transmission opportunities); and</li>
        <li id="ul0008-0003" num="0062">Upstream propagation delay (to allow the CM's transmission of the first upstream data to begin in time to arrive at CMTS <b>50</b> at time t<sub>3</sub>).</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0041" num="0063">2. At t<sub>2</sub>, CM <b>56</b> receives this MAP and scans it for request opportunities. In order to minimize request collisions, CM <b>56</b> calculates t<sub>6 </sub>as a random offset based on the Data Backoff Start value in the most recent MAP.</p>
<p id="p-0042" num="0064">3. At t<sub>4</sub>, CM <b>56</b> transmits a request for as many mini-slots as needed to accommodate the PDU. Time t<sub>4 </sub>is chosen based on the ranging offset so that the request will arrive at CMTS <b>50</b> at t<sub>6</sub>.</p>
<p id="p-0043" num="0065">4. At t<sub>6</sub>, CMTS <b>50</b> receives the request and schedules it for service in the next MAP. (The choice of which requests to grant will vary with the class of service requested, any competing requests, and the algorithm used by CMTS <b>50</b>.)</p>
<p id="p-0044" num="0066">5. At t<sub>7</sub>, CMTS <b>50</b> transmits a MAP having an effective starting time of t<sub>9</sub>. Within this MAP, a data grant for CM <b>56</b> will start at t<sub>11</sub>.</p>
<p id="p-0045" num="0067">6. At t<sub>8</sub>, CM <b>56</b> receives the MAP and scans for its data grant.</p>
<p id="p-0046" num="0068">7. At t<sub>10</sub>, CM <b>56</b> transmits its data PDU so that it will arrive at CMTS <b>50</b> at t<sub>11</sub>. Time t<sub>10 </sub>is calculated from the ranging offset as in step 3 above.</p>
<p id="p-0047" num="0069">Steps 1 and 2 need not contribute to access latency if CMs <b>56</b> routinely maintain a list of request opportunities. At step 3, the request may collide with requests from other CMs <b>56</b> and be lost. CMTS <b>50</b> may not directly detect the collision. CM <b>56</b> determines that a collision (or other reception failure) occurred when the next MAP fails to include acknowledgment of the request. CM <b>56</b> may then perform a back-off algorithm and retry.</p>
<p id="p-0048" num="0070">At step 4, CMTS <b>50</b> scheduler may fail to accommodate the request within the next MAP. If so, CMTS <b>50</b> scheduler may reply with a zero-length grant in that MAP or discard the request by giving no grant at all. CMTS <b>50</b> scheduler may continue to report this zero-length grant in all succeeding MAPs until the request can be granted or is discarded. This will signal to CM <b>56</b> that the request is still pending. So long as CM <b>56</b> is receiving a zero-length grant, CM <b>56</b> will not issue new requests for that service queue.</p>
<p id="p-0049" num="0071">Since many different scheduling algorithms can be implemented in CMTS <b>50</b>, the DOCSIS specification does not mandate a particular scheduling algorithm. Instead, DOCSIS describes the protocol elements by which bandwidth is requested and granted. CMs <b>56</b> may issue requests to CMTS <b>50</b> for upstream bandwidth. CMTS <b>50</b> transmit allocation MAP PDUs on the downstream channel define the allowed usage of each mini-slot.</p>
<p id="p-0050" num="0072">Contention Resolution</p>
<p id="p-0051" num="0073">The DOCSIS specification mandates the method of contention resolution as the truncated binary exponential back-off, with the initial back-off window and the maximum back-off window controlled by CMTS <b>50</b>. The values are specified as part of the Bandwidth Allocation MAP MAC message and represent a power-of-two value. For example, a value of 4 indicates a window between 0 and 15 while a value of 10 indicates a window between 0 and 1023.</p>
<p id="p-0052" num="0074">When CM <b>56</b> has information to send and wants to enter the contention resolution process, CM <b>56</b> sets its internal back-off window equal to the Data Backoff Start defined in the MAP currently in effect. CM <b>56</b> may randomly select a number within its back-off window. This random value indicates the number of contention transmit opportunities which CM <b>56</b> will defer before transmitting. CM <b>56</b> may consider contention transmit opportunities for which this transmission would have been eligible. These are defined by either Request IEs or Request/Data IEs in the MAP. It will be appreciated that each IE can represent multiple transmission opportunities.</p>
<p id="p-0053" num="0075">As an example, consider a CM <b>56</b> whose initial back-off window is 0 to 15. Assume that CM <b>56</b> randomly selects the number 11. CM <b>56</b> defers a total of 11 contention transmission opportunities. If the first available Request IE is for 6 requests, CM <b>56</b> does not use this and has 5 more opportunities to defer. If the next Request IE is for 2 requests, CM <b>56</b> has 3 more to defer. If the third Request IE is for 8 requests, CM <b>56</b> transmits on the fourth request, after deferring for 3 more opportunities.</p>
<p id="p-0054" num="0076">After a contention transmission, CM <b>56</b> waits for a Data Grant (Data Grant Pending) or Data Acknowledge in a subsequent MAP. Once either is received, the contention resolution is complete. CM <b>56</b> determines that the contention transmission was lost when it finds a MAP without a Data Grant (Data Grant Pending) or Data Acknowledge for it and with an acknowledge time more recent than the time of transmission. CM <b>56</b> may increase its back-off window by a factor of two, as long as the new value is less than the maximum back-off window. CM <b>56</b> may randomly select a number within its new back-off window and repeat the deferring process described above.</p>
<p id="p-0055" num="0077">This re-try process continues until the maximum number of retries (e.g., 16) has been reached, at which time the PDU will be discarded. The maximum number of retries is independent of the initial and maximum back-off windows that are defined by CMTS <b>50</b>. If CM <b>56</b> receives a unicast Request or Data Grant at any time while deferring for this SID, CM <b>56</b> may stop the contention resolution process and use the explicit transmit opportunity.</p>
<p id="p-0056" num="0078">CMTS <b>50</b> has much flexibility in controlling the contention resolution. At one extreme, CMTS <b>50</b> may choose to set up the Data Backoff Start and End to emulate an Ethernet-style back-off with its associated simplicity and distributed nature, but also its fairness and efficiency issues. This would be done by setting Data Backoff Start=0 and End=10 in the MAP. At the other end, CMTS <b>50</b> may make the Data Backoff Start and End identical and frequently update these values in the MAP so all CMs <b>56</b> are using the same, and hopefully optimal, back-off window.</p>
<p id="p-0057" num="0079">CM Bandwidth Utilization</p>
<p id="p-0058" num="0080">The following rules govern the response CM <b>56</b> makes when processing MAPs. These standard behaviors can be overridden by the CM's Request/Transmission Policy.</p>
<p id="p-0059" num="0081">1. CM <b>56</b> may first use any Grants assigned to it. Next, CM <b>56</b> may use any unicast REQ for it. Finally, CM <b>56</b> may use the next available broadcast/multicast REQ or REQ/Data IEs for which it is eligible.</p>
<p id="p-0060" num="0082">2. CM <b>56</b> may not have more than one Request outstanding at a time for a particular SID.</p>
<p id="p-0061" num="0083">3. If CM <b>56</b> has a Request pending, it will not use intervening contention intervals for that SID.</p>
<p id="p-0062" num="0084">DOCSIS CMTS Scheduling</p>
<p id="p-0063" num="0085">DOCSIS scheduling services are designed to improve the efficiency of the poll/grant process. By specifying a scheduling service and its associated QoS parameters, the DOCSIS CMTS <b>50</b> can anticipate the throughput and latency needs of the upstream traffic and provide polls and/or grants at the appropriate times.</p>
<p id="p-0064" num="0086">Each service is tailored to a specific type of data flow as described below. The basic services include:
<ul id="ul0009" list-style="none">
    <li id="ul0009-0001" num="0000">
    <ul id="ul0010" list-style="none">
        <li id="ul0010-0001" num="0087">Unsolicited Grant Service (UGS),</li>
        <li id="ul0010-0002" num="0088">Real-Time Polling Service (rtPS),</li>
        <li id="ul0010-0003" num="0089">Unsolicited Grant Service with Activity Detection (UGS-AD),</li>
        <li id="ul0010-0004" num="0090">Non-Real-Time Polling Service (nrtPS), and</li>
        <li id="ul0010-0005" num="0091">Best Effort (BE) service.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0065" num="0092"><figref idref="DRAWINGS">FIG. 7</figref> illustrates the relationship between the scheduling services and the related QoS parameters. Each is described in more detail below.</p>
<p id="h-0009" num="0000">Unsolicited Grant Service</p>
<p id="p-0066" num="0093">The Unsolicited Grant Service (UGS) is designed to support real-time service flows that generate fixed size data packets on a periodic basis, such as Voice over IP (VoIP). The UGS service offers fixed size grants on a real-time periodic basis, which eliminates the overhead and latency of CM <b>56</b> requests and assure that grants will be available to meet the flow's real-time needs.</p>
<p id="p-0067" num="0094">CMTS <b>50</b> provides fixed size data grants at periodic intervals to the service flow. In order for this service to work correctly, the Request/Transmission Policy setting should be such that CM <b>56</b> is prohibited from using any contention request or request/data opportunities and CMTS <b>50</b> does not provide any unicast request opportunities. The Request/Transmission Policy also prohibits piggyback requests. This will result in CM <b>56</b> only using unsolicited data grants for upstream transmissions. The key service parameters are the Unsolicited Grant Size, the Nominal Grant interval, the Tolerated Grant Jitter and the Request/Transmission Policy.</p>
<p id="h-0010" num="0000">ATM Constant Bit Rate (CBR) Services</p>
<p id="p-0068" num="0095">The CBR service class is intended for real-time applications (i.e., those requiring tightly constrained delay and delay variation), as would be appropriate for voice and video applications. The consistent availability of a fixed quantity of bandwidth is considered appropriate for CBR service. Cells that are delayed beyond the value specified by Cell Transfer Delay (CTD) are assumed to be significantly less value to the application.</p>
<p id="p-0069" num="0096">For CBR, the following ATM attributes are specified:
<ul id="ul0011" list-style="none">
    <li id="ul0011-0001" num="0000">
    <ul id="ul0012" list-style="none">
        <li id="ul0012-0001" num="0097">PCR/CDVT(peak cell rate/cell delay variation tolerance),</li>
        <li id="ul0012-0002" num="0098">Cell Loss Rate (CLR),</li>
        <li id="ul0012-0003" num="0099">CTD/CDV, and</li>
        <li id="ul0012-0004" num="0100">CLR may be unspecified for CLP equal to 1.
<br/>
Real-Time Polling Service
</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0070" num="0101">The Real-Time Polling Service (rtPS) is designed to support real-time service flows that generate variable size data packets on a periodic basis, such as MPEG video. rtPS offers real-time, periodic, unicast request opportunities, that meet the flow's real-time needs and allow CM <b>56</b> to specify the size of the desired grant. rtPS requires more request overhead than UGS, but supports variable grant sizes for optimum data transport efficiency.</p>
<p id="p-0071" num="0102">CMTS <b>50</b> may provide periodic unicast request opportunities. In order for this service to work correctly, the Request/Transmission Policy setting should be such that CM <b>56</b> is prohibited from using any contention request or request/data opportunities. The Request/Transmission Policy should also prohibit piggyback requests. CMTS <b>50</b> may issue unicast request opportunities as prescribed by this service even if a grant is pending. This will result in CM <b>56</b> using only unicast request opportunities in order to obtain upstream transmission opportunities (CM <b>56</b> could still use unsolicited data grants for upstream transmissions as well). All other bits of the Request/Transmission Policy are not relevant to the fundamental operation of this scheduling service and should be set according to network policy. The key service parameters are the Nominal Polling Interval, the Tolerated Poll Jitter and the Request/Transmission Policy.</p>
<p id="h-0011" num="0000">ATM Real Time VBR</p>
<p id="p-0072" num="0103">The real time VBR service class is intended for real-time applications (i.e., those requiring tightly constrained delay and delay variation), as would be appropriate for voice and video applications. Sources are expected to transmit at a rate that varies with time. As a result, the source can be described as &#x201c;bursty.&#x201d; Cells that are delayed beyond the value specified by CTD are assumed to be of significantly less value to the application. Real-time VBR service may support statistical multiplexing of real-time sources, or may provide a consistently guaranteed QoS.</p>
<p id="p-0073" num="0104">For real time VBR, the following ATM attributes are specified:
<ul id="ul0013" list-style="none">
    <li id="ul0013-0001" num="0000">
    <ul id="ul0014" list-style="none">
        <li id="ul0014-0001" num="0105">PCR/CDVT,</li>
        <li id="ul0014-0002" num="0106">CLR,</li>
        <li id="ul0014-0003" num="0107">CTD/CDV, and</li>
        <li id="ul0014-0004" num="0108">SCR and BT (sustainable cell rate and burst tolerance).
<br/>
Unsolicited Grant Service with Activity Detection
</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0074" num="0109">The Unsolicited Grant Service with Activity Detection (UGS/AD) is designed to support UGS flows that may become inactive for substantial portions of time (e.g., tens of milliseconds or more), such as VoIP with silence suppression. The service provides Unsolicited Grants when the flow is active and unicast polls when the flow is inactive. This combines the low overhead and low latency of UGS with the efficiency of rtPS. Though USG/AD combines UGS and rtPS, only one scheduling service is active at a time.</p>
<p id="p-0075" num="0110">CMTS <b>50</b> may provide periodic unicast grants, when the flow is active, but may revert to providing periodic unicast request opportunities when the flow is inactive. CMTS <b>50</b> can detect flow inactivity by detecting unused grants. However, the algorithm for detecting a flow changing from an active to an inactive state is dependent on CMTS <b>50</b> implementation. In order for this service to work correctly, the Request/Transmission Policy setting should be such that CM <b>56</b> is prohibited from using any contention request or request/data opportunities. The Request/Transmission Policy should also prohibit piggyback requests. This results in CM <b>56</b> using only unicast request opportunities in order to obtain upstream transmission opportunities. However, CM <b>56</b> may use unsolicited data grants for upstream transmissions as well.</p>
<p id="p-0076" num="0111">All other bits of the Request/Transmission Policy are not relevant to the fundamental operation of this scheduling service and should be set according to network policy. The key service parameters are the Nominal Polling Interval, the Tolerated Poll Jitter, the Nominal Grant Interval, the Tolerated Grant Jitter, the Unsolicited Grant Size, and the Request/Transmission Policy.</p>
<p id="p-0077" num="0112">In UGS-AD service, when restarting UGS after an interval of rtPS, CMTS <b>50</b> may provide additional grants in the first (and/or second) grant interval such that CM <b>56</b> receives a total of one grant for each grant interval from the time CM <b>56</b> requested restart of UGS, plus one additional grant. Because the service flow is provisioned as a UGS flow with a specific grant interval and grant size, when restarting UGS, CM <b>56</b> may not request a different sized grant than the already provisioned UGS flow. As with any service flow, changes may be requested with a DSC command. If the restarted activity requires more than one grant per interval, CM <b>56</b> may indicate this in the Active Grants field of the UGSH beginning with the first packet sent.</p>
<p id="p-0078" num="0113">The Service Flow Extended Header Element allows CM <b>56</b> to dynamically state how many grants per interval are required to support the number of flows with activity present. In UGS/AD, CM <b>56</b> may use the Queue Indicator Bit in the UGSH. The remaining seven bits of the UGSH define the Active Grants field. This field defines the number of grants within a Nominal Grant Interval that this service flow currently requires.</p>
<p id="p-0079" num="0114">When using UGS/AD, CM <b>56</b> may indicate the number of requested grants per Nominal Grant Interval in this field. The Active Grants field of the UGSH may be ignored with UGS without Activity Detection. This field allows CM <b>56</b> to signal to CMTS <b>50</b> to dynamically adjust the number of grants per interval that this UGS Service Flow is actually using. CM <b>56</b> may not request more than the number of Grants per Interval in the ActiveQoSParameterSet.</p>
<p id="p-0080" num="0115">If CMTS <b>50</b> allocates additional bandwidth in response to the QI bit, CMTS <b>50</b> will use the same rate limiting formula as UGS, but the formula only applies to steady state periods where CMTS <b>50</b> has adjusted the grants per interval to match the active grants requested by CM <b>56</b>.</p>
<p id="p-0081" num="0116">When CM <b>56</b> receives unsolicited grants and detects no activity on the service flow, CM <b>56</b> may send one packet with the Active Grants field set to zero grants and then cease transmission. Because this packet may not be received by CMTS <b>50</b>, when the service flow goes from inactive to active, CM <b>56</b> may be able to restart transmission with either polled requests or unsolicited grants.</p>
<p id="h-0012" num="0000">Non-Real-Time Polling Service</p>
<p id="p-0082" num="0117">The Non-Real-Time Polling Service (nrtPS) is designed to support non real-time service flows that require variable size data grants on a regular basis, such as high bandwidth FTP. nrtPS offers unicast polls on a regular basis, which assures that the flow receives request opportunities even during network congestion. CMTS <b>50</b> typically polls nrtPS SIDs on periodic or non-periodic intervals on the order of one second or less.</p>
<p id="p-0083" num="0118">CMTS <b>50</b> provides timely unicast request opportunities. In order for this service to work correctly, the Request/Transmission Policy setting should be such that CM <b>56</b> is allowed to use contention request opportunities. This results in CM <b>56</b> using contention request opportunities, as well as unicast request opportunities and unsolicited data grants. All other bits of the Request/Transmission Policy are not relevant to the fundamental operation of this scheduling service and should be set according to network policy. The key service parameters are Nominal Polling Interval, Minimum Reserved Traffic Rate, Maximum Sustained Traffic Rate, Request/Transmission Policy, and Traffic Priority.</p>
<p id="h-0013" num="0000">ATM Non-Real Time VBR</p>
<p id="p-0084" num="0119">The non-real time VBR service class is intended for non-real time applications that have &#x201c;bursty&#x201d; traffic characteristics and can be characterized in terms of a GCRA. For those cells that are transferred, it expects a bound on the cell transfer delay. Non-real time VBR service supports statistical multiplexing of connections.</p>
<p id="p-0085" num="0120">For non-real time VBR, the following ATM attributes are specified:
<ul id="ul0015" list-style="none">
    <li id="ul0015-0001" num="0000">
    <ul id="ul0016" list-style="none">
        <li id="ul0016-0001" num="0121">PCR/CDVT,</li>
        <li id="ul0016-0002" num="0122">CLR,</li>
        <li id="ul0016-0003" num="0123">CTD, and</li>
        <li id="ul0016-0004" num="0124">SCR and BT.
<br/>
Best Effort Service
</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0086" num="0125">The intent of the Best Effort (BE) service is to provide efficient service to best effort traffic. In order for this service to work correctly, the Request/Transmission Policy setting should be such that CM <b>56</b> is allowed to use contention request opportunities. This results in CM <b>56</b> using contention request opportunities, as well as unicast request opportunities and unsolicited data grants. All other bits of the Request/Transmission Policy are not relevant to the fundamental operation of this scheduling service and should be set according to network policy. The key service parameters are the Minimum Reserved Traffic Rate, the Maximum Sustained Traffic Rate, and the Traffic Priority.</p>
<p id="h-0014" num="0000">ATM UBR (Unspecified Bit Rate)</p>
<p id="p-0087" num="0126">The UBR service class is intended for delay-tolerant or non-real-time applications (i.e., those that do not require tightly constrained delay and delay variation), such as traditional computer communications applications. Sources are expected to transmit non-continuous bursts of cells. UBR service supports a high degree of statistical multiplexing among sources. UBR service includes no notion of a per-VC allocated bandwidth resource. Transport of cells in UBR service is not necessarily guaranteed by mechanisms operating at the cell level. However, it is expected that resources will be provisioned for UBR service in such a way as to make it usable for some set of applications. UBR service may be considered as interpretation of the common term &#x201c;best effort service.&#x201d;</p>
<p id="p-0088" num="0127">For UBR, the following ATM attribute is specified:</p>
<p id="p-0089" num="0128">PCR/CDVT.</p>
<p id="h-0015" num="0000">ATM ABR (Available Bit Rate)</p>
<p id="p-0090" num="0129">Many applications have the ability to reduce their information transfer rate if the network requires them to do so. Likewise, they may wish to increase their information transfer rate if there is extra bandwidth available within the network. There may not be deterministic parameters because the users are willing to live with unreserved bandwidth. To support traffic from such sources in an ATM network may require facilities different from those for Peak Cell Rate of Sustainable Cell Rate traffic. The ABR service is designed to fill this need.</p>
<p id="p-0091" num="0130">Relevant Encodings for the Upstream Scheduling</p>
<p id="h-0016" num="0000">Service Flow Scheduling Type</p>
<p id="p-0092" num="0131">The value of this parameter specifies which upstream scheduling service is used for upstream transmission requests and packet transmissions. If this parameter is omitted, then the Best Effort service is generally assumed. This parameter is applicable at CMTS <b>50</b>. If defined, this parameter is enforced by CMTS <b>50</b>.</p>
<p id="p-0093" num="0132">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="21pt" align="center"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="168pt" align="left"/>
<thead>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
<row>
<entry>Type</entry>
<entry>Length</entry>
<entry>Value</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>24.15</entry>
<entry>1</entry>
<entry>0 Reserved</entry>
</row>
<row>
<entry/>
<entry/>
<entry>1 for Undefined (CMTS implementation-dependent 1)</entry>
</row>
<row>
<entry/>
<entry/>
<entry>2 for Best Effort</entry>
</row>
<row>
<entry/>
<entry/>
<entry>3 for Non-Real-Time Polling Service</entry>
</row>
<row>
<entry/>
<entry/>
<entry>4 for Real-Time Polling Service</entry>
</row>
<row>
<entry/>
<entry/>
<entry>5 for Unsolicited Grant Service with Activity Detection</entry>
</row>
<row>
<entry/>
<entry/>
<entry>6 for Unsolicited Grant Service</entry>
</row>
<row>
<entry/>
<entry/>
<entry>7 through 255 are reserved for future use</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
<br/>
Request/Transmission Policy
</p>
<p id="p-0094" num="0133">The value of this parameter specifies 1) which IUC opportunities CM <b>56</b> uses for upstream transmission requests and packet transmissions for this service flow, 2) whether requests for this service flow may be piggybacked with data, and 3) whether data packets transmitted on this service flow can be concatenated, fragmented, or have their payload headers suppressed. For UGS, it also specifies how to treat packets that do not fit into the UGS grant. The data grants may include both short and long data grants.</p>
<p id="p-0095" num="0134">Bit #<b>0</b>&#x2014;The service flow will not use &#x201c;all CMs&#x201d; broadcast request opportunities.</p>
<p id="p-0096" num="0135">Bit #<b>1</b>&#x2014;The service flow will not use Priority Request multicast request opportunities.</p>
<p id="p-0097" num="0136">Bit #<b>2</b>&#x2014;The service flow will not use Request/Data opportunities for Requests.</p>
<p id="p-0098" num="0137">Bit #<b>3</b>&#x2014;The service flow will not use Request/Data opportunities for Data.</p>
<p id="p-0099" num="0138">Bit #<b>4</b>&#x2014;The service flow will not piggyback requests with data.</p>
<p id="p-0100" num="0139">Bit #<b>5</b>&#x2014;The service flow will not concatenate data.</p>
<p id="p-0101" num="0140">Bit #<b>6</b>&#x2014;The service flow will not fragment data.</p>
<p id="p-0102" num="0141">Bit #<b>7</b>&#x2014;The service flow will not suppress payload headers.</p>
<p id="p-0103" num="0142">Bit #<b>8</b>&#x2014;The service flow will drop packets that do not fit in the Unsolicited Grant Size.</p>
<p id="h-0017" num="0000">Priority Request Service IDs</p>
<p id="p-0104" num="0143">These SIDs (0x3Exx) are reserved for Request IEs:</p>
<p id="p-0105" num="0144">If 0x01 bit is set, priority zero can request.</p>
<p id="p-0106" num="0145">If 0x02 bit is set, priority one can request.</p>
<p id="p-0107" num="0146">If 0x04 bit is set, priority two can request.</p>
<p id="p-0108" num="0147">If 0x08 bit is set, priority three can request.</p>
<p id="p-0109" num="0148">If 0x10 bit is set, priority four can request.</p>
<p id="p-0110" num="0149">If 0x20 bit is set, priority five can request.</p>
<p id="p-0111" num="0150">If 0x40 bit is set, priority six can request.</p>
<p id="p-0112" num="0151">If 0x80 bit is set, priority seven can request.</p>
<p id="h-0018" num="0000">Bits can be combined as desired by the CMTS upstream scheduler for any Request IUCs.</p>
<p id="h-0019" num="0000">Traffic Priority</p>
<p id="p-0113" num="0152">The value of this parameter specifies the priority assigned to a service flow. Given two service flows identical in all QoS parameters besides priority, the higher priority service flow should be given lower delay and higher buffering preference. For otherwise non-identical service flows, the priority parameter will not take precedence over any conflicting service flow QoS parameter. The specific algorithm for enforcing this parameter is not mandated here.</p>
<p id="p-0114" num="0153">For upstream service flows, CMTS <b>50</b> should use this parameter when determining precedence in request service and grant generation, and CM <b>56</b> may preferentially select contention Request opportunities for Priority Request SIDs based on this priority and its Request/Transmission Policy.</p>
<p id="p-0115" num="0154">To illustrate the problem current CMTS scheduling under DOCSIS presents, an example application known commonly in the industry as &#x201c;PacketCable&#x201d; is described below. PacketCable is a project conducted by Cable Television Laboratories, Inc. and its member companies. The PacketCable project is aimed at defining interface specifications that can be used to develop interoperable equipment capable of providing packet-based voice, video, and other high-speed multimedia services over hybrid-fiber/coax (HFC) cable systems utilizing the DOCSIS protocol. PacketCable utilizes a network superstructure that overlays the two-way data-ready broadband cable access network. While the initial PacketCable offering will be packet-based voice communications for existing and new cable subscribers, the long-term project vision encompasses a large suite of packet-based capabilities.</p>
<p id="p-0116" num="0155">The application of NCS PacketCable call setup will be used throughout when discussing the various embodiments of the invention. The example uses the PacketCable NCS call protocol along with the DQoS setup procedure. The PacketCable NCS protocol requires a large number of messages passed between the eMTA (embedded multimedia terminal adapter: a device that includes both the VoIP functionality and the CM functionality). The messages passed in their protocol flow are shown in <figref idref="DRAWINGS">FIGS. 8-10</figref>.</p>
<p id="p-0117" num="0156">There are three alternatives to the PacketCable NCS call setup using strict DOCSIS mechanisms. The first one is the simplest one and puts the call signaling messaging in the request/contention area. The second one uses the polled requests for the NCS call signaling. The last one uses priority requests. Each of these is described in turn.</p>
<p id="h-0020" num="0000">Using Broadcast Request Opportunities</p>
<p id="p-0118" num="0157">In the method that uses broadcast request opportunities, the NCS call signaling uses the best effort scheduling type. Two problems may exist in the areas of transmission: the first one is the delay in transmitting packets from the eMTA, and the second one relates to the sharing of bandwidth between requests/contentions and data transmissions.</p>
<p id="p-0119" num="0158">The first issue is that assuming there is no contention on CM <b>56</b> requests, a delay occurs in transmitting the packet. <figref idref="DRAWINGS">FIGS. 11-13</figref> show the messages that are exchanged between the eMTA and the CMTS for transmission of the call signaling packets when using broadcast request opportunities. Referring to <figref idref="DRAWINGS">FIGS. 11-13</figref>, it can be shown that there are 4 packets that have to be sent upstream before the phone rings on the originator and 3 packets that have to be sent out on the far-end. This is assuming that the dial map is designed in such a way that the first time the eMTA contacts the CMTS is the time that all the digits are completed.</p>
<p id="p-0120" num="0159">To further analyze, certain designs of a CMTS issue MAP messages every 4 milliseconds. Thus using that metric, on average, packets wait in the queue of the CMTS for 2 milliseconds to make the request. Further, it takes 1 millisecond for the message to propagate to the CMTS. Also, assume that the request can be granted in the first MAP message and on average the packet would be scheduled from the arrival of MAP within 2 milliseconds. It takes 2 milliseconds for the MAP packet to be received from the CMTS to the CM.</p>
<p id="p-0121" num="0160">The result is shown in Table 2 below:</p>
<p id="p-0122" num="0161">
<tables id="TABLE-US-00003" num="00003">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="140pt" align="left"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="49pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="3" rowsep="1">TABLE 2</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
<row>
<entry>Explanation</entry>
<entry>Delay</entry>
<entry>Total Delay</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>The request is send in the contention area</entry>
<entry>2 ms</entry>
<entry>2 ms</entry>
</row>
<row>
<entry>Interleaving delay</entry>
<entry>3 ms</entry>
<entry>5 ms</entry>
</row>
<row>
<entry>Upstream Propagation delay</entry>
<entry>1 ms</entry>
<entry>6 ms</entry>
</row>
<row>
<entry>The CMTS processes the request and schedules</entry>
<entry>1 ms</entry>
<entry>7 ms</entry>
</row>
<row>
<entry>Downstream propagation delay</entry>
<entry>1 ms</entry>
<entry>8 ms</entry>
</row>
<row>
<entry>The data area is used</entry>
<entry>2 ms</entry>
<entry>10 ms&#x2002;</entry>
</row>
<row>
<entry>Interleaving delay</entry>
<entry>3 ms</entry>
<entry>13 ms&#x2002;</entry>
</row>
<row>
<entry>The data is received by the CMTS</entry>
<entry>1 ms</entry>
<entry>14 ms&#x2002;</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0123" num="0162">It should be noted that these numbers assume that the CMTS processing is in such a way that the data grant is issued with the next MAP message. A more realistic number is 15 millisecond average delay between the call signaling packet interception at the CM to the packet arriving at the CMTS for further processing.</p>
<p id="p-0124" num="0163">The contribution of cable transmission delay to post dial delay may be calculated for the originating side as:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>4 upstream messages*15 ms per message delay=60 ms delay.<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
For the far-end the result is:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>3 upstream messages*15 ms per message delay=45 ms delay.<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Therefore, the cable segment transmission consumes 10% of the end-to-end delay budget of less than one second of post dial delay.
</p>
<p id="p-0125" num="0164">For the second issue, it has been shown that the sharing of request/contention areas with data transmissions introduces a very big delay to the system that may not be acceptable during congestion intervals. It is possible that such is not applicable to a modern scheduler that schedules the number of contention/requests to the traffic usage pattern. But, the issue still remains since the use of request/contention area cannot be prioritized between SIDs that are on different CMs, meaning that it is not possible for the CMTS to give call signaling packets preferential treatment. Since the cable transmission delay cannot be guaranteed, this would be reason enough for the request/contention area not to be used. The second alternative is the use of the non-real time polling.</p>
<p id="h-0021" num="0000">Using Polled Request Opportunities</p>
<p id="p-0126" num="0165">The polled request opportunity method assumes that all of the NCS call signaling packets are sent through the service flows that are using the non-real-time polled scheduling type as defined by DOCSIS. In the non-real time polling, the CM can use the request/contention grants but the CMTS is responsible for providing timely unicast request opportunities. The problem with this kind of scheduling is that since the CMTS cannot guess which CMs are in contention in a contention/request opportunity, when a contention is detected, the CM should revert to the Unicast Polling Opportunities, which makes use of the request/contention opportunities difficult during high traffic.</p>
<p id="p-0127" num="0166">Due to the reasons whether the non-real-time polling or the real-time polling is to be used in such kind of a situation, the service flow should not use broadcast request opportunities. For the real-time polling, the CMTS may generate a request opportunity for each service flow individually. The CMTS may, for example, give a unicast request opportunity to each one of the 1000 CMs. Assume that a unicast request takes 12 bytes, which, for the best case of transmission, takes 12.5 microseconds of upstream time. For all CMs, this yields an upstream time of 12.5 microseconds*1000 (i.e., 12.5 milliseconds).</p>
<p id="p-0128" num="0167">Assuming the presence of maintenance and other overhead information, the minimum interval for the CM polling may not exceed 7 millisecond intervals. It is important to note that in such a case, the whole upstream bandwidth is being used for polling and the upstream bandwidth cannot be used for other data transmission. It is important to consider, however, that the main idea is to be able to use the upstream for the transport of VoIP and other data transmissions as well.</p>
<p id="h-0022" num="0000">Using Priority Request Opportunities</p>
<p id="p-0129" num="0168">The last method is to use the priority request SIDs for the NCS call signaling packets. In this method, all of the NCS call signaling packets use the service flows that have the request transmission policy set to indicate that CM will not use the broadcast request opportunities and the CM will use the priority request multicast opportunities.</p>
<p id="p-0130" num="0169">Even though the DOCSIS specification defines these fields as strict ordering for lower delay and higher buffering, it is possible to use the priority for grouping the service flows for NCS call signaling. If it is assumed that all the remaining flows with best effort scheduling type are using the priority zero and the NCS call signaling is using priority 5, then the CMTS schedules with every MAP cycle a priority 5 request opportunity (using SID x3E20).</p>
<p id="p-0131" num="0170">In such a case, the NCS data packets using the priority 0 will be using the broadcast request opportunities and the priority 5 request opportunity will be used by the NCS call signaling. The benefit of such a scheme is that there is no waste of bandwidth due to individual poll and at the same time the NCS call signaling packets will not be contending with the NCS data packets.</p>
<p id="p-0132" num="0171">The only issue with such a method is that the CM will use the truncated binary exponential backoff algorithm to pick the opportunity it will utilize, and there is only one global data backoff start setting and one data backoff end setting. If a CM uses the same values that are being used for the broadcast data opportunities or any of the other contention request opportunities, then this would cause an unnecessary bandwidth waste. One solution may be to use the segmented backoff setting bandwidth allocation MAP messages generation in the CMTS scheduler.</p>
<p id="p-0133" num="0172">The problem with using Priority Requests is as follows. Assume that the priority 5 is being used for the NCS call signaling and the data backoff setting of a start value of 0 and an end value of 3 is sufficient for the expected contention probability. It can be further assumed that the broadcast request opportunities use the start value of 2 and an end value of 7. Table 3 below contains the number of mini-slots in one 4 millisecond interval for various symbol rates/modulations.</p>
<p id="p-0134" num="0173">
<tables id="TABLE-US-00004" num="00004">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="168pt" align="center"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" rowsep="1">TABLE 3</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>mini-slot size (ticks)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="8">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="21pt" align="center"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="21pt" align="center"/>
<colspec colname="4" colwidth="28pt" align="center"/>
<colspec colname="5" colwidth="21pt" align="center"/>
<colspec colname="6" colwidth="28pt" align="center"/>
<colspec colname="7" colwidth="21pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>2</entry>
<entry>4</entry>
<entry>8</entry>
<entry>16</entry>
<entry>32</entry>
<entry>64</entry>
<entry>128</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="168pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>mini-slot size (us)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="8">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="21pt" align="center"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="21pt" align="center"/>
<colspec colname="4" colwidth="28pt" align="center"/>
<colspec colname="5" colwidth="21pt" align="center"/>
<colspec colname="6" colwidth="28pt" align="center"/>
<colspec colname="7" colwidth="21pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>12.5</entry>
<entry>25</entry>
<entry>50</entry>
<entry>100</entry>
<entry>200</entry>
<entry>400</entry>
<entry>800</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="49pt" align="center"/>
<colspec colname="2" colwidth="168pt" align="center"/>
<tbody valign="top">
<row>
<entry>symbol rate</entry>
<entry>number of mini-slots in 4 ms interval</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="8">
<colspec colname="1" colwidth="49pt" align="char" char="."/>
<colspec colname="2" colwidth="21pt" align="center"/>
<colspec colname="3" colwidth="28pt" align="center"/>
<colspec colname="4" colwidth="21pt" align="center"/>
<colspec colname="5" colwidth="28pt" align="center"/>
<colspec colname="6" colwidth="21pt" align="center"/>
<colspec colname="7" colwidth="28pt" align="center"/>
<colspec colname="8" colwidth="21pt" align="center"/>
<tbody valign="top">
<row>
<entry>160000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>320000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>640000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>1280000</entry>
<entry>N/A</entry>
<entry>160</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>25600000</entry>
<entry>320</entry>
<entry>160</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>160000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>320000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>640000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>1280000</entry>
<entry>N/A</entry>
<entry>160</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry>25600000</entry>
<entry>320</entry>
<entry>160</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
</row>
<row>
<entry namest="1" nameend="8" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0135" num="0174">Assuming that a request takes 2 mini-slots, the number of request opportunities on a 4 millisecond interval is shown in Table 4.</p>
<p id="p-0136" num="0175">
<tables id="TABLE-US-00005" num="00005">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="168pt" align="center"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" rowsep="1">TABLE 4</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>mini-slot size (ticks)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="8">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="21pt" align="center"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="21pt" align="center"/>
<colspec colname="4" colwidth="28pt" align="center"/>
<colspec colname="5" colwidth="21pt" align="center"/>
<colspec colname="6" colwidth="28pt" align="center"/>
<colspec colname="7" colwidth="21pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>2</entry>
<entry>4</entry>
<entry>8</entry>
<entry>16</entry>
<entry>32</entry>
<entry>64</entry>
<entry>128</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="168pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>mini-slot size (us)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="8">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="21pt" align="center"/>
<colspec colname="2" colwidth="28pt" align="center"/>
<colspec colname="3" colwidth="21pt" align="center"/>
<colspec colname="4" colwidth="28pt" align="center"/>
<colspec colname="5" colwidth="21pt" align="center"/>
<colspec colname="6" colwidth="28pt" align="center"/>
<colspec colname="7" colwidth="21pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>12.5</entry>
<entry>25</entry>
<entry>50</entry>
<entry>100</entry>
<entry>200</entry>
<entry>400</entry>
<entry>800</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="49pt" align="center"/>
<colspec colname="2" colwidth="168pt" align="center"/>
<tbody valign="top">
<row>
<entry>symbol rate</entry>
<entry>number of requests in 4 ms interval</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="8">
<colspec colname="1" colwidth="49pt" align="char" char="."/>
<colspec colname="2" colwidth="21pt" align="center"/>
<colspec colname="3" colwidth="28pt" align="center"/>
<colspec colname="4" colwidth="21pt" align="center"/>
<colspec colname="5" colwidth="28pt" align="center"/>
<colspec colname="6" colwidth="21pt" align="center"/>
<colspec colname="7" colwidth="28pt" align="center"/>
<colspec colname="8" colwidth="21pt" align="center"/>
<tbody valign="top">
<row>
<entry>16000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>32000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>64000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>128000</entry>
<entry>N/A</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>2560000</entry>
<entry>160</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>16000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>32000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>64000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>128000</entry>
<entry>N/A</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry>2560000</entry>
<entry>160</entry>
<entry>80</entry>
<entry>40</entry>
<entry>20</entry>
<entry>10</entry>
<entry>5</entry>
<entry>2.5</entry>
</row>
<row>
<entry namest="1" nameend="8" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0137" num="0176">Assuming that all the priority request types are being used, then 8 requests per MAP are possible. The difference between using the broadcast request data backoff settings and a specific value for the priority request is: 8 priority values*3 unnecessary requests per MAP interval=24 unnecessary requests.</p>
<p id="p-0138" num="0177">Due to the fact that the main reason for the use of priority requests is the timely transport of packets, it is assumed that at least the initial data backoff setting of priority request opportunities has to be given in each interval. If there are at least 4 requests per MAP interval, the wasted interval can be calculated as shown in Table 5.</p>
<p id="p-0139" num="0178">
<tables id="TABLE-US-00006" num="00006">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="56pt" align="left"/>
<colspec colname="1" colwidth="161pt" align="center"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" rowsep="1">TABLE 5</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>mini-slot size (ticks)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="4">
<colspec colname="offset" colwidth="56pt" align="left"/>
<colspec colname="1" colwidth="63pt" align="center"/>
<colspec colname="2" colwidth="35pt" align="center"/>
<colspec colname="3" colwidth="63pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>2</entry>
<entry>4</entry>
<entry>8</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="56pt" align="left"/>
<colspec colname="1" colwidth="161pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>mini-slot size (us)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="4">
<colspec colname="offset" colwidth="56pt" align="left"/>
<colspec colname="1" colwidth="63pt" align="center"/>
<colspec colname="2" colwidth="35pt" align="center"/>
<colspec colname="3" colwidth="63pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>12.5</entry>
<entry>25</entry>
<entry>50</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="14pt" align="left"/>
<colspec colname="1" colwidth="42pt" align="center"/>
<colspec colname="2" colwidth="161pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>Symbol rate</entry>
<entry>number of requests in 4 ms interval</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="offset" colwidth="14pt" align="left"/>
<colspec colname="1" colwidth="42pt" align="center"/>
<colspec colname="2" colwidth="63pt" align="center"/>
<colspec colname="3" colwidth="35pt" align="center"/>
<colspec colname="4" colwidth="63pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>160000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
</row>
<row>
<entry/>
<entry>320000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
</row>
<row>
<entry/>
<entry>640000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>0.666667</entry>
</row>
<row>
<entry/>
<entry>1280000&#x2002;</entry>
<entry>N/A</entry>
<entry>0.315789</entry>
<entry>0.666667</entry>
</row>
<row>
<entry/>
<entry>25600000&#x2003;</entry>
<entry>0.153846</entry>
<entry>0.315789</entry>
<entry>0.666667</entry>
</row>
<row>
<entry/>
<entry>160000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
</row>
<row>
<entry/>
<entry>320000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>N/A</entry>
</row>
<row>
<entry/>
<entry>640000</entry>
<entry>N/A</entry>
<entry>N/A</entry>
<entry>0.666667</entry>
</row>
<row>
<entry/>
<entry>1280000&#x2002;</entry>
<entry>N/A</entry>
<entry>0.315789</entry>
<entry>0.666667</entry>
</row>
<row>
<entry/>
<entry>25600000&#x2003;</entry>
<entry>0.153846</entry>
<entry>0.315789</entry>
<entry>0.666667</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="4" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
<br/>
This implies that a minimum of 15% of the upstream mini-slots will be wasted due to inability of the scheduler to send bandwidth allocation MAP messages with different data backoff settings.
</p>
<p id="p-0140" num="0179">A challenging aspect of DOCSIS CMTS design are problems with scheduling channels and service flows generated therein based upon applications that use the bandwidth provided to them by the CM system. Today, the general analysis of the DOCSIS upstream scheduling is carried out in the domain of scheduling the data transmission opportunities. The request for upstream transmission is assumed to arrive at the CMTS timely, and a uniform delay distribution is generally assumed for request arrival. For instance, the typical CM may have no idea if the application requesting a service flow is an HTTP application or a VoIP. The main challenge for the CMTS is to identify the particular application that is requesting the service flow so that the CMTS can meet the delay, bandwidth and other requirements of service flow quality of service encodings by scheduling the data transmission opportunities.</p>
<p id="p-0141" num="0180">Therefore, there exists a need for systems and methods that identify applications requesting service flows.</p>
<heading id="h-0023" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0142" num="0181">Systems and methods consistent with the present invention address this and other needs by providing techniques for identifying applications in a cable modem communications network.</p>
<p id="p-0143" num="0182">In accordance with the purpose of this invention as embodied and broadly described herein, a method for allocating resources in a network is disclosed. The method includes receiving an allocation request for a first flow and a second flow from an application, identifying the application based on the allocation request, and scheduling resources based on the identifying and the second flow.</p>
<p id="p-0144" num="0183">In another implementation consistent with the present invention, a network device is disclosed. The network device includes logic that receives a request for a first flow and a second flow from an application, logic that characterizes the application based on the request, and logic that schedules resources for the first flow based on the characterization of the application and the second flow.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0024" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0145" num="0184">The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate an embodiment of the invention and, together with the description, explain the invention. In the drawings,</p>
<p id="p-0146" num="0185"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a simplified diagram of a conventional cable modem system;</p>
<p id="p-0147" num="0186"><figref idref="DRAWINGS">FIG. 2</figref> illustrates the upstream transmission time-line being divided into intervals by the upstream bandwidth allocation mechanism;</p>
<p id="p-0148" num="0187"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a MAC Header and MAC Management Message Header fields;</p>
<p id="p-0149" num="0188"><figref idref="DRAWINGS">FIG. 4</figref> illustrates the components of an upstream bandwidth allocation MAP including a variable number of IEs;</p>
<p id="p-0150" num="0189"><figref idref="DRAWINGS">FIG. 5</figref> illustrates the structure of a MAP IE;</p>
<p id="p-0151" num="0190"><figref idref="DRAWINGS">FIG. 6</figref> illustrates a protocol exchange between a CM and a CMTS;</p>
<p id="p-0152" num="0191"><figref idref="DRAWINGS">FIG. 7</figref> illustrates the relationship between the scheduling services and the related QoS parameters;</p>
<p id="p-0153" num="0192"><figref idref="DRAWINGS">FIG. 8</figref> illustrates a first portion of all of the messages passed in a NCS PacketCable call setup protocol flow;</p>
<p id="p-0154" num="0193"><figref idref="DRAWINGS">FIG. 9</figref> illustrates a second portion of all of the messages passed in a NCS PacketCable call setup protocol flow;</p>
<p id="p-0155" num="0194"><figref idref="DRAWINGS">FIG. 10</figref> illustrates a third portion of all of the messages passed in a NCS PacketCable call setup protocol flow;</p>
<p id="p-0156" num="0195"><figref idref="DRAWINGS">FIG. 11</figref> illustrates a first portion of all the messages that are exchanged between the eMTA and the CMTS for transmission of the call signaling packets when using broadcast request opportunities;</p>
<p id="p-0157" num="0196"><figref idref="DRAWINGS">FIG. 12</figref> illustrates a second portion of all the messages that are exchanged between the eMTA and the CMTS for transmission of the call signaling packets when using broadcast request opportunities;</p>
<p id="p-0158" num="0197"><figref idref="DRAWINGS">FIG. 13</figref> illustrates a third portion of all the messages that are exchanged between the eMTA and the CMTS for transmission of the call signaling packets when using broadcast request opportunities;</p>
<p id="p-0159" num="0198"><figref idref="DRAWINGS">FIG. 14</figref> illustrates an exemplary configuration of a CMTS in which systems and methods consistent with the principles of the invention may be implemented;</p>
<p id="p-0160" num="0199"><figref idref="DRAWINGS">FIG. 15</figref> illustrates an exemplary process for scheduling resources in an implementation consistent with the principles of the invention;</p>
<p id="p-0161" num="0200"><figref idref="DRAWINGS">FIG. 16</figref> illustrates the allocation of resources by a context dependent scheduler in an implementation consistent with the principles of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0025" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0162" num="0201">The following detailed description of implementations consistent with the present invention refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements. Also, the following detailed description does not limit the invention. Instead, the scope of the invention is defined by the appended claims and their equivalents.</p>
<p id="p-0163" num="0202">Implementations consistent with the present invention provide techniques for identifying applications requesting service flows in a cable modem communications network. By identifying the applications, the CMTS can determine the QoS parameters to associate with the applications, and thus, the amount of resources to be scheduled for the applications.</p>
<heading id="h-0026" level="1">Exemplary System</heading>
<p id="p-0164" num="0203"><figref idref="DRAWINGS">FIG. 14</figref> illustrates an exemplary CMTS <b>1400</b> in which systems and methods, consistent with the present invention, may be implemented. CMTS <b>1400</b> may include one or more processing units <b>1405</b>, a memory <b>1410</b>, a communication interface <b>1415</b>, a classification unit <b>1420</b>, an upstream/downstream communication interface <b>1425</b>, and a bus <b>1430</b>.</p>
<p id="p-0165" num="0204">Processing unit(s) <b>1405</b> may perform data processing functions for data transmitted/received via communication interface <b>1415</b> to/from a data network, such as a local area network (LAN), a wide area network (WAN), an intranet, the Internet, or the like, and data transmitted/received via upstream/downstream communication interface <b>1425</b> to/from a cable network. Memory <b>1410</b> may include Random Access Memory (RAM) that provides temporary working storage of data and instructions for use by processing unit <b>1405</b> in performing control and processing functions. Memory <b>1410</b> may additionally include Read Only Memory (ROM) that provides permanent or semi-permanent storage of data and instructions for use by processing unit <b>1405</b>. Memory <b>1410</b> can also include large-capacity storage devices, such as a magnetic and/or optical recording medium and its corresponding drive.</p>
<p id="p-0166" num="0205">Communication interface <b>1415</b> may include conventional circuitry well known to one skilled in the art for transmitting data to, or receiving data from, the data network. Classification unit <b>1420</b> may, as will be described in detail below, identify applications requesting service flows to determine the QoS to be applied to the service flows. CMTS <b>1400</b> may assign resources for the service flows based on the identification.</p>
<p id="p-0167" num="0206">Upstream/downstream communication interface <b>1425</b> may include transceiver circuitry well known to one skilled in the art for transmitting data bursts on downstream channels, and receiving data bursts on upstream channels, via the cable network. Such transceiver circuitry may include amplifiers, filters, modulators/demodulators, interleavers, error correction circuitry, and other conventional circuitry used to convert data into radio frequency (RF) signals for transmission via the cable network, or to interpret data bursts received from CMs via the cable network as data symbols.</p>
<p id="p-0168" num="0207">Bus <b>1430</b> interconnects the various components of CMTS <b>1400</b> to permit the components to communicate with one another.</p>
<heading id="h-0027" level="1">Exemplary Processing</heading>
<p id="p-0169" num="0208">When scheduling resources, such as upstream or downstream bandwidth, a CMTS may allocate more resources to those applications (e.g., voice, video, and other high-speed multimedia applications) requiring better performance (e.g., lower delays, less dropped packets, etc.). On the other hand, the CMTS may allocate less resources to less-demanding applications, such as web surfing applications. In either case, the CMTS needs to be able to identify an application so that the appropriate amount of resources can be allocated.</p>
<p id="p-0170" num="0209"><figref idref="DRAWINGS">FIG. 15</figref> illustrates an exemplary process for allocating resources in an implementation consistent with the present invention. Processing may begin with a CMTS, such as CMTS <b>1400</b>, receiving a service flow creation request from an application via a CM [act <b>1510</b>]. The application may, for example, be a higher priority application, such as a VoIP-related application, where packet dropping and delays are less acceptable to an end-user or a lower priority application, such as a web surfing application. CMTS <b>1400</b> may give preference to higher priority applications when assigning system resources.</p>
<p id="p-0171" num="0210">CMTS <b>1400</b> may then classify the application based on the request [act <b>1520</b>]. The classification may be based on a Service Class Name associated with the application or an application name provided by some external process, such as an external QoS authorization process (e.g., PacketCable DQoS Gate Control) and RSVP+ messaging with PacketCable extensions or the Internet standard RSVP protocol with Application and Sub-Application identity policy elements.</p>
<p id="p-0172" num="0211">The CMTS scheduler can use the application information and IP packet flow in other flows other than the scheduling is running against to make decisions. For example, if CMTS <b>1400</b> knows when a packet is sent downstream for the application, it is possible for the context dependent scheduling (CDS) to predict (in general, the application processing does not take time) when the application would generate an upstream packet. If the application is VoIP, for example, considered before it is apparent that the VOIP call has entered the ringing state, the VoIP application response time depends on the processing of the message by the NCS/DQoS stack. For this reason, if CMTS <b>1400</b> has the ability to detect the VoIP call signaling packets, for example, due to the DiffSery markings and destination IP address, the CDS can anticipate that an upstream packet is to be generated by the VoIP application and schedule a request and/or data opportunity in anticipation of the packet to be generated by the application.</p>
<p id="p-0173" num="0212">The choice of the CDS to give a request and/or data opportunity depends on several factors. Some of these factors include the determinism of the upstream packet generation, certainty of the expected packet size, and bandwidth utilization at that instant. If the application would most probably generate a packet having a size of, for example, 430 bytes, then it is possible for the CDS to schedule a 430 byte data opportunity for the next MAP message (assuming that the anticipated time is before the scheduled time). It may then be possible to use unicast polling with a frequency of 100 msec, which will only affect the first packet sent upstream during the messaging bursts. From that point on, however, the latency will be contained to anticipated packet generation time, which for all practical purposes can be considered as 4 msec (assuming 1 msec delay in downstream, 1 msec in the inter-protocol communication, 1 msec for the NCS/DQoS protocol stack, and 1 msec for the inter-protocol communication), making the upstream cable transport delay around 5 msec. If there are 5 messages occurring for the call setup, then the total time is:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>50 (average poll wait)+1(upstream delay)+4*5=71 msec.<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
It is important to note that for a unicast polling system to reach this response time, the polls should occur with the frequency of:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(71 msec&#x2212;5 msec (upstream propagation time)/5(no. upstream messages)*2(normalize the average number)=26.4 msec,<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
which is almost a fourth of what is being used as the polling interval.
</p>
<p id="p-0174" num="0213">Identification Using Service Class Name</p>
<p id="p-0175" num="0214">The DOCSIS definition for QoS includes a Service Class Name field. A Service Class Name is a string, which the CMTS associates with a QoS Parameter Set. The Service Class serves the following purposes that are described in DOCSIS RFI v1.1 specification:</p>
<p id="p-0176" num="0215">1. It allows operators, who so wish, to move the burden of configuring service flows from the provisioning server to the CMTS. Operators provision the CMs with the Service Class Name. The implementation of the name may be configured at the CMTS via a command-line interface (CLI). This allows operators to modify the implementation of a given service without changing CM provisioning. For example, some scheduling parameters may need to be tweaked differently for two different CMTSs to provide the same service. As another example, service profiles could be changed by time of day.</p>
<p id="p-0177" num="0216">2. It allows CMTS vendors to provide class-based-queuing if they choose, where service flows compete within their class and classes compete with each other for bandwidth.</p>
<p id="p-0178" num="0217">3. It allows higher-layer protocols to create a service flow by its Service Class Name. For example, telephony signaling may direct the CM to instantiate any available provisioned service flow of class &#x201c;G711.&#x201d;</p>
<p id="p-0179" num="0218">4. It allows packet classification policies to be defined which refer to a desired service class, without having to refer to a particular service flow instance of that class.</p>
<p id="p-0180" num="0219">5. CMTS implementations may treat such &#x201c;unclassed&#x201d; flows differently from &#x201c;classed&#x201d; flows with equivalent parameters.</p>
<p id="p-0181" num="0220">The Service Class Name may be used in the Registration, Dynamic Service Addition Request (DSA-REQ), and Dynamic Service Change Request (DSC-REQ) messages generated by the CM. In all of these cases, CMTS <b>1400</b> may include a Service Flow Encoding that includes the Service Class Name and the QoS Parameter Set of the Service Class.</p>
<p id="p-0182" num="0221">CMTS <b>1400</b> may identify applications based on the Service Class Names. For example, assume that VoIP applications use the Service Class Name &#x201c;voipcallsignalingupstream&#x201d; for PacketCable upstream call signaling and &#x201c;voipcallsignalingdownstream&#x201d; for PacketCable downstream call signaling. An operator may define these names as being associated with PacketCable Call Signaling in CMTS <b>1400</b> using the CLI. Since the embedded multimedia terminal adapters (eMTAs) uses Service Class Names when requesting a service flow to be created, CMTS <b>1400</b> may readily identify the applications associated with the Service Class Names. For example, if CMTS <b>1400</b> receives a service flow request that includes the Service Class Name &#x201c;voipcallsignalingupstream,&#x201d; CMTS <b>1400</b> may determine that the requesting application is associated with PacketCable Call Signaling.</p>
<p id="p-0183" num="0222">Identification Using External Processes</p>
<p id="p-0184" num="0223">If CMTS <b>1400</b> does not use the CM-originating Service Class Name, CMTS <b>1400</b> may use the PacketCable DQoS Gate Control message and RSVP+ messaging with PacketCable extensions for application identification purposes. The PacketCable DQoS specification, dated Jan. 16, 2002, pages 1-225, the entire contents of which are incorporated by reference herein, defines a gate as a policy control entity implemented at the CMTS to control access to enhanced QoS Services of a DOCSIS 1.1 cable network by a single IP flow. Gates are unidirectional (i.e., gates control access to a flow in either the upstream or downstream direction). In an implementation consistent with the principles of the invention, each gate includes the following fields:
<ul id="ul0017" list-style="none">
    <li id="ul0017-0001" num="0000">
    <ul id="ul0018" list-style="none">
        <li id="ul0018-0001" num="0224">Gate-ID,</li>
        <li id="ul0018-0002" num="0225">Prototype Classifier,</li>
        <li id="ul0018-0003" num="0226">A group of flags,</li>
        <li id="ul0018-0004" num="0227">An authorized envelope (flow spec),</li>
        <li id="ul0018-0005" num="0228">A reserved envelope (flow spec),</li>
        <li id="ul0018-0006" num="0229">Resource-ID, and</li>
        <li id="ul0018-0007" num="0230">Application Name.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0185" num="0231">The Gate-ID field includes a local 32 bit identifier that is allocated from the local space at the CMTS where the gate resides. Typically, a Gate-ID identifies a single upstream flow and a single downstream flow, and corresponds to a single multimedia session. The Prototype Classifier field may consist of direction information (i.e., upstream or downstream), protocol information, source IP information that identifies the source of the flow, destination IP information that identifies the destination of the flow, destination port information that identifies the port at the destination device to which the flow is directed, and source port information that identifies the port on the source device from which the flow originates.</p>
<p id="p-0186" num="0232">The group of flags may include an auto-commit flag and a commit-not-allowed flag. The auto-commit flag, when set, causes CMTS <b>1400</b> to commit resources immediately upon reservation. The commit-not-allowed flag, when set, causes CMTS <b>1400</b> to ignore any COMMIT messages for this particular gate.</p>
<p id="p-0187" num="0233">The Authorized and Reserved Envelopes are RSVP Flow Specs (both TSpec and RSpec) that identifies the resources that are being reserved for this service flow. The Resource-ID field may include a local 32-bit identifier that is allocated from the local space at the CMTS where the gate resides. It will be appreciated that any number of gates may share a resource-ID, and therefore share a common set of resources, with the restriction that only one of these gates in each direction has resources committed.</p>
<p id="p-0188" num="0234">The Application Name field may identify the originating application. When a new service flow is to be created using an RSVP+ message (as defined by the PacketCable DQoS specification), CMTS <b>1400</b> may use the Gate-ID from the RSVP+ message to find the gate to which the application is assigned. Once the gate is identified, CMTS <b>1400</b> may identify the application from the Application Name field included in the gate. In other implementations, it may be possible to include sub-application names at the gate to allow for differentiation between various applications/payment groups/provider classes.</p>
<p id="p-0189" num="0235">Identification Using RFC2872-Defined RSVP Fields</p>
<p id="p-0190" num="0236">RFC2872 defines application and sub-application identity policy elements for use with RSVP. The RFC2872 policy elements may include an identifier that uniquely identifies the application vendor, an application identifier, an application version number, and a sub-application identifier. In one exemplary implementation, the Gate Control protocol may be modified to include an Application Name field and an Application X.500 field. The Application Name field may include an ASCII string representing the name of the application. The Application X.500 field may include a distinguished name as is well known in the art. In an alternative implementation, an operator may store application identifying information, such as an application name, at CMTS <b>1400</b>. The operator may, for example, store the application identifying information in memory <b>1410</b>. In each of these exemplary implementations, wild cards may be used for multiple unknown characters and question marks for a specific character may be used as well. For example, &#x201c;*VoIP*SIP*&#x201d; may be used as application identifying information for a VoIP application SIP sub-application. Such application identifying information would accept the following exemplary application name fields in the RSVP message:</p>
<p id="p-0191" num="0237">Microsoft VoIP protocol SIP v1.00.exe</p>
<p id="p-0192" num="0238">Generic VoIP SIP.exe</p>
<p id="p-0193" num="0239">Voip_sip.exe.</p>
<p id="h-0028" num="0000">CMTS <b>1400</b> may identify an application by comparing the application name field in a RSVP message to the application identifying information from the Gate Control protocol or to the application identifying information stored in memory <b>1410</b>.</p>
<p id="p-0194" num="0240">Once the application is identified, CMTS <b>1400</b> may allocate (or schedule) resources for the application based on the identification [act <b>1530</b>]. If, for example, CMTS <b>1400</b> identifies the application as a high priority application, such as a voice, video, or multimedia-related application, CMTS <b>1400</b> may give preference to system resources with respect to these types of applications.</p>
<p id="p-0195" num="0241">When the decision to use a specific Context Dependent Scheduler <b>1640</b> is made using the application decision, the scheduling is carried out using the second flow information <b>1650</b> and first flow information <b>1670</b> and first flow bandwidth request <b>1660</b> to make a decision on how to allocate resources for the first flow <b>1680</b>, as illustrated in <figref idref="DRAWINGS">FIG. 16</figref>.</p>
<heading id="h-0029" level="1">CONCLUSION</heading>
<p id="p-0196" num="0242">Systems and methods consistent with the present invention identify applications requesting service flows in a cable modem communications environment. A CMTS may identify applications using Service Class Names, or other application identifying information from external processes. When scheduling resources, a CMTS may allocate more resources to those applications (e.g., voice, video, and other high-speed multimedia applications) identified as requiring enhanced performance (e.g., lower delays, less dropped packets, etc.). On the other hand, the CMTS may allocate fewer resources to less-demanding applications, such as web surfing applications.</p>
<p id="p-0197" num="0243">The foregoing description of exemplary embodiments of the present invention provides illustration and description, but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example, the above implementations can be implemented in software, hardware, or a combination of software and hardware. Thus, the present invention is not limited to any specific combination of hardware circuitry and software.</p>
<p id="p-0198" num="0244">While a series of acts has been described with regard to <figref idref="DRAWINGS">FIG. 15</figref>, the order of the acts may be varied in other implementations consistent with the present invention. Moreover, non-dependent acts may be implemented in parallel.</p>
<p id="p-0199" num="0245">No element, act, or instruction used in the description of the present application should be construed as critical or essential to the invention unless explicitly described as such. Also, as used herein, the article &#x201c;a&#x201d; is intended to include one or more items. Where only one item is intended, the term &#x201c;one&#x201d; or similar language is used.</p>
<p id="p-0200" num="0246">The scope of the invention is defined by the claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>receiving, via a Cable Modem Termination System (CMTS), a first allocation request for a first flow from a first application and a second allocation request for a second flow from a second application,
<claim-text>the first allocation request including a resource reservation protocol message that includes a gate identifier;</claim-text>
</claim-text>
<claim-text>identifying, via the CMTS, a type of the first application based on the gate identifier that is included in the resource reservation protocol message of the first allocation request; and</claim-text>
<claim-text>scheduling, via the CMTS, resources, for the first flow, based on the identified type of the first application and information associated with the second flow.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where scheduling the resources further comprises:
<claim-text>identifying a quality of service parameter set based on a service class name associated with the first allocation request, and</claim-text>
<claim-text>scheduling the resources for the first flow further based on the quality of service parameter set.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, where the second allocation request includes one of a Registration message, a Dynamic Service Addition message, or a Dynamic Service Change message.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, where identifying the type of the first application further includes:
<claim-text>comparing a service class name associated with the first allocation request to stored application identifiers, and</claim-text>
<claim-text>identifying the type of the first application further based on comparing the service class name to the stored application identifiers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where scheduling the resources for the first flow includes:
<claim-text>predicting a size of a data packet that is to be generated by the first application based on the type of the first application, and</claim-text>
<claim-text>scheduling the resources based on the predicted size of the data packet and the information associated with the second allocation request.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the gate identifier is associated with a gate of the CMTS.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>including, via the CMTS, a service flow encoding that includes a service class name associated with the first allocation request and includes a Quality of Service (QoS) parameter set of a service class associated with the service class name.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where identifying the type of the first application includes:
<claim-text>identifying the type of the first application further based on a service class name included in the first allocation request.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where identifying the type of the first application includes:
<claim-text>determining an application name using the gate identifier,</claim-text>
<claim-text>comparing the application name to stored application identifiers, and</claim-text>
<claim-text>identifying the type of the first application further based on comparing the application name to the stored application identifiers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>where the resource reservation protocol message further includes application identification information that identifies at least one of:
<claim-text>an application vendor,</claim-text>
<claim-text>an application identifier,</claim-text>
<claim-text>an application version number, or</claim-text>
<claim-text>a sub-application identifier, and</claim-text>
</claim-text>
<claim-text>where identifying the type of the first application includes:
<claim-text>identifying the type of the first application further based on the at least one of the application vendor, the application identifier, the application version number, or the sub-application identifier.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>,
<claim-text>where the application identification information identifies the sub-application identifier, and</claim-text>
<claim-text>where identifying the type of the first application further includes:
<claim-text>identifying the type of the first application based on the sub-application identifier.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, where identifying the type of the first application further includes:
<claim-text>comparing the application identification information to stored application identifiers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, where identifying the type of the first application further includes:
<claim-text>comparing the application identification information to information in a gate control protocol.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A system comprising:
<claim-text>a network device to:
<claim-text>receive a first request, for a first flow, from a first application and a second request from a second application,
<claim-text>the first request being received via a cable modem termination system over a cable network, and</claim-text>
<claim-text>the first request including a resource reservation protocol message that includes a gate identifier;</claim-text>
</claim-text>
<claim-text>identify a type of the first application based on the gate identifier that is included in the resource reservation protocol message of the first request; and</claim-text>
<claim-text>schedule resources, for the first flow, based on the type of the first application and information associated with the second request.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>,
<claim-text>where the first request further includes a service class name, and</claim-text>
<claim-text>where, when identifying the type of the first application, the network device is further to:
<claim-text>compare the service class name to a group of stored application identifiers.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, where, when identifying the type of the first application, the network device is further to:
<claim-text>determine an application name using the gate identifier, and</claim-text>
<claim-text>compare the application name to a group of stored application identifiers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>,
<claim-text>where the resource reservation protocol message further includes application identification information, and</claim-text>
<claim-text>where, when identifying the type of the first application, the network device is further to:
<claim-text>compare the application identification information to a group of stored application identifiers.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A non-transitory computer-readable medium storing instructions, the instructions comprising:
<claim-text>one or more instructions that, when executed by at least one component of a network device, cause the at least one component to:
<claim-text>receive a first request for a first flow from an application via a cable modem network,
<claim-text>the first request including a resource reservation protocol message that includes a gate identifier;</claim-text>
</claim-text>
<claim-text>receive a second request from a second application via the cable modem network;</claim-text>
<claim-text>identify a type of the first application based on the gate identifier that is included in the resource reservation protocol message of the first request; and</claim-text>
<claim-text>schedule an amount of resources, for the first flow, based on the type of the first application and information associated with the second request.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The non-transitory computer-readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>, where the one or more instructions to identify the type of the first application include:
<claim-text>one or more instructions that, when executed by the at least one component, cause the at least one component to:
<claim-text>identify the type of the first application as one of a higher priority application or a lower priority application.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The non-transitory computer-readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>,
<claim-text>where the second request includes a service class name, and</claim-text>
<claim-text>where the instructions further comprise:
<claim-text>one or more instructions that, when executed by the at least one component, cause the at least one component to:</claim-text>
<claim-text>compare the service class name to a group of stored application identifiers,</claim-text>
<claim-text>identify another type of the second application based on comparing the service class name, and</claim-text>
<claim-text>scheduling other resources for the second application based on the other type.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The non-transitory computer-readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>,
<claim-text>where the second request includes a service class name, and</claim-text>
<claim-text>where the instructions further comprise:
<claim-text>one or more instructions that, when executed by the at least one component, cause the at least one component to:
<claim-text>include, for the second request, a service flow encoding that includes the service class name and includes a Quality of Service (QoS) parameter set of a service class associated with the service class name.</claim-text>
</claim-text>
</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
