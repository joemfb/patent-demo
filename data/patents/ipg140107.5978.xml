<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627096-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627096</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13550164</doc-number>
<date>20120716</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>21</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>713186</main-classification>
</classification-national>
<invention-title id="d2e43">System and method for providing secure access to an electronic device using both a screen gesture and facial biometrics</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7552467</doc-number>
<kind>B2</kind>
<name>Lindsay</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2004/0236701</doc-number>
<kind>A1</kind>
<name>Beenau et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2006/0206717</doc-number>
<kind>A1</kind>
<name>Holt et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713182</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2007/0271466</doc-number>
<kind>A1</kind>
<name>Mak et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2009/0160609</doc-number>
<kind>A1</kind>
<name>Lin et al.</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2009/0309698</doc-number>
<kind>A1</kind>
<name>Headley et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2010/0107219</doc-number>
<kind>A1</kind>
<name>Thompson et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2011/0088086</doc-number>
<kind>A1</kind>
<name>Swink et al.</name>
<date>20110400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2011/0317872</doc-number>
<kind>A1</kind>
<name>Free</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382103</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>WO</country>
<doc-number>2010022185</doc-number>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>Samuel Gibbs, &#x201c;Biometric Face Recognition for Jailbroken iPhones With RecognizeMe,&#x201d; internet, publication date May 18, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>713186</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713182</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713183</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 34</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 16</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 26</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61507707</doc-number>
<date>20110714</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130167212</doc-number>
<kind>A1</kind>
<date>20130627</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Azar</last-name>
<first-name>Cyrus</first-name>
<address>
<city>Spokane Valley</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Brostoff</last-name>
<first-name>George</first-name>
<address>
<city>Covert</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Azar</last-name>
<first-name>Cyrus</first-name>
<address>
<city>Spokane Valley</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Brostoff</last-name>
<first-name>George</first-name>
<address>
<city>Covert</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Barnes &#x26; Thornburg LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sensible Vision, Inc.</orgname>
<role>02</role>
<address>
<city>Covert</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Zee</last-name>
<first-name>Edward</first-name>
<department>2435</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system and method for providing secure authorization to an electronic device by combining two or more security features of authentication process at substantially the same time where at least one of the factors is a &#x201c;tolerant&#x201d; factor. By combining two factors such as a facial recognition any screen gesture, these can be analyzed at substantially the same time such that the tolerance match required by the tolerant factors providing a better user authentication experience without reducing the overall security accuracy.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="219.54mm" wi="151.55mm" file="US08627096-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="172.21mm" wi="168.83mm" file="US08627096-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="241.72mm" wi="155.11mm" file="US08627096-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="233.43mm" wi="183.73mm" file="US08627096-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="247.73mm" wi="160.44mm" file="US08627096-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="257.56mm" wi="122.00mm" file="US08627096-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="241.72mm" wi="120.48mm" file="US08627096-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="165.69mm" wi="176.19mm" file="US08627096-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="237.24mm" wi="160.44mm" file="US08627096-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="155.96mm" wi="166.71mm" file="US08627096-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application claims the benefit of U.S. provisional patent application No. 61/507,707 filed on Jul. 14, 2011, entitled &#x201c;SYSTEM AND METHOD FOR PROVIDING SECURE ACCESS TO AN ELECTRONIC DEVICE USING BOTH A SCREEN GESTURE AND FACIAL BIOMETRICS,&#x201d; the entire contents of which is incorporated by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">This invention relates in general to electronic security and more particularly to a method using both a screen gesture and facial biometrics for authenticating the user of an electronic device.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Many electronic devices such as personal computers, mobile devices including mobile phones and tablet devices use some form of authentication, typically a password that must be input into the device to gain access. The password is most often typed onto a keyboard or other interface which then allows the user to gain partial or full access to the utility of the device and/or network. A problem associated with using passwords is that they are time consuming and inconvenient for the user to enter. Users often use informal passwords or share their password with others which works to compromise system security. These practices negate the password's value and make it difficult to have an accurate auditing of access. Moreover, passwords are expensive to administer when forgotten or misplaced. Although the use of other types of security access systems such as voice recognition, fingerprint recognition or iris scans have been implemented, these types of systems require a different procedure to access and use the device. These techniques also require a specific and time-consuming enrollment process in order to be operational.</p>
<p id="p-0005" num="0004">Biometric authentication using facial recognition is also often used to gain access to electronic devices. U.S. Pat. No. 6,853,739 to Kyle and U.S. Pat. No. 6,724,919 to Akiyama et al., which are both herein incorporated by reference, disclose examples of identity verification systems wherein a database is employed to compare facial features of a user to those in the pre-established database. Once a comparison is made, then authentication is verified and access is granted to the system. The disadvantage of this type of system is the requirement of a separate and specific enrollment procedure by the user to create the database. As with this type of facial recognition system and others in the prior art, the database must be populated before being used; otherwise, the system will not operate. This puts an unnecessary burden on the system operator, requiring detailed education on the steps to populate the database before the system may become operational. Additionally, this type of security system does not permit the automatic updating of the database to accommodate changes in head position, user features (such as different glasses), a change in the camera's operational characteristics, lighting and other environmental factors. This can limit the speed, accuracy, and even the success of database matching (recognition). Also, these prior art facial recognition and other biometric systems operate only at the instant of authentication.</p>
<p id="p-0006" num="0005">Still other techniques use a gesture associated with the device's display. This type of recognition technique involves the user touching the device's touch screen and providing movements that are recognized by the device. These movements can be linked to device functionality such as operation of certain appliances or allowing access to the device. Another example of a security system using biometrics to supplement password entry is U.S. Pat. No. 7,161,468, &#x201c;User Authentication Method and Apparatus,&#x201d; issued Jan. 9, 2007 to Hwang and Lee. Described therein is a user authentication apparatus that authenticates a user based on a password input by the user and the user's biometrics information. The user authentication apparatus includes a password input unit which determines whether a password has been input; a storage unit which stores a registered password and registered biometrics; a threshold value setting unit which sets a first threshold value if the input password matches with a registered password and sets a second threshold value if the input password does not match with the registered password; and a biometrics unit which obtains biometrics information from the outside, determines how much the obtained biometrics information matches with registered biometrics information, and authenticates a user if the extent to which the obtained biometrics information matches with registered biometrics information is larger than the first or second threshold value. As an example of how such a system could be adapted within the scope of the present invention, the biometrics input could be supplemented with a hidden action to either fully authenticate the user or convey a secondary password and associated actions, such as account restrictions, feigned access, or issuance of alerts, following previously configured rules.</p>
<p id="p-0007" num="0006">Finally, U.S. Patent Publication 2009/0160609 to Lin describes a method of unlocking a locked computing device where the user's touch is used as a request to unlock a device while biometric information can be used with this process. Although the user may use a touch screen for a request to unlock the device, Lin does not use a combination of both a screen gesture and biometric information to authenticate the user.</p>
<p id="p-0008" num="0007">These and other features, advantages, and objects of the present invention will be further understood and appreciated by those skilled in the art by reference to the following specification, claims, and appended drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing the topology of the system and method of the invention wherein a camera is used to provide user system authentication;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart diagram illustrating an overview of the method using facial biometrics;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref> is a flow chart diagram illustrating a continuous authentication routine used in accordance with an embodiment of the invention;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart diagram illustrating a back-timing process used with the automatic database in accordance with an embodiment of the invention;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart diagram illustrating facial feature tracking and a delayed lock subroutine as used in accordance with an embodiment of the invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 6</figref> is a flow chart diagram illustrating an alternative embodiment to the biometric authentication and delayed lock routine shown in <figref idref="DRAWINGS">FIG. 5</figref> as used in accordance with the invention;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram showing the topology of the system and method of the invention wherein a screen gesture and camera are used to provide user system authentication in accordance with an alternative embodiment of the invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 8</figref> is flow chart diagram illustrating yet another alternative embodiments for providing authentication of an electronic device using both a screen gesture and facial biometrics; and</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram illustrating screen gesture shapes that can be used in accordance with an embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0018" num="0017">An embodiment of the invention works to close a fundamental security hole that exists in many forms of existing security authentication for all types of electronic devices that require secure access. Existing security methods only confirm the user at the moment the user enters his or her password, scans his or her fingerprint, or iris, etc. The system has no ability to discern whether the current user is the same individual who authenticated even a few milliseconds earlier. This leaves the device completely unsecured and vulnerable until it is logged off or locked. It only takes a few moments for persons having malicious intent to steal and/or delete data from a device from which the user has already logged in. The existing solution is to require the user to manually lock/logoff, or create user inactivity timers to lock or logoff a user.</p>
<p id="p-0019" num="0018">In addition, most information technology (IT) organizations resist change because they prefer not to risk changes that would affect their existing hardware/software systems. Also, they prefer not to expend the support costs necessary for implementing a solution. Support costs for training users and answering help desk questions can be significant factors. The present invention automates the database creation in way that is transparent to the end user. The invention requires little training with minimal &#x201c;help desk&#x201d; costs. The invention utilizes an auto-enrollment feature that permits the device to automatically update a database to constantly improve the quality of the user recognition. In contrast, current biometric products require a special set of steps to establish and update the database. In some cases, these steps can be performed by the user only after a learning orientation. In many cases, an IT administrator must work with the user to actually train the database before it can be used in the system.</p>
<p id="p-0020" num="0019">Security compliance is also a major problem often requiring users to manually lock or logoff their computers when stepping away from them. This process is time consuming, cumbersome and is secondary to the user's purpose in using the computer. Moreover, locking or logging off requires the user to enter a password when the user returns to the device which is a major inconvenience. Unless rigorously enforced, users will typically ignore the proper security procedures. Short of direct observation, there is essentially no way for a system administrator to confirm that users are properly following a prescribed security policy.</p>
<p id="p-0021" num="0020">One impractical solution has often involved the use of a timer. The timer works by locking the device when there is no peripheral activity within a predetermined time period. As will be recognized by those skilled in the art, the peripherals may include, but are not limited to, a mouse, keyboard or touch screen. If a timer is set to a short enough duration to reasonably close a security hole when the user steps away, the device will lock when the user is reviewing data on the screen. The user is then constantly inputting his or her credentials each time the system locks or logs the user off. This causes frustration for the user and greatly reduces productivity. As a result, typical inactivity times are at least 2-5 minutes, which provides a huge window of vulnerability. In addition, inactivity timers are ineffective. All an unauthorized user must do is access the system within the timer period. After that, the unauthorized user can continue working indefinitely.</p>
<p id="p-0022" num="0021">The system and method of the present invention directly address these compliance issues by automating the process, thus ensuring complete compliance. Since the process is automated and transparent to the operator, user acceptance is very high. The users find the system is more convenient to use than before the installation of the present invention. Additionally, system audit logs showing persons who accessed the device are now accurate because of this continuous authentication security process. The invention operates by instantly locking/logging off when the user is out of view of the device and then unlocking as soon as the user reappears in front of the computer.</p>
<p id="p-0023" num="0022">Referring now to <figref idref="DRAWINGS">FIG. 1</figref>, the system <b>100</b> as used in accordance with the present invention includes an electronic device <b>101</b> including, but not limited to, a personal computer, mobile telephone, alpha numeric paging device, personal digital assistant (PDA), electronic gaming device or the like which require some type of authentication to gain access to the utility of the device <b>101</b>. A camera <b>105</b> may also be used to add an additional level of security to the device where the camera is used in connection with the device <b>101</b> to populate an internal database <b>107</b> with a plurality of image vectors. The camera provides substantially real-time images and typically runs at a rate of approximately 5-10 frames per second for continuously supplying digital image data to the electronic device <b>101</b>. The camera is used in connection with an optional facial feature tracking software typically used within the device that works to track the movement of the user's face while in a position in front of the camera. Thus, as the user moves his head back and forth or side to side while using the device, the software used in connection with the camera will track this facial movement to allow continuous authentication while using low CPU and device resources <b>113</b>.</p>
<p id="p-0024" num="0023">Those skilled in the art will recognize that the camera <b>105</b> may be integrated into the electronic device <b>101</b> or it may stand alone as an accessory or peripheral, sending image data to the electronic device through a wired or wireless connection. As described in connection with the preferred method of the invention, a microprocessor <b>109</b> is then used with a comparator <b>111</b> for making a determination whether images continuously supplied by the camera <b>105</b> are human facial images. If a human facial image is detected, it is determined whether this image matches any of those stored in the database <b>107</b> from previous user sessions. Each vector represents a numerical representation of a digital image sent from the camera <b>105</b> to the electronic device <b>101</b>. As will be discussed herein, the electronic device <b>101</b> makes a comparison between a vector established in the database <b>107</b> with a current vector provided by the camera <b>105</b>. When a match is affirmatively established and the user is authenticated, the system <b>100</b> may be configured to allow a user either full or limited access to the electronic device <b>101</b>.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart diagram illustrating an overview of the facial biometric method <b>100</b> of an embodiment of the present invention. Although this method is depicted as a sequence in <figref idref="DRAWINGS">FIG. 2</figref>, it will be evident to those skilled in the art that other iterations and definitions are possible without departing from the spirit and scope of the present method. These methods may include, but are not limited to, two-dimensional (2D), three-dimensional (3D), infra-red (IR) and/or other facial recognition techniques. In the method for the facial biometric overview <b>200</b>, the initial startup process for logging on to the device is initiated <b>201</b>, and the device displays a screen <b>203</b> allowing the user to supply his or her login password or other authentication credentials. A video frame is received <b>205</b> from the camera associated with the device whereby the device then determines <b>207</b> whether the image data received from the camera is a facial image using face detection. If it is not a facial image, the device then continues to wait <b>203</b> for the user's login credentials.</p>
<p id="p-0026" num="0025">However, if the image data is a facial image, a user alert timer is started <b>209</b>. The user alert timer is used to establish some predetermined time within which the user should be authenticated before a message is displayed to the user to request the user to manually input his or her credentials. The expiration of the user alert timer has no effect on authentication other than to recommend to the user to login manually since the authentication process has exceeded an expected duration and the system would benefit from a database update. Thus, the camera frames continue to be evaluated even if the user is requested to enter a password. The system may be able to identify users as they are entering their credentials, speeding their access. So long as the user remains in front of the device, the system and method of the invention attempts to perform a database match. Even after authentication has occurred, each camera frame is evaluated utilizing this continuous authentication feature.</p>
<p id="p-0027" num="0026">After the image from the camera is converted to an image vector, the device then determines <b>211</b> if the vector has any match to one already established in the database. If no match occurs and the user alert timer has not expired <b>221</b>, then the device continues to process new incoming image vectors with those in the database to determine whether a match occurs. If the user alert timer has expired, the user is then requested <b>223</b> for his log-in credentials which may be input using a keyboard onto which the user can manually input a password or other credentials or, alternatively, another type of interface such as other biometric methods. Concurrently, the device continues to scan new incoming images/vectors for a match to the database <b>211</b>. If at any time there is a match to the database <b>211</b>, the system will proceed to match to optional factors <b>213</b>. If the credentials input by the user do not match those stored in the database, the process starts again whereby the device waits for initial login credentials from the user <b>203</b> and scanning for vectors continues.</p>
<p id="p-0028" num="0027">However, if the credentials do match those in the database and match the optional factors authentication factors <b>213</b>, then the automatic database process is initiated which will be discussed with regard to <figref idref="DRAWINGS">FIG. 3</figref>. In the event that a match does occur between the current vector received from the camera and one stored in the database before the user alert timer <b>221</b> expires, then the user may be prompted for one or more additional authentication factors such as a pass phrase or a second password that provides an optional additional factor for authentication. If the user fails to provide this pass phrase or if the pass phrase does not match that in the database, the system returns to the start, the user alert timer is reset and the initial logon screen <b>203</b> is displayed.</p>
<p id="p-0029" num="0028">Once the user is authenticated, the user is then granted access <b>215</b> and logged into the device for full or limited use of its features. An inventive aspect of the present invention, as compared to the prior art, is that the user is <b>217</b> is continuously scanned and authenticated once the user has gained access. Those skilled in the art will recognize that this continuous authentication process enables the user to step away from the device, allowing the viewing screen to be disabled so images present on the screen or monitor are no longer able to be viewed and data entry locked. Thus, text, images or other data presently displayed on the device may be easily secured when the user moves from the camera's field of view. Once the user again steps back into the camera's view, the method of the present invention provides for re-authentication of that user. Once re-authentication is established, the display and data entry are unlocked, allowing instant access to the device in the same state as when the user stepped from view.</p>
<p id="p-0030" num="0029">In typical use, while a personal computer is secured using this method, the application software running on the device is unaffected and continues to run on the device, although with no display. However, the method of the invention allows the user to select to what extent the device will be affected when the device becomes locked or unlocked. Thus, the user may determine to have the device: 1) locked; 2) unlocked; 3) logon on; or 4) logged off, using this method. The &#x201c;locking&#x201d; of the device provides a secure desktop without disconnecting the user from a document or email server and without shutting down any application software running on the device. The display, keyboard and/or mouse on the device may be disabled while the user is not present within the camera's view. Once the user steps back into the field of view, the method provides for re-authentication. Once this security is reestablished, the device's display is again enabled for use. Hence, this process provides a simplified means of maintaining security of a personal computer or other device while the user is situated outside the camera's field of view. Since facial biometrics are used and the user is continuously authenticated, the user can be assured that data displayed on the device and access to the network will be secure when the user steps away from a work station for a moment or longer periods of time.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 3</figref> is a flow chart diagram illustrating the continuous authentication routine as briefly described in <figref idref="DRAWINGS">FIG. 2</figref>. The continuous authentication process is a key feature of the invention since it allows the user to be easy re-authenticated after stepping from the camera's field of view. The continuous authentication process <b>300</b> begins <b>301</b> when an authenticated user is granted access and the device is unlocked <b>303</b>. A biometric re-authentication or facial feature tracking routine is used to confirm <b>305</b> that the user remains present in the camera's field of view. Re-authentication of the user's face allows the highest degree of security while keeping the system unlocked. Conversely, Facial Feature tracking allows high security with low CPU resources by tracking the authenticated user's features. Facial Feature Tracking and continuous authentication is discussed herein with regard to <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0032" num="0031">If an authenticated user steps out of the field of view of the camera <b>307</b>, an optional delayed locking timer process is initiated <b>309</b>. The delayed locking timer process will be more fully described with regard to <figref idref="DRAWINGS">FIG. 5</figref>. After this process is complete, the device is locked <b>311</b>. If a user does step into the field of view of the camera <b>313</b>, a determination is made whether the optional fast unlock timer has expired <b>315</b>. If used, the fast unlock timer is typically brief, usually 1-10 seconds. If the fast unlock timer has not expired, the device is unlocked <b>335</b> with the presence of any face rather than the recognition of a specific face. If the fast lock timer has expired, the device resumes <b>317</b> continuous biometric scanning for authentication. The user alert timer is restarted <b>319</b>, and it is determined whether the image from the camera matches <b>321</b> a vector stored in the database. If the camera image does not match any stored image then it is determined whether the user alert timer has expired <b>323</b>. If not, the process continues where the image is matched <b>321</b> against those in the database. If the user alert timer has expired, biometric scanning and database matching continues and the current user is requested <b>325</b> for his or her authentication credentials. If there is a match, the automatic database process is started <b>329</b> as more fully described in <figref idref="DRAWINGS">FIG. 4</figref>. If a database match is made before the user enters his or her credentials but the user alert timer has expired, the automatic database process <b>329</b> is executed. At the completion of the automatic database process, the user will be considered authenticated. The system will either unlock the device <b>335</b>, or optionally logoff an existing user <b>337</b> who had locked the computer. The system will then automatically log on the new user to the user's account without any additional authentication.</p>
<p id="p-0033" num="0032">If an image does initially match one that is in the database <b>321</b>, the user may optionally be prompted <b>331</b> for additional authentication factors such as a pass phrase or other type of password. If there is no match for the additional authentication factors, the ongoing biometric scanning is continued <b>317</b>. If there is a match, a determination <b>333</b> is made whether this is the existing authenticated user who may have just momentarily stepped from the field of view. If it is the existing authenticated user, the device is unlocked <b>335</b>. If it is not the existing user, the device may be configured to log off <b>337</b> the existing user and start the initial log-in process <b>301</b> at which point the continuous authentication routine is completed <b>339</b>.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart diagram illustrating the process for populating the database together with a back timer process <b>400</b> that can be used to improve the quality of the vectors in the database. The automatic database is a process by which the system database will be created or updated while a user uses the system and enters a password, or a database match occurred after the user alert timer expired. Although a password may initially be required, an objective of the automatic database is to permit the data to be populated through actual use rather than a specific enrollment procedure, whereby a user can eventually stop using password authentication and the method of the invention can be employed to authenticate using facial biometric data. By updating the database whenever it has taken too long a period of time for the database matching, the quality of the database is improved and the amount of time for subsequent database matches decreases. This also accommodates the various physical changes to a user's face over time, including ageing, changes in glasses, color of the skin (tanning), the position of the user's head relative to the camera, changing camera characteristic, and various environmental conditions including lighting. The purpose of the back timer process is to update the database with one or more images from a time previous to the actual recognition or authentication event. This permits the system to acquire higher quality images that closely match the head position of the user when the user is first accessing the device.</p>
<p id="p-0035" num="0034">The automatic database and back timer process starts <b>401</b> when a video frame is received <b>403</b> from the camera. The user alert timer is started <b>405</b> and a determination is made <b>407</b> whether the image is a facial image. If it is not a facial image, the routine returns to receiving a video <b>403</b>. Once a facial image is detected, the video frame is temporarily stored <b>409</b> in memory along with a time stamp. The time stamp denotes the actual time the facial image was processed by the camera. A comparison is made <b>411</b> to determine whether the image matches another image vector in the database. If a match occurs, then the user is authenticated <b>427</b>. If no match occurs, a determination is made <b>413</b> whether the user alert timer has expired. If the user alert timer has not expired, the image is then reviewed <b>407</b> to determine whether it is a facial image. If the user alert timer has expired, the user is requested <b>415</b> for the user's name and password, pass phrase or the like. If the user is not authenticated with the correct credentials <b>417</b>, the image is again reviewed <b>407</b> to determine whether it is a facial image. If the user is authenticated, then images from memory are acquired <b>419</b> based on the actual authentication time less the back timer value. Since video frames are still received <b>403</b> and database matching <b>411</b> continues while the user is requested to enter his or her credentials, the system may make a database match and proceed to User Authenticated <b>407</b> even as the user is entering his or her credentials. It is next determined <b>421</b> whether the user has preexisting images in the database. If the user does not have a preexisting image in the database, a new database is created <b>423</b> for that user. Subsequently, once the new database is created or preexisting images are available, the acquired images are added <b>425</b> to the user's database. The user is then authenticated <b>427</b> and the process is completed <b>429</b>.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart diagram illustrating a continuous facial feature tracking and delayed lock process <b>500</b> as used for the continuous authentication embodiment of the invention. The benefit of facial feature tracking as a method of continuous authentication is a substantially low central processing unit (CPU) load and high tolerance for the position of the user's face relative to the camera. Since the system can lock or start a log off in a very short time period, the delayed locking timer permits the user to set how quickly the system locks to match the user's usage requirements. This process operates immediately after initial authentication <b>215</b> until the device is locked or logged off. If this condition exists, the system will remain unlocked if there is tracking of the user's face or any mouse or keyboard activity. This can be desirable as the locking/logoff action may occur too quickly. Once the mouse or keyboard activity is no longer detected, the method of the invention provides an optional predetermined time period before the device will be locked. If the user's face returns to the field of view or if keyboard/mouse activity is restarted before an inactivity timer expires, then the device will not lock and the timer is reset.</p>
<p id="p-0037" num="0036">More specifically, the process starts <b>501</b> when an authenticated user is granted access to the device which is unlocked <b>503</b>. A video frame is received from the camera <b>505</b> and one or more tracking dots are placed <b>507</b> on the prominent features of the user's face. The number of tracking dots are then counted <b>509</b> and a determination is made <b>511</b> of how many tracking dots are present. If tracking dots meet a minimum threshold, then the process begins again, where the user has been granted access <b>503</b> and the device remains unlocked. If the number of tracking dots is below the minimum threshold, the delay locking timer is started <b>513</b>. The process for using the delayed locking timer is more fully described with regard to <figref idref="DRAWINGS">FIG. 6</figref>. It is next determined <b>515</b> whether there is any mouse, keyboard or other peripheral activity such as activity on a touch screen. If there is no activity, the process begins again <b>503</b> with the authenticated user having access to an unlocked device. If there is activity on the mouse or keyboard, it is determined <b>517</b> whether the delay locking timer <b>519</b> has expired. If the delayed locking timer has not expired, the process is restarted <b>503</b>. If the locking timer has expired, the device is locked <b>529</b> and the process is completed <b>521</b>.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 6</figref> illustrates a Continuous Biometric Authentication &#x26; Delayed Locking flow chart diagram which is an alternative embodiment to the Continuous Facial Feature Tracking and Delayed Lock process <b>500</b> as shown in <figref idref="DRAWINGS">FIG. 5</figref>. Although the method described in <figref idref="DRAWINGS">FIG. 6</figref> is very similar to the tracking feature described in <figref idref="DRAWINGS">FIG. 5</figref>, continuous biometric authentication provides theoretically better security because it is constantly reconfirming the user. In practice the continuous facial feature tracking can lock the system so rapidly that it would be difficult for a new user to replace the existing user before the system locks. Matching database vectors for continuous biometric authentication is very CPU-intensive, and it requires a more consistent placement of the user's face in front of the camera. These two factors make continuous biometric authentication less desirable in many environments and devices. An alternative implementation would include a combination of both Continuous Biometric Authentication and Continuous Facial Feature Tracking where facial feature tracking is performed the majority of the time and Biometric Authentication is run at periodic intervals.</p>
<p id="p-0039" num="0038">In <figref idref="DRAWINGS">FIG. 6</figref>, a continuous biometric authentication and the delayed lock process <b>600</b> are used. The process is started <b>601</b> when the user has been granted access <b>603</b> to an unlocked device. A video frame from the camera is received <b>605</b> and it is determined whether the image matches the authenticated user. If the images do not match, the process begins again with the user continuing access <b>603</b> to an unlocked device. If the image does not match that of an authenticated user, a delayed lock timer is started <b>609</b> and it is determined <b>611</b> whether there is any mouse or keyboard activity. If no activity is present and the delayed lock timer <b>613</b> has expired the device will lock or log off <b>615</b> and the routine will finish <b>617</b>. If there is no activity <b>611</b> and the delayed locking timer has not expired <b>613</b>, the device begins again <b>603</b>. If there is activity <b>611</b> or the delayed locking timer <b>613</b> has not expired, the process begins again <b>603</b>.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram showing the topology of the system and method of the invention wherein a screen gesture and camera are used to provide user system authentication in accordance with an alternative embodiment of the invention. Initially, those skilled in the art should recognize that a &#x201c;tolerant&#x201d; factor are those type inputs or factors that are tolerant since they can be accepted without having exacting precision to provide secure access to an electronic device. In contrast, other factors can be selected so that are an &#x201c;exact&#x201d; factor meaning their matching tolerance must be exactly and/or substantially precise in order to allow access to the device. The degree upon which the tolerant or exact factors will operate correctly are generally selected by the manufacturer of the software however, it is the combination of these types of factors that allow the method to provide a great deal of security for the device while still providing easy use and access by the user.</p>
<p id="p-0041" num="0040">The system <b>700</b> includes each of the components as described with regard to <figref idref="DRAWINGS">FIG. 1</figref> however, this device also includes a touch screen <b>709</b> that is connected to and used within the electronic device <b>701</b>. Although shown using a separate keyboard <b>703</b>, those skilled in the art will recognize that the keyboard <b>703</b> can also be integrated with the touch screen <b>709</b> in software to form a virtual keyboard so that the keyboard <b>703</b> and touch screen <b>709</b> would act as one device. As noted herein, the touch screen <b>709</b> will operate in combination with the camera <b>711</b> whose inputs are controlled and interpreted by the microprocessor <b>705</b>. This allows the user to input a gesture into the touch screen <b>709</b> that is used in combination with the camera <b>711</b> to provide user authentication for the device. As described herein, a &#x201c;gesture&#x201d; may be a continuous input from forming a pattern shape from the user's finger to the touch screen or a discrete series of symbol inputs such as numbers, letters, symbols and/or shapes. These inputs are compared to data and other information stored in database <b>713</b>. This data can be compared using a comparator <b>715</b> that provides a comparative type analysis for providing operational access to the electronic device <b>701</b>. As described herein, an optical tracking feature <b>717</b> can also be used to insure the user of the device remains the same person with no gaps or breaches in security.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 8</figref> is flow chart diagram illustrating yet another alternative embodiment for providing user authentication of an electronic device using both a screen gesture and facial biometrics. Those skilled in the art will recognize the invention can be implemented using a non-transitory computer readable medium having computer readable instructions stored thereon for execution by a processor. Although the use of gestures and biometric security systems are taught in the art, there presently is no system or method that works to combine these techniques for providing robust security while also providing a user with flexible access to an electronic device. The authentication process using both a screen gesture and facial biometrics <b>800</b> includes the steps of starting the initial &#x201c;log-on&#x201d; process <b>801</b> that triggers some external event requiring authentication credentials to be entered by the user. An authentication screen is then displayed <b>803</b> and at least one video frame is received by the camera <b>805</b> so that the user can then input a predetermined screen gesture or other security factor <b>807</b>. The gesture is typically input to a touch screen using the user's finger, stylist or the like. The screen gesture may be either a single predetermined shape (letter, number, square, circle, etc.) continuously input by the user typically on a touch screen or the selection of a sequence of symbols and/or shapes that are entered in a predetermined order as described with regard to <figref idref="DRAWINGS">FIG. 9</figref> herein. The skilled in the art will further recognize that the term &#x201c;gesture&#x201d; can refer to both the continuous movement of the user's finger on a screen to symbolize a shape or the discrete entry of shapes, symbols, numbers, letters etc. that may occur on a keypad on the touch screen.</p>
<p id="p-0043" num="0042">Thereafter, a determination is made to match the facial recognition frame received by the camera to a cloud or local database <b>809</b>. Those skilled in the art will recognize that &#x201c;cloud computing&#x201d; means using multiple server computers via a digital network, as though they were one computer. Computers using cloud computing may be accessed via the Internet or the like. If after some predetermined time period, a counter tracking the number of tried log-in attempts or other data is exceeded <b>811</b>, then the user is asked to enter alternate credentials or cancel the request <b>815</b>. If a predetermined number of attempts in the counter are not exceeded, then the camera will be used for supplying additional video frames <b>805</b>. Once alternate credentials are entered, then a determination is made if the credentials match those stored in a database <b>817</b>. If the credentials match, then an automatic database process is performed to update the images and/or other data stored in the database <b>819</b>. However, if the credentials do not match, then the camera can be used for supplying additional video frames for authentication <b>805</b>.</p>
<p id="p-0044" num="0043">When the gesture does not match to the cloud or local database <b>813</b>, then the user is again asked to enter alterative credentials or cancel the request <b>815</b>. Alternative credentials can be a user name and password, screen gesture and/or the entry of unique symbols or shapes in a predetermined sequence. If the new credentials do not match, then the process starts again with at least one new frame from the camera <b>805</b>. However if the new credentials do match then an update is performed on the automatic database to update the facial biometrics <b>819</b>. However, if the gestures do match <b>813</b>, then the user is authenticated and the local cloud based credentials can be placed into a specific application for granting access and/or use <b>821</b>. Any updated biometric facial data <b>819</b> will be used in this authentication process <b>821</b>. Thereafter, the authentication screen is cleared <b>823</b> and the process ends <b>825</b>. Thus, by using both a screen gesture and some form of biometric recognition, the matching tolerance i.e. false rejections of the user are greatly reduced while still allowing a high level of security for the electronic device.</p>
<p id="p-0045" num="0044">In typical use, a user on a Smartphone, or any electronic device requiring authentication, accesses the device or application that requires authentication. This authentication typically requires the entry of a user name and password. The method according to an embodiment of the invention authenticates by using the built-in front facing imaging device such as a camera to obtain a facial recognition template. The camera is typically built into the mobile phone such as a Smartphone or tablet. At substantially the same time, the user is prompted to enter a gesture that they had previously enrolled and stored in a local database or cloud. In the event it is too dark or for some reason the imaging device or camera cannot be used, then the user can use alternative credentials such as a gesture, password and/or sequence of secret shapes as described herein to gain access to the electronic device.</p>
<p id="p-0046" num="0045">In use, both the face and a selected gesture is compared to the database of previously enrolled templates of enrolled users. By having both biometric facial data and gesture comparisons at substantially the same moment in time, the matching tolerance for each factor is reduced without reducing the reliability of the security. This allows for a greatly improved user experience since the conditions that normally would lead to a reduction in the confidence of facial recognition or gesture recognition would normally cause an undesired false rejection of the real user are greatly reduced.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 9</figref> illustrates shapes <b>900</b> such as a crown <b>901</b>, paw <b>903</b>, cloud <b>905</b>, hand <b>907</b>, square <b>909</b>, star <b>911</b>, circle <b>913</b>, pentagon <b>915</b>, triangle <b>917</b>, tear drop <b>919</b>, butter fly <b>921</b>, sign <b>923</b>, leaf <b>925</b>, plant <b>927</b>, puzzle piece <b>929</b> and airplane <b>931</b>. Although the shapes <b>900</b> are default shapes that are &#x201c;secret&#x201d; shapes whose sequence is only known to the user, those skilled in the art will recognize that other custom shapes can be used in combination or in lieu of the default shapes. As described herein, one or more default shapes are selected in a predetermined sequence. Alternatively, a single shape can be used of different colors where the colored shapes be selected in a predetermined sequence. As shown in <figref idref="DRAWINGS">FIG. 9</figref>, the shapes are typically arranged in a grid like pattern that can be displayed in a fixed or random location in the grid. Thus, when setting up the gestures for authentication, the user can select the specific shapes, the number of shapes in a sequence, the sequential order the shapes are input by the user as well as whether the shapes are color or mono-chromatic such as gray scale shapes.</p>
<p id="p-0048" num="0047">In use, both the biometric recognition and a selected gesture are compared to the database of previously enrolled templates of enrolled users. By having both biometric data and gesture comparisons at substantially the same moment in time, the matching tolerance for each factor is reduced without reducing the reliability of the security. This allows for a greatly improved user experience since the conditions that normally would lead to a reduction in the confidence of facial recognition or gesture recognition would normally cause an undesired false rejection of the real user are greatly reduced.</p>
<p id="p-0049" num="0048">Those skilled in the art will further recognize that many different variations of gesture and biometric information that can work as exact factors/tolerant factors or the use of multiple tolerant factors that include but are not limited to:</p>
<p id="h-0006" num="0000">Exact Factor and Tolerant Factors</p>
<p id="p-0050" num="0000">
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0049">Password and Face</li>
        <li id="ul0002-0002" num="0050">Password and Gesture</li>
        <li id="ul0002-0003" num="0051">Password and Pattern</li>
        <li id="ul0002-0004" num="0052">Password and Fingerprint</li>
        <li id="ul0002-0005" num="0053">Pin and Face</li>
        <li id="ul0002-0006" num="0054">Pin and Voice</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0051" num="0055">Multiple Tolerant Factors
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0056">Face and Gesture</li>
        <li id="ul0004-0002" num="0057">Face and Partial Password (reduce number of password characters for acceptance)</li>
        <li id="ul0004-0003" num="0058">Face and Pattern</li>
        <li id="ul0004-0004" num="0059">Face and Fingerprint</li>
        <li id="ul0004-0005" num="0060">Face and Voice</li>
        <li id="ul0004-0006" num="0061">Face, Voice and Gesture</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0052" num="0062">Those skilled in the art will recognize that certain factors rely on exact matching while other factors, due to their nature of their design, use some level of &#x201c;matching tolerance&#x201d; also known as tolerant factors to determine acceptance of the gesture or credential. Examples of exact factors include a user's full password, smartcard or the code from a hardware security token. These factors must always precisely match the previously stored credentials for allowing access to the electronic device. In contrast, a tolerant factor would include all forms of biometrics (face, voice, retina and fingerprint) pattern in combination with a gesture entry where some predefined deviation/tolerance from an exact match to the stored credentials is permitted. Even a password can become a tolerant factor if less than the full length of the password is accepted under certain circumstances. This provides for a relaxed authentication for the electronic device.</p>
<p id="p-0053" num="0063">Thus, the system and method of the invention provide fast, simple, and secure access to a personal computer or other electronic device that requires security. The invention combines the use of a screen gesture with biometric security in the authentication process. By combining two factors analyzed at substantially the same time, the tolerance match required by the tolerant factor(s) can be reduced without reducing the overall security accuracy of the electronic device. This allows a secure electronic device to be more consistently accessed rather than by using facial recognition processes alone. It provides an ease of use while still maintaining a substantially high level of security.</p>
<p id="p-0054" num="0064">While the preferred embodiments of the invention have been illustrated and described, it will be clear that the invention is not so limited. Numerous modifications, changes, variations, substitutions and equivalents will occur to those skilled in the art without departing from the spirit and scope of the present invention as defined by the appended claims. As used herein, the terms &#x201c;comprises,&#x201d; &#x201c;comprising,&#x201d; or any other variation thereof, are intended to cover a non-exclusive inclusion, such that a process, method, article, or apparatus that comprises a list of elements does not include only those elements but may include other elements not expressly listed or inherent to such process, method, article, or apparatus.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>We claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A biometric recognition system for providing security for an electronic device comprising:
<claim-text>a digital camera having a field of view for providing at least one facial biometric image from a user of the electronic device;</claim-text>
<claim-text>at least one processor configured for use with the electronic device for:
<claim-text>comparing the at least one facial biometric image to both facial biometric image data and a user selected screen gesture stored in a database;</claim-text>
<claim-text>utilizing a first matching tolerance factor based on the at least one facial biometric image and a second matching tolerance factor based on the user selected screen gesture to authenticate the identity of the user; and</claim-text>
<claim-text>selecting a reduced strength of the first matching tolerance factor or second matching tolerance factor such that the strength of the first matching tolerance factor and second matching tolerance factor are used in combination by the at least one processor to provide access to the electronic device, without reducing the reliability of the authentication.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A facial biometric recognition system as in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the screen gesture is a symbol continuously input from the user's finger on a touch screen of the electronic device.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A facial biometric recognition system as in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the screen gesture is a plurality of shape indicia entered on the touch screen in a predetermined sequence.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A facial biometric recognition system as in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the plurality of shape indicia are arranged in a fixed or random grid pattern.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A facial biometric recognition system as in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the selected screen gesture is a plurality of gestures each assigned different colors.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A biometric recognition system as in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a predefined deviation from an entered biometric image to an exact match of a stored biometric image is utilized for providing ease of use of the electronic device.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A biometric recognition system as in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic device is one from the group of personal computer, tablet, mobile telephone or gaming device.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A non-transitory computer readable medium having computer readable instructions stored thereon for execution by a processor to perform a method comprising the steps of:
<claim-text>storing a plurality of facial biometric images provided from a digital imaging device input into a database;</claim-text>
<claim-text>storing a user selected screen gesture into the database;</claim-text>
<claim-text>providing a first matching tolerance factor based on the facial biometric images and a second matching tolerance factor based on the user selected screen gesture;</claim-text>
<claim-text>selecting a reduced strength of the first matching tolerance factor or second matching tolerance factor;</claim-text>
<claim-text>utilizing at least one processor in an electronic device for authenticating the identity of the user such that the strength of the first matching factor and second matching factor are used in combination by the at least one processor to provide access to the electronic device, without reducing the reliability of the authentication; and</claim-text>
<claim-text>inputting local or cloud based credentials into an application run on the electronic device if the user is authenticated.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A non-transitory computer readable medium as in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising the step of:
<claim-text>utilizing a predefined shape input on a touch screen as the selected screen gesture.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A non-transitory computer readable medium as in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising the step of:
<claim-text>utilizing a plurality of shape indicia entered on the touch screen in a predetermined sequence as the selected screen gesture.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A non-transitory computer readable medium as in <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising the step of:
<claim-text>arranging the plurality of shape indicia in a fixed or random grid pattern.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A facial biometric recognition system as in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the selected screen gesture is a plurality of gestures each assigned different colors.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A non-transitory computer readable medium as in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising the step of:
<claim-text>utilizing biometric images from at least one from the group of a facial image, finger print image or retinal image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A non-transitory computer readable medium as in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising the step of:
<claim-text>selecting the electronic device that is from the group of personal computer, tablet, mobile telephone or gaming device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A method for providing security to an electronic device comprising the steps of:
<claim-text>displaying an authentication screen;</claim-text>
<claim-text>providing data from at least one camera for providing facial biometric authentication data;</claim-text>
<claim-text>providing a first matching factor for the facial biometric authentication data;</claim-text>
<claim-text>providing at least one screen gesture to a touch screen display;</claim-text>
<claim-text>providing a second matching factor for the at least one screen gesture;</claim-text>
<claim-text>utilizing the first matching factor and second matching factor to determine if the biometric authentication data matches information stored in a cloud or database;</claim-text>
<claim-text>utilizing the second matching factor to determine if the at least one screen gesture matches a gesture stored in a cloud or database;</claim-text>
<claim-text>selecting a reduced strength of the first matching tolerance factor or second matching tolerance factor;</claim-text>
<claim-text>providing access to the electronic device upon entry of authentication credentials such that a predefined deviation from the first matching factor and second matching factor is used in combination for providing relaxed authentication of a user of the electronic device, without reducing the reliability of the authentication.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A method for providing security as in <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising the step of:
<claim-text>using a predefined shape input on the touch screen as the screen gesture.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A method for providing security as in <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising the step of:
<claim-text>using a plurality of shape indicia arranged in a predetermined pattern and entered on the electronic device in a predetermined sequence as the screen gesture.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A method for providing security as in <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising the step of:
<claim-text>using a plurality of identical gestures each assigned a different color entered in a predetermined sequence as the screen gesture.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A method for providing security as in <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising the step of:
<claim-text>selecting the electronic device that is from the group of personal computer, tablet, mobile telephone or gaming device. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
