<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624915-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624915</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13152811</doc-number>
<date>20110603</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>137</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>50</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345589</main-classification>
<further-classification>345426</further-classification>
<further-classification>345600</further-classification>
</classification-national>
<invention-title id="d2e53">Color-space selective darkness and lightness adjustment</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5818975</doc-number>
<kind>A</kind>
<name>Goodwin et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6822762</doc-number>
<kind>B2</kind>
<name>Moroney et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7412105</doc-number>
<kind>B2</kind>
<name>Wilensky</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7853096</doc-number>
<kind>B1</kind>
<name>Wilensky</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2012/0081577</doc-number>
<kind>A1</kind>
<name>Cote et al.</name>
<date>20120400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34823199</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>28</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345589</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>13</number-of-drawing-sheets>
<number-of-figures>15</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120306906</doc-number>
<kind>A1</kind>
<date>20121206</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Johnson</last-name>
<first-name>Garrett M.</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Webb</last-name>
<first-name>Russell Y.</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Johnson</last-name>
<first-name>Garrett M.</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Webb</last-name>
<first-name>Russell Y.</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Wong, Cabello, Lutsch, Rutherford &#x26; Brucculeri, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Apple Inc.</orgname>
<role>02</role>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Xiao</last-name>
<first-name>Ke</first-name>
<department>2677</department>
</primary-examiner>
<assistant-examiner>
<last-name>Lee</last-name>
<first-name>Kwang</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for color-space selective darkness and lightness improvements. In one aspect, a method accessing multiple pixels that represent a digital image in an RGB color space. The accessed pixels are processed based on a darkness of the digital image resulting in a first set of processed pixels, and separately based on a lightness of the digital image resulting in a second set of processed pixels. Both sets of processed pixels are combined to generate a processed output image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="109.98mm" wi="140.89mm" file="US08624915-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="194.73mm" wi="164.42mm" orientation="landscape" file="US08624915-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="198.04mm" wi="170.35mm" orientation="landscape" file="US08624915-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="173.31mm" wi="178.90mm" file="US08624915-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="217.17mm" wi="157.82mm" file="US08624915-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="223.35mm" wi="155.53mm" file="US08624915-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="225.04mm" wi="159.43mm" file="US08624915-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="222.08mm" wi="155.87mm" file="US08624915-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="226.31mm" wi="173.65mm" file="US08624915-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="221.74mm" wi="157.82mm" file="US08624915-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="226.31mm" wi="156.21mm" file="US08624915-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="221.74mm" wi="163.75mm" file="US08624915-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="233.93mm" wi="152.57mm" file="US08624915-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="250.11mm" wi="153.50mm" file="US08624915-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">This document describes image processing.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">A digital images that has been captured&#x2014;using a variety of devices&#x2014;can be stored on computer-readable storage media, rendered on a display device, and/or processed using an image processing computer software application. A digital image&#x2014;which is formed from a collection of discrete picture elements, or &#x201c;pixels&#x201d;&#x2014;can be stored on a computer-readable storage medium (for example, a hard disk of a computer system) essentially as a matrix of numbers. Each number represents a grayscale or a color scale value associated with a pixel, the collection of which collectively constitute the digital image. When the image is rendered on a display device, the numbers are passed through a lookup table (LUT) that maps the image intensity values to brightness values. If the LUT is linear, then the image can be mapped directly to the display. Otherwise, if the LUT is non-linear, the displayed image may not be an exact representation of the underlying image and thus must be further processed before being rendered on the display device.</p>
<p id="p-0004" num="0003">In the context of color images, an appearance of the digital image on a display device can be manipulated by modifying the color values associated with the pixels that constitute the image. One technique to do so is referred to as &#x201c;gamma correction&#x201d; in which the color scale value of each pixel (typically normalized between 0 and 1) is exponentiated to a gamma value as shown in equation (1).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>R</i><sub>processed</sub><i>=R</i><sup>F</sup>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0005" num="0004">In equation (1), R is a red component of an RGB color space value. Gamma correction according to equation (1) includes determining corresponding values for a green component (G) and a blue component (B).</p>
<p id="p-0006" num="0005">For gamma, &#x3b3;, values greater than 1.0, image processing according to the function referenced by equation (1) can increase a contrast of an image to make the image, when displayed, appear darker than its corresponding original image. Such image processing also can decrease highlight regions of the original image by darkening color scale values that constitute the highlight regions. Alternatively, image processing based on a gamma value of less than 1.0 can cause a decrease in a contrast by making the output image appear lighter overall relative to the original image. Consequently, processing in this manner can enhance the shadows of the original image.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0007" num="0006">This specification describes technologies relating to color-space selective darkness and lightness adjustments.</p>
<p id="p-0008" num="0007">One innovative aspect of the subject matter described here can be implemented as a method performed by data processing apparatus. Multiple pixels that represent a digital image in an RGB color space are accessed. The accessed multiple pixels are processed based on a darkness of the digital image to adjust a contrast a brightness of color space values of the multiple pixels, resulting in a first set of processed pixels. The accessed multiple pixels are processed based on a lightness of the digital image to adjust a contrast and a brightness of the color space values of the multiple pixels resulting in a second set of processed pixels. The first set of processed pixels and the second set of processed pixels are combined to generate a processed output image.</p>
<p id="p-0009" num="0008">This, and other aspects, can include one or more of the following features. Processing the accessed multiple pixels to adjust the contrast and the brightness of color space values of the multiple pixels based on the darkness of the digital image can include adjusting the contrast and the brightness of the color space values of dark regions of the digital image differently from the contrast and brightness of the color space values of light regions of the digital image. Adjusting the contrast and the brightness of the color space values of dark regions of the digital image differently from the contrast and brightness of the color space values of light regions of the digital image can include increasing a contrast and a brightness of the dark regions, and decreasing a contrast and a brightness of the light regions. Processing the accessed multiple pixels to adjust the contrast and the brightness of color space values of the multiple pixels based on the darkness of the digital image can include adjusting a red component, a blue component, and a green component of a color space value of each pixel according to a gamma function based on a blur, a color scale value, and a user input defining an adjustment to the contrast and the brightness based on the darkness. The blur can be a Gaussian blur with a 2-pixel radius. The color scale value can be within a range of 0.4-2.0.</p>
<p id="p-0010" num="0009">A region in the digital image that represents a particular tone can be identified based on hue angles and brightness values of pixels included in the region. The user input can be adjusted to modulate the gamma function in the identified region. Input can be received to adjust the darkness of the digital image. In response to receiving the input, corresponding values by which a red component, a blue component, and a green component of each pixel are to be adjusted based on the received input can be determined. Processing the accessed multiple pixels to adjust a contrast and the brightness of color space values of the multiple pixels based on the darkness of the digital image can include adjusting a red component, a blue component, and a green component of a color space value of each pixel based on determined corresponding value. Processing the accessed multiple pixels to adjust a contrast and a brightness of color space values of the multiple pixels based on the darkness of the digital image can include determining a common adjustment value from the corresponding values, and adjusting a color space of each pixel based on the common adjustment value. The common value can be one of a maximum of, a minimum of, an average of, or a median of the corresponding values.</p>
<p id="p-0011" num="0010">Processing the accessed multiple pixels to adjust the contrast and a brightness of the color space values of the plurality of pixels based on the lightness of the digital image can include adjusting the contrast and the brightness of the color space values of light regions of the digital image differently from the contrast and the brightness of the color space values of dark regions of the digital image. Adjusting the contrast and the brightness of the color space values of light regions of the digital image differently from the contrast and the brightness of the color space values of the dark regions of the digital image can include increasing a contrast and a brightness of the light regions, and decreasing a contrast and a brightness of the dark regions. Processing the accessed multiple pixels to adjust the contrast and the brightness of color space values of the plurality of pixels based on the lightness of the digital image can include adjusting a red component, a blue component, and a green component of a color space value of each pixel according to a gamma function based on a blur, a color scale value, and a user input defining an adjustment to the contrast and the brightness based on the lightness, and according to a linear segment. Combining the first set of processed pixels and the second set of processed pixels can include combining using a luminance mask. Processing based on the darkness of the image and processing based on the lightness of the image can be order independent.</p>
<p id="p-0012" num="0011">Another innovative aspect of the subject matter described here can be implemented as a computer storage medium encoded with a computer program, the program including instructions that when executed by data processing apparatus cause the data processing apparatus to perform operations including accessing multiple pixels that represent a digital image in an RGB color space, receiving input to adjust a darkness of the digital image, in response to receiving the input, adjusting the contrast and the brightness of color space values of the accessed multiple pixels based on a darkness of the digital image to generate a processed shadow image, and combining the processed shadow image with a processed highlight image. Adjusting to generate the processed shadow image includes adjusting the contrast and the brightness of dark regions of the digital image differently from the contrast and the brightness of light regions. Adjusting to generate the processed highlight image includes adjusting the contrast and the brightness of the color space values of the accessed multiple pixels based on a lightness of the digital image.</p>
<p id="p-0013" num="0012">This, and other aspects, can include one or more of the following features. Adjusting the contrast and the brightness of dark regions of the digital image differently from the contrast and the brightness of light regions can include increasing a darkness of the dark regions while decreasing a brightness of the light regions. Adjusting a contrast and a brightness of color space values of the accessed plurality of pixels based on a darkness of the digital image can include adjusting a red component, a blue component, and a green component of a color space value of each pixel according to a gamma function based on a blur, a color scale value, and user input defining an adjustment. The blur can be a Gaussian blur having a pixel radius. The pixel radius can include a maximum of five pixels. The color space value can range from 0.5 to 2.0. The operations can include identifying a region in the digital image that represents a particular tone based on hue angles and brightness values of pixels included in the region, and modifying the user input to modulate the gamma function in the identified region. The operations can include generating the processed highlight image by adjusting the contrast and the brightness of the color space values of the accessed plurality of pixels based on the lightness of the digital image. Combining the processed shadow image with the processed highlight image can include combining using a luminance mask.</p>
<p id="p-0014" num="0013">A further innovative aspect of the subject matter described here can be implemented as a system including data processing apparatus, and a computer storage medium encoded with a computer program, the program including instructions that when executed by the data processing apparatus cause the data processing apparatus to perform operations including accessing a plurality of pixels that represent a digital image in an RGB color space, receiving input to adjust a lightness of the digital image, in response to receiving the input, adjusting a contrast and a brightness of color space values of the plurality of pixels based on a lightness of the digital image to generate a processed highlight image, wherein the adjusting comprises adjusting the contrast and the brightness of light regions of the digital image differently from the contrast of dark regions, and combining the processed light image with a processed shadow image generated by adjusting the contrast and the brightness of the color space values of the plurality of pixels based on a darkness of the digital image.</p>
<p id="p-0015" num="0014">This, and other aspects, can include one or more of the following features. Adjusting the contrast and the brightness of light regions of the digital image differently from the contrast of dark regions can include increasing a brightness of the bright regions while decreasing a darkness of the dark regions. Adjusting the contrast and the brightness of color space values of the plurality of pixels based on the lightness of the digital image can include adjusting a red component, a blue component, and a green component of a color space value of each pixel according to a gamma function based on a blur, a color scale value, and a user input defining an adjustment, and according to a linear segment. The operations can further include generating the processed shadow image by adjusting the contrast and the brightness of the color space values of the plurality of pixels based on the darkness of the digital image. Combining the processed highlight image with the processed shadow image can include combining using a luminance mask.</p>
<p id="p-0016" num="0015">Another innovative aspect of the subject matter described here can be implemented as a computer-implemented method. Multiple pixels that represent a digital image in an RGB color space are accessed. Input to adjust a darkness or a brightness of the digital image is received. A region in the digital image that represents a particular tone is identified based on hue angles and brightness values of pixels included in the region. The darkness or the brightness of the identified region in the digital image is adjusted based on a common adjustment value determined for all pixels in the identified region. The darkness or the brightness of remaining regions in the digital image is adjusted based on a corresponding adjustment value determined for each pixel in the remaining regions. An output image is generated based on adjusting the darkness or the brightness of the identified region and based on adjusting the darkness or the brightness of the remaining regions.</p>
<p id="p-0017" num="0016">This, and other aspects, can include one or more of the following features. For each pixel in the digital image, corresponding adjustment values by which a red component, a blue component, and a green component of each pixel are to be adjusted can be determined. The corresponding values can be based on the received input. The common adjustment value can be determined from the corresponding values. The common adjustment value can be one of a maximum of, a minimum of, an average of, or a median of the corresponding adjustment values. Receiving input to adjust a darkness or a brightness of the digital image can include receiving a first input to adjust a contrast and a brightness of color space values of the multiple pixels based on the darkness of the image, and receiving a second input to adjust a contrast a brightness of color space values of the multiple pixels based on the lightness of the image. The darkness of the digital image can be adjusted in response to receiving the first input. The brightness of the digital image can be adjusted in response to receiving the second input.</p>
<p id="p-0018" num="0017">Particular implementations of the subject matter described in this specification may be implemented so as to realize one or more of the following potential advantages. Image processing performed by implementing the techniques described in this document may improve visibility of detail in dark areas of an image (shadow regions) as well as the light areas of the image (highlight regions) based upon user input. Implementations of the techniques described here may take into account different regions of color space to create more pleasing results for different colors. For example, the detail of shadows can be increased differently for skin tone colors relative to green foliage, such that the skin in an image does not become over-saturated nor too red, while grass and leaves appear colorful.</p>
<p id="p-0019" num="0018">When processing an image to adjust a contrast and brightness based upon a darkness of the image, the entire image, and not merely dark regions, can be processed. Nevertheless, dark regions of the image can be processed differently from light regions. Similarly, when adjusting an entire image based upon a lightness of the image, light regions of the image can be processed differently from dark regions. Because the image is processed based upon darkness and lightness in respective, separate paths, image processing can be implemented using a small kernel. Also, the speed of processing can be increased.</p>
<p id="p-0020" num="0019">Further, image processing can be performed by RGB-sensitive scaling of user input parameters. When adjusting the image based upon a lightness of the image, extended range image data can be recovered while controlling highlight adjustment. Furthermore, more global information, such as face detection, location, camera meta-data, dark noise estimation, gender, foliage, water, cloud detection, and the like, can be taken into account for each pixel when adjusting the image.</p>
<p id="p-0021" num="0020">Details of one or more implementations of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and potential advantages of the subject matter will become apparent from the description, the drawings, and the claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. 1A and 1B</figref> show example image processing systems.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 2</figref> shows a flowchart of images generated during image processing.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 3A-H</figref> show example images generated during image processing.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. 4-7</figref> are flowcharts of example processes for generating a processed output image.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0026" num="0025">Like reference numbers and designations in the various drawings indicate like elements.</p>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. 1A and 1B</figref> show example image processing systems. <figref idref="DRAWINGS">FIG. 1A</figref>, in particular, shows an image processing system that includes a computer system <b>100</b> that is coupled to a display device <b>105</b> and one or more input devices including a keyboard <b>107</b>, a mouse <b>109</b>, and a touch-sensitive input device <b>111</b>. The computer system <b>100</b> (for example, a desktop computer, a laptop computer, a personal digital assistant, a tablet computer, a smart phone, and the like) can include data processing apparatus <b>115</b> that execute computer software instructions stored on a computer-readable storage medium <b>120</b> to implement an image processing computer software application that can process a digital image to improve the visibility of detail in the dark areas of the image (shadow region) as well as the light areas of the image (highlight region) based upon user input. In addition, when implementing the image processing application, the computer system <b>100</b> can process different regions of color space differently (for example, regions displaying human skin differently from regions displaying foliage).</p>
<p id="p-0028" num="0027">The computer system <b>100</b> can display a user interface <b>125</b> in the display device <b>105</b>, and, within the user interface <b>125</b>, a digital image <b>130</b> and user-selectable controls (for example, a first slide control <b>132</b> and a second slide control <b>134</b>). Using the input devices (the keyboard <b>107</b>, the mouse <b>109</b>, the touch-sensitive input device <b>111</b>, or combinations of them), a user can provide input to adjust a darkness and a lightness of the digital image <b>130</b>. In response to receiving and based upon the input, the computer system <b>100</b> can adjust a contrast and a brightness of the digital image as described below.</p>
<p id="p-0029" num="0028">In some implementations, the computer system <b>100</b> can receive multiple pixels that represent the digital image <b>130</b> in an RGB color space. The computer system <b>100</b> can process the received pixels to adjust a contrast and a brightness of color space values of the multiple pixels based on a darkness of the digital image, and separately based on a lightness of the digital image. For example, the computer system <b>100</b> can process the received pixels in response to receiving user input to adjust the darkness and the lightness through the first control <b>132</b> and the second control <b>134</b>, respectively. After processing, the computer system <b>100</b> can combine the processed pixels to generate a processed output image <b>135</b> (<figref idref="DRAWINGS">FIG. 1B</figref>).</p>
<p id="p-0030" num="0029">An example of image processing to adjust a contrast and a brightness of a digital image was proposed in the literature, and is shown in (2).</p>
<p id="p-0031" num="0030">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>R</mi>
          <mi>processed</mi>
        </msub>
        <mo>=</mo>
        <msup>
          <mi>R</mi>
          <msup>
            <mn>2</mn>
            <mrow>
              <mo>(</mo>
              <mfrac>
                <mrow>
                  <mn>0.5</mn>
                  <mo>-</mo>
                  <mrow>
                    <mo>(</mo>
                    <mfrac>
                      <mn>1</mn>
                      <mi>blur</mi>
                    </mfrac>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mn>0.5</mn>
              </mfrac>
              <mo>)</mo>
            </mrow>
          </msup>
        </msup>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>2</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0032" num="0031">By implementing (2), the computer system <b>100</b> can create a per-pixel gamma value as a function of a low-passed or blurred input image. The computer system <b>100</b>, in such implementations, can generate a gamma value for each pixel in the range of 0.5-2.0 based on the blurred version of the image. In some implementations, the computer system <b>100</b> implements image processing step, s and generates intermediate processed images as described with reference to FIGS. <b>2</b> and <b>3</b>A-<b>3</b>H.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 2</figref> shows a flowchart of images generated during image processing. In some implementations, the computer system <b>100</b> receives a digital image, for example, the digital image shown in <figref idref="DRAWINGS">FIG. 3A</figref>, represented by multiple pixels. For example, the computer system <b>100</b> can store the digital image <b>130</b> in a non-linear encoding. As a first step in image processing, the computer system <b>100</b> can linearize the encoding and generate a digital image <b>200</b> represented by a linear encoding in the RGB color space.</p>
<p id="p-0034" num="0033">The computer system <b>100</b> can receive a first user input to adjust a darkness and a second user input to adjust a lightness of the digital image <b>130</b>, for example, through the first slide control <b>132</b> and the second slide control <b>134</b>. In particular, the system <b>100</b> can receive the first and second user inputs in any order or simultaneously. Similarly, the computer system <b>100</b> can process the digital image <b>200</b> based on the input to adjust the darkness and then process the digital image <b>200</b> based on the input to adjust the lightness or vice versa. In some situations, the computer system <b>100</b> can implement both processing steps simultaneously, i.e., in parallel.</p>
<p id="p-0035" num="0034">In some implementations, upon receiving user input to adjust the darkness of the digital image <b>130</b>, the computer system <b>100</b> can process the digital image <b>200</b> to generate a blurred image <b>205</b> by implementing (3).</p>
<p id="p-0036" num="0035">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>R</mi>
          <mi>processed</mi>
        </msub>
        <mo>=</mo>
        <msup>
          <mi>R</mi>
          <msup>
            <mn>2</mn>
            <mrow>
              <mo>(</mo>
              <mfrac>
                <mrow>
                  <mi>userInput</mi>
                  <mo>-</mo>
                  <mrow>
                    <mo>(</mo>
                    <mfrac>
                      <mi>blur</mi>
                      <mi>colorScale</mi>
                    </mfrac>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mn>0.5</mn>
              </mfrac>
              <mo>)</mo>
            </mrow>
          </msup>
        </msup>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0037" num="0036">In particular, the computer system <b>100</b> implements (3) for each pixel in the digital image <b>200</b>. In (3), R is a red component of a color scale value of a pixel in digital image <b>200</b>, and R<sub>processed </sub>is the processed red component of the color scale value of the pixel in the blurred image <b>205</b>. The term &#x201c;userinput&#x201d; refers to the user input to adjust a darkness of the digital image <b>130</b>. The term &#x201c;colorScale/0.5&#x201d; represents half the color scale, but alternatively can range between 0.4 and 2.0 of the color scale. The term &#x201c;blur&#x201d; refers to a local area surrounding each processed pixel. The local area can include a range of pixels, for example, between two and six pixels, or, alternatively, fewer than two (for example, zero pixels) or more than six pixels (for example, fifty pixels).</p>
<p id="p-0038" num="0037">The computer system <b>100</b> determines similar values for the green component (G<sub>processed</sub>) and for the blue component (B<sub>processed</sub>) from the green component and the blue component of a color scale value of a pixel, respectively. Thus, the computer system <b>100</b> adjusts a red component, a blue component, and a green component of a color space value of each pixel according to a gamma function based on a blur, a color scale value, and a user input defining an adjustment to the contrast and the brightness based on the darkness of the digital image <b>200</b>. To do so, the computer system <b>100</b> generates a blurred image <b>205</b> that includes as many pixels as the digital image <b>200</b> such that a pixel in the blurred image <b>205</b> is a blurred version of a corresponding pixel in the digital image <b>200</b>. The computer system <b>100</b> then generates a shadow image <b>210</b> based on the digital image <b>200</b>, the blurred image <b>215</b>, and the user input <b>215</b>.</p>
<p id="p-0039" num="0038">In this manner, the computer system <b>100</b> implements (3) to adjust the contrast and the brightness of the color space values of dark regions of the digital image <b>200</b> differently from the contrast and brightness of the color space values of light regions of the digital image <b>200</b>. To adjust the contrast and brightness of the dark regions differently from those of the light regions, the computer system <b>100</b> increases a contrast and a brightness of the dark regions while decreasing those of the light regions.</p>
<p id="p-0040" num="0039">In some implementations, the user input can range from &#x2212;0.5 to +0.5, or alternatively from &#x2212;1.0 to +1.0. A user input of 0 indicates no adjustment, an input less than 0 indicates an input to adjust based on a darkness of the image, and an input greater than 0 is an input to lift shadows to see more detail in the image. For most of these values, the per-pixel gamma will be less than 1.0 and will result in the shadows being lifted. For some values, however, the per-pixel gamma value will be above 1.0, and will result in the shadows being darkened. Such a situation can be useful for low-contrast scenes (for example, foggy images) to which adding shadows may be preferable. Because the computer system <b>100</b> processes the digital image separately to adjust a darkness and a brightness, low gamma values are acceptable at this stage. The computer system <b>100</b> can use a small blur kernel (for example, a Gaussian blur with a 5-pixel radius) and preserve local contrast.</p>
<p id="p-0041" num="0040">In some implementations, the computer system <b>100</b> can execute operations to increase a colorfulness and brightness of shadow regions in the digital image <b>200</b>. For example, the computer system <b>100</b> can increase a brightness of green color in foliage. If, for example, an image includes green color representing foliage and blue color representing the sky, a common increase in brightness of both colors may not be desirable. Instead, it may be desirable to emphasize the blue sky but keep the green region relatively darker to increase contrast in foliage. The computer system <b>100</b> can execute operations to achieve this result by implementing (4).</p>
<p id="p-0042" num="0041">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>userInput</mi>
        <mo>=</mo>
        <mrow>
          <mi>userInput</mi>
          <mo>&#xb7;</mo>
          <mrow>
            <mo>(</mo>
            <mfrac>
              <mrow>
                <mrow>
                  <mi>rS</mi>
                  <mo>&#xb7;</mo>
                  <mi>inputR</mi>
                </mrow>
                <mo>+</mo>
                <mrow>
                  <mi>gS</mi>
                  <mo>&#xb7;</mo>
                  <mi>inputG</mi>
                </mrow>
                <mo>+</mo>
                <mrow>
                  <mi>bS</mi>
                  <mo>&#xb7;</mo>
                  <mi>inputB</mi>
                </mrow>
              </mrow>
              <mrow>
                <mi>inputR</mi>
                <mo>+</mo>
                <mi>inputG</mi>
                <mo>+</mo>
                <mi>inputB</mi>
                <mo>+</mo>
                <mi>&#x25b;</mi>
              </mrow>
            </mfrac>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0043" num="0042">In (4), inputR, inputG, and inputB are the red component, the green component, and the blue component of the RGB color space values, respectively, rS, gS, and bS are color space scalar values, and eps is a small number to prevent division by zero and to anchor the black pixels in the image. Example values of rS, gS, and bS could be 1.0, 0.8, and 1.1, respectively, which would increase the color of the blue region while not saturating the color of the green region. In alternative implementations, the computer system <b>100</b> can use a more specific hue-angle based scaling factor. In such implementations, the computer system <b>100</b> can scale the user input as a function of hue angle.</p>
<p id="p-0044" num="0043">Thus, by implementing (4), the computer system <b>100</b> can augment the user input value with color-specific tuning. To do so, the computer system <b>100</b> can identify a region in the digital image <b>200</b> that represents a particular tone based on hue angles and brightness values of pixels included in the region, and adjust the user input to modulate the gamma function in the identified region. In particular, the computer system <b>100</b> adjusts a red component of a color space value of each pixel based on a determined corresponding value, and similarly adjusts a green component and a blue component. Each corresponding value represents a scaling factor by which the computer system <b>100</b> modifies the user input for each of the red component, the green component, and the blue component of a color space value of each pixel, when implementing (3).</p>
<p id="p-0045" num="0044">In some situations, doing so can result in oversaturation of colors. For example, regions that represent skin tones can be depicted as red rather than pink. In such situations, the computer system <b>100</b> can determine corresponding scaling factors for each of the red, green, and blue components, but use a common value, selected from among the scaling factors, as &#x201c;userinput&#x201d; in (3). In some implementations, the computer system <b>100</b> can determine the same exponent for all three color-channels, and calculate the exponent as shown in (5a) and (5b).</p>
<p id="p-0046" num="0045">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>exp</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mi>RGB</mi>
        </mrow>
        <mo>=</mo>
        <msup>
          <mn>2</mn>
          <mrow>
            <mo>(</mo>
            <mfrac>
              <mrow>
                <mi>userInput</mi>
                <mo>&#x2062;</mo>
                <mfrac>
                  <mi>blur</mi>
                  <mi>colorScale</mi>
                </mfrac>
              </mrow>
              <mn>0.5</mn>
            </mfrac>
            <mo>)</mo>
          </mrow>
        </msup>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>5</mn>
          <mo>&#x2062;</mo>
          <mi>a</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>exp</mi>
        <mo>=</mo>
        <mrow>
          <mi>min</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <mi>exp</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <mi>R</mi>
              </mrow>
              <mo>,</mo>
              <mrow>
                <mi>exp</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <mi>G</mi>
              </mrow>
              <mo>,</mo>
              <mrow>
                <mi>exp</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <mi>B</mi>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>5</mn>
          <mo>&#x2062;</mo>
          <mi>b</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0047" num="0046">By implementing (5a) and (5b), the computer system <b>100</b> determines a corresponding value for the red component, the green component, and the blue component of all color scale values of the pixels included in the digital image <b>200</b>. The computer system <b>100</b> then exponentiates each of these values, and determines a common value from the exponentiated values. For each pixel, the computer system <b>100</b> can select the common value as one of a maximum of, a minimum of, a median of, or an average of the exponentiated red component, green component, and blue component of the color scale values, or variations of them.</p>
<p id="p-0048" num="0047">In this manner, in response to receiving input to adjust the darkness of the digital image, the computer system <b>100</b> determines corresponding values by which a red component, a green component, and a blue component of each pixel are to be adjusted. The computer system <b>100</b> determines a common adjustment values from the corresponding values, and adjusts a color space value of each pixel based on the common adjustment value.</p>
<p id="p-0049" num="0048">In some situations, implementing (5a) and (5b) results in skin-tone values of an output image being more pleasing relative to not doing so. However, in such situations, the non-skin regions may be too de-saturated. In some implementations, the computer system <b>100</b> can generate the shadow image <b>210</b> by using individual RGB gamma values for non-skin regions, and identical RGB gamma values for the skin region. To do so, the computer system <b>100</b> can create a skin mask calculated using hue angles and brightness values, or, alternatively, implement an RGB calculation shown in (6a)-(6h).</p>
<p id="p-0050" num="0049">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>gray</mi>
          <mo>=</mo>
          <mfrac>
            <mrow>
              <mi>inputR</mi>
              <mo>+</mo>
              <mi>inputG</mi>
              <mo>+</mo>
              <mi>inputB</mi>
            </mrow>
            <mn>3.0</mn>
          </mfrac>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>a</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>m</mi>
          <mo>=</mo>
          <mfrac>
            <mn>1.0</mn>
            <mrow>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mn>1.0</mn>
                  <mo>-</mo>
                  <mi>gray</mi>
                </mrow>
                <mo>)</mo>
              </mrow>
              <mo>&#xb7;</mo>
              <mi>gray</mi>
            </mrow>
          </mfrac>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>b</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>gi</mi>
          <mo>=</mo>
          <mrow>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mn>1.0</mn>
                <mo>-</mo>
                <mi>gray</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
            <mo>&#xb7;</mo>
            <mi>m</mi>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>c</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>gii</mi>
          <mo>=</mo>
          <mrow>
            <mi>gray</mi>
            <mo>&#xb7;</mo>
            <mi>m</mi>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>d</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mstyle>
            <mspace width="4.4em" height="4.4ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <mrow>
            <mi>sat</mi>
            <mo>=</mo>
            <mrow>
              <mi>max</mi>
              <mo>&#x2061;</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mrow>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>inputR</mi>
                        <mo>-</mo>
                        <mi>gray</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                    <mo>&#xb7;</mo>
                    <mi>gi</mi>
                  </mrow>
                  <mo>,</mo>
                  <mrow>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>gray</mi>
                        <mo>-</mo>
                        <mi>inputR</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                    <mo>&#xb7;</mo>
                    <mi>gii</mi>
                  </mrow>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mo>&#x3c;</mo>
        <mn>0.99</mn>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>e</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>skin</mi>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mi>min</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mi>inputR</mi>
                    <mo>-</mo>
                    <mi>inputG</mi>
                  </mrow>
                  <mo>)</mo>
                </mrow>
                <mo>,</mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mrow>
                      <mn>2.0</mn>
                      <mo>&#xb7;</mo>
                      <mi>inputG</mi>
                    </mrow>
                    <mo>-</mo>
                    <mi>inputB</mi>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>&#xb7;</mo>
          <mn>4.0</mn>
          <mo>&#xb7;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mn>1.0</mn>
              <mo>-</mo>
              <mi>sat</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
          <mo>&#xb7;</mo>
          <mi>gi</mi>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>f</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>skin</mi>
          <mo>=</mo>
          <mrow>
            <mi>clamp</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>skin</mi>
                <mo>,</mo>
                <mn>0.0</mn>
                <mo>,</mo>
                <mn>1.0</mn>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>g</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mstyle>
          <mspace width="4.4em" height="4.4ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>skin</mi>
          <mo>=</mo>
          <mrow>
            <mn>0.15</mn>
            <mo>+</mo>
            <mrow>
              <mn>0.17</mn>
              <mo>&#xb7;</mo>
              <mi>skin</mi>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>6</mn>
          <mo>&#x2062;</mo>
          <mi>h</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0051" num="0050">By implementing (6a)-(6h), the computer system <b>100</b> can determine regions in a digital image <b>200</b> that are pink, and are likely skin. Upon determining such regions, the computer system <b>100</b> can implement a masking process (for example, a linear interpolation) to process regions of the digital image that represent skin tone differently from remaining regions.</p>
<p id="p-0052" num="0051">In some implementations, upon receiving the multiple pixels that represent the digital image <b>200</b> in the RGB color space, and upon receiving input to adjust the digital image, the computer system <b>100</b> can implement (6a)-(6h) to identify a region in the digital image that represents a particular tone (for example, skin tone) based on hue angles and brightness values of pixels included in the region. The computer system <b>100</b> can further adjust the darkness or the brightness of the identified region based on a common adjustment value determined for all pixels in the identified region, for example, by implementing (5) shown above. The computer system <b>100</b> can adjust the darkness or the brightness of remaining regions in the digital image based on a corresponding adjustment value determined for each pixel in the remaining region, for example, by implementing (3) shown above. The computer system <b>100</b> can then generate an output image based on the adjustments of the identified region and of the remaining regions by implementing (7) shown below. In this manner, the computer system <b>100</b> can then use the skin mask to modulate between the per-color-channel gamma value for non-skin colors and the uniform gamma value for skin tone by implementing (7) shown below.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>ex=mix(exp<i>RGB</i>,exp,skin)&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0053" num="0052">To determine the shadow image <b>210</b>, the computer system <b>100</b> implements (8) shown below, resulting in a per-pixel, per-color-channel, color space location-dependent gamma function.</p>
<p id="p-0054" num="0053">
<maths id="MATH-US-00006" num="00006">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>RGB</mi>
          <mrow>
            <mi>shadow</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
          </mrow>
        </msub>
        <mo>=</mo>
        <mfrac>
          <msup>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>colorScale</mi>
                <mo>&#xb7;</mo>
                <mi>RGB</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
            <mi>ex</mi>
          </msup>
          <mi>colorScale</mi>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>8</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0055" num="0054">In (8), &#x201c;colorScale&#x201d; values are the same as those in (3) and (5), and can be, for example, 0.5. An example of a digital image that the computer system <b>100</b> generates by implementing (8) is shown in <figref idref="DRAWINGS">FIG. 3B</figref>. In some implementations, as an alternative or in addition to modifying the image processing based on detecting skin tone, the computer system <b>100</b> can be configured to modify image processing based on factors including face detection, location, camera meta-data, dark noise estimation, gender, foliage, water, cloud detection, and the like in one or more regions in the digital image.</p>
<p id="p-0056" num="0055">From the digital image <b>200</b>, the computer system <b>100</b> can separately determine a highlight image <b>220</b>, for example, by determining a gamma correction with a linear segment, as shown below in (9a) and (9b). To do so, the computer system <b>100</b> can adjust the contrast and the brightness of the color space values of light regions of the digital image differently from the contrast and the brightness of the color space values of dark regions of the digital image. In particular, the computer system <b>100</b> can increase a contrast and a brightness of the light regions, and decrease a contrast and a brightness of the dark regions.</p>
<p id="p-0057" num="0056">By implementing (9a) and (9b), the computer system <b>100</b> can bring values greater than 1.0 back into the 0-1.0 range, which is useful for highlight recovery when dealing with raw and high-dynamic range imagery.</p>
<p id="p-0058" num="0057">
<maths id="MATH-US-00007" num="00007">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>d</mi>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mrow>
              <msup>
                <mi>e</mi>
                <mrow>
                  <mrow>
                    <mn>3.0</mn>
                    <mo>&#xb7;</mo>
                    <mi>highInput</mi>
                  </mrow>
                  <mo>-</mo>
                  <mn>6.0</mn>
                </mrow>
              </msup>
              <mo>-</mo>
              <mn>1.0</mn>
            </mrow>
            <mrow>
              <mrow>
                <mn>2.0</mn>
                <mo>&#xb7;</mo>
                <msup>
                  <mi>e</mi>
                  <mrow>
                    <mrow>
                      <mn>3.0</mn>
                      <mo>&#xb7;</mo>
                      <mi>highInput</mi>
                    </mrow>
                    <mo>-</mo>
                    <mn>6.0</mn>
                  </mrow>
                </msup>
              </mrow>
              <mo>+</mo>
              <mn>1.0</mn>
            </mrow>
          </mfrac>
          <mo>+</mo>
          <mn>1.5</mn>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>9</mn>
          <mo>&#x2062;</mo>
          <mi>a</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>RGB</mi>
          <mrow>
            <mi>highlight</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
          </mrow>
        </msub>
        <mo>=</mo>
        <msup>
          <mrow>
            <mo>(</mo>
            <mfrac>
              <mi>inputRGB</mi>
              <mi>d</mi>
            </mfrac>
            <mo>)</mo>
          </mrow>
          <mi>highInput</mi>
        </msup>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mn>9</mn>
          <mo>&#x2062;</mo>
          <mi>b</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0059" num="0058">In (9a) and (9b), &#x201c;highInput&#x201d; is the user input <b>225</b>, and can range between 1.25 and 2.5. In (9b), &#x201c;inputRGB&#x201d; is the input pixel red, green, and blue values. An example of a digital image that the computer system <b>100</b> generates by implementing (9a) and (9b) is shown in <figref idref="DRAWINGS">FIG. 3C</figref>.</p>
<p id="p-0060" num="0059">The computer system <b>100</b> can subsequently combine the shadow image <b>210</b> and the highlight image <b>210</b> to generate a processed output image <b>235</b> using, for example, a luminance mask, or grayscale mask as shown in (10).</p>
<p id="p-0061" num="0060">
<maths id="MATH-US-00008" num="00008">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>blurLum</mi>
        <mo>=</mo>
        <msqrt>
          <mrow>
            <mrow>
              <mn>0.297377</mn>
              <mo>&#xb7;</mo>
              <mi>inputR</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mn>0.6273491</mn>
              <mo>&#xb7;</mo>
              <mi>inputG</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mn>0.0752741</mn>
              <mo>&#xb7;</mo>
              <mi>inputB</mi>
            </mrow>
          </mrow>
        </msqrt>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>10</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0062" num="0061">Alternatively, the computer system <b>100</b> can determine the mask using the channel maximum, as shown in (11).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>blueLum=max(input<i>R</i>,input<i>G</i>,inpug<i>B</i>)&#x2003;&#x2003;(11)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0063" num="0062">An example of a digital image that the computer system <b>100</b> generates by implementing (11) is shown in <figref idref="DRAWINGS">FIG. 3D</figref>. In some implementations, the computer system <b>100</b> can threshold the mask using a threshold function, which can create a smooth gradient on the mask as shown in (12).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>origPercent=&#x221a;{square root over (smoothstep(0.0,0.1+0.5*shadAmt,blurLum))}&#x2003;&#x2003;(12)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0064" num="0063">The computer system <b>100</b> can further multiply the smooth mask by its inverse so that black and white points of the image do not get impacted.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>origPercent=origPercent&#xd7;(1&#x2212;origPercent)&#x2003;&#x2003;(13)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0065" num="0064">An example of a digital image that the computer system <b>100</b> generates by implementing (13) is shown in <figref idref="DRAWINGS">FIG. 3E</figref>. The computer system <b>100</b> can then blend the shadow image back with the original using origPercent as the mixing function, as shown in (14).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Shad=mix(shad,orig,origPercent)&#x2003;&#x2003;(14)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0066" num="0065">An example of a digital image that the computer system <b>100</b> generates by implementing (14) is shown in <figref idref="DRAWINGS">FIG. 3F</figref>. In this manner, the computer system <b>100</b> can determine a smooth mask for the shadow image <b>210</b> and apply the mask to the shadow image <b>210</b>. The computer system <b>100</b> can similarly determine a smooth mask for the highlight image <b>220</b>, for example, by implementing (15) and (16).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>origPercent=1&#x2212;smoothstep(0.2,0.8,blurLum)&#x2003;&#x2003;(15)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>high=mix(high,orig,origPercent)&#x2003;&#x2003;(16)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0067" num="0066">An example of a digital image that the computer system <b>100</b> generates by implementing (16) is shown in <figref idref="DRAWINGS">FIG. 3G</figref>. The computer system <b>100</b> can merge the processed highlight image back together with the blurred luminance, as shown in (17).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>final=mix(shad,high,blurLum)&#x2003;&#x2003;(17)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0068" num="0067">In some implementations, the computer system <b>100</b> can additionally add mid-contrast back into the image by calculating another gray image based upon the corrected final image, as shown in (18).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>gray=0.3&#xd7;final<i>R+</i>0.6&#xd7;final<i>G+</i>0.1&#xd7;final<i>B</i>&#x2003;&#x2003;(18)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0069" num="0068">The computer system can then adjust contrast by moving the final pixel value away from 0.5, for example, by implementing (19).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>final=final+(final&#x2212;0.5)&#xd7;effect&#xd7;gray&#x2003;&#x2003;(19)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0070" num="0069">In (19), &#x201c;effect&#x201d; can be a user input, a function of the inputShadAmount or a function of the gray value as well. In this manner, the computer system <b>100</b> can generate a final processed image, such as the digital image shown in <figref idref="DRAWINGS">FIG. 3H</figref>.</p>
<p id="p-0071" num="0070">In some implementations, the computer system <b>100</b> can store each of the intermediate images (for example, the blurred image <b>205</b>, the shadow image <b>210</b>, the highlight image <b>220</b>, the image shown in each of <figref idref="DRAWINGS">FIGS. 3A-3F</figref>, and the like) generated during the image processing for subsequent access. Alternatively, or in addition, the computer system <b>100</b> may not permanently store all of the intermediate images. In some implementations, the computer system <b>100</b> can implement the aforementioned image processing on a region of a received digital image, for example, a region identified by user input.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 4</figref> shows a flowchart of an example process <b>400</b> to generate a processed output image. The process can be performed by a system of one or more computers configured to perform particular operations or actions by virtue of having software, firmware, hardware, or a combination of them installed on the system that in operation causes or cause the system to perform the actions. One or more computer programs can be configured to perform particular operations or actions by virtue of including instructions that, when executed by data processing apparatus, cause the apparatus to perform the process <b>400</b>. The process <b>400</b> receives pixels representing a digital image (step <b>402</b>). The process <b>400</b> receives input to adjust darkness of the image (step <b>404</b>). The process <b>400</b> receives input to adjust brightness of the image (step <b>406</b>). The process <b>400</b> combines the adjusted images (step <b>408</b>). The process <b>400</b> generates a processed output image (step <b>410</b>).</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. 5</figref> shows a flowchart of an example process <b>500</b> to generate a processed output image. The process <b>500</b> receives pixels representing digital image (step <b>502</b>). The process receives input to adjust a darkness of the digital image (step <b>504</b>). The process adjusts a contrast and a brightness of dark regions differently from contrast and brightness of light regions (step <b>506</b>).</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 6</figref> shows a flowchart of an example process <b>600</b> to generate a processed output image. The process <b>600</b> receives pixels representing a digital image (step <b>602</b>). The process <b>600</b> receives input to adjust a lightness of the digital image (step <b>604</b>). The process <b>600</b> adjusts a contrast and a brightness of light regions differently from contrast and brightness of dark regions (step <b>506</b>).</p>
<p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. 7</figref> shows a flowchart of an example process <b>700</b> to generate a processed output image. The process <b>700</b> receives multiple pixels that represent a digital image (step <b>702</b>). The process <b>700</b> receives input to adjust the digital image (step <b>704</b>). The process <b>700</b> identifies a region that represents a particular tone (step <b>706</b>). The process <b>700</b> adjusts the identified region based on a common value determined for all pixels in the identified region (step <b>708</b>). The process <b>700</b> adjusts remaining regions based on a corresponding value determined for each pixel in the remaining regions (step <b>710</b>). The process <b>700</b> generates an output image based on adjustments to the identified region and the remaining regions (step <b>712</b>).</p>
<p id="p-0076" num="0075">Implementations of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Implementations of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on computer storage medium for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. A computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Moreover, while a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially-generated propagated signal. The computer storage medium can also be, or be included in, one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).</p>
<p id="p-0077" num="0076">The operations described in this specification can be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.</p>
<p id="p-0078" num="0077">The term &#x201c;data processing apparatus&#x201d; encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple ones, or combinations, of the foregoing The apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment can realize various different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.</p>
<p id="p-0079" num="0078">A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.</p>
<p id="p-0080" num="0079">The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).</p>
<p id="p-0081" num="0080">Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a universal serial bus (USB) flash drive), to name just a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.</p>
<p id="p-0082" num="0081">To provide for interaction with a user, implementations of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a web browser on a user's client device in response to requests received from the web browser.</p>
<p id="p-0083" num="0082">While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features specific to particular implementations of particular inventions. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely, various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.</p>
<p id="p-0084" num="0083">Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the implementations described above should not be understood as requiring such separation in all implementations, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.</p>
<p id="p-0085" num="0084">Thus, particular implementations of the subject matter have been described. Other implementations are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain implementations, multitasking and parallel processing may be advantageous.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08624915-20140107-M00001.NB">
<img id="EMI-M00001" he="7.79mm" wi="76.20mm" file="US08624915-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08624915-20140107-M00002.NB">
<img id="EMI-M00002" he="7.79mm" wi="76.20mm" file="US08624915-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08624915-20140107-M00003.NB">
<img id="EMI-M00003" he="7.03mm" wi="76.20mm" file="US08624915-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US08624915-20140107-M00004.NB">
<img id="EMI-M00004" he="11.26mm" wi="76.20mm" file="US08624915-20140107-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US08624915-20140107-M00005.NB">
<img id="EMI-M00005" he="48.34mm" wi="76.20mm" file="US08624915-20140107-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00006" nb-file="US08624915-20140107-M00006.NB">
<img id="EMI-M00006" he="6.35mm" wi="76.20mm" file="US08624915-20140107-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00007" nb-file="US08624915-20140107-M00007.NB">
<img id="EMI-M00007" he="15.49mm" wi="76.20mm" file="US08624915-20140107-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00008" nb-file="US08624915-20140107-M00008.NB">
<img id="EMI-M00008" he="7.79mm" wi="76.20mm" file="US08624915-20140107-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method performed by one or more data processing apparatuses, the method comprising:
<claim-text>accessing a plurality of pixels that represent a digital image;</claim-text>
<claim-text>processing each of the accessed plurality of pixels based on a darkness of the digital image to adjust a contrast and a brightness of color space values of the plurality of pixels, resulting in a first plurality of processed pixels, wherein processing the accessed plurality of pixels based on a darkness of the digital image comprises:
<claim-text>adjusting a red component, a blue component, and a green component of a color space value of each pixel in the accessed plurality of pixels according to a gamma function based on at least one of the following: a blur, a color scale value, and a user input defining an adjustment to the contrast and the brightness based on the darkness;</claim-text>
<claim-text>increasing a contrast and a brightness of dark regions; and decreasing a contrast and a brightness of light regions;</claim-text>
</claim-text>
<claim-text>processing each of the accessed plurality of pixels based on a lightness of the digital image to adjust a contrast and a brightness of the color space values of the plurality of pixels resulting in a second plurality of processed pixels, wherein processing the accessed plurality of pixels based on a darkness of the digital image comprises:
<claim-text>adjusting a red component, a blue component, and a green component of a color space value of each pixel in the accessed plurality of pixels according to a gamma fuction based on at least one of the following: a blur, a color scale value, and a user input defining an adjustment to the contrast and the brightness based on the lightness;</claim-text>
<claim-text>increasing a contrast and a brightness of light regions; and</claim-text>
<claim-text>decreasing a contrast and a brightness of dark regions; and</claim-text>
</claim-text>
<claim-text>combining the first plurality of processed pixels and the second plurality of processed pixels to generate a processed output image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the blur is a Gaussian blur with a 2-pixel radius.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the color scale value is within a range of 0.4-2.0.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>identifying a region in the digital image that represents a particular tone based on hue angles and brightness values of pixels included in the region; and</claim-text>
<claim-text>adjusting the user input to modulate the gamma function in the identified region.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>receiving input to adjust the darkness of the digital image; and</claim-text>
<claim-text>in response to receiving the input, determining corresponding values by which a red component, a blue component, and a green component of each pixel are to be adjusted based on the received input.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein processing each of the accessed plurality of pixels to adjust a contrast and the brightness of color space values of the plurality of pixels based on the darkness of the digital image further comprises:
<claim-text>adjusting a red component of a color space value of each pixel based on a determined corresponding value;</claim-text>
<claim-text>adjusting a blue component of a color space value of each pixel based on a determined corresponding value; and</claim-text>
<claim-text>adjusting a green component of a color space value of each pixel based on a determined corresponding value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein processing each of the accessed plurality of pixels to adjust a contrast and a brightness of color space values of the plurality of pixels based on the darkness of the digital image further comprises:
<claim-text>determining a common adjustment value from the corresponding values; and</claim-text>
<claim-text>adjusting a color space value of each pixel based on the common adjustment value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the common value is one of a maximum of, a minimum of, an average of, or a median of the corresponding values.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein processing each of the accessed plurality of pixels to adjust the contrast and the brightness of color space values of the plurality of pixels based on the lightness of the digital image further comprises adjusting a red component, a blue component, and a green component of a color space value of each pixel according to a gamma function and according to a linear segment.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein combining the first plurality of processed pixels and the second plurality of processed pixels comprises combining using a luminance mask.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein processing based on the darkness of the image and processing based on the lightness of the image are order independent.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A computer storage medium encoded with a computer program, the program comprising instructions that when executed by one or more data processing apparatuses cause the one or more data processing apparatus to perform operations comprising:
<claim-text>accessing a plurality of pixels that represent a digital image;</claim-text>
<claim-text>receiving input to adjust a darkness of the digital image;</claim-text>
<claim-text>in response to receiving the input, adjusting the contrast and the brightness of color space values of the accessed plurality of pixels based on a darkness of the digital image to generate a processed shadow image, wherein the adjusting comprises adjusting the contrast and the brightness of dark regions of the digital image differently from the contrast and the brightness of light regions; and</claim-text>
<claim-text>combining the processed shadow image with a processed highlight image generated by adjusting the contrast and the brightness of the color space values of the accessed plurality of pixels based on a lightness of the digital image,</claim-text>
<claim-text>wherein adjusting the contrast and the brightness of the dark regions of the digital image differently from the contrast and the brightness of light regions comprises:
<claim-text>adjusting a red component, a blue component, and a green component of a color space value of each pixel in the accessed plurality of pixels according to a gamma fuction based on at least one of the following: a blur, a color scale value, and a user input defining an adjustment to the contrast and the brightness based on the darkness; and</claim-text>
<claim-text>increasing a contrast and a brightness of dark regions while decreasing a contrast and a brightness of light regions.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the blur is a Gaussian blur having a pixel radius.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The medium of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the pixel radius includes a maximum of five pixels.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The medium of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the color scale value ranges from 0.4 to 2.0.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The medium of <claim-ref idref="CLM-00013">claim 13</claim-ref>, the operations further comprising:
<claim-text>identifying a region in the digital image that represents a particular tone based on hue angles and brightness values of pixels included in the region; and</claim-text>
<claim-text>modifying the user input to modulate the gamma function in the identified region.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising generating the processed highlight image by adjusting the contrast and the brightness of the color space values of the accessed plurality of pixels based on the lightness of the digital image.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein combining the processed shadow image with the processed highlight image comprises combining using a luminance mask.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A system comprising:
<claim-text>one or more data processing apparatuses; and</claim-text>
<claim-text>a computer storage medium encoded with a computer program, the program comprising instructions that when executed by the one or more data processing apparatuses cause the one or more data processing apparatuses to perform operations comprising:</claim-text>
<claim-text>accessing a plurality of pixels that represent a digital image;</claim-text>
<claim-text>receiving input to adjust a lightness of the digital image;</claim-text>
<claim-text>in response to receiving the input, adjusting a contrast and a brightness of color space values of the plurality of pixels based on a lightness of the digital image to generate a processed highlight image, wherein the adjusting comprises adjusting the contrast and the brightness of light regions of the digital image differently from the contrast of dark regions; and</claim-text>
<claim-text>combining the processed light image with a processed shadow image generated by adjusting the contrast and the brightness of the color space values of the plurality of pixels based on a darkness of the digital image,</claim-text>
<claim-text>wherein adjusting the contrast and the brightness of the light regions of the digital image differently from the contrast and the brightness of dark regions comprises:
<claim-text>adjusting a red component, a blue component, and a green component of a color space value of each pixel in the accessed plurality of pixels according to a gamma fuction based on at least one of the following: a blur, a color scale value, and a user input defining an adjustment to the contrast and the brightness based on the darkness; and</claim-text>
<claim-text>increasing a contrast and a brightness of light regions while decreasing a contrast and a brightness of dark regions.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein adjusting the contrast and the brightness of color space values of the plurality of pixels based on the lightness of the digital image further comprises adjusting a red component, a blue component, and a green component of a color space value of each pixel according to a gamma function and according to a linear segment.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, the operations further comprising generating the processed shadow image by adjusting the contrast and the brightness of the color space values of the plurality of pixels based on the darkness of the digital image.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein combining the processed highlight image with the processed shadow image comprises combining using a luminance mask.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. A computer-implemented method comprising:
<claim-text>accessing a plurality of pixels that represent a digital image;</claim-text>
<claim-text>receiving input to adjust a darkness or a brightness of the digital image;</claim-text>
<claim-text>identifying a region in the digital image that represents a particular tone based on hue angles and brightness values of pixels included in the region;</claim-text>
<claim-text>adjusting the darkness or the brightness of the identified region in the digital image based on a common adjustment value determined for all pixels in the identified region;</claim-text>
<claim-text>adjusting the darkness or the brightness of remaining regions in the digital image based on a corresponding adjustment value determined for each pixel in the remaining regions; and</claim-text>
<claim-text>generating an output image by combining the adjusted identified region in the digital image and the adjusted remaining regions in the digital image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising determining, for each pixel in the digital image, corresponding adjustment values by which a red component, a blue component, and a green component of each pixel are to be adjusted, wherein the corresponding values are based on the received input.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising determining the common adjustment value from the corresponding values.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method of <claim-ref idref="CLM-00025">claim 25</claim-ref>, wherein the common adjustment value is one of a maximum of, a minimum of, an average of, or a median of the corresponding adjustment values.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein receiving input to adjust a darkness or a brightness of the digital image comprises:
<claim-text>receiving a first input to adjust a contrast and a brightness of color space values of the plurality of pixels based on the darkness of the image; and</claim-text>
<claim-text>receiving a second input to adjust a contrast and a brightness of color space values of the plurality of pixels based on the lightness of the image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The method of <claim-ref idref="CLM-00027">claim 27</claim-ref>, further comprising:
<claim-text>adjusting the darkness of the digital image in response to receiving the first input; and</claim-text>
<claim-text>adjusting the brightness of the digital image in response to receiving the second input. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
