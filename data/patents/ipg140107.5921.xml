<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627030-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627030</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11936249</doc-number>
<date>20071107</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1356</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>13</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>13</main-group>
<subgroup>28</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>711163</main-classification>
<further-classification>711130</further-classification>
<further-classification>711E12091</further-classification>
</classification-national>
<invention-title id="d2e53">Late lock acquire mechanism for hardware lock elision (HLE)</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4763249</doc-number>
<kind>A</kind>
<name>Bomba et al.</name>
<date>19880800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713600</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6560776</doc-number>
<kind>B1</kind>
<name>Breggin et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717176</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2003/0079094</doc-number>
<kind>A1</kind>
<name>Rajwar et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711150</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2004/0215933</doc-number>
<kind>A1</kind>
<name>Nguyen et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>712200</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2008/0115042</doc-number>
<kind>A1</kind>
<name>Akkary et al.</name>
<date>20080500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714806</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00006">
<othercit>Office Action Received for Chinese Patent Application No. 200810190835.2 mailed on Aug. 22, 2011, 19 Pages of Office Action including 3 pages of English translation.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>24</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>711150</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711130</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>712 E905</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090119459</doc-number>
<kind>A1</kind>
<date>20090507</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Akkary</last-name>
<first-name>Haitham</first-name>
<address>
<city>Portland</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Rajwar</last-name>
<first-name>Ravi</first-name>
<address>
<city>Portland</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Srinivasan</last-name>
<first-name>Srikanth T.</first-name>
<address>
<city>Portland</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Akkary</last-name>
<first-name>Haitham</first-name>
<address>
<city>Portland</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Rajwar</last-name>
<first-name>Ravi</first-name>
<address>
<city>Portland</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Srinivasan</last-name>
<first-name>Srikanth T.</first-name>
<address>
<city>Portland</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Blakely, Sokoloff, Taylor &#x26; Zafman LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Intel Corporation</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bragdon</last-name>
<first-name>Reginald</first-name>
<department>2189</department>
</primary-examiner>
<assistant-examiner>
<last-name>Cardwell</last-name>
<first-name>Eric S</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and apparatus for a late lock acquire mechanism is herein described. In response to detecting a late-lock acquire event, such as expiration of a timer, a full cachet set, and an irrevocable event, a late-lock acquire may be initiated. Consecutive critical sections are stalled until a late-lock acquire is completed utilizing fields of access buffer entries associated with consecutive critical section operations.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="200.66mm" wi="158.75mm" file="US08627030-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="201.17mm" wi="158.75mm" file="US08627030-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="194.56mm" wi="158.75mm" file="US08627030-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="213.44mm" wi="158.75mm" file="US08627030-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="158.75mm" wi="51.65mm" file="US08627030-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="158.75mm" wi="105.24mm" file="US08627030-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD</heading>
<p id="p-0002" num="0001">This invention relates to the field of processor execution and, in particular, to acquiring locks for execution of sections of code.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Advances in semi-conductor processing and logic design have permitted an increase in the amount of logic that may be present on integrated circuit devices. As a result, computer system configurations have evolved from a single or multiple integrated circuits in a system to multiple cores and multiple logical processors present on individual integrated circuits. A processor or integrated circuit typically comprises a single processor die, where the processor die may include any number of cores or logical processors.</p>
<p id="p-0004" num="0003">The ever increasing number of cores and logical processors on integrated circuits enables more software threads to be executed. However, the increase in the number of software threads that may be executed simultaneously has created problems with synchronizing data shared among the software threads. One common solution to accessing shared data in multiple core or multiple logical processor systems comprises the use of locks to guarantee mutual exclusion across multiple accesses to shared data. However, the ever increasing ability to execute multiple software threads potentially results in false contention and a serialization of execution.</p>
<p id="p-0005" num="0004">For example, consider a hash table holding shared data. With a lock system, a programmer may lock the entire hash table, allowing one thread to access the entire hash table. However, throughput and performance of other threads is potentially adversely affected, as they are unable to access any entries in the hash table, until the lock is released. Alternatively, each entry in the hash table may be locked. However, this increases programming complexity, as programmers have to account for more locks within a hashtable.</p>
<p id="p-0006" num="0005">Another data synchronization technique includes the use of transactional memory (TM). Often transactional execution includes speculatively executing a grouping of a plurality of micro-operations, operations, or instructions. In the example above, both threads execute within the hash table, and their accesses are monitored/tracked. If both threads access/alter the same entry, one of the transactions may be aborted to resolve the conflict. However, some applications may not take advantage of transactional memory programming, as a result, a hardware data synchronization technique, which is often referred to Hardware Lock Elision (HLE), is utilized to elide locks to obtain synchronization benefits similar to transactional memory.</p>
<p id="p-0007" num="0006">As a result, HLE is able to detect and predict critical sections of code. However, during execution of a critical section for transactional memory or through HLE, when HLE prediction is incorrect, tentative access tracking overflows memory, or an irrevocable event is encountered, often, the critical section is aborted and restarted. Yet, aborting a critical section potentially wastes the execution cycles for the operation performed before the abort.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007">The present invention is illustrated by way of example and not intended to be limited by the figures of the accompanying drawings.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an embodiment of a multi-processing element processor including a late-lock acquire mechanism.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an embodiment of logic to perform late-lock acquire for a critical section.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>illustrates an embodiment of a flow diagram for a method of performing a late-lock acquire for a current critical section.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 3</figref><i>b </i>illustrates an embodiment of a flow diagram for a method of stalling subsequent critical section operations during a late-lock acquire for a current critical section.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref><i>c </i>illustrates another embodiment of a flow diagram for a method of stalling subsequent critical section operations during a late-lock acquire for a current critical section.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0014" num="0013">In the following description, numerous specific details are set forth such as examples of specific hardware support for Hardware Lock Elision (HLE), specific tracking/meta-data methods, specific types of local/memory in processors, and specific types of memory accesses and locations, etc. in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art that these specific details need not be employed to practice the present invention. In other instances, well known components or methods, such as coding of critical sections in software, demarcation of critical sections, specific multi-core and multi-threaded processor architectures, interrupt generation/handling, cache organizations, and specific operational details of microprocessors, have not been described in detail in order to avoid unnecessarily obscuring the present invention.</p>
<p id="p-0015" num="0014">The method and apparatus described herein are for a late-lock acquire scheme during execution of critical sections. Specifically, the late-lock acquire scheme is primarily discussed in reference to multi-core processor computer systems. However, the methods and apparatus for a late-lock acquire scheme are not so limited, as they may be implemented on or in association with any integrated circuit device or system, such as cell phones, personal digital assistants, embedded controllers, mobile platforms, desktop platforms, and server platforms, as well as in conjunction with other resources, such as hardware/software threads, that execute critical sections. Furthermore, the late-lock acquire scheme is primarily also discussed in reference to execution of critical sections during Hardware Lock Elision (HLE). Yet, a late-lock acquire may be utilized during any critical section execution scheme, such as during transactional execution.</p>
<p id="p-0016" num="0015">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, an embodiment of multi-core processor <b>100</b>, which is capable of performing late-lock acquire for a critical section is illustrated. As shown, physical processor <b>100</b> includes any number of processing elements. A processing element refers to a thread, a process, a context, a logical processor, a hardware thread, a core, and/or any processing element, which potentially shares access to resources of the processor, such as reservation units, execution units, pipelines, and higher level caches/memory. A physical processor typically refers to an integrated circuit, which may include any number of processing elements, such as cores or hardware threads.</p>
<p id="p-0017" num="0016">A core often refers to logic located on an integrated circuit capable of maintaining an independent architectural state wherein each independently maintained architectural state is associated with at least some dedicated execution resources. In contrast to cores, a hardware thread typically refers to any logic located on an integrated circuit capable of maintaining an independent architectural state wherein the independently maintained architectural states share access to execution resources. Physical processor <b>100</b>, as illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, includes two cores, core <b>101</b> and <b>102</b>, which share access to higher level cache <b>110</b>. In addition, core <b>101</b> includes two hardware threads <b>110</b><i>a </i>and <b>110</b><i>b</i>, while core <b>102</b> includes two hardware threads <b>102</b><i>a </i>and <b>102</b><i>b</i>. Therefore, software entities, such as an operating system or application, potentially view processor <b>100</b> as four separate processors, while processor <b>100</b> is capable of executing four software threads.</p>
<p id="p-0018" num="0017">As can be seen, when certain resources are shared and others are dedicated to an architectural state, the line between the nomenclature of a hardware thread and core overlaps. Yet often, a core and a hardware thread are viewed by an operating system as individual logical processors, where the operating system is able to individually schedule operations on each logical processor. Therefore, a processing element includes any of the aforementioned entities capable of maintaining a context, such as cores, threads, hardware threads, logical processors, virtual machines, or other processing resources.</p>
<p id="p-0019" num="0018">In one embodiment, processor <b>100</b> is a multi-core processor capable of executing multiple threads in parallel. Here, a first thread is associated with architecture state registers <b>101</b><i>a</i>, a second thread is associated with architecture state registers <b>111</b><i>b</i>, a third thread is associated with architecture state registers <b>102</b><i>a</i>, and a fourth thread is associated with architecture state registers <b>102</b><i>b</i>. Reference to processing elements in processor <b>100</b>, in one embodiment, includes reference to cores <b>101</b> and <b>102</b>, as well as threads <b>101</b><i>a</i>, <b>101</b><i>b</i>, <b>102</b><i>a</i>, and <b>102</b><i>b</i>. In another embodiment, a processing element refers to elements at the same level in a hierarchy of processing domain. For example, core <b>101</b> and <b>102</b> are in the same domain level, threads <b>101</b><i>a </i>and <b>101</b><i>b </i>are on the same domain level within core <b>101</b>, and threads <b>101</b><i>a</i>, <b>101</b><i>b</i>, <b>102</b><i>a</i>, and <b>102</b><i>b </i>are in the same domain level within cores <b>101</b> and <b>102</b>.</p>
<p id="p-0020" num="0019">Although processor <b>100</b> may include asymmetric cores, i.e. cores with different configurations, functional units, and/or logic, symmetric cores are illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. As a result, core <b>102</b>, which is illustrated as identical to core <b>101</b>, will not be discussed in detail to avoid obscuring the discussion.</p>
<p id="p-0021" num="0020">As illustrated, architecture state registers <b>101</b><i>a </i>are replicated in architecture state registers <b>101</b><i>b</i>, so individual architecture states/contexts are capable of being stored for processing element <b>101</b><i>a </i>and processing element <b>101</b><i>b</i>. Other smaller resources, such as instruction pointers and renaming logic in rename allocater logic <b>130</b> may also be replicated for threads <b>101</b><i>a </i>and <b>101</b><i>b</i>. Some resources, such as re-order buffers in reorder/retirement unit <b>135</b>, ILTB <b>120</b>, load/store buffers <b>180</b>, and queues may be shared through partitioning. Other resources, such as general purpose internal registers, page-table base register, low-level data-cache and data-TLB <b>110</b>, execution unit(s) <b>140</b>, and out-of-order unit <b>135</b> are potentially fully shared. Note that a thread may be implemented in any manner of sharing resources of core <b>101</b>.</p>
<p id="p-0022" num="0021">Bus interface module <b>105</b> is to communicate with devices external to processor <b>100</b>, such as system memory <b>175</b>, a chipset, a northbridge, or other integrated circuit. Memory <b>175</b> may be dedicated to processor <b>100</b> or shared with other devices in a system. Examples of memory <b>175</b> includes dynamic random access memory (DRAM), static RAM (SRAM), non-volatile memory (NV memory), and long-term storage.</p>
<p id="p-0023" num="0022">Typically bus interface unit <b>105</b> includes input/output (I/O) buffers to transmit and receive bus signals on interconnect <b>170</b>. Examples of interconnect <b>170</b> include a Gunning Transceiver Logic (GTL) bus, a GTL+bus, a double data rate (DDR) bus, a pumped bus, a differential bus, a cache coherent bus, a point-to-point bus, a multi-drop bus or other known interconnect implementing any known bus protocol. Bus interface unit <b>105</b> as shown is also to communicate with higher level cache <b>110</b>.</p>
<p id="p-0024" num="0023">Higher-level or further-out cache <b>110</b> is to cache recently fetched and/or operated on elements. Note that higher-level or further-out refers to cache levels increasing or getting further way from the execution unit(s). In one embodiment, higher-level cache <b>110</b> is a second-level data cache. However, higher level cache <b>110</b> is not so limited, as it may be or include an instruction cache, which may also be referred to as a trace cache. A trace cache may instead be coupled after decoder <b>125</b> to store recently decoded traces. Module <b>120</b> also potentially includes a branch target buffer to predict branches to be executed/taken and an instruction-translation buffer (I-TLB) to store address translation entries for instructions. Here, a processor capable of speculative execution potentially prefetches and speculatively executes predicted branches.</p>
<p id="p-0025" num="0024">Decode module <b>125</b> is coupled to fetch unit <b>120</b> to decode fetched elements. In one embodiment, processor <b>100</b> is associated with an Instruction Set Architecture (ISA), which defines/specifies instructions executable on processor <b>100</b>. Here, often machine code instructions recognized by the ISA include a portion of the instruction referred to as an opcode, which references/specifies an instruction or operation to be performed.</p>
<p id="p-0026" num="0025">In one example, allocator and renamer block <b>130</b> includes an allocator to reserve resources, such as register files to store instruction processing results. However, threads <b>101</b><i>a </i>and <b>101</b><i>b </i>are potentially capable of out-of-order execution, where allocator and renamer block <b>130</b> also reserves other resources, such as reorder buffers to track instruction results. Unit <b>130</b> may also include a register renamer to rename program/instruction reference registers to other registers internal to processor <b>100</b>.</p>
<p id="p-0027" num="0026">Reorder/retirement unit <b>135</b> includes components, such as the reorder buffers mentioned above and load/store buffers <b>180</b> to support out-of-order execution and later retirement of instructions executed out-of-order. Buffers <b>180</b>, in one embodiment, are capable of holding fields/values to indicate associated memory accesses are to be blocked/stalled until a late-lock acquire in progress for a critical section is completed. Although buffers <b>180</b> are shown located in one area, buffers <b>180</b> and late-lock acquire logic are not so limited. In fact, tracking logic <b>180</b> may be distributed through processor <b>100</b>, as well as associated with any portion of the front or back end of a processor pipeline.</p>
<p id="p-0028" num="0027">Scheduler and execution unit(s) block <b>140</b>, in one embodiment, includes a scheduler unit to schedule instructions/operation on execution units. In fact, instructions/operations are potentially scheduled on execution units according to their type availability. For example, a floating point instruction is scheduled on a port of an execution unit that has an available floating point execution unit. Register files associated with the execution units are also included to store information instruction processing results. Exemplary execution units include a floating point execution unit, an integer execution unit, a jump execution unit, a load execution unit, a store execution unit, and other known execution units.</p>
<p id="p-0029" num="0028">Note from above, that as illustrated, processor <b>100</b> is capable of executing at least four software threads. In addition, in one embodiment, processor <b>100</b> is capable of transactional execution. Transactional execution usually includes grouping a plurality of instructions or operations into a transaction, atomic section of code, or a critical section of code. In some cases, use of the word instruction refers to a macro-instruction which is made up of a plurality of operations. In a processor, a transaction is typically executed speculatively and committed upon the end of the transaction. A pendency of a transaction, as used herein, refers to a transaction that has begun execution and has not been committed or aborted, i.e. pending. Usually, while a transaction is still pending, locations loaded from and written to within a memory are tracked.</p>
<p id="p-0030" num="0029">Upon successful validation of those memory locations, the transaction is committed and updates made during the transaction are made globally visible. However, if the transaction is invalidated during its pendency, the transaction is restarted without making the updates globally visible. Often, software demarcation is included in code to identify a transaction. For example, transactions may be grouped by instructions indicating a beginning of a transaction and an end of a transaction. However, transactional execution often utilizes programmers or compilers to insert the beginning and ending instructions for a transaction.</p>
<p id="p-0031" num="0030">Therefore, in one embodiment, processor <b>100</b> is capable of hardware lock elision (HLE), where hardware is able to elide locks for critical sections and execute them simultaneously. Here, pre-compiled binaries without transactional support or newly compiled binaries utilizing lock programming are capable of benefiting from simultaneous execution through support of HLE. As a result of providing transparent compatibility, HLE often includes hardware to detect critical sections and to track memory accesses. In fact, since locks ensuring exclusion to data are elided, memory accesses may be tracked in a similar manner as during execution of transactions. Consequently, the late-lock acquire scheme discussed herein may be utilized during transactional execution, HLE, another memory access tracking scheme, or a combination thereof. Therefore, discussion of execution of critical sections below potentially includes reference to a critical section of a transaction or a critical section detected by HLE.</p>
<p id="p-0032" num="0031">In one embodiment, a memory device being accessed is utilized to track accesses from a critical section. For example, lower level data cache <b>150</b> is utilized to track accesses from critical sections; either associated with transactional execution or HLE. Cache <b>150</b> is to store recently accessed elements, such as data operands, which are potentially held in memory coherency states, such as modified, exclusive, shared, and invalid (MESI) states. Cache <b>150</b> may be organized as a fully associative, a set associative, a direct mapped, or other known cache organization. Although not illustrated, a D-TLB may be associated with cache <b>150</b> to store recent virtual/linear to physical address translations.</p>
<p id="p-0033" num="0032">As illustrated, lines <b>151</b>, <b>152</b>, and <b>153</b> include portions and fields, such as portion <b>151</b><i>a </i>and field <b>151</b><i>b</i>. In one embodiment fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>and portions <b>151</b><i>a</i>, <b>152</b><i>a</i>, and <b>153</b><i>a </i>are part of a same memory array making up lines <b>151</b>, <b>152</b>, and <b>153</b>. In another embodiment, fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>are part of a separate array to be accessed through separate dedicated ports from lines <b>151</b><i>a</i>, <b>152</b><i>a</i>, and <b>153</b><i>a</i>. However, even when fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>are part of a separate array, fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>are associated with portions <b>151</b><i>a</i>, <b>152</b><i>a</i>, and <b>153</b><i>a</i>, respectively. As a result, when referring to line <b>151</b> of cache <b>150</b>, line <b>151</b> potentially includes portion <b>151</b><i>a</i>, <b>152</b><i>b</i>, or a combination thereof. For example, when loading from line <b>151</b>, portion <b>151</b><i>a </i>may be loaded from. Additionally, when setting a tracking field to track a load from line <b>151</b>, field <b>151</b><i>b </i>is accessed.</p>
<p id="p-0034" num="0033">In one embodiment, lines, locations, blocks or words, such as lines <b>151</b><i>a</i>, <b>152</b><i>a</i>, and <b>153</b><i>a </i>are capable of storing multiple elements. An element refers to any instruction, operand, data operand, variable, or other grouping of logical values that is commonly stored in memory. As an example, cache line <b>151</b> stores four elements in portion <b>151</b><i>a</i>, such as four operands. The elements stored in cache line <b>151</b><i>a </i>may be in a packed or compressed state, as well as an uncompressed state. Moreover, elements may be stored in cache <b>150</b> aligned or unaligned with boundaries of lines, sets, or ways of cache <b>150</b>. Memory <b>150</b> will be discussed in more detail in reference to the exemplary embodiments below.</p>
<p id="p-0035" num="0034">Cache <b>150</b>, as well as other features and devices in processor <b>100</b>, store and/or operate on logic values. Often, the use of logic levels, logic values, or logical values is also referred to as 1's and 0's, which simply represents binary logic states. For example, a 1 refers to a high logic level and 0 refers to a low logic level. Other representations of values in computer systems have been used, such as decimal and hexadecimal representation of logical values or binary values. For example, take the decimal number 10, which is represented in binary values as 1010 and in hexadecimal as the letter A.</p>
<p id="p-0036" num="0035">In the embodiment illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, accesses to lines <b>151</b>, <b>152</b>, and <b>153</b> are tracked to support execution of critical sections. Accesses include operations, such as reads, writes, stores, loads, evictions, snoops, or other known accesses to memory locations. Access tracking fields, such as fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>are utilized to track accesses to their corresponding memory lines. For example, memory line/portion <b>151</b><i>a </i>is associated with corresponding tracking field <b>151</b><i>b</i>. Here, access tracking field <b>151</b><i>b </i>is associated with and corresponds to cache line <b>151</b><i>a</i>, as tracking field <b>151</b><i>b </i>includes bits that are part of cache line <b>151</b>. Association may be through physical placement, as illustrated, or other association, such as relating or mapping access tracking field <b>151</b><i>b </i>to memory line <b>151</b><i>a </i>or <b>151</b><i>b </i>in a hardware or software lookup table.</p>
<p id="p-0037" num="0036">As a simplified illustrative example, assume access tracking fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>include two transaction bits: a first read tracking bit and a second write tracking bit. In a default state, i.e. a first logical value, the first and second bits in access tracking fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>represent that cache lines <b>151</b>, <b>152</b>, and <b>153</b>, respectively, have not been accessed during execution of a critical section.</p>
<p id="p-0038" num="0037">Assume a load operation to load from line <b>151</b><i>a </i>is encountered in a critical section. The first read tracking bit is updated from the default state to a second accessed state, such as a second logical value. Here, the first read tracking bit holding the second logical value represents that a read/load from cache line <b>151</b> occurred during execution of the critical section. A store operation may be handled in a similar manner to update the first write tracking bit to indicate a store to a memory location occurred during execution of the critical section</p>
<p id="p-0039" num="0038">Consequently, if the tracking bits in field <b>151</b><i>b </i>associated with line <b>151</b> are checked, and the transaction bits represent the default state, then cache line <b>151</b> has not been accessed during a pendency of a critical section. Inversely, if the first read tracking bit represents the second value, then cache line <b>151</b> has been previously read during execution of a critical section. Furthermore, if the first write tracking bit represents the second value, then a write to line <b>151</b> occurred during a pendency of the critical section.</p>
<p id="p-0040" num="0039">Access fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>are potentially used to support any type of transactional execution or HLE. In one embodiment, where processor <b>100</b> is capable of hardware transactional execution, access fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>are to detect conflicts and perform validation. In another embodiment, where hardware transactional memory (HTM), software transactional memory (STM), or a hybrid thereof is utilized for transactional execution, access tracking fields <b>151</b><i>b</i>, <b>152</b><i>b</i>, and <b>153</b><i>b </i>provide similar tracking and validation functions.</p>
<p id="p-0041" num="0040">As a first example of how access fields, and specifically tracking bits, are potentially used to aid transactional execution, a co-pending application entitled, &#x201c;Hardware Acceleration for A Software Transactional Memory System,&#x201d; with Ser. No 11/349,787 discloses use of access fields/transaction bits to accelerate a STM. As another example, extending/virtualizing transactional memory including storing states of access fields/transaction tracking bits into a second memory are discussed in co-pending application entitled, &#x201c;Global Overflow Method for Virtualized Transactional Memory,&#x201d; with Ser. No. 11/479,902.</p>
<p id="p-0042" num="0041">Turning to <figref idref="DRAWINGS">FIG. 2</figref>, an embodiment of logic to initiate a late lock acquire for a critical section is illustrated. As stated above, a transaction is often demarcated by start transaction and end transaction instructions, which allows for easy identification of critical sections. However, HLE includes detecting/identifying and potentially predicting critical sections, eliding locks demarcating the critical sections, check pointing register states for roll-back upon critical section abort, tracking tentative memory updates, and detecting potential data conflicts. One difficulty in detecting/identifying critical sections is delineating between regular lock instructions, which do not define a critical section, and lock/lock release instructions that demarcate a critical section.</p>
<p id="p-0043" num="0042">In one embodiment, for HLE a critical section is defined by a lock instruction, i.e. a start critical section instruction, and a matching lock release instruction, i.e. and end critical section instruction. A lock instruction may include a load from an address location, i.e. checking if the lock is available, and a modify/write to the address location, i.e. an update to the address location to acquire the lock. A few examples of instructions that may be used as lock instructions include, a compare and exchange instruction, a bit test and set instruction, and an exchange and add instruction. In Intel's IA-32 and IA-64 instruction set, the aforementioned instructions include CMPXCHG, BTS, and XADD, as described in Intel&#xae; 64 and IA-32 instruction set documents discussed above.</p>
<p id="p-0044" num="0043">As an example, where predetermined instructions, such as CMPXCHG, BTS, and XADD are detected/recognized, detection logic and/or decode logic detects the instructions utilizing an opcode field or other field of the instruction. As an example, CMPXCHG is associated with the following opcodes: 0F B0/r, REX+0F B0/r, and REX.W+0F B1/r. In another embodiment, operations associated with an instruction are utilized to detect a lock instruction. For example, in x86 the following three memory micro-operations are often used to perform an atomic memory update indicating a potential lock instruction: (1) Load_Store_Intent (L_S_I) with opcode 0x63; (2) STA with opcode 0x76; and (3) STD with opcode 0x7F. Here, L_S_I obtains the memory location in exclusive ownership state and does a read of the memory location, while the STA and STD operations modify and write to the memory location. In other words, detection logic is searching for a load with store intent (L_S_I) to define the beginning of a critical section. Note that lock instructions may have any number of other non-memory, as well as other memory, operations associated with the read, write, modify memory operations.</p>
<p id="p-0045" num="0044">Often a stack, such as lock stack <b>205</b>, is utilized to hold an entry, such as entry <b>206</b>, which is associated with a lock instruction. Lock instruction entry (LIE) <b>206</b> may include any number of fields to store critical section related information, such as a lock instruction store physical address (LI Str PA), a lock instruction load value and load size, an unlocked value, a lock instruction store value and size, a locked value, a micro-operation count, a release flag, a late lock acquire flag, and a last instruction pointer field.</p>
<p id="p-0046" num="0045">Here, a lock release instruction corresponding to the lock instruction demarcates the end of a critical section. Detection logic searches for a lock release instruction that corresponds to the address modified by the lock instruction. Note that the address modified by the lock instruction may be held in LIE <b>206</b> on lock stack <b>205</b>. As a result, in one embodiment, a lock release instruction includes any store operation that sets the address modified by the corresponding lock instruction back to an unlocked value. An address referenced by an L_S_I instruction that is stored in lock stack <b>206</b> is compared against subsequent store instructions to detect a corresponding lock release instruction. More information on detecting and predicting critical sections may be found in a co-pending application entitled, &#x201c;A CRITICAL SECTION DETECTION AND PREDICTION MECHANISM FOR HARDWARE LOCK ELISION,&#x201d; with application Ser. No. 11/599,009.</p>
<p id="p-0047" num="0046">In other words, with HLE, in one embodiment, a critical section is demarcated by an L_S_I instruction and a corresponding lock release store instruction. Similarly, a critical section of a transaction is defined by a start transaction instruction and an end transaction instruction. Therefore, reference to a start critical section operation/instruction includes any instruction starting an HLE, transactional memory, or other critical section, while reference to an end critical section operation/instruction includes starting an HLE, transactional memory, or other critical section ending instructions.</p>
<p id="p-0048" num="0047">In one embodiment, an access buffer, such as a load buffer <b>220</b> and/or store buffer <b>280</b>, is to hold access entries associated with memory access operations. Each access buffer entry includes a block code field/portion. By default the block code field is to hold a first value, such as an unblocked value, to indicate a corresponding memory access operation is free to be dispatched. However, when a late-lock acquire is initiated for a current critical section, block code fields for buffer entries associated with a subsequent critical section are updated to a second value or blocked value to indicate the associated memory access operations are to be blocked/stalled.</p>
<p id="p-0049" num="0048">As illustrated, load buffer <b>220</b> includes a plurality of load buffer entries, such as entries <b>228</b>-<b>233</b>. When a load operation is encountered, a load buffer entry is created/stored in load buffer <b>220</b>. In one embodiment, load buffer <b>220</b> stores load buffer entries in program order, i.e. an order the instructions or operations are ordered in the program code. Here, youngest load buffer entry <b>228</b>, i.e. the most recently stored load buffer entry, is referenced by load tail pointer <b>235</b>. In contrast, oldest load buffer entry <b>230</b>, which is not a senior load, is referenced by load head pointer <b>236</b>.</p>
<p id="p-0050" num="0049">In an in-order execution processing element, load operations are executed in the program order stored in the load buffer. As a result, the oldest buffer entries are executed first, and load head pointer <b>236</b> is re-directed to the next oldest entry, such as entry <b>229</b>. In contrast, in an out-of-order machine, operations are executed in any order. However, entries are typically removed, i.e. de-allocated from the load buffer, in program order. As a result, load head pointer <b>236</b> and load tail pointer <b>235</b> operate in similar manner between the two types of execution.</p>
<p id="p-0051" num="0050">Load buffer entry <b>230</b> may include any type of information, such as a memory update value, a pointer value, a reference to an associated load operation, a reference to an address associated with the load operation, a value loaded from an address, and other associated load buffer values, flags, or references. Note that store buffer <b>280</b> may operate in a similar manner to load buffer <b>220</b>, as store buffer <b>280</b> is depicted as including entries <b>281</b>-<b>286</b> and block code field <b>283</b><i>a </i>for entry <b>283</b>. In addition, both load buffer <b>220</b> and store buffer <b>280</b> include senior load portions <b>250</b> and <b>280</b>, respectively. As a result, during transactional execution or HLE, pre-retire accesses, post-retire access, or a hybrid thereof may be used to update access tracking bits <b>271</b>-<b>273</b><i>a</i>-<i>b</i>. A co-pending application entitled, &#x201c;A POST-RETIRE SCHEME FOR TRACKING TENTATIVE ACCESSES DURING TRANSACTIONAL EXECUTION,&#x201d; with application Ser. No. 11/517,029 discusses in more detail utilization of post-retire access tracking for tentative memory accesses. In addition, a co-pending application entitled, &#x201c;A PRE-POST RETIRE HYBRID HARDWARE LOCK ELISION (HLE) SCHEME,&#x201d; with application Ser. No. 11/936,243 discusses a hybrid scheme for tentative access tracking.</p>
<p id="p-0052" num="0051">In one embodiment, each load buffer entry, such as entry <b>230</b>, includes a block code field, such as block code field <b>225</b>. As an example, assume a Load with Store Intention (LSI) operation associated with load entry <b>230</b> references a system memory address. Whether originally owned and located in cache line <b>271</b><i>a </i>or fetched in response to a miss to cache <b>270</b>, assume the element referenced by the system memory address currently resides in cache line <b>271</b><i>a</i>. In this example, cache line <b>271</b><i>a </i>holds a lock value for an address or range of addresses to be accessed during execution of a critical section. Therefore, in loading line <b>271</b><i>a </i>the lock value is read. Here, it is determined if the lock <b>271</b><i>a </i>holds a locked value or an unlocked value.</p>
<p id="p-0053" num="0052">When the load operation is allocated, memory update field <b>225</b> is, by default, updated to an unblocked value to indicate the load operation is able to be dispatched. Note that updating a bit, a value, or a field does not necessarily indicate a change to the bit, value or the field. For example, if field <b>225</b> is already set to a logical zero, then updating to a logical zero potentially includes re-writing a logical zero to field <b>225</b>, as well as no action to leave field <b>225</b> holding a logical zero.</p>
<p id="p-0054" num="0053">In contrast to the scenario discussed above, assume load entry <b>230</b> is associated with a subsequent critical section, such as a subsequent start critical section operation. In addition, a current critical section encounters a late-lock acquire event. Examples of a late-lock acquire event includes expiration of a timer, a cache set being full, and detecting an irrevocable event. More detail about late-lock acquire events is discussed below. In response to detecting a late-lock acquire event, field <b>225</b> is updated to a blocked value to block/stall the subsequent start critical section operation. Blocking and stalling of a subsequent start critical section operation, as well as blocking creation of a checkpoint for the subsequent critical section, is also discussed in more detail below.</p>
<p id="p-0055" num="0054">In one embodiment, the current critical section determines if a pre-condition is satisfied before initiating a late-lock acquire. A first example of a pre-condition includes waiting for pending fill buffer entries to be globally ordered. Here, when an access to cache <b>270</b> misses, i.e. the line is not present in a modified or exclusive state, then a fill buffer entry is allocated to receive the requested element upon retrieval. In one embodiment, global ordering includes any ordering of at least stores prior to a late-lock acquire store to ensure memory consistency, i.e. no memory ordering violations.</p>
<p id="p-0056" num="0055">Another example of a potential pre-condition for late-lock acquire includes determining a start critical section operation for the current critical section has updated a lock stack with a lock value. As discussed above, a start critical section operation may include a load/read to determine if the lock holds a locked or unlocked value and a store operation to perform a store of a lock value to the lock location. However, in HLE locks are elided and critical sections are tentatively executed. Therefore, the store, which may be associated with store entry <b>283</b> in store buffer <b>280</b>, is not performed to update line <b>271</b><i>a</i>, but rather is to update lock stack <b>205</b>. In fact, when a late-lock acquire is to be attempted, the lock value from lock stack entry <b>206</b> is used to update cache line <b>271</b><i>a </i>to the locked value. In other words, for HLE, the lock in cache line <b>271</b><i>a </i>is not acquired, until a late lock is performed by updating cache line <b>271</b><i>a </i>with a locked value from entry <b>206</b>.</p>
<p id="p-0057" num="0056">However, in one embodiment, stores, such as senior stores, are blocked/stalled in response to a late-lock acquire being initiated. Consequently, if the store to update lock stack entry <b>206</b> with the lock value has not been performed and a late-lock acquire is initiated, a dead-lock situation potentially occurs. Here, the store of the lock value to be used for the late-lock acquire has not been performed to lock stack <b>205</b> and that store is now stalled during late-lock acquire. In other words, the late lock acquire is waiting for the store to lock stack <b>205</b>, and the store is waiting on the late-lock acquire to complete before it updates lock stack <b>205</b>. Therefore, in one embodiment, a pre-condition includes determining the store to lock stack <b>205</b> with the lock value for the current critical section has been performed before initiating a late-lock acquire for the current critical section.</p>
<p id="p-0058" num="0057">As stated above, in one embodiment, during a late lock acquire for a current critical section, when a subsequent critical section is encountered, the subsequent critical section is stalled. In one embodiment, stalling a critical section includes blocking a start critical section operation, such as an LSI associated with load entry <b>230</b>, from creating a checkpoint. Often, a checkpoint is created when the LSI is retired. Therefore, during a late-lock acquire for a current critical section, a start subsequent critical section operation, such as the LSI associated with entry <b>230</b>, is to be blocked. Here, update logic <b>210</b> updates field <b>225</b> to a blocked value. In response to field <b>225</b> holding a blocked value, the LSI associated with entry <b>230</b> is not dispatched. As an example, a scheduler does not schedule the subsequent critical section LSI based on field <b>225</b> holding the blocked value. Note that update logic may set any number of fields similar to field <b>225</b> to a blocked value to block/stall any other operations.</p>
<p id="p-0059" num="0058">In one embodiment, a blocked value includes an identifier (ID). As a result, when a condition is satisfied to unblock an access operation, such as a load associated with entry <b>230</b>, the ID is broadcast by update logic <b>210</b>. All of the fields including the ID are release, i.e. unblocked. For example, when field <b>225</b> includes a blocked value, such as a MOB_BLOCK_CODE value, then in response to a store buffer draining, an ID is broadcast by update logic <b>210</b>. All load entries matching the ID are released, i.e. unblocked. As another example, field <b>225</b> may be an HLE_BLOCK_CODE field. Here, in response to a late-lock acquire completing, an ID is broadcast to entries in load buffer <b>220</b>, which releases/unblocks load entries matching the ID.</p>
<p id="p-0060" num="0059">As stated above, in one embodiment, during late-lock acquire senior stores are stalled. Here, logic, such as logic <b>225</b>, updates fields, such as field <b>283</b><i>a</i>, to a blocked value to stall senior stores. Here, race conditions between an end critical section operation, such as a lock release operation, and a late lock acquire operation are avoided. As an example, assume a lock is to be held in cache line <b>271</b><i>a</i>. A start critical section operation to acquire the lock is elided and the value to obtain the lock is stored in lock stack entry <b>206</b>. Next, a late-lock acquire event is detected. Here, a lock release store referencing an unlocked value would potentially contend with a late-lock acquire store to obtain the lock. As a result, senior store dispatches are stalled to avoid this potential contention.</p>
<p id="p-0061" num="0060">Note, that lock stack <b>205</b>, as illustrated, includes multiple stack entries. In one embodiment, lock stack <b>205</b> is capable of maintaining multiple entries for multiple critical sections, such as nested critical sections. As an example, when a late-lock acquire is to be performed for one critical section nested on stack <b>205</b>, a late-lock acquire is to be performed for the other critical sections referenced on stack <b>205</b>. To illustrate, a critical section referenced by LIE <b>206</b> is the innermost critical section nested within a second critical section referenced by LIE <b>207</b>. Additionally, the second critical section is nested within an outermost critical section associated with entry <b>208</b>.</p>
<p id="p-0062" num="0061">Here, when a late-lock acquire is to be performed for the innermost critical section, a late-lock acquire is also to be performed for the second and outermost critical sections. However, in another embodiment, when a lock release has been observed for the innermost critical section and a late-lock acquire is to be performed for the second critical section, then a late-lock acquire is to be performed for the outermost critical section and not the innermost critical section. In other words, a late-lock acquire is performed for all critical sections at a higher nested depth than the current late-lock acquire in this embodiment.</p>
<p id="p-0063" num="0062">Turning to <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>c </i>an embodiment of a flow diagram for a method of performing a late-lock acquire during hardware lock elision execution of a critical section is illustrated. Although, the flow diagram illustrates a flow in a reasonably linear fashion, flows may take place in any order in different embodiments. For example, determining if filter buffer entries are globally observed may occur after determining if a current critical section lock value has updated a lock stack.</p>
<p id="p-0064" num="0063">In flow <b>305</b>, a late-lock acquire event is detected. Here, a start critical section operation has already been detected and elided. For example, a lock value, which is to acquire a lock for the critical section, is stored in a lock instruction entry (LIE) on a lock stack. Examples of late-lock acquire events include expiration of a timer, a full cache set, and an irrevocable event.</p>
<p id="p-0065" num="0064">In one embodiment, expiration of a timer includes expiration of a watchdog timer. Here, a watchdog timer is initiated in response to detecting a load with store intention (LSI) operation and/or allocating an associated LIE. If a corresponding lock release instruction is not detected before the watchdog timer expires then a late-lock acquire is to be performed. In other words, upon predicting a critical section start and not discovering a corresponding end to the critical section in an amount of time, a lock is to be acquired.</p>
<p id="p-0066" num="0065">In another embodiment, a late-lock acquire includes a full cache set. For example, during execution of a critical section, accesses are tracked to detect data conflicts. However, a cache set may fill up with tentative accesses tracked during execution of a critical section. Therefore, a subsequent access may result in selection of a line of cache for eviction, where that line includes tracking information for a previous tentative access. As a result, a late-lock acquire may be initiated in response to the eviction indicating a full cache set.</p>
<p id="p-0067" num="0066">As yet another example, a late-lock acquire event may include detection of an irrevocable event, i.e. an event, process, or access that may not be easily undone. As a specific example, an I/O access often is irrevocable, as an access to an I/O device is difficult to undue. Therefore, in response to detecting an I/O access, a late-lock acquire is to be initiated.</p>
<p id="p-0068" num="0067">Next, in flow <b>310</b>, after detecting a late lock acquire, it is determined if previous fill buffer entries (FBEs) have been globally observed. If previous entries are not globally observed, then the late-lock acquire is stalled, i.e. not initiated, until previous FBEs are globally observed/ordered in flow <b>315</b>. In one embodiment, globally observed includes ordered in any manner, such as for dispatch on a bus/interconnect to be fulfilled. Also, as an example, stalling of a late-lock acquire includes updating a store buffer entry associated with a late-lock acquire store with a blocked value.</p>
<p id="p-0069" num="0068">As another potential pre-condition to late-lock acquire, it is determined in flow <b>320</b> if a current critical section lock value has updated the lock stack. As stated above, a start critical section instruction for a critical section often includes a store instruction to acquire a lock by storing a lock value to a lock location. However, during HLE the store is elided to the lock location and the lock value is recorded in a lock stack entry associated with the critical section. In one embodiment, senior stores are stalled, such as in flow <b>335</b>. However, as the lock value from the lock stack is to be utilized during a late-lock acquire, before senior stalls are stored, a late-lock acquire is stalled until the lock value updates the lock stack in flow <b>325</b>.</p>
<p id="p-0070" num="0069">Next, in flow <b>330</b> a late lock acquire is initiated. In one embodiment, initiating a late-lock acquire includes initiating a store operation to store the lock value from the lock stack to a lock location to acquire the lock. Note that a late-lock acquire may fail, as in flow <b>345</b>, and a critical section may be aborted and retried in flow <b>355</b>. For example, during a late-lock acquire, the lock may already be acquired by another processing element. Here, the late-lock acquire may spin until the lock is released and then acquire the lock when it is released by the other processing element. Alternatively, the late-lock acquire is immediately failed and the critical section is aborted/restarted.</p>
<p id="p-0071" num="0070">In one embodiment, senior stores are stalled during the late-lock acquire, as illustrated in flow <b>335</b>. Note that a late-lock acquire may complete successfully in flow <b>345</b>, without detecting a subsequent critical section; in which case, loads and senior stores are unblocked, while execution of the critical section with locks continues in flow <b>350</b>. However, if a subsequent critical section in flow <b>340</b>, then the flow continues through connection flow <b>360</b> to <figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>3</b><i>b. </i></p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>illustrates one embodiment of handling a subsequent critical section, such as a consecutive critical section, during a late-lock acquire for a critical section. Here, at flow <b>365</b> the subsequent start critical section operation is stalled. For example, a load with store intention operation is blocked in a load buffer until the late lock acquire is completed. <figref idref="DRAWINGS">FIG. 3</figref><i>b </i>illustrates another embodiment of handling a subsequent critical section during a late-lock acquire for a current critical section.</p>
<p id="p-0073" num="0072">In flow <b>370</b>, it is determined if a store buffer is drained. If the store buffer is not drained, then subsequent critical section loads are blocked until the store buffer is drained in flow <b>375</b>. In one embodiment, load buffer entries include a block_code field. When the block_code field holds a blocked value, the associated load is blocked from dispatch. Here, when the store buffer is drained, a value, such as an ID, is broadcast to the load buffer. Load buffer entries matching the value are unblocked/released for dispatch.</p>
<p id="p-0074" num="0073">After the store buffer is drained, it is determined if the subsequent critical section is a nested critical section in flow <b>380</b>. In one embodiment, if a lock release, i.e. a store to release a lock, for the current critical section is not detected when the store buffer is drained, then the subsequent critical section is a nested critical section. Here, no checkpoint is created, as the original checkpoint for the outermost critical section is potentially sufficient. In contrast, subsequent critical section accesses, such as a load with store intention access, is blocked until the late-lock acquire is complete. In one embodiment, stalling an L_S_I includes blocking the L_S_I from creating a checkpoint. Here, a block code field, similar to the block code field above may be utilized to block accesses. To illustrate, the first block code field is a MOB_BLOCK_CODE field and the second block code field is an HLE_BLOCK_CODE field. Similarly, when the late-lock acquire is completed, a value is broadcast to release/unblock the L_S_I.</p>
<p id="p-0075" num="0074">As illustrated above, critical sections may be executed utilizing transactional memory and/or hardware lock elision (HLE). Instead of aborting a critical section and wasting previous execution cycles by retrying the critical section, a late-lock acquire may be attempted to continue forward with execution of the critical section. However, to prevent deadlocks and invalid data, some conditions may be optionally imposed before initiating the late-lock acquire and during the late-lock acquire. For example, a subsequent consecutive critical section may be stalled until a late-lock acquire is completed for a current critical section to ensure coherence and data validity.</p>
<p id="p-0076" num="0075">The embodiments of methods, software, firmware or code set forth above may be implemented via instructions or code stored on a machine-accessible or machine readable medium which are executable by a processing element. A machine-accessible/readable medium includes any mechanism that provides (i.e., stores and/or transmits) information in a form readable by a machine, such as a computer or electronic system. For example, a machine-accessible medium includes random-access memory (RAM), such as static RAM (SRAM) or dynamic RAM (DRAM); read-only memory (ROM); magnetic or optical storage medium; and flash memory devices. As another example, a machine-accessible/readable medium includes any mechanism that receives, copies, stores, transmits, or otherwise manipulates electrical, optical, acoustical or other form of propagated signals (e.g., carrier waves, infrared signals, digital signals); etc including the embodiments of methods, software, firmware or code set forth above.</p>
<p id="p-0077" num="0076">Reference throughout this specification to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment is included in one embodiment of the present invention and is not required to be present in all discussed embodiments. Thus, the appearances of the phrases &#x201c;in one embodiment&#x201d; or &#x201c;in an embodiment&#x201d; in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.</p>
<p id="p-0078" num="0077">In the foregoing specification, a detailed description has been given with reference to specific exemplary embodiments. It will, however, be evident that various modifications and changes may be made without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are, accordingly, to be regarded as an illustrative sense rather than a restrictive sense. Furthermore, the foregoing use of embodiment and other exemplary language does not necessarily refer to the same embodiment or the same example, but may refer to different and distinct embodiments, as well as potentially the same embodiment.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An apparatus comprising:
<claim-text>decode logic adapted to recognize a lock instruction at a start of a critical section to obtain a lock for the critical section;</claim-text>
<claim-text>execution logic adapted to elide at least a part of the lock instruction that is to obtain the lock for the critical section, to store an address and a lock value referenced by the lock instruction in a lock entry, and to execute the critical section without the lock for the critical section; and</claim-text>
<claim-text>late-lock acquire logic coupled to the execution logic, the late-lock acquire logic being adapted to cause the execution logic to attempt to execute the at least the part of the lock instruction to obtain the lock for the critical section after the start of the critical section and without a restart of the critical section in response to encountering a late-lock acquire event during a pendancy of the critical section.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a cache memory associated with the execution logic, wherein the lock instruction is to reference the lock value and the address that is to be associated with a line of the cache memory, and wherein the late-lock acquire logic being adapted to cause the execution logic to attempt to execute the lock instruction to obtain the lock for the critical section comprises the late-lock acquire logic being adapted to cause the execution logic to execute a store of the lock value to the line of the cache memory that is associated with the address if the line of the cache memory represents that the lock for the critical section is available.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:
<claim-text>a storage area coupled to the execution logic and the late-lock acquire logic, the storage area being adapted to hold the address associated with lock value in a lock entry in a stack of lock entries; and</claim-text>
<claim-text>detection logic coupled to the decode logic and the execution logic, the detection logic being adapted to identify the at least the part of the lock instruction is to be elided and the cause the execution logic to elide the at least the part of the lock instruction, wherein the at least the part of the lock instruction comprises a store to the address of the lock value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein a store buffer associated with the execution logic is adapted to hold a store buffer entry associated with the store to the address of the lock value, the store buffer entry being adapted to hold a block code field, wherein update logic associated with the store buffer is adapted to update the block code field to a block value in response to encountering the late-lock acquire event.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The apparatus of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the update logic is further adapted to update the block code field to an unblocked value in response to the late-lock acquire logic causing the execution logic to successfully complete the attempt to execute the lock instruction to obtain the lock for the critical section.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the lock instruction includes a read modify write (RMW) instruction with a read operation of the RMW instruction including a Load with Store Intent (LSI) operation, and wherein the late-lock acquire logic causing the execution logic to successfully complete the attempt to execute the lock instruction to obtain the lock for the critical section comprises the late-lock acquire logic causing the execution logic to: execute the LSI operation to load a loaded value from the address; execute a modify operation to modify the loaded value from an available value to the lock value; and write the lock value to the address to obtain the lock.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the late-lock acquire event is selected from a group consisting of an expiration of a timer indicating no lock release instruction corresponding to the lock instruction has been detected by the decode logic in a predetermined amount of time, a detection of all lines in a cache set having speculative information, and an occurrence of an irrevocable event.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An apparatus comprising:
<claim-text>a processing element adapted to execute a current critical section and a subsequent critical section, wherein the processing element is further adapted to elide lock acquisition at the start of the current and subsequent critical sections;</claim-text>
<claim-text>an access buffer associated with the processing element, the access buffer adapted to hold an access entry associated with an access operation from the subsequent critical section, the access buffer entry being adapted to hold a block code field wherein the access operation is to be blocked from being dispatched in response to the access entry holding a block code field including a blocked value; and</claim-text>
<claim-text>update logic coupled to the access buffer, the updated logic being adapted to update the block code field to include the blocked value in response to the processing element attempting a late lock acquire for the current critical section without a restart of the current critical section after the processing element elides lock acquisition for the current critical section.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the block code field is adapted to hold, by default, an unblocked value, wherein the access operation is free to be dispatched in response to the block code field including the unblocked value.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein attempting the late-lock acquire for the current critical section is in response to detecting a late-lock acquire event during execution of the current critical section after the processing element elides lock acquisition for the current critical section, and wherein the late-lock acquire event is selected from a group consisting of a timer expiration event, a full cache set event, and an irrevocable event.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the update logic being adapted to update the block code field to include the blocked value in response to the processing element attempting a late lock acquire for the current critical section without a restart of the current critical section after the processing element elides lock acquisition for the current critical section comprises the updated logic being adapted to update the block code field to include the blocked value in response to detecting the late lock acquire event and further in response to fulfilling a late-lock acquire pre-condition.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the late-lock acquire pre-condition includes allowing a plurality of pending fill buffer entries to be globally observed.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the access buffer is a load buffer, and wherein the access operation includes a subsequent Load with Store Intention (L_S_I) operation to designate a start of the subsequent critical section.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising a lock-stack, which includes a lock stack entry associated with a current L_S_I operation to designate a start of the current critical section, wherein the late-lock acquire pre-condition includes waiting for a store operation associated with the current L_S_I for the current critical section to update the lock stack entry.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the blocked value includes an identifier, and wherein in response to completing the late lock acquire the update logic is further adapted to broadcast the identifier to the load buffer entry to update the block code field to an unblocked value.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A method comprising:
<claim-text>eliding a lock acquire operation at a start of a current critical section;</claim-text>
<claim-text>detecting a late-lock acquire event during execution of the current critical section;</claim-text>
<claim-text>initiating a late-lock acquire for the current critical section without restating the current critical section in response to detecting the late-lock acquire event during execution of the critical section;</claim-text>
<claim-text>stalling a subsequent lock acquire operation for a subsequent critical section in response to an access buffer holding a reference to the subsequent lock acquire operation and initiating the late lock acquire for the current critical section.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the late-lock acquire event is selected from a group comprising expiration of a watchdog timer, selecting a cache line for eviction that has tracked a memory access during execution of the critical section, and encountering an irrevocable event.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein initiating a late-lock acquire for the current critical section includes initiating a store of a lock value referencing a lock address, the lock value and address to be held in a lock stack entry associated with a reference to the lock acquire operation for the current critical section.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising stalling a plurality of senior stores held in a store buffer in response to initiating the late lock acquire for the current critical section, wherein the plurality of senior stores are unblocked to be dispatched in response to the store of the lock value referencing the lock address retiring.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein initiating the late-lock acquire for the critical section is further in response to globally observing a plurality of pending fill buffer entries and determining a lock stack entry associated with the critical section is updated with a lock value.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00020">claim 20</claim-ref>, further comprising:
<claim-text>blocking creation of a checkpoint associated with the subsequent critical section in response to stalling the subsequent lock acquire operation for the subsequent critical section.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising:
<claim-text>determining the subsequent critical section is not a nested critical section, wherein blocking creation of the checkpoint is further in response to determining the subsequent critical section is not a nested critical section.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein determining the subsequent critical is not a nested critical section comprises:
<claim-text>draining a store buffer in response to the store buffer holding store buffer entries;</claim-text>
<claim-text>in response to the store buffer being drained:
<claim-text>determining the subsequent critical section is a nested critical section responsive to not detecting a current end critical section operation; and</claim-text>
<claim-text>determining the subsequent critical section is not a nested critical section responsive to detecting a current end critical section operation.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the subsequent lock acquire operation for the subsequent critical section includes a Load with Store Intent (L_S_I) operation, and wherein blocking creation of the checkpoint associated with the subsequent critical section comprises:
<claim-text>blocking the L_S_I operation from being dispatched from a load buffer. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
