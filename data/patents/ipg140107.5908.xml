<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627017-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627017</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12346530</doc-number>
<date>20081230</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>668</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>12</main-group>
<subgroup>08</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>711145</main-classification>
<further-classification>711141</further-classification>
<further-classification>711E12002</further-classification>
</classification-national>
<invention-title id="d2e53">Read and write monitoring attributes in transactional memory (TM) systems</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5008813</doc-number>
<kind>A</kind>
<name>Crane et al.</name>
<date>19910400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5301294</doc-number>
<kind>A</kind>
<name>Kawai et al.</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6272602</doc-number>
<kind>B1</kind>
<name>Singhal et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6549996</doc-number>
<kind>B1</kind>
<name>Manry, IV et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2002/0087801</doc-number>
<kind>A1</kind>
<name>Bogin et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2003/0005219</doc-number>
<kind>A1</kind>
<name>Royer, Jr. et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2003/0014697</doc-number>
<kind>A1</kind>
<name>Hornung et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2003/0131030</doc-number>
<kind>A1</kind>
<name>Sebot et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>708209</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2003/0204670</doc-number>
<kind>A1</kind>
<name>Holt et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2003/0217234</doc-number>
<kind>A1</kind>
<name>Rowlands</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2004/0064651</doc-number>
<kind>A1</kind>
<name>Conway</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2004/0064813</doc-number>
<kind>A1</kind>
<name>Neiger et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2004/0093467</doc-number>
<kind>A1</kind>
<name>Shen et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2005/0060495</doc-number>
<kind>A1</kind>
<name>Pistoulet</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2005/0091459</doc-number>
<kind>A1</kind>
<name>Quach et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2005/0160230</doc-number>
<kind>A1</kind>
<name>Doren et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2005/0160232</doc-number>
<kind>A1</kind>
<name>Tierney et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2005/0246487</doc-number>
<kind>A1</kind>
<name>Ergan</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2006/0085611</doc-number>
<kind>A1</kind>
<name>Ikeda et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2006/0248259</doc-number>
<kind>A1</kind>
<name>Ryu et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2007/0061511</doc-number>
<kind>A1</kind>
<name>Faber</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2007/0239942</doc-number>
<kind>A1</kind>
<name>Rajwar et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2007/0245309</doc-number>
<kind>A1</kind>
<name>Gray et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2008/0040551</doc-number>
<kind>A1</kind>
<name>Gray et al.</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2008/0126647</doc-number>
<kind>A1</kind>
<name>Cometto et al.</name>
<date>20080500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710200</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2008/0209133</doc-number>
<kind>A1</kind>
<name>Ozer et al.</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2008/0229070</doc-number>
<kind>A1</kind>
<name>Charra et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>712207</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2008/0276304</doc-number>
<kind>A1</kind>
<name>Maffione et al.</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>726  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2008/0307169</doc-number>
<kind>A1</kind>
<name>Averill</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2008/0320254</doc-number>
<kind>A1</kind>
<name>Wingard et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711157</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2008/0320268</doc-number>
<kind>A1</kind>
<name>Wingard et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711202</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2009/0158006</doc-number>
<kind>A1</kind>
<name>Nam</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2010/0122073</doc-number>
<kind>A1</kind>
<name>Narayanaswamy et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2010/0332716</doc-number>
<kind>A1</kind>
<name>Sheaffer et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>2011/0302446</doc-number>
<kind>A1</kind>
<name>Becker-Szendy et al.</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>WO</country>
<doc-number>2010/077850</doc-number>
<kind>A2</kind>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>International Search Report and Written Opinion received for PCT Application No. PCT/US2009/068004, mailed on Jun. 22, 2010, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>International Preliminary Report on Patentability received for PCT Application No. PCT/US2009/068004, Mailed on Jul. 14, 2011, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>Office Action mailed May 25, 2012, Chinese Patent Application No. 200911000282.0, 7 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>Bruce Jacob et al., Memory Systems: Cache, DRAM, Disk. Sep. 2007, Morgan Kaufmann, 7 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>J. Eliot, B. Moss, and Antony L Hosking, &#x201c;Nested Transactional Memory: Model and Preliminary Architecture Sketches,&#x201d; Oct. 2005, ACM. SCOOL '05, 10 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>25</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>711118</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711141</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711151</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711152</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711145</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711E12002</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711E12026</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100169579</doc-number>
<kind>A1</kind>
<date>20100701</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sheaffer</last-name>
<first-name>Gad</first-name>
<address>
<city>Haifa</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Raikin</last-name>
<first-name>Shlomo</first-name>
<address>
<city>Geva Carmel</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Bassin</last-name>
<first-name>Vadim</first-name>
<address>
<city>Raanana</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sade</last-name>
<first-name>Raanan</first-name>
<address>
<city>Kibutz Gvat</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Cohen</last-name>
<first-name>Ehud</first-name>
<address>
<city>Kiryat Motskin</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Margulis</last-name>
<first-name>Oleg</first-name>
<address>
<city>Haifa</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Sheaffer</last-name>
<first-name>Gad</first-name>
<address>
<city>Haifa</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Raikin</last-name>
<first-name>Shlomo</first-name>
<address>
<city>Geva Carmel</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Bassin</last-name>
<first-name>Vadim</first-name>
<address>
<city>Raanana</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Sade</last-name>
<first-name>Raanan</first-name>
<address>
<city>Kibutz Gvat</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Cohen</last-name>
<first-name>Ehud</first-name>
<address>
<city>Kiryat Motskin</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Margulis</last-name>
<first-name>Oleg</first-name>
<address>
<city>Haifa</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Blakely, Sokoloff, Taylor &#x26; Zafman LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Intel Corporation</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bataille</last-name>
<first-name>Pierre-Michel</first-name>
<department>2186</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and apparatus for monitoring memory accesses in hardware to support transactional execution is herein described. Attributes are monitor accesses to data items without regard for detection at physical storage structure granularity, but rather ensuring monitoring at least at data items granularity. As an example, attributes are added to state bits of a cache to enable new cache coherency states. Upon a monitored memory access to a data item, which may be selectively determined, coherency states associated with the data item are updated to a monitored state. As a result, invalidating requests to the data item are detected through combination of the request type and the monitored coherency state of the data item.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="199.73mm" wi="143.00mm" file="US08627017-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="223.94mm" wi="169.67mm" file="US08627017-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="180.09mm" wi="147.74mm" orientation="landscape" file="US08627017-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="133.52mm" wi="162.56mm" file="US08627017-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="226.99mm" wi="160.27mm" file="US08627017-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="198.71mm" wi="141.99mm" file="US08627017-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD</heading>
<p id="p-0002" num="0001">This invention relates to the field of processor execution and, in particular, to execution of groups of instructions.</p>
<heading id="h-0002" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0003" num="0002">This application is related to the following patent applications filed herewith: U.S. patent application Ser. No. 12/346,543, entitled &#x201c;Extending Cache Coherency Protocols to Support Locally Buffered Data,&#x201d; by Gad Sheaffer et al., filed on Dec. 30, 2008; U.S. patent application Ser. No. 12/346,539, entitled &#x201c;Memory Model for Hardware Attributes Within a Transactional Memory System,&#x201d; by Gad Sheaffer et al., filed on Dec. 30, 2008 U.S. patent application Ser. No. 12/346,518, entitled &#x201c;Registering a User-Handler in Hardware for Transactional Memory Event Handling,&#x201d; by Gad Sheaffer et al., filed on Dec. 30, 2008; U.S. patent application Ser. No. 12/346,500, entitled &#x201c;Metaphysical Address Space for Holding Lossy Meta-data in Hardware,&#x201d; by Gad Sheaffer et al., filed on Dec. 30, 2008.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">Advances in semi-conductor processing and logic design have permitted an increase in the amount of logic that may be present on integrated circuit devices. As a result, computer system configurations have evolved from a single or multiple integrated circuits in a system to multiple cores and multiple logical processors present on individual integrated circuits. A processor or integrated circuit typically comprises a single processor die, where the processor die may include any number of cores or logical processors.</p>
<p id="p-0005" num="0004">The ever increasing number of cores and logical processors on integrated circuits enables more software threads to be concurrently executed. However, the increase in the number of software threads that may be executed simultaneously have created problems with synchronizing data shared among the software threads. One common solution to accessing shared data in multiple core or multiple logical processor systems comprises the use of locks to guarantee mutual exclusion across multiple accesses to shared data. However, the ever increasing ability to execute multiple software threads potentially results in false contention and a serialization of execution.</p>
<p id="p-0006" num="0005">For example, consider a hash table holding shared data. With a lock system, a programmer may lock the entire hash table, allowing one thread to access the entire hash table. However, throughput and performance of other threads is potentially adversely affected, as they are unable to access any entries in the hash table, until the lock is released. Alternatively, each entry in the hash table may be locked. Either way, after extrapolating this simple example into a large scalable program, it is apparent that the complexity of lock contention, serialization, fine-grain synchronization, and deadlock avoidance become extremely cumbersome burdens for programmers.</p>
<p id="p-0007" num="0006">Another recent data synchronization technique includes the use of transactional memory (TM). Often transactional execution includes executing a grouping of a plurality of micro-operations, operations, or instructions. In the example above, both threads execute within the hash table, and their memory accesses are monitored/tracked. If both threads access/alter the same entry, conflict resolution may be performed to ensure data validity. One type of transactional execution includes Software Transactional Memory (STM), where tracking of memory accesses, conflict resolution, abort tasks, and other transactional tasks are performed in software, often without the support of hardware.</p>
<p id="p-0008" num="0007">In strongly atomic Software Transactional Memory (STM) systems, to ensure runtime conflicts between transactional memory operations and non-transactional memory operations do not occur, compilers treat each non-transactional memory operation as a single operation transaction. In other words, transactional barriers are inserted at transactional memory accesses and at non-transactional memory accesses to isolate transactions from each other and non-transactional memory accesses. However, execution of transactional barriers at every transactional and non-transactional memory operation is potentially expensive and complex.</p>
<p id="p-0009" num="0008">Another type of transactional execution includes a Hardware Transactional Memory (HTM) System, where hardware is included to support access tracking, conflict resolution, and other transactional tasks. However, previous attempts at hardware support for transactional execution have not effectively integrated software transactional advantages, such as access tracking and conflict detection on any data granularity level, into hardware.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0010" num="0009">The present invention is illustrated by way of example and not intended to be limited by the figures of the accompanying drawings.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an embodiment of a processor including multiple processing elements capable of executing multiple software threads concurrently.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an embodiment of structures in a processor to support transactional execution.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an embodiment of a flowchart for a method of operating in a selective association mode for memory access monitoring or a non-selective association mode for memory access monitoring.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4</figref> illustrates another embodiment of a state transition diagram for cache coherency states including additional monitored cache coherency states.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an embodiment of a flow diagram for a method of monitoring memory accesses.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0016" num="0015">In the following description, numerous specific details are set forth such as examples of specific hardware structures for transactional execution, specific types and implementations of access monitors, specific cache implementations, specific types cache coherency models, specific data granularities, and specific types of memory accesses and locations, etc. in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art that these specific details need not be employed to practice the present invention. In other instances, well known components or methods, such as coding of transactions in software, demarcation of transactions, specific and alternative multi-core and multi-threaded processor architectures, specific compiler methods/implementations, and specific operational details of microprocessors, have not been described in detail in order to avoid unnecessarily obscuring the present invention.</p>
<p id="p-0017" num="0016">The method and apparatus described herein are for providing memory access monitors to support transactional execution. Specifically, providing memory access monitors is primarily discussed in reference to monitors associated with cache memory structures to track accesses to memory addresses. In fact, specific reference is made to monitors associated with a cache memory in <figref idref="DRAWINGS">FIGS. 2 and 4</figref> below. However, the methods and apparatus for providing memory access monitors is not so limited, as they may be implemented in conjunction with any structure to track memory accesses to data elements.</p>
<p id="p-0018" num="0017">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, an embodiment of a processor capable of executing multiple threads concurrently is illustrated. Note, processor <b>100</b> may include hardware support for hardware transactional execution. Either in conjunction with hardware transactional execution, or separately, processor <b>100</b> may also provide hardware support for hardware acceleration of a Software Transactional Memory (STM), separate execution of a STM, or a combination thereof, such as a hybrid Transactional Memory (TM) system. Processor <b>100</b> includes any processor, such as a micro-processor, an embedded processor, a digital signal processor (DSP), a network processor, or other device to execute code. Processor <b>100</b>, as illustrated, includes a plurality of processing elements.</p>
<p id="p-0019" num="0018">In one embodiment, a processing element refers to a thread unit, a process unit, a context, a logical processor, a hardware thread, a core, and/or any other element, which is capable of holding a state for a processor, such as an execution state or architectural state. In other words, a processing element, in one embodiment, refers to any hardware capable of being independently associated with code, such as a software thread, operating system, application, or other code. A physical processor typically refers to an integrated circuit, which potentially includes any number of other processing elements, such as cores or hardware threads.</p>
<p id="p-0020" num="0019">A core often refers to logic located on an integrated circuit capable of maintaining an independent architectural state wherein each independently maintained architectural state is associated with at least some dedicated execution resources. In contrast to cores, a hardware thread typically refers to any logic located on an integrated circuit capable of maintaining an independent architectural state wherein the independently maintained architectural states share access to execution resources. As can be seen, when certain resources are shared and others are dedicated to an architectural state, the line between the nomenclature of a hardware thread and core overlaps. Yet often, a core and a hardware thread are viewed by an operating system as individual logical processors, where the operating system is able to individually schedule operations on each logical processor.</p>
<p id="p-0021" num="0020">Physical processor <b>100</b>, as illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, includes two cores, core <b>101</b> and <b>102</b>, which share access to higher level cache <b>110</b>. Although processor <b>100</b> may include asymmetric cores, i.e. cores with different configurations, functional units, and/or logic, symmetric cores are illustrated. As a result, core <b>102</b>, which is illustrated as identical to core <b>101</b>, will not be discussed in detail to avoid repetitive discussion. In addition, core <b>101</b> includes two hardware threads <b>101</b><i>a </i>and <b>101</b><i>b</i>, while core <b>102</b> includes two hardware threads <b>102</b><i>a </i>and <b>102</b><i>b</i>. Therefore, software entities, such as an operating system, potentially view processor <b>100</b> as four separate processors, i.e. four logical processors or processing elements capable of executing four software threads concurrently.</p>
<p id="p-0022" num="0021">Here, a first thread is associated with architecture state registers <b>101</b><i>a</i>, a second thread is associated with architecture state registers <b>101</b><i>b,a </i>third thread is associated with architecture state registers <b>102</b><i>a</i>, and a fourth thread is associated with architecture state registers <b>102</b><i>b</i>. As illustrated, architecture state registers <b>101</b><i>a </i>are replicated in architecture state registers <b>101</b><i>b</i>, so individual architecture states/contexts are capable of being stored for logical processor <b>101</b><i>a </i>and logical processor <b>101</b><i>b</i>. Other smaller resources, such as instruction pointers and renaming logic in rename allocator logic <b>130</b> may also be replicated for threads <b>101</b><i>a </i>and <b>101</b><i>b</i>. Some resources, such as re-order buffers in reorder/retirement unit <b>135</b>, ILTB <b>120</b>, load/store buffers, and queues may be shared through partitioning. Other resources, such as general purpose internal registers, page-table base register, low-level data-cache and data-TLB <b>115</b>, execution unit(s) <b>140</b>, and portions of out-of-order unit <b>135</b> are potentially fully shared.</p>
<p id="p-0023" num="0022">Processor <b>100</b> often includes other resources, which may be fully shared, shared through partitioning, or dedicated by/to processing elements. In <figref idref="DRAWINGS">FIG. 1</figref>, an embodiment of a purely exemplary processor with illustrative functional units/resources of a processor is illustrated. Note that a processor may include, or omit, any of these functional units, as well as include any other known functional units, logic, or firmware not depicted.</p>
<p id="p-0024" num="0023">As illustrated, processor <b>100</b> includes bus interface module <b>105</b> to communicate with devices external to processor <b>100</b>, such as system memory <b>175</b>, a chipset, a northbridge, or other integrated circuit. Memory <b>175</b> may be dedicated to processor <b>100</b> or shared with other devices in a system. Higher-level or further-out cache <b>110</b> is to cache recently fetched elements from higher-level cache <b>110</b>. Note that higher-level or further-out refers to cache levels increasing or getting further way from the execution unit(s). In one embodiment, higher-level cache <b>110</b> is a second-level data cache. However, higher level cache <b>110</b> is not so limited, as it may be associated with or include an instruction cache. A trace cache, i.e. a type of instruction cache, may instead be coupled after decoder <b>125</b> to store recently decoded traces. Module <b>120</b> also potentially includes a branch target buffer to predict branches to be executed/taken and an instruction-translation buffer (I-TLB) to store address translation entries for instructions.</p>
<p id="p-0025" num="0024">Decode module <b>125</b> is coupled to fetch unit <b>120</b> to decode fetched elements. In one embodiment, processor <b>100</b> is associated with an Instruction Set Architecture (ISA), which defines/specifies instructions executable on processor <b>100</b>. Here, often machine code instructions recognized by the ISA include a portion of the instruction referred to as an opcode, which references/specifies an instruction or operation to be performed.</p>
<p id="p-0026" num="0025">In one example, allocator and renamer block <b>130</b> includes an allocator to reserve resources, such as register files to store instruction processing results. However, threads <b>101</b><i>a </i>and <b>101</b><i>b </i>are potentially capable of out-of-order execution, where allocator and renamer block <b>130</b> also reserves other resources, such as reorder buffers to track instruction results. Unit <b>130</b> may also include a register renamer to rename program/instruction reference registers to other registers internal to processor <b>100</b>. Reorder/retirement unit <b>135</b> includes components, such as the reorder buffers mentioned above, load buffers, and store buffers, to support out-of-order execution and later in-order retirement of instructions executed out-of-order.</p>
<p id="p-0027" num="0026">Scheduler and execution unit(s) block <b>140</b>, in one embodiment, includes a scheduler unit to schedule instructions/operation on execution units. For example, a floating point instruction is scheduled on a port of an execution unit that has an available floating point execution unit. Register files associated with the execution units are also included to store information instruction processing results. Exemplary execution units include a floating point execution unit, an integer execution unit, a jump execution unit, a load execution unit, a store execution unit, and other known execution units.</p>
<p id="p-0028" num="0027">Lower level data cache and data translation buffer (D-TLB) <b>150</b> are coupled to execution unit(s) <b>140</b>. The data cache is to store recently used/operated on elements, such as data operands, which are potentially held in memory coherency states. The D-TLB is to store recent virtual/linear to physical address translations. As a specific example, a processor may include a page table structure to break physical memory into a plurality of virtual pages.</p>
<p id="p-0029" num="0028">In one embodiment, processor <b>100</b> is capable of transactional execution. A transaction, which may also be referred to as a critical or atomic section of code, includes a grouping of instructions, operations, or micro-operations to be executed as an atomic group. For example, instructions or operations may be used to demarcate a transaction or a critical section. In one embodiment, described in more detail below, these instructions are part of a set of instructions, such as an Instruction Set Architecture (ISA), which are recognizable by hardware of processor <b>100</b>, such as decoders described above. Often, these instructions, once compiled from a high-level language to hardware recognizable assembly language include operation codes (opcodes), or other portions of the instructions, that decoders recognize during a decode stage.</p>
<p id="p-0030" num="0029">Typically, during execution of a transaction, updates to memory are not made globally visible until the transaction is committed. As an example, a transactional write to a location is potentially visible to a local thread, yet, in response to a read from another thread the write data is not forwarded until the transaction including the transactional write is committed. While the transaction is still pending, data items/elements loaded from and written to within a memory are tracked, as discussed in more detail below. Once the transaction reaches a commit point, if not conflicts have been detected for the transaction, then the transaction is committed and updates made during the transaction are made globally visible.</p>
<p id="p-0031" num="0030">However, if the transaction is invalidated during its pendency, the transaction is aborted and potentially restarted without making the updates globally visible. As a result, pendency of a transaction, as used herein, refers to a transaction that has begun execution and has not been committed or aborted, i.e. pending. Example implementations for transactional execution include a Hardware Transactional Memory (HTM) system, a Software Transactional Memory (STM) system, and a combination or hybrid thereof.</p>
<p id="p-0032" num="0031">A Software Transactional Memory (STM) system often refers to performing access tracking, conflict resolution, or other transactional memory tasks in or at least partially in software. In one embodiment, processor <b>100</b> is capable of executing a compiler to compile program code to support transactional execution. Here, the compiler may insert operations, calls, functions, and other code to enable execution of transactions.</p>
<p id="p-0033" num="0032">A compiler often includes a program or set of programs to translate source text/code into target text/code. Usually, compilation of program/application code with a compiler is done in multiple phases and passes to transform hi-level programming language code into low-level machine or assembly language code. Yet, single pass compilers may still be utilized for simple compilation. A compiler may utilize any known compilation techniques and perform any known compiler operations, such as lexical analysis, preprocessing, parsing, semantic analysis, code generation, code transformation, and code optimization.</p>
<p id="p-0034" num="0033">Larger compilers often include multiple phases, but most often these phases are included within two general phases: (1) a front-end, i.e. generally where syntactic processing, semantic processing, and some transformation/optimization may take place, and (2) a back-end, i.e. generally where analysis, transformations, optimizations, and code generation takes place. Some compilers refer to a middle end, which illustrates the blurring of delineation between a front-end and back end of a compiler. As a result, reference to insertion, association, generation, or other operation of a compiler may take place in any of the aforementioned phases or passes, as well as any other known phases or passes of a compiler. As an illustrative example, a compiler potentially inserts transactional operations, calls, functions, etc. in one or more phases of compilation, such as insertion of calls/operations in a front-end phase of compilation and then transformation of the calls/operations into lower-level code during a transactional memory transformation phase.</p>
<p id="p-0035" num="0034">Nevertheless, despite the execution environment and dynamic or static nature of a compiler, the compiler, in one embodiment, compiles program code to enable transactional execution. Therefore, reference to execution of program code, in one embodiment, refers to (1) execution of a compiler program(s), either dynamically or statically, to compile main program code, to maintain transactional structures, or to perform other transaction related operations, (2) execution of main program code including transactional operations/calls, (3) execution of other program code, such as libraries, associated with the main program code, or (4) a combination thereof.</p>
<p id="p-0036" num="0035">In one embodiment, processor <b>100</b> is capable of executing transactions utilizing hardware/logic, i.e. within a Hardware Transactional Memory (HTM) system. Numerous specific implementation details exist both from an architectural and microarchitectural perspective when implementing an HTM; most of which are not discussed herein to avoid unnecessarily obscuring the invention. However, some structures and implementations are disclosed for illustrative purposes. Yet, it should be noted that these structures and implementations are not required and may be augmented and/or replaced with other structures having different implementation details.</p>
<p id="p-0037" num="0036">As an example of an implementation design choice, an HTM may operate in an update-in-place manner or a write-buffering manner. In an update-in place HTM, transactional writes are performed to referenced memory addresses to modify previous data held therein. However, this modified data is not provided to external requesting threads, i.e. the data is not made globally visible, but is provided to local reads for local memory ordering purposes. Additionally, the previous data is often &#x201c;logged,&#x201d; such that upon an abort of the transaction, the previous data is capable of being restored to achieve the state of the thread before execution of the transaction begun.</p>
<p id="p-0038" num="0037">To illustrate, assume data cache <b>150</b> includes a first level data cache to hold data from higher level memory, such as cache <b>110</b> and system memory <b>175</b>. Therefore, upon encountering a transactional write to data cache <b>150</b>, the previous data item, in one embodiment of a write-back cache, writes the previous data item back to higher level cache <b>110</b>. Alternatively, the previous data may be logged in another separate memory within processor <b>100</b> or external thereto. After logging the previous data item, the transactional write is performed to update the data item in cache <b>150</b>. Therefore, a local thread, such as local thread <b>101</b><i>a</i>, i.e. a thread that is associated with the transactional write, may read from the modified data item in cache <b>150</b>. However, another thread, such as thread <b>102</b><i>b</i>, is not provided the modified data, but rather the logged data, in response to a read request, if the transaction including the transactional write having not yet committed. When the transaction commits, the logged data is invalidated or disregarded. Yet, if the transaction aborts, the previous data is reloaded or globally identified as the valid data.</p>
<p id="p-0039" num="0038">In contrast, in a write-buffering HTM, transactional writes are buffered in a write buffer, while previous data resides in its original location. If a local thread, such as thread <b>102</b><i>b</i>, performs a read of the data transactionally written, then the modified data is forwarded from the write buffer. As a corollary, if an external thread requests a read of the data while the transaction including the transactional write is still pending, the previous data from the original location is provided. Furthermore, upon a commit of the transaction, the modified data is copied to the corresponding memory address, while upon an abort, the buffered data is disregarded.</p>
<p id="p-0040" num="0039">As can be seen from the discussion above, accesses and requests may be made to data items both by local processing elements, as well as potentially by other processing elements. Without safety mechanisms, some of these accesses would potentially result in invalid data and execution, i.e. a write to data invalidating a read, or a read of invalid data. As a result, processor <b>100</b> potentially includes logic to track or monitor memory accesses for identification of potential conflicts.</p>
<p id="p-0041" num="0040">In one embodiment, processor <b>100</b> includes read and write monitors to monitor and/or track memory accesses. As a first example, the monitors are to monitor memory accesses to a data element at a granularity of the data element without regard to being limited to the granularity of physical memory structures/locations to hold the data element. A data item or data element may include data at any granularity level, as defined by hardware, software or a combination thereof.</p>
<p id="p-0042" num="0041">A non-exhaustive list of examples of data, data elements, data items, or references thereto, include a memory address, a data object, a class, a field of a type of dynamic language code, a type of dynamic language code, a variable, an operand, a data structure, and an indirect reference to a memory address. However, any known grouping of data may be referred to as a data element or data item. A few of the examples above, such as a field of a type of dynamic language code and a type of dynamic language code refer to data structures of dynamic language code. To illustrate, dynamic language code, such as Java&#x2122; from Sun Microsystems, Inc, is a strongly typed language. Each variable has a type that is known at compile time. The types are divided in two categories&#x2014;primitive types (boolean and numeric, e.g., int, float) and reference types (classes, interfaces and arrays). The values of reference types are references to objects. In Java&#x2122;, an object, which consists of fields, may be a class instance or an array. Given object a of class A it is customary to use the notation A::x to refer to the field x of type A and a&#xb7;x to the field x of object a of class A. For example, an expression may be couched as a&#xb7;x=a&#xb7;y+a&#xb7;z. Here, field y and field z are loaded to be added and the result is to be written to field x.</p>
<p id="p-0043" num="0042">Therefore, monitoring memory accesses to data items may be performed at any of data level granularity. For example, in one embodiment, memory accesses to data are monitored at a type level. Here, a transactional write to a field A::x and a non-transactional load of field A::y may be monitored as accesses to the same data item, i.e. type A. In another embodiment, memory access monitoring is performed at a field level granularity. Here, a transactional write to A::x and a non-transactional load of A::y are not monitored as accesses to the same data item, as they are references to separate fields. Note, other data structures or programming techniques may be taken into account in tracking memory accesses to data items. As an example, assume that fields x and y of object of class A, i.e. A::x and A::y, point to objects of class B, are initialized to newly allocated objects, and are never written to after initialization. In one embodiment, a transactional write to a field B::z of an object pointed to by A::x are not monitored as memory access to the same data item in regards to a non-transactional load of field B::z of an object pointed to by A::y. Extrapolating from these examples, it is possible to determine that monitors may perform monitoring at any data granularity level.</p>
<p id="p-0044" num="0043">In one embodiment, monitors include read monitors and write monitors to track loads and stores, which are determined to be monitored, accordingly. As an example, hardware read monitors and write monitors are to perform bounded monitoring of data items at least at a granularity of the data items despite the granularity of storage structures to hold the data items. In one embodiment, a read monitor for a data item includes a first number of read attributes to be associated with the data item. Similarly, a write monitor for a data item includes a second number of write attributes to be associated with the data item. Note that the first number of read attributes and the second number of write attributes may be the same; however, they are not so limited, and potentially include different numbers of attributes.</p>
<p id="p-0045" num="0044">Read or write attributes include any logic, firmware, or structure for holding states or information associated with data items. For example, attributes for a data item include a bit vector, where each bit in the bit vector represents an attribute of a data item, such as transactionally loaded, transactionally written, non-transactionally loaded, non-transactionally written, not transactionally loaded, not transactionally written, not non-transactionally loaded, not non-transactionally written, access conflict detected, no access conflict detected, a read request, no read request, a write request, no write request, an ownership request, no ownership request, or any other attribute or state associated with a data item or memory location to hold the data item.</p>
<p id="p-0046" num="0045">As another example, the attributes for a data item includes an encoded value. For example, states, such as the four states: (1) transactionally written; (2) transactionally read; (3) not transactionally written; and (4) not transactionally read, are encoded utilizing two attribute bits, i.e. four binary values of 00, 01, 11, and 10. Note these four states may include an example of a monitored write state, a monitored read state, a not monitored written state, and a not monitored read state.</p>
<p id="p-0047" num="0046">As referred to above, read and write attributes may be associated with data items/elements in any known manner. For example, general storage within processor <b>100</b> may be utilized to hold read and write attributes corresponding to data items read and written that are to monitored, accordingly. The amount of ways to associate attributes with data items are too numerous to elaborate all of the methods.</p>
<p id="p-0048" num="0047">Yet, as a first example, attributes are associated with a subset of bytes of a cache line. For example, assume a cache line of cache <b>150</b> is 64 bytes in length and is accessible by processor <b>100</b> in 8 byte segments. Here, attributes may be associated with any physical granularity of storage, such as 2, 4, 8, 16, 32, 64, or 128 bytes of data as illustrative examples, and may vary amongst cache <b>150</b>, such as being associated with each 4 bytes of physical storage for one portion of cache <b>150</b> and each 8 bytes for another portion of cache <b>150</b>.</p>
<p id="p-0049" num="0048">Yet, in one embodiment, regardless of or despite the boundaries of physical storage, monitors/attributes are to perform bounded monitoring of a data item at the data item's granularity level despite a granularity of the physical storage in processor <b>100</b>, i.e. one or both of cache <b>150</b> and attribute storage. For example, assume cache <b>150</b> includes 16 byte lines accessible in 4 byte segments, i.e. four accessible segments within each cache line. Furthermore, assume read and write attributes are associated with each 8 byte segment of each 16 byte line. Therefore, the cache is capable of reading and writing every 4 bytes of data, while attributes are capable of monitoring every 8 bytes of data.</p>
<p id="p-0050" num="0049">To further the example, a monitored load results in a load of a data item having a size of 20 bytes spanning a portion of two cache lines of cache <b>150</b>, i.e. all 16 bytes of a first line and the first 4 bytes of a second line. Therefore, the read attributes associated with the 16 bytes of the first cache line of cache <b>150</b> are updated to indicate the monitored load occurred. Furthermore, the read attributes associated with the first 8 bytes of the second cache line of cache <b>150</b> are also similarly updated, even though, the data item only occupies 4 bytes of the second cache line. Essentially, monitoring for the data item, in this embodiment, is provided at least at the granularity level of the data item, and potentially at a larger granularity to ensure the full data item is monitored, i.e. bounded monitoring. In other words, here, attributes bound monitoring of the data item without regard to physical storage granularity limitations or attribute association by ensuring the data item is monitored even if a greater amount of data is included due to the granularity of the physical storage. Inversely, if attributes provide a smaller granularity as compared to cache <b>150</b>, then tracking a data item based on the attribute association is potentially more accurate than at the accessibility granularity of cache <b>150</b>.</p>
<p id="p-0051" num="0050">The example above assumed static association of attributes/monitors to a predetermined size, such as monitors for every 8 bytes of a 16 byte cache line. Note these associations are purely illustrative and may vary drastically, such as including smaller or greater monitor association granularity. However, in another embodiment, attributes are dynamically assigned from a pool of attributes upon a load or store of a data item. To illustrate, the example above is reexamined in this context. Here, when the 20 byte data item is loaded utilizing a monitored load, then read attributes are dynamically associated at that time with the 20 bytes of cache <b>150</b> that the data item is loaded from. Here, monitoring of the data item is truly decoupled from the granularity of a physical storage structure. In both instances, data is bounded by the monitors despite the granularity of the underlying storage structure, i.e. cache <b>150</b>. However, in the first example the static granularity of the association of monitors with portions of cache <b>150</b> have to be taken into account to ensure data is bounded by correct monitoring. However, in the second example, monitors are dynamically associated at a specific granularity of the data item.</p>
<p id="p-0052" num="0051">In one embodiment, monitors within processor <b>100</b>, in a first mode, are to monitor all memory accesses. For example, when a transaction is being executed, all of the transactional memory accesses are monitored. Furthermore, in another mode, processor <b>100</b> is potentially capable of selectively monitoring memory accesses. Selective monitoring of memory accesses is discussed in more detail below in reference to <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0053" num="0052">In one embodiment, hardware monitors to monitor memory access operations are utilized for conflict detection, such as detection of invalidating memory accesses that may require an abort of a transaction. Regardless of how the association of hardware monitors or attributes are implemented, as discussed in more detail herein, access states of monitors may be utilized by conflict detection logic, firmware, software, or a combination thereof, to detect potential memory access conflicts. To illustrate, assume a read hardware monitor associated with a data item held in cache <b>150</b> indicates the data item has been previously loaded by a transaction, and subsequently, a request by another thread to write the data item is received by cache control logic for cache <b>150</b>. Based on the write request and the current state of the read monitor, i.e. transactionally loaded, the conflict logic, which in one embodiment is included with or coupled to the cache control logic, detects the potential conflict. In response to the potential conflict, any number of actions may be taken in hardware, software, or a combination thereof. An example, discussed in more detail in reference to <figref idref="DRAWINGS">FIG. 2</figref>, includes setting a bit in a status register or setting a flag in response to the conflict, and transferring control to a handler to handle the potential conflict responsive to setting the bit or the flag.</p>
<p id="p-0054" num="0053">Therefore, as inferred in the above example, in one embodiment, where attributes are associated with a cache memory, such as data cache <b>150</b>, then existing known coherency and communication/snoop protocols may be utilized in combination with hardware monitors/attributes to detect conflicts. Here, based on the design, different combinations of cache coherency requests and states of monitors/attributes result in a potential conflict, such as the read monitor above indicating a monitored load of a data item and a snoop indicating a write request to the data item. Inversely, a write monitor indicating a monitored write to a data item and a snoop indicating a read request to the data item may be considered potentially conflicting. In one embodiment, to detect such combinations of access requests and attribute states snoop logic is coupled to conflict detection/reporting logic, such as monitors and/or logic for conflict detection/reporting.</p>
<p id="p-0055" num="0054">Yet, detecting conflicts, in one embodiment, is not limited to utilizing common coherence protocols. Take for example, the architecture of processor <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. Here, separate physical threads share access to both data cache <b>150</b> and higher level cache <b>110</b>. Therefore, if monitors are associated with cache <b>150</b>, which is a shared cache to be shared between threads <b>101</b><i>a </i>and <b>101</b><i>b</i>, then potential conflicts between threads <b>101</b><i>a </i>and <b>101</b><i>b </i>may not be adequately detected due to the lack of interconnect requests being generated with cache <b>150</b> in response to accesses from threads <b>101</b><i>a </i>and <b>101</b><i>b. </i></p>
<p id="p-0056" num="0055">Consequently, monitors/attributes, in one embodiment, are replicated on a per processing element basis. In this example, attributes may be replicated per thread, i.e. the same attributes replicated for thread <b>101</b><i>a </i>and <b>101</b><i>b</i>. Note attribute replication potentially includes association of a single grouping of attributes with different thread identifiers to indicate which thread is associated with the state of the single grouping of attributes. In contrast, replication may include a number of individual groups of replicated attributes, each of which are associated with a thread. As an example, one set of attributes for a data item are associated with thread <b>101</b><i>a </i>and a second set of attributes for the data item are associated with thread <b>101</b><i>b. </i></p>
<p id="p-0057" num="0056">As a result, to detect conflicts between threads <b>101</b><i>a </i>and <b>101</b><i>b </i>sharing access to a cache <b>150</b> includes access tracking on a per processing element, such as a per thread basis. To illustrate, assume thread <b>101</b><i>a </i>sets a monitor associated with a data item D. Here, the replicated attributes associated with thread <b>101</b><i>a </i>are set to an appropriate monitored value. Therefore, if thread <b>101</b><i>b </i>makes a conflicting request to data item D, then a conflict is detected. In one embodiment, reporting logic coupled to the control logic to detect the conflict reports the conflict for appropriate handling. As an example, a logical operation, such as a logical OR, combines different conflict events, such as a loss of monitoring due to external reasons (eviction or external snoop) and due to shared cache thread access conflicts.</p>
<p id="p-0058" num="0057">In one embodiment, attributes associated with data items held in cache <b>150</b> are implemented utilizing ephemeral or private stores. Here, attributes may be held anywhere in cache <b>150</b>, such as in lines of cache <b>150</b> themselves. For example, one example of an HTM described above, includes an update-in-place HTM. Here, transactional modified data is held in current memory locations, while the previous data is logged/backed up, such as in a higher-level memory. As a result, in one embodiment, when cache <b>150</b> is accessed with regard to a data item, the attributes are ephemerally stored with the data item in cache <b>150</b>. Here, the data item is held in a private or ephemeral coherency state, which allows cache control logic to ensure transactional semantics are upheld. In other words, a data item held in an ephemeral state is not provided to other threads.</p>
<p id="p-0059" num="0058">However, if the data item is evicted from cache <b>150</b>, then the privately held attributes are potentially lost. Essentially, the attributes are system created to monitor the data item, and are not written back to higher level memory. In a scenario where attributes are to decay, i.e. lost upon an eviction or other event, a potential conflict may be triggered in a similar manner to detecting a potential access conflict, as described above. A version of ephemeral stores and private states, such as buffered stores and a buffered state, is discussed in a related application filed herewith having attorney docket number P29132 entitled, &#x201c;Extending the MESI protocol to support locally buffered data.&#x201d;</p>
<p id="p-0060" num="0059">As illustrated by the examples discussed above, hardware attributes, which are associated with data items in a cache, may be held outside a cache, within cache logic, within arrays of a cache, within other structures of a cache, or even ephemerally within data portions of a cache. Often, these hardware attributes are maintained by hardware without direct manipulation by execution of user-instructions. For example, a software program includes a transactional write to a data item. When the processor encounters the transactional write and determines it is to be monitored, the hardware updates the write attributes associated with the data item, appropriately. For example, an ephemeral store is inserted and executed to update cache <b>150</b> with the data item and associated write attributes. As another example, attributes are appended to coherency state bits of cache <b>150</b> and the coherency state of lines of cache <b>150</b> to hold the data item are updated in response to the transactional write.</p>
<p id="p-0061" num="0060">Yet, in one embodiment, in addition to hardware management of hardware monitors/attributes, instructions are also recognizable by the hardware to directly manipulate the attributes. As an example, these instructions or operations are part of an Instruction Set Architecture (ISA) recognizable by processor <b>100</b> to perform operations on the attributes. For example, the ISA includes opcodes, when detected by decoders of processor <b>100</b>, to modify the attributes, accordingly. Examples of instructions that may be utilized includes, a set instruction to set attributes associated with a data item to a state, a reset instruction to reset attributes associated with a data item to a default state, a test or read instruction to read a state of attributes, and a clear instruction to clear all attributes for a transaction or within a cache.</p>
<p id="p-0062" num="0061">One of the aforementioned examples included a clear instruction to clear attributes. In one embodiment, a bulk clear instruction is utilized to clear a bulk of read and write monitors. Note a bulk clear instruction is potentially useful in a number of scenarios. First, upon a commit or abort of a transaction, read and write monitors for the transaction are potentially cleared/reset. Second, a transition of processor <b>100</b> from one domain to another may be configurable to clear/reset read and write monitors. Examples of domains in Intel's IA <b>32</b> architecture include a read domain, a big real domain, and a virtual domain. Third, upon an exception or interrupt it may be useful to clear read and write monitors. Consequently, when the clear instruction is encountered, either a monitor, a range of monitors, all monitors meeting a specified condition, or all monitors within a cache are cleared.</p>
<p id="p-0063" num="0062">As state above in the initial reference to <figref idref="DRAWINGS">FIG. 1</figref>, the architecture of processor <b>100</b> is purely illustrative for purpose of discussion. Similarly, the specific examples of associating attributes with data items/elements is also exemplary, as any method of associating hardware monitors/attributes at different granularity data items may be utilized. An example of associating attributes with data items in a cache is further discussed in reference to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0064" num="0063">Referring to <figref idref="DRAWINGS">FIG. 2</figref>, an embodiment of associating attributes with a data item in cache memory is illustrated. Processor <b>250</b> includes any type of known processor with any number of processing elements capable of transactional execution. As discussed above, attributes may be statically associated with any physical size of a physical storage structure, or dynamically assigned to data items. The embodiment of <figref idref="DRAWINGS">FIG. 2</figref> illustrates attributes, i.e. attributes <b>211</b>.<i>r</i>-<b>226</b>.<i>r </i>and <b>211</b>.<i>w</i>-<b>226</b>.<i>w</i>, associated with a static portion of cache <b>205</b>, i.e. portions <b>210</b>-<b>225</b>, respectively. For example, portions <b>210</b>-<b>225</b> are cache lines of cache <b>250</b>. Cache <b>250</b> includes any cache associated with a processor, such as a first level cache or a second level cache.</p>
<p id="p-0065" num="0064">As illustrated, read attribute <b>211</b>.<i>r </i>is associated with cache line <b>210</b> and write attribute <b>211</b>.<i>w </i>is associated with cache line <b>210</b>. Array <b>235</b>, in one embodiment, includes a tag array with attributes <b>211</b>.<i>r </i>and <b>211</b>.<i>w</i>. In another embodiment, array <b>235</b> includes a state array, such as a coherency state array, with attributes <b>211</b>.<i>r </i>and <b>211</b>.<i>w </i>being included within the state bits to essentially create new coherency states for cache <b>205</b>. An example of utilizing coherency states is described in more detail below in reference to <figref idref="DRAWINGS">FIG. 4</figref>. In yet another embodiment, array <b>235</b> includes any array within cache control logic <b>230</b>, as illustrated, or any other structure of attributes outside control logic and within processor <b>250</b>, which is not depicted.</p>
<p id="p-0066" num="0065">In one embodiment, attributes <b>211</b>.<i>r</i>-<b>226</b>.<i>r </i>and <b>211</b>.<i>w</i>-<b>226</b>.<i>w</i>, monitor memory accesses to data items/elements, such as data element <b>201</b>, despite physical boundaries of storage structures, such as boundaries of cache lines within cache <b>205</b>. In fact, data items may be unaligned with boundaries, such as cache lines, of cache <b>205</b>. Here, monitoring the data item despite physical boundaries of cache <b>205</b> includes bounding the unaligned data item with monitoring based on association of monitoring attributes with portions of cache <b>205</b>. Here, attributes are associated on a per line basis; therefore, any lines containing a monitored data item are monitored even if they hold other data to ensure the data item is properly monitored.</p>
<p id="p-0067" num="0066">Numerous examples of different data items are discussed above. In <figref idref="DRAWINGS">FIG. 2</figref>, data item <b>201</b> is depicted as the size of 1&#xbd; cache lines. As an illustrative example, assume a transactional load operation is executed to load from a memory address referencing data element <b>201</b>, which results in a load of data element <b>201</b> into cache lines <b>210</b> and <b>215</b>. Processor <b>250</b>, either by mode or set of conditions, determines the transactional load is to be monitored.</p>
<p id="p-0068" num="0067">As a result, control logic <b>230</b> determines data item <b>201</b> is to be bounded, i.e. at least the data item is monitored and potentially more data than necessary is monitored to ensure correct conflict detection. Here, control logic <b>230</b> updates fields <b>211</b><i>r </i>and <b>216</b><i>r </i>to indicate a monitored load from cache lines <b>215</b> and <b>216</b> has occurred. As a first example, fields <b>211</b><i>r </i>and <b>216</b><i>r </i>are updated to a monitored logical value, such as a logical one, from an unmonitored logical value, such as a logical zero. In the embodiment where array <b>235</b> is a coherency state array, fields <b>211</b> and <b>216</b> are transitioned to appropriate coherency states, such as a monitored read shared coherency state, as described below. Therefore, as an example, when snoop logic in control logic <b>230</b> detects a request to write to either cache line <b>210</b> or <b>205</b>, then a potential conflict is detected.</p>
<p id="p-0069" num="0068">Although <figref idref="DRAWINGS">FIG. 2</figref> primarily focuses on attributes being separate from data portion <b>205</b> of a cache, as mentioned above, attributes may be held within data portion <b>205</b>. Utilizing the example immediately above, instead of updating attributes <b>211</b><i>r </i>and <b>216</b><i>r </i>in response to the monitored load the attributes are privately stored in cache line <b>210</b>, <b>215</b>, or both. The state of cache lines <b>210</b> and <b>215</b> are transitioned to a buffered or private state. Therefore, upon the write request, a similar conflict is detected utilizing the private held attribute information. However, upon an eviction of lines <b>210</b> or <b>215</b>, the attribute information potentially decays, i.e. is lost. As a result, a similar conflict process may be triggered. Note also that discussion in reference to <figref idref="DRAWINGS">FIG. 2</figref> includes only one set of attributes per cache line. However, attributes may be replicated per thread of processor <b>250</b>, as stated above in reference to cache <b>150</b> of <figref idref="DRAWINGS">FIG. 1</figref>. As an example, attributes are replicated per thread that shares cache <b>205</b>. In addition, different numbers of read and write attributes may be provided instead of the even number of read and write attributes illustrated.</p>
<p id="p-0070" num="0069">In one embodiment, conflict logic, which may be included within cache control logic <b>230</b> or associated therewith, is to detect conflicts associated with the attributes. Based on design implementation, any combination of attribute states, requests, communication protocols, or coherency protocols may be utilized to determine a conflict exists. As oversimplified basic examples, a write to a monitored read is potentially a conflict and a read or a write of a monitored write is potentially a conflict.</p>
<p id="p-0071" num="0070">Once a conflict is detected, in one embodiment, reporting logic reports the conflict. The conflict may be handled by hardware, firmware, software, or a combination thereof. In one embodiment, reporting logic includes a storage element, such as register <b>245</b>. The storage element may include any structure(s) within processor <b>250</b> for holding information, such as a memory, generic register, or model specific register (MSR). As a first example, register <b>245</b> includes a status register. In response to detecting a conflict a value may be set in register <b>245</b> to a conflict value to indicate a conflict has occurred. Here, software may poll register <b>245</b> to see if the value was set to a conflict value. As another example, processor <b>250</b> includes a flags register to include a flag, such as an overflow flag, which is to be tested by an instruction, such as a jump instruction. To illustrate, a conditional jump instruction following a load instruction is capable of being utilized to test consistency of the read set of a transaction.</p>
<p id="p-0072" num="0071">As referred to above, loss of attribute data, due to an eviction or other event, is also considered a conflict. Here, register <b>245</b> may be utilized in a similar manner to indicate loss of attribute data. In one embodiment, in response to loss of attribute data, reporting logic redirects operation of processor <b>250</b> to a software handler to accommodate the limited storage capacity for monitoring attributes. An example of virtualizing transactional memory in response to an overflow event is discussed in co-pending application with Ser. No. 11/479,902 entitled, &#x201c;Global Overflow Method for Virtualized Transactional Memory.&#x201d; In addition an example of utilizing a storage element, such as register <b>245</b>, to register a user handler to handle transactional events, such as conflicts, is discussed in an application filed having Ser. No. 12/346,518, entitled &#x201c;Registering a User-Handler in Hardware for Transactional Memory Event Handling,&#x201d; by Gad Sheaffer et al., filed on Dec. 30, 2008.</p>
<p id="p-0073" num="0072">Register <b>245</b>, in one embodiment, is to hold a value to indicate an operating mode of processor <b>250</b>, such as non-monitoring mode, a non-selective monitoring mode, and a selective monitoring mode. Within a selective monitoring mode, register <b>245</b>, or other registers, may also define selection criteria for monitoring an access. Note that discussion of register <b>245</b> in regards to use as a status register, a register to register a user handler, a register to define an operating mode, and a register to define selection criteria may refer to a single register or a combination of registers to implement any combination of the aforementioned potential uses of storage element <b>245</b>.</p>
<p id="p-0074" num="0073">Referring next to <figref idref="DRAWINGS">FIG. 3</figref>, an embodiment of a flowchart for a method of monitoring in different modes is illustrated. Note the flowcharts of <figref idref="DRAWINGS">FIGS. 3 and 5</figref> are illustrated in a substantially serial fashion. However, the methods illustrated by these Figures are not so limited, as they may occur in any order, as well as being performed at least partially in parallel.</p>
<p id="p-0075" num="0074">In flow <b>305</b>, it is determined if a memory access referencing a data element is to be monitored. In one embodiment, multiple modes of monitoring are provided, such as not monitoring, non-selective monitoring, and selective monitoring. As an example, software is capable of setting a monitoring mode. For example, a user instruction is capable of addressing a register, such as register <b>245</b> from <figref idref="DRAWINGS">FIG. 2</figref>, to indicate a mode of monitoring. Here, software determines which reads and writes are to be monitored. As an example, this determination may be made by software code, such as a compiler either statically or during runtime, application code, operating system code, hypervisor code, or a transactional runtime code.</p>
<p id="p-0076" num="0075">During a selective mode of monitoring, in one embodiment, reads and writes are monitored, except for those that fall within specific criteria, which may be defined in any manner. A non-exhaustive exemplary list of selection criteria for memory accesses to memory addresses that may not be monitored include memory accesses to: virtual addresses falling within or outside a range or matching a mask, physical addresses falling within or outside a range or matching a mask, addresses belonging to specific memory types, address within a input/output (I/O) space, addresses executed in one protection domain on behalf of operations in another protection domain, address accessed by instructions identified by specific opcodes or prefixes, and specific data types, such as floating point or vector operations. In addition, monitoring attributes may be set in response to specific recognized instructions, such as only for explicitly transactional load and explicitly transactional store operations that are identified by the user and recognizable by hardware of processor <b>250</b>.</p>
<p id="p-0077" num="0076">Once it is determined if monitoring is to be applied in flow <b>350</b>, then monitoring is either applied in flow <b>315</b> through updating of a monitor associated with the data element, or monitoring is not performed in flow <b>310</b> and the access is performed normally. Updating a monitor, such as attributes, associated with a data element includes any method of modifying the attributes to monitor the access appropriately, as discussed herein. An example of updating a monitor to different coherency states based on monitored and unmonitored read/writes is discussed below.</p>
<p id="p-0078" num="0077">Referring next to <figref idref="DRAWINGS">FIG. 4</figref>, an embodiment of a state transition diagram for a method of transitioning between coherency states, which include monitored coherency states, is depicted. Note that the state transition diagram in <figref idref="DRAWINGS">FIG. 4</figref> is a partial state diagram, which does not illustrate some state transitions, such as clearing of monitoring attributes, to simplify the diagram. Furthermore, the states and transitions in between the states are purely illustrative. As an example, multiple step state transitions may occur between states instead of some of the direct transitions illustrated in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0079" num="0078">A list of the depicted cache coherency states include: (1) a modified (M <b>420</b>) state, i.e. the address was written and has no attribute associated with it; (2) a modified read (MR <b>430</b>) state, i.e. the address was read and has the read attribute associated with it (e.g. when a previous read to the address and then the transaction writes an address); (3) a modified write (MW <b>425</b>) state, i.e. the address was written and has the write attribute associated with it; (4) a modified read write (MRW <b>435</b>) state, i.e. the address was read, then written, and has both Read and Write attributes associated with it; (5) an exclusive (E <b>440</b>) state, i.e. the address was read and has no attribute associated with it; (6) an exclusive read (ER <b>445</b>) state, i.e. the address was read and has the read attribute associated with it; (7) a shared (S <b>410</b>), i.e. the address was read and has no attribute associated with it; (8) a shared read (SR <b>415</b>) state, i.e. the address was read and has a Read attribute associated with it.</p>
<p id="p-0080" num="0079">In one embodiment, these states may be implemented in accordance with an example of <figref idref="DRAWINGS">FIG. 2</figref>, where attributes are included within state bits of a cache thereby creating these new monitored coherency states. As an example, when a line(s) is held in a shared state <b>410</b> and a monitored read occurs referencing a memory address of a data item including the line(s), the coherency of the line(s) is transitioned to SR <b>415</b> state. As a result, in one embodiment, an external request to write the line(s) results in a potential conflict due to the coherency state being SR <b>415</b>. Other potential conflicts may exists based on the coherency states in combination with other memory access request types, such as an external read request for a data item when a cache line including at least a portion of the data item is held in the MW coherency state <b>425</b>.</p>
<p id="p-0081" num="0080">Turning to <figref idref="DRAWINGS">FIG. 5</figref>, an embodiment of a flow diagram for performing a memory access is illustrated. In flow <b>505</b>, a memory access referencing a memory address associated with a data item is encountered. Encountering a memory access includes any method of detecting a memory access at any stage of execution. Examples of different stages of encountering an operation include a decoder recognizing an opcode for a memory access, retrieving a memory access operation from an instruction cache, scheduling a memory access for execution on an execution unit, such as a load/store unit, and retiring a memory access.</p>
<p id="p-0082" num="0081">In flow <b>510</b> it is determined if a processor is operating a selective mode of operation. As stated above, in one embodiment, software sets the mode of the processor. Here, software, when executing, updates a storage element, such as a register, to indicate the mode of operation. As an example, when execution of a transaction begins, software sets the mode to a non-selective, i.e. all memory accesses are monitored. When the transaction is finished the mode is toggled to selective monitoring or no monitoring. However, in another embodiment, hardware in the processor determines the mode of operation.</p>
<p id="p-0083" num="0082">If the mode is determined to be selective, then in flow <b>515</b> it is determined if the specific memory access is to be monitored. Any number of selection criteria may be applied in this determination, such as whether or not the referenced memory address falls within a specified range of addresses or whether the data item is of a specific type. In addition, the criteria may simply include whether the memory access is identified by the software to be monitored, such as identified as an explicit transactional memory access. If the memory access is not to be monitored, then it is performed as normal in flow <b>525</b>. However, if the memory access is to be monitored, then in flow <b>520</b> an access monitor(s) associated with the data item is updated accordingly. Here, the access may be performed in flow <b>525</b> before, during, or after the monitor is updated in flow <b>520</b>.</p>
<p id="p-0084" num="0083">Therefore, as can be seen from above, monitors, such as attributes, provide monitoring of memory accesses at a granularity of at least a data item/element without being limited by physical storage structure granularity. As a result, hardware attributes provide monitoring of accesses to memory address and associated data items within hardware, while maintaining the ability to monitor and detect conflicts at a software's data structure level. Furthermore, attributes also potentially operate as a filter for large transactions through supporting overflow into software when attribute information decays. Additionally, user mechanism, in one embodiment, are included to allow access to the attributes to perform direct operations on them.</p>
<p id="p-0085" num="0084">A module as used herein refers to any hardware, software, firmware, or a combination thereof. Often module boundaries that are illustrated as separate commonly vary and potentially overlap. For example, a first and a second module may share hardware, software, firmware, or a combination thereof, while potentially retaining some independent hardware, software, or firmware. In one embodiment, use of the term logic includes hardware, such as transistors, registers, or other hardware, such as programmable logic devices. However, in another embodiment, logic also includes software or code integrated with hardware, such as firmware or micro-code.</p>
<p id="p-0086" num="0085">A value, as used herein, includes any known representation of a number, a state, a logical state, or a binary logical state. Often, the use of logic levels, logic values, or logical values is also referred to as 1's and 0's, which simply represents binary logic states. For example, a 1 refers to a high logic level and 0 refers to a low logic level. In one embodiment, a storage cell, such as a transistor or flash cell, may be capable of holding a single logical value or multiple logical values. However, other representations of values in computer systems have been used. For example the decimal number ten may also be represented as a binary value of 1010 and a hexadecimal letter A. Therefore, a value includes any representation of information capable of being held in a computer system.</p>
<p id="p-0087" num="0086">Moreover, states may be represented by values or portions of values. As an example, a first value, such as a logical one, may represent a default or initial state, while a second value, such as a logical zero, may represent a non-default state. In addition, the terms reset and set, in one embodiment, refer to a default and an updated value or state, respectively. For example, a default value potentially includes a high logical value, i.e. reset, while an updated value potentially includes a low logical value, i.e. set. Note that any combination of values may be utilized to represent any number of states.</p>
<p id="p-0088" num="0087">The embodiments of methods, hardware, software, firmware or code set forth above may be implemented via instructions or code stored on a machine-accessible or machine readable medium which are executable by a processing element. A machine-accessible/readable medium includes any mechanism that provides (i.e., stores and/or transmits) information in a form readable by a machine, such as a computer or electronic system. For example, a machine-accessible medium includes random-access memory (RAM), such as static RAM (SRAM) or dynamic RAM (DRAM); ROM; magnetic or optical storage medium; flash memory devices; electrical storage device, optical storage devices, acoustical storage devices or other form of propagated signal (e.g., carrier waves, infrared signals, digital signals) storage device; etc. For example, a machine may access a storage device through receiving a propagated signal, such as a carrier wave, from a medium capable of holding the information to be transmitted on the propagated signal.</p>
<p id="p-0089" num="0088">Reference throughout this specification to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearances of the phrases &#x201c;in one embodiment&#x201d; or &#x201c;in an embodiment&#x201d; in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.</p>
<p id="p-0090" num="0089">In the foregoing specification, a detailed description has been given with reference to specific exemplary embodiments. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are, accordingly, to be regarded in an illustrative sense rather than a restrictive sense. Furthermore, the foregoing use of embodiment and other exemplarily language does not necessarily refer to the same embodiment or the same example, but may refer to different and distinct embodiments, as well as potentially the same embodiment.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>determining if a memory access operation referencing a data item is to be monitored;</claim-text>
<claim-text>caching the data item in a number of lines of a cache; and</claim-text>
<claim-text>in response to determining the memory access operation is to be monitored,
<claim-text>dynamically assigning the hardware attributes to be associated with the data item unaligned with the number of lines,</claim-text>
<claim-text>updating the hardware attributes to represent an access state associated with a type of the memory access operation.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining if a memory access operation referencing a data item is to be monitored is based on an operating mode of a processor to execute the memory access operation.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining if a memory access operation referencing a data item is to be monitored is based on an identification by user-level software of the memory access operation as an operation to be monitored.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the access state associated with the type of the memory access operation includes a monitored read state in response to the type of the memory access operation including a read type and a monitored write state in response to the type of the memory access operation including a write type.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>detecting a conflict in response to an external access request subsequent to execution of the memory access operation based on a type of the external access and the access state associated with a type of the memory access operation;</claim-text>
<claim-text>reporting the conflict utilizing a status register in the processor to software in response to detecting the conflict; and</claim-text>
<claim-text>executing a software handler to handle the conflict in response to reporting the conflict utilizing a status register in the processor to software.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A method comprising:
<claim-text>determining if a memory access operation referencing a data item is to be monitored;</claim-text>
<claim-text>caching the data item in a number of lines of a cache; and</claim-text>
<claim-text>in response to determining the memory access operation is to be monitored,
<claim-text>determining hardware attribute bits within coherency state entries associated with the number of lines, and</claim-text>
<claim-text>updating the hardware attribute bits within coherency state entries associated with number of lines to represent a monitored coherency state associated with the type of the memory access operation.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein determining if a memory access operation referencing a data item is to be monitored is based on an operating mode of a processor to execute the memory access operation.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein determining if a memory access operation referencing a data item is to be monitored is based on an identification by user-level software of the memory access operation as an operation to be monitored.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the access state associated with the type of the memory access operation includes a monitored read state in response to the type of the memory access operation including a read type and a monitored write state in response to the type of the memory access operation including a write type.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:
<claim-text>detecting a conflict in response to an external access request subsequent to execution of the memory access operation based on a type of the external access and the access state associated with a type of the memory access operation;</claim-text>
<claim-text>reporting the conflict utilizing a status register in the processor to software in response to detecting the conflict; and</claim-text>
<claim-text>executing a software handler to handle the conflict in response to reporting the conflict utilizing a status register in the processor to software.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An apparatus comprising:
<claim-text>execution logic configured to execute a transactional memory access operation to reference a memory address to be associated with a data item;</claim-text>
<claim-text>a memory coupled to the processing logic, the memory configured to hold the data item unaligned with boundaries of a plurality of lines of the memory in response to the execution logic executing the transactional memory access operation; and</claim-text>
<claim-text>a plurality of read monitors and a plurality of write monitors corresponding to the plurality of memory lines of the memory the plurality of read monitors and write monitors configured to perform bounded access monitoring of the data item despite a granularity of the memory in response to the execution logic executing the transactional memory access operation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the plurality of read monitors and the plurality of write monitors are to be readable and modifiable in response to the execution logic executing user-level instructions.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the memory includes a data cache.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the transactional memory access operation includes a transactional load, and wherein the hardware monitors associated with the data cache to perform bounded access monitoring of the data item despite a granularity of the memory in response to the execution logic executing the transactional load comprises a number of read monitors of the plurality of read monitors, which correspond to the number of cache lines of the plurality of cache lines holding at least a portion of the data item, to be updated to a monitored read state in response to the execution logic executing the transactional load.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the transactional memory access operation includes a transactional store, and wherein the hardware monitors associated with the data cache to perform bounded access monitoring of the data item despite a granularity of the memory in response to the execution logic executing the transactional store comprises a number of write monitors of the plurality of write monitors, which correspond to the number of cache lines of the plurality of cache lines holding at least a portion of the data item, to be updated to a monitored write state in response to the execution logic executing the transactional write.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein control logic is to detect a transactional conflict in response to the control logic detecting an external write request to a cache line of the number of cache lines when a read monitor of the number of read monitors corresponding to the cache line is updated to the monitored read state.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the control logic is to detect a transactional conflict in response to the control logic detecting an external read request from a cache line of the number of cache lines when a write monitor of the number of write monitors corresponding to the cache line is updated to the monitored write state.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the number of read monitors and the number of write monitors are to be reset to an unmonitored state in response to the execution logic executing a user-level clear operation.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the number includes an integer greater than one.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the plurality of read monitors and the plurality of write monitors are to be associated with the memory dynamically based on a size of the data item.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The apparatus of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the the plurality of read monitors and the plurality of write monitors are to be associated with the memory dynamically based on a size of the data item comprises logic to dynamically assign a read monitor and a write monitor from a pool of the plurlaity of read monitors and the plurliaty of write monitors to a plurality of lines of the memory, which are to hold at least a portion of the data item, responsive to the size of the data item being greater than a line of the memory and the execution logic executing the transactional memory access operation.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The apparatus of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the plurality of read monitors and the plurality of write monitors associated with the memory to perform bounded access monitoring of the data item despite a granularity of the memory in response to the execution logic executing the transactional memory access operation comprises the read monitor assigned to the plurality of lines being set to a read monitored state in response to the execution logic executing the a transactional load operation and the write monitor assigned to the plurality of liens being set to a write monitored state in response to the execution logic executing a transactional store operation.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. An apparatus comprising:
<claim-text>execution logic configured to execute a transactional memory access operation to reference a memory address to be associated with a data item;</claim-text>
<claim-text>a memory coupled to the processing logic, the memory configured to hold the data item in response to the execution logic executing the transactional memory access operation; and</claim-text>
<claim-text>a plurality of read monitors and a plurality of write monitors to be associated with the memory dynamically based on a size of the data item, the plurality of read monitors and write monitors configured to perform bounded access monitoring of the data item despite a granularity of the memory in response to the execution logic executing the transactional memory access operation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The apparatus of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the the plurality of read monitors and the plurality of write monitors are to be associated with the memory dynamically based on a size of the data item comprises logic to dynamically assign a read monitor and a write monitor from a pool of the plurlaity of read monitors and the plurliaty of write monitors to a plurality of lines of the memory, which are to hold at least a portion of the data item, responsive to the size of the data item being greater than a line of the memory and the execution logic executing the transactional memory access operation.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The apparatus of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the plurality of read monitors and the plurality of write monitors associated with the memory to perform bounded access monitoring of the data item despite a granularity of the memory in response to the execution logic executing the transactional memory access operation comprises the read monitor assigned to the plurality of lines being set to a read monitored state in response to the execution logic executing the a transactional load operation and the write monitor assigned to the plurality of liens being set to a write monitored state in response to the execution logic executing a transactional store operation.</claim-text>
</claim>
</claims>
</us-patent-grant>
