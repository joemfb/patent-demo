<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626211-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626211</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13594042</doc-number>
<date>20120824</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2011-0117330</doc-number>
<date>20111111</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>1</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>11</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>B</subclass>
<main-group>1</main-group>
<subgroup>38</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>455466</main-classification>
<further-classification>4555501</further-classification>
<further-classification>455566</further-classification>
<further-classification>345634</further-classification>
<further-classification>379 9323</further-classification>
</classification-national>
<invention-title id="d2e69">Mobile terminal and controlling method thereof</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6069648</doc-number>
<kind>A</kind>
<name>Suso et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1402</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2004/0092284</doc-number>
<kind>A1</kind>
<name>Satoh et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4555501</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2006/0277266</doc-number>
<kind>A1</kind>
<name>Kim et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709206</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2007/0035616</doc-number>
<kind>A1</kind>
<name>Lee et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1416</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2007/0115109</doc-number>
<kind>A1</kind>
<name>Turney et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>340506</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0275762</doc-number>
<kind>A1</kind>
<name>Aaltone et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455566</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2007/0291107</doc-number>
<kind>A1</kind>
<name>Kang</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1401</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2007/0296739</doc-number>
<kind>A1</kind>
<name>Lonn</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345634</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2010/0057466</doc-number>
<kind>A1</kind>
<name>Garg et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704260</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2011/0047487</doc-number>
<kind>A1</kind>
<name>DeWeese et al.</name>
<date>20110200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715758</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>WO</country>
<doc-number>WO 0193590</doc-number>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
</us-citation>
</us-references-cited>
<number-of-claims>8</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>3405391</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>34053925</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345  4</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>455466</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>455566</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>4555501</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709206</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>725109</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>34</number-of-drawing-sheets>
<number-of-figures>36</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130122944</doc-number>
<kind>A1</kind>
<date>20130516</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yun</last-name>
<first-name>Yeerang</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yoon</last-name>
<first-name>Sungyoung</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yeo</last-name>
<first-name>Byungsang</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Jiyoun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Park</last-name>
<first-name>Jinwoo</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Yun</last-name>
<first-name>Yeerang</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Yoon</last-name>
<first-name>Sungyoung</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Yeo</last-name>
<first-name>Byungsang</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Jiyoun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Park</last-name>
<first-name>Jinwoo</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>KED &#x26; Associates LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>LG Electronics Inc.</orgname>
<role>03</role>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Sivji</last-name>
<first-name>Nizar</first-name>
<department>2645</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A mobile terminal and controlling method thereof are disclosed. The present invention includes an A/V input unit receiving an input of a surrounding image via an image sensor, a display unit, a wireless communication unit, a memory recording an image inputted by real time via the camera as a real-time taken data, and a controller controlling the real-time taken data to be outputted to the display unit, the controller controlling the wireless communication unit to relay the real-time taken data to at least one external terminal by real time, the controller controlling the display unit to display a 1<sup>st </sup>type message related to the real-time taken data and a 2<sup>nd </sup>type message not related to the real-time taken data in a manner that the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message are visually discriminated from each other.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="142.16mm" wi="99.82mm" file="US08626211-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="205.66mm" wi="168.40mm" file="US08626211-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="125.56mm" wi="142.32mm" file="US08626211-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="228.94mm" wi="150.88mm" file="US08626211-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="175.51mm" wi="93.90mm" file="US08626211-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="172.72mm" wi="103.12mm" file="US08626211-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="179.24mm" wi="95.76mm" file="US08626211-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="171.20mm" wi="96.94mm" file="US08626211-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="139.95mm" wi="148.00mm" file="US08626211-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="175.26mm" wi="106.26mm" file="US08626211-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="175.85mm" wi="97.54mm" file="US08626211-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="181.44mm" wi="105.66mm" file="US08626211-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="167.81mm" wi="106.85mm" file="US08626211-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="172.13mm" wi="99.40mm" file="US08626211-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="175.26mm" wi="108.71mm" file="US08626211-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="175.26mm" wi="102.53mm" file="US08626211-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="172.13mm" wi="91.95mm" file="US08626211-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="171.53mm" wi="101.52mm" file="US08626211-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="176.45mm" wi="109.98mm" file="US08626211-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="172.72mm" wi="100.08mm" file="US08626211-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="178.31mm" wi="99.40mm" file="US08626211-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="178.31mm" wi="106.26mm" file="US08626211-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="218.10mm" wi="155.36mm" file="US08626211-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="233.68mm" wi="153.50mm" file="US08626211-20140107-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="230.04mm" wi="155.62mm" file="US08626211-20140107-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="136.82mm" wi="152.99mm" file="US08626211-20140107-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00026" num="00026">
<img id="EMI-D00026" he="165.27mm" wi="101.94mm" file="US08626211-20140107-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00027" num="00027">
<img id="EMI-D00027" he="144.78mm" wi="103.80mm" file="US08626211-20140107-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00028" num="00028">
<img id="EMI-D00028" he="224.62mm" wi="90.00mm" file="US08626211-20140107-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00029" num="00029">
<img id="EMI-D00029" he="179.41mm" wi="103.72mm" file="US08626211-20140107-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00030" num="00030">
<img id="EMI-D00030" he="173.40mm" wi="101.26mm" file="US08626211-20140107-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00031" num="00031">
<img id="EMI-D00031" he="173.65mm" wi="98.21mm" file="US08626211-20140107-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00032" num="00032">
<img id="EMI-D00032" he="176.45mm" wi="106.85mm" file="US08626211-20140107-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00033" num="00033">
<img id="EMI-D00033" he="178.31mm" wi="108.12mm" file="US08626211-20140107-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00034" num="00034">
<img id="EMI-D00034" he="175.85mm" wi="106.85mm" file="US08626211-20140107-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading>
<p id="p-0002" num="0001">Pursuant to 35 U.S.C. &#xa7;119(a), this application claims the benefit of earlier filing date and right of priority to Korean Application No. 10-2011-0117330, filed on Nov. 11, 2011, the contents of which are hereby incorporated by reference herein in their entirety.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">1. Field</p>
<p id="p-0004" num="0003">The present invention relates to a mobile terminal, and more particularly, to a mobile terminal and controlling method thereof. Although the present invention is suitable for a wide scope of applications, it is particularly suitable for relaying a taken-image by real time.</p>
<p id="p-0005" num="0004">2. Background</p>
<p id="p-0006" num="0005">Generally, terminals can be classified into mobile/portable terminals and stationary terminals. The mobile terminals can be further classified into handheld terminals and vehicle mount terminals according to possibility of user's direct portability.</p>
<p id="p-0007" num="0006">As functions of the terminal are getting diversified, the terminal tends to be implemented as a multimedia player provided with composite functions such as photographing of photos or videos, playback of music or video files, game play, broadcast reception and the like for example.</p>
<p id="p-0008" num="0007">To support and increase the terminal functions, it may be able to consider the improvement of structural parts and/or software parts of the terminal.</p>
<p id="p-0009" num="0008">A mobile terminal performs an inter-terminal communication through a messaging service. For instance, the message service may be categorized into SMS (short message service), LMS (long message service) and MMS (multimedia message service). The MMS may mean a messaging service capable of attaching various kinds of multimedia files such as image files, music files, video files, audio files and the like, whereas the SMS or LMS is a text based messaging service.</p>
<p id="p-0010" num="0009">Although a related art messaging service enables a transmission of a photographing-completed video file to a prescribed external terminal, it is unable to transmit a taken image by real time to a prescribed external terminal.</p>
<p id="p-0011" num="0010">An instant messaging service, which provides a messaging environment equal to a computing environment, is coming into wide use together with a smart phone. However, it may be still impossible for the instant messaging service to transmit a taken image by real time to a prescribed external terminal.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0012" num="0011">Accordingly, the present invention is directed to a mobile terminal and controlling method thereof that substantially obviate one or more problems due to limitations and disadvantages of the related art.</p>
<p id="p-0013" num="0012">An object of the present invention is to provide a mobile terminal and controlling method thereof, by which a message service different from conventional message services can be provided.</p>
<p id="p-0014" num="0013">Another object of the present invention is to provide a mobile terminal and controlling method thereof, by which an image taken by real time by the mobile terminal can be relayed live to an external terminal.</p>
<p id="p-0015" num="0014">Another object of the present invention is to provide a mobile terminal and controlling method thereof, by which a user can be provided with visual convenience in a manner that a message transmitted/received to/from an external terminal is set to be visually discriminated from other messages in the course of relaying a real-time taken image.</p>
<p id="p-0016" num="0015">A further object of the present invention is to provide a system, by which a taken image can be relayed by real time despite that an operating system of a mobile terminal is different from that of an external terminal.</p>
<p id="p-0017" num="0016">Additional advantages, objects, and features of the invention will be set forth in part in the description which follows and in part will become apparent to those having ordinary skill in the art upon examination of the following or may be learned from practice of the invention. The objectives and other advantages of the invention may be realized and attained by the structure particularly pointed out in the written description and claims hereof as well as the appended drawings.</p>
<p id="p-0018" num="0017">To achieve these objects and other advantages and in accordance with the purpose of the invention, as embodied and broadly described herein, a mobile terminal according to the present invention may include a camera receiving an input of a surrounding image, a display unit, a wireless communication unit, a memory recording an image inputted by real time via the camera as a real-time taken data, and a controller controlling the real-time taken data to be outputted to the display unit, the controller controlling the wireless communication unit to relay the real-time taken data to at least one external terminal by real time, the controller controlling the display unit to display a 1<sup>st </sup>type message related to the real-time taken data and a 2<sup>nd </sup>type message not related to the real-time taken data in a manner that the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message are visually discriminated from each other.</p>
<p id="p-0019" num="0018">In another aspect of the present invention, a method of controlling a mobile terminal may include a 1<sup>st </sup>step of activating an A/V (audio/video) input unit, a 2<sup>nd </sup>step of relaying a real-time taken data inputted by real time via the A/V input unit to an external terminal, and a 3<sup>rd </sup>step of displaying the real-time taken data inputted by real time via the A/V input unit, a 1<sup>st </sup>type message related to the real-time taken data and a 2<sup>nd </sup>type message not related to the real-time taken data in a manner that the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message are visually discriminated from each other.</p>
<p id="p-0020" num="0019">In a further aspect of the present invention, a computer-readable recording medium may include a program recorded therein to control a mobile terminal, the program including a command to activate an A/V (audio/video) input unit, a command to relay a real-time taken data inputted by real time via the A/V input unit to an external terminal, and a command to display the real-time taken data inputted by real time via the A/V input unit, a 1<sup>st </sup>type message related to the real-time taken data and a 2<sup>nd </sup>type message not related to the real-time taken data in a manner that the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message are visually discriminated from each other.</p>
<p id="p-0021" num="0020">Accordingly, the present invention provides the following effects and/or advantages.</p>
<p id="p-0022" num="0021">First of all, a mobile terminal according to at least one embodiment of the present invention may be able to relay a taken image of surroundings to an external terminal by real time.</p>
<p id="p-0023" num="0022">Secondly, the present invention may provide a user with visual convenience in a manner that a message transmitted/received to/from an external terminal is set to be visually discriminated from other messages in the course of relaying a real-time taken image.</p>
<p id="p-0024" num="0023">Thirdly, the present invention may be able to relay a taken image by real time despite that an operating system of a mobile terminal is different from that of an external terminal.</p>
<p id="p-0025" num="0024">Effects obtainable from the present invention may be non-limited by the above mentioned effect. And, other unmentioned effects can be clearly understood from the following description by those having ordinary skill in the technical field to which the present invention pertains.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0026" num="0025">The embodiments will be described in detail with reference to the following drawings in which like reference numerals refer to like elements wherein:</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a mobile terminal according to one embodiment of the present invention;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 2</figref> is a front perspective diagram of a mobile or handheld terminal according to one embodiment of the present invention;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart for a method of controlling a mobile terminal according to one embodiment of the present invention;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 4A</figref> and <figref idref="DRAWINGS">FIG. 4B</figref> are diagrams for examples of a screen related to a message module provided to a user;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 5A</figref> and <figref idref="DRAWINGS">FIG. 5B</figref> are diagrams for output examples of a display unit provided to a user to enter a casting mode;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram for one example of a screen related to a camera module provided to a user;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 7A</figref> and <figref idref="DRAWINGS">FIG. 7B</figref> are diagrams for output examples of a display unit to describe 1<sup>st </sup>and 2<sup>nd </sup>regions of the display unit;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. 8A to 8C</figref> are diagrams for output examples of a display unit provided to a user to add an external terminal;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIGS. 9A to 9C</figref> are diagrams for output examples of a display unit to describe that a 1<sup>st </sup>type message is displayed;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIGS. 10A to 10D</figref> are diagrams for examples to describe a controlling method in case that real-time taken data deviates from a 1<sup>st </sup>region;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram for one example of a screen for uploading real-time taken data and a 1<sup>st </sup>type message to Facebook site;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart for a method of controlling a mobile terminal according to another embodiment of the present invention;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 13A</figref> and <figref idref="DRAWINGS">FIG. 13B</figref> are diagrams of screens provided to a user to enter a casting mode;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIGS. 14A to 14C</figref> are diagrams for examples of screens for displaying real-time taken data on a full screen;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram for one example of an output of a display unit for outputting real-time taken data in a status that a map is set as a background screen;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 16</figref> is a diagram of configuration to describe that real-time taken data is transmitted to an external terminal via a cloud server;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 17</figref> is a flowchart for controlling a mobile terminal in case of receiving real-time taken data according to another embodiment of the present invention;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 18</figref> is a diagram for one example of a screen having a casting mode indication message displayed thereon;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 19A</figref> and <figref idref="DRAWINGS">FIG. 19B</figref> are diagrams for examples of screen configuration in case that a mobile terminal receives real-time taken data;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 20</figref> is a diagram for one example of a screen for discriminating a 1<sup>st </sup>type message and a 2<sup>nd </sup>type message from each other;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 21</figref> is a diagram for one example of a screen at the end of a casting mode is ended; and</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 22</figref> is a diagram for one example of a screen for a reception of a new message after end of a casting mode.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0049" num="0048">In the following detailed description, reference is made to the accompanying drawing figures which form a part hereof, and which show by way of illustration specific embodiments of the invention. It is to be understood by those of ordinary skill in this technological field that other embodiments may be utilized, and structural, electrical, as well as procedural changes may be made without departing from the scope of the present invention. Wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or similar parts.</p>
<p id="p-0050" num="0049">As used herein, the suffixes &#x2018;module&#x2019;, &#x2018;unit&#x2019; and &#x2018;part&#x2019; are often used for elements in order to facilitate discussion of the disclosure. Therefore, significant meanings or roles are not given to the suffixes themselves and it is understood that the &#x2018;module&#x2019;, &#x2018;unit&#x2019; and &#x2018;part&#x2019; can be used together or interchangeably.</p>
<p id="p-0051" num="0050">Various types of terminals may be implemented using the various techniques discussed herein. Examples of such terminals include mobile as well as stationary terminals, such as mobile phones, user equipment, smart phones, DTV, computers, digital broadcast terminals, personal digital assistants, portable multimedia players (PMPs), navigators, and the like. By way of non-limiting example only, further description will be with regard to a mobile terminal <b>100</b>, and such teachings may apply equally to other types of terminals.</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a mobile terminal <b>100</b> in accordance with an embodiment of the present invention. <figref idref="DRAWINGS">FIG. 1</figref> shows the mobile terminal <b>100</b> having a wireless communication unit <b>110</b>, an A/V (audio/video) input unit <b>120</b>, a user input unit <b>130</b>, a sensing unit <b>140</b>, an output unit <b>150</b>, a memory <b>160</b>, an interface unit <b>170</b>, a controller <b>180</b>, a power supply unit <b>190</b>, among other components. Mobile terminal <b>100</b> is shown having various components, but it is understood that implementing all of the illustrated components is not a requirement as greater or fewer components may alternatively be implemented.</p>
<p id="p-0053" num="0052">First of all, the wireless communication unit <b>110</b> typically includes one or more components which permits wireless communication between the mobile terminal <b>100</b> and a wireless communication system or network within which the mobile terminal <b>100</b> is located. For instance, the wireless communication unit <b>110</b> can include a broadcast receiving module <b>111</b>, a mobile communication module <b>112</b>, a wireless internet module <b>113</b>, a short-range communication module <b>114</b>, a position-location module <b>115</b>, and the like.</p>
<p id="p-0054" num="0053">The broadcast receiving module <b>111</b> receives a broadcast signal and/or broadcast associated information from an external broadcast managing server via a broadcast channel. The broadcast channel may include a satellite channel and a terrestrial channel. The broadcast managing server generally refers to a server which generates and transmits a broadcast signal and/or broadcast associated information or a server which is provided with a previously generated broadcast signal and/or broadcast associated information and then transmits the provided signal or information to a terminal. The broadcast signal may be implemented as a TV broadcast signal, a radio broadcast signal, and a data broadcast signal, among others. If desired, the broadcast signal may further include a broadcast signal combined with a TV or radio broadcast signal.</p>
<p id="p-0055" num="0054">The broadcast associated information includes information associated with a broadcast channel, a broadcast program, a broadcast service provider, etc. This broadcast associated information can also be provided via a mobile communication network. In this case, the broadcast associated information can be received by the mobile communication module <b>112</b>.</p>
<p id="p-0056" num="0055">The broadcast associated information can be implemented in various forms. For instance, broadcast associated information may include an electronic program guide (EPG) of digital multimedia broadcasting (DMB) and electronic service guide (ESG) of digital video broadcast-handheld (DVB-H).</p>
<p id="p-0057" num="0056">The broadcast receiving module <b>111</b> may be configured to receive broadcast signals transmitted from various types of broadcast systems. By non-limiting example, such broadcasting systems include digital multimedia broadcasting-terrestrial (DMB-T), digital multimedia broadcasting-satellite (DMB-S), digital video broadcast-handheld (DVB-H), the data broadcasting system known as media forward link only (MediaFLO&#xae;) and integrated services digital broadcast-terrestrial (ISDB-T). Optionally, the broadcast receiving module <b>111</b> can be configured to be suitable for other broadcasting systems as well as the above-identified digital broadcasting systems.</p>
<p id="p-0058" num="0057">The broadcast signal and/or broadcast associated information received by the broadcast receiving module <b>111</b> may be stored in a suitable device, such as a memory <b>160</b>.</p>
<p id="p-0059" num="0058">The mobile communication module <b>112</b> transmits/receives wireless signals to/from one or more network entities (e.g., base station, external terminal, server, etc.). Such wireless signals may represent audio, video, and data according to text/multimedia message transceiving, among others.</p>
<p id="p-0060" num="0059">The wireless internet module <b>113</b> supports Internet access for the mobile terminal <b>100</b>. This module may be internally or externally coupled to the mobile terminal <b>100</b>. In this case, the wireless Internet technology can include WLAN (Wireless LAN) (Wi-Fi), Wibro (Wireless broadband), Wimax (World Interoperability for Microwave Access), HSDPA (High Speed Downlink Packet Access), and the like.</p>
<p id="p-0061" num="0060">The short-range communication module <b>114</b> facilitates relatively short-range communications. Suitable technologies for implementing this module include radio frequency identification (RFID), infrared data association (IrDA), ultra-wideband (UWB), as well at the networking technologies commonly referred to as Bluetooth and ZigBee, to name a few.</p>
<p id="p-0062" num="0061">The position-location module <b>115</b> identifies or otherwise obtains the location of the mobile terminal <b>100</b>. If desired, this module may be implemented with a global positioning system (GPS) module.</p>
<p id="p-0063" num="0062">Referring still to <figref idref="DRAWINGS">FIG. 1</figref>, the audio/video (NV) input unit <b>120</b> is shown configured to provide audio or video signal input to the mobile terminal <b>100</b>. As shown, the A/V input unit <b>120</b> includes a camera <b>121</b> and a microphone <b>122</b>. The camera <b>121</b> receives and processes image frames of still pictures or video, which are obtained by an image sensor in a video call mode or a photographing mode. Typically, the processed image frames can be displayed on the display <b>151</b>.</p>
<p id="p-0064" num="0063">The image frames processed by the camera <b>121</b> can be stored in the memory <b>160</b> or can be externally transmitted via the wireless communication unit <b>110</b>. Optionally, two or more cameras <b>121</b> can be provided to the mobile terminal <b>100</b> according to the environment in which the terminal used to according to user needs.</p>
<p id="p-0065" num="0064">The microphone <b>122</b> receives an external audio signal while the portable device is in a particular mode, such as phone call mode, recording mode and voice recognition mode. This audio signal is processed and converted into electric audio data. The processed audio data is transformed into a format transmittable to a mobile communication base station via the mobile communication module <b>112</b> in case of a call mode. The microphone <b>122</b> typically includes assorted noise removing algorithms to remove noise generated in the course of receiving the external audio signal.</p>
<p id="p-0066" num="0065">The user input unit <b>130</b> generates input data responsive to user manipulation of an associated input device or devices. Examples of such devices include a keypad, a dome switch, a touchpad (e.g., static pressure/capacitance), a jog wheel, a jog switch, and the like.</p>
<p id="p-0067" num="0066">The sensing unit <b>140</b> provides sensing signals for controlling operations of the mobile terminal <b>100</b> using status measurements of various aspects of the mobile terminal. For instance, the sensing unit <b>140</b> may detect an open/close status of the mobile terminal <b>100</b>, relative positioning of components (e.g., a display and keypad) of the mobile terminal <b>100</b>, a change of position of the mobile terminal <b>100</b> or a component of the mobile terminal <b>100</b>, a presence or absence of user contact with the mobile terminal <b>100</b>, orientation or acceleration/deceleration of the mobile terminal <b>100</b>.</p>
<p id="p-0068" num="0067">As an example, consider the mobile terminal <b>100</b> being configured as a slide-type mobile terminal. In this configuration, the sensing unit <b>140</b> may sense whether a sliding portion of the mobile terminal is open or closed. Other examples include the sensing unit <b>140</b> sensing the presence or absence of power provided by the power supply <b>190</b>, the presence or absence of a coupling or other connection between the interface unit <b>170</b> and an external device. If desired, the sensing unit <b>140</b> can include a proximity sensor <b>141</b>.</p>
<p id="p-0069" num="0068">The output unit <b>150</b> generates outputs relevant to the senses of sight, hearing, touch and the like. In some cases, the output unit <b>150</b> includes the display <b>151</b>, an audio output module <b>152</b>, an alarm unit <b>153</b>, a haptic module <b>154</b>, a projector module <b>155</b>, and the like.</p>
<p id="p-0070" num="0069">The display <b>151</b> is typically implemented to visually display (output) information associated with the mobile terminal <b>100</b>. For instance, if the mobile terminal is operating in a phone call mode, the display will generally provide a user interface (UI) or graphical user interface (GUI) which includes information associated with placing, conducting, and terminating a phone call. As another example, if the mobile terminal <b>100</b> is in a video call mode or a photographing mode, the display <b>151</b> may additionally or alternatively display images which are associated with these modes, the UI or the GUI.</p>
<p id="p-0071" num="0070">The display module <b>151</b> may be implemented using known display technologies including, for example, a liquid crystal display (LCD), a thin film transistor-liquid crystal display (TFT-LCD), an organic light-emitting diode display (OLED), a flexible display and a three-dimensional display. The mobile terminal <b>100</b> may include one or more of such displays.</p>
<p id="p-0072" num="0071">Some of the above displays can be implemented in a transparent or optical transmissive type, which can be named a transparent display. As a representative example for the transparent display, there is TOLED (transparent OLED) or the like. A rear configuration of the display <b>151</b> can be implemented in the optical transmissive type as well. In this configuration, a user is able to see an object in rear of a terminal body via the area occupied by the display <b>151</b> of the terminal body.</p>
<p id="p-0073" num="0072">At least two displays <b>151</b> can be provided to the mobile terminal <b>100</b> in accordance with the implemented configuration of the mobile terminal <b>100</b>. For instance, a plurality of displays can be arranged on a single face of the mobile terminal <b>100</b> in a manner of being spaced apart from each other or being built in one body. Alternatively, a plurality of displays can be arranged on different faces of the mobile terminal <b>100</b>.</p>
<p id="p-0074" num="0073">In the case where the display <b>151</b> and a sensor for detecting a touch action (hereinafter also referred to a &#x2018;touch sensor&#x2019;) configures a mutual layer structure (hereinafter also referred to a &#x2018;touchscreen&#x2019;), the user can use the display <b>151</b> as an input device as well as an output device. In this case, the touch sensor can be configured as a touch film, a touch sheet, a touchpad or the like.</p>
<p id="p-0075" num="0074">The touch sensor can be configured to convert a pressure applied to a specific portion of the display <b>151</b> or a variation of a capacitance generated from a specific portion of the display <b>151</b> to an electric input signal. Moreover, it is able to configure the touch sensor to detect a pressure of a touch as well as a touched position or size.</p>
<p id="p-0076" num="0075">If a touch input is made to the touch sensor, signal(s) corresponding to the touch is transferred to a touch controller. The touch controller processes the signal(s) and then transfers the processed signal(s) to the controller <b>180</b>. Therefore, the controller <b>180</b> is able to know whether a prescribed portion of the display <b>151</b> is touched.</p>
<p id="p-0077" num="0076">With continued reference to <figref idref="DRAWINGS">FIG. 1</figref>, a proximity sensor (not shown in the drawing) can be provided to an internal area of the mobile terminal <b>100</b> enclosed by the touchscreen or proximate to the touchscreen. The proximity sensor is the sensor that detects a presence or non-presence of an object approaching a prescribed detecting surface or an object existing around the proximity sensor using an electromagnetic field strength or infrared ray without mechanical contact. Hence, the proximity sensor has durability longer than that of a contact type sensor and also has utility wider than that of the contact type sensor.</p>
<p id="p-0078" num="0077">The proximity sensor can include one or more of a transmissive photoelectric sensor, a direct reflective photoelectric sensor, a mirror reflective photoelectric sensor, a radio frequency oscillation proximity sensor, an electrostatic capacity proximity sensor, a magnetic proximity sensor, an infrared proximity sensor, and the like. When the touchscreen includes the electrostatic capacity proximity sensor, it may also be configured to detect the proximity of a pointer using a variation of electric field according to the proximity of the pointer. In this scenario, the touchscreen (touch sensor) can be classified as a proximity sensor.</p>
<p id="p-0079" num="0078">In the following description, for clarity, an action that a pointer approaches without contacting with the touchscreen to be recognized as located on the touchscreen is referred to as &#x2018;proximity touch&#x2019; while an action that a pointer actually touches the touchscreen may be referred to as a &#x2018;contact touch&#x2019;. The meaning of the position on the touchscreen proximity-touched by the pointer refers to the position of the pointer which vertically opposes the touchscreen when the pointer performs the proximity touch.</p>
<p id="p-0080" num="0079">The proximity sensor detects a proximity touch and a proximity touch pattern (e.g., a proximity touch distance, a proximity touch duration, a proximity touch position, a proximity touch shift state, etc.). In addition, information corresponding to the detected proximity touch action and the detected proximity touch pattern can be outputted to the touchscreen.</p>
<p id="p-0081" num="0080">The audio output module <b>152</b> functions in various modes including a call-receiving mode, a call-placing mode, a recording mode, a voice recognition mode, a broadcast reception mode and the like to output audio data which is received from the wireless communication unit <b>110</b> or is stored in the memory <b>160</b>. During operation, the audio output module <b>152</b> outputs audio relating to a particular function (e.g., call received, message received, etc.). The audio output module <b>152</b> is often implemented using one or more speakers, buzzers, other audio producing devices, and combinations thereof.</p>
<p id="p-0082" num="0081">The alarm unit <b>153</b> is output a signal for announcing the occurrence of a particular event associated with the mobile terminal <b>100</b>. Typical events include a call received event, a message received event and a touch input received event. The alarm unit <b>153</b> is able to output a signal for announcing the event occurrence by way of vibration as well as video or audio signal. The video or audio signal can be outputted via the display <b>151</b> or the audio output unit <b>152</b>. Hence, the display <b>151</b> or the audio output module <b>152</b> can be regarded as a part of the alarm unit <b>153</b>.</p>
<p id="p-0083" num="0082">The haptic module <b>154</b> generates various tactile effects that can be sensed by a user. Vibration is a representative one of the tactile effects generated by the haptic module <b>154</b>. Strength and pattern of the vibration generated by the haptic module <b>154</b> are controllable. For instance, different vibrations can be outputted in a manner of being synthesized together or can be outputted in sequence.</p>
<p id="p-0084" num="0083">The haptic module <b>154</b> is able to generate various tactile effects as well as the vibration. For instance, the haptic module <b>154</b> generates the effect attributed to the arrangement of pins vertically moving against a contact skin surface, the effect attributed to the injection/suction power of air though an injection/suction hole, the effect attributed to the skim over a skin surface, the effect attributed to the contact with electrode, the effect attributed to the electrostatic force, the effect attributed to the representation of hold/cold sense using an endothermic or exothermic device and the like.</p>
<p id="p-0085" num="0084">The haptic module <b>154</b> can be implemented to enable a user to sense the tactile effect through a muscle sense of finger, arm or the like as well as to transfer the tactile effect through a direct contact. Optionally, at least two haptic modules <b>154</b> can be provided to the mobile terminal <b>100</b> in accordance with the corresponding configuration type of the mobile terminal <b>100</b>.</p>
<p id="p-0086" num="0085">The projector module <b>155</b> is the element for performing an image projector function using the mobile terminal <b>100</b>. And, the projector module <b>155</b> is able to display an image, which is identical to or partially different at least from the image displayed on the display <b>151</b>, on an external screen or wall according to a control signal of the controller <b>180</b>.</p>
<p id="p-0087" num="0086">In particular, the projector module <b>155</b> can include a light source (not shown in the drawing) generating light (e.g., laser) for projecting an image externally, an image producing element (not shown in the drawing) for producing an image to output externally using the light generated from the light source, and a lens (not shown in the drawing) for enlarging the image for output externally at predetermined focus distance. The projector module <b>155</b> can further include a device (not shown in the drawing) for adjusting an image projected direction by mechanically moving the lens or the whole module.</p>
<p id="p-0088" num="0087">The projector module <b>155</b> can be classified into a CRT (cathode ray tube) module, an LCD (liquid crystal display) module, a DLP (digital light processing) module or the like according to a device type of a display means. In particular, the DLP module is operated by the mechanism of enabling the light generated from the light source to reflect on a DMD (digital micro-mirror device) chip and can be advantageous for the downsizing of the projector module <b>151</b>.</p>
<p id="p-0089" num="0088">Preferably, the projector module <b>155</b> can be provided in a length direction of a lateral, front or backside direction of the mobile terminal <b>100</b>. It is understood that the projector module <b>155</b> can be provided to any portion of the mobile terminal <b>100</b> according to the necessity thereof.</p>
<p id="p-0090" num="0089">The memory unit <b>160</b> is generally used to store various types of data to support the processing, control, and storage requirements of the mobile terminal <b>100</b>. Examples of such data include program instructions for applications operating on the mobile terminal <b>100</b>, contact data, phonebook data, messages, audio, still pictures, moving pictures, etc. And, a recent use history or a cumulative use frequency of each data (e.g., use frequency for each phonebook, each message or each multimedia) can be stored in the memory unit <b>160</b>. Moreover, data for various patterns of vibration and/or sound outputted in case of a touch input to the touchscreen can be stored in the memory unit <b>160</b>.</p>
<p id="p-0091" num="0090">The memory <b>160</b> may be implemented using any type or combination of suitable volatile and non-volatile memory or storage devices including hard disk, random access memory (RAM), static random access memory (SRAM), electrically erasable programmable read-only memory (EEPROM), erasable programmable read-only memory (EPROM), programmable read-only memory (PROM), read-only memory (ROM), magnetic memory, flash memory, magnetic or optical disk, multimedia card micro type memory, card-type memory (e.g., SD memory, XD memory, etc.), or other similar memory or data storage device. And, the mobile terminal <b>100</b> is able to operate in association with a web storage for performing a storage function of the memory <b>160</b> on the Internet.</p>
<p id="p-0092" num="0091">The interface unit <b>170</b> is often implemented to couple the mobile terminal <b>100</b> with external devices. The interface unit <b>170</b> receives data from the external devices or is supplied with the power and then transfers the data or power to the respective elements of the mobile terminal <b>100</b> or enables data within the mobile terminal <b>100</b> to be transferred to the external devices. The interface unit <b>170</b> may be configured using a wired/wireless headset port, an external charger port, a wired/wireless data port, a memory card port, a port for coupling to a device having an identity module, audio input/output ports, video input/output ports, an earphone port and/or the like.</p>
<p id="p-0093" num="0092">The identity module is the chip for storing various kinds of information for authenticating a use authority of the mobile terminal <b>100</b> and can include User Identify Module (UIM), Subscriber Identity Module (SIM), Universal Subscriber Identity Module (USIM) and/or the like. A device having the identity module (hereinafter called &#x2018;identity device&#x2019;) can be manufactured as a smart card. Therefore, the identity device is connectible to the mobile terminal <b>100</b> via the corresponding port.</p>
<p id="p-0094" num="0093">When the mobile terminal <b>110</b> is connected to an external cradle, the interface unit <b>170</b> becomes a passage for supplying the mobile terminal <b>100</b> with a power from the cradle or a passage for delivering various command signals inputted from the cradle by a user to the mobile terminal <b>100</b>. Each of the various command signals inputted from the cradle or the power can operate as a signal enabling the mobile terminal <b>100</b> to recognize that it is correctly loaded in the cradle.</p>
<p id="p-0095" num="0094">The controller <b>180</b> typically controls the overall operations of the mobile terminal <b>100</b>. For example, the controller <b>180</b> performs the control and processing associated with voice calls, data communications, video calls, etc. The controller <b>180</b> may include a multimedia module <b>181</b> that provides multimedia playback. The multimedia module <b>181</b> may be configured as part of the controller <b>180</b>, or implemented as a separate component. Moreover, the controller <b>180</b> is able to perform a pattern recognizing process for recognizing a writing input and a picture drawing input carried out on the touchscreen as characters or images, respectively.</p>
<p id="p-0096" num="0095">The power supply unit <b>190</b> provides power required by the various components for the mobile terminal <b>100</b>. The power may be internal power, external power, or combinations thereof.</p>
<p id="p-0097" num="0096">Various embodiments described herein may be implemented in a computer-readable medium using, for example, computer software, hardware, or some combination thereof. For a hardware implementation, the embodiments described herein may be implemented within one or more application specific integrated circuits (ASICs), digital signal processors (DSPs), digital signal processing devices (DSPDs), programmable logic devices (PLDs), field programmable gate arrays (FPGAs), processors, controllers, micro-controllers, microprocessors, other electronic units designed to perform the functions described herein, or a selective combination thereof. Such feature may also be implemented by the controller <b>180</b>.</p>
<p id="p-0098" num="0097">For a software implementation, the embodiments described herein may be implemented with separate software modules, such as procedures and functions, each of which perform one or more of the functions and operations described herein. The software codes can be implemented with a software application written in any suitable programming language and may be stored in memory such as the memory <b>160</b>, and executed by a controller or processor, such as the controller <b>180</b>.</p>
<p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. 2</figref> is a front perspective diagram of a mobile terminal according to various embodiments of the present invention. The mobile terminal <b>100</b> is shown as a bar type terminal body, but the mobile terminal may alternative be implemented using other configuration such as folder-type, slide-type, rotational-type, swing-type, combinations thereof, and the like. For clarity, further disclosure will primarily relate to a bar-type mobile terminal <b>100</b>, but such teachings apply equally to other types of mobile terminals.</p>
<p id="p-0100" num="0099">Referring still to <figref idref="DRAWINGS">FIG. 2</figref>, the mobile terminal <b>100</b> includes a case (casing, housing, cover, etc.) configuring an exterior thereof. The case is shown divided into a front case <b>101</b> and a rear case <b>102</b>. Various electric/electronic parts are positioned or otherwise located in a space or cavity provided between the front and rear cases <b>101</b> and <b>102</b>. Optionally, at least one middle case can be further provided between the front and rear cases <b>101</b> and <b>102</b>. The cases <b>101</b> and <b>102</b> may be formed by injection molding of synthetic resin or they can be formed of metal substance such as stainless steel (STS), titanium (Ti) or the like, for example.</p>
<p id="p-0101" num="0100">A display <b>151</b>, an audio output unit <b>152</b>, a camera <b>121</b>, user input units <b>130</b>/<b>131</b> and <b>132</b>, a microphone <b>122</b>, an interface <b>180</b> and the like can be provided to the terminal body, and more particularly, to the front case <b>101</b>.</p>
<p id="p-0102" num="0101">The display <b>151</b> is shown occupying the majority of a main face of the front case <b>101</b>. The audio output unit <b>151</b> and the camera <b>121</b> are provided to an area adjacent to one of both end portions of the display <b>151</b>, while the user input unit <b>131</b> and the microphone <b>122</b> are provided to another area adjacent to the other end portion of the display <b>151</b>. The user input unit <b>132</b> and the interface <b>170</b> can be provided to lateral sides of the front and rear cases <b>101</b> and <b>102</b>.</p>
<p id="p-0103" num="0102">The input unit <b>130</b> is manipulated to receive a command for controlling an operation of the terminal <b>100</b>. The input unit <b>130</b> may also include a plurality of manipulating units <b>131</b> and <b>132</b>. The manipulating units <b>131</b> and <b>132</b> will sometimes be referred to herein as a manipulating portion and they may implement any mechanism of a tactile manner that enables a user to perform a manipulation action by experiencing a tactile feeling.</p>
<p id="p-0104" num="0103">Content inputted by the first or second manipulating unit <b>131</b> or <b>132</b> can be diversely set. For instance, such a command as start, end, scroll and the like is inputted to the first manipulating unit <b>131</b>. A command for volume adjustment of sound outputted from the audio output unit <b>152</b>, a command for switching to a touch recognizing mode of the display <b>151</b> or the like can be inputted to the second manipulating unit <b>132</b>.</p>
<p id="p-0105" num="0104">For clarity and convenience of the following description, assume that a mobile terminal mentioned in the following description may include at least one of the components shown in <figref idref="DRAWINGS">FIG. 1</figref>. In particular, a mobile terminal according to the present invention may include an A/V input unit <b>120</b>, a wireless communication unit <b>110</b>, a memory <b>160</b>, a display unit <b>151</b> and a controller <b>180</b>.</p>
<p id="p-0106" num="0105">The A/V input unit <b>120</b> may be able to receive an input of a surrounding image through an image sensor of a camera <b>121</b>. The A/V input unit <b>120</b> may be activated by the controller <b>180</b>. In this case, the controller <b>180</b> may be able to determine whether to activate the A/V input unit <b>120</b> based on an external input.</p>
<p id="p-0107" num="0106">The controller <b>180</b> processes an image inputted by real time through the A/V input unit <b>120</b> into a real-time taken data and then saves the corresponding data in the memory <b>160</b>. And, the controller <b>180</b> may be able to control the real-time taken data saved in the memory <b>160</b> to be displayed on the display unit <b>151</b>.</p>
<p id="p-0108" num="0107">The controller <b>180</b> may be able to control the wireless communication unit <b>110</b> to relay the real-time taken data to at least one external terminal by real time. In particular, the controller <b>180</b> may be able to control the wireless communication unit <b>110</b> to transmit the real-time taken data to the external terminal.</p>
<p id="p-0109" num="0108">In doing so, the controller <b>180</b> may be able to control the display unit <b>151</b> to display a 1<sup>st </sup>type message related to the real-time taken data and a 2<sup>nd </sup>type message having no relation with the real-time taken data in a manner that the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message are visually discriminated from each other.</p>
<p id="p-0110" num="0109"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart for a method of controlling a mobile terminal according to one embodiment of the present invention.</p>
<p id="p-0111" num="0110">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, the controller <b>180</b> executes a message application [S<b>1</b>] and then controls the display unit <b>151</b> to display a screen related to the message module.</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 4A</figref> and <figref idref="DRAWINGS">FIG. 4B</figref> are diagrams for examples of a screen related to a message application provided to a user. Referring to <figref idref="DRAWINGS">FIG. 4A</figref> and <figref idref="DRAWINGS">FIG. 4B</figref>, the controller <b>180</b> sorts a plurality of messages transceived with a plurality of external terminals by at least one of a phone number, a counterpart name and an email address and may be then able to display the sorted messages on the display unit. In particular, <figref idref="DRAWINGS">FIG. 4A</figref> is a diagram for one example of an output for sorting messages by a counterpart. If a user selects a specific counterpart from the screen provided as the example shown in <figref idref="DRAWINGS">FIG. 4A</figref>, the controller <b>180</b> may be able to control contents of the messages transceived with the selected counterpart (e.g., an external terminal of the selected counterpart) to be displayed in detail [<figref idref="DRAWINGS">FIG. 4B</figref>].</p>
<p id="p-0113" num="0112">If the user selects a particular counterpart and then enters the screen shown in <figref idref="DRAWINGS">FIG. 4B</figref>, the controller <b>180</b> may be able to control the display unit <b>151</b> to display an icon <b>11</b> for setting whether to enter a casting mode for relaying real-time taken data to the external terminal of the selected counterpart.</p>
<p id="p-0114" num="0113"><figref idref="DRAWINGS">FIG. 5A</figref> and <figref idref="DRAWINGS">FIG. 5B</figref> are diagrams for output examples of a display unit provided to a user to enter a casting mode. Referring to <figref idref="DRAWINGS">FIG. 5A</figref>, the controller <b>180</b> may be able to provide an icon <b>11</b> for determining whether to enter a casting mode. Yet, when the icon <b>11</b> is selected, if the casting mode is already active or the casting mode is active in an external terminal, referring to <figref idref="DRAWINGS">FIG. 5B</figref>, the controller <b>180</b> controls the display unit to output a toast message <b>12</b> to notify that the casting mode is not executable.</p>
<p id="p-0115" num="0114">For instance, the controller <b>180</b> may be able to enter the casting mode by inputting the icon <b>11</b> shown in <figref idref="DRAWINGS">FIG. 5A</figref> [S<b>2</b>]. When the casting mode is entered, the controller <b>180</b> activates the A/V input unit <b>120</b> [S<b>3</b>], executes the camera application [S<b>4</b>], and may be then able to control the display unit <b>151</b> to display a screen related to the camera application and an image sensed by an image sensor of the camera <b>121</b> [S<b>5</b>].</p>
<p id="p-0116" num="0115"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram for one example of a screen related to a camera application provided to a user. Referring to <figref idref="DRAWINGS">FIG. 6</figref>, if the camera application is executed, the controller <b>180</b> displays an image inputted via the A/V input unit <b>120</b> and may be then able to display a menu screen <b>13</b> for adjusting items related to the camera <b>121</b> and a recording button <b>14</b>. For instance, referring to <figref idref="DRAWINGS">FIG. 6</figref>, it may be able to provide the menu screen <b>13</b> for setting On/Off of a flash, a photographing brightness, a zoom of a camera lens and the like. Moreover, the controller <b>180</b> may be able to provide a menu for setting ISO, photographing resolution and the like. In case that at least two cameras are provided to a mobile terminal, it may be able to provide a menu for determining which camera will be used for photographing.</p>
<p id="p-0117" num="0116">When a recording is started by pressing the recording button <b>14</b> [S<b>6</b>], the controller <b>180</b> creates a real-time taken data based on the image inputted via the A/V input unit <b>120</b> and may be then able to save the real-time taken data in the memory <b>160</b> (e.g., a volatile memory, a non-volatile memory, etc.) temporarily or permanently [S<b>7</b>]. Preferably, the real-time taken data saved in the memory <b>160</b> may have a streaming playable file format, by which the real-time taken data may be non-limited. In particular, the real-time taken data may be saved using such a streaming available extension as .wmv, .mp4, .flv, .asf and the like, by which the real-time taken data may be non-limited.</p>
<p id="p-0118" num="0117">Once the recording is started, the controller <b>180</b> controls the output of the display unit <b>151</b> to switch to a message application activated screen [S<b>8</b>] and controls the display unit <b>151</b> to display a real-time taken data [S<b>9</b>]. In doing so, the controller <b>180</b> controls the display unit <b>151</b> to display the real-time taken data on a 1<sup>st </sup>region of the display unit <b>151</b> and also controls the display unit <b>151</b> to output a message (e.g., a 1<sup>st </sup>type message explained later in this description) transceived with an external terminal during a casting mode to a 2<sup>nd </sup>region different from the 1<sup>st </sup>region.</p>
<p id="p-0119" num="0118">In this case, the controller <b>180</b> may set the real-time taken data to be displayed by being fixed to the 1<sup>st </sup>region during the casting mode, by which the real-time taken data <b>180</b> may be non-limited. For instance, the real-time taken data may be set to be displayed on another region deviating from the 1<sup>st </sup>region.</p>
<p id="p-0120" num="0119">When the real-time taken data is displayed on the 1<sup>st </sup>region, the controller <b>180</b> may control the display unit <b>151</b> to display the 2<sup>nd </sup>region, which is different from the 1<sup>st </sup>region, as an empty screen or may control the display unit <b>151</b> to display a message (e.g., a 2<sup>nd </sup>type message explained later in this description) transceived with an external terminal, which was selected before the real-time taken data is relayed, on the 2<sup>nd </sup>region.</p>
<p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. 7A</figref> and <figref idref="DRAWINGS">FIG. 7B</figref> are diagrams for output examples of a display unit to describe 1<sup>st </sup>and 2<sup>nd </sup>regions of the display unit. Referring to <figref idref="DRAWINGS">FIG. 7A</figref> and <figref idref="DRAWINGS">FIG. 7B</figref>, the controller <b>180</b> may configure a 1<sup>st </sup>region <b>17</b>/<b>21</b> and a 2<sup>nd </sup>region <b>18</b>/<b>22</b> in a manner of partitioning the display unit into a top part and a bottom part. Referring to <figref idref="DRAWINGS">FIG. 7A</figref>, the controller <b>180</b> displays a real-time taken data on the 1<sup>st </sup>region <b>17</b> of the display unit and also displays an empty screen on the 2<sup>nd </sup>region <b>18</b>, thereby controlling a message, which is transceived with an external terminal during the casting mode, to be displayed on the 2<sup>nd </sup>region <b>18</b>. Referring to <figref idref="DRAWINGS">FIG. 7B</figref>, the controller <b>180</b> displays a real-time taken data on the 1<sup>st </sup>region <b>21</b> and controls a message (e.g., a 2<sup>nd </sup>type message explained later in this description), which was transceived with an external terminal before the casting mode is entered, to be outputted to the 2<sup>nd </sup>region <b>22</b>.</p>
<p id="p-0122" num="0121">Furthermore, referring to <figref idref="DRAWINGS">FIG. 7A</figref>, the controller <b>180</b> may be able to further provide a button (e.g., a stop button) <b>19</b> for ending the casting mode and a progressing bar <b>20</b> indicating a video recordable time on the basis of a remaining storage capacity of the memory <b>160</b> as well as the real-time taken data.</p>
<p id="p-0123" num="0122"><figref idref="DRAWINGS">FIG. 7A</figref> and <figref idref="DRAWINGS">FIG. 7B</figref> describe that the display unit is partitioned in to 2 regions, by which the present invention is non-limited. Alternatively, the display unit is partitioned into at least 3 regions including 1<sup>st </sup>to 3<sup>rd </sup>regions. In particular, a real-time taken data may be displayed on the 1<sup>st </sup>region, an empty screen may be displayed on the 2<sup>nd </sup>region, and a message (e.g., a 2<sup>nd </sup>type message explained later in this description) transceived with an external terminal before the casting mode entry may be displayed on the 3<sup>rd </sup>region.</p>
<p id="p-0124" num="0123">The controller <b>180</b> transmits the real-time taken data to the selected external terminal and may control the transmitted real-time taken data to be played in the external terminal [S<b>10</b>]. In particular, the controller <b>180</b> partitions the real-time taken data into a plurality of data blocks, transmits the data blocks to the external terminal in order via the wireless communication unit <b>11</b>, and controls the real-time taken data to be played in the selected external terminal by streaming.</p>
<p id="p-0125" num="0124">According to the present embodiment, after a single external terminal has been selected, the controller <b>180</b> transmits real-time taken data by unicast, by which the present invention may be non-limited. Alternatively, a plurality of external terminals is selected or an external terminal is added during the casting mode, and real-time taken data is then controlled to be transmitted by multicast.</p>
<p id="p-0126" num="0125"><figref idref="DRAWINGS">FIGS. 8A to 8C</figref> are diagrams for output examples of a display unit provided to a user to add an external terminal.</p>
<p id="p-0127" num="0126">Referring to <figref idref="DRAWINGS">FIGS. 8A to 8C</figref>, while a real-time taken data is transmitted to a single external terminal (user <b>1</b>) via the wireless communication unit <b>110</b>, if a user presses a button (Add) to add an external terminal [<figref idref="DRAWINGS">FIG. 8A</figref>], the controller <b>180</b> may be able to provide a popup <b>25</b> for selecting an external terminal to add [<figref idref="DRAWINGS">FIG. 8B</figref>]. If the user selects a particular external terminal, the controller <b>180</b> may be able to control the wireless communication unit <b>110</b> to transmit the real-time taken data to a plurality of the external terminals (user <b>1</b>, user <b>2</b>) [<figref idref="DRAWINGS">FIG. 8C</figref>].</p>
<p id="p-0128" num="0127">On the other hand, while real-time taken data is transmitted to a plurality of external terminals, if a user selects a button (Delete) <b>24</b> to delete an external terminal, the controller <b>180</b> deletes the selected external terminal from a real-time taken data transmission list and controls the real-time taken data not to be transmitted to the deleted external terminal.</p>
<p id="p-0129" num="0128">While the casting mode is active or the real-time taken data is relay to the external terminal, if a new message is transmitted/received to/from the external terminal [S<b>11</b>], the controller <b>180</b> may control the display unit <b>151</b> to display the new message [S<b>12</b>].</p>
<p id="p-0130" num="0129">In doing so, the controller <b>180</b> may be able to control the new message to be displayed on the 2<sup>nd </sup>region of the display unit <b>151</b>. Moreover, the controller <b>180</b> may be able to control an output of the display unit <b>151</b> in a manner that a message (hereinafter named a 1<sup>st </sup>type message) transmitted/received to/from the external terminal in the course of an operation in the casting mode or relaying the real-time taken data to the external terminal and a 2<sup>nd </sup>type message (e.g., a message transceived with the external terminal before a casting mode entry or after a casting mode end, a message transceived with the external terminal having the real-time taken data not transmitted thereto, etc.) different from the 1<sup>st </sup>type message are visually discriminated from each other.</p>
<p id="p-0131" num="0130"><figref idref="DRAWINGS">FIGS. 9A to 9C</figref> are diagrams for output examples of a display unit to describe that a 1<sup>st </sup>type message is displayed. Referring to <figref idref="DRAWINGS">FIGS. 9A to 9C</figref>, while a casting mode is activated, if a new message <b>28</b> categorized into a 1<sup>st </sup>type message is received, the controller <b>180</b> may be able to control the new message to be outputted to a 2<sup>nd </sup>region <b>27</b> [<figref idref="DRAWINGS">FIG. 9A</figref>]. If a received/transmitted count of new messages is plural, the controller <b>180</b> arranges 1<sup>st </sup>type messages <b>28</b> and <b>29</b> in time order and then controls the arranged messages to be displayed on the 2<sup>nd </sup>region <b>27</b> in order of recent messages [<figref idref="DRAWINGS">FIG. 9B</figref>]. In doing so, in order to check the 1<sup>st </sup>type message not displayed on the 2<sup>nd </sup>region <b>27</b>, the controller <b>180</b> may be able to limitedly provide a scroll function to the 2<sup>nd </sup>region <b>27</b>. A user may be able to check the 1<sup>st </sup>type message by scrolling the 2<sup>nd </sup>region <b>27</b> in a vertical (or horizontal) direction. By providing the scroll function to the 2<sup>nd </sup>region <b>27</b> limitedly, the real-time taken data may be displayed on the 1<sup>st </sup>region by being fixed thereto and a user may be able to check the 1<sup>st </sup>type message, which is not displayed on the screen in a manner of shifting the 1<sup>st </sup>type message displayed on the 2<sup>nd </sup>region <b>27</b> in the vertical (or horizontal) direction.</p>
<p id="p-0132" num="0131">Once the casting mode is ended, referring to <figref idref="DRAWINGS">FIG. 9C</figref>, the controller <b>180</b> releases the real-time taken data from being fixed to the 1<sup>st </sup>region and also cancels the scroll function from the 2<sup>nd </sup>region, thereby controlling the display unit <b>151</b> to display the 1<sup>st </sup>type messages <b>28</b> to <b>31</b> to be displayed across the 1<sup>st </sup>region and the 2<sup>nd </sup>region.</p>
<p id="p-0133" num="0132">In order to check the 2<sup>nd </sup>type message failing to be displayed on the screen, the controller <b>180</b> may be able to provide a scroll function to shift both of the 1<sup>st </sup>region and the 2<sup>nd </sup>region in a vertical (or horizontal) direction. In doing so, if the real-time taken data deviates from the 1<sup>st </sup>region due to the scroll, the controller <b>180</b> may be able to control the real-time taken data to be automatically shifted to another position spaced apart in a prescribed distance from a boundary of the 1<sup>st </sup>region.</p>
<p id="p-0134" num="0133"><figref idref="DRAWINGS">FIGS. 10A to 10D</figref> are diagrams for examples to describe a controlling method in case that real-time taken data deviates from a 1<sup>st </sup>region. As mentioned in the foregoing description of the example shown in <figref idref="DRAWINGS">FIG. 9B</figref>, while a real-time taken data is displayed on a 1<sup>st </sup>region <b>26</b> and a 1<sup>st </sup>type messages <b>28</b> and <b>29</b> are provided to a 2<sup>nd </sup>region, if a whole screen is shifted to make the real-time taken data deviate from the 1<sup>st </sup>region <b>26</b>, as described in the example shown in <figref idref="DRAWINGS">FIG. 10A</figref>, the controller <b>180</b> may be able to control the real-time taken data to be automatically shifted to another position (e.g., a bottom part of the display unit <b>151</b> shown in <figref idref="DRAWINGS">FIG. 10B</figref>) spaced apart in a prescribed distance from a boundary of the 1<sup>st </sup>region <b>26</b>. In case that the real-time taken data deviates from the 1<sup>st </sup>region <b>26</b>, the controller <b>180</b> may be able to control an output of the display unit <b>151</b> to display <b>2</b><sup>nd </sup>type messages <b>32</b> to <b>34</b> on the 1<sup>st </sup>region <b>26</b>.</p>
<p id="p-0135" num="0134">In the configuration shown in <figref idref="DRAWINGS">FIG. 10B</figref>, if a new message <b>35</b>, which can be categorized into a 1<sup>st </sup>type message, is transmitted or received, the controller <b>180</b> may control the real-time taken data to return to its original position and may control the new message <b>35</b> to be displayed on the 2<sup>nd </sup>region <b>27</b> [<figref idref="DRAWINGS">FIG. 10C</figref>]. Alternatively, referring to <figref idref="DRAWINGS">FIG. 10D</figref>, while the real-time taken data is fixed to the bottom part of the display unit, the controller <b>180</b> may be able to control the content of the new message to be displayed via a semitransparent window <b>36</b>.</p>
<p id="p-0136" num="0135">The controller <b>180</b> may be able to control an output of the display unit to visually discriminate a 1<sup>st </sup>type message and a 2<sup>nd </sup>type message from each other. In particular, in order to visually discriminate a 1<sup>st </sup>type message and a 2<sup>nd </sup>type message from each other, various kinds of methods may be available.</p>
<p id="p-0137" num="0136">For instance, referring to <figref idref="DRAWINGS">FIG. 9A</figref> and <figref idref="DRAWINGS">FIG. 10A</figref>, the controller <b>180</b> may be able to control the display unit <b>151</b> to display the real-time taken data and the 1<sup>st </sup>type message tied together on one chat window <b>37</b>. As the 1<sup>st </sup>type message and the real-time taken data are outputted in a manner of being tied into one chat window, a user may be able to visually identify the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message from each other through a boundary line of the chat window. Moreover, the controller <b>180</b> sorts the 1<sup>st </sup>type messages into a transmitted message and a received message and may be then able to further control the transmitted message and the received message to be visually discriminated from each other.</p>
<p id="p-0138" num="0137">According to another embodiment of the present invention, the controller <b>180</b> may be able to control the display unit <b>151</b> to identifiably display a message window of the 1<sup>st </sup>type message and a message window of the 2<sup>nd </sup>type message in a manner that the message windows of the 1<sup>st </sup>and 2<sup>nd </sup>type messages differ from each other in at least one of color, size, shape and pattern.</p>
<p id="p-0139" num="0138">If a storage space of the memory <b>160</b> is insufficient, the casting mode in the external terminal is ended, or a prescribed user input is received, the controller <b>180</b> may be able to end the casting mode [S<b>13</b>]. For instance, if the stop button shown in <figref idref="DRAWINGS">FIG. 7A</figref> and <figref idref="DRAWINGS">FIG. 7B</figref> is pressed or the message application is ended, the controller <b>180</b> may be able to control the casting mode to be ended.</p>
<p id="p-0140" num="0139">Once the casting mode is ended, the controller <b>180</b> stops recording the real-time taken data and may be then able to display a thumbnail image of the real-time taken data together with a play button. If a user presses the play button, the controller <b>180</b> may be able to play back the real-time taken data via the multimedia module <b>181</b>.</p>
<p id="p-0141" num="0140">In doing so, the 1<sup>st </sup>message transmitted/received to/from the external terminal during the casting mode may be provided as a subtitle when the real-time taken data is played back. In particular, by converting the 1<sup>st </sup>type message to a subtitle file, it may be able to check the 1<sup>st </sup>type message transmitted/received to/from the external terminal in the course of relaying the real-time taken data when the real-time taken data is played back.</p>
<p id="p-0142" num="0141">In order to display the 1<sup>st </sup>type message as a subtitle, the controller <b>180</b> converts the 1<sup>st </sup>type message to the subtitle file or processes the real-time taken data and the 1<sup>st </sup>type message into a single file through encoding and may be then able to save the corresponding file in the memory <b>160</b> [S<b>14</b>].</p>
<p id="p-0143" num="0142">Subsequently, the controller <b>180</b> may be able to upload the real-time taken data and the 1<sup>st </sup>type message to an SNS site by interconnecting with the SNS site [S<b>15</b>]. In particular, the controller <b>180</b> accesses the SNS site periodically or asynchronously and may be then able to upload the real-time taken data and the 1<sup>st </sup>type message to the accessed SNS site.</p>
<p id="p-0144" num="0143">In doing so, the transmitted message transmitted to the external terminal among the 1<sup>st </sup>type messages may be uploaded with a ID of a user of the mobile terminal, while the received message received from the external terminal among the 1<sup>st </sup>type messages may be uploaded with a ID of a user of the external terminal.</p>
<p id="p-0145" num="0144"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram for one example of a screen for uploading real-time taken data and a 1<sup>st </sup>type message to Facebook site. First of all, a real-time taken data may be saved as a main frame on a posting and a 1<sup>st </sup>type message may be provided as a comment on the posting.</p>
<p id="p-0146" num="0145">In the above-mentioned description of the embodiment, as the casting mode is entered in the message application, the A/V input unit is activated, by which the embodiment may be non-limited.</p>
<p id="p-0147" num="0146"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart for a method of controlling a mobile terminal according to another embodiment of the present invention. Comparing <figref idref="DRAWINGS">FIG. 12</figref> with <figref idref="DRAWINGS">FIG. 3</figref>, steps S<b>28</b> to S<b>34</b> shown in <figref idref="DRAWINGS">FIG. 12</figref> may correspond to the former steps S<b>9</b> to S<b>15</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>. Hence, details of the steps S<b>28</b> to S<b>34</b> shall be omitted from the following description. The differences between <figref idref="DRAWINGS">FIG. 12</figref> and <figref idref="DRAWINGS">FIG. 3</figref> are described as follows. First of all, the controller <b>180</b> activates the A/V input unit <b>120</b> based on an external input [S<b>21</b>] and executes the camera application [S<b>22</b>]. If the camera application is executed, the controller <b>180</b> may be able to display the image sensed by the camera and the menu screen <b>23</b>, as described in the example shown in <figref idref="DRAWINGS">FIG. 6</figref> [S<b>23</b>].</p>
<p id="p-0148" num="0147">Based on a user input to the menu screen, the controller <b>180</b> may enter a casting mode [S<b>24</b>]. <figref idref="DRAWINGS">FIG. 13A</figref> and <figref idref="DRAWINGS">FIG. 13B</figref> are diagrams of screens provided to a user to enter a casting mode.</p>
<p id="p-0149" num="0148">Referring to <figref idref="DRAWINGS">FIG. 13A</figref>, on a screen related to the camera application, a user enables a casting mode to be entered by such a method as a manipulation of a toggle key <b>15</b> and the like. In particular, <figref idref="DRAWINGS">FIG. 13A</figref> shows a screen that the casting mode can be entered in a manner that the toggle key <b>15</b> is pulled down to a bottom side.</p>
<p id="p-0150" num="0149">Once the casting mode is entered, referring to <figref idref="DRAWINGS">FIG. 13B</figref>, the controller <b>180</b> provides a popup <b>16</b> for selecting an external terminal (particularly, a user of an external terminal or a phone number of an external terminal), to which a real-time taken data will be transmitted, to enable the user to select an external terminal to which the real-time taken data will be relayed [S<b>25</b>]. Once the external terminal is selected, the controller <b>180</b> converts an image inputted via the A/V input unit by real time into a real-time taken data and then saves the real-time taken data in the memory [S<b>26</b>]. And, the controller <b>180</b> may be able to control the wireless communication unit <b>110</b> to relay the real-time taken data to the selected external terminal.</p>
<p id="p-0151" num="0150">The controller <b>180</b> executes the message application [S<b>27</b>] and then controls a screen related to the message application to be displayed, thereby providing the screen of the examples show in <figref idref="DRAWINGS">FIG. 8A</figref> and <figref idref="DRAWINGS">FIG. 8B</figref>.</p>
<p id="p-0152" num="0151">In particular, although <figref idref="DRAWINGS">FIG. 3</figref> shows that the casting mode can be set after executing the message application, <figref idref="DRAWINGS">FIG. 12</figref> differs from <figref idref="DRAWINGS">FIG. 3</figref> in that the casting mode can be set after executing the camera application in the first place.</p>
<p id="p-0153" num="0152">Yet, the casting mode is entered through an input of the button provided by the message application or the camera application, by which the present invention may be non-limited. Alternatively, the present invention may include various modifications devised by those skilled in the art to which the present invention pertains.</p>
<p id="p-0154" num="0153">In the above description of the embodiments, the display unit <b>151</b> is outputted in the portrait mode for example. Alternatively, the controller <b>180</b> may be able to control the display unit <b>151</b> to be outputted in a landscape mode. If the display unit <b>151</b> is set in the landscape mode, the controller <b>180</b> may be able to control a real-time taken data to be displayed on a full screen.</p>
<p id="p-0155" num="0154"><figref idref="DRAWINGS">FIGS. 14A to 14C</figref> are diagrams for examples of screens for displaying real-time taken data on a full screen. Referring to <figref idref="DRAWINGS">FIG. 14A</figref>, the controller <b>180</b> may be able to control the display unit <b>151</b> to display a real-time taken data on a full screen. While the real-time taken data is being displayed on a full screen of the display unit <b>151</b>, if a new message possibly categorized into a 1<sup>st </sup>type message is received, referring to <figref idref="DRAWINGS">FIG. 14B</figref>, the controller <b>180</b> may be able to control an output of the display unit <b>151</b> to enable the new message to be outputted in a manner of overlapping with the real-time taken data. In doing so, the new message outputted by overlapping may be set to be displayable only for predetermined duration. Alternatively, referring to <figref idref="DRAWINGS">FIG. 14C</figref>, the controller is configured to reduce a size of a screen displaying the real-time taken data, thereby controlling the display unit to separately output the new message and the real-time taken data.</p>
<p id="p-0156" num="0155">Moreover, the controller <b>180</b> converts a text content of the new message to an audio content and may output the audio content via a speaker of the audio output module <b>152</b>.</p>
<p id="p-0157" num="0156">While the real-time taken data is being displayed on a full screen, a user may be able to create a new message categorized into a 1<sup>st </sup>type message through a virtual keypad or a speech.</p>
<p id="p-0158" num="0157">In particular, the controller <b>180</b> outputs a virtual keypad in a manner that the outputted virtual keypad overlaps with the real-time taken data, thereby enabling a user to write or create a new message. In doing so, the virtual keypad may be set semi-transparent, whereby the real-time taken data can keep being displayed on the display unit <b>151</b> without being blocked by the virtual keypad.</p>
<p id="p-0159" num="0158">The controller <b>180</b> converts audio data received from the A/V input unit <b>120</b> to a text and may be then able to create a new message from the corresponding text.</p>
<p id="p-0160" num="0159">And, the controller <b>180</b> may be able to control the wireless communication unit <b>110</b> to transmit the new message created via the virtual keypad or the A/V input unit to an external terminal.</p>
<p id="p-0161" num="0160">According to one embodiment of the present invention, the wireless communication unit <b>110</b> obtains location information of the mobile terminal <b>100</b> and may set a background image to a map corresponding to the location information. In particular, the wireless communication unit <b>110</b> may be able to obtain the location information of the mobile terminal via at least one of the mobile communication module <b>112</b>, the wireless internet module <b>113</b> and the position location module <b>115</b>.</p>
<p id="p-0162" num="0161"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram for one example of an output of a display unit for outputting real-time taken data in a status that a map is set as a background screen. Referring to <figref idref="DRAWINGS">FIG. 15</figref>, the controller <b>180</b> may be able to receive map data, which matches location information, from a map managing server (not shown in the drawing) via the wireless communication unit <b>110</b>. Based on the received map data, the controller <b>180</b> may be able to control the display unit <b>151</b> to display a map matching the location information as a background image.</p>
<p id="p-0163" num="0162">According to another embodiment of the present invention, the controller <b>180</b> may be able to control the wireless communication unit <b>110</b> to further transmit the location information, which is obtained via the wireless communication unit <b>110</b>, to an external terminal. If the location information is transmitted to the external terminal, the external terminal may be able to set a background image to a map that matches the location information of the mobile terminal.</p>
<p id="p-0164" num="0163">As the real-time taken data received from the mobile terminal is outputted having a map set as a background, a user of the external terminal may be able to conveniently obtain a geographical location and environment of the mobile terminal <b>100</b>.</p>
<p id="p-0165" num="0164">According to another embodiment of the present invention, the controller <b>180</b> may be able to control the wireless communication unit <b>110</b> to transmit a real-time taken data to a cloud server.</p>
<p id="p-0166" num="0165">In particular, if a mobile terminal and an external terminal differ from each other in an operating system (OS) or the external terminal is unable to support a casting mode, the mobile terminal may enable the external terminal to receive a real-time taken data via a cloud server.</p>
<p id="p-0167" num="0166"><figref idref="DRAWINGS">FIG. 16</figref> is a diagram of configuration to describe that real-time taken data is transmitted to an external terminal via a cloud server.</p>
<p id="p-0168" num="0167">Referring to <figref idref="DRAWINGS">FIG. 16</figref>, the controller <b>180</b> of the mobile terminal <b>100</b> creates a real-time taken data based on an image inputted via the A/V input unit <b>120</b> and may control the wireless communication unit <b>110</b> to transmit the real-time taken data to a cloud server <b>300</b>. The mobile terminal <b>100</b> acquires URL for accessing the real-time taken data from the cloud server <b>300</b> and may be then able to transmit the acquired URL address to an external terminal <b>200</b>.</p>
<p id="p-0169" num="0168">Subsequently, the external terminal <b>200</b> may be able to play back the real-time taken data, which is saved in the cloud server <b>300</b>, by streaming via the URL address received from the mobile terminal <b>100</b>. As the external terminal <b>200</b> plays back the real-time taken data saved in the cloud server <b>300</b> by streaming, the real-time taken data can be relayed to the external terminal <b>200</b>.</p>
<p id="p-0170" num="0169">In this case, a 1<sup>st </sup>type message may be defined as a message exchanged with the external terminal while the real-time taken data is being transmitted to the cloud server. And, a 2<sup>nd </sup>type message may be defined as a message (e.g., a message exchanged with the external terminal if the real-time taken data is not transmitted to the cloud server) except the 1<sup>st </sup>type message.</p>
<p id="p-0171" num="0170">The above embodiments may be described on the basis that a mobile terminal transmits a real-time taken data to an external terminal, by which the present invention may be non-limited. A mobile terminal may operate as &#x2018;a transmitting side mobile terminal&#x2019; for transmitting a real-time taken data to an external terminal or &#x2018;a receiving side mobile terminal&#x2019; for receiving the real-time taken data from the external terminal. In the following description, the details of operations of a receiving side mobile terminal shall be explained mainly with reference to a difference from a transmitting side mobile terminal. If there is no further or separate description, it is apparent that contents of the transmitting side mobile terminal described with reference to <figref idref="DRAWINGS">FIGS. 3 to 16</figref> can be applied to the receiving side mobile terminal.</p>
<p id="p-0172" num="0171"><figref idref="DRAWINGS">FIG. 17</figref> is a flowchart for controlling a mobile terminal in case of receiving real-time taken data according to another embodiment of the present invention.</p>
<p id="p-0173" num="0172">Referring to <figref idref="DRAWINGS">FIG. 17</figref>, if a casting request signal is received from an external terminal via the wireless communication unit <b>110</b>, the controller <b>180</b> may be able to output a casting mode indication message to the display unit <b>151</b> [S<b>41</b>].</p>
<p id="p-0174" num="0173"><figref idref="DRAWINGS">FIG. 18</figref> is a diagram for one example of a screen having a casting mode indication message displayed thereon.</p>
<p id="p-0175" num="0174">Referring to <figref idref="DRAWINGS">FIG. 18</figref>, if a casting mode request signal is received from an external terminal, the controller <b>180</b> outputs a casting mode indication message <b>40</b> to enable a user to select whether a casting mode is entered.</p>
<p id="p-0176" num="0175">If the casting mode is entered based on the user input [S<b>42</b>], the controller <b>180</b> executes the message application [S<b>43</b>], receives a real-time taken data from the external terminal [S<b>44</b>] and then controls the real-time taken data to be displayed on the display unit <b>151</b> [S<b>45</b>]. In this case, the received real-time taken data may be saved in the memory <b>160</b> temporarily or permanently.</p>
<p id="p-0177" num="0176"><figref idref="DRAWINGS">FIG. 19A</figref> and <figref idref="DRAWINGS">FIG. 19B</figref> are diagrams for examples of screen configuration in case that a mobile terminal receives real-time taken data. Referring to <figref idref="DRAWINGS">FIG. 19A</figref>, the controller <b>180</b> may output a real-time taken data on a 1<sup>st </sup>region <b>41</b> of the display unit and may leave a 2<sup>nd </sup>region <b>42</b> as an empty screen. In doing so, a button <b>43</b> for ending a casting mode may be provided together with the real-time taken data. If a new message categorized into a 1<sup>st </sup>type message is received, the controller <b>180</b> may be able to display the new message on the 2<sup>nd </sup>region. Compared to <figref idref="DRAWINGS">FIG. 7A</figref>, <figref idref="DRAWINGS">FIG. 19A</figref> shows that a progressing bar <b>20</b> may not be provided, which is not mandatory.</p>
<p id="p-0178" num="0177">Referring to <figref idref="DRAWINGS">FIG. 19B</figref>, before the casting mode is entered with a real-time taken data, the controller <b>180</b> may be able to display the real-time taken data together with a message (e.g., a message categorized into a 2<sup>nd </sup>type message) exchanged with an external terminal.</p>
<p id="p-0179" num="0178">A display size of a real-time taken data displayed on a receiving side mobile terminal may be set smaller than that of the real-time taken data displayed on a transmitting side mobile terminal. As the display size of the real-time taken data is set smaller than that of the real-time taken data of the transmitting side mobile terminal, more messages can be checked at a glance.</p>
<p id="p-0180" num="0179">While the real-time taken data is being displayed, if a new message possibly categorized into the 1<sup>st </sup>type message is received [S<b>46</b>], the controller <b>180</b> may be able to control the new message to be displayed on a 2<sup>nd </sup>region different from the 1<sup>st </sup>region [S<b>47</b>].</p>
<p id="p-0181" num="0180"><figref idref="DRAWINGS">FIG. 20</figref> is a diagram for one example of a screen for discriminating a 1<sup>st </sup>type message and a 2<sup>nd </sup>type message from each other. Referring to <figref idref="DRAWINGS">FIG. 20</figref>, the controller <b>180</b> controls the display unit to output a real-time taken data and a 1<sup>st </sup>type message in a manner that the real-time taken data and the 1<sup>st </sup>type message are tied into one chat window <b>44</b>, whereby first type messages <b>46</b> and <b>47</b> can be discriminated from a 2<sup>nd </sup>type message <b>45</b>.</p>
<p id="p-0182" num="0181">If the casting mode is ended in the external terminal of a user input is received (e.g., a user presses the end button <b>43</b>), the controller <b>180</b> may be able to end the casting mode [S<b>48</b>].</p>
<p id="p-0183" num="0182">If the casting mode is ended, the controller <b>180</b> deletes the real-time taken data saved in the memory <b>160</b> or may set the real-time taken data to be saved as a video file in the memory <b>160</b>.</p>
<p id="p-0184" num="0183">In case that the real-time taken data is deleted, the controller <b>180</b> may be able to display a last picture of the real-time taken data. In case that the real-time taken data is saved as the video file in the memory <b>160</b>, the controller <b>180</b> may display a thumbnail image of the real-time taken data together with a play button.</p>
<p id="p-0185" num="0184"><figref idref="DRAWINGS">FIG. 21</figref> is a diagram for one example of a screen at the end of a casting mode is ended.</p>
<p id="p-0186" num="0185">Referring to <figref idref="DRAWINGS">FIG. 21</figref>, if a real-time taken data is saved as a video file in the memory <b>160</b>, the controller <b>180</b> may be able to provide a thumbnail image of the real-time taken data together with a play button <b>48</b>. If a user presses the play button <b>48</b>, the controller <b>180</b> may be able to play back the real-time taken data via the multimedia module <b>181</b>.</p>
<p id="p-0187" num="0186">After the casting mode has been ended, if a new message possibly categorized into a 2<sup>nd </sup>type message is received, the controller <b>180</b> may be able to display the new message to be visually discriminated from a 1<sup>st </sup>type message.</p>
<p id="p-0188" num="0187"><figref idref="DRAWINGS">FIG. 22</figref> is a diagram for one example of a screen for a reception of a new message after end of a casting mode. Referring to <figref idref="DRAWINGS">FIG. 22</figref>, as a new message <b>49</b> possible categorized into a 2<sup>nd </sup>type message is displayed outside a chat window <b>50</b> having a 1<sup>st </sup>type message belong thereto, the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message can be visually discriminated from each other on a boundary of the chat window <b>50</b>.</p>
<p id="p-0189" num="0188">According to the above embodiments, a 1<sup>st </sup>type message is defined as a message exchanged with an external terminal while a real-time taken data is being transmitted/received to/from the external terminal. And, a 2<sup>nd </sup>type message is explained as a message except the 1<sup>st </sup>type message. For example, the 2<sup>nd </sup>type message includes one of a message transceived with the external terminal in the course of not transmitting/receiving real-time taken data to/from the external terminal, a message transceived with another external terminal and the like. Yet, this may non-limit the 1<sup>st </sup>type message and the 2<sup>nd </sup>type message.</p>
<p id="p-0190" num="0189">Besides, the message categorization with reference to the real-time taken data may come within the scope of the appended claims and their equivalents. For instance, 1<sup>st </sup>and 2<sup>nd </sup>type messages can be categorized by various real-time taken data based methods including a method of defining a 1<sup>st </sup>type message as a message transceived with an external terminal in the course of displaying a real-time taken data, a method of defining a 1<sup>st </sup>type message as a message transceived with an external terminal in the course of outputting an image sensed via the A/V input unit to a display before a relay of an external terminal, a method of defining a 1<sup>st </sup>type message as a message transceived with an external terminal in the course of displaying a thumbnail of a real-time taken data after an end of a casting mode, a method of defining a 1<sup>st </sup>type message as a message transceived with an external terminal in the course of playing a real-time taken data after a casting mode end, a method of defining a 1<sup>st </sup>type message as a message transceived with an external terminal in the course of transmitting a real-time taken data to a cloud server, a method of configuring a 1<sup>st </sup>type message by combining the above-enumerated items together and the like.</p>
<p id="p-0191" num="0190">According to one embodiment of the present invention, the above-described methods can be implemented in a program recorded medium as computer-readable codes. The computer-readable media include all kinds of recording devices in which data readable by a computer system are stored. The computer-readable media include ROM, RAM, CD-ROM, magnetic tapes, floppy discs, optical data storage devices, and the like for example and also include carrier-wave type implementations (e.g., transmission via Internet).</p>
<p id="p-0192" num="0191">The above-described mobile terminal may be achieved by combination of structural elements and features of the present invention in a predetermined type. Each of the structural elements or features should be considered selectively unless specified separately. Each of the structural elements or features may be carried out without being combined with other structural elements or features. Also, some structural elements and/or features may be combined with one another to constitute the embodiments of the present invention.</p>
<p id="p-0193" num="0192">It will be apparent to those skilled in the art that various modifications and variations can be made in the present invention without departing from the spirit or scope of the inventions. Thus, it is intended that the present invention covers the modifications and variations of this invention provided they come within the scope of the appended claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A mobile terminal comprising:
<claim-text>a camera configured to film a real-time video;</claim-text>
<claim-text>a display unit configured to display the real-time video;</claim-text>
<claim-text>a wireless communication unit configured to communicate with an external terminal;</claim-text>
<claim-text>a memory configured to store the real-time video; and</claim-text>
<claim-text>a controller configured to:
<claim-text>activate the camera during communication with the external terminal in order to film the real-time video; and</claim-text>
<claim-text>control the wireless communication unit to transmit the real-time video to the external terminal in order to share the real-time video with the external terminal,</claim-text>
</claim-text>
<claim-text>wherein when sharing the real-time video with the external terminal is initiated, the controller is configured to control the display unit to be divided into a first region and a second region so that the real-time video is fixedly displayed on the first region of the display unit and a first message and a second message are displayed on the second region of the display unit,</claim-text>
<claim-text>wherein when sharing the real-time video with the external terminal is ended, the controller is configured to control the display unit to stop being divided into the first region and the second region and control the real-time video, and the first and second messages to be displayed in order of time,
<claim-text>wherein the controller is further configured to control the display unit to visually distinguish the first message exchanged during the communication with the external terminal and the second message exchanged during the communication with the external terminal, and</claim-text>
<claim-text>wherein the first message is exchanged during the sharing of the real-time video with the external terminal, and the second message is exchanged before or after the sharing of the real-time video with the external terminal.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when a portion of the real-time video is removed from the first region of the display unit, the controller controls the display unit such that the real-time video is automatically moved to a different position on the display unit that is spaced apart from a boundary of the first region by a prescribed distance.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The mobile terminal of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein when a new message categorized as the first message is received at the mobile terminal, the controller controls the real-time video to be provided back to the first region of the display unit.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when a new message categorized as the first message is transmitted from the mobile terminal or is received by the mobile terminal, the controller controls the display unit to display the new message such that the new message overlaps with the real-time video displayed on a full screen.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the wireless communication unit is further configured to transmit a location information of the mobile terminal to the external terminal.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is further configured to control the wireless communication unit to transmit the real-time video to a cloud server.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The mobile terminal of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the controller is further configured to control the wireless communication unit to transmit a URL address for accessing the real-time video stored in the cloud server to the external terminal.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A method of controlling a mobile terminal, comprising:
<claim-text>activating a camera during a communication with an external terminal in order to film a real-time video;</claim-text>
<claim-text>transmitting the real-time video to the external terminal in order to share the real-time video with the external terminal; and</claim-text>
<claim-text>displaying a first message and a second message exchanged during the communication with the external terminal, and</claim-text>
<claim-text>wherein the first message is exchanged during the sharing of the real-time video with the external terminal, and the second message is exchanged before or after the sharing of the real-time video with the external terminal,</claim-text>
<claim-text>wherein when sharing the real-time video with the external terminal is initiated, the method further comprises dividing a display unit into a first region and a second region so that the real-time video is fixedly displayed on the first region of the display unit and the first message and the second message are displayed on the second region of the display unit,</claim-text>
<claim-text>wherein when sharing the real-time video with the external terminal is ended, method further comprises stop dividing the display unit into the first region and the second region and then displaying the real-time video, and the first and second messages in order of time. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
