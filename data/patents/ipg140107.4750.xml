<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625843-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625843</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11501372</doc-number>
<date>20060809</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>P2005-233073</doc-number>
<date>20050811</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>981</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>26</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382103</main-classification>
<further-classification>348152</further-classification>
<further-classification>348153</further-classification>
<further-classification>348154</further-classification>
<further-classification>348159</further-classification>
</classification-national>
<invention-title id="d2e71">Monitoring system, image-processing apparatus, management apparatus, event detecting method, and program</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5594504</doc-number>
<kind>A</kind>
<name>Ebrahimi</name>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6441734</doc-number>
<kind>B1</kind>
<name>Gutta et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>340541</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6678417</doc-number>
<kind>B1</kind>
<name>Baumgartner et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382236</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7177448</doc-number>
<kind>B1</kind>
<name>Sah</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382107</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7346188</doc-number>
<kind>B2</kind>
<name>Aichi</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382103</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7463145</doc-number>
<kind>B2</kind>
<name>Jentoft</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>340541</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7525571</doc-number>
<kind>B2</kind>
<name>Ando et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482071</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7623152</doc-number>
<kind>B1</kind>
<name>Kaplinsky</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34820816</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2002/0054211</doc-number>
<kind>A1</kind>
<name>Edelson et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348169</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2002/0163577</doc-number>
<kind>A1</kind>
<name>Myers</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2002/0171734</doc-number>
<kind>A1</kind>
<name>Arakawa et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348143</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2003/0062997</doc-number>
<kind>A1</kind>
<name>Naidoo et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2004/0148518</doc-number>
<kind>A1</kind>
<name>Grundback et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713201</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2004/0184529</doc-number>
<kind>A1</kind>
<name>Henocq et al.</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524001</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2004/0240542</doc-number>
<kind>A1</kind>
<name>Yeredor et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524001</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2005/0057653</doc-number>
<kind>A1</kind>
<name>Maruya</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2006/0095539</doc-number>
<kind>A1</kind>
<name>Renkis</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709217</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2007/0039030</doc-number>
<kind>A1</kind>
<name>Romanowich et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725105</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>JP</country>
<doc-number>6-105312</doc-number>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>2002-44645</doc-number>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>A 2004-056655</doc-number>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>JP</country>
<doc-number>A 2004-186844</doc-number>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>JP</country>
<doc-number>2005-39693</doc-number>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>JP</country>
<doc-number>2005-118927</doc-number>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>WO</country>
<doc-number>WO 0072573</doc-number>
<kind>A2</kind>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Chung, et al. &#x201c;Efficient Block-based Motion Segmentation Method using Motion Vector Consistency.&#x201d; MVA2005 IAPR Conference on Machine Vision Applications. (2005): 550-553. Print.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Japanese Office Action dated Oct. 13, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>12</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382103</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348152</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348153</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348154</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348159</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>17</number-of-drawing-sheets>
<number-of-figures>29</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070036515</doc-number>
<kind>A1</kind>
<date>20070215</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Oosawa</last-name>
<first-name>Katsumi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Oosawa</last-name>
<first-name>Katsumi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Frommer Lawrence &#x26; Haug LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Frommer</last-name>
<first-name>William S.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="03" rep-type="attorney">
<addressbook>
<last-name>Emas</last-name>
<first-name>Ellen Marcie</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Newman</last-name>
<first-name>Michael A</first-name>
<department>2667</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A monitoring system includes a plurality of image-capturing apparatuses each including an event detector that executes on a corresponding captured image at least one of a plurality of processing algorithms for detection of a monitor event, and a transmission controller that outputs to a network only a processing result of the executed processing algorithm when a monitor event is not detected and that outputs to the network at least the captured image when a monitor event is detected; and a management apparatus managing the plurality of image-capturing apparatuses via the network and including an event determination unit that determines occurrence of a monitor event in accordance with the received processing result and a record controller that records the received captured image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="212.51mm" wi="158.67mm" file="US08625843-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="244.26mm" wi="181.78mm" orientation="landscape" file="US08625843-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="243.92mm" wi="141.82mm" orientation="landscape" file="US08625843-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="209.55mm" wi="183.13mm" file="US08625843-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="144.78mm" wi="149.44mm" file="US08625843-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="208.87mm" wi="179.49mm" orientation="landscape" file="US08625843-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="160.61mm" wi="164.93mm" file="US08625843-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="254.76mm" wi="170.35mm" orientation="landscape" file="US08625843-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="248.92mm" wi="170.77mm" file="US08625843-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="263.14mm" wi="148.84mm" orientation="landscape" file="US08625843-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="212.77mm" wi="177.29mm" file="US08625843-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="222.59mm" wi="143.85mm" file="US08625843-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="151.30mm" wi="152.15mm" file="US08625843-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="257.47mm" wi="176.53mm" orientation="landscape" file="US08625843-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="249.68mm" wi="172.30mm" orientation="landscape" file="US08625843-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="164.08mm" wi="97.45mm" file="US08625843-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="255.52mm" wi="183.22mm" file="US08625843-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="249.26mm" wi="177.38mm" file="US08625843-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCES TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present invention contains subject matter related to Japanese Patent Application JP 2005-233073 filed in the Japanese Patent Office on Aug. 11, 2005, the entire contents of which are incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to a system that detects occurrence of a monitor event within an image capture range and to an event detecting method. The present invention also relates to an image-processing apparatus disposed on an image capture side in a monitoring system. The present invention also relates to a management apparatus that records a captured image in accordance with occurrence of a monitor event within a system in the monitoring system. The present invention also relates to a program for realizing functions of the image-processing apparatus and the management apparatus.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Currently, monitoring systems are used in various fields, such as in the establishment of security systems.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 1</figref> shows an example of a known structure of a security system. Referring to <figref idref="DRAWINGS">FIG. 1</figref>, the security system includes an image-capturing camera <b>1</b> and a management apparatus <b>3</b> managing the image-capturing camera <b>1</b>. In the example shown in <figref idref="DRAWINGS">FIG. 1</figref>, a display device <b>5</b> is externally connected to the management apparatus <b>3</b>.</p>
<p id="p-0008" num="0007">Moving body detection is a typical function of security systems. Moving body detection is a function of detecting intrusion of a moving body, such as a human being or a vehicle, into an image capture range. In general, when a moving body is detected, an alert is sent out and a captured image is recorded.</p>
<p id="p-0009" num="0008">In known security systems, the image-capturing camera <b>1</b> is provided with only a function of distributing a captured image, and the management apparatus <b>3</b> performs a moving body detection process.</p>
<p id="p-0010" num="0009">For example, the image-capturing camera <b>1</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> includes an image-capturing element <b>11</b>, a camera signal processor <b>13</b>, a central processing unit (CPU) <b>15</b>, an image compressor <b>17</b>, and a network processor <b>19</b>. The camera signal processor <b>13</b> is a processing device that performs signal amplification processing, analog/digital conversion processing, exposure control processing, and other processing necessary for converting a captured image into a video signal. The image compressor <b>17</b> is a processing device that compresses and encodes a captured image in, for example, a joint photographic experts group (JPEG) format or a moving picture experts group (MPEG) format.</p>
<p id="p-0011" num="0010">The management apparatus <b>3</b> includes a network processor <b>31</b>, a CPU <b>33</b>, a display controller <b>35</b>, an image decompressor <b>37</b>, an event detector <b>39</b>, a disk controller <b>41</b>, and a hard disk device <b>43</b>. The event detector <b>39</b> is a processing device that detects intrusion of a moving body using image processing of a captured image received via a network. The network is based on the communication standard defined by, for example, the IEEE 802.3 standard.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> shows an example of function allocation of processing algorithms for moving body detection. Referring to <figref idref="DRAWINGS">FIG. 2</figref>, the image-capturing camera <b>1</b> performs processing from image capture to transfer of a captured image to a network. The management apparatus <b>3</b> performs a series of processes from motion detection to alert execution.</p>
<p id="p-0013" num="0012">A known technology is described, for example, in Japanese Unexamined Patent Application Publication No. 2003-233889.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0014" num="0013">As described above, in existing security systems, a management apparatus performs a moving body detection process. Thus, it is necessary for an image-capturing camera to distribute captured image data.</p>
<p id="p-0015" num="0014">Parts (a) and (b) of <figref idref="DRAWINGS">FIG. 3</figref> show examples of use of network bandwidth. Part (a) of <figref idref="DRAWINGS">FIG. 3</figref> shows an example of use of bandwidth during a period (normal period) in which intrusion of a moving body is not detected. Part (b) of <figref idref="DRAWINGS">FIG. 3</figref> shows an example of use of bandwidth during a period (alert period) after intrusion of a moving body is detected. As is clear from parts (a) and (b) of <figref idref="DRAWINGS">FIG. 3</figref>, in existing security systems, a constant amount (in this example, 3 Mbps) of network bandwidth is occupied, irrespective of intrusion or non-intrusion of a moving body.</p>
<p id="p-0016" num="0015">Moreover, as shown in <figref idref="DRAWINGS">FIG. 4</figref>, if the number of image-capturing cameras <b>1</b> managed by the management apparatus <b>3</b> increases, the occupied bandwidth of a network increases. For example, if the management apparatus <b>3</b> manages four image-capturing cameras <b>1</b>, a bandwidth of 12 Mbps (=3 Mbps&#xd7;4) is normally occupied. Thus, when the number of image-capturing cameras <b>1</b> managed by the management apparatus <b>3</b> increases, an increase in the occupied bandwidth of a network becomes an issue.</p>
<p id="p-0017" num="0016">In addition, when the number of image-capturing cameras <b>1</b> that have stopped their operations increases, the management apparatus <b>3</b> performs a moving body detection process in a concentrated manner. Thus, as the number of image-capturing cameras <b>1</b> managed by the management apparatus <b>3</b> increases, a higher processing ability is necessary for the management apparatus <b>3</b>. For example, when the management apparatus <b>3</b> manages four image-capturing cameras <b>1</b>, processing ability similar to that of a Pentium&#xae; 3 GHz processor is necessary for realizing a moving body detection process that is suitable for practical use in terms of the current level of technology.</p>
<p id="p-0018" num="0017">In addition, in order to establish a large-scale security system managing many image-capturing cameras, it is necessary to increase the number of management apparatuses <b>3</b> in proportion to an increase in the number of image-capturing cameras <b>1</b> to be managed by the management apparatuses <b>3</b>.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 5</figref> shows an example of establishment of a large-scale security system. In the example shown in <figref idref="DRAWINGS">FIG. 5</figref>, four management apparatuses <b>3</b> manage sixteen image-capturing cameras <b>1</b> and a system server <b>7</b> hierarchically manages the four management apparatuses <b>3</b>.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 6</figref> shows the relationship between the number of image-capturing cameras <b>1</b> and the necessary number of management apparatuses <b>3</b>. Referring to <figref idref="DRAWINGS">FIG. 6</figref>, the number of management apparatuses <b>3</b> increases in proportion to an increase in the number of image-capturing cameras <b>1</b>.</p>
<p id="p-0021" num="0020">Accordingly, a monitoring system according to an embodiment of the present invention includes a plurality of image-capturing apparatuses each including an event detector that executes on a corresponding captured image at least one of a plurality of processing algorithms for detection of a monitor event, and a transmission controller that outputs to a network only a processing result of the executed processing algorithm when a monitor event is not detected and that outputs to the network at least the captured image when a monitor event is detected; and a management apparatus managing the plurality of image-capturing apparatuses via the network and including an event determination unit that determines occurrence of a monitor event in accordance with the received processing result and a record controller that records the received captured image.</p>
<p id="p-0022" num="0021">A monitoring system according to another embodiment of the present invention includes a plurality of image-capturing apparatuses; a plurality of image-processing apparatuses each including an event detector that executes on a corresponding captured image at least one of a plurality of processing algorithms for detection of a monitor event, and a transmission controller that outputs to a network only a processing result of the executed processing algorithm when a monitor event is not detected and that outputs to the network at least the captured image when a monitor event is detected; and a management apparatus managing the plurality of image-processing apparatuses via the network and including an event determination unit that determines occurrence of a monitor event in accordance with the received processing result and a record controller that records the received captured image.</p>
<p id="p-0023" num="0022">In the monitoring system according to any one of the foregoing embodiments, the image capture side executes at least one of a plurality of processing algorithms for detection of a monitor event. In a normal state, only a processing result is transmitted to a network. Only when a monitor event occurs, a captured image is transmitted to the network.</p>
<p id="p-0024" num="0023">Thus, the occupied bandwidth of the network is reduced, and network resources can be effectively utilized.</p>
<p id="p-0025" num="0024">In addition, since the processing load of a management apparatus managing a plurality of image capture side apparatuses (including image-capturing apparatuses and image-prbcessing apparatuses) is reduced, a large-scale system managing many image capture side apparatuses can be established using a smaller number of management apparatuses, compared with known systems.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 1</figref> shows an example of a known configuration of a security system;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 2</figref> shows an example of functional allocation for an image-capturing apparatus and a management apparatus according to a known technology;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 3</figref> shows an example of use of network bandwidth according to the known technology;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 4</figref> shows an example in which an apparatus manages image-capturing cameras according to the known technology;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 5</figref> shows an example of a system according to the known technology in which many image-capturing cameras are managed;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 6</figref> shows the relationship between the number of image-capturing cameras and the necessary number of management apparatuses when a system is configured using known apparatuses;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 7</figref> shows a security system according to an embodiment of the present invention;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIGS. 8A to 8E</figref> show an example of processing steps when intrusion of a moving body is detected;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 9</figref> shows an example of functional allocation for an image-capturing apparatus and a management apparatus according to the embodiment;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 10</figref> shows an example of use of network bandwidth according to the embodiment;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 11</figref> shows an example of the system according to the embodiment when many image-capturing cameras are managed;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 12</figref> shows the relationship between the number of image-capturing cameras and the necessary number of management apparatuses when the system is configured using the apparatuses according to the embodiment;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 13</figref> shows an example of a security system according to another embodiment of the present invention;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 14</figref> shows an example of a security system according to another embodiment of the present invention;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 15</figref> shows an example of processing steps when intrusion or installation of a non-moving body is detected;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIGS. 16A to 16E</figref> show processing results when a moving body makes intrusion; and</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIGS. 17A to 17E</figref> show processing results when a non-moving body makes intrusion.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0043" num="0042">Embodiments of the present invention will be described.</p>
<p id="p-0044" num="0043">Well-known technologies in the technical field of the present invention are applied to portions not illustrated or described in this specification.</p>
<p id="p-0045" num="0044">The embodiments given below are merely examples, and the present invention is not limited to the embodiments.</p>
<heading id="h-0006" level="1">First Embodiment</heading>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 7</figref> shows an example of the configuration of a monitoring system when applied to a security system. In FIG. <b>7</b>, parts corresponding to parts in <figref idref="DRAWINGS">FIG. 1</figref> are referred to with the same reference numerals.</p>
<p id="p-0047" num="0046">The security system includes an image-capturing camera <b>111</b> and a management apparatus <b>131</b> that manages the image-capturing camera <b>111</b>. A display device <b>5</b> is externally connected to the management apparatus <b>131</b>.</p>
<p id="p-0048" num="0047">The image-capturing camera <b>111</b> includes an image-capturing element <b>11</b>, a camera signal processor <b>13</b>, a CPU <b>15</b>, an image compressor <b>17</b>, a network processor <b>19</b>, and an event detector <b>113</b>.</p>
<p id="p-0049" num="0048">The image-capturing element <b>11</b> includes a solid-state image-capturing element, such as a charge-coupled device (CCD) sensor or a complementary metal-oxide semiconductor (CMOS) sensor. The camera signal processor <b>13</b> is a processing device that performs signal amplification processing, analog/digital conversion processing, exposure control processing, and other processing necessary for converting a captured image into a video signal.</p>
<p id="p-0050" num="0049">The CPU <b>15</b> is a control device that controls processing operations of the entire image-capturing camera <b>111</b>. For example, the CPU <b>15</b> includes a microprocessor. The CPU <b>15</b> also functions as a transmission controller that selects data to be output to a network.</p>
<p id="p-0051" num="0050">The image compressor <b>17</b> is a processing device that compresses and encodes a captured image to be output to the network.</p>
<p id="p-0052" num="0051">The network processor <b>19</b> is a communication device that performs data transmission and reception via the network.</p>
<p id="p-0053" num="0052">The event detector <b>113</b> is a processing device that performs image processing on image data captured by the image-capturing element <b>11</b> and that detects occurrence of a monitor event. A process for detecting a monitor event is achieved by performing a plurality of processing steps in accordance with a detection purpose and a processing detail.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIGS. 8A to 8E</figref> show an example of processing steps when a monitor event indicates intrusion of a moving body into a set area. In this case, the detection process includes motion detection processing (<figref idref="DRAWINGS">FIG. 8B</figref>), region integration processing (<figref idref="DRAWINGS">FIG. 8C</figref>), labeling processing (<figref idref="DRAWINGS">FIG. 8D</figref>), and region determination processing (<figref idref="DRAWINGS">FIG. 8E</figref>).</p>
<p id="p-0055" num="0054">In the motion detection processing, motion vectors in a captured image (<figref idref="DRAWINGS">FIG. 8A</figref>) are detected.</p>
<p id="p-0056" num="0055">In the region integration processing, regions including detected motion vectors are integrated together for each moving body. In this processing, a size S and coordinates (x,y) of each integrated region are acquired.</p>
<p id="p-0057" num="0056">In the labeling processing, a label is provided to each integrated region.</p>
<p id="p-0058" num="0057">In the region determination processing, it is determined where on the screen each region provided with a label is located.</p>
<p id="p-0059" num="0058">By performing the above-described processing, intrusion or non-intrusion of a moving body and the position into which the moving body intrudes can be acquired.</p>
<p id="p-0060" num="0059">In this embodiment, when intrusion of a moving body is detected, the CPU <b>15</b>, which serves as the transmission controller, gives an instruction to output to the network a captured image and a processing result acquired by the moving body detection process. In contrast, when intrusion of a moving body is not detected, the CPU <b>15</b>, which serves as the transmission controller, gives an instruction to output to the network only a processing result acquired by the moving body detection process. That is, the CPU <b>15</b> transmits a captured image only in a case where a captured image to be recorded is generated. In other cases, the CPU <b>15</b> transmits only the current detection result.</p>
<p id="p-0061" num="0060">In contrast, the management apparatus <b>131</b> includes a network processor <b>31</b>, a CPU <b>33</b>, a display controller <b>35</b>, an image decompressor <b>37</b>, a disk controller <b>41</b>, a hard disk device <b>43</b>, and an event determination unit <b>133</b>.</p>
<p id="p-0062" num="0061">The network processor <b>31</b> is a communication device that performs data transmission and reception via the network.</p>
<p id="p-0063" num="0062">The CPU <b>33</b> is a control device that controls processing operations of the entire management apparatus <b>131</b>. For example, the CPU <b>33</b> includes a microprocessor. The CPU <b>33</b> also functions as a record controller that gives an instruction to record to the hard disk device <b>43</b> a captured image received via the network.</p>
<p id="p-0064" num="0063">The display controller <b>35</b> is a data processor that outputs to the display device <b>5</b> security conditions and a captured image received from the containing image-capturing camera <b>111</b>.</p>
<p id="p-0065" num="0064">The image decompressor <b>37</b> is a decoder that releases compression and encoding processing on a captured image in order to recover the original image.</p>
<p id="p-0066" num="0065">The disk controller <b>41</b> is a controller that controls the hard disk device <b>43</b> to record and play back data including a captured image.</p>
<p id="p-0067" num="0066">The event determination unit <b>133</b> is a processing device that determines whether or not a monitor event received via the network occurs. The event determination unit <b>133</b> performs the processing on a processing result acquired by the moving body detection process. Thus, even if the management apparatus <b>131</b> manages many image-capturing cameras <b>111</b>, the event determination unit <b>133</b> handles only a small processing load. In this embodiment, the event determination unit <b>133</b> sends out an alert when a moving body makes intrusion.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 9</figref> shows an example of function allocation of processing algorithms for moving body detection. Referring to <figref idref="DRAWINGS">FIG. 9</figref>, the image-capturing camera <b>111</b> performs processing from image capture to transfer of a motion detection result (processing result) to a network. The management apparatus <b>131</b> performs a series of processes from determination of the received processing result to alert execution.</p>
<p id="p-0069" num="0068">Thus, since the image-capturing camera <b>111</b> performs the motion detection processing, this security system is capable of minimizing the occupied bandwidth during a normal period.</p>
<p id="p-0070" num="0069">Parts (a) and (b) of <figref idref="DRAWINGS">FIG. 10</figref> show examples of use of network bandwidth. Part (a) of <figref idref="DRAWINGS">FIG. 10</figref> shows an example of use of bandwidth during a period (normal period) in which intrusion of a moving body is not detected. Part (b) of <figref idref="DRAWINGS">FIG. 10</figref> shows an example of use of bandwidth during a period (alert period) after intrusion of a moving body is detected.</p>
<p id="p-0071" num="0070">As shown in parts (a) and (b) of <figref idref="DRAWINGS">FIG. 10</figref>, in the security system shown in <figref idref="DRAWINGS">FIG. 7</figref>, during a period in which intrusion of a moving body is not detected, the occupied bandwidth can be reduced to about several kbps even if the management apparatus <b>131</b> manages four image-capturing cameras <b>111</b>. In addition, in any cases other than a case where all the four image-capturing cameras <b>111</b> detect intrusion of moving bodies, the occupied bandwidth of the network can be reduced compared with a case where an existing security system is used.</p>
<p id="p-0072" num="0071">Moreover, since the processing load of the management apparatus <b>131</b> can be dramatically reduced, the single management apparatus <b>131</b> is capable of managing many image-capturing cameras <b>111</b>. Thus, an increase or decrease in the number of image-capturing cameras can be easily achieved. Therefore, a system can be flexibly changed even after system operation.</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. 12</figref> shows the relationship between the number of image-capturing cameras <b>111</b> and the necessary number of management apparatuses <b>131</b>. As shown in <figref idref="DRAWINGS">FIG. 12</figref>, an increase in the number of the management apparatuses <b>131</b> can be suppressed with respect to an increase in the number of the image-capturing cameras <b>111</b>.</p>
<heading id="h-0007" level="1">Other Embodiments</heading>
<p id="p-0074" num="0073">In the first embodiment, a case where the image-capturing camera <b>111</b> includes the event detector <b>113</b> is described. That is, a configuration of a product in which the event detector <b>113</b> is mounted or installed in the image-capturing camera <b>111</b> is described.</p>
<p id="p-0075" num="0074">However, the configuration of an apparatus on an image capture side is not limited to this. For example, the event detector <b>113</b> may be installed in an image-processing apparatus that is independent of an image-capturing apparatus. In this case, the image-processing apparatus is provided with a function of communicating with the network.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 13</figref> shows another example of the configuration of the monitoring system. In <figref idref="DRAWINGS">FIG. 13</figref>, parts corresponding to parts in <figref idref="DRAWINGS">FIG. 7</figref> are referred to with the same reference numerals.</p>
<p id="p-0077" num="0076">The monitoring system shown in <figref idref="DRAWINGS">FIG. 13</figref> includes an image-capturing camera <b>141</b>, an image-processing apparatus <b>151</b>, and a management apparatus <b>131</b>. Since each device within the apparatuses is similar to that in the first embodiment, the description of the device will be omitted. In this system configuration, since a captured image (image data) is distributed on the network only when a moving body is detected, advantages similar to those in the first embodiment can be achieved.</p>
<p id="p-0078" num="0077">Although the configuration of an image-capturing camera is described in the foregoing embodiments, the monitoring system can be established using an image-processing apparatus <b>161</b> of any type having a function other than the image-capturing function.</p>
<p id="p-0079" num="0078">For example, the monitoring system can be established using a portable information terminal, such as a cellular phone or a mobile information terminal, or a robot, such as a humanoid robot or animal robot.</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. 14</figref> shows an example of the configuration of a monitoring system of this type. In <figref idref="DRAWINGS">FIG. 14</figref>, parts corresponding to parts in <figref idref="DRAWINGS">FIG. 7</figref> are referred to with the same reference numerals.</p>
<p id="p-0081" num="0080">In the monitoring system shown in <figref idref="DRAWINGS">FIG. 14</figref>, the image-processing apparatus <b>161</b> including the image-capturing element <b>11</b> performs a process for detecting a monitor event, and transmits a processing result to the management apparatus <b>131</b> via the network. In this case, advantages similar to those in the foregoing embodiments can be achieved.</p>
<p id="p-0082" num="0081">Although a case where intrusion of a moving body is detected as a monitor event is described in the foregoing embodiments, the monitor event does not necessarily indicate intrusion of a moving body.</p>
<p id="p-0083" num="0082">For example, the present invention can also be applied to a case where intrusion or installation of a non-moving body into a set area is detected as a monitor event.</p>
<p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. 15</figref> shows an example of a process performed by the event detector <b>113</b> for detecting a non-moving body. In this case, the event detector <b>113</b> performs processing for detecting motion (step S<b>1</b>), processing for performing region integration (step S<b>2</b>), processing for determining a static region (step S<b>3</b>), processing for performing labeling (step S<b>4</b>), and processing for determining a region (step S<b>5</b>).</p>
<p id="p-0085" num="0084">The processing steps other than the processing step of determining a static region can be realized by processing steps similar to those for the moving body detection process. In the processing for determining a static region, it is determined whether or not a region that is identified as a moving body at a point in time is kept stationary at a position for a predetermined period of time. Labeling is performed only on a region whose static state is confirmed, and detection is not performed on a region whose static state is not confirmed.</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIGS. 16A to 16E</figref> show processing results corresponding to screens on which captured images of a vehicle traversing the screen are displayed. The vehicle is detected as a moving body at a point in time when the vehicle intrudes into an image capture range, and the vehicle traverses the screen. Thus, the vehicle is not detected as a non-moving body.</p>
<p id="p-0087" num="0086"><figref idref="DRAWINGS">FIGS. 17A to 17E</figref> show processing results corresponding to screens on which captured images of a vehicle stopping or parking in the screen are displayed.</p>
<p id="p-0088" num="0087">At a point in time when the vehicle intrudes into an image capture range, the vehicle is detected as a moving body. Then, after the vehicle stops moving and stands still at a place in the screen, the vehicle is detected as a non-moving body.</p>
<p id="p-0089" num="0088">The processing results shown in <figref idref="DRAWINGS">FIGS. 17A to 17E</figref> indicate the sizes S, coordinates (x,y), and times t of integrated regions.</p>
<p id="p-0090" num="0089">A case where the event detector <b>113</b> performs the entire detection process is described in the foregoing embodiments. That is, a case where, in a moving body detection process, all the motion detection processing (<figref idref="DRAWINGS">FIG. 8B</figref>), the region integration processing (<figref idref="DRAWINGS">FIG. 8C</figref>), the labeling processing (<figref idref="DRAWINGS">FIG. 8D</figref>), and the region determination processing (<figref idref="DRAWINGS">FIG. 8E</figref>) are executed in the event detector <b>113</b> is described in the foregoing embodiments.</p>
<p id="p-0091" num="0090">However, a procedure in which the event detector <b>113</b> performs only some of processing functions of the processing algorithms and in which the management apparatus <b>131</b> (the event determination unit <b>133</b>) performs the other processing functions can be adopted. For example, the event detector <b>113</b> may perform processes until the region integration processing and may transmit the processing results to the management apparatus <b>131</b> via the network, and the management apparatus <b>131</b> may perform the labeling processing and the region determination processing. In this case, the occupied bandwidth can be significantly reduced compared with a case where a captured image is distributed on the network.</p>
<p id="p-0092" num="0091">In addition, since a large load is not necessary for the labeling processing and the region determination processing, many image-capturing cameras can be managed by a management apparatus without any trouble.</p>
<p id="p-0093" num="0092">In this case, a procedure in which the management apparatus instructs the image-capturing apparatus to transmit a captured image in accordance with detection of a monitor event can be adopted.</p>
<p id="p-0094" num="0093">The event detector <b>113</b> may autonomously determine transmission of a captured image within a range determined from a result of processing performed by the event detector <b>113</b>.</p>
<p id="p-0095" num="0094">Descriptions are mostly focused on a security system in the foregoing embodiments.</p>
<p id="p-0096" num="0095">However, the present invention can also be applied to an industrial camera system, a video convention system, a remote camera system (for talks, lectures, and other educational subjects, chamber photography, and event photography), and other monitoring systems as long as the system is used for recording a captured image and for sending out an alert only when a particular monitor event is detected.</p>
<p id="p-0097" num="0096">Although a case where a process for detecting a monitor event is realized in terms of hardware is described in the foregoing embodiments, such a process can be realized as software processing. In this case, a program may be distributed via a network or distributed by being stored on a storage medium. The storage medium used for distribution may be a magnetic storage medium, an optical storage medium, a semiconductor storage medium, or the like.</p>
<p id="p-0098" num="0097">Various modifications can be made to the present invention without departing from the scope of the present invention. In addition, various modifications and applications can be created or combined in accordance with the descriptions in this specification.</p>
<p id="p-0099" num="0098">It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A monitoring system comprising:
<claim-text>a plurality of image-capturing apparatuses each including an event detector that executes on a corresponding captured image only some of a plurality of processing algorithms about a monitor event including region integration processing, and a transmission controller (a) that outputs to a network only a processing result of at least size of each integrated region for each moving body from the region integration processing of the executed processing algorithms without outputting the captured image when the monitor event is not determined by a management apparatus and (b) that outputs to the network the captured image for recording by the management apparatus only when an instruction to transmit the captured image is received from the management apparatus; and</claim-text>
<claim-text>the management apparatus managing the plurality of image-capturing apparatuses via the network and including (1) an event determination unit that (a) determines occurrence of the monitor event in accordance with the received region integration processing results, (b) instructs the image capturing apparatus to transmit the captured image for recording only when the monitor event is determined to occur and (c) performs remaining processing algorithms of the plurality of processing algorithms on the received captured image and (2) a record controller that records the received captured image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The monitoring system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitor event indicates intrusion of a moving body into a set area.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The monitoring system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitor event indicates intrusion or installation of a nonmoving body into a set area.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A monitoring system comprising:
<claim-text>a plurality of image-capturing apparatuses;</claim-text>
<claim-text>a plurality of image-processing apparatuses each including an event detector that executes on a corresponding captured image only part of a plurality of processing algorithms about a monitor event including region integration processing, and a transmission controller (a) that outputs to a network only a processing result of at least size of each integrated region for each moving body from the region integration processing of the executed processing algorithms without outputting the captured image when the monitor event is not determined by a management apparatus and (b) that outputs to the network the captured image for recording by the management apparatus only when an instruction to transmit the captured image is received from the management apparatus; and</claim-text>
<claim-text>the management apparatus managing the plurality of image-processing apparatuses via the network and including (1) an event determination unit that (a) determines occurrence of the monitor event in accordance with the received region integration processing results, (b) instructs the image processing apparatus to transmit the captured image for recording only when the monitor event is determined to occur and (c) performs remaining processing algorithms on the received captured image and (2) a record controller that records the received captured image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The monitoring system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein each of the plurality of image-processing apparatuses includes a corresponding one of the image-capturing apparatuses.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The monitoring system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein each of the plurality of image-processing apparatuses is externally connected to a corresponding one of the image capturing apparatuses.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An image-processing apparatus comprising:
<claim-text>an event detector that executes on a corresponding captured image only some of a plurality of processing algorithms about a monitor event, wherein some of the plurality of processing algorithm include at least a processing result of at least size of each integrated region for each moving body from region integration processing in the captured image; and</claim-text>
<claim-text>a transmission controller (a) that outputs to a network only the region integration processing result of the executed processing algorithms without outputting the captured image when the monitor event is not determined by an external device and (h) that outputs to the network at least the captured image for recording by the external device only when an instruction to transmit the captured image is received from the external device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A management apparatus comprising:
<claim-text>an event determination unit that (a) receives only processing result of at least size of each integrated region for each moving body from region integration processing of some of a plurality of processing algorithms via a network without receiving captured image from an external device, (b) determines occurrence of a monitor event in accordance with the received region integration processing result, (c) instructs the external device to transmit the captured image for recording only when the monitor event is determined to occur, (d) receives the captured image only after the external device receives the instruction to transmit the captured image for recording and (e) performs remaining processing of the plurality of the algorithms on the received captured image; and</claim-text>
<claim-text>a record controller that records the captured image received after the external device is instructed to send the captured image based upon occurrence of the monitor event.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. An event detecting method for use in a monitoring system including a plurality of image-capturing apparatuses and a management apparatus managing the plurality of image-capturing apparatuses via a network, the method comprising the steps of:
<claim-text>executing, by each of the plurality of image-capturing apparatuses, on a corresponding captured image only some of a plurality of processing algorithms about a monitor event;</claim-text>
<claim-text>outputting, by each of the plurality of image-capturing apparatuses, to the network only processing results of at least size of each integrated region for each moving body from region integration processing of the executed processing algorithms without outputting the captured image when the monitor event is not determined by the management apparatus;</claim-text>
<claim-text>determining, by the management apparatus, occurrence of the monitor event in accordance with the received region integration processing result;</claim-text>
<claim-text>instructing a respective image-capturing apparatus to transmit the captured image for recording by the management apparatus only when the monitor event is determined to occur;</claim-text>
<claim-text>outputting, by each respective image-capturing apparatus to the network, the captured image for recording by the management apparatus only when the instruction to transmit the captured image is received by the respective image-capturing apparatus;</claim-text>
<claim-text>performing remaining processing algorithms on the received captured image; and</claim-text>
<claim-text>recording, by the management apparatus, the received captured image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An event detecting method for use in a monitoring system including a plurality of image-capturing apparatuses, a plurality of image-processing apparatuses, and a management apparatus managing the plurality of image-capturing apparatuses and the plurality of image-processing apparatuses via a network, the method comprising the steps of:
<claim-text>executing, by each of the plurality of image-processing apparatuses, on a corresponding captured image, only some of a plurality of processing algorithms about a monitor event;</claim-text>
<claim-text>outputting, by each of the plurality of image-processing apparatuses, to the network only processing results of at least size of each integrated region for each moving body front region integration processing of the executed processing algorithms without outputting the captured image when the monitor event is not determined by the management apparatus;</claim-text>
<claim-text>determining, by management apparatus, occurrence of a monitor event in accordance with the received region integration processing results;</claim-text>
<claim-text>instructing the image-processing apparatus to transmit the captured image for recording by the management apparatus only after the monitor event is determined to occur by the management apparatus;</claim-text>
<claim-text>outputting, by each respective mage-processing apparatus to the network, the captured image for recording by the management apparatus only when an instruction to transmit the captured image is received by the respective image-processing apparatus;</claim-text>
<claim-text>performing remaining processing algorithms on the received captured image by the management apparatus, and</claim-text>
<claim-text>recording, by the management apparatus, the received captured image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An event detecting method comprising the steps of:
<claim-text>causing a computer to execute on a corresponding captured image some of a plurality of processing algorithms about a monitor event;</claim-text>
<claim-text>causing the computer to output to a network only processing results of at least size of each integrated region for each moving body from region integration processing of the executed processing algorithms without outputting a captured image when the monitor event is not determined to occur by an external device; and</claim-text>
<claim-text>causing the computer to output to the network at least the captured image for recording by the external device only when an instruction to transmit the captured image for recording by the external device is received from the external device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A program embodied on a non-transitory computer-readable medium causing a computer to execute processing comprising the steps of:
<claim-text>receiving only processing results of at least size of each integrated region for each moving both from region integration processing of a plurality of processing algorithms about a monitor event via a network without receiving a captured image from an external device;</claim-text>
<claim-text>determining occurrence of a monitor event in accordance with only the received region integration processing result;</claim-text>
<claim-text>instructing the external device to transmit the captured image for recording only when the monitor event is determined to occur;</claim-text>
<claim-text>receiving the captured image only when the external device receives the instruction to transmit the captured image for recording;</claim-text>
<claim-text>performing processing of remaining processing algorithms on the received captured image; and</claim-text>
<claim-text>recording the captured image received after the external device is instructed based upon the occurrence of the monitor event. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
