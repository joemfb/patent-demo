<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625007-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625007</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13533302</doc-number>
<date>20120626</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2011-146322</doc-number>
<date>20110630</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>8</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>64</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348246</main-classification>
</classification-national>
<invention-title id="d2e71">Image pickup apparatus, image combination method, and computer program</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7362916</doc-number>
<kind>B2</kind>
<name>Yamazaki</name>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382275</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7872680</doc-number>
<kind>B2</kind>
<name>Misawa</name>
<date>20110100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348247</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7973977</doc-number>
<kind>B2</kind>
<name>Thurston, III</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  326</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>8081232</doc-number>
<kind>B2</kind>
<name>Sakamoto et al.</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482221</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2008/0259188</doc-number>
<kind>A1</kind>
<name>Kobayashi et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348247</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>2004-242103</doc-number>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>2008-306508</doc-number>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>18</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348241</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348246</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348247</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>35</number-of-drawing-sheets>
<number-of-figures>86</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130002910</doc-number>
<kind>A1</kind>
<date>20130103</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sambonsugi</last-name>
<first-name>Hideaki</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Sambonsugi</last-name>
<first-name>Hideaki</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Cowan, Liebowitz &#x26; Latman, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Canon Kabushiki Kaisha</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Henn</last-name>
<first-name>Timothy J</first-name>
<department>2662</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image pickup apparatus arranged to derive a change amount of an image B to an image A as combination position information, on the basis of which the image B is combined to the image A by shifting a position of the image B to generate a combined image D and a position of pixel defect information of the image B is changed, and synthesize pixel defect information of the image A and pixel defect information of the image B after the change to generate pixel defect information of the combined image D such that the pixel defect information in which a detection level corresponding to ISO100 is deleted from the pixel defect information of the combined image D and a detection level of pixel defect information of the pixel shown by same addresses is raised.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="178.56mm" wi="265.51mm" file="US08625007-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="194.82mm" wi="177.80mm" orientation="landscape" file="US08625007-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="266.36mm" wi="177.55mm" orientation="landscape" file="US08625007-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="252.81mm" wi="120.14mm" orientation="landscape" file="US08625007-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="249.09mm" wi="189.40mm" file="US08625007-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="267.97mm" wi="161.04mm" file="US08625007-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="245.96mm" wi="180.68mm" file="US08625007-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="244.35mm" wi="175.26mm" file="US08625007-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="258.49mm" wi="176.78mm" file="US08625007-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="244.35mm" wi="168.91mm" file="US08625007-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="196.43mm" wi="150.11mm" file="US08625007-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="241.98mm" wi="180.68mm" file="US08625007-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="245.11mm" wi="186.18mm" file="US08625007-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="244.35mm" wi="180.68mm" file="US08625007-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="168.15mm" wi="146.90mm" file="US08625007-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="249.09mm" wi="183.05mm" file="US08625007-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="252.22mm" wi="185.42mm" file="US08625007-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="267.97mm" wi="174.41mm" orientation="landscape" file="US08625007-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="261.62mm" wi="154.01mm" orientation="landscape" file="US08625007-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="222.33mm" wi="137.50mm" file="US08625007-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="241.98mm" wi="178.39mm" file="US08625007-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="249.85mm" wi="176.78mm" file="US08625007-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="244.35mm" wi="173.65mm" file="US08625007-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="235.71mm" wi="184.66mm" file="US08625007-20140107-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="238.84mm" wi="179.15mm" file="US08625007-20140107-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="242.82mm" wi="173.65mm" file="US08625007-20140107-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00026" num="00026">
<img id="EMI-D00026" he="234.95mm" wi="179.92mm" file="US08625007-20140107-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00027" num="00027">
<img id="EMI-D00027" he="236.47mm" wi="180.68mm" file="US08625007-20140107-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00028" num="00028">
<img id="EMI-D00028" he="252.98mm" wi="176.02mm" file="US08625007-20140107-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00029" num="00029">
<img id="EMI-D00029" he="260.10mm" wi="187.03mm" file="US08625007-20140107-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00030" num="00030">
<img id="EMI-D00030" he="226.31mm" wi="173.65mm" file="US08625007-20140107-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00031" num="00031">
<img id="EMI-D00031" he="254.59mm" wi="186.18mm" file="US08625007-20140107-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00032" num="00032">
<img id="EMI-D00032" he="238.84mm" wi="187.79mm" file="US08625007-20140107-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00033" num="00033">
<img id="EMI-D00033" he="229.45mm" wi="193.29mm" file="US08625007-20140107-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00034" num="00034">
<img id="EMI-D00034" he="255.35mm" wi="173.65mm" file="US08625007-20140107-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00035" num="00035">
<img id="EMI-D00035" he="249.09mm" wi="179.92mm" file="US08625007-20140107-D00035.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates to an image pickup apparatus, an image combination method, and a computer program and, more particularly, is suitable for use for correctings a defect of a pixel of an image pickup element.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">In an image pickup apparatus in the related art, a pixel defect of an image pickup element is corrected as follows. First, pixel defect information such as position information and the like of a defective pixel in the image pickup element is inspected just before a shipping of a product, and the pixel defect information is stored every product of the image pickup apparatus. By a dedicated correction circuit equipped for the image pickup apparatus, a processing for suppressing that a damage which causes a pixel defect stands out is executed to an image which is formed by the image pickup apparatus.</p>
<p id="p-0006" num="0005">For example, Japanese Patent Application Laid-Open No. 2004-242103 discloses a method whereby position information of a defective pixel is stored every operation mode such as still image shooting mode, live view mode (monitor mode), or the like and the pixel defect is corrected in each operation mode by using the position information of each defective pixel.</p>
<p id="p-0007" num="0006">In the image pickup apparatus, such a vibration correction or multiple exposure that after a plurality of images are image picked up and a position adjustment is performed, obtained images are combined is executed. In the case of combining the images as mentioned above, there is such a problem that when the images are superimposed, such fine pixel defects that no problem will occur in a single image is accumulated and the pixel defects become conspicuous as a damage.</p>
<p id="p-0008" num="0007">However, according to the related art disclosed in the above patent literature, in the case of combining a plurality of images by shifting (matching) the positions thereof, a damage which became conspicuous due to coincidence of the positions of the fine pixel cannot be corrected.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">It is an aspect of the invention to surely correct a damage which is caused by accumulation of fine pixel defects included in each image when a plurality of photographed images are combined by shifting positions thereof.</p>
<p id="p-0010" num="0009">According to an aspect of the present invention, an image pickup apparatus comprises: a combination unit configured to combine a plurality of images photographed by using an image pickup element; a change unit configured to, in the case where pixel positions of defective pixels in each of the plurality of images which are to be combined by the combination unit coincide, change defect level information showing a level of the defect of the defective pixel in a combined image; and a correction unit configured to, on the basis of the defect level information before it is changed by the change unit, correct the defective pixels in each of the plurality of images which are to be combined by the combination unit and, on the basis of the defect level information changed by the change unit, correct the defective pixels in the image combined by the combination unit.</p>
<p id="p-0011" num="0010">According to the invention, the damage which is caused by accumulation of the fine pixel defects included in each image when a plurality of photographed images are combined by shifting positions thereof can be surely corrected.</p>
<p id="p-0012" num="0011">Further features of the present invention will become apparent from the following description of exemplary embodiments with reference to the attached drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating a construction of an image pickup apparatus.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating a construction of an image processing unit of the first embodiment.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating a construction of a pixel defect information synthesization unit of the first embodiment.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart for describing the operation of the image pickup apparatus of the first embodiment.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. 5A</figref>, <b>5</b>B and <b>5</b>C are diagrams illustrating pixel defect positions, pixel defect information, defective pixels, and pixels surrounding them.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. 6A</figref>, <b>6</b>B and <b>6</b>C are diagrams illustrating damage positions of an image A after correction, an object position, and damage information.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. 7A</figref>, <b>7</b>B and <b>7</b>C are diagrams illustrating pixel defect positions of an image B after correction, an object position, and pixel defect information.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIGS. 8A</figref>, <b>8</b>B and <b>8</b>C are diagrams illustrating pixel defect positions of an image C after correction, an object position, and pixel defect information.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. 9A</figref>, <b>9</b>B and <b>9</b>C are diagrams illustrating pixel defect positions of the image B after address conversion, an object position, and pixel defect information.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 10</figref> is a diagram illustrating pixel defect information in which pixel defect information of the image A and pixel defect information of the image B are synthesized.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 11A</figref>, <b>11</b>B and <b>11</b>C are diagrams illustrating pixel defect positions of a combined image D, an object position, and pixel defect information.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 12A</figref>, <b>12</b>B and <b>12</b>C are diagrams illustrating pixel defect positions of the combined image D after correction, an object position, and pixel defect information.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. 13A</figref>, <b>13</b>B and <b>13</b>C are diagrams illustrating pixel defect positions of the image C after address conversion, an object position, and pixel defect information.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 14</figref> is a diagram illustrating a damaged image in which pixel defect information of the combined image D and pixel defect information of the image C are synthesized.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. 15A</figref>, <b>15</b>B and <b>15</b>C are diagrams illustrating pixel defect positions of a combined image E, an object position, and pixel defect information.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIGS. 16A</figref>, <b>16</b>B and <b>16</b>C are diagrams illustrating pixel defect positions of the combined image E after correction, an object position, and pixel defect information.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 17</figref> is a diagram illustrating a construction of an image processing unit of the second embodiment.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 18</figref> is a diagram illustrating a construction of a pixel defect information synthesization unit of the second embodiment.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 19</figref> is a flowchart for describing the operation of the image pickup apparatus of the second embodiment.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIGS. 20A and 20B</figref> are diagrams illustrating pixel defect positions and pixel defect information.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIGS. 21A</figref>, <b>21</b>B and <b>21</b>C are diagrams illustrating pixel defect positions of an image F after correction, an object position, and pixel defect information.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. 22A</figref>, <b>22</b>B and <b>22</b>C are diagrams illustrating pixel defect positions of an image G after correction, an object position, and pixel defect information.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIGS. 23A</figref>, <b>23</b>B and <b>23</b>C are diagrams illustrating pixel defect positions of an image H after correction, an object position, and pixel defect information.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIGS. 24A</figref>, <b>24</b>B and <b>24</b>C are diagrams illustrating pixel defect information of the image F in which the information of the pixels corrected at the time of photographing and the information of the pixels existing out of a range of the image pickup element are deleted.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIGS. 25A</figref>, <b>25</b>B and <b>25</b>C are diagrams illustrating pixel defect information of the image G in which the information of the pixels corrected at the time of photographing and the information of the pixels existing out of a range of the image pickup element are deleted.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIGS. 26A</figref>, <b>26</b>B and <b>26</b>C are diagrams illustrating pixel defect positions of the image G after address conversion, an object position, and pixel defect information.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIGS. 27A</figref>, <b>27</b>B and <b>27</b>C are diagrams illustrating positions of defective pixels of the image G after a detection level is converted, an object position, and pixel defect information.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIGS. 28A</figref>, <b>28</b>B and <b>28</b>C are diagrams illustrating pixel defect positions of a combined image I, an object position, and pixel defect information.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIGS. 29A</figref>, <b>29</b>B and <b>29</b>C are diagrams illustrating pixel defect positions of the combined image I after correction, an object position, and pixel defect information.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIGS. 30A</figref>, <b>30</b>B and <b>30</b>C are diagrams illustrating positions of defective pixels of an image H in which the information of the pixels corrected at the time of photographing and the information of the pixels existing out of the range of the image pickup element are deleted, an object position, and pixel defect information.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. 31A</figref>, <b>31</b>B and <b>31</b>C are diagrams illustrating positions of defective pixels of the combined image I in which the information of the pixels corrected upon combination is deleted, an object position, and pixel defect information.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. 32A</figref>, <b>32</b>B and <b>32</b>C are diagrams illustrating pixel defect positions of the image H after address conversion, an object position, and pixel defect information.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIGS. 33A</figref>, <b>33</b>B and <b>33</b>C are diagrams illustrating an example of positions of defective pixels of the image H after a detection level is converted, an object position, and pixel defect information.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIGS. 34A</figref>, <b>34</b>B and <b>34</b>C are diagrams illustrating pixel defect positions of a combined image J, an object position, and pixel defect information.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. 35A</figref>, <b>35</b>B and <b>35</b>C are diagrams illustrating positions of defective pixels of the combined image J after the defective pixels are corrected, an object position, and pixel defect information.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DESCRIPTION OF THE EMBODIMENTS</heading>
<p id="p-0048" num="0047">Exemplar embodiments of the present invention will be described in detail hereinbelow with reference to the drawings.</p>
<heading id="h-0005" level="1">First Embodiment</heading>
<p id="p-0049" num="0048">First, the first embodiment of the invention will be described. <figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating an example of a construction of an image pickup apparatus according to the embodiment. An example of a fundamental construction of the image pickup apparatus of the embodiment will be described hereinbelow with reference to <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0050" num="0049">In an image pickup apparatus <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, an image pickup element <b>101</b> converts (photoelectrically converts) an optical image into an electric signal. An analog front end (AFE) <b>103</b> executes a gain adjustment and a digital conversion corresponding to a predetermined quantization bit to an analog image signal which is output from the image pickup element <b>101</b>. A TG <b>102</b> is a timing generator for controlling drive timing of the image pickup element <b>101</b> and the AFE <b>103</b>.</p>
<p id="p-0051" num="0050">A RAM <b>108</b> also has: a function serving as an image data storage unit for storing digital image data converted by the AFE <b>103</b> and image data processed by an image processing unit <b>109</b>, which will be described hereinafter; a function serving as a work memory which is used when a CPU <b>104</b>, which will be described hereinafter, operates; and the like. Although those functions are executed by using the RAM <b>108</b> in the embodiment, those functions can be also realized by using a memory other than the RAM <b>108</b> so long as it is a memory whose access rate is at such a level that no problem will occur.</p>
<p id="p-0052" num="0051">A program and the like which are used when the CPU <b>104</b>, which will be described hereinafter, operates are stored in a ROM <b>106</b>. Although a case where the ROM <b>106</b> is a Flash-ROM will be mentioned and described as an example in the embodiment, a memory other than the Flash-ROM can be also applied as a ROM <b>106</b> so long as it is a memory whose access rate is at such a level that no problem will occur.</p>
<p id="p-0053" num="0052">The CPU <b>104</b> integratedly control the image pickup apparatus <b>100</b>. The image processing unit <b>109</b> executes processings such as correction, compression, and the like of a photographed image.</p>
<p id="p-0054" num="0053">An interface (I/F) <b>110</b> is provided to record still image data and moving image data into an external recording medium <b>113</b> connected through a connector <b>112</b> or to input data from the external recording medium <b>113</b>. For example, the external recording medium <b>113</b> is a non-volatile memory, a hard disk, or the like. The external recording medium <b>113</b> has: a connector <b>116</b> for connecting the recording medium <b>113</b> to the image pickup apparatus <b>100</b>; and an I/F <b>114</b> for inputting and outputting the still image data and the moving image data to/from the image pickup apparatus <b>100</b>.</p>
<p id="p-0055" num="0054">Although the detachable external recording medium <b>113</b> is applied as a recording medium in the embodiment, another device such as non-volatile memory, hard disk, or the like in which data can be written may be included in the image pickup apparatus <b>100</b> as a built-in device.</p>
<p id="p-0056" num="0055">An operation unit <b>105</b> is provided to set a photographing command, a photographing condition, and the like into the CPU <b>104</b> on the basis of the operation of the user. A display unit <b>107</b> displays a photographed still image or moving image, a menu, or the like.</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating an example of a construction of the image processing unit <b>109</b>.</p>
<p id="p-0058" num="0057">An image combination unit <b>200</b><i>a </i>combines a plurality of photographed images. A positional difference detection unit <b>200</b><i>h </i>detects a positional difference among object positions of the plurality of images from a plurality of photographed image data and outputs a positional difference amount of the object positions to the image combination unit <b>200</b><i>a </i>and a pixel defect information synthesization unit <b>200</b><i>b</i>, which will be described hereinafter. On the basis of &#x201c;positional difference amount of the object positions&#x201d; which is obtained from the positional difference detection unit <b>200</b><i>h</i>, the image combination unit <b>200</b><i>a </i>executes a predetermined position adjustment processing to the plurality of image data and combines the plurality of images. Although the combination of the images is realized by executing an addition processing of the mutually corresponding pixel data in the embodiment, the image combination method is not limited to such a method.</p>
<p id="p-0059" num="0058">In the embodiment, the pixel defects of the image are corrected on the basis of pixel defect information stored in the ROM <b>106</b>. The damage information is information including, for example, a level of the pixel defect and &#x201c;position (addresses) on the image pickup element <b>101</b>&#x201d; of a defective pixel. A pixel defect correction unit <b>200</b><i>e </i>inputs the image data to be subjected to a correction of the pixel defect and the pixel defect information and detects and corrects the pixel defect by processings, which will be described hereinafter.</p>
<p id="p-0060" num="0059">When a plurality of image data are combined, the pixel defect information synthesization unit <b>200</b><i>b </i>forms pixel defect information of the image after the combination on the basis of photographing information and the pixel defect information of the image data to be subjected to the combination and outputs to the pixel defect correction unit <b>200</b><i>e. </i></p>
<p id="p-0061" num="0060">An image compression unit <b>200</b><i>f </i>compresses the image when the image is recorded. Each of selectors <b>200</b><i>c</i>, <b>200</b><i>d</i>, and <b>200</b><i>g </i>selects and outputs the image data or the pixel defect information.</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating an example of a construction of the pixel defect information synthesization unit <b>200</b><i>b </i>illustrated in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0063" num="0062">An address conversion unit <b>201</b><i>a </i>converts addresses of the pixel defect information. A pixel defect information synthesization unit <b>201</b><i>b </i>synthesizes a plurality of pixel defect information. A detection level conversion unit <b>201</b><i>c </i>changes a detection level in the synthesized pixel defect information on the basis of coincidence and dissidence of the addresses at the time of synthesization and on the basis of photographing information.</p>
<p id="p-0064" num="0063">Subsequently, an example of the operation of the image pickup apparatus <b>100</b> of the embodiment will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0065" num="0064">The user sets &#x201c;valid&#x201d; or &#x201c;invalid&#x201d; of an image vibration-proof function at the time of photographing by using the operation unit <b>105</b> from a menu setting which is previously displayed on the display unit <b>107</b>. After that, when a shutter button of the operation unit <b>105</b> is depressed by the user, the photographing is started.</p>
<p id="p-0066" num="0065">When the photographing is started, in step S<b>101</b>, the CPU <b>104</b> discriminates whether or not the image vibration-proof function is valid. If the image vibration-proof function is valid as a result of the discrimination, step S<b>102</b> follows.</p>
<p id="p-0067" num="0066">In step S<b>102</b>, when the CPU <b>104</b> makes a predetermined setting into the image pickup element <b>101</b>, TG <b>102</b>, and AFE <b>103</b>, the photographing of the image is started. An image signal which is output from the image pickup element <b>101</b> is A/D converted (converted into digital data) by the AFE <b>103</b>. The image signal (image data) which is converted into the digital data is stored in the RAM <b>108</b>. In the embodiment, it is assumed that photographing sensitivity is equal to ISO100.</p>
<p id="p-0068" num="0067">After that, in step S<b>103</b>, a correction of a pixel defect is performed. The CPU <b>104</b> transfers the image data stored in the RAM <b>108</b> to the image processing unit <b>109</b>. The image data transferred to the image processing unit <b>109</b> is input to the image processing unit <b>109</b> as a data input C illustrated in <figref idref="DRAWINGS">FIG. 2</figref>. At this time, the selector <b>200</b><i>d </i>is connected to a b side and the image data which is input as a data input C is input to the pixel defect correction unit <b>200</b><i>e. </i></p>
<p id="p-0069" num="0068">The CPU <b>104</b> transfers &#x201c;pixel defect information of the image pickup element <b>101</b>&#x201d; stored in the ROM <b>106</b> to the image processing unit <b>109</b>. The pixel defect information transferred in this manner is input to the image processing unit <b>109</b> as a pixel defect information input C illustrated in <figref idref="DRAWINGS">FIG. 2</figref>. At this time, the selector <b>200</b><i>c </i>is connected to a b side and the pixel defect information which is input as a pixel defect information input C is input to the pixel defect correction unit <b>200</b><i>e. </i></p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 5A</figref> illustrates pixel positions (pixel defect positions) on the image pickup element <b>101</b> and one lattice corresponds to one pixel. It is assumed that the pixel position is defined by an X address and a Y address and pixels are arranged every n pixels in the X address direction and every m pixels in the Y address direction, respectively. In <figref idref="DRAWINGS">FIG. 5A</figref>, a pixel in which a pattern is drawn is a defective pixel. <figref idref="DRAWINGS">FIG. 5B</figref> is a diagram illustrating pixel defect information corresponding to the defective pixel illustrated in <figref idref="DRAWINGS">FIG. 5A</figref>. A pixel defect position shown by the X&#xb7;Y addresses and a detection level of the pixel defect showing a degree (size) of the pixel defect of each defective pixel are included in the pixel defect information. The larger a value of the detection level is, the smaller an output value (pixel value) as a defective pixel is. In <figref idref="DRAWINGS">FIG. 5A</figref>, the defective pixel is shown by making the pattern different in accordance with the detection level.</p>
<p id="p-0071" num="0070">The pixel defect correction unit <b>200</b><i>e </i>sequentially monitors (designates) the pixel positions of the image data which is sequentially input to the pixel defect correction unit <b>200</b><i>e</i>. When the position (X&#xb7;Y addresses) of the defective pixel existing in the pixel defect information is designated, the detection level of the relevant pixel is referred to from the pixel defect information. The pixel defect correction unit <b>200</b><i>e </i>refers to the photographing sensitivity from the photographing information which is input simultaneously with the image data and discriminates the presence or absence of the correction of the relevant pixel (detects the pixel defect) in accordance with the photographing sensitivity and the detection level. For example, when the photographing sensitivity is equal to ISO100, the pixel defect correction unit <b>200</b><i>e </i>corrects the defective pixel whose detection level is equal to 100. When the photographing sensitivity is equal to ISO200, the pixel defect correction unit <b>200</b><i>e </i>corrects the defective pixel whose detection level is equal to or less than 200.</p>
<p id="p-0072" num="0071">The correction of the defective pixel is performed by, for example, a method whereby an average value of outputs (pixel values) of the pixels surrounding the relevant pixel, that is, the pixels of the same color as that of the relevant pixel is replaced as a pixel value of the relevant pixel. <figref idref="DRAWINGS">FIG. 5C</figref> is a diagram illustrating an example of the defective pixel and the pixels surrounding it. For example, in the case of correcting &#x201c;pixel locating at G<b>22</b>&#x201d; illustrated in <figref idref="DRAWINGS">FIG. 5C</figref>, a value obtained by averaging outputs (pixel values) of the pixels locating at G<b>11</b>, G<b>13</b>, G<b>31</b>, and G<b>33</b> is replaced as a pixel value at G<b>22</b>. Although the embodiment is described with respect to the case of correcting the defective pixel as mentioned above as an example, the method of correcting the defective pixel is not limited.</p>
<p id="p-0073" num="0072">Since the photographing is executed at the photographing sensitivity of ISO100 in the embodiment, &#x201c;pixels whose addresses (X, Y) are equal to (2, 10), (3, 8), (7, 4), (8, 1), and (9, 11)&#x201d; whose detection levels are equal to 100 are corrected. <figref idref="DRAWINGS">FIGS. 6A to 6C</figref> are diagrams illustrating an example of positions (<figref idref="DRAWINGS">FIG. 6A</figref>) of defective pixels of the first image after defective pixels are corrected, an object position (<figref idref="DRAWINGS">FIG. 6B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 6C</figref>). In <figref idref="DRAWINGS">FIG. 6A</figref>, although the defect pixels which are not corrected since the detection level is equal to 200 remain, since an output value of each of those defective pixels is small as a defective pixel, they do not exert an influence on image quality.</p>
<p id="p-0074" num="0073">The corrected image is stored as a first image into the RAM <b>108</b>. A relation between the pixel position of the image pickup element of the first image and the object position is as illustrated in <figref idref="DRAWINGS">FIG. 6B</figref>. Such an image is referred to as an image A in the following description.</p>
<p id="p-0075" num="0074">Subsequently, in step S<b>104</b>, the CPU <b>104</b> discriminates whether or not the photographing of the necessary number of photographings (the set number of photographings) at the time of the image vibration-proof operation is completed. Since three images are used at the time of the image vibration-proof operation in the embodiment, the processing routine is returned to step S<b>102</b> and the next photographing is executed. After that, the operations of steps S<b>102</b> to S<b>104</b> mentioned above are repeated and the second and third images are stored into the RAM <b>108</b>.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIGS. 7A to 7C</figref> and <figref idref="DRAWINGS">FIGS. 8A to 8C</figref> are diagrams illustrating examples of positions (<figref idref="DRAWINGS">FIG. 7A</figref>, <figref idref="DRAWINGS">FIG. 8A</figref>) of defective pixels of the second and third images after the defective pixels are corrected, object positions (<figref idref="DRAWINGS">FIG. 7B</figref>, <figref idref="DRAWINGS">FIG. 8B</figref>), and pixel image information (<figref idref="DRAWINGS">FIG. 7C</figref>, <figref idref="DRAWINGS">FIG. 8C</figref>). Relations among &#x201c;the defective pixels of the images after the pixel defects are corrected, the pixel positions of the image pickup element, and the object positions&#x201d; of the second and third images are as illustrated in <figref idref="DRAWINGS">FIGS. 7A to 7C</figref> and <figref idref="DRAWINGS">FIGS. 8A to 8C</figref>, respectively. Those images are referred to as an image B and an image C in the following description, respectively.</p>
<p id="p-0077" num="0076">If the photographing of the set number and the correction of the defective pixels are completed in step S<b>104</b>, the processing routine advances to step S<b>105</b> and the three images A, B, and C are combined. First, the CPU <b>104</b> transfers the data of the images A and B stored in the RAM <b>108</b> to the image processing unit <b>109</b>. As a data input A illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, the data of the image A is input to the image processing unit <b>109</b> and, as a data input B, the data of the image B is input thereto. Thus, the data of the images A and B is input to the positional difference detection unit <b>200</b><i>h</i>. The positional difference detection unit <b>200</b><i>h </i>detects a positional difference between the images A and B. As illustrated in <figref idref="DRAWINGS">FIGS. 6A to 6C</figref> and <figref idref="DRAWINGS">FIGS. 7A to 7C</figref>, if the addresses of each pixel of the image B are shifted in the X address direction by +4 and in the Y address direction by +2, the object position coincides with the position of the image A. Therefore, the positional difference detection unit <b>200</b><i>h </i>outputs combination position information (+4, +2). Although the positions of the images B and C are matched with the position of the image A in the embodiment, it is not always necessary to perform such an operation if the positions of the images A, B, and C are matched with a reference position.</p>
<p id="p-0078" num="0077">The image combination unit <b>200</b><i>a </i>shifts the addresses of each pixel of the image B in the X address direction by +4 and in the Y address direction by +2 on the basis of the combination position information (+4, +2) which is output from the positional difference detection unit <b>200</b><i>h</i>, adds the image B after it is shifted and the image A, and outputs a combined image D. After that, in step S<b>106</b>, defective pixels of the combined image D are corrected.</p>
<p id="p-0079" num="0078">First, the CPU <b>104</b> transfers pixel defect information of the images A and B to the image processing unit <b>109</b>. The pixel defect information is input to the image processing unit <b>109</b> as pixel defect information inputs A and B illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, respectively. The pixel defect information of the images A and B in this instance is as illustrated in <figref idref="DRAWINGS">FIGS. 6C and 7C</figref>, respectively, and is identical to the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 5B</figref>. Photographing information of the photographing sensitivity (ISO100) at the time of photographing the images A and B and the combination position information which is output from the positional difference detection unit <b>200</b><i>h </i>are input to the pixel defect information synthesization unit <b>200</b><i>b</i>. The pixel defect information of the image B which is input as a pixel defect information input B and the combination position information are input to the address conversion unit <b>201</b><i>a</i>. On the basis of the combination position information, the address conversion unit <b>201</b><i>a </i>converts the addresses included in the pixel defect information of the image B. <figref idref="DRAWINGS">FIGS. 9A to 9C</figref> are diagrams illustrating an example of positions (<figref idref="DRAWINGS">FIG. 9A</figref>) of defective pixels of the second image (image B) after the addresses are converted, an object position (<figref idref="DRAWINGS">FIG. 9B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 9C</figref>). Since the combination position information at this time is equal to (+4, +2), the addresses included in the pixel defect information of the image B are shifted in the X address direction by +4 and in the Y address direction by +2. Thus, the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 7C</figref> is converted into the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 9C</figref>.</p>
<p id="p-0080" num="0079">After that, the pixel defect information of the image A which is input as a pixel defect input A and the pixel defect information (after the conversion) of the image B which is output from the address conversion unit <b>201</b><i>a </i>are synthesized. <figref idref="DRAWINGS">FIG. 10</figref> is a diagram illustrating pixel defect information in which the pixel defect information of the image A and the pixel defect information of the image B after the addresses are converted in accordance with the image A are synthesized. The data of the synthesized pixel defect information is input to the detection level conversion unit <b>201</b><i>c</i>. The photographing information (photographing sensitivity of ISO100) is also input to the detection level conversion unit <b>201</b><i>c</i>. Since the defect whose detection level is equal to 100 is already corrected, it is deleted from the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 10</figref>. The pixel in which the same (two) addresses are shown as pixel defect information is a pixel in which the defects double after the images are combined and it is shown that an output value as a defect is large. Therefore, with respect to such a pixel, the detection level of the pixel defect information is changed higher by one degree. In the example illustrated in <figref idref="DRAWINGS">FIG. 10</figref>, since the defects whose detection levels are equal to 200 double in the pixel of the addresses (5, 3), the detection level is changed to 100 which is higher by one degree.</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIGS. 11A to 11C</figref> are diagrams illustrating pixel defect positions (<figref idref="DRAWINGS">FIG. 11A</figref>) of a combined image D formed as mentioned above, an object position (<figref idref="DRAWINGS">FIG. 11B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 11C</figref>). The selector <b>200</b><i>c </i>is connected to an a side and the pixel defect information of the combined image D illustrated in <figref idref="DRAWINGS">FIG. 11C</figref> is input to the pixel defect correction unit <b>200</b><i>e</i>. The selector <b>200</b><i>d </i>is connected to an a side and the data of the combined image D is input to the pixel defect correction unit <b>200</b><i>e</i>. In the pixel defect correction unit <b>200</b><i>e</i>, the defective pixels of the combined image D are corrected by using the pixel defect information of the combined image D in a manner similar to the processings mentioned above.</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIGS. 12A to 12C</figref> are diagrams illustrating positions (<figref idref="DRAWINGS">FIG. 12A</figref>) of the defective pixels of the combined image D in which the defective pixels are corrected, an object position (<figref idref="DRAWINGS">FIG. 12B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 12C</figref>). The selector <b>200</b><i>g </i>is connected to a b side and the data of the combined image D after the defective pixels are corrected and the pixel defect information of the combined image D are stored into the RAM <b>108</b>.</p>
<p id="p-0083" num="0082">Subsequently, in step S<b>107</b>, the CPU <b>104</b> discriminates whether or not the combination of the set number of images is completed. If it is decided as a result of the discrimination that the combination of the set number of images is not completed, the processing routine is returned to step S<b>105</b> and the processings of steps S<b>105</b> and S<b>106</b> are executed. Since three images are combined here, the processing routine is returned to step S<b>105</b>.</p>
<p id="p-0084" num="0083">In step S<b>105</b>, three images are combined. First, the CPU <b>104</b> transfers the data of the combined image D and the data of the image C which are stored in the RAM <b>108</b> to the image processing unit <b>109</b>. As a data input A in <figref idref="DRAWINGS">FIG. 2</figref>, the data of the combined image D is input to the image processing unit <b>109</b> and, as a data input B, the data of the image C is input thereto. Thus, the data of the combined image D and the data of the image C are input to the positional difference detection unit <b>200</b><i>h</i>. The positional difference detection unit <b>200</b><i>h </i>detects the positional difference between the combined image D and the image C. As illustrated in <figref idref="DRAWINGS">FIGS. 12A to 12C</figref> and <b>8</b>A to <b>8</b>C, if the addresses of each pixel of the image C are shifted in the X address direction by +2 and in the Y address direction by +2, the object position coincides with the position of the combined image D. Therefore, the positional difference detection unit <b>200</b><i>h </i>outputs combination position information (+2, +2).</p>
<p id="p-0085" num="0084">The image combination unit <b>200</b><i>a </i>shifts the addresses of each pixel of the image C in the X address direction by +2 and in the Y address direction by +2 on the basis of the combination position information (+2, +2) which is output from the positional difference detection unit <b>200</b><i>h</i>. The image combination unit <b>200</b><i>a </i>adds the image C in which the position of each pixel is shifted and the combined image D and outputs a combined image E. After that, in step S<b>106</b>, defective pixels of the combined image E are corrected.</p>
<p id="p-0086" num="0085">First, the CPU <b>104</b> transfers pixel defect information of the combined image D and pixel defect information of the image C to the image processing unit <b>109</b>. The pixel defect information is input to the image processing unit <b>109</b> as pixel defect information inputs A and B illustrated in <figref idref="DRAWINGS">FIG. 2</figref>. The pixel defect information of the combined image D and the pixel defect information of the image C at this time are as illustrated in <figref idref="DRAWINGS">FIGS. 12C and 8C</figref>, respectively. Photographing information of the photographing sensitivity (ISO100) at the time of photographing the image C and the combination position information which is output from the positional difference detection unit <b>200</b><i>h </i>are input to the pixel defect information synthesization unit <b>200</b><i>b</i>. The pixel defect information of the image C which is input as a pixel defect information input B and the combination position information are input to the address conversion unit <b>201</b><i>a</i>. On the basis of the combination position information, the address conversion unit <b>201</b><i>a </i>converts the addresses included in the pixel defect information of the image C. <figref idref="DRAWINGS">FIGS. 13A to 13C</figref> are diagrams illustrating an example of positions (<figref idref="DRAWINGS">FIG. 13A</figref>) of defective pixels of the third image (image C) after the addresses are converted, an object position (<figref idref="DRAWINGS">FIG. 13B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 13C</figref>). Since the combination position information at this time is equal to (+2, +2), the addresses included in the pixel defect information of the image C are shifted in the X address direction by +2 and in the Y address direction by +2. Thus, the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 8C</figref> is converted into the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 13C</figref>.</p>
<p id="p-0087" num="0086">After that, the pixel defect information of the combined image D which is input as a defect input A and the pixel defect information (after the conversion) of the image C which is output from the address conversion unit <b>201</b><i>a </i>are synthesized. <figref idref="DRAWINGS">FIG. 14</figref> is a diagram illustrating pixel defect information in which the pixel defect information of the combined image D and the pixel defect information of the image C after the addresses are converted in accordance with the combined image D are synthesized. The data of the synthesized pixel defect information is input to the detection level conversion unit <b>201</b><i>c</i>. The photographing information (photographing sensitivity of ISO100) is also input to the detection level conversion unit <b>201</b><i>c</i>. Since the defect whose detection level is equal to 100 is already corrected, it is deleted from the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 14</figref>. The pixel in which the same addresses are shown as pixel defect information is a pixel in which the defects double after the images are combined and it is shown that an output value as a defect is large. Therefore, with respect to such a pixel, the detection level of the pixel defect information is changed higher by one degree. In the example illustrated in <figref idref="DRAWINGS">FIG. 14</figref>, since the defects whose detection levels are equal to 200 double in the pixel of the addresses (7, 9), the detection level is changed to 100 which is higher by one degree.</p>
<p id="p-0088" num="0087"><figref idref="DRAWINGS">FIGS. 15A to 15C</figref> are diagrams illustrating pixel defect positions (<figref idref="DRAWINGS">FIG. 15A</figref>) of a combined image E formed as mentioned above, an object position (<figref idref="DRAWINGS">FIG. 15B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 15C</figref>). The selector <b>200</b><i>c </i>is connected to the a side and the pixel defect information of the combined image E is input to the pixel defect correction unit <b>200</b><i>e</i>. The selector <b>200</b><i>d </i>is connected to the a side and the data of the combined image E is input to the pixel defect correction unit <b>200</b><i>e</i>. In the pixel defect correction unit <b>200</b><i>e</i>, the defective pixels of the combined image E are corrected by using the pixel defect information of the combined image E in a manner similar to the foregoing processing.</p>
<p id="p-0089" num="0088"><figref idref="DRAWINGS">FIGS. 16A to 16C</figref> are diagrams illustrating positions (<figref idref="DRAWINGS">FIG. 16A</figref>) of the defective pixels of the combined image E after the defective pixels are corrected, an object position (<figref idref="DRAWINGS">FIG. 16B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 16C</figref>). Since the image combination is completed, the selector <b>200</b><i>g </i>is connected to an a side and the data of the combined image E in which the defective pixels are corrected is compressed by the image compression unit <b>200</b><i>f </i>and, thereafter, stored into the RAM <b>108</b>.</p>
<p id="p-0090" num="0089">When the combination of all of (three) images A to C is completed, the processing routine advances to step S<b>108</b>. The CPU <b>104</b> allows the data of the combined image E stored in the RAM <b>108</b> to be recorded into the external recording medium <b>113</b>. The photographing is finished.</p>
<p id="p-0091" num="0090">If it is decided as a result of the discrimination of step S<b>101</b> that the image vibration-proof function is invalid, the processing routine advances to step S<b>109</b> and the photographing, the correction of the defective pixels, and the recording are executed every image. The operations of steps S<b>109</b> and S<b>110</b> are similar to the operations of steps S<b>102</b> and S<b>103</b>. The image data in which the correction of the defective pixels is finished in step S<b>110</b> is compressed by the image compression unit <b>200</b><i>f </i>and stored into the RAM <b>108</b>. Finally, in step S<b>111</b>, the CPU <b>104</b> allows the image data stored in the RAM <b>108</b> to be recorded into the external recording medium <b>113</b>. The photographing is finished.</p>
<p id="p-0092" num="0091">As mentioned above, in the embodiment, the pixel defect information including the position (addresses) of the defective pixels and the detection level is preliminarily stored in the image pickup apparatus <b>100</b>. It is assumed that three images are picked up in order to detect a motion (positional difference). First, a change amount of the second image B to the first image A is derived as combination position information. On the basis of the combination position information, the combined image D is formed by shifting the position of the image B and combining the image B to the image A and the position (addresses) of the pixel defect information of the image B is changed. pixel defect information of the combined image D is formed by synthesizing the pixel defect information of the image A and the pixel defect information of the image B after the change. In this instance, the pixel defect information in which the detection level corresponding to the photographing information (photographing sensitivity of ISO100) is equal to 100 is deleted from the pixel defect information of the combined image D and, at the same time, the detection level of the pixel defect information of the pixel in which the same addresses are shown is raised. By using such pixel defect information, the defective pixels of the combined image D are corrected. Subsequently, with respect to the combined image D and the image C, the same processings as those for the images A and B are executed, pixel defect information of the combined image E of the images A and B is formed, and the defective pixels of the combined image E are corrected. By executing the above processings, when a plurality of images are combined by shifting (adjusting) the positions thereof, if fine defective pixels which are not corrected by the correction of the defective pixels of every image double, only the pixel in which an output value serving as a defect increased can be corrected.</p>
<p id="p-0093" num="0092">Modification</p>
<p id="p-0094" num="0093">In the embodiment, when the pixel defect information of the two images are synthesized, only in the case where the addresses coincide in the pixel defect information of those images, the detection level of the defective pixel corresponding to those addresses is changed (raised) so that the defective pixel can be easily detected (corrected). However, it is not always necessary to execute such a processing. For example, even in the case where fine defects exist in the adjacent pixels, they are likely to be conspicuous as defects. Therefore, for example, when the defect information of the two images is synthesized, in the case where a predetermined number of addresses are (continuously) adjacent one after another in the pixel defect information of those images, the detection level of the defective pixel corresponding to those addresses may be changed so that the damaged pixel can be easily detected. Both of the detection level corresponding to the coincident addresses and the detection level corresponding to the adjacent addresses may be changed.</p>
<p id="p-0095" num="0094">If the number of images to be combined is large as a whole, there is a fear that fine defects are located closely together and image quality of the combined image is deteriorated. Therefore, for example, the detection level included in the pixel defect information may be changed (reduced) in such a manner that the number of fine defects (defective pixels) in a predetermined region after the defective pixels are corrected is equal to or less than a predetermined number (so that the defective pixels become difficult to be detected (corrected)).</p>
<p id="p-0096" num="0095">Degrees of conspicuousness of defects differ in dependence on pixel outputs (pixel values) of the pixels surrounding the defective pixel. Therefore, in addition to or in place of the change of the detection level mentioned above, for example, a degree of changing the detection level of the defective pixel so that the defective pixel can be easily detected (corrected) may be made different in accordance with the pixel outputs (pixel values) of the pixels surrounding the defective pixel.</p>
<p id="p-0097" num="0096">Although the embodiment is described with respect to the example of the case where the image data is image data of a Bayer array of RGB, the image data is not limited to such data. The method of the embodiment can be applied to any image data such as image data having luminance and color difference of YUV or the like so long as the position of the pixel defect is changed in dependence on the positional difference of the image.</p>
<p id="p-0098" num="0097">Although the embodiment is described with respect to the example of the case where the defective pixels are detected with reference to the detection level included in the pixel defect information, the method of detecting the defective pixels is not limited to such a method. For example, it is also possible to use such a method that an output value of the pixel specified by the addresses included in the pixel defect information and a predetermined set detection threshold value are compared and the pixel exceeding the detection threshold value is detected as a defective pixel. In this case, the detection level is not included in the pixel defect information but only address information can be also included therein. In this case, for example, there is used such a construction that on the basis of the combination position information, the addresses included in the pixel defect information of one image are converted in accordance with the other image, their pixel defect information is synthesized, and thereafter, if those addresses coincide or lie within a predetermined condition, the detection threshold value is changed. Such a processing as to enable the damaged pixel to be easily detected is realized not only by changing the detection level but also by changing the detection threshold value.</p>
<heading id="h-0006" level="1">Second Embodiment</heading>
<p id="p-0099" num="0098">Subsequently, the second embodiment of the invention will be described. Since a fundamental construction of an image pickup apparatus of the embodiment is the construction illustrated in <figref idref="DRAWINGS">FIG. 1</figref> and is substantially the same as that of the first embodiment, its detailed description is omitted here.</p>
<p id="p-0100" num="0099"><figref idref="DRAWINGS">FIG. 17</figref> is a diagram illustrating an example of a construction of the image processing unit <b>109</b> of the embodiment. An image combination unit <b>300</b><i>a </i>combines a plurality of photographed images. In the image combination unit <b>300</b><i>a</i>, on the basis of preset combination position information, a predetermined position adjustment processing is executed to a plurality of image data and the images are combined. Although the combination of the images is realized by executing an addition processing of the mutually corresponding pixel data in the embodiment, the image combination method is not limited to such a method.</p>
<p id="p-0101" num="0100">Also in the embodiment, defective pixels of the image are corrected on the basis of the pixel defect information stored in the ROM <b>106</b> in a manner similar to the first embodiment. The pixel defect information is information including a level of the pixel defect and a &#x201c;position (addresses) on the image pickup element <b>101</b>&#x201d; having a damage. A pixel defect correction unit <b>300</b><i>e </i>inputs the image data to be subjected to a correction of the pixel defect and the pixel defect information and detects and corrects the pixel defect by processings, which will be described hereinafter.</p>
<p id="p-0102" num="0101">When a plurality of image data are combined, a pixel defect information synthesization unit <b>300</b><i>b </i>forms pixel defect information of the image after the combination on the basis of photographing information and the pixel defect information of the image data to be subjected to the combination and outputs to the pixel defect correction unit <b>300</b><i>e</i>. An image compression unit <b>300</b><i>f </i>compresses the image when the image is recorded. Each of selectors <b>300</b><i>c</i>, <b>300</b><i>d</i>, and <b>300</b><i>g </i>selects and outputs the image data or the pixel defect information.</p>
<p id="p-0103" num="0102"><figref idref="DRAWINGS">FIG. 18</figref> is a diagram illustrating an example of a construction of the pixel defect information synthesization unit <b>300</b><i>b </i>illustrated in <figref idref="DRAWINGS">FIG. 17</figref>. Each of uncorrected pixel detection units <b>301</b><i>d </i>and <b>301</b><i>e </i>detects uncorrected pixels in the pixel defect information on the basis of the photographing information. An address conversion unit <b>301</b><i>a </i>converts addresses of the pixel defect information. A pixel defect information synthesization unit <b>301</b><i>b </i>synthesizes a plurality of damage information. A detection level conversion unit <b>301</b><i>c </i>changes a detection level in the synthesized pixel defect information on the basis of the photographing information and weighting information at the time of the image combination.</p>
<p id="p-0104" num="0103">Subsequently, an example of the operation of the image pickup apparatus <b>100</b> of the embodiment will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. 19</figref>. In the embodiment, the photographing of the image has previously been performed and the image data is recorded in the external recording medium <b>113</b>. The processings at the time of photographing are realized by the same processings as steps S<b>109</b> to S<b>111</b> described in the first embodiment. The image data in which the defective pixels are corrected is recorded in the external recording medium <b>113</b>.</p>
<p id="p-0105" num="0104"><figref idref="DRAWINGS">FIG. 20A</figref> illustrates pixel positions (pixel defect positions) on the image pickup element <b>101</b>. In this figure, one lattice corresponds to one pixel. It is assumed that the pixel position is defined by the X address and the Y address and pixels are arranged every n pixels in the X address and every m pixels in the Y address. In <figref idref="DRAWINGS">FIG. 20A</figref>, pixels in each of which a pattern is drawn are defective pixel. <figref idref="DRAWINGS">FIG. 20B</figref> is a diagram illustrating pixel defect information corresponding to the defective pixels illustrated in <figref idref="DRAWINGS">FIG. 20A</figref>. A pixel defect position shown by the X&#xb7;Y addresses and a detection level of the pixel defect showing a degree of the pixel defect of each defective pixel are included in the pixel defect information. The larger a value of the detection level is, the smaller an output value as a defective pixel is. In <figref idref="DRAWINGS">FIG. 20A</figref>, the defective pixel is shown by making the pattern different in accordance with the detection level. The correction of the defective pixel at the time of photographing is performed on the basis of the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 20B</figref>.</p>
<p id="p-0106" num="0105">In the embodiment, three photographed images are combined. In the following description, the three images are referred to as an image F, an image G, and an image H. The images F, G, and H are images photographed by the photographing sensitivities of ISO100, ISO200, and ISO400, respectively. <figref idref="DRAWINGS">FIGS. 21A to 23C</figref> are diagrams showing examples of positions (<figref idref="DRAWINGS">FIGS. 21A to 23A</figref>) of defective pixels of the images F, G, and H after the defective pixels are corrected, object positions (<figref idref="DRAWINGS">FIGS. 21B to 23B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIGS. 21C to 23C</figref>).</p>
<p id="p-0107" num="0106">In step S<b>201</b>, the user selects the image combination from a menu displayed in the display unit <b>107</b>. Images which are recorded in the external recording medium <b>113</b> are displayed in the display unit <b>107</b>. The user selects the images F, G, and H by using the operation unit <b>105</b>. The operation unit <b>105</b> sets a fact that the images F, G, and H are selected by the user into the CPU <b>104</b>.</p>
<p id="p-0108" num="0107">Subsequently, in step S<b>202</b>, the user sets the positions of the images F, G, and H at the time of combination by using the operation unit <b>105</b>. In this instance, it is assumed that the user does not change the position of the image F but sets the positions to the position where the addresses of each pixel of the image G are changed in the X address direction by &#x2212;2 and in the Y address direction by &#x2212;2 and to the position where the addresses of each pixel of the image H are changed in the Y address direction by &#x2212;2. Together with this setting, the user sets the luminosity of each of the images F, G, and H at the time of combination by using the operation unit <b>105</b>. In this instance, it is assumed that the user sets the luminosity of the image H to a double luminosity. The operation unit <b>105</b> sets those contents into the CPU <b>104</b>.</p>
<p id="p-0109" num="0108">When the setting of the position and luminosity of each of the images F, G, and H at the time of combination is finished, in step S<b>203</b>, the reading-out of the image is started. The CPU <b>104</b> transfers the data of the images F and G stored in the external recording medium <b>113</b> to the image processing unit <b>109</b>. As a data input A illustrated in <figref idref="DRAWINGS">FIG. 17</figref>, the data of the image F is input to the image processing unit <b>109</b> and, as a data input B, the data of the image G is input thereto.</p>
<p id="p-0110" num="0109">Subsequently, in step S<b>204</b>, the three images F, G, and H are combined. First, the CPU <b>104</b> transmits combination position information (the X address is changed, the Y address is changed)=(&#x2212;2, &#x2212;2) of the image G and luminosity information (luminosity change information) as an example of weighting information to the image processing unit <b>109</b>. On the basis of the combination position information (&#x2212;2, &#x2212;2), the image combination unit <b>300</b><i>a </i>shifts the addresses of each pixel of the image G in the X address direction by &#x2212;2 and in the Y address direction by &#x2212;2. Since the luminosity of the image G is not changed, the image combination unit <b>300</b><i>a </i>multiplies the luminosity of the image G by 1 time serving as luminosity information, adds the image G in which the addresses of each pixel are shifted and which is multiplied by 1 time as a luminosity and the image F, and outputs a combined image I.</p>
<p id="p-0111" num="0110">After that, in step S<b>205</b>, the correction (pixel defect correction) of the defective pixels of the combined image I is performed. First, the CPU <b>104</b> transfers the pixel defect information of the images F and G to the image processing unit <b>109</b>. The pixel defect information is input to the image processing unit <b>109</b> as pixel defect information inputs A and B illustrated in <figref idref="DRAWINGS">FIG. 18</figref>, respectively. The pixel defect information of the images F and G at this time is as illustrated in <figref idref="DRAWINGS">FIGS. 21C and 22C</figref>, respectively, and is the same as the pixel defect information illustrated in <figref idref="DRAWINGS">FIG. 20B</figref>. Those pixel defect information and the photographing information of the photographing sensitivities (ISO100, ISO200) at the time of photographing the images F and G are input to the uncorrected pixel detection units <b>301</b><i>d </i>and <b>301</b><i>e </i>illustrated in <figref idref="DRAWINGS">FIG. 18</figref>, respectively.</p>
<p id="p-0112" num="0111">The uncorrected pixel detection units <b>301</b><i>d </i>and <b>301</b><i>e </i>delete the information of the pixels which are corrected at the time of photographing the images F and G from the pixel defect information. The uncorrected pixel detection units <b>301</b><i>d </i>and <b>301</b><i>e </i>also delete the information of the pixels whose addresses are out of a range of the image pickup element from the pixel defect information. <figref idref="DRAWINGS">FIGS. 24A to 24C</figref> and <figref idref="DRAWINGS">FIGS. 25A to 25C</figref> are diagrams showing examples of positions (<figref idref="DRAWINGS">FIG. 24A</figref>, <figref idref="DRAWINGS">FIG. 25A</figref>) of the defective pixels of the images F and G in which the information of the pixels which are corrected at the time of photographing and the information of the pixels existing out of the range of the image pickup element are deleted, object positions (<figref idref="DRAWINGS">FIG. 24B</figref>, <figref idref="DRAWINGS">FIG. 25B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 24C</figref>, <figref idref="DRAWINGS">FIG. 25C</figref>).</p>
<p id="p-0113" num="0112">After that, an output from the uncorrected pixel detection unit <b>301</b><i>e </i>and the combination position information are input to the address conversion unit <b>301</b><i>a </i>illustrated in <figref idref="DRAWINGS">FIG. 18</figref>. The address conversion unit <b>301</b><i>a </i>converts the addresses included in the pixel defect information of the image G. Since the combination position information at this time is equal to (&#x2212;2, &#x2212;2), the addresses included in the pixel defect information of the image G are shifted in the X address direction by &#x2212;2 and in the Y address direction by &#x2212;2. <figref idref="DRAWINGS">FIGS. 26A to 26C</figref> are diagrams showing an example of positions (<figref idref="DRAWINGS">FIG. 26A</figref>) of the defective pixels of the image G after the addresses are converted, an object position (<figref idref="DRAWINGS">FIG. 26B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 26C</figref>).</p>
<p id="p-0114" num="0113">An output from the address conversion unit <b>301</b><i>a </i>is input to the detection level conversion unit <b>301</b><i>c</i>. The detection level conversion unit <b>301</b><i>c </i>converts the detection level of the pixel defect information of the image G. The photographing sensitivity as an example of the photographing condition and the luminosity information as an example of the weighting information are input to the detection level conversion unit <b>301</b><i>c</i>. Since the image photographed at another photographing sensitivity and a reference of the pixel defect detection need to be handled in common at the time of the synthesization of the pixel defect information, which will be described hereinafter, the detection level of the pixel defect information of the image G has to be converted into the photographing sensitivity of ISO100. Since the image G is photographed at the photographing sensitivity of ISO200, the detection level conversion unit <b>301</b><i>c </i>sets the detection level of the image G so as to be higher by one degree. Further, when the images are combined by raising the luminosity, since the output value as a defective pixel increases, it is necessary to raise the detection level by an amount corresponding to the increased luminosity. Since the luminosity (luminosity information) of the image G is set to 1 time, there is no change in detection level here. Therefore, the detection level conversion unit <b>301</b><i>c </i>converts the detection level of the image G so as to be higher by one degree by adding a conversion amount for the photographing sensitivity and a conversion amount for the luminosity. <figref idref="DRAWINGS">FIGS. 27A to 27C</figref> are diagrams showing an example of positions (<figref idref="DRAWINGS">FIG. 27A</figref>) of the defective pixels of the image G after the detection level is converted, an object position (<figref idref="DRAWINGS">FIG. 27B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 27C</figref>).</p>
<p id="p-0115" num="0114">After that, the pixel defect information synthesization unit <b>301</b><i>b </i>synthesizes the pixel defect information of the image F illustrated in <figref idref="DRAWINGS">FIG. 24C</figref> and the pixel defect information of the image G illustrated in <figref idref="DRAWINGS">FIG. 27C</figref>. The pixel in which the same (two) addresses are shown as pixel defect information is a pixel in which the defects double after the images are combined and it is shown that an output value as a defect is large. Therefore, with respect to such a pixel, the detection level of the pixel defect information is changed higher by one degree. In this case, since the pixel of the addresses (7, 9) is a pixel in which the defects whose detection levels are equal to 200 double, the detection level is changed to 100 which is higher by one degree.</p>
<p id="p-0116" num="0115"><figref idref="DRAWINGS">FIGS. 28A to 28C</figref> are diagrams illustrating pixel defect positions (<figref idref="DRAWINGS">FIG. 28A</figref>) of a combined image I formed as mentioned above, an object position (<figref idref="DRAWINGS">FIG. 28B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 28C</figref>). The selector <b>300</b><i>c </i>is connected to an a side and the pixel defect information of the combined image I illustrated in <figref idref="DRAWINGS">FIG. 28C</figref> is input to the pixel defect correction unit <b>300</b><i>e</i>. The selector <b>300</b><i>d </i>is connected to an a side and the data of the combined image I is input to the pixel defect correction unit <b>300</b><i>e</i>. In the pixel defect correction unit <b>300</b><i>e</i>, the defective pixels of the combined image I are corrected by using the pixel defect information in a manner similar to the processing of the pixel defect correction unit <b>200</b><i>e. </i></p>
<p id="p-0117" num="0116"><figref idref="DRAWINGS">FIGS. 29A to 29C</figref> are diagrams illustrating positions (<figref idref="DRAWINGS">FIG. 29A</figref>) of the defective pixels of the combined image I after the defective pixels are corrected, an object position (<figref idref="DRAWINGS">FIG. 29B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 29C</figref>). The selector <b>300</b><i>g </i>is connected to a b side and the data of the combined image I in which the defective pixels are corrected and the pixel defect information of the combined image I are stored into the RAM <b>108</b>.</p>
<p id="p-0118" num="0117">Subsequently, in step S<b>206</b>, the CPU <b>104</b> discriminates whether or not the combination of the set number of images is completed. If it is decided as a result of the discrimination that the combination of the set number of images is not completed, the processing routine is returned to step S<b>203</b> and the processings of steps S<b>203</b> and S<b>205</b> are executed. Since three images are combined here, the processing routine is returned to step S<b>203</b>.</p>
<p id="p-0119" num="0118">In step S<b>203</b>, the reading-out of the next image is started. First, the CPU <b>104</b> transfers the data of the combined image I and the data of the image H which are stored in the external recording medium <b>113</b> to the image processing unit <b>109</b>. As a data input A in <figref idref="DRAWINGS">FIG. 17</figref>, the data of the combined image I is input to the image processing unit <b>109</b> and, as a data input B, the data of the image H is input thereto.</p>
<p id="p-0120" num="0119">Subsequently, in step S<b>204</b>, the combined image I and the image H are combined. First, the CPU <b>104</b> transmits combination position information (the X address is changed, the Y address is changed)=(0, &#x2212;2) of the image H and luminosity information (luminosity change information) as an example of the weighting information to the image processing unit <b>109</b>. On the basis of the combination position information (0, &#x2212;2), the image combination unit <b>300</b><i>a </i>shifts the addresses of each pixel of the image H in the Y address direction by &#x2212;2. Since the image H is combined by doubling the luminosity thereof, the image combination unit <b>300</b><i>a </i>multiplies the luminosity of the image H by 2 times serving as luminosity information. The image combination unit <b>300</b><i>a </i>adds the image H in which the addresses of each pixel are shifted and which is multiplied by 2 times as a luminosity and the combined image I, and outputs a combined image J.</p>
<p id="p-0121" num="0120">After that, in step S<b>205</b>, the correction of the defective pixels of the combined image J is performed. First, the CPU <b>104</b> transfers the pixel defect information of the combined image I and the pixel defect information of the image H to the image processing unit <b>109</b>. The pixel defect information is input to the image processing unit <b>109</b> as pixel defect information inputs A and B illustrated in <figref idref="DRAWINGS">FIG. 18</figref>, respectively. The pixel defect information of the combined image I and the pixel defect information of the image H at this time are as illustrated in <figref idref="DRAWINGS">FIGS. 29C and 23C</figref>, respectively. Those pixel defect information and the photographing information of the photographing sensitivity (ISO400) at the time of photographing the image H are input to the uncorrected pixel detection units <b>301</b><i>d </i>and <b>301</b><i>e </i>illustrated in <figref idref="DRAWINGS">FIG. 18</figref>, respectively.</p>
<p id="p-0122" num="0121">The uncorrected pixel detection unit <b>301</b><i>d </i>deletes the information of the pixels which are corrected at the time of combination of the combined image I from the pixel defect information. When the combined image I is combined, since the detection level is discriminated by using the photographing sensitivity of ISO100 as a reference, the information of the pixels whose detection levels are equal to 100 are deleted from the pixel defect information. The uncorrected pixel detection unit <b>301</b><i>e </i>also deletes the information of the pixels whose addresses are out of the range of the image pickup element from the pixel defect information. <figref idref="DRAWINGS">FIGS. 30A to 30C</figref> are diagrams showing an example of positions (<figref idref="DRAWINGS">FIG. 30A</figref>) of the defective pixels of the image H in which the information of the pixels which are corrected at the time of photographing and the information of the pixels existing out of the range of the image pickup element are deleted, an object position (<figref idref="DRAWINGS">FIG. 30B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 30C</figref>). <figref idref="DRAWINGS">FIG. 31</figref> is a diagram showing an example of positions (<figref idref="DRAWINGS">FIG. 31A</figref>) of the defective pixels of the combined image I in which the information of the pixels which are corrected at the time of combination of the combined image I is deleted, an object position (<figref idref="DRAWINGS">FIG. 31B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 31C</figref>).</p>
<p id="p-0123" num="0122">After that, an output from the uncorrected pixel detection unit <b>301</b><i>e </i>and the combination position information are input to the address conversion unit <b>301</b><i>a </i>illustrated in <figref idref="DRAWINGS">FIG. 18</figref>. The address conversion unit <b>301</b><i>a </i>converts the addresses included in the pixel defect information of the image H. Since the combination position information at this time is equal to (0, &#x2212;2), the addresses included in the pixel defect information of the image H are shifted in the Y address direction by &#x2212;2. <figref idref="DRAWINGS">FIGS. 32A to 32C</figref> are diagrams showing an example of positions (<figref idref="DRAWINGS">FIG. 32A</figref>) of the defective pixels of the image H after the addresses are converted, an object position (<figref idref="DRAWINGS">FIG. 32B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 32C</figref>).</p>
<p id="p-0124" num="0123">The output from the address conversion unit <b>301</b><i>a </i>is input to the detection level conversion unit <b>301</b><i>c</i>. The detection level conversion unit <b>301</b><i>c </i>converts the detection level of the pixel defect information of the image H. The photographing sensitivity as an example of the photographing information and the luminosity information as an example of the weighting information are input to the detection level conversion unit <b>301</b><i>c</i>. Since the image photographed at another photographing sensitivity and the reference of the pixel defect detection need to be handled in common at the time of synthesizing the pixel defect information as mentioned above, it is necessary that the detection level of the pixel defect information of the image H is converted into the photographing sensitivity of ISO100. Since the image H is photographed at the photographing sensitivity of ISO400, the detection level of the image H is set to be higher by two degrees. Further, when the images are combined by raising the luminosity, since the output value as a defective pixel increases, it is necessary to raise the detection level by an amount corresponding to the increased luminosity. Since the luminosity (luminosity information) of the image H is set to 2 times, the detection level is set to be higher by one degree. Therefore, the detection level conversion unit <b>301</b><i>c </i>converts the detection level so as to be higher by three degrees by adding the conversion amount for the photographing sensitivity and the conversion amount for the luminosity. <figref idref="DRAWINGS">FIGS. 33A to 33C</figref> are diagrams showing an example of positions (<figref idref="DRAWINGS">FIG. 33A</figref>) of the defective pixels of the image H after the detection level is converted, an object position (<figref idref="DRAWINGS">FIG. 33B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 33C</figref>).</p>
<p id="p-0125" num="0124">After that, the pixel defect information synthesization unit <b>301</b><i>b </i>synthesizes the pixel defect information of the combined image I illustrated in <figref idref="DRAWINGS">FIG. 31C</figref> and the pixel defect information of the image H illustrated in <figref idref="DRAWINGS">FIG. 33C</figref>. As mentioned above, the pixel in which the same (two) addresses are shown as pixel defect information is a pixel in which the defects double after the images are combined and it is shown that an output value as a defect is large. Therefore, with respect to such a pixel, the detection level of the pixel defect information is changed higher by one degree. In the examples illustrated in <figref idref="DRAWINGS">FIGS. 31A to 31C</figref> and <figref idref="DRAWINGS">FIGS. 33A to 33C</figref>, since the pixel of the addresses (5, 4) is a pixel in which the defects whose detection levels are equal to 200 double, the detection level is changed to 100 which is higher by one degree.</p>
<p id="p-0126" num="0125"><figref idref="DRAWINGS">FIGS. 34A to 34C</figref> are diagrams illustrating positions (<figref idref="DRAWINGS">FIG. 34A</figref>) of the defective pixels of a combined image J formed as mentioned above, an object position (<figref idref="DRAWINGS">FIG. 34B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 34C</figref>). The selector <b>300</b><i>c </i>is connected to the a side and the pixel defect information of the combined image J illustrated in <figref idref="DRAWINGS">FIG. 34C</figref> is input to the pixel defect correction unit <b>300</b><i>e</i>. The selector <b>300</b><i>d </i>is connected to the a side and the data of the combined image J is input to the pixel defect correction unit <b>300</b><i>e</i>. In the pixel defect correction unit <b>300</b><i>e</i>, the defective pixels of the combined image J are corrected by using the pixel defect information in a manner similar to the processing of the pixel defect correction unit <b>200</b><i>e </i>described in the first embodiment.</p>
<p id="p-0127" num="0126"><figref idref="DRAWINGS">FIGS. 35A to 35C</figref> are diagrams illustrating positions (<figref idref="DRAWINGS">FIG. 35A</figref>) of the defective pixels of the combined image J after the defective pixels are corrected, an object position (<figref idref="DRAWINGS">FIG. 35B</figref>), and pixel defect information (<figref idref="DRAWINGS">FIG. 35C</figref>). Since the combination of the images is now completed, the selector <b>300</b><i>g </i>is connected to an a side, the data of the combined image J in which the defective pixels are corrected is compressed by the image compression unit <b>300</b><i>f</i>, and thereafter, stored into the RAM <b>108</b>.</p>
<p id="p-0128" num="0127">Thus, since it is determined in step S<b>206</b> that the combination of the set number of images is completed, in step S<b>207</b>, the CPU <b>104</b> allows the data of the combined image J stored in the RAM <b>108</b> to be recorded into the external recording medium <b>113</b>. The combination of the images is finished.</p>
<p id="p-0129" num="0128">As mentioned above, in the embodiment, the pixel defect information including the positions (addresses) of the defective pixels and the detection level is preliminarily stored in the image pickup apparatus <b>100</b>. In the case of combining the three images F, G, and H which are already recorded in the external recording medium, the addresses of each pixel of the images G and H are shifted so as to be matched with the image F on the basis of a designation by the user, and the luminosities of the images F, G, and H are changed. First, the addresses of each pixel of the image G in which the luminosity is changed are shifted so as to be matched with the image F, the combined image I of the images G and F is formed, and at the same time, the position (addresses) of the pixel defect information of the image G is changed. The detection level of the pixel defect information of the image G is changed in accordance with the photographing sensitivity and the luminosity of the image F. Pixel defect information of the combined image I is formed by synthesizing the pixel defect information of the image G in which the detection level and the position (addresses) are changed and the pixel defect information of the image F. At this time, the detection level of the pixel defect information of the pixels shown by the same addresses is raised. The defective pixels of the combined image I are corrected by using the pixel defect information. With respect to the combined image I and the image H, the same processings as those for the images F and G are executed, pixel defect information of the combined image J of the combined image I and the image H is formed, and the defective pixels of the combined image J are corrected. By executing the processings as mentioned above, when a plurality of images are combined by shifting the positions thereof, if the fine defects which are not corrected by the pixel defect correction of every image double, only the pixels whose output values serving as defects are large can be corrected correspondingly to the photographing condition and combination condition.</p>
<p id="p-0130" num="0129">Also in the embodiment, various modifications described in the first embodiment can be used.</p>
<p id="p-0131" num="0130">Although the exemplary embodiments of the invention are described above, the invention is not limited to those embodiments but various modifications and changes within the scope of the spirit of the invention are possible.</p>
<p id="p-0132" num="0131">The foregoing embodiments are nothing but the specific examples for embodying the invention and the technical scope of the invention should not be limitedly interpreted by them. That is, the invention can be embodied by various forms without departing from its technical idea or its main features.</p>
<heading id="h-0007" level="1">Other Embodiments</heading>
<p id="p-0133" num="0132">The invention is realized by executing the following processings. That is, first, software (computer program) for realizing the functions of the embodiments mentioned above is supplied to a system or an apparatus through a network or various kinds of storage media, and a computer (or a CPU, MPU, or the like) of the system or apparatus reads out the computer program and executes processings on the basis of the computer program.</p>
<p id="p-0134" num="0133">While the present invention is described with reference to exemplary embodiments, it is to be understood that the invention is not limited to the disclosed exemplary embodiments. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures and functions.</p>
<p id="p-0135" num="0134">This application claims the benefit of Japanese Patent Application No. 2011-146322 filed on Jun. 30, 2011, which is hereby incorporated by reference herein in its entirety.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image pickup apparatus comprising:
<claim-text>a combination unit configured to combine a plurality of photographed images by using an image pickup element;</claim-text>
<claim-text>a change unit configured to, in the case where pixel positions of defective pixels in each of the plurality of images which are to be combined by the combination unit coincide, change defect level information showing a level of a defect of the defective pixel in a combined image; and</claim-text>
<claim-text>a correction unit configured to, on the basis of the defect level information before it is changed by the change unit, correct the defective pixels in each of the plurality of images which are to be combined by the combination unit and, on the basis of the defect level information changed by the change unit, correct the defective pixels in the image combined by the combination unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pixel defect information includes information showing a position of the defective pixel in the image pickup element and information showing a size of a defect of the defective pixel,
<claim-text>wherein the change unit further changes information indicating a size of a defect of the defective pixel which is specified by the pixel defect information of each of the plurality of images which are to be combined by the combination unit, that is, the change unit further changes information indicating a size of a defect of one of the defective pixels which are both located at a same position, and information indicating a size of a defect of one of the defective pixels which are located at respective positions mutually adjacent to each other, and</claim-text>
<claim-text>wherein after the pixel defect information is changed by the change unit, on the basis of the pixel defect information, the correction unit corrects the defective pixels in the image combined by the combination unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. An apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the change unit changes the information indicating the size of the defect of the defective pixel included in the pixel defect information of the plurality of images which are to be combined by the combination unit in such a manner that the number of defective pixels which are corrected by the correction unit and which exist in a predetermined region is equal to or less than a predetermined number.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. An apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising a detection unit configured to detect the defect information of the plurality of images which are to be combined by the combination unit,
<claim-text>wherein on the basis of a photographing condition, the change unit changes information indicating a size of a defect of the defective pixel which is specified by the pixel defect information of each of the plurality of images which are to be combined by the combination unit, and is at least one of the defective pixels which are both located at a same position or are located at respective positions mutually adjacent to each other, such that the detection unit readily detects the defective pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. An apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the photographing condition includes a photographing sensitivity.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. An apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising a detection unit configured to detect the defect information of the plurality of images which are to be combined by the combination unit,
<claim-text>wherein on the basis of weighting information to a size of a pixel value of the image, the change unit changes information indicating a size of a defect of the defective pixel which is specified by the pixel defect information of each of the plurality of images which are to be combined by the combination unit, and is at least one of the defective pixels which are both located at a same position or are located at respective positions mutually adjacent to each other, such that the detection unit readily detects the defective pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the weighting information includes a luminosity.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising a detection unit configured to detect the defect information of the plurality of images which are to be combined by the combination unit,
<claim-text>wherein in accordance with a pixel value of a pixel surrounding the defective pixel, the change unit changes information indicating a size of a defect of the defective pixel which is specified by the pixel defect information of each of the plurality of images which are to be combined by the combination unit, and is at least one of the defective pixels which are both located at a same position, or are located at respective positions mutually adjacent to each other, such that the detection unit readily detects the defective pixel.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a detection unit configured to detect the defect information of the plurality of images which are to be combined by the combination unit,
<claim-text>wherein the pixel defect information includes information indicating a position of the defective pixel in the image pickup element, and</claim-text>
<claim-text>wherein the detection unit detects the defective pixel by using the information indicating the position of the defective pixel in the image pickup element included in the pixel defect information and a result of a comparison between a pixel value of the defective pixel and a detection threshold value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein after the pixel defect information is changed by the change unit, if at least one of information indicating positions of the defective pixels which are both located at a same position and information indicating positions of the defective pixels which are located at respective positions mutually adjacent to each other is included in the pixel defect information of each of the plurality of images which are to be combined by the combination unit, the detection unit changes the detection threshold value, such that the correction unit readily corrects the pixel value of the defective pixel.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein on the basis of a photographing condition, the detection unit changes the detection threshold value such that the correction unit readily corrects the pixel value of the defective pixel.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the photographing condition includes a photographing sensitivity.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. An apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein on the basis of weighting information to a size of a pixel value of the image, the detection unit changes the detection threshold value such that the correction unit readily corrects the pixel value of the defective pixel.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. An apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the weighting information includes a luminosity.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein in accordance with a pixel value of a pixel surrounding the defective pixel, the detection unit changes the detection threshold value such that the detection unit readily detects the defective pixel.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. An apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a forming unit configured to form combination position information including a change amount of a position of each pixel of each image at the time of combining a plurality of images in accordance with a result of a detection of a positional difference among the plurality of images or a result of an operation of an operation unit.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. An image combination method comprising:
<claim-text>a combination step of combining a plurality of photographed images by using an image pickup element;</claim-text>
<claim-text>a change step of, in the case where pixel positions of defective pixels in each of the plurality of images which are to be combined by the combination step coincide, changing defect level information showing a level of a defect of the defective pixel in a combined image; and</claim-text>
<claim-text>a correction step of, on the basis of the defect level information before it is changed by the change step, correcting the defective pixels in each of the plurality of images which are to be combined by the combination step and, on the basis of the defect level information changed by the change step, correcting the defective pixels in the image combined by the combination step.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A non-transitory computer-readable storage medium storing a computer program for allowing a computer to execute:
<claim-text>a combination step of combining a plurality of photographed images by using an image pickup element;</claim-text>
<claim-text>a change step of, in the case where pixel positions of defective pixels in each of the plurality of images which are to be combined by the combination step coincide, changing defect level information showing a level of a defect of the defective pixel in a combined image; and</claim-text>
<claim-text>a correction step of, on the basis of the defect level information before it is changed by the change step, correcting the defective pixels in each of the plurality of images which are to be combined by the combination step and, on the basis of the defect level information changed by the change step, correcting the defective pixels in the image combined by the combination step.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
