<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625467-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625467</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13028656</doc-number>
<date>20110216</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>322</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>12</main-group>
<subgroup>28</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>370256</main-classification>
</classification-national>
<invention-title id="d2e53">Rate-varying multicast transmission for clock distribution in packet networks</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>EP</country>
<doc-number>1610502</doc-number>
<kind>A1</kind>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>WO</country>
<doc-number>2001/019029</doc-number>
<kind>A1</kind>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>WO</country>
<doc-number>2009/105838</doc-number>
<kind>A1</kind>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00004">
<othercit>Ferrant, J., &#x201c;Report of the Edinburgh SG 15/13 Interim Meeting,&#x201d; Rapporteur Q13, Edinburgh, Jun. 8-12, 2009, 18 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00005">
<othercit>Foreign Communications From a Counterpart Application, European Application 11710916.5, European Office Action dated Jan. 10, 2013, 7 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00006">
<othercit>&#x201c;Draft Standard for a Precision Clock Synchronization Protocol for Networked Measurement and Control Systems,&#x201d; IEEE Standard P1588&#x2122; D2.2, 2007, 305 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00007">
<othercit>&#x201c;IEEE Standard for Local and Metropolitan Area Networks&#x2014;Virtual Bridged Local Area Networks&#x2014;Amendment 5: Connectivity Fault Management,&#x201d; IEEE Standard Std 802.1aq/D3.0&#x2122;, Jun. 10, 2010, 246 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00008">
<othercit>&#x201c;Series G: Transmission Systems and Media, Digital Systems and Networks Packet Over Transport Aspects&#x2014;Quality and Availability Targets,&#x201d; ITUT G.8265.1/ Y 1365.1, Oct. 2010, 30 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00009">
<othercit>Ferrant, J., et. al., &#x201c;ITU-T SG 15 Documents Pertaining to Synchronization on Q13/15,&#x201d; Apr. 20, 2010, 2 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00010">
<othercit>Wittmann, R., et. al., &#x201c;AMnet: Active Multicasting Network,&#x201d; IEEE International Conference in Atlanta, Georgia, vol. 2, Jun. 7, 1998, pp. 896-900.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>Foreign Communication From a Related Counterpart Application, PCT Application, PCT/US2011/025037, International Search Report, Jul. 6, 2011, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Foreign Communication From a Related Counterpart Application, PCT Application, PCT/US2011/025037, Written Opinion, Jul. 6, 2011, 10 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>16</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>370244</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370253</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370254</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370256</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370390</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61304983</doc-number>
<date>20100216</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110199941</doc-number>
<kind>A1</kind>
<date>20110818</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ouellette</last-name>
<first-name>Michel</first-name>
<address>
<city>Orleans</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ashwood-Smith</last-name>
<first-name>Peter</first-name>
<address>
<city>Gatineau</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Ouellette</last-name>
<first-name>Michel</first-name>
<address>
<city>Orleans</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Ashwood-Smith</last-name>
<first-name>Peter</first-name>
<address>
<city>Gatineau</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Conley Rose, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Rodolph</last-name>
<first-name>Grant</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="03" rep-type="attorney">
<addressbook>
<last-name>Chung</last-name>
<first-name>Rayhao</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Futurewei Technologies, Inc.</orgname>
<role>02</role>
<address>
<city>Plano</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Phan</last-name>
<first-name>Man</first-name>
<department>2475</department>
</primary-examiner>
<assistant-examiner>
<last-name>Mansoury</last-name>
<first-name>Nourali</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">In at least some embodiments, the disclosure includes an apparatus a root node in a packet based network that multicasts a plurality of packets. The apparatus also includes an intermediary node coupled to the root node and a plurality of leaf nodes coupled to the intermediary node. The root node, the intermediary node, and the plurality of leaf nodes are arranged in a tree topology. The packets are received at the intermediary node from the root node at a data rate equal to the data rate of the leaf node having the maximum data rate. The packets are multicast from the intermediary node to each of the plurality of leaf nodes at a plurality of different data rates such that each particular one of the plurality of leaf nodes receives the packets at a data rate corresponding to the data rate for the particular one of the plurality of leaf nodes.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="189.57mm" wi="248.24mm" file="US08625467-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="179.58mm" wi="160.02mm" orientation="landscape" file="US08625467-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="178.73mm" wi="164.17mm" orientation="landscape" file="US08625467-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="209.04mm" wi="161.71mm" orientation="landscape" file="US08625467-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="191.52mm" wi="163.91mm" orientation="landscape" file="US08625467-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="191.09mm" wi="162.73mm" orientation="landscape" file="US08625467-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="178.73mm" wi="161.97mm" orientation="landscape" file="US08625467-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="247.99mm" wi="191.60mm" orientation="landscape" file="US08625467-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="238.42mm" wi="169.84mm" orientation="landscape" file="US08625467-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="224.96mm" wi="168.57mm" file="US08625467-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="157.48mm" wi="142.66mm" file="US08625467-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="182.71mm" wi="140.72mm" file="US08625467-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present application claims the benefit of U.S. Provisional Patent Application No. 61/304,983 filed Feb. 16, 2010 by Michel Ouellette et al. and entitled &#x201c;Rate-Varying Multicast Transmission for Clock Distribution in Packet Networks,&#x201d; which is incorporated herein by reference as if reproduced in its entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT</heading>
<p id="p-0003" num="0002">Not applicable.</p>
<heading id="h-0003" level="1">REFERENCE TO A MICROFICHE APPENDIX</heading>
<p id="p-0004" num="0003">Not applicable.</p>
<heading id="h-0004" level="1">BACKGROUND</heading>
<p id="p-0005" num="0004">Modern communications and data networks are comprised of nodes that transport data through the network. The nodes may include routers, switches, bridges, or combinations thereof that transport the individual data packets or frames through the network. Some networks may offer data services that forward data frames or packets from one node to another node across the network without using pre-configured routes on intermediate nodes. Other networks may forward the data frames or packets from one node to another node across the network along pre-configured or pre-established paths. The packets forwarded in the network may be unicast packets that are transmitted to a plurality of nodes via a plurality of corresponding point-to-point (P2P) links. Alternatively, the packets forwarded in the network may be multicast packets that are transmitted to a plurality of nodes via a point-to-multipoint (P2MP) link or a tree.</p>
<heading id="h-0005" level="1">SUMMARY</heading>
<p id="p-0006" num="0005">In one embodiment, the disclosure includes an apparatus a root node in a packet based network that multicasts a plurality of packets. The apparatus also includes one or more intermediary nodes coupled to the root node and a plurality of leaf nodes coupled each of which is coupled to one of the intermediary nodes. The root node, the intermediary node, and the plurality of leaf nodes are arranged in a tree topology. The packets are received at the intermediary node from the root node at a data rate equal to the data rate of the leaf node having the maximum data rate. The packets are multicast from the intermediary node to each of the plurality of leaf nodes at a plurality of different data rates such that each particular one of the plurality of leaf nodes receives the packets at a data rate corresponding to the data rate for the particular one of the plurality of leaf nodes.</p>
<p id="p-0007" num="0006">In another embodiment, the disclosure includes a network component comprising a packet replication block coupled to an ingress link and configured to replicate a plurality of packets received on the ingress link at an upstream data rate. The network component also includes a plurality of packet discard blocks coupled to the packet replication block and to a plurality of egress links and configured to pass through or reduce some of the received packets to match a plurality of downstream data rates associated with the egress links.</p>
<p id="p-0008" num="0007">In a third aspect, the disclosure includes a method. The method comprises receiving a plurality of advertised downstream data rates via a plurality of egress links from a plurality of downstream nodes. The method also comprises assigning an upstream data rate that corresponds to a maximum of the received downstream data rates to an ingress link. The method further comprises advertising the upstream data rate via the ingress link to an upstream node.</p>
<p id="p-0009" num="0008">These and other features will be more clearly understood from the following detailed description taken in conjunction with the accompanying drawings and claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0010" num="0009">For a more complete understanding of this disclosure, reference is now made to the following brief description, taken in connection with the accompanying drawings and detailed description, wherein like reference numerals represent like parts.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram of an embodiment of a packet multicast scheme.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic diagram of an embodiment of a packet unicast scheme.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic diagram of an embodiment of a clock distribution scheme.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic diagram of an embodiment of a multicast clock distribution scheme.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic diagram of an embodiment of a unicast clock distribution scheme.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 6</figref> is a schematic diagram of an embodiment of a rate-varying multicast scheme.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 7</figref> is a schematic diagram of another embodiment of a rate-varying multicast clock distribution scheme.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 8</figref> is a schematic diagram of an embodiment of a multicast forwarding and discarding scheme.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of an embodiment of a rate-varying multicast method.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 10</figref> is a schematic diagram of an embodiment of a transmitter/receiver unit.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 11</figref> is a schematic diagram of an embodiment of a general-purpose computer system.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0007" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0022" num="0021">It should be understood at the outset that although an illustrative implementation of one or more embodiments are provided below, the disclosed systems and/or methods may be implemented using any number of techniques, whether currently known or in existence. The disclosure should in no way be limited to the illustrative implementations, drawings, and techniques illustrated below, including the exemplary designs and implementations illustrated and described herein, but may be modified within the scope of the appended claims along with their full scope of equivalents.</p>
<p id="p-0023" num="0022">Disclosed herein is a system and method for providing rate-varying multicast transmissions for clock distribution in packet based networks. The rate-varying multicast transmissions may be provided from a multicast source to a plurality of multicast receivers. The receivers may receive similar multicast transmissions in the form of multicast packets from the source at different rates. The multicast packets may be used to synchronize the frequency and/or time of the clocks at the receivers, e.g., with the source's clock. The multicast packets may be delivered to the receivers at different rates that may match the different clock rates of the receivers, e.g., according to the different link bandwidths and/or processing capabilities of the receivers.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a typical packet multicast scheme <b>100</b> that may be used to transmit packets in packet based networks. The packet multicast scheme <b>100</b> may be implemented between a source or root node <b>110</b> and a plurality of leaf nodes <b>120</b> that may be all coupled to a packet based network <b>130</b>. For instance, the packet based network <b>130</b> may be an Ethernet network, an Internet Protocol (IP) network, a Multi-Protocol Label Switching (MPLS) network, or any other packet switched network (PSN).</p>
<p id="p-0025" num="0024">The root node <b>110</b> and similarly the leaf nodes <b>120</b> may be any nodes, devices, or components configured to receive, transmit, and/or forward packets associated with the packet based network <b>130</b>. Specifically, in the packet multicast scheme <b>100</b>, the root node <b>110</b> may be a transmitter of a plurality of packets and the leaf nodes <b>120</b> may be the receivers of the packets. The same or similar packets may be duplicated and sent to every leaf node <b>120</b> via a plurality of links in a tree topology, e.g., a P2MP link. For instance, the packets may be distributed to the leaf nodes <b>120</b> via a multicast tree distribution tree topology, such as an Ethernet tree (E-Tree) service. In an embodiment, the tree topology may be generated as described in the Institute of Electrical and Electronics Engineers (IEEE) standard 802.1aq which is incorporated herein by reference.</p>
<p id="p-0026" num="0025">The tree or P2MP link may comprise a plurality of links or paths, e.g., in the packet based network <b>130</b>, that may couple each leaf node <b>120</b> to the root node <b>110</b>. The links or paths may be coupled to a plurality of internal nodes (not shown) in the packet based network <b>130</b>. The internal nodes may receive and replicate the packets, when necessary, before forwarding the packets towards the leaf nodes <b>120</b>. Typically, the packets may be transmitted from the root node <b>110</b> over the P2MP link and received by the leaf nodes <b>120</b> at about the same data rate. This is indicated by the same solid line arrow type for each of the leaf nodes <b>120</b>. The packets arriving and replicated at the internal nodes may also have about the same data rates as the root node <b>110</b> and the leaf nodes <b>120</b>. The packet multicast scheme <b>100</b> may efficiently use network bandwidth by having the internal nodes replicate the packets that are sent from the root node to the leaf, e.g., in comparison to packet unicast schemes where the root node must itself replicate the packet (for each leaf) before it can be sent to the internal nodes to reach the leaf nodes. Multicast decreases the processing and traffic of the root node while minimizing the number of packets to be forwarded by the intermediate nodes.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a typical packet unicast scheme <b>200</b> that may be used to transmit packets in packet based networks. The packet unicast scheme <b>200</b> may be implemented between a source or root node <b>210</b> and a plurality of leaf nodes <b>220</b> that may be all coupled to a packet based network. The packet based network <b>230</b>, the root node <b>210</b>, and the leaf nodes <b>220</b> may be similar to the packet based network <b>130</b>, the root node <b>110</b>, and the leaf nodes <b>120</b>, respectively.</p>
<p id="p-0028" num="0027">However, the root node <b>210</b> may transmit a plurality of similar or different packets to the leaf nodes <b>220</b>. The packets may be forwarded by the intermediate nodes (not shown) to the leaf nodes <b>220</b> via a plurality of corresponding links, e.g., a P2P links. Each link associated between the root node and a leaf node <b>220</b> may be established separately or independent of the other links for the other leaf nodes <b>220</b>. Each P2P link may transport similar or different packets from the other links at similar or different rates. This is indicated by the different solid and dotted line arrow types for the leaf nodes <b>220</b>. The links may be coupled to a plurality of internal nodes (not shown) in the packet based network <b>230</b>. The internal nodes may receive and forward the packets, e.g., without duplication, towards the leaf nodes <b>220</b>.</p>
<p id="p-0029" num="0028">The packet unicast scheme <b>200</b> may use higher data rates and may have reduced network bandwidth utilization than the packet multicast scheme <b>100</b>. For instance, the total transported data rates in the packet multicast scheme <b>100</b> may be about equal to the received data rates at each of the leaf nodes <b>120</b>, while the total transported data rates in the packet unicast scheme <b>200</b> may be about equal to the sum of the received data rates at all the leaf nodes <b>220</b>. Thus, the packet multicast scheme <b>100</b> may be less demanding than the packet unicast scheme <b>200</b> in terms of data processing, bandwidth consumption, and/or the amount of transported traffic.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a clock distribution scheme <b>300</b> that may be used to synchronize or align the clock/timing between a master clock and a plurality of slave clocks. The clock distribution scheme <b>300</b> may be implemented between a source or root node <b>310</b> and a plurality of leaf nodes <b>320</b> that may be all coupled to a packet based network. The packet based network <b>330</b>, the root node <b>310</b>, and the leaf nodes <b>320</b> may be configured substantially similar to the packet based network <b>130</b>, the root node <b>110</b>, and the leaf nodes <b>120</b>, respectively.</p>
<p id="p-0031" num="0030">Specifically, the root node <b>310</b> may comprise or may be coupled to the master clock (not shown) and the leaf nodes <b>320</b> may comprise or may be coupled to a plurality of corresponding slave clocks (not shown). The master and slave may be used to control the transmissions and/or processing times of the source node <b>310</b> and the leaf nodes <b>320</b>. The clock distribution scheme <b>300</b> may be used to synchronize the frequency and/or time of the slave clocks with the master clock, e.g., to synchronize the communications between the root node <b>310</b> and the leaf nodes <b>320</b>. The frequency/time at the individual slave clocks may be aligned with the frequency/time of the master clock using a plurality of timestamps or synchronization information that may be sent in a plurality of transmitted packets between the root node <b>310</b> and the leaf nodes <b>320</b>. The same timestamps or synchronization information may be transmitted from the root node <b>310</b> to each of the leaf nodes <b>320</b>.</p>
<p id="p-0032" num="0031">The synchronization information may be sent from the root node <b>310</b> to the leaf nodes <b>320</b> in a unidirectional manner, e.g., downstream only. Alternatively, the root node <b>310</b> and the leaf nodes <b>320</b> may exchange synchronization information in a bidirectional manner, e.g., both downstream and upstream. Examples of unidirectional and bidirectional frequency/time distribution schemes are described in IEEE 1588, which is incorporated herein by reference. Further, each leaf node <b>320</b> may be configured to receive the synchronization information at a corresponding slave clock rate. The rates at the leaf nodes <b>320</b> may vary depending on different network conditions, such as microwave links versus fiber links, different adaptive clock recovery implementations, different packet delay variation tolerance, and/or different oscillatory quality.</p>
<p id="p-0033" num="0032">For instance, the root node <b>310</b> may be configured to transmit frequency and/or time information in a plurality of packets at a master clock rate, r<sub>m</sub>, in a unidirectional scheme, bidirectional scheme, or both. The packets may comprise the same time and frequency information. A first leaf node <b>320</b> from the leaf nodes <b>320</b> may be configured to receive frequency information in the packets at a first slave rate, r<sub>s1</sub>, in a unidirectional scheme. A second leaf node <b>320</b> may also be configured to receive frequency information in the packets at a second slave rate, r<sub>s2</sub>, and exchange frequency information with the root node <b>310</b> in a bidirectional scheme. A third leaf node <b>320</b> may also be configured to receive time information in the packets at a third slave rate, r<sub>s3</sub>, and exchange time information with the root node <b>310</b> in a bidirectional scheme. The packets transmitted at different rates to the leaf nodes <b>320</b> are shown using different patterns in <figref idref="DRAWINGS">FIG. 3</figref>. The unidirectional scheme is shown using a single solid line arrow and the bidirectional schemes are shown using two opposite solid line arrows.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 4</figref> illustrates an embodiment of a multicast clock distribution scheme <b>400</b> that may implement a clock (e.g., time/frequency) distribution scheme using a packet multicast scheme. For instance, the multicast clock distribution scheme <b>400</b> may implement the clock distribution scheme <b>300</b> using the packet multicast scheme <b>100</b>. The multicast clock distribution scheme <b>400</b> may be implemented between a source or root node <b>410</b> and a plurality of leaf nodes <b>420</b> that may be all coupled to a packet based network <b>430</b>. The packet based network <b>430</b> may also comprise a plurality of internal nodes <b>432</b>. The packet based network <b>430</b>, the root node <b>410</b>, and the leaf nodes <b>420</b> may be configured substantially similar to the packet based network <b>130</b>, the root node <b>110</b>, and the leaf nodes <b>120</b>, respectively. The internal nodes <b>432</b> may be any nodes, devices, or components configured to receive, transmit, and/or forward packets in the packet based network <b>430</b>.</p>
<p id="p-0035" num="0034">The root node <b>410</b> may transmit frequency and/or time information in a plurality of packets at a master clock rate, r<sub>m</sub>, to the leaf nodes <b>420</b>, e.g., in a unidirectional and/or bidirectional scheme. The packets may be received, duplicated, and forwarded to the leaf nodes <b>420</b> by the internal nodes <b>432</b> at about the same data rates. For instance, a first internal node <b>432</b> (n<b>1</b>) may receive the packets from the root node <b>410</b>, duplicate the packets, forward a first copy of the packets to a second internal node <b>432</b> (n<b>2</b>) via first link at a first data rate (rd<sub>11</sub>), and forward a second copy of the packets to a third internal node <b>432</b> (n<b>3</b>) via a second link at a second data rate (rd<sub>12</sub>). The second internal node <b>432</b> may receive the packets from the first internal node <b>432</b>, duplicate the packets, forward a first copy of the packets to a first leaf node <b>420</b> via third link at a third data rate (rd<sub>21</sub>), and forward a second copy of the packets to a second leaf node <b>420</b> via a fourth link at a fourth data rate (rd<sub>22</sub>). Similarly, the third internal node <b>432</b> may receive packets from the first internal node <b>432</b> and forward the packets to a third leaf node <b>420</b> via a fifth link at a fifth data rate (rd<sub>31</sub>).</p>
<p id="p-0036" num="0035">Using this packet multicast scheme, the data rates of the internal nodes <b>432</b> and the corresponding links may be substantially equal, which may improve bandwidth consumption in the packet based network <b>430</b>. As such, rd<sub>11</sub>, rd<sub>12</sub>, rd<sub>21</sub>, rd<sub>22</sub>, and rd<sub>23 </sub>may all be about equal to r<sub>m</sub>. For example, each of the data rates may be equal to about 20 messages per second. The same packets transmitted at about the same rates are shown using the same pattern in <figref idref="DRAWINGS">FIG. 4</figref>. However, the received data rates at the leaf nodes <b>420</b> may not efficiently meet the different data rate requirements of the leaf nodes <b>420</b>. For instance, the first leaf node <b>420</b>, the second leaf node <b>420</b>, and the third leaf node <b>420</b> may have a first slave rate, r<sub>s1</sub>, a second slave rate, r<sub>s2</sub>, and a third slave rate, r<sub>s3</sub>, respectively, which may be different based on different network conditions. The three leaf nodes <b>420</b> may receive about the same data rates from the packet based network <b>430</b>, which may be greater than or smaller than the individual corresponding slave rates.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an embodiment of a unicast clock distribution scheme <b>500</b> that may implement a clock (e.g., time/frequency) distribution scheme using a packet unicast scheme. For instance, the multicast clock distribution scheme <b>500</b> may implement the clock distribution scheme <b>300</b> using the packet unicast scheme <b>200</b>. The unicast clock distribution scheme <b>500</b> may be implemented between a source or root node <b>510</b> and a plurality of leaf nodes <b>520</b> that may be all coupled to a packet based network <b>530</b>. The packet based network <b>530</b> may also comprise a plurality of internal nodes <b>532</b>. The packet based network <b>530</b>, the root node <b>510</b>, and the leaf nodes <b>520</b> may be configured substantially similar to the packet based network <b>230</b>, the root node <b>210</b>, and the leaf nodes <b>220</b>, respectively. The internal nodes <b>532</b> may be any nodes, devices, or components configured to receive, transmit, and/or forward packets in the packet based network <b>530</b>.</p>
<p id="p-0038" num="0037">The root node <b>510</b> may transmit frequency and/or time information in a plurality of packets at a master clock rate, r<sub>m</sub>, to the leaf nodes <b>520</b>, e.g., in a unidirectional and/or bidirectional scheme. Unlike the multicast clock distribution scheme <b>400</b>, the root node <b>510</b> may meet the different data rate requirements of the slave clocks at the leaf nodes <b>420</b> by transmitting different sets of packets at the different data rates of the leaf node <b>520</b> (indicated by different patterns in <figref idref="DRAWINGS">FIG. 5</figref>). Specifically, the total transmitted data rate from the source node <b>510</b> may be about equal to the sum of all the slave rates, e.g., r<sub>m</sub>=&#x3a3;r<sub>si</sub>, where i is the quantity of leaf nodes <b>520</b>. The packets may be received and forwarded properly to the designated leaf nodes <b>520</b> by the internal nodes <b>532</b>. The internal nodes <b>532</b> may forward the packets on a plurality of links at corresponding data rates rd<sub>ij</sub>, where i indicates the internal node <b>532</b> and j indicates one of its links. The link data rates rd<sub>ij </sub>may be equal to about the sums of all the slave rates forwarded on the link.</p>
<p id="p-0039" num="0038">For instance, in the case of three leaf nodes <b>520</b>, the total transmitted data rates from the source node <b>510</b> may be r<sub>m</sub>=r<sub>s1</sub>+r<sub>s2</sub>+r<sub>s3</sub>, where r<sub>s1</sub>, r<sub>s2</sub>, and r<sub>s3</sub>, are the slave rates of the three leaf nodes <b>520</b>. For example, if r<sub>s1 </sub>and similarly r<sub>s2 </sub>are equal to about 10 messages per second and r<sub>s3 </sub>is equal to about 20 messages per second, then r<sub>m </sub>may be equal to about 40 messages per second. Specifically, a first internal node <b>532</b> (n<b>1</b>) may receive all the packets at the total data rate r<sub>m </sub>from the root node <b>410</b>. The first internal node <b>532</b> may then forward the packets designated for a first leaf node <b>520</b> and a second leaf node <b>520</b> on a first link to a second internal node <b>532</b> (n<b>2</b>) at a first data rate (rd<sub>11</sub>), and forward the packets designated for a third leaf node <b>520</b> on a second link to a third internal node <b>532</b> (n<b>3</b>) at a second data rate (rd<sub>12</sub>). The first data rate may be equal to about the sum of the first slave rate for the first leaf node <b>520</b> and the second slave rate for the second leaf node <b>520</b>, e.g., rd<sub>11</sub>=r<sub>s1</sub>+r<sub>s2</sub>. For example, if r<sub>s1 </sub>and similarly r<sub>s2 </sub>are equal to about 10 messages per second and r<sub>s3 </sub>is equal to about 20 messages per second, then rd<sub>11 </sub>may be equal to about 20 messages per second and rd<sub>12 </sub>may be equal to about 20 messages per second. The second data rate may be about equal to the third slave rate of the third leaf node <b>520</b>, e.g., rd<sub>12</sub>=r<sub>s3</sub>.</p>
<p id="p-0040" num="0039">The second internal node <b>532</b> may forward the packets designated for the first leaf node <b>520</b> on a third link at a third data rate (rd<sub>21</sub>), and forward the packets designated for the second leaf node <b>520</b> on a fourth link at a fourth data rate (rd<sub>22</sub>). The third data rate may be about equal to the first slave rate of the first leaf node <b>520</b>, e.g., rd<sub>21</sub>=r<sub>s1</sub>, and the fourth data rate may be about equal to the second slave rate of the second leaf node <b>520</b>, e.g., rd<sub>22</sub>=r<sub>s2</sub>. Similarly, the third internal node <b>532</b> may forward the packets designated for the third leaf node <b>520</b> on a fifth link at a fifth data rate (rd<sub>31</sub>). The fifth data rate may be about equal to the third slave rate of the third leaf node <b>520</b>, e.g., rd<sub>31</sub>=r<sub>s3</sub>.</p>
<p id="p-0041" num="0040">Using this packet unicast scheme, the data rates of the individual leaf nodes <b>520</b> may be met, where each leaf node <b>520</b> may receive its designated packets at about its corresponding slave rate. However, this may require transmitting the packets in the packet based network <b>530</b> at all the data rates of the leaf nodes <b>520</b>. This may increase traffic and require more traffic engineering and/or network capacity planning, e.g., in comparison to the packet multicast scheme above, and may also require additional configurations at the master and slave nodes. The total amount of high-priority network bandwidth that may be generated using this scheme may be substantially large, such as in the case of femtocell mobile backhaul, where a large number of slave clocks (e.g., about multiple tens of thousands) may be coupled to a single master clock. Additionally, this packet unicast scheme may not be suitable or compatible with some network protocols that may be designed for packet multicast schemes, such as IEEE 1588 protocol, which is incorporated herein by reference.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an embodiment of a rate-varying multicast scheme <b>600</b> that may be used to transmit packets in packet based networks. The rate-varying multicast scheme <b>600</b> may be implemented between a source or root node <b>610</b> and a plurality of leaf nodes <b>620</b> that may be all coupled to a packet based network <b>630</b>. The packet based network <b>630</b>, the root node <b>610</b>, and the leaf nodes <b>620</b> may be configured substantially similar to the packet based network <b>130</b>, the root node <b>110</b>, and the leaf nodes <b>120</b>, respectively. The rate-varying multicast scheme <b>600</b> may efficiently use network bandwidth utilization, e.g., by using reduced data rates in comparison to packet unicast schemes, and may also meet different data rate requirements of the leaf nodes <b>420</b> unlike typical packet multicast schemes.</p>
<p id="p-0043" num="0042">The root node <b>610</b> may transmit a plurality of packets at an initial data rate that may be about equal to the highest data rate of the leaf nodes <b>620</b>. A plurality of internal nodes (not shown) in the packet based network <b>630</b> may receive, replicate, and forward the same or similar packets downstream at the same or reduced rate to meet the different data rates at the leaf nodes <b>620</b>. The data rates of the leaf nodes <b>620</b> may be advertized to the upstream internal nodes, which may in turn advertize all the data rates to the root node <b>610</b>, as described in detail below. Each internal node may receive a data rate that may be equal to a maximum data rate advertized by the next hops or internal nodes on all the egress links. Each internal node may then forward the same data rate or a reduce data rate on each egress link as advertized by the next hop, until finally each leaf node <b>620</b> receives the packets at the leaf node's advertized data rate. Thus, each sub-link in the tree (or P2MP link) may transport the same or similar packets as the other sub-links at similar or different rates. This is indicated by the different solid, dashed, and dotted line arrow types for the leaf nodes <b>620</b>.</p>
<p id="p-0044" num="0043">The rate-varying multicast scheme <b>600</b> may be suitable for network applications where members of the multicast network may require the same information but at different rates, which may be difficult to achieve using a typical packet multicast scheme, such as the packet multicast scheme <b>100</b>. Instead, the rate-varying multicast scheme <b>600</b> may support multicast traffic for varying-rate receivers. For example, using the rate-varying multicast scheme <b>600</b>, a video source or root node may transmit relatively high rate video content to a set of high rate or capacity receivers and lower rate video content to another set of low rate or capacity receivers. Another example where the rate-varying multicast scheme <b>600</b> may be used is in mobile backhaul, where wireless base stations that comprise slave clocks may be coupled to a packet based network and may receive timing reference signals from a master clock in the network.</p>
<p id="p-0045" num="0044">Typically, the rate of the synchronization information (r<sub>si</sub>) that a slave or leaf node may require to meet performance metrics (e.g., network wander limits, fractional frequency offsets, etc.) may be related to the packet network characteristics and the corresponding slave clock design. The rate may be a function of various packet network impairments (e.g., latency, delay variation, medium type, etc.), the packet selection and filtering algorithm, and/or the oscillator used in the slave node. For instance, the rate of synchronization information required at a slave node may be higher in the case of microwave environments compared to optical fiber environments. The rate of synchronization information may also be dependent on the slave node's operational state. For instance, the rate required may be higher during warm-up phase compared to steady-state phase. This may also be the case for periods after network rearrangements. Warm-up periods may last for several minutes/hours, while rearrangements may last for several seconds. In such scenarios, the rate-varying multicast scheme <b>600</b> may be used to support multicast addressing and provide independent rates of information from master-to-slave. Such system may emulate some of the characteristics of unicast systems but also offer advantages of multicast systems.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an embodiment of a rate-varying multicast clock distribution scheme <b>700</b> that may be implemented using the rate-varying multicast scheme <b>600</b>. The rate-varying multicast clock distribution scheme <b>700</b> may be implemented between a source or root node <b>710</b> and a plurality of leaf nodes <b>720</b> that may be all coupled to a packet based network <b>730</b>. The packet based network <b>730</b> may also comprise a plurality of internal nodes <b>732</b>. The packet based network <b>730</b>, the root node <b>710</b>, and the leaf nodes <b>720</b> may be configured substantially similar to the packet based network <b>130</b>, the root node <b>110</b>, and the leaf nodes <b>120</b>, respectively. The internal nodes <b>732</b> may be any nodes, devices, or components configured to receive, transmit, and/or forward packets in the packet based network <b>730</b>.</p>
<p id="p-0047" num="0046">Upon establishing the tree topology (or P2MP link) between the root node <b>710</b> and the leaf nodes <b>720</b>, e.g., using a multicast protocol such as IEEE 802.1ag, the leaf nodes <b>720</b> may advertize their slave rates, r<sub>si</sub>, to the packet based network <b>730</b> and the root node <b>710</b>. Each leaf node <b>720</b> may advertize its slave rate to a next upstream internal node <b>732</b> (n<sub>i</sub>) that may be directly coupled to the leaf node <b>720</b> via a downstream link. The internal node <b>732</b> may collect all received data rates on the downstream links, rd<sub>ij</sub>, and maintain the data rates in a table. The rates may be expressed in powers of two, e.g., to reduce the size of advertized traffic. For example, the advertized rates may vary from about 1/64 messages per second to about 256 messages per second. The internal node <b>732</b> may then determine the maximum received data rate, ru<sub>ij</sub>, and advertize the maximum data rate to a next upstream internal node <b>732</b>. This process may be repeated until the root node <b>710</b> collects all received advertised data rates from the downstream links, maintain the data rates in a table, and determine the maximum data rate, r<sub>m</sub>, for all the data rates of the leaf nodes <b>720</b>.</p>
<p id="p-0048" num="0047">For instance, a first leaf node <b>720</b> may advertise a first slave rate r<sub>s1</sub>=r to a first upstream internal node <b>732</b> (n<b>2</b>) that may be directly coupled to the first leaf node <b>720</b>. Similarly, both a second leaf node <b>720</b> and a third leaf node <b>720</b> that may be directly coupled to the same first upstream internal node <b>732</b> (n<b>2</b>) may advertise a second slave rate r<sub>s2</sub>=r/2 and a third slave rate r<sub>s3</sub>=r/4, respectively, to the first upstream internal node <b>732</b> (n<b>2</b>). The slave rates r<sub>s1</sub>, r<sub>s2</sub>, and r<sub>s3 </sub>may be sent via a first downstream link, a second downstream link, and a third downstream link, respectively, of the first upstream internal node <b>732</b> (n<b>2</b>). The first upstream internal node <b>732</b> (n<b>2</b>) may collect the received slave rates and assign each slave rate to the corresponding downstream link in a corresponding table <b>791</b>, e.g., in a downstream rates column. For example, a first downstream data rate rd<sub>21 </sub>may be set to r<sub>s1 </sub>or r, a second downstream data rate rd<sub>22 </sub>may be set to r<sub>s2 </sub>or r/2, and a third downstream data rate rd<sub>23 </sub>may be set to r<sub>s3 </sub>or r/4. The first upstream internal node <b>732</b> (n<b>2</b>) may then determine the maximum downstream data rate and assign the maximum downstream data rate to a corresponding upstream link in the corresponding table <b>791</b>, e.g., in an upstream rate column. For example, the upstream data rate ru<sub>21 </sub>may be set to max{rd<sub>21</sub>, rd<sub>22</sub>, rd<sub>23</sub>}=r. The table <b>791</b> may be stored at the first upstream internal node <b>732</b> (n<b>2</b>) or at the packet based network <b>730</b> and may also comprise a node identifier (ID) of the first upstream internal node <b>732</b>, e.g., n<b>2</b>.</p>
<p id="p-0049" num="0048">Additionally, both a fourth leaf node <b>720</b> and a fifth leaf node <b>720</b> that may be directly coupled to a same second upstream internal node <b>732</b> (n<b>3</b>) may advertise a fourth slave rate r<sub>s4</sub>=r/4 and a fifth slave rate r<sub>s5</sub>=r/2, respectively, to the second upstream internal node <b>732</b> (n<b>3</b>). The slave rates r<sub>s4 </sub>and r<sub>s4 </sub>may be sent via a first downstream link and a second downstream link, respectively, of the second upstream internal node <b>732</b> (n<b>3</b>). The second upstream internal node <b>732</b> (n<b>3</b>) may collect the received slave rates and assign each slave rate to the corresponding downstream link in a corresponding table <b>792</b>, e.g., in a downstream rates column. For example, a first downstream data rate rd<sub>31 </sub>may be set to r<sub>s4 </sub>or r/4, and a second downstream data rate rd<sub>32 </sub>may be set to r<sub>s5 </sub>or r/2. The second upstream internal node <b>732</b> (n<b>3</b>) may then determine the maximum downstream data rate and assign the maximum downstream data rate to a corresponding upstream link in the corresponding table <b>792</b>, e.g., in an upstream rate column. For example, the upstream data rate ru<sub>31 </sub>may be set to max{rd<sub>31</sub>, rd<sub>32</sub>}=r/2. The table <b>792</b> may be stored at the second upstream internal node <b>732</b> (n<b>3</b>) or at the packet based network <b>730</b> and may also comprise a node ID of the second upstream internal node <b>732</b>, e.g., n<b>3</b>.</p>
<p id="p-0050" num="0049">The first upstream internal node <b>732</b> may advertise its upstream data rate ru<sub>21</sub>=r to a third upstream internal node <b>732</b> (n<b>1</b>) that may be directly coupled to the first upstream internal node <b>732</b> (n<b>2</b>). Similarly, the second upstream internal node <b>732</b> (n<b>3</b>), that may also be directly coupled to the third upstream internal node <b>732</b> (n<b>1</b>), may advertise its upstream data rate ru<sub>31</sub>=r/2 to the third upstream internal node <b>732</b> (n<b>1</b>). The upstream data rates ru<sub>21 </sub>and ru<sub>31 </sub>may be sent via a first downstream link and a second downstream link of the third upstream internal node <b>732</b> (n<b>1</b>). The third upstream internal node <b>732</b> (n<b>1</b>) may collect the received data rates and assign each data rate to the corresponding downstream link in a corresponding table <b>793</b>, e.g., in a downstream rates column. For example, a first downstream data rate rd<sub>11 </sub>may be set to ru<sub>21 </sub>or r, and a second downstream data rate rd<sub>12 </sub>may be set to ru<sub>31 </sub>or r/2. The third upstream internal node <b>732</b> (n<b>1</b>) may then determine the maximum downstream data rate and assign the maximum downstream data rate to a corresponding upstream link in the corresponding table <b>793</b>, e.g., in an upstream rate column. For example, the upstream data rate ru<sub>11 </sub>may be set to max{rd<sub>11</sub>, rd<sub>12</sub>}=r. The table <b>793</b> may be stored at the third upstream internal node <b>732</b> (n<b>1</b>) or at the packet based network <b>730</b> and may also comprise a node ID of the third upstream internal node <b>732</b>, e.g., n<b>1</b>.</p>
<p id="p-0051" num="0050">The third upstream internal node <b>732</b> (n<b>1</b>) may then advertise its upstream data rate ru<sub>11</sub>=r to the root node <b>710</b> that may be directly coupled to the third upstream internal node <b>732</b> (n<b>1</b>). The upstream data rate ru<sub>11 </sub>may be sent via a downstream link of the root node <b>710</b>, which may set its master rate, to the received data rate in a corresponding table <b>794</b>, e.g., in a downstream rates column. For example, the master rate r<sub>m </sub>may be set to ru<sub>11 </sub>or r. The master rate may also correspond to the maximum data rate of the slave rates of the leaf nodes <b>720</b>. The table <b>794</b> may be stored at the root node <b>710</b> or at the packet based network <b>730</b> and may also comprise a node ID of the root node <b>710</b> that indicates a master or source node.</p>
<p id="p-0052" num="0051">After determining the master rate or maximum data rate of the slave rates, the root node <b>710</b> may transmit at the master rate a plurality of packets, which may comprise frequency/time synchronization information, to the leaf nodes <b>720</b> via the internal nodes <b>732</b>. Each internal node <b>732</b> may in turn receive the packets on an upstream link at a rate that matches the upstream data rate in the corresponding table, and forward a copy of the packets on each downstream link at the corresponding downstream data rate in the table. The internal nodes <b>732</b> may reduce the upstream data rate to match the downstream data rates if necessary, e.g., by dropping some of the packets in a proper order. For example, the internal nodes <b>732</b> may discard every one out of ru<sub>ij</sub>/rd<sub>ij </sub>messages and transmit the remaining messages. As such, each leaf node <b>720</b> may subsequently receive on its upstream link from a corresponding internal node <b>732</b> a copy of the packets at about the slave rate of the corresponding leaf node <b>720</b>.</p>
<p id="p-0053" num="0052">For instance, the root node <b>710</b> may transmit the packets at the master rate r<sub>m </sub>to a first downstream internal node <b>732</b> (n<b>1</b>). The first downstream internal node <b>732</b> (n<b>1</b>) may receive the packets at a rate that matches its upstream data rate ru<sub>11 </sub>in Table <b>793</b>. The first downstream internal node <b>732</b> (n<b>1</b>) may then transmit the packets at an about equal first downstream data rate rd<sub>11 </sub>to a second downstream internal node <b>732</b> (n<b>2</b>) and at a reduced second downstream data rate rd<sub>12 </sub>to a third downstream internal node <b>732</b> (n<b>3</b>), as indicated in Table <b>793</b>. The second downstream internal node <b>732</b> (n<b>2</b>) may receive the packets at a rate that matches its upstream data rate ru<sub>21 </sub>in Table <b>791</b>. The second downstream internal node <b>732</b> (n<b>2</b>) may then transmit the packets at an about equal first downstream data rate rd<sub>21 </sub>to a first leaf node <b>720</b>, at a reduced second downstream data rate rd<sub>22 </sub>to a second leaf node <b>720</b>, and at a further reduced third downstream data rate rd<sub>23 </sub>to a third leaf node <b>720</b>, as indicated in Table <b>791</b>. The downstream data rates rd<sub>21</sub>, rd<sub>22</sub>, and rd<sub>23 </sub>may match the slave rates r<sub>s1</sub>, r<sub>s2</sub>, and r<sub>s3 </sub>of the first, second, and third leaf nodes <b>720</b>, respectively. Similarly, the third downstream internal node <b>732</b> (n<b>3</b>) may receive the packets at a rate that matches its upstream data rate ru<sub>31 </sub>in Table <b>792</b>, and transmit the packets at a reduce first downstream data rate rd<sub>31 </sub>to a fourth leaf node <b>720</b> and at a less reduced second downstream data rate rd<sub>32 </sub>to a fifth leaf node <b>720</b>, as indicated in Table <b>792</b>. The downstream data rates rd<sub>31 </sub>and rd<sub>32 </sub>may match the slave rates r<sub>s4 </sub>and r<sub>s5 </sub>of the fourth and fifth leaf nodes <b>720</b>, respectively.</p>
<p id="p-0054" num="0053">The rate-varying multicast clock distribution scheme <b>700</b> and the rate-varying multicast scheme <b>600</b> may provide packets or synchronization information to the leaf nodes <b>720</b> and <b>620</b> at their corresponding slave rates while efficiently using the network bandwidth and preventing timing loops. The corresponding networks, e.g., the packet based networks <b>730</b> and <b>630</b>, may substantially contribute in determining, processing, and filtering the incoming (upstream) and outgoing (downstream) rates of the network nodes, e.g., the internal nodes <b>732</b> and <b>632</b>. Although the internal nodes <b>732</b> and <b>632</b> in the schemes above are each coupled to one upstream node via a single upstream link, in other embodiments one or more internal nodes in the network may be coupled to a plurality of upstream nodes via a plurality of corresponding upstream links. For instance, the internal nodes may be part of a plurality of trees and may receive packets from a plurality of root or master nodes associated with the different trees. Further, the tables associated with the internal nodes may be continuously updated, e.g., in a dynamic manner, as the leaf or slave nodes update or request higher or lower rates, are disconnected from the tree or network, and/or join the tree or network.</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 8</figref> illustrates an embodiment of a multicast forwarding and discarding scheme <b>800</b> that may be implemented by an internal node in the rate-varying multicast clock distribution scheme <b>700</b> or the rate-varying multicast scheme <b>600</b>, e.g., to adjust the data rate of downstream packets. The multicast forwarding and discarding scheme <b>800</b> may be implemented by an internal node <b>810</b> in a packet based network positioned between a root node and plurality of leaf nodes to transmit the packets on each associated downstream link at the data rate advertized by a corresponding downstream node. For instance, the internal node <b>810</b> may correspond to an internal node <b>632</b> in the packet based network <b>630</b> or an internal node <b>732</b> in the packet based network <b>730</b>.</p>
<p id="p-0056" num="0055">The internal node <b>810</b> may comprise a packet replication function (block <b>812</b>) for each upstream or ingress link and one or more packet discard functions (block <b>814</b>) for each downstream or egress link. The packet replication function (block <b>812</b>) may receive a plurality of packets over the associated upstream or ingress link at an incoming upstream data rate, e.g., ru<sub>11</sub>. For example, ru<sub>11 </sub>may be equal to about 40 messages per second. At each packet discard function or block <b>814</b>, the packets' upstream data rate may be compared to a corresponding downstream data rate. The downstream data rate may be obtained from a table of downstream data rates <b>824</b> that associates each egress link with a downstream data rate. Similarly, the packets' upstream data rate may be obtained from a table of upstream data rates <b>826</b> that associates each ingress link with an upstream data rate. The table of downstream data rates <b>824</b> and the table of upstream data rates <b>826</b> may be stored at the internal node <b>810</b> or the packet based network.</p>
<p id="p-0057" num="0056">If the downstream data rate matches the upstream data rate, then the packets may be passed through without change. For example, if rd<sub>11</sub>=ru<sub>11 </sub>for a first egress link (Link <b>1</b>) or rd<sub>12</sub>=ru<sub>11 </sub>for a second egress link (Link <b>2</b>), then the packets may be sent on the corresponding egress link at about the same received rate, e.g., at about 40 messages per second. Alternatively, if the downstream data rate is less than the upstream data rate, then some of the packets may be discarded to reduce the packets' data rate appropriately. For example, if rd<sub>11</sub>&#x3c;ru<sub>11 </sub>or rd<sub>12</sub>&#x3c;ru<sub>11</sub>, then every one out of ru<sub>11</sub>/rd<sub>11 </sub>messages or one out of ru<sub>11</sub>/rd<sub>12 </sub>messages may be transmitted and the remainder discarded, respectively. The remaining non-discarded messages may be sent on the corresponding egress link. For example, only about 20 messages per second may be sent on the second egress link if the corresponding downstream data rate is equal to about half the upstream data rate.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 9</figref> illustrates an embodiment of a rate-varying multicast method <b>900</b> that may be implemented in the rate-varying multicast scheme <b>600</b> or the rate-varying multicast clock distribution scheme <b>700</b>. Specifically, the rate-varying multicast method <b>900</b> may be implemented by an internal node <b>632</b> in the packet based network <b>630</b> or an internal node <b>732</b> in the packet based network <b>730</b>. The method may begin at block <b>910</b>, where one or more advertized downstream data rates may be received via one or more downstream or egress links from a downstream internal node or a leaf node. The downstream data rates may be maintained in a table at the internal node or the packet based network of the internal node. At block <b>920</b>, an upstream data rate may that corresponds to a maximum of the received downstream data rates may be assigned to an upstream or ingress link. The upstream data rate may also be maintained in the table. At block <b>930</b>, the upstream data rate may be sent via the ingress link to an upstream internal node or a root node. The blocks <b>910</b>, <b>920</b>, and <b>930</b> may correspond to the data rates advertisement scheme described in the rate-varying multicast clock distribution scheme <b>700</b>.</p>
<p id="p-0059" num="0058">At block <b>940</b>, a plurality of packets may be received over the ingress link at the corresponding upstream data rate. At block <b>950</b>, the packets' data rate may be adjusted to the downstream data rate associated with each egress link. For instance, the packets may be maintained without change if the upstream data rate and the downstream data rate are about equal or some of the packets may be discarded, e.g., using the multicast forwarding and discarding scheme <b>800</b>, if the downstream data rate is less than the upstream data rate. At block <b>960</b>, the packets may be sent on each egress link at the corresponding downstream data rate. The blocks <b>940</b>, <b>950</b> and <b>960</b> may correspond to the downstream multicast scheme of the rate-varying multicast clock distribution scheme <b>700</b>. The method <b>900</b> may then end.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 10</figref> illustrates an embodiment of a transmitter/receiver unit <b>1000</b>, which may be any device that transports packets through a network. For instance, the transmitter/receiver unit <b>1000</b> may be located in the root node, internal node, or leaf node in the schemes described above. The transmitted/receiver unit <b>1000</b> may comprise one or more ingress ports or units <b>1010</b> for receiving packets, objects, or type-length-values (TLVs) from other network components, logic circuitry <b>1020</b> to determine which network components to send the packets to, and one or more egress ports or units <b>1030</b> for transmitting frames to the other network components. The logic circuitry <b>1020</b> may also determine the proper data rates to transmit the packets via the downstream or egress links.</p>
<p id="p-0061" num="0060">The network components described above may be implemented on any general-purpose network component, such as a computer or network component with sufficient processing power, memory resources, and network throughput capability to handle the necessary workload placed upon it. <figref idref="DRAWINGS">FIG. 11</figref> illustrates a typical, general-purpose network component <b>1100</b> suitable for implementing one or more embodiments of the components disclosed herein. The network component <b>1100</b> includes a processor <b>1102</b> (which may be referred to as a central processor unit or CPU) that is in communication with memory devices including second storage <b>1104</b>, read only memory (ROM) <b>1106</b>, random access memory (RAM) <b>1108</b>, input/output (I/O) devices <b>1110</b>, and network connectivity devices <b>1112</b>. The processor <b>1102</b> may be implemented as one or more CPU chips, or may be part of one or more application specific integrated circuits (ASICs).</p>
<p id="p-0062" num="0061">The second storage <b>1104</b> is typically comprised of one or more disk drives or tape drives and is used for non-volatile storage of data and as an over-flow data storage device if RAM <b>1108</b> is not large enough to hold all working data. Second storage <b>1104</b> may be used to store programs that are loaded into RAM <b>1108</b> when such programs are selected for execution. The ROM <b>1106</b> is used to store instructions and perhaps data that are read during program execution. ROM <b>1106</b> is a non-volatile memory device that typically has a small memory capacity relative to the larger memory capacity of second storage <b>1104</b>. The RAM <b>1108</b> is used to store volatile data and perhaps to store instructions. Access to both ROM <b>1106</b> and RAM <b>1108</b> is typically faster than to second storage <b>1104</b>.</p>
<p id="p-0063" num="0062">At least one embodiment is disclosed and variations, combinations, and/or modifications of the embodiment(s) and/or features of the embodiment(s) made by a person having ordinary skill in the art are within the scope of the disclosure. Alternative embodiments that result from combining, integrating, and/or omitting features of the embodiment(s) are also within the scope of the disclosure. Where numerical ranges or limitations are expressly stated, such express ranges or limitations should be understood to include iterative ranges or limitations of like magnitude falling within the expressly stated ranges or limitations (e.g., from about 1 to about 10 includes, 2, 3, 4, etc.; greater than 0.10 includes 0.11, 0.12, 0.13, etc.). For example, whenever a numerical range with a lower limit, R<sub>1</sub>, and an upper limit, R<sub>u</sub>, is disclosed, any number falling within the range is specifically disclosed. In particular, the following numbers within the range are specifically disclosed: R=R<sub>1</sub>+k*(R<sub>u</sub>&#x2212;R<sub>1</sub>), wherein k is a variable ranging from 1 percent to 100 percent with a 1 percent increment, i.e., k is 1 percent, 2 percent, 3 percent, 4 percent, 7 percent, . . . , 70 percent, 71 percent, 72 percent, . . . , 97 percent, 96 percent, 97 percent, 98 percent, 99 percent, or 100 percent. Moreover, any numerical range defined by two R numbers as defined in the above is also specifically disclosed. Use of the term &#x201c;optionally&#x201d; with respect to any element of a claim means that the element is required, or alternatively, the element is not required, both alternatives being within the scope of the claim. Use of broader terms such as comprises, includes, and having should be understood to provide support for narrower terms such as consisting of, consisting essentially of, and comprised substantially of. Accordingly, the scope of protection is not limited by the description set out above but is defined by the claims that follow, that scope including all equivalents of the subject matter of the claims. Each and every claim is incorporated as further disclosure into the specification and the claims are embodiment(s) of the present disclosure. The discussion of a reference in the disclosure is not an admission that it is prior art, especially any reference that has a publication date after the priority date of this application. The disclosure of all patents, patent applications, and publications cited in the disclosure are hereby incorporated by reference, to the extent that they provide exemplary, procedural, or other details supplementary to the disclosure.</p>
<p id="p-0064" num="0063">While several embodiments have been provided in the present disclosure, it should be understood that the disclosed systems and methods might be embodied in many other specific forms without departing from the spirit or scope of the present disclosure. The present examples are to be considered as illustrative and not restrictive, and the intention is not to be limited to the details given herein. For example, the various elements or components may be combined or integrated in another system or certain features may be omitted, or not implemented.</p>
<p id="p-0065" num="0064">In addition, techniques, systems, subsystems, and methods described and illustrated in the various embodiments as discrete or separate may be combined or integrated with other systems, modules, techniques, or methods without departing from the scope of the present disclosure. Other items shown or discussed as coupled or directly coupled or communicating with each other may be indirectly coupled or communicating through some interface, device, or intermediate component whether electrically, mechanically, or otherwise. Other examples of changes, substitutions, and alterations are ascertainable by one skilled in the art and could be made without departing from the spirit and scope disclosed herein.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An apparatus comprising:
<claim-text>an upstream node in a packet based network that multicasts a plurality of packets;</claim-text>
<claim-text>an intermediary node coupled to the upstream node; and</claim-text>
<claim-text>a plurality of downstream nodes coupled to the intermediary node,</claim-text>
<claim-text>wherein the upstream node, the intermediary node, and the downstream nodes are arranged in a tree topology, and</claim-text>
<claim-text>wherein the intermediary node is configured to:
<claim-text>receive a plurality of downstream data rates advertised by the downstream nodes;</claim-text>
<claim-text>receive the packets from the upstream node at an upstream data rate equal to a maximum data rate of the downstream data rates; and</claim-text>
<claim-text>multicast the packets from the intermediary node to the downstream nodes at the downstream data rates, and wherein the upstream node is coupled to a master clock associated with the maximum data rate and the downstream nodes are coupled to a plurality of corresponding slave clocks associated with the downstream data rates of the leaf nodes,</claim-text>
</claim-text>
<claim-text>wherein the packets comprise timestamps or frequency and time synchronization information for the master clock and the slave clocks, and
<claim-text>wherein some of the packets are dropped when at least one of the downstream data rates is less than the upstream data rate.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the master clock and the slave clocks are synchronized in a unidirectional or a bidirectional manner.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the intermediary node comprises a first table that comprises the downstream data rates associated with a plurality of egress links and a second table that comprises the upstream data rate associated with an ingress link.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the intermediary node is part of a tree topology that couples the upstream node to the downstream nodes, and wherein the intermediary node is coupled to the upstream node via the ingress link, and wherein the intermediary node is coupled to the downstream nodes via the egress links.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the different rates of the downstream nodes depend on at least one of the following performance metrics of the downstream nodes: characteristics of corresponding slave clock designs, various packet network impairments, packet selection and filtering algorithms, oscillators used in the downstream nodes, and operational states of the downstream nodes.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the upstream node is a video content transmitter and the downstream nodes are video content receivers, and wherein a first set of the downstream nodes comprises high capacity receivers and a second set of the downstream nodes comprises lower capacity receivers.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the dropped packets are packets destined for only downstream nodes that advertise downstream data rates that are less than the upstream data rate.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the packets are forwarded, without dropping any of the packets, to the downstream nodes that advertise downstream data rates that are the same as the upstream data rate.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the number of dropped packets for one of the downstream nodes is determined by the upstream data rate divided by the downstream data rate for the one of the downstream nodes.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A network component comprising:
<claim-text>a packet replication block coupled to an ingress link and configured to replicate a plurality of packets received on the ingress link at an upstream data rate;</claim-text>
<claim-text>a packet discard block coupled to the packet replication block and to an egress link; and</claim-text>
<claim-text>a second packet discard block coupled to the packet replication block and to a second egress link,</claim-text>
<claim-text>wherein the packet discard block is configured to:
<claim-text>pass through the received packets without dropping the received packets when a downstream data rate that corresponds to the egress link matches the upstream data rate that corresponds to the upstream link; and</claim-text>
<claim-text>reduce some of the received packets to match the downstream data rate when the downstream data rate that corresponds to the egress link is less than the upstream data rate that corresponds to the upstream link,</claim-text>
</claim-text>
<claim-text>wherein the second packet discard block is configured to reduce some of the received packets to match a second downstream data rate when the second downstream rate is less than the upstream data rate,</claim-text>
<claim-text>wherein the second downstream data rate corresponds to a data rate for the second egress link, and</claim-text>
<claim-text>wherein the packet replication block forwards the same quantity of packets to the packet discard block and the second packet discard block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The network component of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the packet discard block is further configured to obtain the upstream data rate associated with the ingress link from a table of upstream data rates and obtain the downstream data rate associated with the egress link in a second table of downstream data rates.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The network component of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the packet discard block is configured to discard a number of the received packets in a quantity of packets and transmit a remaining number of the received packets such that the ratio of the transmitted packets to discarded packets is about equal to the ratio of the upstream data rate to the downstream data rate when the downstream data rate is less than the upstream data rate.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The network component of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the packet discard block is further configured to compare the upstream data rate obtained from the upstream table and the downstream data rate obtained from the downstream table.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A method comprising:
<claim-text>receiving a plurality of advertised downstream data rates via a plurality of egress links from a plurality of downstream nodes;</claim-text>
<claim-text>assigning an upstream data rate that corresponds to a maximum of the received downstream data rates to an ingress link;</claim-text>
<claim-text>advertising the upstream data rate via the ingress link to an upstream node;</claim-text>
<claim-text>receiving a plurality of packets via the ingress link at the upstream data rate; and</claim-text>
<claim-text>forwarding the packets to the downstream nodes at rates that match the advertised downstream data rates from the downstream nodes,</claim-text>
<claim-text>wherein the packets are dropped when the advertised downstream data rates are less than the upstream data rate,</claim-text>
<claim-text>wherein the downstream nodes comprise a plurality of leaf nodes within a multicast tree distribution tree topology that are coupled to a packet based network,</claim-text>
<claim-text>wherein the upstream node comprises a root node within the multicast tree distribution tree topology that is coupled to the packet based network, and</claim-text>
<claim-text>wherein the downstream data rates and the upstream data rate are advertised and updated continuously in a dynamic manner when the downstream nodes request higher or lower data rates, one or more of the downstream nodes are disconnected from the packet based network, and one or more of the downstream nodes join the packet based network.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the downstream data rates and the upstream data rate determine quantities of transmitted messages per second and are maintained by the packet based network.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the downstream data rates and the upstream data rate are advertised and expressed in powers of two, and wherein a number of packets dropped when forwarding the packets to one of the downstream nodes is determined by the upstream data rate divided by the advertised downstream data rate received from the one of the downstream nodes.</claim-text>
</claim>
</claims>
</us-patent-grant>
