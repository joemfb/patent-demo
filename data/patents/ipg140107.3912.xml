<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624980-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624980</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11659774</doc-number>
<date>20040810</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1158</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>17</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>14</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348184</main-classification>
<further-classification>348701</further-classification>
<further-classification>348180</further-classification>
</classification-national>
<invention-title id="d2e53">Apparatus and method for indicating the detected degree of motion in video</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4409615</doc-number>
<kind>A</kind>
<name>McMann et al.</name>
<date>19831000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>378 982</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4847909</doc-number>
<kind>A</kind>
<name>Shibata</name>
<date>19890700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382107</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4926361</doc-number>
<kind>A</kind>
<name>Ohtsubo et al.</name>
<date>19900500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348607</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5063438</doc-number>
<kind>A</kind>
<name>Faroudja</name>
<date>19911100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348610</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5083203</doc-number>
<kind>A</kind>
<name>Ko et al.</name>
<date>19920100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348701</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5119409</doc-number>
<kind>A</kind>
<name>Nields et al.</name>
<date>19920600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>378106</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5185664</doc-number>
<kind>A</kind>
<name>Darby</name>
<date>19930200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348620</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5225898</doc-number>
<kind>A</kind>
<name>Imai et al.</name>
<date>19930700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5519451</doc-number>
<kind>A</kind>
<name>Clatanoff et al.</name>
<date>19960500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348606</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5548346</doc-number>
<kind>A</kind>
<name>Mimura et al.</name>
<date>19960800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348738</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5579054</doc-number>
<kind>A</kind>
<name>Sezan et al.</name>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348452</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5625412</doc-number>
<kind>A</kind>
<name>Aciu et al.</name>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482221</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5734362</doc-number>
<kind>A</kind>
<name>Eglit</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345 89</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5796437</doc-number>
<kind>A</kind>
<name>Muraji et al.</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348452</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5872602</doc-number>
<kind>A</kind>
<name>Johnson</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348620</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6118489</doc-number>
<kind>A</kind>
<name>Han et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348452</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6181382</doc-number>
<kind>B1</kind>
<name>Kieu et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348459</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6252632</doc-number>
<kind>B1</kind>
<name>Cavallaro</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348585</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6489989</doc-number>
<kind>B1</kind>
<name>Shapiro et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6580812</doc-number>
<kind>B1</kind>
<name>Harrington</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382107</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6670963</doc-number>
<kind>B2</kind>
<name>Osberger</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345629</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6734916</doc-number>
<kind>B1</kind>
<name>Sims</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6756954</doc-number>
<kind>B2</kind>
<name>Yamamoto et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345 87</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>7180529</doc-number>
<kind>B2</kind>
<name>Covannon et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345690</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>7256755</doc-number>
<kind>B2</kind>
<name>Ohta et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345 68</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2001/0015768</doc-number>
<kind>A1</kind>
<name>Shin et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348452</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2002/0047818</doc-number>
<kind>A1</kind>
<name>Yamamoto et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345 87</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2004/0086046</doc-number>
<kind>A1</kind>
<name>Ma et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2006/0153475</doc-number>
<kind>A1</kind>
<name>Ruggiero</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382276</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2006/0209957</doc-number>
<kind>A1</kind>
<name>Riemens et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2006/0244759</doc-number>
<kind>A1</kind>
<name>Kempf</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345611</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2006/0268179</doc-number>
<kind>A1</kind>
<name>Renner et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348666</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>GB</country>
<doc-number>2 266 638</doc-number>
<kind>A</kind>
<date>19931100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>GB</country>
<doc-number>2 343 317</doc-number>
<kind>A</kind>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>JP</country>
<doc-number>3-242797</doc-number>
<date>19911000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>JP</country>
<doc-number>11-318829</doc-number>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>KR</country>
<doc-number>20040047541</doc-number>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>WO</country>
<doc-number>WO 00/28498</doc-number>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>International Search Report Dated May 3, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>6</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348701</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348607</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348448</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348452</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348450</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348180</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348184</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348553</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348569</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348687</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348678</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348169</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345581</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345589</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345647</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345473</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345474</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345690</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345 63</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345 87</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345 89</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345102</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382107</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070268409</doc-number>
<kind>A1</kind>
<date>20071122</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Rumreich</last-name>
<first-name>Mark Francis</first-name>
<address>
<city>Indianapolis</city>
<state>IN</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Keen</last-name>
<first-name>Ronald Thomas</first-name>
<address>
<city>Indianapolis</city>
<state>IN</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Rumreich</last-name>
<first-name>Mark Francis</first-name>
<address>
<city>Indianapolis</city>
<state>IN</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Keen</last-name>
<first-name>Ronald Thomas</first-name>
<address>
<city>Indianapolis</city>
<state>IN</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Shedd</last-name>
<first-name>Robert D.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Cromarty</last-name>
<first-name>Brian J.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Thomson Licensing</orgname>
<role>03</role>
<address>
<city>Boulogne-Billancourt</city>
<country>FR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kostak</last-name>
<first-name>Victor</first-name>
<department>2422</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/US2004/026032</doc-number>
<kind>00</kind>
<date>20040810</date>
</document-id>
<us-371c124-date>
<date>20070208</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2006/022705</doc-number>
<kind>A </kind>
<date>20060302</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A video apparatus such as a television signal receiver enables a video display that readily indicates the detected degree of a video attribute such as motion and/or other video attribute present in the video display. According to an exemplary embodiment, the video apparatus includes first circuitry operative to receive video data. Second circuitry is operative to enable a video display corresponding to the video data. The video display includes first and second video attributes. The first video attribute varies in proportion to a detected degree of the second video attribute.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="162.56mm" wi="237.15mm" file="US08624980-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="231.14mm" wi="129.79mm" file="US08624980-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="236.14mm" wi="164.85mm" orientation="landscape" file="US08624980-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="240.88mm" wi="160.95mm" orientation="landscape" file="US08624980-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="166.03mm" wi="106.93mm" file="US08624980-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">This application claims the benefit, under 35 U.S.C. &#xa7;365 of International Application PCT/US2004/026032, filed Aug. 10, 2004, which was published in accordance with PCT Article 21(2) on Mar. 2, 2006 in English.</p>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention generally relates to video apparatuses such as television signal receivers, and more particularly, to an apparatus and method for enabling a video display that readily indicates the detected degree of a video attribute such as motion and/or other video attribute present in the video display.</p>
<heading id="h-0002" level="1">BACKGROUND INFORMATION</heading>
<p id="p-0004" num="0003">Video apparatuses such as television signal receivers often include motion detectors for adaptive video processing to facilitate functions such as frequency upconversion, data compression or line/frame combing. High quality motion detection for video signals such as National Television Standards Committee (NTSC) signals often involves sophisticated processing to correctly identify actual motion without falsely detecting motion due to the alternating phase of chrominance with respect to luminance on alternating video frames. As a result, motion detectors often include several control registers whose settings may be adjusted in order to optimize the performance of the motion detector for a particular application or condition (e.g., noisy video). Because of the complexity of motion detection, and the potentially large number of control registers associated with a given motion detector, it may be difficult for application circuit designers to optimize the control register settings of a motion detector. Accordingly, there is a need for a convenient means for enabling application circuit designers to determine the optimal control register settings for a motion detector in the product design environment.</p>
<p id="p-0005" num="0004">One conventional approach for enabling application circuit designers to determine the control register settings for a motion detector is to overlay points of detected motion upon a video display. According to this conventional approach, the pixels in a video display that represent points of motion are replaced with black pixels. That is, those pixels of a video display that represent points of motion are displayed in black, while those pixels that do not represent points of motion are displayed in accordance with their original level of luminance. This conventional approach, however, is less than optimal since it uses single threshold and replacement values, and therefore indicates only whether motion is present at a given pixel, but does not indicate the degree of motion present at the given pixel. As a result, this approach is deficient in that it does not provide application circuit designers with a good indication of the degree of detected motion in a video display.</p>
<p id="p-0006" num="0005">Accordingly, there is a need for an apparatus and method which avoids the foregoing problems, and thereby enables a video display that readily indicates the detected degree of motion and/or other video attribute present in the video display. The present invention may address these and/or other issues.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">In accordance with an aspect of the present invention, a video apparatus is disclosed. According to an exemplary embodiment, the video apparatus comprises means for receiving video data and means for enabling a video display corresponding to the video data. The video display includes first and second video attributes. The first video attribute varies in proportion to a detected degree of the second video attribute.</p>
<p id="p-0008" num="0007">In accordance with another aspect of the present invention, a method for enabling a video display is disclosed. According to an exemplary embodiment, the method comprises steps of receiving video data, and enabling the video display corresponding to the video data. The video display includes first and second video attributes. The first video attribute varies in proportion to a detected degree of the second video attribute.</p>
<p id="p-0009" num="0008">In accordance with yet another aspect of the present invention, a television signal receiver is disclosed. According to an exemplary embodiment, the television signal receiver comprises first circuitry operative to receive video data, and second circuitry operative to enable a video display corresponding to the video data. The video display includes first and second video attributes. The first video attribute varies in proportion to a detected degree of the second video attribute.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0010" num="0009">The above-mentioned and other features and advantages of this invention, and the manner of attaining them, will become more apparent and the invention will be better understood by reference to the following description of embodiments of the invention taken in conjunction with the accompanying drawings, wherein:</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of an exemplary environment suitable for implementing the present invention;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a processor included in the video apparatus of <figref idref="DRAWINGS">FIG. 1</figref> according to an exemplary embodiment of the present invention;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of signal processing apparatus including a line comb, frame comb and motion detector included in the video apparatus of <figref idref="DRAWINGS">FIG. 1</figref> according to an exemplary embodiment of the present invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram providing further details of the frame comb and soft switch of <figref idref="DRAWINGS">FIG. 3</figref> according to an exemplary embodiment of the present invention; and</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating steps according to an exemplary embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0016" num="0015">The exemplifications set out herein illustrate preferred embodiments of the invention, and such exemplifications are not to be construed as limiting the scope of the invention in any manner.</p>
<heading id="h-0005" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0017" num="0016">Referring now to the drawings, and more particularly to <figref idref="DRAWINGS">FIG. 1</figref>, an exemplary environment suitable for implementing the present invention is shown. The exemplary environment of <figref idref="DRAWINGS">FIG. 1</figref> comprises user input means such as user input device <b>10</b>, and a video apparatus <b>100</b> that enables a video display function. According to an exemplary embodiment, video apparatus <b>100</b> is embodied as a television signal receiver, but may be embodied as any device or apparatus that enables a video display function, regardless of whether it includes an integrated display device.</p>
<p id="p-0018" num="0017">User input device <b>10</b> is operative to generate and output control signals that control the operation of video apparatus <b>100</b> and/or other devices. According to an exemplary embodiment, user input device <b>10</b> includes a plurality of input keys and outputs control signals in a wired and/or wireless (e.g., via infrared or radio frequency (RF) link, etc.) manner responsive to user depression of its input keys. User input device <b>10</b> may for example be embodied as a hand-held remote control device, wired and/or wireless keyboard, integrated control panel of video apparatus <b>100</b>, and/or other user input device.</p>
<p id="p-0019" num="0018">Video apparatus <b>100</b> is operative to receive signals including audio, video and/or data signals in analog and/or digital format from one or more signal sources such as terrestrial, cable, satellite, internet and/or other signal sources and to provide aural and/or visual outputs corresponding to these received signals. According to an exemplary embodiment, video apparatus <b>100</b> enables a video display including a first video attribute (e.g., luminance, etc.) that is readily discernible by a user from viewing the video display, and a second video attribute (e.g., motion, noise, etc.) that is not readily discernible by the user from viewing the video display. According to this exemplary embodiment, the first video attribute varies in proportion to a detected degree of the second video attribute and thereby enables a user such as an application circuit designer to adjust and select one or more control settings related to the second video attribute. For example, an application circuit designer may use the visually observed degree of luminance in the video display as an indicator of the degree of motion present in the video display. In this manner, the application circuit designer may adjust various motion control settings of video apparatus <b>100</b> until the desired optimal control settings are identified. Further details regarding these aspects of the present invention will be provided later herein.</p>
<p id="p-0020" num="0019">Referring to <figref idref="DRAWINGS">FIG. 2</figref>, a block diagram of a processor <b>20</b> included in video apparatus <b>100</b> of <figref idref="DRAWINGS">FIG. 1</figref> according to an exemplary embodiment of the present invention is shown. As indicated in <figref idref="DRAWINGS">FIG. 2</figref>, processor <b>20</b> is operative to output various control signals including a DY_GAIN signal, a DY_CORING signal, a DC_GAIN signal, a DC_CORING signal, a BY_GAIN signal, a BY_CORING signal, a MOTION_MARKERS signal, a NONSTANDARD THRESH signal, a TILT_ADJ signal, and a PHASE_ADJ signal. According to an exemplary embodiment, the foregoing control signals may be output from processor <b>20</b> to other elements of video apparatus <b>100</b> via an inter-integrated circuit (I2C) bus responsive to key inputs entered via user input device <b>10</b>. In <figref idref="DRAWINGS">FIG. 2</figref>, the number above each signal line represents the bit width of each signal according to an exemplary embodiment. The &#x201c;*&#x201d; symbol indicates that the signal is unsigned.</p>
<p id="p-0021" num="0020">According to an exemplary embodiment, the DY_GAIN signal, the DY_CORING signal, the DC_GAIN signal, the DC_CORING signal, the BY_GAIN signal, and the BY_CORING signal represent control signals for a motion detection function of video apparatus <b>100</b>. As will be described later herein, the foregoing signals may be set to optimal values by an application circuit designer during a test mode of video apparatus <b>100</b>. According to this exemplary embodiment, the foregoing control signals represent the following. The DY_GAIN signal indicates a luminance gain sensitivity value used for motion detection. The DY_CORING signal indicates a luminance quantization sensitivity value used for motion detection. The DC_GAIN signal indicates a chrominance gain sensitivity value used for motion detection. The DC_CORING signal indicates a chrominance quantization sensitivity value used for motion detection. The BY_GAIN signal indicates a luminance gain sensitivity value used for motion detection for luminance signals near the chrominance pass band (e.g., 3.58 MHz, etc.). The BY_CORING signal indicates a luminance quantization sensitivity value used for motion detection for luminance signals near the chrominance pass band (e.g., 3.58 MHz, etc.). According to an exemplary embodiment, the foregoing control signals are used as control &#x201c;knobs&#x201d; by an application circuit designer to adjust the motion detection control settings of video apparatus <b>100</b>. That is, the values of these control signals may be adjusted by the application circuit designer during a test mode of video apparatus <b>100</b> in order to select the combination of values which produce the most optimal video display results. The foregoing control signals are examples only. In practice, other control signals may be used for motion detection, and the number of such control signals may be a matter of design choice.</p>
<p id="p-0022" num="0021">Also according to an exemplary embodiment, the MOTION_MARKERS signal output from processor <b>20</b> is used to turn a test mode of video apparatus <b>100</b> for motion detection on and off. The NONSTANDARD THRESH signal indicates a threshold value used to determine whether a received video signal is a nonstandard video signal. For example, a video signal provided to video apparatus <b>100</b> from an external device such as a video cassette recorder (VCR), video game box, or other device may be considered a nonstandard video signal. The TILT_ADJ signal and the PHASE_ADJ signal are used to adjust the chrominance magnitude and group delay symmetry of received video signals, respectively.</p>
<p id="p-0023" num="0022">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, a block diagram of signal processing apparatus including a line comb, frame comb and motion detector included in the video apparatus of <figref idref="DRAWINGS">FIG. 1</figref> according to an exemplary embodiment of the present invention is shown. In particular, the signal processing apparatus of <figref idref="DRAWINGS">FIG. 3</figref> includes line combing means such as line comb <b>30</b>, frame combing and switching means such as frame comb and soft switch <b>40</b>, chrominance amplitude equalizing means such as chroma amplitude equalizer <b>50</b>, chrominance phase equalizing means such as chroma phase equalizer <b>60</b>, motion detecting means such as motion detector <b>70</b>, luminance delay means such as luma delay <b>80</b>, and nonstandard signal detecting means such as nonstandard signal detector <b>90</b>. According to an exemplary embodiment, the foregoing elements of <figref idref="DRAWINGS">FIG. 3</figref> are included on a single integrated circuit (IC), but may also be included on a plurality of ICs. In <figref idref="DRAWINGS">FIG. 3</figref>, the number above each signal line represents the bit width of each signal according to an exemplary embodiment. The &#x201c;*&#x201d; symbol indicates that the signal is unsigned.</p>
<p id="p-0024" num="0023">Line comb <b>30</b> is operative to perform a line combing function. According to an exemplary embodiment, line comb <b>30</b> performs an adaptive line combing function in accordance with a clock enabling signal VSO_B using three adjacent video line signals FILTER_IN_NM_<b>1</b> (e.g., line N&#x2212;1), FILTER_IN_N_<b>1</b> (e.g., line N), and FILTER_IN_NP_<b>1</b> (e.g., line N+1) for a given frame (e.g., frame <b>1</b>) to produce a combined chrominance signal, C1. The foregoing video signals may for example be provided to line comb <b>30</b> from intermediate frequency (IF) processing and/or video delay circuitry (not shown in FIGS.) of video apparatus <b>100</b>. Clock enabling signal VSO_B may be provided from other circuitry of video apparatus <b>100</b> (not shown in FIGS.).</p>
<p id="p-0025" num="0024">Frame comb and soft switch <b>40</b> is operative to perform functions including frame combing and switching functions. According to an exemplary embodiment, frame comb and soft switch <b>40</b> performs an adaptive frame combing function in accordance with clock enabling signal VSO_B using the C1 signal, the FILTER_IN_N<sub>&#x2014;</sub>1 signal, a FILTER_IN_N<sub>&#x2014;</sub>2 signal, a K_MOTION signal, a LINE_COUNT signal, a NO_BURST signal, the MOTION_MARKERS signal, and a NONSTANDARD signal, to thereby generate adaptively combed chrominance and luminance output signals. According to this exemplary embodiment, the foregoing signals represent the following. The C1 signal is provided from line comb <b>30</b>, as previously described herein. The FILTER_IN_N<sub>&#x2014;</sub>1 signal is a video signal for line N of a frame (e.g., frame <b>1</b>). The FILTER_IN_N<sub>&#x2014;</sub>2 signal is a video signal for line N of a next frame (e.g., frame <b>2</b>). The FILTER_IN_N<sub>&#x2014;</sub>1 signal and the FILTER_IN_N<sub>&#x2014;</sub>2 signal may for example be provided from IF processing and/or video delay circuitry (not shown in FIGS.) of video apparatus <b>100</b>. The K_MOTION signal is provided from motion detector <b>70</b> and controls an amount of blending between line combing and frame combing (e.g., all line combing, 50% line combing/50% frame combing, all frame combing, etc.). The LINE_COUNT signal indicates the current video line number. The NO_BURST signal indicates whether chrominance is present. The LINE_COUNT signal and the NO_BURST signal may for example be provided to frame comb and soft switch <b>40</b> from processing circuitry (not shown in FIGS.) included on the same IC as the elements shown in <figref idref="DRAWINGS">FIG. 3</figref>. The MOTION_MARKERS signal is provided from processor <b>20</b> of <figref idref="DRAWINGS">FIG. 2</figref>, and is used to turn a test mode of video apparatus <b>100</b> for motion detection on and off. The NONSTANDARD signal is provided from nonstandard signal detector <b>90</b> and indicates whether a received video signal is a nonstandard video signal (e.g., a video signal provided to video apparatus <b>100</b> from an external device such as a VCR, video game box, or other device). Further exemplary details regarding frame comb and soft switch <b>40</b> will be provided later herein.</p>
<p id="p-0026" num="0025">Chroma amplitude equalizer <b>50</b> is operative to perform a chrominance amplitude equalization function. According to an exemplary embodiment, chroma amplitude equalizer <b>50</b> performs the chrominance amplitude equalization function on the adaptively combed chrominance output signal provided from frame comb and soft switch <b>40</b> in accordance with the TILT_ADJ signal provided from processor <b>20</b> <figref idref="DRAWINGS">FIG. 2</figref> and clock enabling signal VSO_B to thereby generate an amplitude equalized chrominance signal.</p>
<p id="p-0027" num="0026">Chroma phase equalizer <b>60</b> is operative to perform a chrominance phase equalization function. According to an exemplary embodiment, chroma phase equalizer <b>60</b> performs the chrominance phase equalization function on the amplitude equalized chrominance signal provided from chroma amplitude equalizer <b>50</b> in accordance with the PHASE_ADJ signal provided from processor <b>20</b> of <figref idref="DRAWINGS">FIG. 2</figref> and clock enabling signal VSO_B to thereby generate a chrominance output signal, CHROMA_OUT, which is provided for further processing (e.g., NTSC decoding, etc.).</p>
<p id="p-0028" num="0027">Motion detector <b>70</b> is operative to perform a motion detection function. According to an exemplary embodiment, motion detector <b>70</b> performs a motion detection function in accordance with clock enabling signal VSO_B using video signals including the FILTER_IN_NM<sub>&#x2014;</sub>1 signal (e.g., line N&#x2212;1, frame <b>1</b>), the FILTER_IN_N<sub>&#x2014;</sub>1 signal (e.g., line N, frame <b>1</b>), the FILTER_IN_NP<sub>&#x2014;</sub>1 signal (e.g., line N+1, frame <b>1</b>), a FILTER_IN_NM<sub>&#x2014;</sub>2 signal (e.g., line N&#x2212;1, frame <b>2</b>), the FILTER_IN_N<sub>&#x2014;</sub>2 signal (e.g., line N, frame <b>2</b>), and a FILTER_IN_NP<sub>&#x2014;</sub>2 signal (e.g., line N+1, frame <b>2</b>), as well as control signals including the DY_GAIN signal, the DY_CORING signal, the DC_GAIN signal, the DC_CORING signal, the BY_GAIN signal, and the BY_CORING signal provided from processor <b>20</b> of <figref idref="DRAWINGS">FIG. 2</figref>, to thereby generate the K_MOTION signal. As previously indicated herein, the K_MOTION signal controls an amount of blending between line combing and frame combing (e.g., all line combing, 50% line combing/50% frame combing, all frame combing, etc.). According to an exemplary embodiment, the less motion detected by motion detector <b>70</b>, the more frame combing and less line combing is performed. Conversely, the more motion detected by motion detector <b>70</b>, the less frame combing and more line combing is performed.</p>
<p id="p-0029" num="0028">Luma delay <b>80</b> is operative to perform a luminance delay function. According to an exemplary embodiment, luma delay <b>80</b> applies a predetermined delay to the adaptively combed luminance output signal provided from frame comb and soft switch <b>40</b> in accordance with clock enabling signal VSO_B to thereby generate a delayed luminance signal, LUMA_OUT, which is provided for further processing (e.g., NTSC decoding, etc.).</p>
<p id="p-0030" num="0029">Nonstandard signal detector <b>90</b> is operative to perform a nonstandard signal detection function. According to an exemplary embodiment, nonstandard signal detector <b>90</b> performs the nonstandard signal detection function in accordance with clock enabling signal VSO_B using the LINE_COUNT signal, the NONSTANDARD_THRES signal, and a COS signal to thereby generate the NONSTANDARD signal which is provided to frame comb and soft switch <b>40</b>. The COS signal indicates the phase of the chrominance subcarrier, and may for example be provided to nonstandard signal detector <b>90</b> from processing circuitry (not shown in FIGS.) included on the same IC as the elements shown in <figref idref="DRAWINGS">FIG. 3</figref>. As previously indicated herein, the NONSTANDARD signal indicates whether a received video signal is a nonstandard video signal (e.g., a video signal provided to video apparatus <b>100</b> from an external device such as a VCR, video game box, or other device) based on the NONSTANDARD_THRESH signal provided from processor <b>20</b> of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0031" num="0030">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, a diagram providing further details of frame comb and soft switch <b>40</b> of <figref idref="DRAWINGS">FIG. 3</figref> according to an exemplary embodiment of the present invention is shown. As shown in <figref idref="DRAWINGS">FIG. 4</figref>, frame comb and soft switch <b>40</b> comprise first multiplexing means such as multiplexer <b>402</b>, first delay means such as delay <b>404</b>, first subtracting means such as subtractor <b>406</b>, second delay means such as delay <b>408</b>, first multiplying means such as multiplier <b>410</b>, first flip-flop means such as D-type flip-flop <b>412</b>, second subtracting means such as subtractor <b>414</b>, second flip-flop means such as D-type flip-flop <b>416</b>, amplifying means such as amplifier <b>418</b>, second multiplying means such as multiplier <b>420</b>, first adding means such as adder <b>422</b>, truncating means such as truncator <b>424</b>, third flip-flop means such as D-type flip-flop <b>426</b>, second multiplexing means such as multiplexer <b>428</b>, third delay means such as delay <b>430</b>, third multiplying means such as multiplier <b>432</b>, second adding means such as adder <b>434</b>, first limiting means such as limiter <b>436</b>, third multiplexing means such as multiplexer <b>438</b>, fourth multiplying means such as multiplier <b>440</b>, minimizing means such as minimizer <b>442</b>, third subtracting means such as subtractor <b>444</b>, second limiting means such as limiter <b>446</b>, fourth flip-flop means such as D-type flip-flop <b>448</b>, gating means such as vertical interval gate <b>450</b>, and logic means such as OR gate <b>452</b>. In <figref idref="DRAWINGS">FIG. 4</figref>, the number above each signal line represents the bit width of each signal according to an exemplary embodiment. The &#x201c;*&#x201d; symbol indicates that the signal is unsigned.</p>
<p id="p-0032" num="0031">Multiplexer <b>402</b> is operative to output a K_MOTION_MUX_OUT signal responsive to the NONSTANDARD signal provided from nonstandard signal detector <b>90</b> of <figref idref="DRAWINGS">FIG. 3</figref>. According to an exemplary embodiment, the K_MOTION_MUX_OUT signal is a control signal that controls the amount of line and/or frame combing to be performed. For example, if the K_MOTION_MUX_OUT signal exhibits a value of 8, only line combing (and no frame combing) is performed. Conversely, if the K_MOTION_MUX_OUT signal exhibits a value of 0, only frame combing (and no line combing) is performed. If the K_MOTION_MUX_OUT signal exhibits a value from 1 to 7 a corresponding combination of frame combing and line combing is performed.</p>
<p id="p-0033" num="0032">Delay <b>404</b> is operative to apply a predetermined delay to the C1 signal provided from line comb <b>30</b> of <figref idref="DRAWINGS">FIG. 3</figref> to thereby generate a delayed signal. According to an exemplary embodiment, delay <b>404</b> is clocked in accordance with clock enabling signal VSO_B, and applies a delay of 13 clock cycles to the C1 signal. Subtractor <b>406</b> is operative to subtract the FILTER_IN_N<sub>&#x2014;</sub>2 signal from the FILTER_IN_N<sub>&#x2014;</sub>1 signal to generate a difference signal, and thereby operates as a fixed frame comb. Delay <b>408</b> is operative to apply a predetermined delay to the difference signal provided from subtractor <b>406</b> to thereby generate a delayed signal. According to an exemplary embodiment, delay <b>408</b> is clocked in accordance with clock enabling signal VSO_B, and applies a delay of 31 clock cycles to the difference signal provided from subtractor <b>406</b>. Multiplier <b>410</b> is operative to multiply the delayed signal provided from delay <b>408</b> by a value of 4 to thereby generate a multiplied signal. D-type flip-flop <b>412</b> is operative to receive and output the multiplied signal provided from multiplier <b>410</b> in accordance with clock enabling signal VSO_B.</p>
<p id="p-0034" num="0033">Subtractor <b>414</b> is operative to subtract the multiplied signal provided from multiplier <b>410</b> from the delayed signal provided from delay <b>404</b> to thereby generate a difference signal. D-type flip-flop <b>416</b> is operative to receive and output the difference signal provided from subtractor <b>414</b> in accordance with clock enabling signal VSO_B. Amplifier <b>418</b> is operative to amplify the output signal provided from D-type flip-flop <b>416</b> responsive to the K_MOTION_MUX_OUT signal to thereby generate an amplified signal. Multiplier <b>420</b> is operative to multiply the amplified signal provided from amplifier <b>418</b> by a value of &#x215b; to thereby generate a multiplied signal. Adder <b>422</b> is operative to add the multiplied signal provided from multiplier <b>420</b> to the output signal provided from D-type flip-flop <b>412</b> to thereby generate a sum signal. Truncator <b>424</b> is operative to truncate the 2 most significant bits (MSBs) from the sum signal provided from adder <b>422</b> to thereby generate a truncated signal. D-type flip-flop <b>426</b> is operative to receive and output the truncated signal provided from truncator <b>424</b> in accordance with clock enabling signal VSO_B. The output signal from D-type flip-flop <b>426</b> is provided to chroma amplitude equalizer <b>50</b> of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0035" num="0034">Multiplexer <b>428</b> is operative to output either the truncated signal provided from truncator <b>424</b> or a logic 0 signal responsive to an INHIBIT_COMB signal. Delay <b>430</b> is operative to apply a predetermined delay to the FILTER_IN_N<sub>&#x2014;</sub>1 signal to thereby generate a delayed signal. According to an exemplary embodiment, delay <b>430</b> is clocked in accordance with clock enabling signal VSO_B, and applies a delay of 32 clock cycles to the FILTER_IN_N<sub>&#x2014;</sub>1 signal. Multiplier <b>432</b> is operative to multiply the delayed signal provided from delay <b>430</b> by a value of 8 to thereby generate a multiplied signal. Adder <b>434</b> is operative to add the multiplied signal provided from multiplier <b>432</b> to a value of 1024 to thereby generate a sum signal. Limiter <b>436</b> is operative to limit the sum signal provided from adder <b>434</b> to a predetermined range of values, which may be matter of design choice.</p>
<p id="p-0036" num="0035">Multiplexer <b>438</b> is operative to output either the K_MOTION signal provided from motion detector <b>70</b> of <figref idref="DRAWINGS">FIG. 3</figref> or a logic 0 signal responsive to the MOTION_MARKERS signal provided from processor <b>20</b> of <figref idref="DRAWINGS">FIG. 2</figref>. Multiplier <b>440</b> is operative to multiply the output signal provided from multiplexer <b>438</b> by a value of 128 to thereby generate a multiplied signal. Minimizer <b>442</b> is operative to receive the output signal from limiter <b>436</b> and the multiplied signal from multiplier <b>440</b> and passes the signal having the lowest value. Subtractor <b>444</b> is operative to subtract the output signal of minimizer <b>442</b> and the output signal of multiplexer <b>428</b> from the multiplied signal provided from multiplier <b>432</b> to thereby generate a difference signal. Limiter <b>446</b> is operative to limit the difference signal provided from subtractor <b>444</b> to a predetermined range of values, which may be matter of design choice. D-type flip-flop <b>448</b> is operative to receive and output the output signal of limiter <b>444</b> in accordance with clock enabling signal VSO_B. The output signal from D-type flip-flop <b>448</b> is provided to luma delay <b>80</b> of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0037" num="0036">Vertical interval gate <b>450</b> is operative to detect the vertical blanking interval (VBI) of a video signal. According to an exemplary embodiment, vertical interval gate <b>450</b> outputs a logic 1 signal if the LINE_COUNT signal represents a value that is less than or equal to 20 or greater than or equal to 262. OR gate <b>452</b> is operative to logically OR the output signal of vertical interval gate <b>450</b> with the NO_BURST signal to thereby generate the INHIBIT_COMB signal which is provided to multiplexer <b>428</b>.</p>
<p id="p-0038" num="0037">In <figref idref="DRAWINGS">FIG. 4</figref>, it is noted that adder <b>434</b>, limiter <b>436</b>, and minimizer <b>442</b> are used to prevent the generation of a motion marking luminance signal (i.e., the output signal from D-type flip-flop <b>448</b>) that is darker than approximately 0 IRE. Accordingly, these elements of <figref idref="DRAWINGS">FIG. 4</figref> prevent the motion marking luminance signal from interfering with the operation of the sync separation circuitry of an NTSC decoder (not shown in FIGS.), and also causes the motion marking luminance signal to vary in proportion to the detected degree of motion in a video display. As used herein, the phrase &#x201c;in proportion to&#x201d; may for example refer to being directly proportional, inversely proportional, step-wise proportional, and/or otherwise proportional in a manner having more than 2 states.</p>
<p id="p-0039" num="0038">To facilitate a better understanding of the present invention, an example will now be provided. Referring to <figref idref="DRAWINGS">FIG. 5</figref>, a flowchart <b>500</b> illustrating steps according to an exemplary embodiment of the present invention is shown. For purposes of example and explanation, the steps of <figref idref="DRAWINGS">FIG. 5</figref> will be described with reference to video apparatus <b>100</b> described herein. The steps of <figref idref="DRAWINGS">FIG. 5</figref> are exemplary only, and are not intended to limit the present invention in any manner.</p>
<p id="p-0040" num="0039">At step <b>510</b>, video apparatus <b>100</b> enters a test mode. According to an exemplary embodiment, video apparatus <b>100</b> may enter the test mode at step <b>510</b> responsive to a predetermined sequence of key inputs provided by an application circuit designer via user input device <b>10</b>. The specific sequence of key inputs used to enter the test mode may be a matter of design choice. However, it is preferable that the sequence of key inputs be sufficiently complex and unique so that a consumer does not inadvertently enter the key input sequence while using user input device <b>10</b> to control video apparatus <b>100</b>. According to an exemplary embodiment, processor <b>20</b> of <figref idref="DRAWINGS">FIG. 2</figref> outputs the MOTION_MARKERS signal in a predetermined logic state to indicate entry of the test mode at step <b>510</b>. Video apparatus <b>100</b> may also enter the test mode at step <b>510</b> in other ways, such as by connecting it to an external computer (not shown in FIGS.) and entering one or more predetermined inputs via the external computer.</p>
<p id="p-0041" num="0040">At step <b>520</b>, a video test signal is applied to video apparatus <b>100</b>. According to an exemplary embodiment, a predetermined video test signal is applied to video apparatus <b>100</b> through one of its video inputs, and the video test signal causes video apparatus <b>100</b> to enable a video display corresponding to the video test signal. The specific type of video test signal used at step <b>520</b> may be a matter of design choice. However, according to an exemplary embodiment, it is preferable that the video test signal provide some degree of motion so that the application circuit designer can identify and select optimal control settings for motion detection.</p>
<p id="p-0042" num="0041">At step <b>530</b>, an application circuit designer selects the optimal control settings for motion detection. According to an exemplary embodiment, the application circuit designer provides inputs to video apparatus <b>100</b> via user input device <b>10</b> to thereby adjust the values of the DY_GAIN signal, the DY_CORING signal, the DC_GAIN signal, the DC_CORING signal, the BY_GAIN signal, and the BY_CORING signal output from processor <b>20</b> of <figref idref="DRAWINGS">FIG. 2</figref> and select the optimal control settings for motion detection at step <b>530</b>. As previously indicated herein, the foregoing signals represent control signals for motion detector <b>70</b> of <figref idref="DRAWINGS">FIG. 3</figref> according to an exemplary embodiment of the present invention. Of course, other control signals may be used according to the present invention, and the number of such control signals may be a matter of design choice.</p>
<p id="p-0043" num="0042">Also previously indicated herein, video apparatus <b>100</b> enables a video display including a first video attribute (e.g., luminance, etc.) that is readily discernible by a user from viewing the video display, and a second video attribute (e.g., motion, noise, etc.) that is not readily discernible by the user from viewing the video display. Moreover, the first video attribute varies in proportion to a detected degree of the second video attribute. Accordingly, the video display produced from the video test signal may include a degree of luminance that varies on a pixel-by-pixel basis in proportion to the detected degree of motion in the video display. This enables the application circuit designer to use the visually observed degree of luminance in the video display as an indicator of the degree of motion present in the video display. Using this video display, the application circuit designer may adjust and ultimately select at step <b>530</b> the values of the DY_GAIN signal, the DY_CORING signal, the DC_GAIN signal, the DC_CORING signal, the BY_GAIN signal, and the BY_CORING signal that he or she deems to produce the optimal video display.</p>
<p id="p-0044" num="0043">At step <b>540</b>, the application circuit designer records the optimal control settings selected at step <b>530</b>. According to an exemplary embodiment, the application circuit designer may record the optimal control settings at step <b>540</b> by simply writing down or otherwise recording the values for the DY_GAIN signal, the DY_CORING signal, the DC_GAIN signal, the DC_CORING signal, the BY_GAIN signal, and the BY_CORING signal that he or she deems to produce the optimal video display.</p>
<p id="p-0045" num="0044">At step <b>550</b>, the optimal control settings are programmed into processor <b>20</b> of video apparatus <b>100</b>. According to an exemplary embodiment, the optimal control settings are programmed into processor <b>20</b> at step <b>550</b> by programming the selected values for the DY_GAIN signal, the DY_CORING signal, the DC_GAIN signal, the DC_CORING signal, the BY_GAIN signal, and the BY_CORING signal into processor <b>20</b>. The programming of such values into processor <b>20</b> may be performed using conventional techniques which are known in the art.</p>
<p id="p-0046" num="0045">As described herein, the present invention provides an apparatus and method for enabling a video display that readily indicates the detected degree of a video attribute such as motion and/or other video attribute present in the video display. The present invention may be applicable to various apparatuses, either with or without a display device. Accordingly, the phrases &#x201c;video apparatus&#x201d; and &#x201c;television signal receiver&#x201d; as used herein may refer to systems or apparatuses including, but not limited to, television sets, computers or monitors that include a display device, and systems or apparatuses such as set-top boxes, VCRs, digital versatile disk (DVD) players, video game boxes, personal video recorders (PVRs), computers or other apparatuses that may not include a display device.</p>
<p id="p-0047" num="0046">While this invention has been described as having a preferred design, the present invention can be further modified within the spirit and scope of this disclosure. This application is therefore intended to cover any variations, uses, or adaptations of the invention using its general principles. Further, this application is intended to cover such departures from the present disclosure as come within known or customary practice in the art to which this invention pertains and which fall within the limits of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A video apparatus, comprising:
<claim-text>means for receiving video data, said video data comprising motion;</claim-text>
<claim-text>means for detecting said motion;</claim-text>
<claim-text>means for enabling a video display of a pixel within a location of said motion in response to said detected motion to indicate a location of said detected motion, said video display including a first video attribute and said motion, wherein said first video attribute includes luminance; and</claim-text>
<claim-text>wherein said first video attribute of said pixel varies in proportion to a detected degree of said detected motion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The video apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said video display enables selection of one or more control settings related to said detected motion.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A method for enabling a video display, comprising steps of:
<claim-text>receiving video data, said video data comprising motion;</claim-text>
<claim-text>detecting said motion;</claim-text>
<claim-text>enabling said video display of in a pixel within a location of said motion in response to said detected motion to indicate a location of said detected motion, said video display including a first video attribute and said motion, wherein said first video attribute includes luminance; and</claim-text>
<claim-text>wherein said first video attribute of said pixel varies in proportion to a detected degree of said detected motion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein said video display enables selection of one or more control settings related to said detected motion.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A television signal receiver, comprising:
<claim-text>first circuitry operative to receive video data and detect motion within said video data;</claim-text>
<claim-text>second circuitry operative to enable a video display of in a pixel within a location of said motion in response to said detected motion to indicate a location of said detected motion, said video display including a first video attribute and said motion, wherein said first video attribute includes luminance; and</claim-text>
<claim-text>wherein said first video attribute of said pixel varies in proportion to a detected degree of said detected motion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The television signal receiver of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein said video display enables selection of one or more control settings related to said detected motion. </claim-text>
</claim>
</claims>
</us-patent-grant>
