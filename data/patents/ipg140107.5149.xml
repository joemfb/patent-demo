<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626248-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626248</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13916400</doc-number>
<date>20130612</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>1</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>455566</main-classification>
<further-classification>345214</further-classification>
</classification-national>
<invention-title id="d2e51">Mobile device display management</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5586182</doc-number>
<kind>A</kind>
<name>Miyashita</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379413</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7042391</doc-number>
<kind>B2</kind>
<name>Meunier et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7302280</doc-number>
<kind>B2</kind>
<name>Hinckley et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7633076</doc-number>
<kind>B2</kind>
<name>Huppi et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7698719</doc-number>
<kind>B2</kind>
<name>Evans et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7702282</doc-number>
<kind>B2</kind>
<name>Sandegard et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7728316</doc-number>
<kind>B2</kind>
<name>Fadell et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>8170621</doc-number>
<kind>B1</kind>
<name>Lockwood</name>
<date>20120500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2003/0197597</doc-number>
<kind>A1</kind>
<name>Bahl et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2004/0233153</doc-number>
<kind>A1</kind>
<name>Robinson</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2006/0017692</doc-number>
<kind>A1</kind>
<name>Wehrenberg et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2006/0240866</doc-number>
<kind>A1</kind>
<name>Eilts</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4555561</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2008/0303681</doc-number>
<kind>A1</kind>
<name>Herz et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2009/0262078</doc-number>
<kind>A1</kind>
<name>Pizzi</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2010/0321321</doc-number>
<kind>A1</kind>
<name>Shenfield et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2011/0216093</doc-number>
<kind>A1</kind>
<name>Griffin</name>
<date>20110900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>U.S. Appl. No. 13/028,909, filed Feb. 16, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Non-Final Office Action from U.S. Appl. No. 13/028,909, dated Apr. 4, 2012, 16 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>Response to Non-Final Office Action from U.S. Appl. No. 13/028,909, filed Jul. 5, 2012, 8 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>International Search Report and Written Opinion of international application No. PCT/US2011/037342, mailed Jan. 19, 2012, 9 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>Notice of Allowance from U.S. Appl. No. 13/028,909, dated Jul. 19, 2012, 9 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>Notice of Allowance from U.S. Appl. No. 13/250,870, dated Jan. 3, 2012, 9 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00023">
<othercit>Notice of Allowance from U.S. Appl. No. 13/656,019, dated Mar. 4, 2013, 19 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00024">
<othercit>U.S. Appl. No. 13/656,019, filed Oct. 19, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>U.S. Appl. No. 13/250,870, filed Sep. 30, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Patent Examination Report No. 1 from corresponding Australian application No. 2011359371, dated Aug. 23, 2013, 3 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>International Preliminary Report on Patentability and Written Opinion from corresponding International application No. PCT/US2011/037342, dated Aug. 29, 2013, 6 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Response to Patent Examination Report No. 1, dated Aug. 23, 2013, from corresponding Australian application No. 2011359371, filed Sep. 3, 2013, 16 pp.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>21</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>455566</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>13656019</doc-number>
<date>20121019</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8478353</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13916400</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>13028909</doc-number>
<date>20110216</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8320970</doc-number>
<date>20121127</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13656019</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130281163</doc-number>
<kind>A1</kind>
<date>20131024</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Google Inc.</orgname>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Lockwood</last-name>
<first-name>Michael</first-name>
<address>
<city>Lexington</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Shumaker &#x26; Sieffert, P.A.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Google Inc.</orgname>
<role>02</role>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Beamer</last-name>
<first-name>Temica M</first-name>
<department>2646</department>
</primary-examiner>
<assistant-examiner>
<last-name>Ajayi</last-name>
<first-name>Joel</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The display of a mobile device is managed during a voice communication session using a proximity sensor and an accelerometer. In one example, the display of a mobile device is turned off during a phone call on the mobile device when a proximity sensor detects an object is proximate the device and an accelerometer determines the device is in a first orientation.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="143.00mm" wi="102.28mm" file="US08626248-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="152.91mm" wi="111.00mm" file="US08626248-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="250.53mm" wi="176.45mm" orientation="landscape" file="US08626248-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.87mm" wi="186.61mm" orientation="landscape" file="US08626248-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="229.19mm" wi="180.59mm" file="US08626248-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="212.85mm" wi="209.21mm" file="US08626248-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="206.93mm" wi="192.62mm" file="US08626248-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="213.53mm" wi="185.93mm" file="US08626248-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="239.86mm" wi="169.33mm" orientation="landscape" file="US08626248-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 13/656,019, filed Oct. 19, 2012, which is a continuation of U.S. application Ser. No. 13/028,909, filed Feb. 16, 2011 know U.S. Pat. No. 8,320,970), the entire contents of each of which is incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Mobile devices provide the benefit of being portable while allowing a user to perform a variety of functions including various forms of communication and computing. For example, some mobile devices are capable of accessing the Internet, executing gaming applications, playing videos and music, as well as providing functionality of a traditional mobile, e.g. cellular, phone. As mobile devices are not tethered to a physical communication medium or stationary power source, such devices are generally powered by a rechargeable battery. A persistent challenge in mobile device design is increasing the length of time the device may operate without recharging the battery.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0004" num="0003">In general, this disclosure is directed to techniques for managing the display of a mobile device during a voice communication session, e.g. during a phone call. In one example, a method includes detecting, during a phone call on a mobile device, an object proximate the mobile device using a proximity sensor of the mobile device, determining, during the phone call, the mobile device is in a first orientation using an accelerometer of the mobile device, and turning off a display of the mobile device during the phone call in response to detecting the object proximate the mobile device and detecting the mobile device is in the first orientation.</p>
<p id="p-0005" num="0004">In another example, a mobile device includes a display, a proximity sensor, and an accelerometer. The proximity sensor is configured to detect an object proximate to the mobile device. The accelerometer is configured to determine an orientation of the mobile device. The device also includes means for turning off the display of the mobile device during a phone call on the mobile device in response to the proximity sensor detecting the object is proximate the mobile device and the accelerometer determining the mobile device is in a first orientation.</p>
<p id="p-0006" num="0005">In another example, a computer readable storage medium includes instructions for causing a programmable processor to turn off a display of a mobile device during a phone call on the mobile device in response to a proximity sensor of the mobile device detecting an object proximate to the mobile device and an accelerometer of the mobile device determining the mobile device is in a first orientation.</p>
<p id="p-0007" num="0006">The details of one or more embodiments of the disclosure are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the disclosure will be apparent from the description and drawings, and from the claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> is a plan view of an example mobile device in accordance with various aspects of this disclosure.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example frame of reference in which an accelerometer of the mobile device of <figref idref="DRAWINGS">FIG. 1</figref> may detect the orientation of the device.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating an example of the mobile device of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating an example method of managing the display of a mobile device during a phone call.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an example orientation vector of a mobile device detected by an accelerometer.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. 6 and 7</figref> are flowcharts illustrating examples of additional functions associated with managing the display of a mobile device during a phone call.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. 8A and 8B</figref> are plan views of two alternative example mobile devices in accordance with this disclosure.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0015" num="0014">This disclosure is directed to techniques for managing the state of a display of a mobile device during a voice communication session, e.g. during a phone call. The disclosure includes techniques for using a proximity sensor and an accelerometer to manage the mobile device display and only turn off the display during phone calls if the proximity sensor is active and the accelerometer indicates the mobile device is being held in a particular orientation.</p>
<p id="p-0016" num="0015">Mobile device displays, e.g. mobile phone displays are often a significant source of power drain on the battery of the phone. As such, disabling the display, e.g. turning the display off, whenever it is not in use, may extend the battery life of the phone, which may, in turn, increase the use of the phone and improve user experience. Some current mobile phones employ a proximity sensor to manage a mobile phone display while in call. For example, when in a call, an algorithm may force the display to turn off when the proximity sensor detects that an object (e.g. user's head) is close to the phone. However, this approach may cause problems if the user attempts to use other features of the phone while in a call. For example, the proximity sensor of a mobile phone may be located proximate the top left of the mobile phone display. If, for example, a user of the mobile phone wants to look up something in email while in a call, the user's finger may trigger the proximity sensor, which may cause the display to turn off while the user is attempting view information and execute functions on the phone.</p>
<p id="p-0017" num="0016">In order to address the foregoing issues, the examples included in this disclosure use both the proximity sensor and an accelerometer. In such examples, a mobile device, e.g. a mobile phone only turns off the phone display if the proximity sensor detects an object proximate the phone and the accelerometer indicates the phone is being held in a particular orientation, e.g., a vertical orientation. Such a vertical orientation can occur if the phone is being held up against the user's head. Additionally, under certain circumstances, if the phone is being held close to another orientation, e.g., a horizontal orientation, which can occur during a phone call, under common usage circumstances it may be assumed that the user is trying to access functions on the phone while in the call and ignore proximity sensor signals such that the display remains on until the phone is held upright again.</p>
<p id="p-0018" num="0017">In one example, after a call is initiated on a mobile phone, a display management algorithm may detect whether there is an object proximate the phone with a proximity sensor and determine the orientation of the phone with an accelerometer. If the proximity sensor is active, indicating that the phone is within some threshold distance from another object (presumably a part of the user's body), and if the accelerometer indicates that the phone is, e.g. vertical, then the display management algorithm will turn off the display. Thereafter, if the foregoing process has occurred to turn off the display during a phone call, the display management algorithm may turn on the phone display regardless of the behavior of proximity sensor when the accelerometer indicates the phone moves to, e.g. a horizontal or near horizontal position. Thus, the algorithm infers that the user has, while still in the phone call, moved the phone from the head into a horizontal position to access phone functions and therefore needs the phone display turned on.</p>
<p id="p-0019" num="0018">The following examples describe the use of a proximity sensor to detect when objects are proximate a mobile phone. The term proximate refers to a distance between the mobile phone and another object that is within the sensing range of a proximity sensor included in the phone such that when the object is proximate the mobile phone, the proximity sensor is activated. Additionally, the disclosed examples describe the use of an accelerometer to determine the orientation of a mobile phone. In some examples, specific orientations are described, including, e.g. horizontal and vertical. While the terms horizontal and vertical, as well as other designations of orientation, may be relative, in the disclosed examples such designations may refer to specific orientations of a mobile phone relative to the earth. For example, vertical may refer to a direction that is approximately perpendicular to the earth and horizontal may refer to a direction that is approximately parallel to the earth. Additionally, specific orientation designations may not, in the disclosed examples, necessarily be exact. For example, a vertical orientation may refer to a mobile phone that is oriented approximately vertical, where the approximation may be defined by a specific tolerance within which the phone's orientation must lie to designate the phone in the vertical orientation. Specific examples of determining the orientation of a mobile phone, including the use of approximations of different orientations are described in more detail below.</p>
<p id="p-0020" num="0019">Although the following examples are described with reference to an accelerometer determining a mobile phone in vertical and horizontal orientations as a basis for managing the display of the phone, other orientations of the phone may form the basis for triggering different states of the display. For example, the phone may turn off the display in response to, among other parameters, an accelerometer determining that the phone is in a horizontal orientation and may turn the display back on in response to the accelerometer determining the phone is in a vertical orientation. More generally, a mobile phone in accordance with this disclosure may turn off the display of the phone during a voice communication session, e.g. during a phone call when a proximity sensor detects an object proximate the phone and an accelerometer determines the phone is in a first orientation.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 1</figref> is a plan view of example mobile phone <b>10</b> including housing <b>12</b>, display <b>14</b>, a user interface, including keypad <b>16</b> and soft keys <b>18</b>, speaker <b>20</b>, microphone <b>22</b>, external antenna <b>24</b>, proximity sensor <b>26</b>, and accelerometer <b>28</b>. As illustrated in <figref idref="DRAWINGS">FIGS. 8A and 8B</figref> described below, example mobile devices according to this disclosure may include a number of different styles and forms than that of example mobile phone <b>10</b> of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0022" num="0021">In <figref idref="DRAWINGS">FIG. 1</figref>, display <b>14</b> is positioned at an upper half of housing <b>12</b> of mobile phone <b>10</b>. Display <b>14</b> may include any one or more of a liquid crystal display (LCD), dot matrix display, light emitting diode (LED) display, organic light-emitting diode (OLED) display, touch screen, e-ink, or similar monochrome or color display capable of providing visible information to users of mobile phone <b>10</b>. Display <b>14</b> may provide a user interface related to functionality provided by mobile phone <b>10</b>. For example, display <b>14</b> may present a user with an address book stored on mobile phone <b>10</b>, which includes a number of contacts. In another example, display <b>14</b> may present the user with a menu of options related to the function and operation of mobile phone <b>10</b>, including, e.g. phone settings such as ring tones and phone modes, e.g. silent, normal, meeting, and other configurable settings for the phone.</p>
<p id="p-0023" num="0022">Keypad <b>16</b> is in a bottom half of housing <b>12</b>. In one example, keypad <b>16</b> is an alphanumeric keypad that users may employ to enter phone numbers, contacts, and other information for use with mobile phone <b>10</b>. Soft keys <b>18</b> are positioned adjacent and below display <b>14</b>. In one example, soft keys <b>18</b> may be configured to execute different functions on mobile phone <b>10</b> based on, e.g., current functions and contexts indicated on display <b>14</b>. For example, one of soft keys <b>18</b> may correspond to a menu key as a default option, from which a number of different functional options available on mobile phone <b>10</b> may be selected, e.g. looking up a contact in an address book stored on the phone. In one example, once soft key <b>18</b> is selected to retrieve the address book and a contact is located, the same soft key may change from a menu option to one of a number of options for interacting with the contact data, e.g. editing the information for the contact in the address book stored on mobile phone <b>10</b>.</p>
<p id="p-0024" num="0023">Mobile phone <b>10</b> also includes speaker <b>20</b> and microphone <b>22</b>, which may function to emit audible sounds to and receive audible input from users, respectively. For example, speaker <b>20</b> may be configured to emit the voice of a person calling mobile phone <b>10</b> and microphone <b>22</b> may be configured to receive the voice of the user of mobile phone <b>10</b> to be transmitted to the person calling mobile phone <b>10</b>. In <figref idref="DRAWINGS">FIG. 1</figref>, speaker <b>20</b> toward the top of housing <b>12</b> above display <b>14</b>. Microphone <b>22</b>, on the other hand, is arranged toward the bottom of housing <b>12</b> below keypad <b>16</b>. In this manner, the positions of speaker <b>20</b> and microphone <b>22</b> may generally correspond to a user's ear and mouth, respectively. In other examples, however, speaker <b>20</b> and microphone <b>22</b> may be arranged in other locations on housing <b>12</b>.</p>
<p id="p-0025" num="0024">Antenna <b>24</b> of mobile phone <b>10</b> extends up from the top of housing <b>12</b>. However, in another example, antenna <b>24</b> may extend from a different portion of housing <b>12</b> or may form part of the housing. Additionally, in some example mobile devices according to this disclosure, the antenna of the device may be internal and thus not visibly extending from any part of the device housing. Antenna <b>24</b> may function to facilitate communications between mobile phone <b>10</b> and other devices, e.g. other mobile devices, remote service provider networks and computing devices, and the like. As such, in one example, antenna <b>24</b> may be any of a number of radio frequency (RF) antennas appropriate for use with mobile devices and configured to transmit and receive RF communications, including, e.g., telephone calls transmitted over a cellular network.</p>
<p id="p-0026" num="0025">Mobile phone <b>10</b> includes proximity sensor <b>26</b> and accelerometer <b>28</b>. Proximity sensor <b>26</b> is arranged toward an upper corner of mobile phone <b>10</b> within housing <b>12</b>. Accelerometer <b>28</b> is arranged toward a lower corner of mobile phone <b>10</b>, also within housing <b>12</b>. Proximity sensor <b>26</b> and accelerometer <b>28</b> may be arranged in a number of different locations with respect to mobile phone <b>10</b> in other examples according to this disclosure. Additionally, in other examples, one or both of proximity sensor <b>26</b> and accelerometer <b>28</b> may not be arranged within housing <b>12</b>. For example, proximity sensor <b>26</b> may be connected to housing <b>12</b> and be arranged such that at least part of the sensor lies outside of the housing.</p>
<p id="p-0027" num="0026">Proximity sensor <b>26</b> and accelerometer <b>28</b>, along with, e.g. a processor of mobile phone <b>10</b>, may be configured to act together to manage display <b>14</b> during a phone call made with mobile phone <b>10</b>. In one example, after a phone call is initiated on mobile phone <b>10</b>, either an outgoing call made to or an incoming call received by the phone, proximity sensor <b>26</b> may be employed to detect the presence of an object proximate to mobile phone <b>10</b>. For example, proximity sensor <b>26</b> may be configured such that the sensor is activated when an object is within a threshold distance from the sensor.</p>
<p id="p-0028" num="0027">In addition to proximity sensor <b>26</b> detecting an object proximate mobile phone <b>10</b>, accelerometer <b>28</b> may determine the orientation, e.g. horizontal or vertical, of the mobile phone during the phone call. In one example, mobile phone <b>10</b> may be configured to turn off display <b>14</b> when proximity sensor <b>26</b> detects an object proximate the mobile phone and accelerometer <b>28</b> determines that the phone is in an approximately vertical orientation. The manner in which a proximity sensor and accelerometer function in a mobile phone to manage the display of the phone during a voice communication session in examples according to this disclosure is described in greater detail with reference to the example method of <figref idref="DRAWINGS">FIG. 4</figref> below.</p>
<p id="p-0029" num="0028">As noted above, while the terms horizontal and vertical, as well as other designations of orientation, may be relative, in the disclosed examples such designations may refer to specific orientations of a mobile phone relative to the earth. An example frame of reference in which accelerometer <b>28</b> may determine the orientation of mobile phone <b>10</b> is illustrated in <figref idref="DRAWINGS">FIG. 2</figref>. In one example, accelerometer <b>28</b> may be configured to determine the orientation of mobile phone <b>10</b> in a reference Cartesian coordinate system illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, in which the Z axis is parallel to gravity vector, G, and the X and Y axes are generally parallel to ground <b>25</b>, which may be the earth, and perpendicular to each other and to the Z axis. In the example frame of reference of <figref idref="DRAWINGS">FIG. 2</figref>, vertical generally corresponds to an orientation that is parallel to gravity, G, but in the opposite direction, i.e. directed away from instead of toward ground <b>25</b>.</p>
<p id="p-0030" num="0029">In the example of <figref idref="DRAWINGS">FIG. 2</figref>, the orientation of mobile phone <b>10</b> determined by accelerometer <b>28</b> is represented by orientation vector, V<sub>phone</sub>. The manner in which the orientation of mobile phone <b>10</b> represented by vector V<sub>phone </sub>is determined based on signals generated by accelerometer <b>28</b> is described in greater de a below. However, in the example of <figref idref="DRAWINGS">FIG. 2</figref>, mobile phone <b>10</b> is represented in two different orientations in position <b>27</b> and <b>29</b>, respectively. In position <b>27</b>, accelerometer <b>28</b> determines the orientation of mobile phone <b>10</b> represented by vector, V<sub>phone</sub>, as approximately equal to vertical. In position <b>29</b>, on the other hand, accelerometer <b>28</b> determines the orientation of mobile phone <b>10</b> represented by vector, V<sub>phone</sub>, as approximately equal to horizontal.</p>
<p id="p-0031" num="0030">The example of <figref idref="DRAWINGS">FIG. 2</figref> is meant to illustrate a frame of reference in which the orientation of mobile phone <b>10</b> may be identified by relative terms, such as vertical and horizontal. In some examples according to this disclosure, the frame of reference in which an accelerometer determines the orientation of a mobile device, e.g. a mobile phone in order to manage the display of the phone during a phone call may differ from that shown in <figref idref="DRAWINGS">FIG. 2</figref>. However, the examples described below include accelerometers that determine orientations in a frame of reference in accordance with the example of <figref idref="DRAWINGS">FIG. 2</figref>. Thus, vertical and horizontal in such examples correspond to orientations that are treated as generally parallel to gravity and perpendicular to the ground and generally perpendicular to gravity and parallel to the ground, respectively. However, in practice, the orientation of mobile phone <b>10</b> may not be exactly or nearly exactly vertical or horizontal as represented by vector, V<sub>phone</sub>, in positions <b>27</b> and <b>29</b> in <figref idref="DRAWINGS">FIG. 2</figref>. Thus, <figref idref="DRAWINGS">FIG. 5</figref> and the associated description provided below illustrate how the orientation of a mobile phone may be determined with an accelerometer when the phone is only approximately vertical or horizontal, e.g. as defined in the example of <figref idref="DRAWINGS">FIG. 2</figref>, by employing a range of orientations within which the phone's orientation vector as determined by the accelerometer may lie to designate the phone in a particular orientation.</p>
<p id="p-0032" num="0031">In some examples, mobile phone <b>10</b>, or another mobile device according to this disclosure, may include more sensors than just proximity sensor <b>26</b> and accelerometer <b>28</b>. For example, a mobile device according to this disclosure may include multiple accelerometers. Additionally, a mobile device according to this disclosure may include a number of sensors for operating a touch-screen display that is configured to receive tactile input from a user to execute functions on the phone.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating example mobile phone <b>10</b> including processor <b>30</b>, storage device <b>32</b>, display <b>14</b>, user interface <b>36</b>, e.g. including keypad <b>16</b> and soft keys <b>18</b>, telemetry module <b>38</b>, including, e.g., antenna <b>24</b>, battery <b>40</b>, speaker <b>20</b>, microphone <b>22</b>, proximity sensor <b>26</b>, and accelerometer <b>28</b>. Processor <b>30</b>, generally speaking, is communicatively coupled to and controls operation of storage device <b>32</b>, display <b>14</b>, user interface <b>36</b>, and telemetry module <b>38</b>, all of which are powered by rechargeable battery <b>40</b>. Processor <b>30</b> may also be configured to execute one or more of the functions associated with managing display <b>14</b> based on information provided by proximity sensor <b>26</b> and accelerometer <b>28</b>.</p>
<p id="p-0034" num="0033">Processor <b>30</b> may include any one or more of a microprocessor, a controller, a digital signal processor (DSP), an application specific integrated circuit (ASIC), a field-programmable gate array (FPGA), or equivalent discrete or integrated logic circuitry. The functions attributed to processor <b>30</b> in this disclosure may be embodied as software, firmware, hardware and combinations thereof. Although example mobile phone <b>10</b> of <figref idref="DRAWINGS">FIG. 3</figref> is illustrated as including one processor <b>30</b>, other example mobile devices according to this disclosure may include multiple processors that are configured to execute one or more functions attributed to processor <b>30</b> of mobile phone <b>10</b> individually or in different cooperative combinations.</p>
<p id="p-0035" num="0034">Storage device <b>32</b> stores instructions for applications that may be executed by processor <b>30</b> and data used in such applications or collected and stored for use outside of mobile phone <b>10</b>, e.g. object proximity and phone orientation data. For example, storage device <b>32</b> may store instructions executable by processor <b>30</b> for managing display <b>14</b> based on information provided by proximity sensor <b>26</b> and accelerometer <b>28</b>. Storage device <b>32</b> may be a computer-readable, machine-readable, or processor-readable storage medium that comprises instructions that cause one or more processors, e.g., processor <b>30</b>, to perform various functions. Storage device <b>32</b> may include any volatile, non-volatile, magnetic, optical, or electrical media, such as a random access memory (RAM), read-only memory (ROM), non-volatile RAM (NVRAM), electrically-erasable programmable ROM (EEPROM), flash memory, or any other digital media. Generally speaking, storage device <b>32</b> may include instructions that cause processor <b>30</b> to perform various functions attributed to the processor in the disclosed examples.</p>
<p id="p-0036" num="0035">Generally speaking, storage device <b>32</b> includes memory that stores software that may be executed by processor <b>30</b> to perform various functions for a user of mobile phone <b>10</b>, including, e.g., making and receiving cellular telephone calls or other communications like text or e-mail messages, using various software applications. The software included in mobile phone <b>10</b> may include telemetry and other hardware drivers for the mobile phone, operating system software, as well as a number of third-party applications. The operating system software of mobile phone <b>10</b> may be, e.g. Linux software or another UNIX based system software. In another example, the operating system software of mobile phone <b>10</b> may be Google's Android. In another example, mobile phone <b>10</b> may include proprietary operating system software not based on an open source platform like UNIX or Android. Mobile phone <b>10</b> also includes various applications <b>42</b> stored on storage device <b>32</b> and executed by processor <b>30</b>, including, e.g., e-mail, calendar, contact management, and web browser applications, as well as various types of third-party vendor applications bundled with the phone.</p>
<p id="p-0037" num="0036">Operation of mobile phone <b>10</b> may require, for various reasons, receiving data from one or more sources including, e.g. application data stored on an application server remote from the phone, as well as transmitting data or other signals from the phone to an external source, e.g. transmitting a user's voice during a phone call to another mobile phone. Data communications to and from mobile phone <b>10</b> may be handled by telemetry module <b>38</b>. Telemetry module <b>38</b> is configured to transmit data/requests to and receive data/responses from one or more external sources via, e.g. a cellular network. Telemetry module <b>38</b> may support various wireless communication techniques and protocols, and includes appropriate hardware and software to provide such communications. For example, telemetry module <b>38</b> may include external antenna <b>24</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>, as well as modulators, demodulators, amplifiers, and other circuitry to effectuate communication between mobile phone <b>10</b> and other devices via, e.g., a cellular network.</p>
<p id="p-0038" num="0037">Mobile phone <b>10</b> includes display <b>14</b>, which may be, e.g., a liquid crystal display (LCD), dot matrix display, light emitting diode (LED) display, organic light-emitting diode (OLED) display, touch screen, e-ink, or other display. Display <b>14</b> presents the content of mobile phone <b>10</b> to a user. For example, display <b>14</b> may present the applications executed on phone <b>10</b> such as an e-mail or calendar application, as well as information about the mobile phone, including, e.g., battery life and/or network signal strength.</p>
<p id="p-0039" num="0038">User interface <b>36</b> allows a user of mobile phone <b>10</b> to interact with the phone via one or more input mechanisms, including keypad <b>16</b> and soft keys <b>18</b>, as well as, e.g., a mouse, a roller ball, buttons, scroll wheel, touch pad, touch screen, or other devices or mechanisms that allow the user to interact with the phone. In some examples, user interface <b>36</b> may also include microphone <b>22</b> to allow a user to provide voice commands. Users may interact with user interface <b>36</b> and/or display <b>14</b> to execute one or more applications stored on storage device <b>32</b> and executed by processor <b>30</b>. Some applications may be executed automatically by mobile phone <b>10</b>, e.g. by processor <b>30</b>, such as when the phone is turned on or booted up. Additionally, in some examples, users may interact with user interface <b>36</b> to configure application data and to execute functions of applications stored on storage device <b>32</b>.</p>
<p id="p-0040" num="0039">Battery <b>40</b> provides power for all if the various components of mobile phone <b>10</b>, and may be rechargeable. Examples of battery <b>40</b> include a lithium polymer battery, a lithium ion battery, nickel cadmium battery, and a nickel metal hydride battery. The life of battery <b>40</b> of mobile phone <b>10</b> depends on many factors. Generally speaking, e.g., the life of battery <b>40</b> is affected by loads on the battery caused by using either software or hardware components of mobile phone. As different components of mobile phone <b>10</b>, both different hardware and different software components, draw different amounts of power, the load on battery <b>40</b> may vary according to component usage patterns. For example, a backlight for display <b>14</b> may draw more power than accelerometer <b>28</b> such that the life of battery <b>40</b> of mobile phone <b>10</b> may decrease significantly with increased backlight usage, while being less impacted by increased usage of the accelerometer. In another example, the network access state of mobile phone <b>10</b>, e.g. 3G access, may require more power than another network access state, e.g. Wi-Fi access.</p>
<p id="p-0041" num="0040">Display <b>14</b> of mobile phone <b>10</b> may draw a significant amount of power from battery <b>14</b> when the display is turned on. As such, disabling display <b>14</b>, e.g. turning the display off whenever it is not in use may extend the life of battery <b>40</b>, which may, in turn, increase the use of mobile phone <b>10</b> and improve user experience. As such, mobile phone <b>10</b> includes proximity sensor <b>26</b> and accelerometer <b>28</b>, which may be configured, in conjunction with, e.g. processor <b>30</b> to manage display <b>14</b> while mobile phone <b>10</b> is in a call. Proximity sensor <b>26</b> and accelerometer <b>28</b>, along with, e.g. processor <b>30</b> of mobile phone <b>10</b>, may be configured to act together to manage display <b>14</b> during a phone call made with mobile phone <b>10</b>. In one example, after a phone call is initiated on mobile phone <b>10</b>, either an outgoing call made to or an incoming call received by the phone, proximity sensor <b>26</b> may be employed to detect the presence of an object proximate to mobile phone <b>10</b>, e.g. the presence of a user's hand or head proximate the phone. For example, proximity sensor <b>26</b> may be configured such that the sensor is activated when an object is within a threshold distance from the sensor.</p>
<p id="p-0042" num="0041">Proximity sensor <b>26</b> of mobile phone <b>10</b> may be any of a number of types of sensors that are configured to detect the presence of objects nearby mobile phone <b>10</b> without any physical contact. Proximity sensor <b>26</b> may include, e.g., a capacitive, photoelectric, or inductive sensor. In one example, proximity sensor <b>26</b> may emit a beam of electromagnetic radiation, e.g. infrared, and detect a return signal after the beam bounces off an object near mobile phone <b>10</b>. In another example, proximity sensor <b>26</b> may emit an electromagnetic or electrostatic field and detect changes in the field as an object proximate mobile phone <b>10</b> enters the field emitted by the sensor. Proximity sensor <b>26</b> may be configured to sense objects up to a maximum distance from mobile phone <b>10</b>, which, in this disclosure, may be referred to as the range of the sensor or as a threshold distance at or within which the sensor detects an object proximate the phone. In one example, the range of proximity sensor <b>26</b> may be adjustable. In any event, proximity sensor <b>26</b> may be configured to detect an object when the object is within the range of the sensor, i.e. when the object is a threshold distance away from mobile phone <b>10</b>. In one example, proximity sensor is configured to detect an object when the object is a threshold distance that is greater than or equal to approximately 5 centimeters (cm) away from mobile phone <b>10</b>.</p>
<p id="p-0043" num="0042">In addition to proximity sensor <b>26</b> detecting an object proximate mobile phone <b>10</b>, accelerometer <b>28</b> may determine the orientation, e.g. horizontal or vertical, of the mobile phone during the phone call. In one example, processor <b>30</b> of mobile phone <b>10</b> may be configured to turn off display <b>14</b> when proximity sensor <b>26</b> detects an object proximate the mobile phone, e.g. the head of a user of the phone and accelerometer <b>28</b> determines that the phone is in an approximately vertical orientation. Accelerometer <b>28</b> may include, e.g., a three-axis accelerometer, capable of determining static orientation or vectors in three-dimensions. In one example, accelerometer <b>28</b> includes a micro-electro-mechanical accelerometer. In another example, accelerometer <b>28</b> may include a piezoelectric or capacitive accelerometer. In other examples, accelerometer <b>28</b> may be any other type of accelerometer capable of determining the orientation of mobile phone <b>10</b>. Additionally, in some examples, mobile devices in accordance with this disclosure may employ other types of devices in addition to or in lieu of an accelerometer to determine orientation, including, e.g., gyroscopes, pressure transducers or other devices capable of determining the orientation of the mobile device.</p>
<p id="p-0044" num="0043">In the foregoing manner, proximity sensor <b>26</b> and accelerometer <b>28</b> may be employed to infer that the user of mobile phone <b>10</b> has, after initiating a phone call, raised the phone to the user's head to listen and talk to another person using the phone. In such circumstances, display <b>14</b> may be unnecessary and, thus, may be turned off to extend the life of battery <b>40</b>, as well as reduce the risk of the user's head inadvertently triggering functions of the phone in examples in which display <b>14</b> is a touch-screen. Additionally, by employing a proximity sensor <b>26</b> and accelerometer <b>28</b>, mobile phone <b>10</b> may be capable of distinguishing between the foregoing use-case and one in which the user's hand triggers proximity sensor <b>26</b> when, e.g. the user holds the phone out in front of their body to access other functions while in the phone call, e.g. to look-up a contact in an address book stored on storage device <b>32</b>. In this circumstance, the user of mobile phone <b>10</b> may need display <b>14</b> active, e.g. turned on in order to access functionality on the phone. The manner in which a proximity sensor and accelerometer function in a mobile device to manage the display of the device during a phone call in these and other use-case examples is described in greater detail with reference to the example method of <figref idref="DRAWINGS">FIG. 4</figref> below.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating an example method of managing a display of mobile phone during a phone call. The method of <figref idref="DRAWINGS">FIG. 4</figref> includes initiating a phone call using a mobile phone (<b>50</b>), detecting an object proximate the mobile phone using a proximity sensor (<b>52</b>), determining an orientation of the mobile phone as approximately vertical using an accelerometer (<b>54</b>), and turning off a display of the mobile phone (<b>56</b>).</p>
<p id="p-0046" num="0045">The functions of the method of <figref idref="DRAWINGS">FIG. 4</figref> for managing a display of a mobile phone while in a phone call are described below as carried out by various components of example mobile phone <b>10</b>, and, in particular, proximity sensor <b>26</b>, accelerometer <b>28</b>, and processor <b>30</b> of the mobile phone for purposes of illustration only. In other examples, one or more of the functions of the method of <figref idref="DRAWINGS">FIG. 4</figref> may be carried out by other devices or systems that differ from mobile phone <b>10</b> in constitution and arrangement. For example, the method of <figref idref="DRAWINGS">FIG. 4</figref> may be executed in whole or in part by a different type of mobile phone, including, e.g. a mobile phone including a touch-screen display. Additionally, the method of <figref idref="DRAWINGS">FIG. 4</figref> may be executed by a mobile phone including more than a proximity sensor and accelerometer, including, e.g., a phone that employs a number of sensors to operate a large touch-screen display. Finally, although the example is described with reference to an accelerometer determining a mobile phone in vertical and horizontal orientations as a basis for managing the display of the phone, other orientations of the phone may form the basis for triggering different states of the display. For example, the phone may turn off the display in response to, among other parameters, an accelerometer determining that the phone is in a horizontal orientation and may turn the display back on in response to the accelerometer determining the phone is in a vertical orientation.</p>
<p id="p-0047" num="0046">The example method of <figref idref="DRAWINGS">FIG. 4</figref> includes initiating a phone call using a mobile phone (<b>50</b>). In one example, a phone call is initiated on mobile phone <b>10</b>. For example, a user of mobile phone <b>10</b> may initiate an outgoing phone call to another person, e.g. over a cellular network over which the mobile phone is configured to communicate. In another example, the user of mobile phone <b>10</b> may receive and accept a phone call on the mobile phone from another person.</p>
<p id="p-0048" num="0047">After initiating a phone call on mobile phone <b>10</b>, the user of the mobile phone may behave in a number of ways while on the call. For example, the user may hold mobile phone <b>10</b> up to their head to listen and talk to the other person on the phone call. In another example, however, the user of mobile phone <b>10</b> may hold the phone out in front of their body to, e.g., access other functions on the phone while in the call, including, e.g., looking up a contact in an address book stored on storage device <b>32</b>. Additionally, in one example, the user may first hold mobile phone <b>10</b> up to their head to listen and talk and, later in the phone call, hold the phone out in front of their body to access other functions on the phone. In these and other use-case examples, as illustrated by the example method of <figref idref="DRAWINGS">FIG. 4</figref>, mobile phone <b>10</b> is equipped with proximity sensor <b>26</b> and accelerometer <b>28</b> to manage the operation of display <b>14</b> during a phone call.</p>
<p id="p-0049" num="0048">The method of <figref idref="DRAWINGS">FIG. 4</figref> also includes detecting an object proximate a mobile phone using a proximity sensor (<b>52</b>). In one example, after a phone call is initiated using mobile phone <b>10</b> (<b>54</b>), either an outgoing call made to or an incoming call received by the phone, proximity sensor <b>26</b> may be employed to detect the presence of an object proximate to mobile phone <b>10</b>, e.g. the presence of a user's hand or head proximate the phone. For example, proximity sensor <b>26</b> may be configured such that the sensor is activated when an object is within a threshold distance from the sensor. Proximity sensor <b>26</b> of mobile phone <b>10</b> may be any of a number of types of sensors that are configured to detect the presence of objects nearby mobile phone <b>10</b> without any physical contact, including, e.g., a capacitive, photoelectric, or inductive sensor. Proximity sensor <b>26</b> may be configured to sense objects up to a maximum distance from mobile phone <b>10</b>, which, in this disclosure, may be referred to as the range of the sensor or as a threshold distance at or within which the sensor detects an object proximate the phone.</p>
<p id="p-0050" num="0049">As noted above, in prior mobile phones employing proximity sensors, the display of the phone may be turned off responsive only to a proximity sensor. In other words, in the event a proximity sensor detected an object proximate the phone during a call, the phone assumed the object was the user's head and turned off the display. However, in some circumstances, the object proximate the phone may be the user's finger as the user, e.g. quickly looks up something in email while in a call, which may cause the display to turn off while the user is attempting view information and execute functions on the phone. As such, examples according to this disclosure include managing the display of a mobile phone by employing a proximity sensor in conjunction with an accelerometer to determine the orientation of the mobile phone in addition to the presence of an object proximate the phone.</p>
<p id="p-0051" num="0050">In addition to detecting an object proximate a mobile phone using a proximity sensor (<b>52</b>), the example of <figref idref="DRAWINGS">FIG. 4</figref> includes determining an orientation of the mobile phone as approximately vertical using an accelerometer (<b>54</b>). In one example, accelerometer <b>28</b> may determine the orientation of mobile phone <b>10</b> as vertical during the phone call. Accelerometer <b>28</b> may include, e.g., a three-axis accelerometer, capable of determining static orientation or vectors in three-dimensions. In one example, accelerometer <b>28</b> includes a micro-electro-mechanical accelerometer. In another example, accelerometer <b>28</b> may include a piezoelectric or capacitive accelerometer. In other examples, accelerometer <b>28</b> may be any other type of accelerometer capable of determining the orientation of mobile phone <b>10</b>.</p>
<p id="p-0052" num="0051">As noted above, in practice, the orientation of mobile phone <b>10</b> determined by accelerometer <b>28</b> may not be exactly or nearly exactly vertical, e.g. as represented by vector, V<sub>phone</sub>, in position <b>27</b> in <figref idref="DRAWINGS">FIG. 2</figref>. Therefore, in one example, mobile phone <b>10</b> and, in particular, processor <b>30</b> of the mobile phone may execute an algorithm, e.g. stored on storage device <b>32</b> to determine when the orientation of the phone as determined by accelerometer <b>28</b>, while not exactly vertical, may be assumed to be vertical for purposes of managing display <b>14</b>. For example, processor <b>30</b> may execute an algorithm that determines when mobile phone <b>10</b> is approximately vertical by employing a range of orientations within which the phone's orientation vector as determined by accelerometer <b>28</b> may lie to designate the phone in a vertical orientation for purposes of managing display <b>14</b>.</p>
<p id="p-0053" num="0052">In one example, accelerometer <b>28</b> of mobile phone <b>10</b> determines the orientation of the phone as a vector in three dimensions, which is represented in <figref idref="DRAWINGS">FIG. 5</figref> as phone vector, V<sub>xyz</sub>. The orientation of mobile phone <b>10</b>, and, in particular, the vector, V<sub>xyz </sub>is defined by the magnitudes of the vector in the X, Y, and Z directions A<sub>x</sub>, A<sub>y</sub>, and A<sub>z</sub>, respectively, as well as the angles between the vector and each of the X, Y, and Z axes (not shown in <figref idref="DRAWINGS">FIG. 5</figref>). In one example, processor <b>30</b> of mobile phone <b>10</b> executes an algorithm that approximates the orientation of the mobile phone as one of horizontal or vertical based on the angle, &#x3b1;, between the phone orientation vector, V<sub>xyz</sub>, and the projection of the vector onto the horizontal X-Y plane.</p>
<p id="p-0054" num="0053">For example, processor <b>30</b> may receive the magnitudes A<sub>x</sub>, A<sub>y</sub>, A<sub>z </sub>of vector, V<sub>xyz </sub>in the X, Y, Z directions, respectively in the example of <figref idref="DRAWINGS">FIG. 5</figref>. Processor <b>30</b> may then calculate the magnitude, A<sub>xy</sub>, of the projection of vector, V<sub>xyz </sub>in the X-Y plane according to the following formula.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i><sub>xy</sub>=&#x221a;{square root over (<i>A</i><sub>x</sub><sup>2</sup><i>+A</i><sub>y</sub><sup>2</sup>)}&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0055" num="0054">Processor <b>30</b> may then calculate the angle, a, between the phone orientation vector, V<sub>xyz</sub>, and the projection of the vector onto the horizontal X-Y plane as a function of the arc tangent of the magnitude, A<sub>z</sub>, of the vertical component of the orientation vector, V<sub>xyz </sub>and the magnitude, A<sub>xy</sub>, of the projection of the vector in the X-Y plane. For example, processor <b>30</b> may calculate the angle, &#x3b1;, according to the following formula.</p>
<p id="p-0056" num="0055">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>&#x3b1;</mi>
        <mo>=</mo>
        <mrow>
          <mi>arctan</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mfrac>
              <msub>
                <mi>A</mi>
                <mi>z</mi>
              </msub>
              <msub>
                <mi>A</mi>
                <mi>xy</mi>
              </msub>
            </mfrac>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>2</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0057" num="0056">In one example, processor <b>30</b> approximates the orientation of mobile phone <b>10</b> as vertical when the angle, &#x3b1;, between the phone orientation vector, V<sub>xyz</sub>, determined by accelerometer <b>28</b> and the projection of the vector onto the horizontal X-Y plane is greater than 50 degrees.</p>
<p id="p-0058" num="0057">Referring again to <figref idref="DRAWINGS">FIG. 4</figref>, the example method includes turning off a display of the mobile phone (<b>56</b>). For example, in the event proximity sensor <b>26</b> detects an object proximate mobile phone <b>10</b> and accelerometer <b>28</b> determines the orientation of the phone as vertical, processor <b>30</b> of the mobile phone may infer that the phone has been raised to the user's head to listen and talk to the other person on the call and may, therefore, turn off display <b>14</b>.</p>
<p id="p-0059" num="0058">In some examples, a mobile phone may apply hysteresis in the management of the display of the phone, e.g. to reduce the occurrence of the phone repeatedly toggling between turning the display on and off. For example, mobile phone <b>10</b>, and, in particular, processor <b>30</b> may only turn off display <b>14</b> in the event that accelerometer <b>28</b> determines the orientation of the phone as vertical for a threshold period of time. In one example, processor <b>30</b> may only turn off display <b>14</b> in the event accelerometer <b>28</b> determines the orientation of the phone as vertical for more than 100 milliseconds.</p>
<p id="p-0060" num="0059">In one example of the method of <figref idref="DRAWINGS">FIG. 4</figref>, the mobile phone may employ additional parameters to determine whether or not to turn off the display of the phone during a call. In one example, processor <b>30</b> is configured to check the manner in which the user is interacting with mobile phone <b>10</b> during a phone call before turning of display <b>14</b> responsive to proximity sensor <b>26</b> detecting an object proximate the phone and accelerometer <b>28</b> determining the orientation of the phone as vertical. For example, processor <b>30</b> may be configured to determine the audio input/output configuration of mobile phone <b>10</b> during a phone call, e.g. the manner in which the user speaks into the phone during the call. In one example, the audio input/output configuration of mobile phone <b>10</b> may include at least one of speaking directly into microphone <b>22</b>, using a speaker phone function where the user holds the phone away from their ear and mouth by some distance and speaks into the microphone and listens to responses from speaker <b>20</b>, or the user speaks into a headset wired or wirelessly, e.g. a Bluetooth headset connected to the microphone of the phone. In one such example, processor <b>30</b> may be configured to turn off display <b>14</b> only when proximity sensor <b>26</b> detects an object proximate mobile phone <b>10</b>, accelerometer <b>28</b> determines the orientation of the phone as vertical, and the processor determines the audio input/output configuration of the phone as the user speaking directly into microphone <b>22</b>.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIGS. 6 and 7</figref> are flowcharts illustrating additional functions that may be executed by a mobile device in examples according to this disclosure to manage the display of the device during a phone call. The functions illustrated in <figref idref="DRAWINGS">FIGS. 6 and 7</figref> can be executed in association with the example method of <figref idref="DRAWINGS">FIG. 4</figref>. In particular, each of <figref idref="DRAWINGS">FIGS. 6 and 7</figref> represent additional functions that may be executed, e.g., after the functions illustrated in <figref idref="DRAWINGS">FIG. 4</figref> have been executed.</p>
<p id="p-0062" num="0061">In the example of <figref idref="DRAWINGS">FIG. 6</figref>, after turning off the display of a mobile phone responsive to an object detected proximate the phone and the orientation of the phone determined as vertical, the mobile phone may determine that the object is no longer proximate the phone (<b>70</b>). For example, proximity sensor <b>26</b> may become deactivated after becoming activated during a phone call using mobile phone <b>10</b> such that the sensor does not detect the presence of any objects at or within a threshold distance to the phone. In one example, processor <b>30</b> of mobile phone <b>10</b> may be configured to infer that the object previously detected as proximate the mobile phone, e.g. the user's head in the example of <figref idref="DRAWINGS">FIG. 4</figref>, is no longer near the phone in the event proximity sensor <b>26</b> becomes deactivated.</p>
<p id="p-0063" num="0062">In addition to determining that the object is not proximate the mobile phone (<b>70</b>), the example of <figref idref="DRAWINGS">FIG. 6</figref> includes determining the orientation of the phone as horizontal. In one example, accelerometer <b>28</b> may determine the orientation of mobile phone <b>10</b> as horizontal during the phone call. However, as with the example of <figref idref="DRAWINGS">FIG. 4</figref>, in practice, the orientation of mobile phone <b>10</b> may not be exactly or nearly exactly horizontal. Therefore, mobile phone <b>10</b>, and, in particular, e.g., processor <b>30</b> of the phone may be configured to execute an algorithm that determines when mobile phone is approximately horizontal by employing a range of orientations within which the phone's orientation vector as determined by accelerometer <b>28</b> may lie to designate the phone in a horizontal orientation for purposes of managing display <b>14</b>. In one example, processor <b>30</b> employs similar techniques described above with reference to <figref idref="DRAWINGS">FIG. 4</figref> for approximating the orientation of mobile phone <b>10</b> as vertical to approximate the orientation of the phone as horizontal.</p>
<p id="p-0064" num="0063">For example, processor <b>30</b> may calculate the angle, &#x3b1;, between a phone orientation vector, V<sub>xyz</sub>, determined by accelerometer <b>28</b> and the projection of the vector onto the horizontal X-Y plane illustrated in <figref idref="DRAWINGS">FIG. 5</figref> as a function of the arc tangent of the magnitude, A<sub>z</sub>, of the vertical component of the orientation vector, V<sub>xyz </sub>and the magnitude, A<sub>xy</sub>, of the projection of the vector in the X-Y plane. In one example, processor <b>30</b> approximates the orientation of mobile phone <b>10</b> as horizontal in the example of <figref idref="DRAWINGS">FIG. 6</figref> when the angle, a, between the phone orientation vector, V<sub>xyz</sub>, determined by accelerometer <b>28</b> and the projection of the vector onto the horizontal X-Y plane is less than or equal to 50 degrees.</p>
<p id="p-0065" num="0064">The example of <figref idref="DRAWINGS">FIG. 6</figref> also includes turning on a display of the mobile phone (<b>56</b>). For example, if it is determined that the object is not proximate mobile phone <b>10</b> using proximity sensor <b>26</b> and accelerometer <b>28</b> determines the orientation of the phone as horizontal, processor <b>30</b> of the mobile phone may infer that the phone has been lowered away from the user's head to, e.g. access other functions on the phone and may, therefore, turn on display <b>14</b>.</p>
<p id="p-0066" num="0065">As with the method of <figref idref="DRAWINGS">FIG. 4</figref>, in some examples of the method of <figref idref="DRAWINGS">FIG. 6</figref>, a mobile phone may apply hysteresis in the management of the display of the phone, e.g. to reduce the occurrence of the phone repeatedly toggling between turning the display on and off. For example, mobile phone <b>10</b>, and, in particular, processor <b>30</b> may only turn display <b>14</b> on in the event that accelerometer <b>28</b> determines the orientation of the phone as horizontal for a threshold period of time. In one example, processor <b>30</b> may only turn on display <b>14</b> in the event accelerometer <b>28</b> determines the orientation of the phone as horizontal for more than 500 milliseconds.</p>
<p id="p-0067" num="0066">Another issue in mobile phone display management is when to reactivate a display after a phone call has been terminated. In some cases, activating the phone display too soon after call termination may cause untoward consequences, including, e.g. a user's head inadvertently triggering phone functions in examples in which the display is a touch-screen display. As such, in the example of <figref idref="DRAWINGS">FIG. 7</figref>, after turning off the display of a mobile phone responsive to an object detected proximate the phone and the orientation of the phone determined as vertical during a phone call, the phone call may be terminated (<b>80</b>). However, as illustrated in the example of <figref idref="DRAWINGS">FIG. 7</figref>, before turning on the display (<b>84</b>) of the phone after the call is terminated, the mobile phone may determine that the object is no longer proximate the phone (<b>82</b>). In one example, a phone call on mobile phone <b>10</b> may be terminated after proximity sensor <b>26</b> detects an object proximate the phone and accelerometer <b>28</b> determines the orientation of the phone as vertical while the call was still active. In such an example, processor <b>30</b> of mobile phone <b>10</b> may be configured to wait until proximity sensor detects that no objects are proximate the phone until the processor turns on display <b>14</b>.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIGS. 8A and 8B</figref> illustrate two alternative mobile phones in accordance with this disclosure. <figref idref="DRAWINGS">FIG. 8A</figref> illustrates a hinged portable mobile phone, also with a keypad and display. <figref idref="DRAWINGS">FIG. 8B</figref> illustrates a mobile phone with a large touchscreen display that functions to present content to and receive input from users, e.g. in lieu of a traditional number keypad or full QWERTY keypad employed on some mobile devices.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 8A</figref> is a plan view of example mobile phone <b>100</b> including housing <b>102</b> with hinge <b>104</b>, display <b>106</b>, keypad <b>108</b>, speaker <b>110</b>, microphone <b>112</b>, proximity sensor <b>114</b>, and accelerometer <b>116</b>. Mobile phone <b>100</b>, including proximity sensor <b>114</b> and accelerometer <b>116</b>, may be configured and function in accordance with the disclosed examples in a manner similar to that described above with reference to example phone <b>10</b> of <figref idref="DRAWINGS">FIG. 1</figref>. Mobile phone <b>100</b>, however, includes some variations from the previous example. For example, mobile phone <b>100</b> includes hinge <b>104</b> in housing <b>102</b>. Hinge <b>104</b> may be configured to permit mobile phone <b>100</b> to assume a number of physical configurations including the unfolded configuration shown in <figref idref="DRAWINGS">FIG. 8A</figref> and a folded configuration by folding the upper half of the phone including display <b>106</b> onto the lower half of the phone including keypad <b>108</b>. In any event, mobile phone <b>100</b>, and, in particular, proximity sensor <b>114</b> and accelerometer <b>116</b> may be configured to manage display <b>104</b> during a phone call made with mobile phone <b>100</b> in a manner similar to that described with reference to phone <b>10</b> of <figref idref="DRAWINGS">FIG. 1</figref> and other examples described in this disclosure.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 8B</figref> is a plan view of example mobile phone <b>200</b> including housing <b>202</b>, touch-screen display <b>204</b>, soft keys <b>206</b>, speaker <b>208</b>, microphone <b>210</b>, proximity sensor <b>212</b>, and accelerometer <b>214</b>. Mobile phone <b>200</b>, including proximity sensor <b>212</b> and accelerometer <b>214</b>, may be, as with phone <b>100</b> of <figref idref="DRAWINGS">FIG. 8A</figref>, configured and function in accordance with the disclosed examples in a manner similar to that described above with reference to example phone <b>10</b> of <figref idref="DRAWINGS">FIG. 1</figref>. Mobile phone <b>210</b>, however, includes some variations from the previous examples of <figref idref="DRAWINGS">FIGS. 1 and 8A</figref>. For example, mobile phone <b>210</b> includes touch-screen display <b>204</b>. Touch-screen display <b>204</b>, along with soft keys <b>206</b>, may form part or all of a user interface for mobile phone <b>210</b>. Mobile phone <b>210</b> may be an integrated personal data assistant (PDA) and mobile phone, which are sometimes referred to as &#x201c;smart phones.&#x201d; In any event, mobile phone <b>200</b>, and, in particular, proximity sensor <b>212</b> and accelerometer <b>214</b> may be configured to manage display <b>204</b> during a phone call made with mobile phone <b>200</b> in a manner similar to that described with reference to phone <b>10</b> of <figref idref="DRAWINGS">FIG. 1</figref> and other examples described in this disclosure.</p>
<p id="p-0071" num="0070">The techniques described in this disclosure may be implemented, at least in part, in hardware, software, firmware or any combination thereof. For example, various aspects of the described techniques may be implemented within one or more processors, including one or more microprocessors, digital signal processors (DSPs), application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), or any other equivalent integrated or discrete logic circuitry, as well as any combinations of such components. The term &#x201c;processor&#x201d; or &#x201c;processing circuitry&#x201d; may generally refer to any of the foregoing logic circuitry, alone or in combination with other logic circuitry, or any other equivalent circuitry. A control unit including hardware may also perform one or more of the techniques of this disclosure.</p>
<p id="p-0072" num="0071">Such hardware, software, and firmware may be implemented within the same device or within separate devices to support the various operations and functions described in this disclosure. In addition, any of the described units, modules or components may be implemented together or separately as discrete but interoperable logic devices. Depiction of different features as modules or units is intended to highlight different functional aspects and does not necessarily imply that such modules or units must be realized by separate hardware or software components. Rather, functionality associated with one or more modules or units may be performed by separate hardware or software components, or integrated within common or separate hardware or software components.</p>
<p id="p-0073" num="0072">The techniques described in this disclosure may also be embodied or encoded in a computer-readable medium, such as a computer-readable storage medium, containing instructions. Instructions embedded or encoded in a computer-readable medium may cause a programmable processor, or other processor, to perform the method, e.g., when the instructions are executed. Computer readable storage media may include random access memory (RAM), read only memory (ROM), programmable read only memory (PROM), erasable programmable read only memory (EPROM), electronically erasable programmable read only memory (EEPROM), flash memory, a hard disk, a CD-ROM, a floppy disk, a cassette, magnetic media, optical media, or other computer readable media. In some examples, an article of manufacture may comprise one or more computer-readable storage media.</p>
<p id="p-0074" num="0073">In some examples, computer-readable storage media may comprise non-transitory media. The term &#x201c;non-transitory&#x201d; may indicate that the storage medium is not embodied in a carrier wave or a propagated signal. In certain examples, a non-transitory storage medium may store data that can, over time, change (e.g., in RAM or cache).</p>
<p id="p-0075" num="0074">Various examples have been described. These and other examples are within the scope of the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08626248-20140107-M00001.NB">
<img id="EMI-M00001" he="7.03mm" wi="76.20mm" file="US08626248-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>determining, by a mobile device, that an object is proximate the mobile device using a proximity sensor of the mobile device;</claim-text>
<claim-text>determining, by the mobile device, that an orientation of the mobile device is an approximately vertical orientation;</claim-text>
<claim-text>in response to determining that the object is proximate the mobile device and that the orientation of the mobile device is the approximately vertical orientation, automatically turning off a display of the mobile device;</claim-text>
<claim-text>while the display of the mobile device is turned off:
<claim-text>receiving one or more voice signals based on audible input received by a microphone the mobile device,</claim-text>
<claim-text>determining, by the mobile device, that the object is not proximate the mobile device using the proximity sensor, and</claim-text>
<claim-text>determining, by the mobile device, that the orientation of the mobile device is an approximately horizontal orientation; and</claim-text>
</claim-text>
<claim-text>in response to determining that the object is not proximate the mobile device and that the orientation of the mobile device is the approximately horizontal orientation, automatically turning on the display of the mobile device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining that the orientation of the mobile device is the approximately horizontal orientation for a threshold period of time before turning on the display.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining that the orientation of the mobile device is the approximately horizontal orientation comprises:
<claim-text>determining an orientation vector of the mobile device; and</claim-text>
<claim-text>approximating the orientation of the mobile device as horizontal based on the orientation vector.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein approximating the orientation of the mobile device as horizontal based on the orientation vector comprises:
<claim-text>calculating a first angle between the orientation vector and a projection of the vector onto a plane that is generally perpendicular to the direction of gravity; and</claim-text>
<claim-text>approximating the orientation of the mobile device as horizontal when the first angle is less than or equal to approximately 50 degrees.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining that the object is not proximate the mobile device using the proximity sensor occurs before determining that the orientation of the mobile device is the approximately horizontal orientation.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>automatically turning off the display of the mobile device in response to at least one of determining that the object is proximate the mobile device a second time using the proximity sensor of the mobile device and determining that the orientation of the mobile device is the approximately vertical orientation a second time.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining that the orientation of the mobile device is the approximately vertical orientation comprises:
<claim-text>determining an orientation vector of the mobile device; and</claim-text>
<claim-text>approximating the orientation of the mobile device as vertical based on the orientation vector.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein approximating the orientation of the mobile device as vertical based on the orientation vector comprises:
<claim-text>calculating a first angle between the orientation vector and the projection of the vector onto a plane that is generally perpendicular to the direction of gravity; and</claim-text>
<claim-text>approximating the orientation of the mobile device as vertical when the first angle is greater than approximately 50 degrees.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the proximity sensor comprises one of a capacitive, photoelectric, or inductive sensor.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining that the orientation of the mobile device is the approximately vertical orientation for a threshold period of time before turning off the display.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining that the object is proximate the mobile device using the proximity sensor comprises determining that the object is a threshold distance away from the mobile device.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining that the orientation of the mobile device is the approximately vertical orientation or the approximately horizontal orientation comprises based on one or more signals generated by an accelerometer of the mobile device.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the accelerometer comprises at least one of a piezoelectric or capacitive accelerometer, and a micro-electro-mechanical system (MEMS).</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A mobile device comprising:
<claim-text>a display;</claim-text>
<claim-text>a microphone;</claim-text>
<claim-text>a proximity sensor configured to detect a proximity of an object to the mobile device; and</claim-text>
<claim-text>one or more processors configured to:
<claim-text>in response to determining that the object is proximate the mobile device and that an orientation of the mobile device is an approximately vertical orientation, automatically turn off the display of the mobile device;</claim-text>
<claim-text>while the display is turned of:
<claim-text>receive one or more voice signals based on audible input received by the microphone,</claim-text>
<claim-text>determine that the object is not proximate the mobile device using the proximity sensor, and</claim-text>
<claim-text>determine that the orientation of the mobile device is an approximately horizontal orientation; and</claim-text>
</claim-text>
<claim-text>in response to determining that the object is not proximate the mobile device and that the orientation of the mobile device is the approximately horizontal orientation, automatically turning on the display of the mobile device.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The mobile device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the one or more processors are configured to determine that the orientation of the mobile device is the approximately horizontal orientation for a threshold period of time before turning on the display.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The mobile device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the one or more processors are configured to determine that the orientation of the mobile device is the approximately vertical orientation for a threshold period of time before turning off the display.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The mobile device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising an accelerometer, wherein the one or more processors are configured to determine that the orientation of the mobile device is the approximately vertical orientation or the approximately horizontal orientation based on one or more signals generated by the accelerometer.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A storage device storing instructions for causing at least one processor to:
<claim-text>automatically turn off a display of a mobile device in response to determining that an object is proximate the mobile device and that an orientation of the mobile device is an approximately vertical orientation;</claim-text>
<claim-text>while the display is turned of:
<claim-text>receive one or more voice signals based on audible input,</claim-text>
<claim-text>determine that the object is not proximate the mobile device, and</claim-text>
<claim-text>determine that the orientation of the mobile device is an approximately horizontal orientation; and</claim-text>
</claim-text>
<claim-text>in response to determining that the object is not proximate the mobile device and that the orientation of the mobile device is the approximately horizontal orientation, automatically turning on the display of the mobile device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The storage device of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further storing instructions for causing the at least one processor to determine that the orientation of the mobile device is the approximately horizontal orientation for a threshold period of time before turning on the display.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The storage device of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further storing instructions for causing the at least one processor to determine that the orientation of the mobile device is the approximately vertical orientation for a threshold period of time before turning off the display.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The storage device of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further storing instructions for causing the at least one processor to determine that the orientation of the mobile device is the approximately vertical orientation or the approximately horizontal orientation based on one or more signals generated by an accelerometer of the mobile device.</claim-text>
</claim>
</claims>
</us-patent-grant>
