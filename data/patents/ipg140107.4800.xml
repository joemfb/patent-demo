<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625893-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625893</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13429968</doc-number>
<date>20120326</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2011-081543</doc-number>
<date>20110401</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>11</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382167</main-classification>
</classification-national>
<invention-title id="d2e71">Image processing device and image processing method</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5761341</doc-number>
<kind>A</kind>
<name>Go</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382232</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7668406</doc-number>
<kind>B2</kind>
<name>Schnee et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382313</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>8244034</doc-number>
<kind>B2</kind>
<name>Ishiga</name>
<date>20120800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382167</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2011/0150354</doc-number>
<kind>A1</kind>
<name>Huang</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382260</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>JP</country>
<doc-number>2006-14024</doc-number>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>2010-157163</doc-number>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00007">
<othercit>(Sei Mashashi, Machine translation of JP2006333316, Dec. 2006).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
</us-references-cited>
<number-of-claims>11</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382167</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>13</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120250995</doc-number>
<kind>A1</kind>
<date>20121004</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Matsumoto</last-name>
<first-name>Jun</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Matsushita</last-name>
<first-name>Nobuyuki</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Matsumoto</last-name>
<first-name>Jun</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Matsushita</last-name>
<first-name>Nobuyuki</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sony Corporation</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Ahmed</last-name>
<first-name>Samir</first-name>
<department>2668</department>
</primary-examiner>
<assistant-examiner>
<last-name>Le</last-name>
<first-name>Totam</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The present technology relates to an image processing device including: a reducing section configured to generate a plurality of reduced images by reducing an input image at a plurality of reduction ratios; a noise removal processing section configured to generate noise-removed images by performing noise removal processing on each of the reduced images; an enlarging section configured to generate enlarged images equal to each other in size by enlarging each of the noise-removed images; and a mixing section configured to generate an output image by mixing two or more different enlarged images of the enlarged images with each other.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="93.64mm" wi="221.32mm" file="US08625893-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="226.91mm" wi="114.47mm" orientation="landscape" file="US08625893-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="263.65mm" wi="156.55mm" orientation="landscape" file="US08625893-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="195.07mm" wi="108.20mm" file="US08625893-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="150.88mm" wi="144.95mm" file="US08625893-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="204.13mm" wi="99.82mm" orientation="landscape" file="US08625893-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="161.04mm" wi="130.98mm" file="US08625893-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="203.45mm" wi="154.09mm" orientation="landscape" file="US08625893-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="253.15mm" wi="157.90mm" orientation="landscape" file="US08625893-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="231.14mm" wi="152.65mm" file="US08625893-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="266.45mm" wi="154.43mm" orientation="landscape" file="US08625893-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="225.81mm" wi="163.15mm" file="US08625893-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">The present technology relates to an image processing device and an image processing method, and particularly to enabling a noise-removed image of excellent image quality without a loss of sharpness in edge parts to be generated in removing noise from an image.</p>
<p id="p-0003" num="0002">In related art, an image processing device removes noise from an image when extracting edge information from the image and performing image processing, for example, because the extraction of the edge information is inevitably affected by a noise part when the noise part is included in the image. In addition, in noise removal, performing image matching processing using edge information, for example, presents a problem in that the matching processing takes much time or matching accuracy is not improved. In order to solve such a problem, an image processing device removes noise by smoothing processing using for example an averaging filter or a Gaussian filter. However, when noise is removed by the smoothing processing, edge parts are blurred more, and it becomes difficult to extract edge information.</p>
<p id="p-0004" num="0003">Accordingly, an image processing device performs filter processing using a median filter, thereby removing noise in the form of dots without losing the sharpness of edge parts. In addition, Japanese Patent Laid-Open No. 2006-014024 (hereinafter referred to as Patent Document 1) discloses smoothing processing performed using only pixels whose differences in luminance value are within a predetermined threshold value, thereby enabling the reduction of false contours and noise without blurring contours while retaining the contours of an input signal.</p>
<p id="p-0005" num="0004">In addition, when noise in a large region is desired to be removed, filter operation in a wide range is necessary. In this case, simply widening a filter range invites an increase in the scale of an arithmetic circuit and processing time. In order to deal with this, Japanese Patent Laid-Open No. 2010-157163 discloses performing filter processing after reducing an input image.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0006" num="0005">When filter processing is performed after an input image is reduced, a chromatic blur occurs at an edge or the like, and invites degradation in image quality. A chromatic blur at an edge in a color of red, in particular, is perceived easily.</p>
<p id="p-0007" num="0006">It is accordingly desirable to provide an image processing device and an image processing method that can provide an image of excellent image quality without a loss of sharpness in edge parts even when performing noise removal.</p>
<p id="p-0008" num="0007">According to a first embodiment of the present technology, there is provided an image processing device including: a reducing section configured to generate a plurality of reduced images by reducing an input image at a plurality of reduction ratios; a noise removal processing section configured to generate noise-removed images by performing noise removal processing on each of the reduced images; an enlarging section configured to generate enlarged images equal to each other in size by enlarging each of the noise-removed images; and a mixing section configured to generate an output image by mixing two or more different enlarged images of the enlarged images with each other.</p>
<p id="p-0009" num="0008">In the present technology, an input image is reduced at a plurality of reduction ratios, and noise-removed images are generated by performing noise removal processing on each of a plurality of reduced images. The noise removal processing section is formed by using a plurality of kinds of filters, and has a rearrangeable filter configuration. For example, on a basis of a result of determination of the color of the input image, a first filter configuration with high noise removal performance is used for a particular color, and a second filter configuration with high processing speed is used for other than the particular color. In addition, the filter configuration is set according to the reduction ratios. The noise-removed images are enlarged to enlarged images equal to each other in size, and an output image is generated by mixing two or more different enlarged images with each other. A mixing ratio between the enlarged images to be mixed with each other is calculated on the basis of correlation between the enlarged images to be mixed with each other. For example, the color-difference signals of the enlarged images to be mixed with each other are used to determine the correlation between the enlarged images, and the mixing ratio is calculated such that the ratio of an image having a high reduction ratio is increased as the correlation is decreased. In addition, on the basis of the result of determination of the color of the input image, the mixing ratio between the images to be mixed with each other is increased or decreased for a particular color. For example, when the input image is of the particular color, the ratio of an image having a high reduction ratio is increased.</p>
<p id="p-0010" num="0009">According to a second embodiment of the present technology, there is provided an image processing method including: generating a plurality of reduced images by reducing an input image at a plurality of reduction ratios; generating noise-removed images by performing noise removal processing on each of the reduced images; generating enlarged images equal to each other in size by enlarging each of the noise-removed images; and generating an output image by mixing two or more different enlarged images of the enlarged images with each other.</p>
<p id="p-0011" num="0010">According to the present technology, an input image is reduced at a plurality of reduction ratios, and noise-removed images are generated by performing noise removal processing on each of a plurality of reduced images. In addition, enlarged images equal to each other in size are generated by enlarging each of the noise-removed images, and an output image is generated by mixing two or more different enlarged images with each other. Because noise removal is thus applied to the images reduced at the plurality of reduction ratios, chromatic blurs in edge parts of the respective enlarged images are different from each other. Mixing two or more different enlarged images with each other can provide an image of excellent image quality without a loss of sharpness in edge parts.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating a configuration of an imaging device;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram showing a configuration of a first embodiment;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram showing the operation of the first embodiment;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram illustrating a data arrangement of an input image and an output image;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. 5A</figref>, <b>5</b>B, and <b>5</b>C are diagrams showing the reduction and enlargement of an image;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram showing a configuration of a noise removal processing section whose noise removal performance is improved by using waiting times;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram showing a configuration of noise removal processing sections allowing the rearrangement of noise removal processing;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram showing a configuration of a second embodiment;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram showing the operation of the second embodiment;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 10</figref> is a diagram showing a configuration of a third embodiment; and</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram showing the operation of the third embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0023" num="0022">Modes for carrying out the present technology will hereinafter be described. Incidentally, description will be made in the following order.</p>
<p id="h-0005" num="0000">1. Configuration of System Using Image Processing Device</p>
<p id="h-0006" num="0000">2. First Embodiment</p>
<p id="p-0024" num="0023">2-1. Configuration of First Embodiment</p>
<p id="p-0025" num="0024">2-2. Operation of First Embodiment</p>
<p id="h-0007" num="0000">3. Second Embodiment</p>
<p id="p-0026" num="0025">3-1. Configuration of Second Embodiment</p>
<p id="p-0027" num="0026">3-2. Operation of Second Embodiment</p>
<p id="h-0008" num="0000">4. Third Embodiment</p>
<p id="p-0028" num="0027">4-1. Configuration of Third Embodiment</p>
<p id="p-0029" num="0028">4-2. Operation of Third Embodiment</p>
<heading id="h-0009" level="1">1. Configuration of System Using Image Processing Device</heading>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a configuration of a system using an image processing device according to an embodiment of the present technology, which system is for example an imaging device. The imaging device <b>10</b> includes an imaging optical system <b>11</b>, an imaging section <b>12</b>, a camera signal processing section <b>13</b>, a signal converting section <b>14</b>, a noise removing unit <b>20</b>, and a control section <b>30</b>.</p>
<p id="p-0031" num="0030">The imaging optical system <b>11</b> mainly includes a lens. The imaging optical system <b>11</b> forms an optical image of a subject not shown in the figure on a light receiving surface of the imaging section <b>12</b>.</p>
<p id="p-0032" num="0031">The imaging section <b>12</b> is formed by using a solid-state imaging element such as a CMOS (Complementary Metal-Oxide Semiconductor), a CCD (Charge-Coupled Device), or the like. The imaging section <b>12</b> generates an imaging signal corresponding to the optical image formed on the light receiving surface by the imaging optical system <b>11</b>. In addition, the imaging section <b>12</b> subjects the imaging signal to correlated double sampling (CDS) processing, analog amplification processing, A/D conversion processing, and the like, and outputs a resulting image signal to the camera signal processing section <b>13</b>.</p>
<p id="p-0033" num="0032">The camera signal processing section <b>13</b> subjects the image signal supplied from the imaging section <b>12</b> to processing such as gamma correction, luminance adjustment, color correction, and the like. The camera signal processing section <b>13</b> outputs the image signal after the processing to the signal converting section <b>14</b>.</p>
<p id="p-0034" num="0033">The signal converting section <b>14</b> performs signal conversion to convert the image signal supplied from the camera signal processing section <b>13</b> into an image signal of a predetermined system, for example a luminance signal and a color-difference signal. The signal converting section <b>14</b> outputs the image signal to the noise removing unit <b>20</b>.</p>
<p id="p-0035" num="0034">The noise removing unit <b>20</b> corresponding to an image processing device according to an embodiment of the present technology subjects the image signal supplied from the signal converting section <b>14</b> to noise removal processing. Incidentally, a configuration and operation of the noise removing unit <b>20</b> will be described later.</p>
<p id="p-0036" num="0035">The control section <b>30</b> is connected with a user interface (I/F) section <b>31</b>. The user I/F section <b>31</b> is to receive operating input from a user. The user I/F section <b>31</b> includes a power switch, various operating keys such as a shutter key, a zoom key, and the like, and operating keys for making menu display, a selection of a menu item, and various settings. The user I/F section outputs an operating signal corresponding to a user operation to the control section <b>30</b>.</p>
<p id="p-0037" num="0036">The control section <b>30</b> is formed by using a microcomputer or the like. The control section <b>30</b> executes a stored program to control various parts on the basis of the operating signal so that the operation of the imaging device <b>10</b> is an operation corresponding to the user operation.</p>
<heading id="h-0010" level="1">2. First Embodiment</heading>
<heading id="h-0011" level="1">2-1. Configuration of First Embodiment</heading>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 2</figref> shows a configuration of a first embodiment of the noise removing unit corresponding to an image signal processing section according to an embodiment of the present technology. The noise removing unit <b>20</b> includes a reducing section <b>21</b>, a noise removal processing section <b>22</b>, an enlarging section <b>23</b>, and a mixing section <b>24</b>.</p>
<p id="p-0039" num="0038">The reducing section <b>21</b> reduces an input image. The reducing section <b>21</b> includes for example a first reduction processing portion <b>21</b>-<b>1</b>, a second reduction processing portion <b>21</b>-<b>2</b>, and a third reduction processing portion <b>21</b>-<b>3</b>. The first reduction processing portion <b>21</b>-<b>1</b> reduces the input image to a first size (for example a &#x2153;-fold size: a reduction ratio of 33.33%), and outputs the image signal of the first reduced image to the noise removal processing section <b>22</b>. The second reduction processing portion <b>21</b>-<b>2</b> reduces the input image to a second size (for example a 1/9-fold size: a reduction ratio of 11.11%), and outputs the image signal of the second reduced image to the noise removal processing section <b>22</b>. The third reduction processing portion <b>21</b>-<b>3</b> reduces the input image to a third size (for example a 1/18-fold size: a reduction ratio of 5.56%), and outputs the image signal of the third reduced image to the noise removal processing section <b>22</b>.</p>
<p id="p-0040" num="0039">Incidentally, sizes in embodiments represent numbers of pixels. For example, a 1/n-fold size indicates 1/n times the number of pixels in a horizontal direction and a vertical direction, and an n-fold size indicates n times the number of pixels in the horizontal direction and the vertical direction.</p>
<p id="p-0041" num="0040">The reducing section <b>21</b> is not limited to the above-described reduction ratios, but may be configured to generate the image signals of reduced images at a plurality of reduction ratios according to specified values. In addition, the reducing section may be configured by a single arithmetic section having a plurality of reduction ratios according to specified values.</p>
<p id="p-0042" num="0041">The noise removal processing section <b>22</b> performs noise removal processing on the image signals supplied from the reducing section <b>21</b>. The noise removal processing section <b>22</b> includes for example a first noise removal processing portion <b>22</b>-<b>1</b>, a second noise removal processing portion <b>22</b>-<b>2</b>, and a third noise removal processing portion <b>22</b>-<b>3</b>. Each of the noise removal processing portions is formed by an adjacent pixel averaging filter such as a low-pass filter, an epsilon filter, a bilateral filter, or the like, or a combination of these filters. The first noise removal processing portion <b>22</b>-<b>1</b> performs filter processing on the image signal output from the first reduction processing portion <b>21</b>-<b>1</b> in the reducing section <b>21</b>, and thereby removes the noise of the image signal. The first noise removal processing portion <b>22</b>-<b>1</b> outputs the image signal to the enlarging section <b>23</b>. The second noise removal processing portion <b>22</b>-<b>2</b> performs filter processing on the image signal output from the second reduction processing portion <b>21</b>-<b>2</b> in the reducing section <b>21</b>, and thereby removes the noise of the image signal. The second noise removal processing portion <b>22</b>-<b>2</b> outputs the image signal to the enlarging section <b>23</b>. The third noise removal processing portion <b>22</b>-<b>3</b> performs filter processing on the image signal output from the third reduction processing portion <b>21</b>-<b>3</b> in the reducing section <b>21</b>, and thereby removes the noise of the image signal. The third noise removal processing portion <b>22</b>-<b>3</b> outputs the image signal to the enlarging section <b>23</b>.</p>
<p id="p-0043" num="0042">The enlarging section <b>23</b> performs image enlargement using the image signals supplied from the noise removal processing section <b>22</b>. The enlarging section <b>23</b> includes for example a first enlargement processing portion <b>23</b>-<b>1</b>, a second enlargement processing portion <b>23</b>-<b>2</b>, and a third enlargement processing portion <b>23</b>-<b>3</b>. Each of the enlargement processing portions performs image enlargement by using a method such as Nearest Neighbor, Bilinear, Bicubic, or the like. The first enlargement processing portion <b>23</b>-<b>1</b> performs enlargement processing using the image signal output from the first noise removal processing portion <b>22</b>-<b>1</b> in the noise removal processing section <b>22</b>, and thereby generates the image signal of an enlarged image obtained by enlarging the image to a first size (for example a three-fold size). The first enlargement processing portion <b>23</b>-<b>1</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>. The second enlargement processing portion <b>23</b>-<b>2</b> performs enlargement processing using the image signal output from the second noise removal processing portion <b>22</b>-<b>2</b> in the noise removal processing section <b>22</b>, and thereby generates the image signal of an enlarged image obtained by enlarging the image to a second size (for example a nine-fold size). The second enlargement processing portion <b>23</b>-<b>2</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>. The third enlargement processing portion <b>23</b>-<b>3</b> performs enlargement processing using the image signal output from the third noise removal processing portion <b>22</b>-<b>3</b> in the noise removal processing section <b>22</b>, and thereby generates the image signal of an enlarged image obtained by enlarging the image to a third size (for example a 18-fold size). The third enlargement processing portion <b>23</b>-<b>3</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>.</p>
<p id="p-0044" num="0043">Incidentally, when the noise removing unit <b>20</b> sets the enlargement factors of the enlarging section <b>23</b> to factors that return the image reduced in the reducing section <b>21</b> to the original size, the size of the output images can be made equal to that of the input image. In addition, the enlargement factors of the enlarging section may be other enlargement ratios when the numbers of pixels of the enlarged images output from the respective enlargement processing portions are the same number of pixels. In addition, the enlarging section <b>23</b> may be a single arithmetic section having a plurality of enlargement ratios according to specified values.</p>
<p id="p-0045" num="0044">The mixing section <b>24</b> performs mixing processing on the images output from the enlarging section <b>23</b>. The mixing section <b>24</b> includes for example a first mixing processing portion <b>24</b>-<b>1</b>, a second mixing processing portion <b>24</b>-<b>2</b>, and a third mixing processing portion <b>24</b>-<b>3</b>. The first mixing processing portion <b>24</b>-<b>1</b> performs mixing processing using the image signal output from the second enlargement processing portion <b>23</b>-<b>2</b> in the enlarging section <b>23</b> and the image signal output from the third enlargement processing portion <b>23</b>-<b>3</b>, and thereby generates the image signal of a first mixed image. The first mixing processing portion <b>24</b>-<b>1</b> outputs the generated image signal of the first mixed image to the second mixing processing portion <b>24</b>-<b>2</b>. The second mixing processing portion <b>24</b>-<b>2</b> performs mixing processing using the image signal of the first mixed image output from the first mixing processing portion <b>24</b>-<b>1</b> and the image signal output from the first enlargement processing portion <b>23</b>-<b>1</b> in the enlarging section <b>23</b>, and thereby generates the image signal of a second mixed image. The second mixing processing portion <b>24</b>-<b>2</b> outputs the generated image signal of the second mixed image to the third mixing processing portion <b>24</b>-<b>3</b>. The third mixing processing portion <b>24</b>-<b>3</b> performs mixing processing using the image signal of the second mixed image output from the second mixing processing portion <b>24</b>-<b>2</b> and the image signal of the input image, and thereby generates the image signal of an output image.</p>
<p id="p-0046" num="0045">Incidentally, in the following description, signals input to the respective parts and signals output from the respective parts will be described as follows.</p>
<p id="p-0047" num="0046">The image signal DVa input to the first reduction processing portion <b>21</b>-<b>1</b>, the second reduction processing portion <b>21</b>-<b>2</b>, and the third reduction processing portion <b>21</b>-<b>3</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DVa=Y</i>1(<i>x,y</i>),<i>Y</i>2(<i>x,y</i>),<i>Cb</i>(<i>x,y</i>),<i>Cr</i>(<i>x,y</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0048" num="0047">The image signal DS<b>1</b> output from the first reduction processing portion <b>21</b>-<b>1</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DS</i>1<i>=ds</i>1<sub>&#x2014;</sub><i>Y</i>1(<i>x&#x2032;,y&#x2032;</i>),<i>ds</i>1<sub>&#x2014;</sub><i>Y</i>2(<i>x&#x2032;,y</i>&#x2032;),<i>ds</i>1<sub>&#x2014;</sub><i>cb</i>(<i>x&#x2032;,y</i>&#x2032;),<i>ds</i>1<sub>&#x2014;</sub><i>cr</i>(<i>x&#x2032;,y</i>&#x2032;)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0049" num="0048">The image signal DS<b>2</b> output from the second reduction processing portion <b>21</b>-<b>2</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DS</i>2<i>=ds</i>2<sub>&#x2014;</sub><i>Y</i>1(<i>x&#x2033;,y</i>&#x2033;),<i>ds</i>2<sub>&#x2014;</sub><i>Y</i>2(<i>x&#x2033;,y</i>&#x2033;),<i>ds</i>2<sub>&#x2014;</sub><i>cb</i>(<i>x&#x2033;,y</i>&#x2033;),<i>ds</i>2<sub>&#x2014;</sub><i>cr</i>(<i>x&#x2033;,y</i>&#x2033;)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0050" num="0049">The image signal DS<b>3</b> output from the third reduction processing portion <b>21</b>-<b>3</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DS</i>3<i>=ds</i>3<sub>&#x2014;</sub><i>Y</i>1(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;),<i>ds</i>3<sub>&#x2014;</sub><i>Y</i>2(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;),<i>ds</i>3<sub>&#x2014;</sub><i>cb</i>(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;),<i>ds</i>3<sub>&#x2014;</sub><i>cr</i>(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0051" num="0050">The image signal DN<b>1</b> output from the first noise removal processing portion <b>22</b>-<b>1</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DN</i>1<i>=ds</i>1<sub>&#x2014;</sub><i>Y</i>1(<i>x&#x2032;,y</i>&#x2032;),<i>ds</i>1<sub>&#x2014;</sub><i>Y</i>2(<i>x&#x2032;,y</i>&#x2032;),<i>nr</i>1<sub>&#x2014;</sub><i>cb</i>(<i>x&#x2032;,y</i>&#x2032;),<i>nr</i>2<sub>&#x2014;</sub><i>cr</i>(<i>x&#x2032;,y</i>&#x2032;)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0052" num="0051">The image signal DN<b>2</b> output from the second noise removal processing portion <b>22</b>-<b>2</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DN</i>2=<i>ds</i>2<sub>&#x2014;</sub><i>Y</i>1(<i>x&#x2033;,y</i>&#x2033;),<i>ds</i>2<sub>&#x2014;</sub><i>Y</i>2(<i>x&#x2033;,y</i>&#x2033;),<i>nr</i>2<sub>&#x2014;</sub><i>cb</i>(<i>x&#x2033;,y</i>&#x2033;),<i>nr</i>2<sub>&#x2014;</sub><i>cr</i>(<i>x&#x2033;,y</i>&#x2033;)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0053" num="0052">The image signal DN<b>3</b> output from the third noise removal processing portion <b>22</b>-<b>3</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DN</i>3=<i>ds</i>3<sub>&#x2014;</sub><i>Y</i>1(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;),<i>ds</i>3<i>Y</i>2(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;),<i>nr</i>3<sub>&#x2014;</sub><i>cb</i>(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;),<i>nr</i>3<sub>&#x2014;</sub><i>cr</i>(<i>x&#x2032;&#x2033;,y</i>&#x2032;&#x2033;)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0054" num="0053">The image signal DU<b>1</b> output from the first enlargement processing portion <b>23</b>-<b>1</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DU</i>1<i>=us</i>1<sub>&#x2014;</sub><i>Y</i>1(<i>x,y</i>),<i>us</i>1<sub>&#x2014;</sub><i>Y</i>2(<i>x,y</i>),<i>us</i>1<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>),<i>us</i>1<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0055" num="0054">The image signal DU<b>2</b> output from the second enlargement processing portion <b>23</b>-<b>2</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DU</i>2=<i>us</i>2<sub>&#x2014;</sub><i>Y</i>1(<i>x,y</i>),<i>us</i>2<sub>&#x2014;</sub><i>Y</i>2(<i>x,y</i>),<i>us</i>2<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>),<i>us</i>2<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0056" num="0055">The image signal DU<b>3</b> output from the third enlargement processing portion <b>23</b>-<b>3</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DU</i>3=<i>us</i>3<sub>&#x2014;</sub><i>Y</i>1(<i>x,y</i>),<i>us</i>3<sub>&#x2014;</sub><i>Y</i>2(<i>x,y</i>),<i>us</i>3<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>),<i>us</i>3<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0057" num="0056">The image signal DM<b>1</b> output from the first mixing processing portion <b>24</b>-<b>1</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DM</i>1<i>=b</i>11<sub>&#x2014;</sub><i>Y</i>1(<i>x,y</i>),<i>b</i>11<sub>&#x2014;</sub><i>Y</i>2(<i>x,y</i>),<i>b</i>11<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>),<i>b</i>11<i>cr</i>(<i>x,y</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0058" num="0057">The image signal DM<b>2</b> output from the second mixing processing portion <b>24</b>-<b>2</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DM</i>2=<i>b</i>12<sub>&#x2014;</sub><i>Y</i>1(<i>x,y</i>),<i>b</i>12<sub>&#x2014;</sub><i>Y</i>2(<i>x,y</i>),<i>b</i>12<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>),<i>b</i>12<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0059" num="0058">The image signal DVb output from the third mixing processing portion <b>24</b>-<b>3</b>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>DVb=b</i>13<sub>&#x2014;</sub><i>Y</i>1(<i>x,y</i>),<i>b</i>13<sub>&#x2014;</sub><i>Y</i>2(<i>x,y</i>),<i>b</i>13<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>),<i>b</i>13<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<heading id="h-0012" level="1">2-2. Operation of First Embodiment</heading>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart illustrating the operation of the first embodiment, that is, the operation of the noise removing unit <b>20</b>. In step ST<b>1</b>, the noise removing unit <b>20</b> generates reduced images. The reducing section <b>21</b> in the noise removing unit <b>20</b> generates the image signals of the reduced images using an image signal supplied from the signal converting section <b>14</b>. The process then proceeds to step ST<b>2</b>.</p>
<p id="p-0061" num="0060">In step ST<b>2</b>, the noise removing unit <b>20</b> generates noise-removed images. The noise removal processing section <b>22</b> in the noise removing unit <b>20</b> performs noise removal processing using the image signals of the reduced images, and thereby generates the image signals of the noise-removed images. The process then proceeds to step ST<b>3</b>.</p>
<p id="p-0062" num="0061">In step ST<b>3</b>, the noise removing unit <b>20</b> generates enlarged images. The enlarging section <b>23</b> in the noise removing unit <b>20</b> performs image enlargement processing using the image signals of the noise-removed images, and thereby generates the image signals of the enlarged images. The process then proceeds to step ST<b>4</b>.</p>
<p id="p-0063" num="0062">In step ST<b>4</b>, the noise removing unit <b>20</b> generates a first mixed image. The mixing section <b>24</b> in the noise removing unit <b>20</b> performs mixing processing in the first mixing processing portion <b>24</b>-<b>1</b>, and thereby generates the image signal of the first mixed image. The process then proceeds to step ST<b>5</b>.</p>
<p id="p-0064" num="0063">In step ST<b>5</b>, the noise removing unit <b>20</b> generates a second mixed image. The mixing section <b>24</b> in the noise removing unit <b>20</b> performs mixing processing in the second mixing processing portion <b>24</b>-<b>2</b>, and thereby generates the image signal of the second mixed image. The process then proceeds to step ST<b>6</b>.</p>
<p id="p-0065" num="0064">In step ST<b>6</b>, the noise removing unit <b>20</b> generates an output image. The mixing section <b>24</b> in the noise removing unit <b>20</b> performs mixing processing in the third mixing processing portion <b>24</b>-<b>3</b>, that is, performs mixing processing using the image signal of the second mixed image and the image signal of the input image, and thereby generates the image signal of the output image. The process then proceeds to step ST<b>7</b>.</p>
<p id="p-0066" num="0065">In step ST<b>7</b>, the noise removing unit <b>20</b> performs image output. The noise removing unit <b>20</b> outputs the image signal of the output image generated in the mixing section <b>24</b>.</p>
<p id="p-0067" num="0066">A concrete operation will next be described. <figref idref="DRAWINGS">FIG. 4</figref> illustrates a data arrangement of the input image and the output image. The following description will be made supposing that an image signal, that is, the signal of a unit pixel includes luminance signals Y<b>1</b> and Y<b>2</b> and color-difference signals Cr and Cb. In addition, the signals of coordinates (x, y) of interest will be represented as Y<b>1</b>(x, y), Y<b>2</b>(x, y), Cb(x, y), and Cr(x, y).</p>
<p id="p-0068" num="0067">The noise removing unit <b>20</b> performs noise removal using a reduced image obtained by reducing an input image, and thereby generates a noise-removed image. In addition, the noise removing unit <b>20</b> generates an enlarged image by enlarging the noise-removed image. <figref idref="DRAWINGS">FIGS. 5A to 5C</figref> shows the reduction and enlargement of an image, and represents for example a case where the first reduction processing portion <b>21</b>-<b>1</b> in the reducing section <b>21</b> generates a reduced image having a &#x2153;-fold size, and the first enlargement processing portion <b>23</b>-<b>1</b> in the enlarging section <b>23</b> generates an enlarged image having a three-fold size.</p>
<p id="p-0069" num="0068">The first reduction processing portion <b>21</b>-<b>1</b> averages signals in a pixel range of a reciprocal of the reduction ratio in a horizontal direction and a vertical direction, that is, in a range of three horizontal pixels&#xd7;three vertical pixels, and sets the average as the signal of one pixel in the reduced image. The first reduction processing portion <b>21</b>-<b>1</b> performs such processing in each of ranges of three horizontal pixels&#xd7;three vertical pixels. The first reduction processing portion <b>21</b>-<b>1</b> thereby generates a &#x2153; reduced image shown in <figref idref="DRAWINGS">FIG. 5B</figref> from an image shown in <figref idref="DRAWINGS">FIG. 5A</figref>.</p>
<p id="p-0070" num="0069">The first enlargement processing portion <b>23</b>-<b>1</b> performs image enlargement using a method such as Nearest Neighbor, Bilinear, Bicubic, or the like. When Nearest Neighbor is used, for example, the first enlargement processing portion <b>23</b>-<b>1</b> calculates the position of coordinates before the enlargement at which coordinates a pixel after the enlargement was situated, and uses the signal of a pixel nearest to the calculated position as the signal of the pixel after the enlargement. The first enlargement processing portion <b>23</b>-<b>1</b> repeats such processing, and thereby generates a x3 enlarged image shown in <figref idref="DRAWINGS">FIG. 5C</figref> from the image shown in <figref idref="DRAWINGS">FIG. 5B</figref>. Reduced images and enlarged images can also be generated at other reduction ratios and enlargement ratios by performing similar processing. Incidentally, in a case of three or more different reduction ratios as in the present embodiment, an averaging range of 18 horizontal pixels and 18 vertical pixels as in the third reduction processing portion <b>21</b>-<b>3</b>, which has a largest averaging range, and a filter region of 9 horizontal pixels and 9 vertical pixels in the third noise removal processing portion <b>22</b>-<b>3</b>, a filter range is 162 (=18&#xd7;9) horizontally and vertically in quasi terms. Hence, the noise removal processing of the third noise removal processing portion <b>22</b>-<b>3</b> is effective against low-frequency noise.</p>
<p id="p-0071" num="0070">In addition, the reducing section <b>21</b> may produce a fraction at a terminal part of reduction processing depending on the reduction ratio. In this case, the reducing section <b>21</b> may change the number of pixels to be averaged only at the terminal part. In addition, the reducing section <b>21</b> may increase or decrease the number of pixels of the input image so as not to produce a fraction.</p>
<p id="p-0072" num="0071">The data of the reduced images output from the respective reduction processing portions in the reducing section <b>21</b> may be sequentially supplied to the noise removal processing section <b>22</b>, or may be supplied to the noise removal processing section <b>22</b> after being stored in a storage area within or without the system temporarily. When the data of the reduced images is sequentially supplied from the reducing section <b>21</b> to the noise removal processing section <b>22</b>, the noise removal processing section <b>22</b> can start noise removal processing from a part whose reduction processing has been completed.</p>
<p id="p-0073" num="0072">The noise removal processing section <b>22</b> performs averaging filter processing on each pixel (x, y) of the reduced images. Various kinds of filters such as a simple low-pass filter, an epsilon filter, a bilateral filter, and the like can be used in the averaging filter processing. In addition, a range where noise can be reduced is determined by a filter range. Thus, when the noise removal processing portions <b>22</b>-<b>1</b>, <b>22</b>-<b>2</b>, and <b>22</b>-<b>3</b> use a same noise removing filter, the noise removal processing portions <b>22</b>-<b>1</b>, <b>22</b>-<b>2</b>, and <b>22</b>-<b>3</b> can perform noise removal processing whose strength increases in order of the first noise removal processing portion <b>22</b>-<b>1</b>, the second noise removal processing portion <b>22</b>-<b>2</b>, and the third noise removal processing portion <b>22</b>-<b>3</b>.</p>
<p id="p-0074" num="0073">The first noise removal processing portion <b>22</b>-<b>1</b> sets a threshold value on the basis of the luminance signal of the first reduced image generated in the first reduction processing portion <b>21</b>-<b>1</b>. For example, an average value of the luminance signal of the first reduced image is set as the threshold value. The second noise removal processing portion <b>22</b>-<b>2</b> sets a threshold value on the basis of the luminance signal of the second reduced image generated in the second reduction processing portion <b>21</b>-<b>2</b>. For example, an average value of the luminance signal of the second reduced image is set as the threshold value. The third noise removal processing portion <b>22</b>-<b>3</b> sets a threshold value on the basis of the luminance signal of the third reduced image generated in the third reduction processing portion <b>21</b>-<b>3</b>. For example, an average value of the luminance signal of the third reduced image is set as the threshold value.</p>
<p id="p-0075" num="0074">Thus, the noise removal processing section <b>22</b> sets the threshold values on the basis of the input image signals, determines image parts in which to perform noise removal using the set threshold values, and performs noise removal processing on the determined image parts.</p>
<p id="p-0076" num="0075">The numbers of pixels of the reduced images decrease in order of the &#x2153; reduced image, the 1/9 reduced image, and the 1/18 reduced image. The numbers of pixels that the respective noise removal processing portions need to process also decrease in order of the first noise removal processing portion <b>22</b>-<b>1</b>, the second noise removal processing portion <b>22</b>-<b>2</b>, and the third noise removal processing portion <b>22</b>-<b>3</b>. Therefore, when the noise removal processing portions perform noise removal processing in parallel with each other, and start the noise removal processing simultaneously, waiting times occur in the second noise removal processing portion <b>22</b>-<b>2</b> and the third noise removal processing portion <b>22</b>-<b>3</b> before the first noise removal processing portion <b>22</b>-<b>1</b> completes the processing. Hence, noise removal performance is improved by using the waiting times. Alternatively, the noise removal processing section <b>22</b> is scheduled so as not to cause the waiting times.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 6</figref> shows a configuration of the noise removal processing section <b>22</b> whose noise removal performance is improved by using the waiting times. The waiting times can be used as times for improving noise removal performance by increasing an operation scale. Hence, because of a smaller number of pixels that the second noise removal processing portion <b>22</b>-<b>2</b> needs to process than the first noise removal processing portion <b>22</b>-<b>1</b>, the second noise removal processing portion <b>22</b>-<b>2</b> performs noise removal processing using a filter with higher noise removal performance than that of the first noise removal processing portion <b>22</b>-<b>1</b>. For example, the second noise removal processing portion <b>22</b>-<b>2</b> performs noise removal processing using an epsilon filter (EPS) with higher noise removal performance than a simple low-pass filter (LPF) used in the first noise removal processing portion <b>22</b>-<b>1</b>. Similarly, because of a smaller number of pixels that the third noise removal processing portion <b>22</b>-<b>3</b> needs to process than the second noise removal processing portion <b>22</b>-<b>2</b>, the third noise removal processing portion <b>22</b>-<b>3</b> performs noise removal processing using a filter with higher noise removal performance than that of the second noise removal processing portion <b>22</b>-<b>2</b>. For example, the third noise removal processing portion <b>22</b>-<b>3</b> performs noise removal processing using a bilateral filter (BL) with higher noise removal performance than the epsilon filter (EPS) used in the second noise removal processing portion <b>22</b>-<b>2</b>.</p>
<p id="p-0078" num="0077">When scheduling is performed so as not to cause a waiting time, a noise removal processing portion that has completed processing performs noise removal for an unprocessed part that another noise removal processing portion is in charge of. In addition, the noise removal processing performed in each noise removal processing portion may be rearranged so as to reduce time differences between ends of processing in the respective noise removal processing portions.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 7</figref> shows a configuration of the noise removal processing portions allowing the rearrangement of noise removal processing. The noise removal processing portions <b>22</b>-<b>1</b>, <b>22</b>-<b>2</b>, and <b>22</b>-<b>3</b> include for example simple low-pass filters (LPF), epsilon filters (EPS), and bilateral filters (BL). In addition, the noise removal processing portions <b>22</b>-<b>1</b>, <b>22</b>-<b>2</b>, and <b>22</b>-<b>3</b> allows the rearrangement of filters for performing noise removal processing, and sets filters for performing noise removal processing so as to reduce time differences between ends of the noise removal processing. For example, the first noise removal processing portion <b>22</b>-<b>1</b> performs noise removal processing using only the simple low-pass filters (LPF). The second noise removal processing portion <b>22</b>-<b>2</b> performs noise removal processing using the simple low-pass filters (LPF) and the epsilon filters. The third noise removal processing portion <b>22</b>-<b>3</b> performs noise removal processing using the simple low-pass filters (LPF) and the bilateral filters. Incidentally, filters indicated by broken lines in <figref idref="DRAWINGS">FIG. 7</figref> output the input signals without performing noise removal processing on the input signals.</p>
<p id="p-0080" num="0079">Further, when the noise removal processing can be rearranged, a filter processing range is reduced for an input signal having a high signal level and negligible noise. Alternatively, it is possible to reduce excessive noise removal processing and increase the speed of the processing by changing to a simple filter configuration. In addition, when the filter processing range is made variably, it is possible to optimize a noise removal frequency characteristic according to the input image.</p>
<p id="p-0081" num="0080">The enlarging section <b>23</b> enlarges the reduced images from which noise is removed. For example, the enlarging section <b>23</b> enlarges the images to the size before the images are reduced in the reducing section <b>21</b>. In addition, when the images are output from the noise removing unit <b>20</b> in a predetermined size different from that of the input image, the enlargement processing portions <b>23</b>-<b>1</b>, <b>23</b>-<b>2</b>, and <b>23</b>-<b>3</b> of the enlarging section <b>23</b> enlarge the images to the predetermined size.</p>
<p id="p-0082" num="0081">The mixing section <b>24</b> performs mixing processing on the image signals of the enlarged images, and thereby generates the image signal of a mixed image. The mixing section <b>24</b> calculates a mixing ratio between the enlarged images to be mixed with each other on the basis of a correlation between the enlarged images to be mixed with each other. For example, when the enlarged images to be mixed with each other are visually similar to each other at certain coordinates (x, y), the mixing section <b>24</b> increases the ratio of the enlarged image whose reduction rate is high and whose noise is removed even in low frequencies. In addition, when the enlarged images to be mixed with each other are not visually similar to each other, the mixing section <b>24</b> increases the ratio of the enlarged image whose blur due to enlargement is small.</p>
<p id="p-0083" num="0082">As for determination as to whether the enlarged images to be mixed with each other are visually similar to each other, when a chromatic blur of a red color system is to be reduced, for example, a difference between the color-difference signals Cr is calculated. It is determined that the enlarged images to be mixed with each other are visually similar to each other when the difference is less than a threshold value set in advance, and it is determined that the enlarged images to be mixed with each other are not visually similar to each other when the difference is equal to or more than the threshold value. In addition, the color-difference signals Cr are mixed with each other according to a result of the determination.</p>
<p id="p-0084" num="0083">For example, the first mixing processing portion <b>24</b>-<b>1</b> mixes the second enlarged image generated in the second enlargement processing portion <b>23</b>-<b>2</b> and the third enlarged image generated in the third enlargement processing portion <b>23</b>-<b>3</b> with each other. The first mixing processing portion <b>24</b>-<b>1</b> calculates a difference Dcr23 (absolute value, 0&#x2266;Dcr23&#x2266;254) between the color-difference signals Cr (&#x2212;127&#x2266;Cr&#x2266;127) of the second enlarged image and the third enlarged image at certain coordinates (x, y) as in Equation (1).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Dcr</i>23(<i>x,y</i>)=|<i>us</i>3<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)&#x2212;<i>us</i>2<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)|&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0085" num="0084">The mixing ratio is set on the basis of the difference Dcr23. For example, when the difference Dcr23 is less than a threshold value &#x201c;10,&#x201d; the mixing ratio Bcr23(x, y) of the third enlarged image to the second enlarged image is determined on the basis of Equation (2). In addition, when the difference Dcr23 is equal to or more than the threshold value &#x201c;10,&#x201d; the mixing ratio Bcr23(x, y) of the third enlarged image to the second enlarged image is determined on the basis of Equation (3).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcr</i>23(<i>x,y</i>)=<i>Dcr</i>23/10(0<i>&#x2266;Dcr</i>23&#x2266;10)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcr</i>23(<i>x,y</i>)=1(10&#x2266;<i>Dcr</i>23)&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0086" num="0085">That is, the ratio of the second enlarged image is increased as the difference Dcr23 becomes larger, and only the second enlarged image is used when the difference Dcr23 is equal to or more than the threshold value.</p>
<p id="p-0087" num="0086">The first mixing processing portion <b>24</b>-<b>1</b> specifically calculates the color-difference signal b11<sub>&#x2014;</sub><i>cr</i>(x, y) at the coordinates (x, y) of the first mixed image by performing the operation of Equation (4).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>b</i>11<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)=<i>Bcr</i>23(<i>x,y</i>)&#xb7;<i>us</i>2<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)+(1&#x2212;<i>Bcr</i>23(<i>x,y</i>))&#xb7;<i>us</i>3<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0088" num="0087">The second mixing processing portion <b>24</b>-<b>2</b> mixes the first mixed image generated in the first mixing processing portion <b>24</b>-<b>1</b> and the first enlarged image generated in the first enlargement processing portion <b>23</b>-<b>1</b> with each other. The second mixing processing portion <b>24</b>-<b>2</b> calculates a difference Dcr123 (absolute value: 0&#x2266;Dcr123&#x2266;254) between the color-difference signals Cr (&#x2212;127&#x2266;Cr&#x2266;127) of the first mixed image and the first enlarged image at certain coordinates (x, y) as in Equation (5).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Dcr</i>123(<i>x,y</i>)=|<i>b</i>11<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)&#x2212;<i>us</i>1<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)|&#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0089" num="0088">The mixing ratio is set on the basis of the difference Dcr123. For example, when the difference Dcr123 is less than a threshold value &#x201c;10,&#x201d; the mixing ratio Bcr123(x, y) of the first enlarged image to the first mixed image is determined on the basis of Equation (6). In addition, when the difference Dcr123 is equal to or more than the threshold value &#x201c;10,&#x201d; the mixing ratio Bcr123(x, y) of the first enlarged image to the first mixed image is determined on the basis of Equation (7).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcr</i>123(<i>x,y</i>)=<i>Dcr</i>123/10(0<i>&#x2266;Dcr</i>123&#x2266;10)&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcr</i>123(<i>x,y</i>)=1(10<i>&#x2266;Dcr</i>123)&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0090" num="0089">That is, the ratio of the first enlarged image is increased as the difference Dcr123 becomes larger, and only the first enlarged image is used when the difference Dcr123 is equal to or more than the threshold value.</p>
<p id="p-0091" num="0090">The second mixing processing portion <b>24</b>-<b>2</b> specifically calculates the color-difference signal b12<sub>&#x2014;</sub><i>cr</i>(x, y) at the coordinates (x, y) of the second mixed image by performing the operation of Equation (8).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>b</i>12<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)=<i>Bcr</i>123(<i>x,y</i>)&#xb7;<i>us</i>1<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)+(1&#x2212;<i>Bcr</i>123(<i>x,y</i>))&#xb7;<i>b</i>11<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)&#x2003;&#x2003;(8)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0092" num="0091">The third mixing processing portion <b>24</b>-<b>3</b> mixes the second mixed image generated in the second mixing processing portion <b>24</b>-<b>2</b> and the input image with each other. The third mixing processing portion <b>24</b>-<b>3</b> calculates a difference Dcr0123 (absolute value: 0&#x2266;Dcr0123&#x2266;254) between the color-difference signals Cr (&#x2212;127&#x2266;Cr&#x2266;127) of the second mixed image and the input image at certain coordinates (x, y) as in Equation (9).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Dcr</i>0123(<i>x,y</i>)=|<i>b</i>12<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)&#x2212;<i>cr</i>(<i>x,y</i>)|&#x2003;&#x2003;(9)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0093" num="0092">The mixing ratio is set on the basis of the difference Dcr0123. For example, when the difference Dcr0123 is less than a threshold value &#x201c;10,&#x201d; the mixing ratio Bcr0123(x, y) of the input image to the second mixed image is determined on the basis of Equation (10). In addition, when the difference Dcr0123 is equal to or more than the threshold value &#x201c;10,&#x201d; the mixing ratio Bcr0123(x, y) of the input image to the second mixed image is determined on the basis of Equation (11).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcr</i>0123(<i>x,y</i>)=<i>Dcr</i>0123/10(0<i>&#x2266;Dcr</i>0123&#x3c;10)&#x2003;&#x2003;(10)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcr</i>0123(<i>x,y</i>)=1(10&#x2266;<i>Dcr</i>0123)&#x2003;&#x2003;(11)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0094" num="0093">That is, the ratio of the input image is increased as the difference Dcr0123 becomes larger, and only the input image is used when the difference Dcr0123 is equal to or more than the threshold value.</p>
<p id="p-0095" num="0094">The third mixing processing portion <b>24</b>-<b>3</b> specifically calculates the color-difference signal b13<sub>&#x2014;</sub><i>cr</i>(x, y) at the coordinates (x, y) of the output image by performing the operation of Equation (12).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>b</i>13<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)=<i>Bcr</i>0123(<i>x,y</i>)&#xb7;<i>cr</i>(<i>x,y</i>)+(1<i>&#x2212;Bcr</i>0123(<i>x,y</i>))&#xb7;<i>b</i>12<sub>&#x2014;</sub><i>cr</i>(<i>x,y</i>)&#x2003;&#x2003;(12)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0096" num="0095">In addition, when the input image has poor accuracy, or for example when the input image is a dark image having a large amount of noise, the second mixed image may be set as the output image without undergoing the processing of the third mixing processing portion <b>24</b>-<b>3</b>, by setting the mixing ratio Bcr0123=0.</p>
<p id="p-0097" num="0096">Further, while the above description has been made of the processing for the color-difference signal Cr, a chromatic blur of a blue color system can be prevented by similarly performing reduction processing, noise removal processing, enlargement processing, and mixing processing for the color-difference signal Cb.</p>
<p id="p-0098" num="0097">The mixing section <b>24</b> calculates a difference between color-difference signals Cb. The mixing section <b>24</b> determines that the enlarged images to be mixed with each other are visually similar to each other when the difference is less than a threshold value set in advance. The mixing section <b>24</b> determines that the enlarged images to be mixed with each other are not visually similar to each other when the difference is equal to or more than the threshold value. In addition, the mixing section <b>24</b> mixes the color-difference signals Cb with each other according to a result of the determination.</p>
<p id="p-0099" num="0098">For example, the first mixing processing portion <b>24</b>-<b>1</b> mixes the second enlarged image generated in the second enlargement processing portion <b>23</b>-<b>2</b> and the third enlarged image generated in the third enlargement processing portion <b>23</b>-<b>3</b> with each other. The first mixing processing portion <b>24</b>-<b>1</b> calculates a difference Dcb23 (absolute value, 0&#x2266;Dcb23&#x2266;254) between the color-difference signals Cb (&#x2212;127&#x2266;Cb&#x2266;127) of the second enlarged image and the third enlarged image at certain coordinates (x, y) as in Equation (13).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Dcb</i>23(<i>x,y</i>)=|<i>us</i>3<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)&#x2212;<i>us</i>2<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)&#x2003;&#x2003;(13)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0100" num="0099">The mixing ratio is set on the basis of the difference Dcb23. For example, when the difference Dcb23 is less than a threshold value &#x201c;10,&#x201d; the mixing ratio Bcb23(x, y) of the third enlarged image to the second enlarged image is determined on the basis of Equation (14). In addition, when the difference Dcb23 is equal to or more than the threshold value &#x201c;10,&#x201d; the mixing ratio Bcb23(x, y) of the third enlarged image to the second enlarged image is determined on the basis of Equation (15).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>23(<i>x,y</i>)=<i>Dcb</i>23/10(0<i>&#x2266;Dcb</i>23&#x3c;10)&#x2003;&#x2003;(14)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>23(<i>x,y</i>)=1(10<i>&#x2266;Dcb</i>23)&#x2003;&#x2003;(15)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0101" num="0100">That is, the ratio of the second enlarged image is increased as the difference Dcb23 becomes larger, and only the second enlarged image is used when the difference Dcb23 is equal to or more than the threshold value.</p>
<p id="p-0102" num="0101">The first mixing processing portion <b>24</b>-<b>1</b> specifically calculates the color-difference signal b11<sub>&#x2014;</sub><i>cb</i>(x, y) at the coordinates (x, y) of the first mixed image by performing the operation of Equation (16).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>b</i>11<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)=<i>Bcb</i>23(<i>x,y</i>)&#xb7;<i>us</i>2<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)+(1&#x2212;<i>Bcb</i>23(<i>x,y</i>))&#xb7;<i>us</i>3<i>cb</i>(<i>x,y</i>)&#x2003;&#x2003;(16)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0103" num="0102">The second mixing processing portion <b>24</b>-<b>2</b> mixes the first mixed image generated in the first mixing processing portion <b>24</b>-<b>1</b> and the first enlarged image generated in the first enlargement processing portion <b>23</b>-<b>1</b> with each other. The second mixing processing portion <b>24</b>-<b>2</b> calculates a difference Dcb123 (absolute value: 0 Dcb123&#x2266;254) between the color-difference signals Cb (&#x2212;127&#x2266;Cb&#x2266;127) of the first mixed image and the first enlarged image at certain coordinates (x, y) as in Equation (17).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Dcb</i>123(<i>x,y</i>)=|<i>b</i>11<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)&#x2212;<i>us</i>1<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)&#x2003;&#x2003;(17)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0104" num="0103">The mixing ratio is set on the basis of the difference Dcb123. For example, when the difference Dcb123 is less than a threshold value &#x201c;10,&#x201d; the mixing ratio Bcb123(x, y) of the first enlarged image to the first mixed image is determined on the basis of Equation (18). In addition, when the difference Dcb123 is equal to or more than the threshold value &#x201c;10,&#x201d; the mixing ratio Bcb123(x, y) of the first enlarged image to the first mixed image is determined on the basis of Equation (19).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>123(<i>x,y</i>)=<i>Dcb</i>123/10(0<i>&#x2266;Dcb</i>123&#x3c;10)&#x2003;&#x2003;(18)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>123(<i>x,y</i>)=1(10&#x2266;<i>Dcb</i>123)&#x2003;&#x2003;(19)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0105" num="0104">That is, the ratio of the first enlarged image is increased as the difference Dcb123 becomes larger, and only the first enlarged image is used when the difference Dcb123 is equal to or more than the threshold value.</p>
<p id="p-0106" num="0105">The second mixing processing portion <b>24</b>-<b>2</b> specifically calculates the color-difference signal b12<sub>&#x2014;</sub><i>cb</i>(x, y) at the coordinates (x, y) of the second mixed image by performing the operation of Equation (20).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>b</i>12<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)=<i>Bcb</i>123(<i>x,y</i>)&#xb7;<i>us</i>1<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)+(1&#x2212;<i>Bcb</i>123(<i>x,y</i>))&#xb7;<i>b</i>11<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)&#x2003;&#x2003;(20)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0107" num="0106">The third mixing processing portion <b>24</b>-<b>3</b> mixes the second mixed image generated in the second mixing processing portion <b>24</b>-<b>2</b> and the input image with each other. The third mixing processing portion <b>24</b>-<b>3</b> calculates a difference Dcb0123 (absolute value: 0&#x2266;Dcb0123&#x2266;254) between the color-difference signals Cb (&#x2212;127&#x2266;Cb&#x2266;127) of the second mixed image and the input image at certain coordinates (x, y) as in Equation (21).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Dcb</i>0123(<i>x,y</i>)=|<i>b</i>12<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)&#x2212;<i>cb</i>(<i>x,y</i>)&#x2003;&#x2003;(21)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0108" num="0107">The mixing ratio is set on the basis of the difference Dcb0123. For example, when the difference Dcb0123 is less than a threshold value &#x201c;10,&#x201d; the mixing ratio Bcb0123(x, y) of the input image to the second mixed image is determined on the basis of Equation (22). In addition, when the difference Dcb0123 is equal to or more than the threshold value &#x201c;10,&#x201d; the mixing ratio Bcb0123(x, y) of the input image to the second mixed image is determined on the basis of Equation (23).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>0123(<i>x,y</i>)=<i>Dcb</i>0123/10(0<i>&#x2266;Dcb</i>0123&#x3c;10)&#x2003;&#x2003;(22)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>0123(<i>x,y</i>)=1(10<i>&#x2266;Dcb</i>0123)&#x2003;&#x2003;(23)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0109" num="0108">That is, the ratio of the input image is increased as the difference Dcb0123 becomes larger, and only the input image is used when the difference Dcb0123 is equal to or more than the threshold value.</p>
<p id="p-0110" num="0109">The third mixing processing portion <b>24</b>-<b>3</b> specifically calculates the color-difference signal b13<sub>&#x2014;</sub><i>cb</i>(x, y) at the coordinates (x, y) of the third mixed image by performing the operation of Equation (24).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>b</i>13<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)=<i>Bcb</i>0123(<i>x,y</i>)&#xb7;<i>cb</i>(<i>x,y</i>)+(1<i>&#x2212;Bcb</i>0123(<i>x,y</i>))&#xb7;<i>b</i>12<sub>&#x2014;</sub><i>cb</i>(<i>x,y</i>)&#x2003;&#x2003;(24)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0111" num="0110">In addition, when the input image has poor accuracy, the second mixed image may be set as the output image without undergoing the processing of the third mixing processing portion <b>24</b>-<b>3</b>, by setting the mixing ratio Bcb0123=0.</p>
<p id="p-0112" num="0111">Further, while the mixing section <b>24</b> calculates the mixing ratios individually using the color-difference signals Cr and Cb, the mixing ratios calculated in the processing for one color-difference signal may be used in the processing for the other color-difference signal. For example, the mixing ratios calculated for the color-difference signal Cr may be used as the mixing ratios in the processing for the color-difference signal Cb. Specifically, the mixing ratios Bcb23, Bcb123, and Bcb0123 are set as in Equations (25) to (27). In this case, the mixing section <b>24</b> does not need to calculate the mixing ratios using each of the color-difference signals. The mixing section <b>24</b> can therefore perform mixing processing at a higher speed than in the case of calculating the mixing ratios individually using each of the color-difference signals.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>23<i>=Bcr</i>23&#x2003;&#x2003;(25)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>123=<i>Bcr</i>123&#x2003;&#x2003;(26)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Bcb</i>0123=<i>Bcr</i>0123&#x2003;&#x2003;(27)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0113" num="0112">In addition, the index for determining the mixing ratios is not limited to the difference between the color-difference signals of the images to be mixed with each other, but a difference according to visual characteristics may be used. In addition, when the image signal of the input image is that of an L*a*b* color system, the mixing ratios may be determined on the basis of Color Difference &#x394;E*ab=[(&#x394;L*)<sup>2</sup>+(&#x394;a*)<sup>2</sup>+(&#x394;b*)<sup>2</sup>]<sup>1/2</sup>.</p>
<p id="p-0114" num="0113">Thus, because noise is removed from images reduced at a plurality of reduction ratios, the chromatic blurs of edge parts in the respective enlarged images differ from each other. Therefore, when two or more different enlarged images are mixed with each other, an image of excellent image quality without a loss of sharpness of edge parts can be obtained. For example, the correlation between enlarged images to be mixed with each other is determined using the color-difference signals of the enlarged images to be mixed with each other, and the ratio of the enlarged image after the noise processing of a reduced image reduced at a high reduction ratio is increased in a part where the correlation is low and a chromatic blur is conspicuous. Specifically, the first mixing processing portion <b>24</b>-<b>1</b> increases the ratio of the enlarged image after the noise processing of the reduced image reduced at a high reduction ratio ( 1/9 reduced image), and decreases the ratio of the enlarged image after the noise processing of the reduced image reduced at a low reduction ratio ( 1/18 reduced image). When the mixing ratio is thus set, the ratio of the enlarged image that tends to cause a chromatic blur is reduced in a part where a chromatic blur tends to be conspicuous. Therefore an image of excellent image quality with a reduced chromatic blur can be obtained. In addition, the ratio of the enlarged image after the noise processing of the reduced image reduced at the low reduction ratio is increased in a part where a chromatic blur tends to be inconspicuous. It is thereby possible to remove noise in a large region, and obtain a strong noise removing effect. In addition, when a filter configuration is set according to the reduction ratios, efficient filter processing can be performed without wasting a time necessary for noise removal.</p>
<heading id="h-0013" level="1">3. Second Embodiment</heading>
<p id="p-0115" num="0114">A region in which a chromatic blur occurs generally exists in only a part of an input image. In addition, degradation in resolution occurs when an averaging filter removes noise. Thus, a color region in which a chromatic blur tends to occur may be determined, and the mixing ratio of the input image not subjected to filter processing may be increased in only the part of the determined color region, thereby weakening the strength of the processing and thus reducing the chromatic blur. In the second embodiment, description will be made of a case of controlling the mixing ratio on the basis of a result of determination of a color region.</p>
<heading id="h-0014" level="1">3-1. Configuration of Second Embodiment</heading>
<p id="p-0116" num="0115"><figref idref="DRAWINGS">FIG. 8</figref> shows a configuration of a second embodiment of the noise removing unit. As in the first embodiment, a noise removing unit <b>20</b><i>a </i>includes a reducing section <b>21</b>, a noise removal processing section <b>22</b>, an enlarging section <b>23</b>, and a mixing section <b>24</b>. The second embodiment further includes a color determining section <b>25</b>.</p>
<p id="p-0117" num="0116">The reducing section <b>21</b> reduces an input image. For example, a first reduction processing portion <b>21</b>-<b>1</b> reduces the input image to a first size, and outputs the image signal of the first reduced image to the noise removal processing section <b>22</b>. A second reduction processing portion <b>21</b>-<b>2</b> reduces the input image to a second size, and outputs the image signal of the second reduced image to the noise removal processing section <b>22</b>. A third reduction processing portion <b>21</b>-<b>3</b> reduces the input image to a third size, and outputs the image signal of the third reduced image to the noise removal processing section <b>22</b>.</p>
<p id="p-0118" num="0117">The noise removal processing section <b>22</b> performs noise removal processing on the image signals supplied from the reducing section <b>21</b>. For example, a first noise removal processing portion <b>22</b>-<b>1</b> performs filter processing on the image signal output from the first reduction processing portion <b>21</b>-<b>1</b> in the reducing section <b>21</b>, thereby removing the noise of the image signal. The first noise removal processing portion <b>22</b>-<b>1</b> outputs the image signal to the enlarging section <b>23</b>. A second noise removal processing portion <b>22</b>-<b>2</b> performs filter processing on the image signal output from the second reduction processing portion <b>21</b>-<b>2</b> in the reducing section <b>21</b>, thereby removing the noise of the image signal. The second noise removal processing portion <b>22</b>-<b>2</b> outputs the image signal to the enlarging section <b>23</b>. A third noise removal processing portion <b>22</b>-<b>3</b> performs filter processing on the image signal output from the third reduction processing portion <b>21</b>-<b>3</b> in the reducing section <b>21</b>, thereby removing the noise of the image signal. The third noise removal processing portion <b>22</b>-<b>3</b> outputs the image signal to the enlarging section <b>23</b>.</p>
<p id="p-0119" num="0118">The enlarging section <b>23</b> performs image enlargement using the image signals supplied from the noise removal processing section <b>22</b>. For example, a first enlargement processing portion <b>23</b>-<b>1</b> performs enlargement processing using the image signal output from the first noise removal processing portion <b>22</b>-<b>1</b> in the noise removal processing section <b>22</b>, thereby generating the image signal of an enlarged image obtained by enlarging the image to a first size. The first enlargement processing portion <b>23</b>-<b>1</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>. A second enlargement processing portion <b>23</b>-<b>2</b> performs enlargement processing using the image signal output from the second noise removal processing portion <b>22</b>-<b>2</b> in the noise removal processing section <b>22</b>, thereby generating the image signal of an enlarged image obtained by enlarging the image to a second size. The second enlargement processing portion <b>23</b>-<b>2</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>. A third enlargement processing portion <b>23</b>-<b>3</b> performs enlargement processing using the image signal output from the third noise removal processing portion <b>22</b>-<b>3</b> in the noise removal processing section <b>22</b>, thereby generating the image signal of an enlarged image obtained by enlarging the image to a third size. The third enlargement processing portion <b>23</b>-<b>3</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>.</p>
<p id="p-0120" num="0119">The mixing section <b>24</b> performs mixing processing on the images output from the enlarging section <b>23</b>. For example, a first mixing processing portion <b>24</b>-<b>1</b> performs mixing processing using the image signal output from the second enlargement processing portion <b>23</b>-<b>2</b> in the enlarging section <b>23</b> and the image signal output from the third enlargement processing portion <b>23</b>-<b>3</b>, thereby generating the image signal of a first mixed image. A second mixing processing portion <b>24</b>-<b>2</b> performs mixing processing using the image signal of the first mixed image output from the first mixing processing portion <b>24</b>-<b>1</b> and the image signal output from the first enlargement processing portion <b>23</b>-<b>1</b> in the enlarging section <b>23</b>, thereby generating the image signal of a second mixed image. A third mixing processing portion <b>24</b>-<b>3</b> performs mixing processing using the image signal of the second mixed image output from the second mixing processing portion <b>24</b>-<b>2</b> and the image signal of the input image, thereby generating the image signal of an output image. Further, the third mixing processing portion <b>24</b>-<b>3</b> increases the ratio of an image having a high reduction ratio, that is, the input image (reduction ratio of 100%) in a color region in which a chromatic blur tends to occur on the basis of a result of color determination, and thereby reducing the chromatic blur.</p>
<p id="p-0121" num="0120">The color determining section <b>25</b> determines the color of each pixel from luminance signals and color-difference signals, and outputs a result of the color determination to the mixing section <b>24</b>. Various methods can be used for color determination processing by the color determining section <b>25</b>. For example, the color determining section <b>25</b> determines the color of each pixel from the signal levels of the luminance signals and the color-difference signals.</p>
<heading id="h-0015" level="1">3-2. Operation of Second Embodiment</heading>
<p id="p-0122" num="0121"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating the operation of the second embodiment, that is, the operation of the noise removing unit <b>20</b><i>a</i>. In step ST<b>11</b>, the noise removing unit <b>20</b><i>a </i>generates reduced images. The reducing section <b>21</b> in the noise removing unit <b>20</b><i>a </i>generates the image signals of the reduced images using an image signal supplied from the signal converting section <b>14</b>. The process then proceeds to step ST<b>12</b>.</p>
<p id="p-0123" num="0122">In step ST<b>12</b>, the noise removing unit <b>20</b><i>a </i>generates noise-removed images. The noise removal processing section <b>22</b> in the noise removing unit <b>20</b><i>a </i>performs noise removal processing using the image signals of the reduced images, thereby generating the image signals of the noise-removed images. The process then proceeds to step ST<b>13</b>.</p>
<p id="p-0124" num="0123">In step ST<b>13</b>, the noise removing unit <b>20</b><i>a </i>generates enlarged images. The enlarging section <b>23</b> in the noise removing unit <b>20</b><i>a </i>performs image enlargement processing using the image signals of the noise-removed images, thereby generating the image signals of the enlarged images. The process then proceeds to step ST<b>14</b>.</p>
<p id="p-0125" num="0124">In step ST<b>14</b>, the noise removing unit <b>20</b><i>a </i>generates a first mixed image. The mixing section <b>24</b> in the noise removing unit <b>20</b><i>a </i>performs mixing processing in the first mixing processing portion <b>24</b>-<b>1</b>, thereby generating the image signal of the first mixed image. The process then proceeds to step ST<b>15</b>.</p>
<p id="p-0126" num="0125">In step ST<b>15</b>, the noise removing unit <b>20</b><i>a </i>generates a second mixed image. The mixing section <b>24</b> in the noise removing unit <b>20</b><i>a </i>performs mixing processing in the second mixing processing portion <b>24</b>-<b>2</b>, thereby generating the image signal of the second mixed image. The process then proceeds to step ST<b>16</b>.</p>
<p id="p-0127" num="0126">In step ST<b>16</b>, the noise removing unit <b>20</b><i>a </i>determines whether a pixel of interest is in a predetermined color region. The color determining section <b>25</b> in the noise removing unit <b>20</b><i>a </i>determines the color of each pixel, and outputs a result of the determination to the mixing section <b>24</b>. On the basis of the result of the color determination, the mixing section <b>24</b> proceeds to step ST<b>17</b> when the pixel is in the predetermined color region, and proceeds to step ST<b>18</b> when the pixel is not in the predetermined color region.</p>
<p id="p-0128" num="0127">In step ST<b>17</b>, the noise removing unit <b>20</b><i>a </i>changes a mixing ratio. The mixing section <b>24</b> in the noise removing unit <b>20</b><i>a </i>increases the ratio of the input image by changing the mixing ratio when the third mixing processing portion <b>24</b>-<b>3</b> mixes the second enlarged image and the input image with each other. The process then proceeds to step ST<b>18</b>.</p>
<p id="p-0129" num="0128">In step ST<b>18</b>, the noise removing unit <b>20</b><i>a </i>generates an output image. The mixing section <b>24</b> in the noise removing unit <b>20</b><i>a </i>performs mixing processing in the third mixing processing portion <b>24</b>-<b>3</b>, that is, performs mixing processing using the image signal of the second mixed image and the image signal of the input image, thereby generating the image signal of the output image. The process then proceeds to step ST<b>19</b>.</p>
<p id="p-0130" num="0129">In step ST<b>19</b>, the noise removing unit <b>20</b><i>a </i>performs image output. The noise removing unit <b>20</b><i>a </i>outputs the image signal of the output image generated in the mixing section <b>24</b>.</p>
<p id="p-0131" num="0130">When the ratio of the input image is thus increased in the predetermined color region, the chromatic blur can be reduced. In addition, when smoothing processing is performed using only pixels whose differences in luminance value are within a predetermined threshold value as in Patent Document 1, a color region of small luminance differences is not excluded from the smoothing processing, so that sharpness is lost in the color region of the small luminance differences. However, the present technology can prevent the loss of sharpness by making color determination, increasing the ratio of an image having a high reduction ratio in a predetermined color region, and thereby weakening the strength of noise removal processing. Incidentally, while the image signal generated by performing mixing processing in the third mixing processing portion <b>24</b>-<b>3</b> is set as the image signal of the output image in <figref idref="DRAWINGS">FIG. 8</figref> and <figref idref="DRAWINGS">FIG. 9</figref>, the image signal generated by performing mixing processing in the second mixing processing portion <b>24</b>-<b>2</b>, for example, can also be set as the image signal of the output image. In this case, the second mixing processing portion <b>24</b>-<b>2</b> can reduce a chromatic blur by increasing the ratio of an image having a high reduction ratio, that is, the image signal output from the first enlargement processing portion <b>23</b>-<b>1</b> in a color region in which a chromatic blur tends to occur on the basis of a result of color determination.</p>
<heading id="h-0016" level="1">4. Third Embodiment</heading>
<p id="p-0132" num="0131">As described above, a region in which a chromatic blur occurs generally exists in only a part of an input image. Therefore, by determining a color region in which a chromatic blur tends to occur and changing filter processing in only the part of the region, it is possible to improve edge extraction performance and noise removing performance and thus improve image quality, and by reducing an operation scale in a region in which a chromatic blur does not occur easily, it is possible to achieve higher speed. In the third embodiment, description will be made of a case of controlling filter processing operation on the basis of a result of determination of a color region.</p>
<heading id="h-0017" level="1">4-1. Configuration of Third Embodiment</heading>
<p id="p-0133" num="0132"><figref idref="DRAWINGS">FIG. 10</figref> shows a configuration of a third embodiment of the noise removing unit. As in the second embodiment, a noise removing unit <b>20</b><i>b </i>includes a reducing section <b>21</b>, a noise removal processing section <b>22</b>, an enlarging section <b>23</b>, a mixing section <b>24</b>, and a color determining section <b>25</b>.</p>
<p id="p-0134" num="0133">The reducing section <b>21</b> reduces an input image. For example, a first reduction processing section <b>21</b>-<b>1</b> reduces the input image to a first size, and outputs the image signal of the first reduced image to the noise removal processing section <b>22</b>. A second reduction processing portion <b>21</b>-<b>2</b> reduces the input image to a second size, and outputs the image signal of the second reduced image to the noise removal processing section <b>22</b>. A third reduction processing portion <b>21</b>-<b>3</b> reduces the input image to a third size, and outputs the image signal of the third reduced image to the noise removal processing section <b>22</b>.</p>
<p id="p-0135" num="0134">The noise removal processing section <b>22</b> performs noise removal processing on the image signals supplied from the reducing section <b>21</b>. For example, a first noise removal processing portion <b>22</b>-<b>1</b> performs filter processing on the image signal output from the first reduction processing portion <b>21</b>-<b>1</b> in the reducing section <b>21</b>, thereby removing the noise of the image signal. The first noise removal processing portion <b>22</b>-<b>1</b> outputs the image signal to the enlarging section <b>23</b>. A second noise removal processing portion <b>22</b>-<b>2</b> performs filter processing on the image signal output from the second reduction processing portion <b>21</b>-<b>2</b> in the reducing section <b>21</b>, thereby removing the noise of the image signal. The second noise removal processing portion <b>22</b>-<b>2</b> outputs the image signal to the enlarging section <b>23</b>. A third noise removal processing portion <b>22</b>-<b>3</b> performs filter processing on the image signal output from the third reduction processing portion <b>21</b>-<b>3</b> in the reducing section <b>21</b>, thereby removing the noise of the image signal. The third noise removal processing portion <b>22</b>-<b>3</b> outputs the image signal to the enlarging section <b>23</b>.</p>
<p id="p-0136" num="0135">In addition, as shown in <figref idref="DRAWINGS">FIG. 7</figref>, the noise removal processing section <b>22</b> can rearrange noise removal processing. The noise removal processing section <b>22</b> selects filters used for the noise removal processing on the basis of a result of color determination from the color determining section <b>25</b>. For example, the noise removal processing section <b>22</b> performs noise removal processing with priority given to processing speed or noise removal processing with priority given to noise removal performance.</p>
<p id="p-0137" num="0136">The enlarging section <b>23</b> performs image enlargement using the image signals supplied from the noise removal processing section <b>22</b>. For example, a first enlargement processing portion <b>23</b>-<b>1</b> performs enlargement processing using the image signal output from the first noise removal processing portion <b>22</b>-<b>1</b> in the noise removal processing section <b>22</b>, thereby generating the image signal of an enlarged image obtained by enlarging the image to a first size. The first enlargement processing portion <b>23</b>-<b>1</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>. A second enlargement processing portion <b>23</b>-<b>2</b> performs enlargement processing using the image signal output from the second noise removal processing portion <b>22</b>-<b>2</b> in the noise removal processing section <b>22</b>, thereby generating the image signal of an enlarged image obtained by enlarging the image to a second size. The second enlargement processing portion <b>23</b>-<b>2</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>. A third enlargement processing portion <b>23</b>-<b>3</b> performs enlargement processing using the image signal output from the third noise removal processing portion <b>22</b>-<b>3</b> in the noise removal processing section <b>22</b>, thereby generating the image signal of an enlarged image obtained by enlarging the image to a third size. The third enlargement processing portion <b>23</b>-<b>3</b> outputs the image signal of the enlarged image to the mixing section <b>24</b>.</p>
<p id="p-0138" num="0137">The mixing section <b>24</b> performs mixing processing on the images output from the enlarging section <b>23</b>. For example, a first mixing processing portion <b>24</b>-<b>1</b> performs mixing processing using the image signal output from the second enlargement processing portion <b>23</b>-<b>2</b> in the enlarging section <b>23</b> and the image signal output from the third enlargement processing portion <b>23</b>-<b>3</b>, thereby generating the image signal of a first mixed image. A second mixing processing portion <b>24</b>-<b>2</b> performs mixing processing using the image signal of the first mixed image output from the first mixing processing portion <b>24</b>-<b>1</b> and the image signal output from the first enlargement processing portion <b>23</b>-<b>1</b> in the enlarging section <b>23</b>, thereby generating the image signal of a second mixed image. A third mixing processing portion <b>24</b>-<b>3</b> performs mixing processing using the image signal of the second mixed image output from the second mixing processing portion <b>24</b>-<b>2</b> and the image signal of the input image, thereby generating the image signal of an output image.</p>
<p id="p-0139" num="0138">The color determining section <b>25</b> determines the color of each pixel from luminance signals and color-difference signals, and outputs a result of the color determination to the noise removal processing section <b>22</b>. Various methods can be used for color determination processing by the color determining section <b>25</b>. For example, the color determining section <b>25</b> determines the color of each pixel from the signal levels of the luminance signals and the color-difference signals. Incidentally, the color determining section <b>25</b> may supply the color determination result to the control section <b>30</b> so that the control section <b>30</b> changes the noise removal processing performed in the noise removal processing section <b>22</b> of the noise removing unit <b>20</b><i>b. </i></p>
<heading id="h-0018" level="1">4-2. Operation of Third Embodiment</heading>
<p id="p-0140" num="0139"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart illustrating the operation of the third embodiment, that is, the operation of the noise removing unit <b>20</b><i>b</i>. In step ST<b>31</b>, the noise removing unit <b>20</b><i>b </i>generates reduced images. The reducing section <b>21</b> in the noise removing unit <b>20</b><i>b </i>generates the image signals of the reduced images using an image signal supplied from the signal converting section <b>14</b>. The process then proceeds to step ST<b>32</b>.</p>
<p id="p-0141" num="0140">In step ST<b>32</b>, the noise removing unit <b>20</b><i>b </i>determines whether a pixel of interest is in a predetermined color region. The color determining section <b>25</b> in the noise removing unit <b>20</b><i>b </i>determines the color of each pixel, and outputs a result of the determination to the noise removal processing section <b>22</b>. On the basis of the result of the color determination, the noise removal processing section <b>22</b> proceeds to step ST<b>33</b> when the pixel is in the predetermined color region, and proceeds to step ST<b>34</b> when the pixel is not in the predetermined color region.</p>
<p id="p-0142" num="0141">In step ST<b>33</b>, the noise removing unit <b>20</b><i>b </i>makes a high-speed noise removal setting. The noise removal processing section <b>22</b> in the noise removing unit <b>20</b><i>b </i>selects filters used for noise removal processing so that the noise removal processing section <b>22</b> performs noise removal processing with priority given to processing speed. The process then proceeds to step ST<b>35</b>. For example, the noise removal processing section <b>22</b> performs noise removal processing using only simple low-pass filters (LPFs).</p>
<p id="p-0143" num="0142">In step S<b>34</b>, the noise removing unit <b>20</b><i>b </i>makes a high-performance noise removal setting. The noise removal processing section <b>22</b> in the noise removing unit <b>20</b><i>b </i>selects filters used for noise removal processing so that the noise removal processing section <b>22</b> performs noise removal processing with priority given to noise removal performance. The process then proceeds to step ST<b>35</b>. For example, the noise removal processing section <b>22</b> performs noise removal processing using bilateral filters (BL) or a combination of bilateral filters and other filters.</p>
<p id="p-0144" num="0143">In step S<b>35</b>, the noise removing unit <b>20</b><i>b </i>generates noise-removed images. The noise removal processing section <b>22</b> in the noise removing unit <b>20</b><i>b </i>performs noise removal processing on the image signals of the reduced images using the filters set in step ST<b>33</b> or step ST<b>34</b>, thereby generating the image signals of the noise-removed images. The process then proceeds to step ST<b>36</b>.</p>
<p id="p-0145" num="0144">In step ST<b>36</b>, the noise removing unit <b>20</b><i>b </i>generates enlarged images. The enlarging section <b>23</b> in the noise removing unit <b>20</b><i>b </i>performs image enlargement processing using the image signals of the noise-removed images, thereby generating the image signals of the enlarged images. The process then proceeds to step ST<b>37</b>.</p>
<p id="p-0146" num="0145">In step ST<b>37</b>, the noise removing unit <b>20</b><i>b </i>generates a first mixed image. The mixing section <b>24</b> in the noise removing unit <b>20</b><i>b </i>performs mixing processing in the first mixing processing portion <b>24</b>-<b>1</b>, thereby generating the image signal of the first mixed image. The process then proceeds to step ST<b>38</b>.</p>
<p id="p-0147" num="0146">In step ST<b>38</b>, the noise removing unit <b>20</b><i>b </i>generates a second mixed image. The mixing section <b>24</b> in the noise removing unit <b>20</b><i>b </i>performs mixing processing in the second mixing processing portion <b>24</b>-<b>2</b>, thereby generating the image signal of the second mixed image. The process then proceeds to step ST<b>39</b>.</p>
<p id="p-0148" num="0147">In step ST<b>39</b>, the noise removing unit <b>20</b><i>b </i>generates an output image. The mixing section <b>24</b> in the noise removing unit <b>20</b><i>b </i>performs mixing processing in the third mixing processing portion <b>24</b>-<b>3</b>, that is, performs mixing processing using the image signal of the second mixed image and the image signal of the input image, thereby generating the image signal of the output image. The process then proceeds to step ST<b>40</b>.</p>
<p id="p-0149" num="0148">In step ST<b>40</b>, the noise removing unit <b>20</b><i>b </i>performs image output. The noise removing unit <b>20</b><i>b </i>outputs the image signal of the output image generated in the mixing section <b>24</b>.</p>
<p id="p-0150" num="0149">Thus, the noise removal processing section is formed by a plurality of kinds of filters, and has a rearrangeable filter configuration. On a basis of a result of determination of the color of the input image, a first filter configuration with high noise removal performance is used for a particular color, and a second filter configuration with high processing speed is used for other than the particular color. With such filter configurations, an image of excellent image quality without a loss of sharpness in edge parts can be obtained efficiently.</p>
<p id="p-0151" num="0150">The series of processes described in the specification can be performed by hardware, software, or a composite configuration of both hardware and software. When processing is performed by software, a program in which a processing sequence is recorded is executed after being installed into a memory within a computer incorporated in dedicated hardware. Alternatively, the program can be executed after being installed on a general-purpose computer capable of performing various kinds of processing.</p>
<p id="p-0152" num="0151">For example, the program can be recorded on a hard disk or a ROM (Read Only Memory) as a recording medium in advance. Alternatively, the program can be stored (recorded) temporarily or permanently on a removable recording medium such as a flexible disk, a CD-ROM (Compact Disc Read Only Memory), an MO (Magneto-Optical) disk, a DVD (Digital Versatile Disc), a magnetic disk, a semiconductor memory, or the like. Such a removable recording medium can be provided as so-called packaged software.</p>
<p id="p-0153" num="0152">In addition to being installed from a removable recording medium as described above onto a computer, the program is transferred by radio from a download site to a computer or transferred by wire to a computer via networks such as a LAN (Local Area Network), the Internet, and the like. The computer can receive the program transferred in such a manner, and install the program onto a recording medium such as a built-in hard disk or the like.</p>
<p id="p-0154" num="0153">Further, the reduction ratios and the enlargement ratios are not limited to the above-described illustrations. In addition, while description has been made of a case where the reducing section generates reduced images in three stages, the reducing section may generate reduction ratios in two stages or four stages or more. In addition, the processing of the noise removal processing section <b>22</b> may be performed by another configuration, and a path in which no processing is performed according to an externally specified value may be provided. Effects of the present technology are not limited to color noise, but the present technical idea is also applicable to noise included in luminance signals. There is only a difference between color-difference signals and luminance signals in that characteristics of frequency and amplitude of noise differ between color-difference signals and luminance signals and thus an optimum filter range and a threshold value differ between color-difference signals and luminance signals. In addition, the image processing device is not only applicable to imaging devices but also applicable to devices for performing image recording and reproduction, editing, output, and the like, for example image editing devices, image recording and reproducing devices, printers, and the like.</p>
<p id="p-0155" num="0154">The present technology is not to be construed as being limited to the foregoing embodiments. The embodiments of the present technology disclose the present technology in an illustrative form. It is obvious that modifications and substitutions in the embodiments can be made by those skilled in the art without departing from the spirit of the present technology. That is, in order to determine the spirit of the present technology, claims are to be considered.</p>
<p id="p-0156" num="0155">According to an image processing device and an image processing method according to an embodiment of the present technology, an input image is reduced at a plurality of reduction ratios, and noise-removed images are generated by performing noise removal processing on each of a plurality of reduced images. In addition, enlarged images equal to each other in size are generated by enlarging each of the noise-removed images, and an output image is generated by mixing two or more different enlarged images with each other. Because noise removal is thus applied to the images reduced at the plurality of reduction ratios, chromatic blurs in edge parts of the respective enlarged images are different from each other. Mixing two or more different enlarged images with each other can provide an image of excellent image quality without a loss of sharpness in edge parts. The present technology is therefore suitable for devices for performing image recording and reproduction, editing, output, and the like, for example imaging devices, image editing devices, image recording and reproducing devices, printers, and the like.</p>
<p id="p-0157" num="0156">The present technology contains subject matter related to that disclosed in Japanese Priority Patent Application JP 2011-081543 filed in the Japan Patent Office on Apr. 1, 2011, the entire content of which is hereby incorporated by reference.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing device comprising:
<claim-text>a reducing section configured to generate a plurality of reduced images by reducing an input image at a plurality of reduction ratios;</claim-text>
<claim-text>a noise removal processing section configured to generate noise-removed images by performing noise removal processing on each of said reduced images;</claim-text>
<claim-text>an enlarging section configured to generate enlarged images equal to each other in size by enlarging each of said noise-removed images; and</claim-text>
<claim-text>a mixing section configured to generate an output image by mixing two or more different enlarged images of said enlarged images with each other,</claim-text>
<claim-text>wherein said mixing section calculates a mixing ratio between the enlarged images to be mixed with each other on a basis of correlation between the enlarged images to be mixed with each other,</claim-text>
<claim-text>wherein said mixing section increases a ratio of an image having a high reduction ratio as said correlation is decreased.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a color determining section configured to determine a color of said input image, wherein said mixing section generates said output image by mixing said input image and an enlarged image after said mixing with each other, and increases or decreases a mixing ratio between said images to be mixed with each other for a particular color on a basis of a result of color determination.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said mixing section increases a ratio of an image having a high said reduction ratio when said input image is of said particular color.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said noise removal processing section is formed by using a plurality of kinds of filters, and has a rearrangeable filter configuration for performing the noise removal processing on said reduced images.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image processing device according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising
<claim-text>a color determining section configured to determine a color of said input image,</claim-text>
<claim-text>wherein said noise removal processing section changes said filter configuration according to a result of color determination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The image processing device according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein said noise removal processing section uses a first filter configuration for a particular color and uses a second filter configuration for other than said particular color on a basis of the result of the color determination, said first filter configuration being a filter configuration with higher noise removal performance than said second filter configuration, and said second filter configuration being a filter configuration with higher processing speed than said first filter configuration.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An image processing method comprising:
<claim-text>generating a plurality of reduced images by reducing an input image at a plurality of reduction ratios;</claim-text>
<claim-text>generating noise-removed images by performing noise removal processing on each of said reduced images;</claim-text>
<claim-text>generating enlarged images equal to each other in size by enlarging each of said noise-removed images; and</claim-text>
<claim-text>generating an output image by mixing two or more different enlarged images of said enlarged images with each other;</claim-text>
<claim-text>determining a color of said input image;</claim-text>
<claim-text>wherein said output image is generated by mixing said input image and an enlarged image after said mixing with each other, and increases or decreases a mixing ratio between said images to be mixed with each other for a particular color based on result of color determination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An image processing device comprising:
<claim-text>a reducing section configured to generate a plurality of reduced images by reducing an input image at a plurality of reduction ratios;</claim-text>
<claim-text>a noise removal processing section configured to generate noise-removed images by performing noise removal processing on each of said reduced images;</claim-text>
<claim-text>an enlarging section configured to generate enlarged images equal to each other in size by enlarging each of said noise-removed images;</claim-text>
<claim-text>a mixing section configured to generate an output image by mixing two or more different enlarged images of said enlarged images with each other; and</claim-text>
<claim-text>a color determining section configured to determine a color of said input image,</claim-text>
<claim-text>wherein said noise removal processing section uses a first filter configuration for a particular color and uses a second filter configuration for other than said particular color based on the result of the color determination, said first filter configuration being a filter configuration with higher noise removal performance than said second filter configuration, and said second filter configuration being a filter configuration with higher processing speed than said first filter configuration.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The image processing device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said mixing section calculates said mixing ratio using color-difference signals of said enlarged images to be mixed with each other.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The image processing device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said noise removal processing section is formed by using a plurality of kinds of filters, and has a rearrangeable filter configuration for performing the noise removal processing on said reduced images.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The image processing device according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising
<claim-text>wherein said noise removal processing section changes said filter configuration according to a result of color determination.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
