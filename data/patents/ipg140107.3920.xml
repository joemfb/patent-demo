<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624988-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624988</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12123201</doc-number>
<date>20080519</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2007-171249</doc-number>
<date>20070628</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>894</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>228</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>03</class>
<subclass>B</subclass>
<main-group>17</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>3482221</main-classification>
<further-classification>382118</further-classification>
<further-classification>396263</further-classification>
</classification-national>
<invention-title id="d2e71">Image pickup apparatus, image pickup method, and program thereof</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7248300</doc-number>
<kind>B1</kind>
<name>Ono</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34833303</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7574128</doc-number>
<kind>B2</kind>
<name>Matsuda</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396264</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7630015</doc-number>
<kind>B2</kind>
<name>Okamura</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348371</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2007/0025722</doc-number>
<kind>A1</kind>
<name>Matsugu et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396263</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>CN</country>
<doc-number>1905629</doc-number>
<kind>A</kind>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>2000-347277</doc-number>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>2000-347278</doc-number>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>2003-92701</doc-number>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>2004-294498</doc-number>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2006-237803</doc-number>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>2007-67560</doc-number>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2007-104235</doc-number>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>U.S. Appl. No. 12/601,838, filed Nov. 25, 2009, Suzuki, et al.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>U.S. Appl. No. 12/100,516, filed Apr. 10, 2008, Abe.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>U.S. Appl. No. 12/107,314, filed Apr. 22, 2008, Abe.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>U.S. Appl. No. 12/126,401, filed May 23, 2008, Abe.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Office Action issued Jul. 14, 2011 in Japanese Patent Application No. 2007-171249.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348778</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348143</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482114</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482115</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482116</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482201</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482221</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>34823199</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482312</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482313</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>34833302</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>34833303</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382118</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382190</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>396263</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>396264</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090002512</doc-number>
<kind>A1</kind>
<date>20090101</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Suzuki</last-name>
<first-name>Yasufumi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Abe</last-name>
<first-name>Hiroshi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Suzuki</last-name>
<first-name>Yasufumi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Abe</last-name>
<first-name>Hiroshi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oblon, Spivak, McClelland, Maier &#x26; Neustadt, L.L.P.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Ye</last-name>
<first-name>Lin</first-name>
<department>2663</department>
</primary-examiner>
<assistant-examiner>
<last-name>Chon</last-name>
<first-name>Peter</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image pickup apparatus includes an image pickup unit configured to pick up a subject image and a control unit configured to perform control in a manner such that, in a case in which a predetermined mode is set, smile detection of a subject is started when an operation input is performed, the subject image is picked up if a smile is detected, and smile detection and image pickup are repeatedly performed until a completion condition is satisfied.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="246.13mm" wi="185.17mm" file="US08624988-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="154.43mm" wi="152.74mm" file="US08624988-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="243.16mm" wi="108.37mm" orientation="landscape" file="US08624988-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="258.06mm" wi="144.61mm" orientation="landscape" file="US08624988-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="187.96mm" wi="153.75mm" file="US08624988-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="249.60mm" wi="190.67mm" file="US08624988-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="244.86mm" wi="170.35mm" orientation="landscape" file="US08624988-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCES TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present invention contains subject matter related to Japanese Patent Application JP 2007-171249 filed in the Japanese Patent Office on Jun. 28, 2007, the entire contents of which are incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to an image pickup apparatus such as, for example, a digital still camera. The present invention relates more particularly to an image pickup apparatus, an image pickup method, and a program thereof that detect, in particular, a smile of a subject and appropriately perform auto focus (AF), auto exposure (AE), auto white balance (AWB), and the like.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Image pickup apparatuses such as digital still cameras and digital video cameras have an AF function. This AF function is used to perform automatic focusing on a subject. In general, an image pickup element such as a charge-coupled device (CCD) or a complementary metal oxide semiconductor (CMOS) is used to pickup a subject image, and a focus position is often automatically determined on the basis of the contrast of a picked-up image. These days, spot AF can be performed. Spot AF allows an AF point to be appropriately set in an AF detectable frame so that a position that a user desires is focused on in an image to be picked up. If an image pickup mode is set as spot AF, a user performs a usual image pickup operation after an AF point which the user desires is selected in an AF detectable frame and the AF point is set on a screen by means of an operation input.</p>
<p id="p-0007" num="0006">Moreover, whether a face of a subject is positioned at an AF point which is set in the AF detectable frame can be detected these days. That is, so-called face detection can be performed.</p>
<p id="p-0008" num="0007">For this type of technology, for example, Japanese Unexamined Patent Application Publication No. 2007-104235 discloses an image pickup apparatus that realizes high-quality image pickup by performing image pickup control which is caused to adapt to a specific image pickup subject. With this technology, for example, in an image pickup apparatus that executes image pickup control which has been adapted to a specific image pickup subject such as a face of a person, in a case in which a shielding object such as a wall causes the image pickup subject to temporarily disappear from an image to be picked up, image control adapted to a specific image pickup subject such as the face of the person is continuously performed.</p>
<p id="p-0009" num="0008">Moreover, technical research is being performed with respect to an image pickup apparatus that detects not only a face of a subject but also a smile thereof. In this case, smile detection is performed, for example, on the basis of whether a main part of a subject satisfies a predetermined condition.</p>
<p id="p-0010" num="0009">With respect to image pickup with smile detection, it is necessary to instantly perform picking up of an image at a time when a smile is detected in order not to miss picking up the smile occurring for just a moment. However, no proposals have been specifically made for appropriate control of a timing of the start/end of image pickup.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0011" num="0010">With respect to image pickup with smile detection of a subject, it is desirable to obtain a high-quality image by appropriately controlling a timing of the start/end of smile detection of the subject.</p>
<p id="p-0012" num="0011">According to an embodiment of the present invention, an image pickup apparatus includes image pickup means for picking up a subject image, and control means for performing control in a manner such that, in a case in which a predetermined mode is set, smile detection of a subject is started when an operation input is performed, the subject image is picked up if a smile is detected, and smile detection and image pickup are repeatedly performed until a completion condition is satisfied.</p>
<p id="p-0013" num="0012">In the image pickup apparatus, the completion condition may be the operation input.</p>
<p id="p-0014" num="0013">In the image pickup apparatus, the completion condition may be reaching of a maximum number of shots that can be taken.</p>
<p id="p-0015" num="0014">In the image pickup apparatus, the completion condition may be a lapse of a predetermined period of time from when the operation input is performed.</p>
<p id="p-0016" num="0015">In the image pickup apparatus, the control means may perform image pickup control between the smile detection and the image pickup.</p>
<p id="p-0017" num="0016">According to another embodiment of the present invention, an image pickup method includes the steps of detecting a smile of a subject when an operation input is performed in a case in which a predetermined mode is set and picking up a subject image if a smile is detected. In the image pickup method, the step of detecting and the step of picking up are repeated until a completion condition is satisfied.</p>
<p id="p-0018" num="0017">The image pickup method may further include the step of performing image pickup control between the step of detecting and the step of picking up.</p>
<p id="p-0019" num="0018">According to another embodiment of the present invention, a program executed by a computer, the program causing the computer to perform an image pickup method, the image pickup method includes the steps of detecting a smile of a subject when an operation input is performed in a case in which a predetermined mode is set and picking up a subject image if a smile is detected. In the image pickup method, the step of detecting and the step of picking up are repeated until a completion condition is satisfied.</p>
<p id="p-0020" num="0019">In the program, the image pickup method may further include the step of performing image pickup control between the step of detecting and the step of picking up.</p>
<p id="p-0021" num="0020">According to another embodiment of the present invention, an image pickup apparatus includes an image pickup unit configured to pick up a subject image, and a control unit configured to perform control in a manner such that, in a case in which a predetermined mode is set, smile detection of a subject is started when an operation input is performed, the subject image is picked up if a smile is detected, and smile detection and image pickup are repeatedly performed until a completion condition is satisfied.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram of an image pickup apparatus according to a first embodiment of the present invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 2</figref> is a sequence diagram used to describe, in more detail, characteristic processing according to the image pickup apparatus according to the first embodiment of the present invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a structure of an image pickup apparatus according to a second embodiment of the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 4A</figref> is a front-side perspective view of the image pickup apparatus according to the second embodiment of the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 4B</figref> is a back-side perspective view of the image pickup apparatus according to the second embodiment of the present invention;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart of characteristic processing of the image pickup apparatus according to the second embodiment of the present invention; and</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 6</figref> is a schematic diagram, which includes screen transition, of the characteristic processing of the image pickup apparatus according to the second embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0029" num="0028">Preferred embodiments (hereinafter simply referred to as &#x201c;embodiments&#x201d;) according to the present invention will be described below with reference to the attached drawings. In image pickup with smile detection, an image pickup apparatus according to a first embodiment of the present invention appropriately controls a timing of the start/end of the image pickup. The timing of the end of the image pickup is controlled on the basis of, for example, a maximum-number-of-shots limitation, a shutter-button operation, and a time limitation.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram showing a structure of an image pickup apparatus according to the first embodiment of the present invention.</p>
<p id="p-0031" num="0030">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the image pickup apparatus according to the first embodiment includes a control unit <b>1</b> which controls the entirety of the image pickup apparatus, an operation input unit <b>3</b>, a storage unit <b>4</b>, a display unit <b>5</b>, and an image pickup unit <b>6</b>.</p>
<p id="p-0032" num="0031">The control unit <b>1</b> provides a smile detection function <b>2</b><i>a</i>, a <b>3</b>A control function <b>2</b><i>b</i>, and a main control function <b>2</b><i>c </i>by reading a control program <b>2</b> stored in the storage unit <b>4</b> and executing the control program <b>2</b>.</p>
<p id="p-0033" num="0032">The operation of each component will be described below with reference to a sequence diagram shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0034" num="0033">First, by means of the main control function <b>2</b><i>c</i>, the control unit <b>1</b> displays a through-the-lens image on the display unit <b>5</b>, allows a user to perform scene selection, and accepts smile mode selection.</p>
<p id="p-0035" num="0034">Here, the &#x201c;smile mode&#x201d; is a mode in which image pickup with smile detection for a subject (hereinafter simply referred to as &#x201c;smile detection&#x201d;) is executed.</p>
<p id="p-0036" num="0035">In this way, in step S<b>1</b>, when an image pickup scene and a smile mode are selected by a user, the control unit <b>1</b> performs setting by means of the main control function <b>2</b><i>c </i>according to these selections.</p>
<p id="p-0037" num="0036">In step S<b>2</b>, when a shutter button included in the operation input unit <b>3</b> is fully pressed by the user, the control unit <b>1</b> detects a signal released by the shutter button, and starts image pickup (processing) in the smile mode by means of the smile detection function <b>2</b><i>a</i>. After step S<b>2</b>, until a completion condition described below is satisfied, smile detection processing, image-pickup control processing, image-pickup processing, and image storage processing are repeatedly performed as processing of each of image pickup <b>1</b> through image pickup n by means of the <b>3</b>A control function <b>2</b><i>b </i>in steps S<b>3</b> and S<b>4</b>.</p>
<p id="p-0038" num="0037">Here, this &#x201c;smile detection&#x201d; is performed, with respect to a main part of a main subject of an image to be picked up, on the basis of whether the main part satisfies a predetermined condition. More specifically, for the subject, such smile detection is performed on the basis of, for example, a size (an area) of the white of an eye or a size (an area) of a white portion in the mouth. However, such smile detection is not limited to these methods.</p>
<p id="p-0039" num="0038">In this way, if one of the completion conditions described below is satisfied, the image pickup (processing) in the smile mode is completed in step S<b>5</b>.</p>
<p id="p-0040" num="0039">That is, in the image pickup apparatus according to the first embodiment, if any one of the following conditions is satisfied,</p>
<p id="p-0041" num="0040">maximum-number-of-shots limitation (for example, steps S<b>3</b> and S<b>4</b> are repeatedly executed until the number of shots reaches a predetermined number, and then pickup (processing) is completed.)</p>
<p id="p-0042" num="0041">shutter button fully pressed (pickup (processing) is completed at a timing of a shutter button being fully pressed.)</p>
<p id="p-0043" num="0042">time limitation (if a time measured by a timer exceeds a predetermined period of time, pickup (processing) is completed.)</p>
<p id="h-0006" num="0000">the control unit <b>1</b> is designed to complete image pickup (processing) in the smile mode by means of the main control function <b>2</b><i>c</i>. These conditions may be prioritized or other completion conditions may be added, as a matter of course.</p>
<p id="p-0044" num="0043">Here, in order to execute the &#x201c;smile mode&#x201d;, it is necessary to first perform &#x201c;face detection&#x201d; of a subject. As a method thereof, an existing method such as a method in which a template of an average face image is prepared in advance and matching between an input image and an image of the template is performed can be utilized. Thus, a detailed description of such face detection is omitted.</p>
<p id="p-0045" num="0044">In this way, in image pickup with smile detection of a subject, the image pickup apparatus according to the first embodiment of the present invention can be used to obtain a high-quality image since the control unit <b>1</b> appropriately controls a timing of the start/end of the image pickup by means of the main control function <b>2</b><i>c. </i></p>
<p id="p-0046" num="0045">Next, a second embodiment of the present invention will be described.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram showing a structure of an image pickup apparatus according to the second embodiment of the present invention.</p>
<p id="p-0048" num="0047">This shows the image pickup apparatus according to the first embodiment described above in more detail.</p>
<p id="p-0049" num="0048">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, a lens unit <b>11</b> which includes, as components thereof, a shooting lens, an aperture, a focus lens, and the like is provided in the image pickup apparatus according to the second embodiment. An image pickup device <b>12</b> such as a CCD is disposed in an optical path of subject-image light entering via the lens unit <b>11</b>. The image pickup device <b>12</b>, an analog signal processing unit <b>13</b>, an analog-to-digital (A/D) conversion unit <b>14</b>, and a digital signal processing unit <b>15</b> are connected in series. An output of the digital signal processing unit <b>15</b> is electrically connected to an input of a liquid crystal panel <b>17</b> and to an input of a recording device <b>19</b>.</p>
<p id="p-0050" num="0049">An actuator <b>20</b> that adjusts the size of the aperture or moves the focus lens is mechanically connected to the lens unit <b>11</b>, the aperture and the focus lens being included in the lens unit <b>11</b>. The actuator <b>20</b> is connected to a motor driver <b>21</b> that performs drive control of the actuator <b>20</b>.</p>
<p id="p-0051" num="0050">Moreover, a central processing unit (CPU) <b>23</b> that controls the entirety of the image pickup apparatus is provided therein. The CPU <b>23</b> is connected to the motor driver <b>21</b>, a timing generator (TG) <b>22</b>, an operation unit <b>24</b>, an electrically erasable programmable read-only memory (EEPROM) <b>25</b>, a program ROM <b>26</b>, a random access memory (RAM) <b>27</b>, and a touch panel <b>16</b>. The CPU <b>23</b> executes, for example, a control function, in particular, a smile detection function, an image-pickup control function, and a main control function by reading out and executing the control program stored in the program ROM <b>26</b>.</p>
<p id="p-0052" num="0051">The touch panel <b>16</b> and the liquid crystal panel <b>17</b> constitute a touch screen <b>18</b>.</p>
<p id="p-0053" num="0052">The recording device <b>19</b> may be, for example, a disc such as a digital versatile disc (DVD), a semiconductor memory such as a memory card, or a removable recording medium other than those mentioned earlier. The recording device <b>19</b> is removable from the body of the image pickup apparatus. The EEPROM <b>25</b> stores, for example, various data on the settings and other data that are necessary to be stored while the power is off. The program ROM <b>26</b> stores a program to be executed by the CPU <b>23</b> and certain data necessary when executing the program. The RAM <b>27</b> serving as a work area temporarily stores a necessary program or data when the CPU <b>23</b> executes various processing.</p>
<p id="p-0054" num="0053">With such a structure, the CPU <b>23</b> controls units constituting the image pickup apparatus by executing the program stored in the program ROM <b>26</b>, and executes predetermined processing in response to a signal input from the touch panel <b>16</b> or a signal input from the operation unit <b>24</b>. The operation unit <b>24</b> is operated by the user, and supplies, to the CPU <b>23</b>, a signal in response to the user's operation.</p>
<p id="p-0055" num="0054">If the touch panel <b>16</b> is pressed, for example, by a finger at an arbitrary position (that is, if a user performs an operation input), the touch panel <b>16</b> detects the coordinates of the pressed position, and sends a signal relating to the coordinates to the CPU <b>23</b>. The CPU <b>23</b> obtains certain information regarding the coordinates, and executes certain processing on the basis of the obtained information.</p>
<p id="p-0056" num="0055">When the subject-image light enters the image pickup device <b>12</b> via the lens unit <b>11</b>, the image pickup device <b>12</b> picks up the subject-image light, converts the subject-image light into an analog image signal, and outputs the analog image signal. Here, the motor driver <b>21</b> drives the actuator <b>20</b> on the basis of the control performed by the CPU <b>23</b>. This driving causes the lens unit <b>11</b> to be exposed to the outside or to be stored in the casing of the image pickup apparatus. This driving also causes the aperture of the lens unit <b>11</b> to be adjusted or the focus lens included in the lens unit <b>11</b> to be moved.</p>
<p id="p-0057" num="0056">Furthermore, the TG <b>22</b> supplies a timing signal to the image pickup device <b>12</b> on the basis of the control performed by the CPU <b>23</b>. This timing signal is used to control, for example, an exposure time for the image pickup device <b>12</b>. The image pickup device <b>12</b> is operated on the basis of the timing signal supplied from the TG <b>22</b>. This causes the image pickup device <b>12</b> to convert the received subject-image light entering via the lens unit <b>11</b> into an analog image signal, which is an electric signal whose amplitude varies in response to the amount of the light received, and supply the analog image signal to the analog signal processing unit <b>13</b>. The analog signal processing unit <b>13</b> performs, on the basis of the control performed by the CPU <b>23</b>, analog signal processing (for example, amplification) on the analog image signal supplied from the image pickup device <b>12</b>, and supplies a resulting image signal to the A/D conversion unit <b>14</b>.</p>
<p id="p-0058" num="0057">The A/D conversion unit <b>14</b> converts, on the basis of the control performed by the CPU <b>23</b>, the analog image signal supplied from the analog signal processing unit <b>13</b> into digital image data, and supplies the digital image data to the digital signal processing unit <b>15</b>. The digital signal processing unit <b>15</b> performs digital signal processing such as noise reduction processing on the digital image data supplied from the A/D conversion unit <b>14</b>, supplies the resulting digital image data to the liquid crystal panel <b>17</b>, and causes an image represented by the resulting digital image data to be displayed on the liquid crystal panel <b>17</b> on the basis of the control performed by the CPU <b>23</b>.</p>
<p id="p-0059" num="0058">The digital signal processing unit <b>15</b> performs compression processing, for example, in accordance with the joint photographic experts group (JPEG) scheme, on the digital image data supplied from the A/D conversion unit <b>14</b>, supplies the resulting compressed digital image data to the recording device <b>19</b>, and causes the resulting compressed digital image data to be recorded in the recording device <b>19</b>.</p>
<p id="p-0060" num="0059">Moreover, the digital signal processing unit <b>15</b> performs decompression processing on the compressed image data recorded in the recording device <b>19</b>, supplies the resulting image data to the liquid crystal panel <b>17</b>, and causes an image represented by the resulting image data to be displayed on the liquid crystal panel <b>17</b>. That is, the digital signal processing unit <b>15</b> supplies, to the liquid crystal panel <b>17</b>, the image data supplied from the A/D conversion unit <b>14</b>, and an image represented by the image data is displayed on the liquid crystal panel <b>17</b> as a so-called through-the-lens image. Furthermore, the digital signal processing unit <b>15</b> generates, on the basis of the control performed by the CPU <b>23</b>, a focus frame (an autofocus (AF) frame) used to control the focus, supplies the focus frame to the liquid crystal panel <b>17</b>, and causes the focus frame to be displayed on the liquid crystal panel <b>17</b>.</p>
<p id="p-0061" num="0060">Then, if a user presses a shutter button included in the operation unit <b>24</b>, the operation unit <b>24</b> supplies a release signal to the CPU <b>23</b>. If such a release signal is supplied to the CPU <b>23</b> in this way, the CPU <b>23</b> controls the digital signal processing unit <b>15</b>, so that the image data supplied from the A/D conversion unit <b>14</b> to the digital signal processing unit <b>15</b> is compressed and the compressed image data is recorded in the recording device <b>19</b>.</p>
<p id="p-0062" num="0061">The image pickup apparatus has an AF function. In this embodiment of the present invention, the AF frame is set on an image picked up by the image pickup device <b>12</b>, and the focus of the lens unit <b>11</b> is controlled on the basis of the image within the AF frame. This AF function allows the AF frame to be set at an arbitrary position on the image displayed on the liquid crystal panel <b>17</b>. Moreover, for example, the position of and the size of the AF frame can be controlled by just operating the touch panel <b>16</b> integrally provided with the liquid crystal panel <b>17</b>. The AF processing is achieved if the CPU <b>23</b> reads and executes a program stored in the program ROM <b>26</b>. In addition this image pickup apparatus has an AE function and an AWB function. These functions can also be achieved if the CPU <b>23</b> reads and executes a program stored in the program ROM <b>26</b>.</p>
<p id="p-0063" num="0062">Here, a characteristic point will be described below. That is, the CPU <b>23</b> controls a timing of the start and end of image pickup in the smile mode. In this example, when a shutter button <b>24</b> included in the operation unit <b>24</b> is fully pressed, image pickup in the smile mode starts. When any one of conditions, for example, a maximum-number-of-shots limitation, a shutter button being fully pressed, and a time limitation, is satisfied, the image pickup (processing) in the smile mode ends. Each of these conditions may be prioritized, or other completion conditions may be further added, as a matter of course. Thus, in image pickup with smile detection of a subject, since the CPU <b>23</b> appropriately controls a timing of the start/end of the image pickup, this image pickup apparatus can be used to obtain a high-quality image.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIGS. 4A and 4B</figref> show external views of an image pickup apparatus according to the second embodiment of the present invention.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 4A</figref> shows a front-side perspective view of the image pickup apparatus, and <figref idref="DRAWINGS">FIG. 4B</figref> shows a back-side perspective view of the image pickup apparatus.</p>
<p id="p-0066" num="0065">A lens cover <b>57</b> is provided on the front side of the image pickup apparatus. A shooting lens <b>55</b>, which is included in the lens unit <b>11</b>, and an AF illuminator <b>56</b> are arranged to be exposed to the outside when the lens cover <b>57</b> is slid down. The AF illuminator <b>56</b> also functions as a self-timer lamp. A zoom lever (TELE/WIDE) <b>51</b>, a shutter button <b>52</b>, a playback button <b>53</b>, and a power button <b>54</b> are provided on the top surface of the image pickup apparatus. The touch screen <b>18</b> is provided at the back side of the image pickup apparatus. The zoom lever <b>51</b>, the shutter button <b>52</b>, the playback button <b>53</b>, and the power button <b>54</b> are included in the operation unit <b>24</b>.</p>
<p id="p-0067" num="0066">Characteristic processing performed by the image pickup apparatus according to the second embodiment of the present invention will be described below in more detail with reference to a flowchart shown in <figref idref="DRAWINGS">FIG. 5</figref>. Reference will be made to <figref idref="DRAWINGS">FIG. 6</figref> as necessary. A series of processing operations described below also corresponds to an image pickup control method according to the second embodiment.</p>
<p id="p-0068" num="0067">In step S<b>11</b>, when a smile mode is set and processing starts, first, a still-image steady-state display is performed using the liquid crystal panel <b>17</b>. This is shown as a screen <b>100</b> in <figref idref="DRAWINGS">FIG. 6</figref>. An AF frame <b>100</b><i>a </i>is displayed on the screen <b>100</b>.</p>
<p id="p-0069" num="0068">Next, in step S<b>12</b>, the CPU <b>23</b> detects whether a shutter button <b>52</b> included in the operation unit <b>24</b> is half-pressed. If the shutter button <b>52</b> is not half-pressed, the still-image steady-state display is continuously performed. If the shutter button <b>52</b> is half-pressed (&#x201c;Yes&#x201d; in step S<b>12</b>), in step S<b>13</b>, scan AF is executed, AF lock is performed, and this state is displayed on the liquid crystal panel <b>17</b>. This is shown as screens <b>101</b> and <b>102</b> in <figref idref="DRAWINGS">FIG. 6</figref>. That is, during AF scanning, AF frames <b>101</b><i>a </i>and <b>101</b><i>b </i>are displayed as shown in the screen <b>101</b>. When the AF scanning is finished and a state is switched to be in an AF lock state, an AF frame <b>102</b><i>a </i>which is locked is specified and displayed on the screen <b>102</b>.</p>
<p id="p-0070" num="0069">In step S<b>14</b>, the CPU <b>23</b> determines whether the shutter button <b>52</b> is fully pressed. If the shutter button <b>52</b> is determined not to be fully pressed (&#x201c;No&#x201d; in step S<b>14</b>), the flow returns to step S<b>12</b>, and the above-described processing is repeated. If the shutter button <b>52</b> is determined to be fully pressed, smile detection is executed in step S<b>15</b>. Here, as shown on a screen <b>103</b> in <figref idref="DRAWINGS">FIG. 6</figref>, an AF frame <b>103</b><i>a </i>surrounds a face which is a subject of smile detection. The face which is a subject of this smile detection was determined, for example, when AF lock was previously performed.</p>
<p id="p-0071" num="0070">Here, smile detection is performed as a result of the CPU <b>23</b> reading out a program stored in the program ROM <b>26</b>. For example, with respect to the face of the subject on which the AF frame has been set, that is, the face being AF locked, a noticeable part is specified. Whether the noticeable part satisfies a predetermined condition is determined. If the noticeable part satisfies the predetermined condition, it is determined that a smile is present on the face of the subject. Such a noticeable part includes, for example, the eyes or mouth of a subject, more particularly, the size (area) of the white of an eye, and/or a lateral length of the mouth and the size (area) of a white part. However, the noticeable part is not limited thereto.</p>
<p id="p-0072" num="0071">In this way, in step S<b>16</b>, image pickup control is performed at a time when a smile is detected. Here, the image pickup control is <b>3</b>A control, which includes AF, AE, and AWB. Afterwards, a subject image is picked up by the image pickup device <b>12</b> and converted into digital image data by the analog signal processing unit <b>13</b> and the A/D conversion unit <b>14</b>. The digital signal processing unit <b>15</b> performs the above-described processing on the digital image data and the processed digital image data is recorded in the recording device <b>19</b> in step S<b>17</b>.</p>
<p id="p-0073" num="0072">Although not shown in the flowchart, auto review can be performed here. In this case, if auto review is set to be &#x201c;ON&#x201d;, an auto-review display is performed using the liquid crystal panel <b>17</b> as shown on a screen <b>104</b> in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0074" num="0073">Next, in step S<b>18</b>, the CPU <b>23</b> determines whether the shutter button <b>52</b> is fully pressed. If the shutter button <b>52</b> is fully pressed (&#x201c;Yes&#x201d; in step S<b>18</b>), processing is completed. If it is determined that the shutter button <b>52</b> is not fully pressed (&#x201c;No&#x201d; in step S<b>18</b>), the CPU <b>23</b> determines whether a maximum number of shots that can be taken has been reached in step S<b>19</b>. If the CPU <b>23</b> determines that the maximum number of shots that can be taken has been reached (&#x201c;Yes&#x201d; in step S<b>19</b>), processing is completed.</p>
<p id="p-0075" num="0074">If it is determined that the maximum number of shots that can be taken has not been reached (&#x201c;No&#x201d; in step S<b>19</b>), the CPU <b>23</b> determines whether a predetermined period of time has passed (timeout) in step S<b>20</b>. If it is determined that the predetermined period of time has passed (&#x201c;Yes&#x201d; in step S<b>20</b>), processing is completed. If the CPU <b>23</b> determines that the predetermined period of time has not been passed (&#x201c;No&#x201d; in step S<b>20</b>), the flow returns to step S<b>15</b> and the above-described processing is repeated. That is, if any of these completion conditions is not satisfied, processing of smile detection, <b>3</b>A control, and image pickup and recording is repeated.</p>
<p id="p-0076" num="0075">Here, determination is performed in the order of whether the shutter button <b>52</b> is fully pressed, whether the maximum number of shots that can be taken has been reached, and whether the predetermined period of time has passed. However, the order is not limited thereto, and the completion conditions may be determined according to priorities assigned arbitrarily. Moreover, other completion conditions may be added.</p>
<p id="p-0077" num="0076">If smiles are detected on a plurality of faces, the highest priority is assigned to the face of a subject selected by a user's operation performed through the touch panel <b>16</b>. For the other faces, a high priority is assigned to a face near the selected face or a face positioned at a subject distance the same as the selected face. According to the priorities, AF frames can be set for a predetermined number of faces, as a matter of course. Moreover, if a user does not specifically select a face of a subject, priorities may be determined by assigning a high priority to a face near the center of a screen or a face the size of which is large. According to the priorities, AF frames can be set for a predetermined number of faces, as a matter of course.</p>
<p id="p-0078" num="0077">As described above, according to the first and second embodiments, if a smile mode is set and image pickup with smile detection is executed, processing of smile detection, <b>3</b>A control, and image pickup and recording is performed in synchronization with, for example, a shutter button being fully pressed until a completion condition is satisfied. When a completion condition such as a shutter button being fully pressed, a maximum number of shots that can be taken being reached, or a lapse of a predetermined period of time is satisfied, a timing of the start/end of image pickup is appropriately controlled so as to complete a series of processing operations. As a result, high-quality images can be obtained.</p>
<p id="p-0079" num="0078">Embodiments of the present invention have been described; however, the present invention is not limited thereto. It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p>
<p id="p-0080" num="0079">For example, in a case in which AF frames have been set for a plurality of faces of subjects, if a plurality of images are picked up in a smile mode, images can be obtained, in each of which one of the subjects smiled, by successively picking up images at times when a smile is detected on one of the faces with the AF frames. Here, the AF frames may be prioritized and images may be picked up according to the priorities. Therefore, once image pickup is started in a smile mode, images can be obtained in each of which one of on-screen subjects smiled.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image pickup apparatus comprising:
<claim-text>image pickup means for picking up a subject image; and</claim-text>
<claim-text>control means for performing control in a manner such that, in a case in which a predetermined mode is set, smile detection of a plurality of subjects is started when an operation input is performed, the subject image is picked up in response to a first smile of a first subject of the plurality of subjects being detected, independent of a total number of the plurality of subjects on which the smile detection is performed, and smile detection and image pickup are repeatedly performed until a completion condition is satisfied, wherein</claim-text>
<claim-text>each of at least two picked up subject images includes a different subject smiling.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image pickup apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the completion condition is the operation input.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image pickup apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the completion condition is reaching of a maximum number of shots that can be taken.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The image pickup apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the completion condition is a lapse of a predetermined period of time from when the operation input is performed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image pickup apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the control means performs image pickup control between the smile detection and the image pickup.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The image pickup apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the smile detection is performed based on a set priority order of each of the plurality of subjects.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The image pickup apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the smile detection is performed based on a priority order that is set according to a position of a face of each of the plurality of subjects.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An image pickup method comprising the steps of:
<claim-text>performing smile detection of a plurality of subjects when an operation input is performed in a case in which a predetermined mode is set;</claim-text>
<claim-text>picking up a subject image in response to a first smile of a first subject of the plurality of subjects being detected, independent of a total number of the plurality of subjects on which the smile detection is performed; and</claim-text>
<claim-text>repeating the step of performing smile detection and the step of picking up until a completion condition is satisfied, each of at least two picked up subject images including a different subject smiling.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The image pickup method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising the step of performing image pickup control between the step of performing smile detection and the step of picking up.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The image pickup method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>,
<claim-text>wherein the completion condition is the operation input.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The image pickup method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>,
<claim-text>wherein the completion condition is reaching of a maximum number of shots that can be taken.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The image pickup method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>,
<claim-text>wherein the completion condition is a lapse of a predetermined period of time from when the operation input is performed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A non-transitory computer-readable storage medium including computer executable instructions, wherein the instructions, when executed by a computer, cause the computer to perform an image pickup method, the image pickup method comprising the steps of:
<claim-text>performing smile detection of a plurality of subjects when an operation input is performed in a case in which a predetermined mode is set;</claim-text>
<claim-text>picking up a subject image in response to a first smile of a first subject of the plurality of subjects being detected, independent of a total number of the plurality of subjects on which the smile detection is performed; and</claim-text>
<claim-text>repeating the step of performing smile detection and the step of picking up until a completion condition is satisfied, each of at least two picked up subject images including a different subject smiling.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The non-transitory computer-readable storage medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>,
<claim-text>further comprising the step of performing image pickup control between the step of performing smile detection and the step of picking up.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An image pickup apparatus comprising:
<claim-text>an image pickup unit configured to pick up a subject image; and</claim-text>
<claim-text>a control unit configured to perform control in a manner such that, in a case in which a predetermined mode is set, smile detection of a plurality of subjects is started when an operation input is performed, the subject image is picked up in response to a first smile of a first subject of the plurality of subjects being detected, independent of a total number of the plurality of subjects on which the smile detection is performed, and smile detection and image pickup are repeatedly performed until a completion condition is satisfied, wherein</claim-text>
<claim-text>each of at least two picked up subject images includes a different subject smiling.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The image pickup apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein the completion condition is the operation input.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The image pickup apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein the completion condition is reaching of a maximum number of shots that can be taken.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The image pickup apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein the completion condition is a lapse of a predetermined period of time from when the operation input is performed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The image pickup apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein the control unit is further configured to perform image pickup control between the smile detection and the image pickup. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
