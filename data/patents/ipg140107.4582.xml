<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625670-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625670</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12405330</doc-number>
<date>20090317</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2008-0024367</doc-number>
<date>20080317</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>656</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>11</main-group>
<subgroup>02</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>37524016</main-classification>
<further-classification>37524012</further-classification>
<further-classification>37524013</further-classification>
<further-classification>37524015</further-classification>
<further-classification>382236</further-classification>
<further-classification>382239</further-classification>
<further-classification>382240</further-classification>
</classification-national>
<invention-title id="d2e71">Method and apparatus for encoding and decoding image</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7110452</doc-number>
<kind>B2</kind>
<name>Katsavounidis et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524008</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7126989</doc-number>
<kind>B2</kind>
<name>Hagai et al.</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524013</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7200275</doc-number>
<kind>B2</kind>
<name>Srinivasan et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382239</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7606311</doc-number>
<kind>B2</kind>
<name>Hsu et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524023</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7852936</doc-number>
<kind>B2</kind>
<name>Mukerjee et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524015</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>8462853</doc-number>
<kind>B2</kind>
<name>Jeon et al.</name>
<date>20130600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2005/0053145</doc-number>
<kind>A1</kind>
<name>Hsu et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2005/0053293</doc-number>
<kind>A1</kind>
<name>Lin et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382236</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2005/0053294</doc-number>
<kind>A1</kind>
<name>Mukerjee et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382236</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2006/0146191</doc-number>
<kind>A1</kind>
<name>Kim et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348557</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2006/0262985</doc-number>
<kind>A1</kind>
<name>Chen et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382240</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2009/0232217</doc-number>
<kind>A1</kind>
<name>Lee et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>KR</country>
<doc-number>10-0378795</doc-number>
<kind>A</kind>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>KR</country>
<doc-number>10-2005-0098243</doc-number>
<kind>A</kind>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>INSPEC<sub>&#x2014;</sub>history<sub>&#x2014;</sub>NPL<sub>&#x2014;</sub>search.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
</us-references-cited>
<number-of-claims>18</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090232217</doc-number>
<kind>A1</kind>
<date>20090917</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Tammy</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Min</last-name>
<first-name>Jung-hye</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Han</last-name>
<first-name>Woo-jin</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Sang-rae</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Tammy</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Min</last-name>
<first-name>Jung-hye</first-name>
<address>
<city>Yongin-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Han</last-name>
<first-name>Woo-jin</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Sang-rae</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sughrue Mion, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Samsung Electronics Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Vaughn, Jr.</last-name>
<first-name>William C</first-name>
<department>2481</department>
</primary-examiner>
<assistant-examiner>
<last-name>Perez</last-name>
<first-name>Luis M</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Provided are a method and apparatus for encoding an image, which can variably encode a residual of a current block that is predicted with a skip mode according to prediction modes of neighboring blocks, and a method and apparatus for decoding the encoded image. When both the prediction mode of the current block and the prediction modes of the neighboring blocks are skip modes, since the method of encoding the image also encodes the residual of the current block that is predicted with the skip mode, more bits can be assigned to the current block with a high probability of acting as a reference block for other blocks.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="166.03mm" wi="160.70mm" file="US08625670-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="90.76mm" wi="160.70mm" file="US08625670-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="187.62mm" wi="159.77mm" orientation="landscape" file="US08625670-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="181.86mm" wi="107.27mm" file="US08625670-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="171.96mm" wi="159.77mm" file="US08625670-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="204.55mm" wi="156.72mm" file="US08625670-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="219.29mm" wi="160.27mm" file="US08625670-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED PATENT APPLICATION</heading>
<p id="p-0002" num="0001">This application claims the benefit of Korean Patent Application No. 10-2008-0024367, filed on Mar. 17, 2008, in the Korean Intellectual Property Office, the disclosure of which is incorporated herein in its entirety by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">Methods and apparatuses consistent with the present invention relate to encoding and decoding an image, and more particularly, to encoding an image by determining whether prediction modes of neighboring blocks of a current block that is predicted with a skip mode are skip modes and assigning more bits to a current block with a high probability of acting as a reference block for other subsequent blocks, and to decoding the encoded image.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Image compression standards, such as moving picture experts group (MPEG)-1, MPEG-2, MPEG-4, and H.264/MPEG-4 advanced video coding (AVC), divide one picture into macroblocks in order to encode an image. After each of the macroblocks is encoded in all inter-prediction and intra-prediction modes, one of the prediction modes is selected according to a bit rate required to encode each macroblock and a distortion level between each original macroblock and decoded macroblock.</p>
<p id="p-0007" num="0006">H.264/MPEG-4 AVC roughly divides one picture into one of I, B, and P slices, and divides the slice into a plurality of macroblocks. The macroblocks are encoded in two prediction modes, that is, an inter mode and an intra mode.</p>
<p id="p-0008" num="0007">An inter mode is a mode used in inter-prediction that encodes macroblocks of a current picture by encoding a difference between a pixel value and information on a motion vector indicating the position of at least one block selected from a reference picture. Since H.264/MPEG-4 AVC has no more than 5 reference pictures, a reference block to which a current macroblock refers is searched for in a frame memory storing reference pictures. The reference pictures stored in the frame memory may precede or follow the current picture.</p>
<p id="p-0009" num="0008">An intra mode is a mode used in intra-prediction that encodes macroblocks of a current picture by calculating a prediction value of a macroblock to be encoded by using a pixel value of a pixel spatially close to the macroblock to be encoded and encoding a difference between the prediction value and the pixel value.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 1</figref> illustrates conventional inter-prediction modes for motion estimation and compensation in H.264/MPEG-4 AVC. One 16&#xd7;16 macroblock may be divided into two 16&#xd7;8 blocks, two 8&#xd7;16 blocks, or four 8&#xd7;8 blocks, and each of the 8&#xd7;8 blocks may be further divided into two 8&#xd7;4 blocks, two 4&#xd7;8 blocks, or four 4&#xd7;4 blocks. Each of the macroblocks is encoded in the inter-prediction modes, and then a prediction mode incurring the least cost is determined according to a bit rate required to encode each macroblock and a distortion level between each original macroblock and decoded macroblock.</p>
<p id="p-0011" num="0010">Also, in H.264/MPEG-4 AVC, in addition to the prediction modes shown in <figref idref="DRAWINGS">FIG. 1</figref>, there is a skip mode in which each of a plurality of macroblocks is encoded by using only a 1-bit flag when motion vectors of macroblocks included in a P slice are the same as predictive motion vectors or motion vectors of macroblocks included in a B slice are the same as direct motion vectors. In the skip mode, only the 1-bit flag is included in a bitstream as encoding information of the macroblock, and a residual of the macroblock is not encoded. When the macroblock encoded with the skip mode is decoded, a predictive motion vector is generated from motion vectors of neighboring blocks that have already been encoded, and motion compensation is performed by using the predictive motion vector to reconstruct the macroblock.</p>
<p id="p-0012" num="0011">In general, a macroblock determined to have a skip mode is often present in a background where less motion occurs. In particular, when there is no scene change and a background is fixed, a probability that areas of subsequent frames corresponding to a background area encoded with a skip mode are encoded with skip modes is high. As such, when a block encoded with a skip mode is used as reference data for other blocks, the quality of the other blocks referring to the block encoded with the skip mode may be reduced as the quality of the block encoded with the skip mode is reduced.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0013" num="0012">The present invention provides a method and apparatus for encoding an image, which can improve the quality of other blocks referring to a skip block, which is encoded with a skip mode having a high probability of acting as reference data, by assigning more bits to the skip block, and a method and apparatus for decoding the encoded image.</p>
<p id="p-0014" num="0013">The present invention also provides a method and apparatus for encoding an image, which can control the number of bits generated when other blocks referring to a skip block, which is used as reference data for the other blocks, are encoded by assigning more bits to the skip block, and a method and apparatus for decoding the encoded image.</p>
<p id="p-0015" num="0014">According to an aspect of the present invention, there is provided a method of encoding an image, the method comprising: performing motion estimation on a current block to be encoded and determining a prediction mode of the current block; when the determined prediction mode of the current block is a skip mode, determining whether prediction modes of neighboring blocks of the current block are skip modes; when it is determined that the prediction modes of the neighboring blocks are skip modes, encoding a residual that is a difference value between the current block and a prediction block of the current block; and adding the residual to a bit stream that is generated by encoding the image.</p>
<p id="p-0016" num="0015">According to another aspect of the present invention, there is provided an apparatus for encoding an image, the apparatus comprising: a motion estimation unit which performs motion estimation on a current block to be encoded by using available prediction modes; an encoding unit which encodes a residual that is a difference value between the current block and a prediction block of the current block; and a control unit which determines a prediction mode of the current block from among the prediction modes by using costs of a bitstream generated by the encoding unit, and when it is determined that the determined prediction mode of the current block is a skip mode and prediction modes of neighboring blocks are skip modes, adds the residual to the bitstream generated by the encoding unit.</p>
<p id="p-0017" num="0016">According to another aspect of the present invention, there is provided a method of decoding an image, the method comprising: extracting a prediction mode of a current block to be decoded from an input bitstream; when the extracted prediction mode of the current block is a skip mode, determining whether prediction modes of neighboring blocks of the current block are skip modes; when it is determined that the prediction modes of the neighboring blocks are skip modes, extracting a residual of the current block from the bitstream and decoding the extracted residual; generating a prediction block of the current block according to the skip mode; and adding the prediction block of the current block and the residual and decoding the current block.</p>
<p id="p-0018" num="0017">According to another aspect of the present invention, there is provided an apparatus for decoding an image, the apparatus comprising: an entropy decoding unit which extracts a residual and a prediction mode of a current block to be decoded from an input bitstream; a prediction unit which generates a prediction block of the current block according to the extracted prediction mode; a residual reconstruction unit which decodes the residual; a control unit, which, when the extracted prediction mode of the current block is a skip mode and prediction modes of neighboring blocks of the current block are skip modes, extracts a residual of the current block from the bitstream and controls the residual reconstruction unit so that the residual reconstruction unit decodes the residual; and an addition unit which adds the prediction block of the current block and the residual and decoding the current block.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0018">The above and other features and advantages of the present invention will become more apparent by describing in detail exemplary embodiments thereof with reference to the attached drawings in which:</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 1</figref> illustrates conventional inter-prediction modes for motion estimation and compensation in H.264/moving picture experts group (MPEG)-4 advanced video coding (AVC);</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of an apparatus for encoding an image, according to an exemplary embodiment of the present invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> are reference views for explaining a method of determining a predictive motion vector according to a skip mode, according to an exemplary embodiment of the present invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating a method of encoding an image, according to an exemplary embodiment of the present invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating operation <b>410</b> of the method of <figref idref="DRAWINGS">FIG. 4</figref>, according to an exemplary embodiment of the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram of an apparatus for decoding an image, according to an exemplary embodiment of the present invention; and</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart illustrating a method of decoding an image, according to an exemplary embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS OF THE INVENTION</heading>
<p id="p-0027" num="0026">The present invention will now be described more fully with reference to the accompanying drawings, in which exemplary embodiments of the invention are shown.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of an apparatus <b>200</b> for encoding an image, according to an embodiment of the present invention. Referring to <figref idref="DRAWINGS">FIG. 2</figref>, the apparatus <b>200</b> according to the current embodiment includes a subtraction unit <b>205</b>, a prediction unit <b>210</b>, a transform and quantization unit <b>220</b>, an entropy coding unit <b>230</b>, and a control unit <b>240</b>. The prediction unit <b>210</b> includes a motion compensation unit <b>212</b>, a storage unit <b>213</b>, a deblocking filter <b>214</b>, an inverse-transform and inverse-quantization unit <b>215</b>, an intra-prediction unit <b>216</b>, and an addition unit <b>217</b>.</p>
<p id="p-0029" num="0028">The prediction unit <b>210</b> divides an input image into blocks of a predetermined size, and generates a prediction block of each of the divided blocks through inter-prediction or intra-prediction. In detail, a motion estimation unit <b>211</b> performs motion estimation that generates a motion vector by searching for a region similar to a current block within a predetermined range of a reference picture, which has already been encoded and reconstructed, according to prediction modes as shown in <figref idref="DRAWINGS">FIG. 1</figref>, that is, 16&#xd7;16, 16&#xd7;8, 8&#xd7;16, 8&#xd7;8, 8&#xd7;4, 4&#xd7;8, or 4&#xd7;4 prediction modes. The motion compensation unit <b>212</b> performs motion compensation that acquires data of a corresponding region of the reference picture indicated by the generated motion vector and generates a prediction block of the current block. The intra-prediction unit <b>216</b> performs intra-prediction that generates a prediction block by using data of neighboring blocks around the current block.</p>
<p id="p-0030" num="0029">The subtraction unit <b>205</b> generates a residual that is a difference between the generated prediction block of the current block and original image data. The transform and quantization unit <b>220</b> transforms the residual into a frequency domain, and quantizes the transformed residual.</p>
<p id="p-0031" num="0030">The entropy coding unit <b>230</b> performs variable length coding on the quantized residual to generate a bitstream.</p>
<p id="p-0032" num="0031">The inverse-transform and inverse-quantization unit <b>215</b> inverse-quantizes and inverse-transforms the transformed and quantized residual to reconstruct the residual. The addition unit <b>217</b> adds the reconstructed residual and the prediction block to reconstruct the current block. The reconstructed current block passes through the deblocking filter <b>214</b>, and is stored in the storage unit <b>213</b> to be used as reference data for a next block.</p>
<p id="p-0033" num="0032">The control unit <b>240</b> compares costs of a bitstream according to the prediction modes and a bitstream according to a skip mode, and determines an optimal prediction mode in encoding the current block. Here, a skip mode is a mode that requires encoding of only the prediction mode of the current block. In general, when a current block to be encoded is a background area, a probability that a reference picture to which the current block refers and the current block are the same is high. Accordingly, in this case, only a prediction mode is transmitted through a 1-bit flag without encoding separate data such as a residual or a motion vector. When a decoder decodes the current block that is determined to have a skip mode, the decoder determines a predictive motion vector of the current block by using motion vectors of the neighboring blocks, and uses a motion compensation value obtained by using the predictive motion vector as a decoded value of the current block.</p>
<p id="p-0034" num="0033">A method of determining a predictive motion vector of a current block in a skip mode will now be explained. Here, the predictive motion vector is not a motion vector that is determined through motion estimation but is a predictive motion vector that is determined by using motion vectors of neighboring blocks of the current block.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> are reference views for explaining a method of determining a predictive motion vector according to a skip mode, according to an embodiment of the present invention. <figref idref="DRAWINGS">FIG. 3A</figref> is a diagram for explaining a method of calculating a predictive motion vector when a current block E and neighboring blocks A, B, and C have the same size. <figref idref="DRAWINGS">FIG. 3B</figref> is a diagram for explaining a method of calculating a predictive motion vector when a current block E and neighboring blocks A, B, and C have different sizes. Referring to <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>, a predictive motion vector MVP of the current block E may be determined as follows.</p>
<p id="p-0036" num="0035">{circle around (1)} The predictive motion vector MVP of the current block E except 16&#xd7;8 and 8&#xd7;16 blocks is calculated as a median value among the motion vectors of the neighboring blocks A, B, and C.</p>
<p id="p-0037" num="0036">{circle around (2)} When the current block E comprises two 16&#xd7;8 blocks, the predictive motion vector MVP of the above 16&#xd7;8 block of the current block E is predicted from the neighboring block B, and the predictive motion vector MVP of the below 16&#xd7;8 of the current block E is predicted from the neighboring block A.</p>
<p id="p-0038" num="0037">{circle around (3)} When the current block E comprises two 8&#xd7;16 blocks, the predictive motion vector MVP of the left 8&#xd7;16 block of the current block E is predicted from the neighboring block A, and the predictive motion vector MVP of the right 8&#xd7;16 block of the current block E is predicted from the neighboring block C.</p>
<p id="p-0039" num="0038">{circle around (4)} The predictive motion vector MVP of the current block E in the case of a skip block is calculated in the same manner as described in {circle around (1)}.</p>
<p id="p-0040" num="0039">The method of determining the predictive motion vector is widely known in H.264/MPEG-4 AVC and thus a detailed explanation thereof is not provided here.</p>
<p id="p-0041" num="0040">The control unit <b>240</b> compares a cost of the current block that is encoded by using a virtual predictive motion vector according to a skip mode and costs of the current block that is encoded according to the prediction modes shown in <figref idref="DRAWINGS">FIG. 1</figref>, and determines a prediction mode with the least cost. The costs may be bit rate-distortion (RD) costs, but the present invention is not limited thereto.</p>
<p id="p-0042" num="0041">When it is determined that the prediction mode of the current block is a skip mode, the control unit <b>240</b> determines whether prediction modes of the neighboring blocks of the current block are skip modes in order to more precisely determine whether the current block that is determined to have a skip mode is a real background area. If the prediction modes of the neighboring blocks of the current block are skip modes, it may be determined that a probability that the current block is a real background area is high. When the blocks in the current picture are raster scanned from left to right and from top to bottom, the neighboring blocks may include at least one of an upper block, a left block, and a left-upper block of the current block which have been encoded before the current block. In order to increase the accuracy of determination on whether the current block determined to have a skip mode (referred to as a skip current block hereinafter) is a real background area, it may be determined that the current block belongs to a background area only when all of the upper block, the left block, and the left-upper block of the current block are determined to have skip modes.</p>
<p id="p-0043" num="0042">When it is determined that the prediction modes of the neighboring blocks of the skip current block are skip modes, the control unit <b>240</b> controls the transform and quantization unit <b>220</b> and the entropy coding unit <b>230</b> so that a residual of the skip current block is encoded. According to the prior art, only a prediction mode of a skip current block determined to have a skip mode is encoded without encoding a residual. However, according to the present invention, a residual of a skip current block whose neighboring blocks are encoded with skip modes is additionally encoded and transmitted, thereby improving prediction efficiency of other blocks referring to the skip current block. In other words, when both the prediction mode of the current block and the prediction modes of the neighboring blocks are skip modes, since a probability that the skip current block is used as a reference block for blocks included in subsequent frames is high, a residual of the skip current block is additionally encoded and transmitted. To this end, when both the prediction mode of the current block and the prediction modes of the neighboring blocks are skip modes, the control unit <b>240</b> controls the transform and quantization unit <b>220</b> and the entropy coding unit <b>230</b> to encode a residual that is a difference between the prediction block of the skip current block generated by using the predictive motion vector and an original current block. The transform and quantization unit <b>220</b> transforms the residual of the skip current block into a frequency domain and quantizes the transformed residual according to a control of the control unit <b>240</b>. The transform and quantization unit <b>220</b> may perform quantization by using a quantization parameter less than a preset quantization parameter in order to assign more bits to the skip current block. For example, when a preset quantization parameter used in quantizing the skip current block according to H.264/MPEG-4 AVC is QP, the residual of the skip current block is quantized by using a quantization parameter QP-2 that is obtained by subtracting 2 steps from the quantization parameter QP.</p>
<p id="p-0044" num="0043">The entropy coding unit <b>230</b> adds the residual of the skip current block and a 1-bit flag indicating whether the prediction mode of the current block is a skip mode to the bitstream that is generated by performing the variable length coding on the skip current block whose neighboring blocks are encoded with skip modes.</p>
<p id="p-0045" num="0044">When it is determined that the prediction modes of the neighboring blocks of the skip current block are not skip modes, the control unit <b>240</b> operates so that only a predetermined flag indicating whether the current block is a skip block is added to the bitstream without encoding the residual of the skip current block like in the prior art.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating a method of encoding an image, according to an embodiment of the present invention. <figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating operation <b>410</b> of the method of <figref idref="DRAWINGS">FIG. 4</figref>, according to an embodiment of the present invention.</p>
<p id="p-0047" num="0046">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, in operation <b>410</b>, motion estimation is performed on a current block to be encoded to determine a prediction mode of the current block. Referring to <figref idref="DRAWINGS">FIG. 5</figref>, in operation <b>411</b>, motion estimation is performed on the current block according to available prediction modes, for example, 16&#xd7;16, 16&#xd7;8, 8&#xd7;16, 8&#xd7;8, 8&#xd7;4, 4&#xd7;8, and 4&#xd7;4 prediction modes, and a skip mode in order to determine the prediction mode of the current block. In operation <b>412</b>, costs, for example, RD costs, according to all the prediction modes are calculated. In operation <b>413</b>, a prediction mode with the least cost is determined as the prediction mode of the current block.</p>
<p id="p-0048" num="0047">Referring to <figref idref="DRAWINGS">FIG. 4</figref> again, in operation <b>420</b>, it is determined whether the prediction mode of the current block is a skip mode. If it is determined in operation <b>420</b> that the prediction mode of the current block is a skip mode, the method proceeds to operation <b>430</b>. In operation <b>430</b>, it is determined whether prediction modes of neighboring blocks of the current block are skip modes. As described above, the neighboring blocks of the current block may include at least one of an upper block, a left block, and a left-upper block of the current block. In order to increase the accuracy of determination, the number of the neighboring blocks may be increased.</p>
<p id="p-0049" num="0048">If it is determined in operation <b>430</b> that the prediction modes of the neighboring blocks of the skip current block are skip modes, the method proceeds to operation <b>440</b>. In operation <b>440</b>, in addition to a 1-bit flag indicating whether the prediction block of the current block is a skip mode, a residual, which is a difference between a motion compensated prediction value of the skip current bock generated by using a predictive motion vector and an input value of the skip current block, is transformed, quantized, and entropy coded to generate a bitstream. At this time, a quantization parameter, which is less than that used to quantize the residual of the skip current block, may be used in order to assign more bits to the skip current block whose neighboring blocks are encoded with skip modes.</p>
<p id="p-0050" num="0049">In operation <b>450</b>, the residual of the skip current block generated in operation <b>440</b> is added to the bitstream along with the 1-bit flag indicating whether the prediction mode of the current block is a skip mode as encoding information of the skip current block.</p>
<p id="p-0051" num="0050">If it is determined in operation <b>420</b> that the prediction mode of the current block is not a skip mode, the method proceeds to operation <b>425</b>. In operation <b>425</b>, the residual of the current block is encoded according to the prediction mode with the least cost to generate a bitstream like in the prior art. If it is determined in operation <b>430</b> that the prediction mode of the current block is a skip mode but the prediction modes of the neighboring blocks are not skip modes, the method proceeds to operation <b>435</b>. In operation <b>435</b>, only the 1-bit flag indicating whether the prediction block of the skip current block is a skip mode is added as encoding information of the skip current block to the bitstream.</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram of an apparatus <b>600</b> for decoding an image, according to an embodiment of the present invention.</p>
<p id="p-0053" num="0052">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, the apparatus <b>600</b> according to the current embodiment includes an entropy decoding unit <b>610</b>, a prediction unit <b>620</b>, a residual reconstruction unit <b>630</b>, a control unit <b>640</b>, an addition unit <b>650</b>, and a storage unit <b>660</b>.</p>
<p id="p-0054" num="0053">The entropy decoding unit <b>610</b> extracts a prediction mode and a residual of a current block to be decoded from an input bitstream. When the extracted prediction mode of the current block is a skip mode and prediction modes of neighboring blocks which have been decoded before the current block are also skip modes, the control unit <b>640</b> controls the entropy decoding unit <b>610</b> so that the residual of the current block is extracted from the bitstream. When the extracted prediction mode of the current block is a skip mode but the prediction modes of the neighboring blocks that have been decoded before the current block are not skip modes, since there is no separate residual of the skip current block, the control unit <b>640</b> controls the entropy decoding unit <b>610</b> so that the residual of the skip current block is not extracted from the bitstream. As such, the control unit <b>640</b> of the apparatus <b>600</b> can determine types of encoded skip blocks from the prediction mode of the current block and the prediction modes of the neighboring blocks that have been decoded before the current block.</p>
<p id="p-0055" num="0054">The prediction unit <b>620</b> generates a prediction block of the current block according to the extracted prediction mode. If it is determined that the prediction mode of the current block is a skip mode, the prediction unit <b>620</b> calculates a predictive motion vector of the skip current block by using motion vectors of the neighboring blocks that have been decoded before the current block, and generates a prediction block of the skip current block by performing motion compensation using the prediction motion vectors.</p>
<p id="p-0056" num="0055">The residual reconstruction unit <b>630</b> inverse-transforms and inverse-quantizes the extracted residual to reconstruct the residual. When the prediction mode of the current block is a skip mode, the control unit <b>640</b> determines whether the prediction modes of the neighboring blocks of the skip current block are also skip modes, and when the prediction modes of the neighboring blocks of the skip current block are skip modes, the control unit <b>640</b> controls the residual reconstruction unit <b>630</b> so that the residual reconstruction unit <b>630</b> reconstructs the residual of the skip current block. The neighboring blocks include at least one of an upper block, a left block, and a left-upper block of the current block.</p>
<p id="p-0057" num="0056">The addition unit <b>650</b> adds the prediction block of the current block which is generated according to the prediction mode and the reconstructed residual to decode the current block. When the skip current block whose neighboring blocks have skip modes as prediction modes is decoded, the addition unit <b>650</b> adds a motion compensation value generated by using the predictive motion vector and the residual extracted from the bitstream. When the skip current block whose neighboring blocks do not have skip modes as prediction modes is decoded, the addition unit <b>650</b> determines a motion compensation value using a predictive motion vector as a decoded value of the skip current block and outputs the motion compensation value like in the prior art.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart illustrating a method of decoding an image, according to an embodiment of the present invention.</p>
<p id="p-0059" num="0058">Referring to <figref idref="DRAWINGS">FIG. 7</figref>, in operation <b>710</b>, a prediction mode of a current block to be decoded is extracted from an input bitstream.</p>
<p id="p-0060" num="0059">In operation <b>720</b>, it is determined whether the extracted prediction mode of the current block is a skip mode. If it is determined in operation <b>720</b> that the prediction mode of the current block is a skip mode, the method proceeds to operation <b>730</b>. In operation <b>730</b>, it is determined whether prediction modes of neighboring blocks of the current block are skip modes.</p>
<p id="p-0061" num="0060">If it is determined in operation <b>730</b> that the prediction modes of the neighboring blocks of the current block are skip modes, the method proceeds to operation <b>740</b>. In operation <b>740</b>, a residual of the current block is extracted from the bitstream and is decoded.</p>
<p id="p-0062" num="0061">In operation <b>750</b>, a predictive motion vector according to a skip mode is calculated, and motion compensation is performed by using the predictive motion vector to generate a prediction block of the current block.</p>
<p id="p-0063" num="0062">In operation <b>760</b>, the prediction block of the current block and the decoded residual are added to decode the current block.</p>
<p id="p-0064" num="0063">If it is determined in operation <b>720</b> that the prediction mode of the current block is not a skip mode, the method proceeds to operation <b>725</b>. In operation <b>725</b>, intra-prediction or inter-prediction is performed according to the extracted prediction mode to generate a prediction block of the current block, and the residual extracted from the bitstream and then decoded and the prediction block are added to decode the current block.</p>
<p id="p-0065" num="0064">If it is determined in operation <b>730</b> that the prediction modes of the neighboring block are not skip modes, the method proceeds to operation <b>735</b>. In operation <b>735</b>, a motion compensation value itself generated by using the predictive motion vector according to the skip mode is calculated as a decoded value of the current block without decoding the residual like in the prior art.</p>
<p id="p-0066" num="0065">As described above, according to the present invention, the quality of other blocks referring to a skip block having a high probability of serving as reference data can be improved, and thus a peak signal to noise ratio (PSNR) of an image can be improved.</p>
<p id="p-0067" num="0066">Moreover, the number of bits generated when the other blocks referring to the skip block are encoded can be adjusted, and thus efficient bit assignment within a limited bandwidth can be performed.</p>
<p id="p-0068" num="0067">While the present invention has been particularly shown and described with reference to exemplary embodiments thereof, it will be understood by one of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present invention as defined by the following claims. The present invention may be embodied as computer-readable codes on a computer-readable recording medium. The computer-readable recording medium is any data storage device that can store data which can be thereafter read by a computer system. Examples of the computer-readable recording medium include read-only memories (ROMs), random-access memories (RAMs), CD-ROMs, magnetic tapes, floppy disks, and optical data storage devices. The computer-readable recording medium can also be distributed over network coupled computer systems so that the computer readable code is stored and executed in a distributed fashion.</p>
<p id="p-0069" num="0068">The present invention may also be embodied as computer-readable codes on a computer-readable transmission medium. The computer-readable transmission medium may be, for example, carrier waves (such as data transmission through the Internet).</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of encoding an image, the method comprising:
<claim-text>performing motion estimation on a current block to be encoded and determining a prediction mode of the current block;</claim-text>
<claim-text>when the determined prediction mode of the current block is a skip mode, determining whether prediction modes of neighboring blocks of the current block are skip modes;</claim-text>
<claim-text>when it is determined that the prediction modes of the neighboring blocks of the current block are skip modes, encoding a residual that is a difference value between the current block and a prediction block of the current block; and</claim-text>
<claim-text>adding the residual of the current block and a mode information indicating that the prediction mode of the current block is the skip mode to a bit stream when the prediction mode of the current block is a skip mode and the prediction modes of the neighbor blocks of the current block are skip modes, and</claim-text>
<claim-text>adding only the mode information indicating that the prediction mode of the current block is the skip mode to the bit stream when the prediction mode of the current block is the skip mode and the prediction modes of the neighbor blocks of the current block are not skip modes.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the neighboring blocks comprise at least one of an upper block, a left block, and a left-upper block of the current block.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining of the prediction mode of the current block comprises:
<claim-text>performing motion estimation on the current block by using all available prediction modes and calculating costs; and</claim-text>
<claim-text>determining a prediction mode with a least cost from among the prediction modes as a prediction mode of the current block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the encoding of the residual further comprises:
<claim-text>transforming the residual into a frequency domain;</claim-text>
<claim-text>when the prediction modes of the neighboring blocks of the current block are skip modes,</claim-text>
<claim-text>quantizing the residual by using a quantization parameter less than a preset quantization parameter; and</claim-text>
<claim-text>entropy coding the quantized residual.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, when it is determined that the prediction modes of the neighboring blocks are not skip modes, further comprising adding only a predetermined flag, which indicates whether the current block is a skip block, to the bitstream without encoding the residual.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. An apparatus for encoding an image, the apparatus comprising:
<claim-text>a motion estimation unit which performs motion estimation on a current block to be encoded by using available prediction modes;</claim-text>
<claim-text>an encoding unit which encodes a residual that is a difference value between the current block and a prediction block of the current block; and</claim-text>
<claim-text>a control unit which determines a prediction mode of the current block from among the prediction modes by using costs of a bitstream generated by the encoding unit, and when it is determined that the determined prediction mode of the current block is a skip mode and prediction modes of neighboring blocks are skip modes,</claim-text>
<claim-text>adds the residual of the current block and a mode information indicating that the prediction mode of the current block is the skip mode to the bitstream generated by the encoding unit and</claim-text>
<claim-text>adds only the mode information indicating that the prediction mode of the current block is the skip mode to the bit stream when the prediction mode of the current block is the skip mode and the prediction modes of the neighbor blocks of the current block are not the skip modes,</claim-text>
<claim-text>wherein the skip mode is a prediction mode that uses a motion compensated prediction value, which is generated by using a predictive motion vector of the current block which is predicted by using motion vectors of the neighboring blocks of the current block, as a prediction block of the current block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the neighboring blocks comprise at least one of an upper block, a left block, and a left-upper block of the current block.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the control unit compares the costs of the bit stream generated by performing motion estimation on the current block according to all the available prediction modes and determines a prediction mode with a least cost as a prediction mode of the current block.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the encoding unit comprises:
<claim-text>a transform and quantization unit which transforms the residual into a frequency domain, and</claim-text>
<claim-text>when the prediction modes of the neighboring blocks of the current block are skip modes, which quantizes the residual by using a quantization parameter less than a preset quantization parameter; and</claim-text>
<claim-text>an entropy coding unit which entropy codes the quantized residual.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein, when it is determined that the prediction modes of the neighboring blocks are not skip modes, the control unit controls the encoding unit so that only a predetermined flag indicating whether the current block is a skip block is added to the bitstream without encoding the residual that is a difference value between the current block and the prediction block of the current block.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A method of decoding an image, the method comprising:
<claim-text>extracting a prediction mode of a current block to be decoded from an input bitstream;</claim-text>
<claim-text>when the extracted prediction mode of the current block is a skip mode, determining whether prediction modes of neighboring blocks of the current block are skip modes;</claim-text>
<claim-text>when it is determined that the extracted prediction mode of the current block is a skip mode and the prediction modes of the neighboring blocks of the current block are skip modes,</claim-text>
<claim-text>extracting a residual of the current block whose prediction mode is a skip mode from the bitstream and decoding the extracted residual;</claim-text>
<claim-text>generating a prediction block of the current block according to the skip mode; and</claim-text>
<claim-text>adding the prediction block of the current block and the residual and decoding the current block;</claim-text>
<claim-text>wherein the skip mode is a prediction mode that uses a motion compensated prediction value, which is generated by using a predictive motion vector of the current block which is predicted by using motion vectors of the neighboring blocks of the current block, as a prediction block of the current block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the neighboring blocks comprise at least one of an upper block, a left block, and a left-upper block of the current block.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the generating of the prediction block of the current block according to the skip mode comprises:
<claim-text>generating a predictive motion vector of the current block by using motion vectors of the neighboring blocks of the current block; and</claim-text>
<claim-text>determining a motion compensated prediction value by using the generated predictive motion vector as a prediction block of the current block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, when it is determined that the prediction modes of the neighboring blocks are not skip modes, further comprising:
<claim-text>generating a predictive motion vector of the current block by using motion vectors of the neighboring blocks of the current block; and</claim-text>
<claim-text>determining a motion compensated prediction value, which is generated by using the generated predictive motion vector, as a decoded value of the current block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An apparatus for decoding an image, the apparatus comprising:
<claim-text>an entropy decoding unit which extracts a residual and a prediction mode of a current block to be decoded from an input bitstream;</claim-text>
<claim-text>a prediction unit which generates a prediction block of the current block according to the extracted prediction mode;</claim-text>
<claim-text>a residual reconstruction unit which decodes the residual;</claim-text>
<claim-text>a control unit, which, when the extracted prediction mode of the current block is a skip mode and prediction modes of neighboring blocks of the current block are skip modes, extracts a residual of the current block from the bitstream and controls the residual reconstruction unit so that the residual reconstruction unit decodes the residual; and</claim-text>
<claim-text>an addition unit which adds the prediction block of the current block and the residual and decodes the current block,</claim-text>
<claim-text>wherein the skip mode is a prediction mode that uses a motion compensated prediction value, which is generated by using a predictive motion vector of the current block which is predicted by using motion vectors of the neighboring blocks of the current block, as a prediction block of the current block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the neighboring blocks comprise at least one of an upper block, a left block, and a left-upper block of the current block.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein, when the extracted prediction mode of the current block is a skip mode, the prediction unit determines a motion compensated prediction value, which is generated by using a predictive motion vector which is generated by using motion vectors of the neighboring blocks of the current block, as a prediction block of the current block.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein, when it is determined that the prediction modes of the neighboring blocks are not skip modes, the control unit determines a motion compensated prediction value of the current block, which is generated by the prediction unit, as a decoded value of the current block without extracting the residual of the current block from the bitstream. </claim-text>
</claim>
</claims>
</us-patent-grant>
