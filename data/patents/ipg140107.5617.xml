<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626718-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626718</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12915448</doc-number>
<date>20101029</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>126</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>7</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>707663</main-classification>
<further-classification>707700</further-classification>
</classification-national>
<invention-title id="d2e53">Content caching based on refresh and expiration times</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6553409</doc-number>
<kind>B1</kind>
<name>Zhang et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709213</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2003/0233423</doc-number>
<kind>A1</kind>
<name>Dilley et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709214</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2003/0236826</doc-number>
<kind>A1</kind>
<name>Islam et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709203</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2004/0093592</doc-number>
<kind>A1</kind>
<name>Rao</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2006/0020962</doc-number>
<kind>A1</kind>
<name>Stark et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 32</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2006/0089917</doc-number>
<kind>A1</kind>
<name>Strom et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 59</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2008/0242324</doc-number>
<kind>A1</kind>
<name>Smuga et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455466</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2009/0293062</doc-number>
<kind>A1</kind>
<name>Amir et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718104</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2010/0005172</doc-number>
<kind>A1</kind>
<name>Singer et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2010/0026510</doc-number>
<kind>A1</kind>
<name>Kiani et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3406913</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2010/0292816</doc-number>
<kind>A1</kind>
<name>Anzures et al.</name>
<date>20101100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>700 94</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>11</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>707700</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707999203</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707663</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>13</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120109902</doc-number>
<kind>A1</kind>
<date>20120503</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Rozensztejn</last-name>
<first-name>Diego S.</first-name>
<address>
<city>Brighton</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Scheer</last-name>
<first-name>Fred</first-name>
<address>
<city>Bradford</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Hao</last-name>
<first-name>Jack Jianxiu</first-name>
<address>
<city>Lexington</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Rozensztejn</last-name>
<first-name>Diego S.</first-name>
<address>
<city>Brighton</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Scheer</last-name>
<first-name>Fred</first-name>
<address>
<city>Bradford</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Hao</last-name>
<first-name>Jack Jianxiu</first-name>
<address>
<city>Lexington</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Verizon Patent and Licensing Inc.</orgname>
<role>02</role>
<address>
<city>Basking Ridge</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Mofiz</last-name>
<first-name>Apu</first-name>
<department>2161</department>
</primary-examiner>
<assistant-examiner>
<last-name>Walker</last-name>
<first-name>Bryan</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system for applying time-based refresh and expiration parameters, including user-defined and/or automatically set values, for accessing cached media content and/or retrieving replacement media content for presentation via a communication device.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="187.88mm" wi="241.22mm" file="US08626718-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="243.16mm" wi="180.26mm" orientation="landscape" file="US08626718-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="244.52mm" wi="194.06mm" orientation="landscape" file="US08626718-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="251.71mm" wi="176.61mm" orientation="landscape" file="US08626718-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="237.91mm" wi="162.48mm" file="US08626718-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="229.62mm" wi="177.63mm" orientation="landscape" file="US08626718-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="238.25mm" wi="140.72mm" file="US08626718-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="180.26mm" wi="189.15mm" file="US08626718-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="241.81mm" wi="164.08mm" file="US08626718-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="220.39mm" wi="164.08mm" orientation="landscape" file="US08626718-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="178.22mm" wi="170.69mm" file="US08626718-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="240.54mm" wi="186.52mm" file="US08626718-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="239.52mm" wi="168.06mm" file="US08626718-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="177.29mm" wi="151.89mm" file="US08626718-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">Content providers, such as wireless telephone service providers, permit users to obtain information regarding multimedia content on their mobile devices. An issue with mobile devices is that sometimes the mobile devices lose their network connectivity, or their bandwidth is limited or slow.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0003" num="0002"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of an overview of an implementation described herein;</p>
<p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram that illustrates an example environment in which systems and/or methods, described herein, may be implemented;</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram of example components of a device that may be used within the environment of <figref idref="DRAWINGS">FIG. 2</figref>;</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram of an example mobile device of <figref idref="DRAWINGS">FIG. 2</figref>;</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram of example components of the mobile device of <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram of example functional components of the mobile device of <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram of an example arrangement of data in a cache memory of <figref idref="DRAWINGS">FIG. 6</figref>;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart of an example process for obtaining video content;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. 9A and 9B</figref> illustrate example user interfaces that may present video content metadata;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart of an example process for defining refresh and expiration parameters; and</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. 11-13</figref> illustrate a flowchart of an example process for presenting video content metadata on a display.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0003" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading>
<p id="p-0014" num="0013">The following detailed description refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements.</p>
<p id="p-0015" num="0014">An implementation, described herein, may cache content metadata so that the content metadata can be quickly presented to the user when the user desires the content metadata. Two parameters may be associated with the content metadata in the cache: a refresh parameter and an expiration parameter. The refresh and expiration parameters may be used to determine whether to read content metadata from the cache or to make a data call to a server to obtain new content metadata. As used herein, the term &#x201c;refresh parameter&#x201d; may refer to how soon the cache refreshes content metadata. As used herein, the term &#x201c;expiration parameter&#x201d; may refer to how long content metadata is to be cached and used before being discarded.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of an overview of an implementation described herein. As shown in <figref idref="DRAWINGS">FIG. 1</figref>, a user may use a mobile device to request and obtain content metadata. &#x201c;Content metadata,&#x201d; as used herein, may refer to information that refers or relates to the content, such as a list of content, a list of categories of content, descriptions of content, or the like. As shown in <figref idref="DRAWINGS">FIG. 1</figref>, a metadata provider may provide the content metadata to the user's mobile device. The content metadata may be stored in a cache associated with the mobile device. Future requests for the content metadata may be satisfied by reading the content metadata from the cache.</p>
<p id="p-0017" num="0016">As described above, refresh and expiration parameters may be associated with the content metadata in the cache. When the user requests the content metadata from the cache and the age of the content metadata is less than the refresh parameter, then the content metadata, from the cache, may be presented to the user. When the user requests the content metadata from the cache and the age of the content metadata is not less than the refresh parameter and is less than the expiration parameter, then the content metadata, from the cache, may be presented to the user and new content metadata may be obtained from a server and stored in the cache to replace the content metadata. When the user requests the content metadata from the cache and the age of the content metadata is not less than the expiration parameter, then new content metadata may be obtained from a server, the new content metadata may be stored in the cache to replace the content metadata, and the new content metadata may be presented to the user.</p>
<p id="p-0018" num="0017">The description to follow will describe the content as video content, such as television content, movie content, gaming content, or the like. The term &#x201c;video content,&#x201d; as used herein, is intended to include video data, which may or may not be combined with audio data. While the description will focus on video content, the description is not so limited and may apply to other types of content, such as audio content (e.g., audio books, music, concerts, etc.).</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram that illustrates an example environment <b>200</b> in which systems and/or methods, described herein, may be implemented. As shown in <figref idref="DRAWINGS">FIG. 2</figref>, environment <b>200</b> may include mobile devices <b>210</b>-<b>1</b>, <b>210</b>-<b>2</b>, . . . , <b>210</b>-M (where M&#x2267;1) (collectively referred to as &#x201c;mobile devices <b>210</b>,&#x201d; and individually as &#x201c;mobile device <b>210</b>&#x201d;), an application server <b>220</b> (hereinafter referred to as &#x201c;app server <b>220</b>&#x201d;), a user profile server <b>230</b>, a license server <b>240</b>, content storage <b>250</b>, a content distribution server <b>260</b>, and a network <b>270</b>. While <figref idref="DRAWINGS">FIG. 2</figref> shows a particular number and arrangement of devices, in practice, environment <b>200</b> may include additional, fewer, different, or differently arranged devices than are shown in <figref idref="DRAWINGS">FIG. 2</figref>. For example, each of servers <b>220</b>-<b>240</b> or <b>260</b> may be implemented as multiple, possibly distributed, devices. Alternatively, two or more of servers <b>220</b>-<b>240</b> and <b>260</b> may be implemented within a single device.</p>
<p id="p-0020" num="0019">Mobile device <b>210</b> may include any portable device capable of communicating via a network, such as network <b>270</b>. For example, mobile device <b>210</b> may correspond to a mobile communication device (e.g., a mobile phone or a personal digital assistant (PDA)), a portable computer device (e.g., a laptop or a tablet computer), or another type of portable device.</p>
<p id="p-0021" num="0020">App server <b>220</b> may include a server device, such as a computer device, that provides a video content application or performs user authentication, content listing management, or order processing. For example, app server <b>220</b> may permit mobile device <b>210</b> to download a video content application that may permit a user to find video content of interest or play downloaded or streaming video content. Also, or alternatively, app server <b>220</b> may provide video content metadata, such as lists video content, categories of video content, or video content descriptions. Also, or alternatively, app server <b>220</b> may authenticate a user who desires to purchase, rent, or subscribe to video content. In one implementation, the interactions between app server <b>220</b> and mobile device <b>210</b> may be performed using the hypertext transfer protocol (HTTP) or the secure HTTP (HTTPS). In another implementation, the interactions between app server <b>220</b> and mobile device <b>210</b> may be performed using another type of protocol.</p>
<p id="p-0022" num="0021">User profile server <b>230</b> may include a server device, such as a computer device, that stores user profile information for users. The user profile information may include various information regarding a user, such as login information (e.g., user identifier and password), billing information, address information, types of services to which the user has subscribed, a list of video content purchased by the user, a list of video content rented by the user, a list of video content to which the user has subscribed, ratings of video content by the user, a device identifier (e.g., a mobile device identifier, a set top box identifier, a personal computer identifier) for devices used by the user, a video content application identifier associated with the video content application obtained from app server <b>220</b>, or the like. App server <b>220</b> may use the user profile information to authenticate a user and may update the user profile information based on the user's activity (with the user's express permission).</p>
<p id="p-0023" num="0022">License server <b>240</b> may include a server device, such as a computer device, that provides key and license management. For example, license server <b>240</b> may receive a request from a mobile device <b>210</b> for a license relating to video content that mobile device <b>210</b> has downloaded. The license may include information regarding the type of use permitted by mobile device <b>210</b> (e.g., a purchase, a rental, or a subscription) and a decryption key that permits mobile device <b>210</b> to decrypt the video content. In one implementation, the communication between license server <b>240</b> and mobile device <b>210</b> may be conducted over a secure channel, may include public and private keys, or may include other forms of secure communication.</p>
<p id="p-0024" num="0023">Content storage <b>250</b> may include a server device, such as a computer device, or a storage device, such as a database, that stores or processes video content. For example, content storage <b>250</b> may perform encoding operations on video content using, for example, public/private keys. Content storage <b>250</b> may also perform transcoding operations on the video content. Content storage <b>250</b> may store video content in encrypted form.</p>
<p id="p-0025" num="0024">Content distribution server <b>260</b> may include a server device, such as a computer device, that delivers video content to mobile devices <b>210</b>. For example, content distribution server <b>260</b> may permit a mobile device <b>210</b> to download particular video content once the user, of mobile device <b>210</b>, has been properly authenticated. In one implementation, the downloading of video content may occur using the file transfer protocol (FTP). In another implementation, the downloading of video content may occur using another type of protocol.</p>
<p id="p-0026" num="0025">Network <b>270</b> may include any type of network or a combination of networks. For example, network <b>270</b> may include a local area network (LAN), a wide area network (WAN) (e.g., the Internet), a metropolitan area network (MAN), an ad hoc network, a telephone network (e.g., a Public Switched Telephone Network (PSTN), a cellular network, or a voice-over-IP (VoIP) network), an optical network, or a combination of networks. In one implementation, mobile device <b>210</b> may download video content via a wireless LAN (WLAN) (e.g., Wi-Fi (wireless fidelity)), a wireless WAN (WWAN) (e.g., EVDO (evolution data optimized)), sideloading (i.e., a transfer between two local devices), or a cable (e.g., USB).</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram of example components of a device <b>300</b>. Device <b>300</b> may correspond to app server <b>220</b>, user profile server <b>230</b>, license server <b>240</b>, content storage <b>250</b>, or content distribution server <b>260</b>. Each of app server <b>220</b>, user profile server <b>230</b>, license server <b>240</b>, content storage <b>250</b>, and content distribution server <b>260</b> may include one or more devices <b>300</b>.</p>
<p id="p-0028" num="0027">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, device <b>300</b> may include a bus <b>305</b>, a processor <b>310</b>, a main memory <b>315</b>, a read only memory (ROM) <b>320</b>, a storage device <b>325</b>, an input device <b>330</b>, an output device <b>335</b>, and a communication interface <b>340</b>. In another implementation, device <b>300</b> may include additional, fewer, different, or differently arranged components.</p>
<p id="p-0029" num="0028">Bus <b>305</b> may include a path that permits communication among the components of device <b>300</b>. Processor <b>310</b> may include a processor, a microprocessor, an application specific integrated circuit (ASIC), a field programmable gate array (FPGA), or another type of processor that interprets and executes instructions. Main memory <b>315</b> may include a random access memory (RAM) or another type of dynamic storage device that stores information or instructions for execution by processor <b>310</b>. ROM <b>320</b> may include a ROM device or another type of static storage device that stores static information or instructions for use by processor <b>310</b>. Storage device <b>325</b> may include a magnetic storage medium, such as a hard disk drive, or a removable memory, such as a flash memory.</p>
<p id="p-0030" num="0029">Input device <b>330</b> may include a mechanism that permits an operator to input information to device <b>300</b>, such as a control button, a keyboard, a keypad, or another type of input device. Output device <b>335</b> may include a mechanism that outputs information to the operator, such as a light emitting diode (LED), a display, or another type of output device. Communication interface <b>340</b> may include any transceiver-like mechanism that enables device <b>300</b> to communicate with other devices (e.g., mobile devices <b>210</b>) or networks (e.g., network <b>270</b>). In one implementation, communication interface <b>340</b> may include a wireless interface, a wired interface, or an optical interface.</p>
<p id="p-0031" num="0030">Device <b>300</b> may perform certain operations, as described in detail below. Device <b>300</b> may perform these operations in response to processor <b>310</b> executing software instructions contained in a computer-readable medium, such as main memory <b>315</b>. A computer-readable medium may be defined as a non-transitory memory device. A memory device may include space within a single physical memory device or spread across multiple physical memory devices.</p>
<p id="p-0032" num="0031">The software instructions may be read into main memory <b>315</b> from another computer-readable medium, such as storage device <b>325</b>, or from another device via communication interface <b>340</b>. The software instructions contained in main memory <b>315</b> may cause processor <b>310</b> to perform processes that will be described later. Alternatively, hardwired circuitry may be used in place of or in combination with software instructions to implement processes described herein. Thus, implementations described herein are not limited to any specific combination of hardware circuitry and software.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram of an example implementation of mobile device <b>210</b>. In the implementation shown in <figref idref="DRAWINGS">FIG. 4</figref>, mobile device <b>210</b> may correspond to a mobile communication device. Mobile device <b>210</b> may include a housing <b>405</b>, a microphone <b>410</b>, a speaker <b>415</b>, a keypad <b>420</b>, and a display <b>425</b>. In other implementations, mobile device <b>210</b> may include fewer, additional, different, or differently arranged components than those illustrated in <figref idref="DRAWINGS">FIG. 4</figref> and described herein. For example, keypad <b>420</b> may be implemented on a touch screen of display <b>425</b>.</p>
<p id="p-0034" num="0033">Housing <b>405</b> may include a structure to contain components of mobile device <b>210</b>. For example, housing <b>405</b> may be formed from plastic, metal, or some other material. Housing <b>405</b> may support microphone <b>410</b>, speaker <b>415</b>, keypad <b>420</b>, and display <b>425</b>.</p>
<p id="p-0035" num="0034">Microphone <b>410</b> may include an input device that converts a sound wave to a corresponding electrical signal. For example, the user may speak into microphone <b>410</b> during a telephone call or to execute a voice command. Speaker <b>415</b> may include an output device that converts an electrical signal to a corresponding sound wave. For example, the user may listen to music, listen to a calling party, or listen to other auditory signals through speaker <b>415</b>.</p>
<p id="p-0036" num="0035">Keypad <b>420</b> may include an input device that provides input into mobile device <b>210</b>. Keypad <b>420</b> may include a standard telephone keypad, a QWERTY keyboard, or some other type or arrangement of keys. Keypad <b>420</b> may also, or alternatively, include one or more special purpose keys. The user may utilize keypad <b>420</b> as an input component to mobile device <b>210</b>. For example, the user may use keypad <b>420</b> to enter information, such as alphanumeric text, to access data, or to invoke a function or an operation. As described above, keypad <b>420</b> may be implemented not as physical keys, but rather as virtual keys on a touch screen of display <b>425</b>.</p>
<p id="p-0037" num="0036">Display <b>425</b> may include an output device that outputs visual content, or may include an input device that receives user input (e.g., a touch screen (also known as a touch display)). Display <b>425</b> may be implemented according to a variety of display technologies, including but not limited to, a liquid crystal display (LCD), a plasma display panel (PDP), a field emission display (FED), a thin film transistor (TFT) display, or some other type of display technology. Additionally, display <b>425</b> may be implemented according to a variety of sensing technologies, including but not limited to, capacitive sensing, surface acoustic wave sensing, resistive sensing, optical sensing, pressure sensing, infrared sensing, gesture sensing, etc. Display <b>425</b> may be implemented as a single-point input device (e.g., capable of sensing a single touch or point of contact) or a multipoint input device (e.g., capable of sensing multiple touches or points of contact that occur at substantially the same time).</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram illustrating example components of mobile device <b>210</b>. As illustrated, mobile device <b>210</b> may include a processing unit <b>510</b>, a memory <b>520</b>, a user interface <b>530</b>, a communication interface <b>540</b>, and an antenna assembly <b>550</b>. In another implementation, mobile device <b>210</b> may include fewer, additional, different, or differently arranged components than those illustrated in <figref idref="DRAWINGS">FIG. 5</figref>. Additionally, in other implementations, a function described as being performed by a particular component of mobile device <b>210</b> may be performed by a different component of mobile device <b>210</b>.</p>
<p id="p-0039" num="0038">Processing unit <b>510</b> may include one or more processors, microprocessors, data processors, co-processors, network processors, ASICs, controllers, programmable logic devices (PLDs), chipsets, FPGAs, or other components that may interpret or execute instructions or data. Processing unit <b>510</b> may control the overall operation, or a portion thereof, of mobile device <b>210</b>, based on, for example, an operating system (not illustrated) and/or various applications. Processing unit <b>510</b> may access instructions from memory <b>520</b>, from other components of mobile device <b>210</b>, or from a source external to mobile device <b>210</b> (e.g., a network or another device).</p>
<p id="p-0040" num="0039">Memory <b>520</b> may include memory or secondary storage. For example, memory <b>520</b> may include a RAM, a dynamic RAM (DRAM), a ROM, a programmable ROM (PROM), a flash memory, or some other type of memory. Memory <b>520</b> may include a hard disk (e.g., a magnetic disk, an optical disk, a magneto-optic disk, a solid state disk, etc.) or some other type of computer-readable medium, along with a corresponding drive. Memory <b>520</b> may store data, applications, or instructions related to the operation of mobile device <b>210</b>. For example, memory <b>520</b> may include a variety of applications, such as a video content application, a navigation application, an e-mail application, a telephone application, a camera application, a voice recognition application, a multi-media application, a music player application, a visual voicemail application, a contacts application, a data organizer application, a calendar application, an instant messaging application, a texting application, a web browsing application, a blogging application, or other types of applications (e.g., a word processing application, a spreadsheet application, etc.). As described above, the video content application may permit a user to find video content of interest; purchase, rent, or subscribe to the video content; or play the video content.</p>
<p id="p-0041" num="0040">In one implementation, memory <b>520</b> may include a cache memory that stores video content metadata. The video content metadata may include a list of available video content, a list of categories of video content, descriptions of video content (e.g., a title of the video content, a release date of the video content, a category of the video content, a length of the video content, a rating of the video content, a synopsis of the video content, a cast list for the video content, a director/producer list for the video content, a trailer associated with the video content, or the like). In one implementation, the cache memory may further include information, corresponding to particular video content metadata, that indicates how long the particular video content metadata has been stored in the cache memory.</p>
<p id="p-0042" num="0041">User interface <b>530</b> may include components for inputting information to mobile device <b>210</b> and for outputting information from mobile device <b>210</b>. Examples of input and output components might include a speaker (e.g., speaker <b>415</b>) to receive electrical signals and output audio signals, a microphone (e.g., microphone <b>410</b>) to receive audio signals and output electrical signals, buttons (e.g., keypad <b>420</b>) to permit data and control commands to be input into mobile device <b>210</b>, a display (e.g., display <b>425</b>) to output visual information, or a vibrator to cause mobile device <b>210</b> to vibrate.</p>
<p id="p-0043" num="0042">Communication interface <b>540</b> may include, for example, a transmitter that may convert baseband signals from processing unit <b>510</b> to radio frequency (RF) signals and/or a receiver that may convert RF signals to baseband signals. Alternatively, communication interface <b>540</b> may include a transceiver to perform functions of both a transmitter and a receiver. Communication interface <b>540</b> may connect to antenna assembly <b>550</b> for transmission and reception of the RF signals.</p>
<p id="p-0044" num="0043">Antenna assembly <b>550</b> may include one or more antennas to transmit and receive RF signals over the air. Antenna assembly <b>550</b> may receive RF signals from communication interface <b>540</b> and transmit the signals over the air, and may receive RF signals over the air and provide the signals to communication interface <b>540</b>.</p>
<p id="p-0045" num="0044">As described herein, mobile device <b>210</b> may perform certain operations in response to processing unit <b>510</b> executing software instructions contained in a computer-readable medium, such as memory <b>520</b>. The software instructions may be read into memory <b>520</b> from another computer-readable medium or from another device via communication interface <b>540</b>. The software instructions contained in memory <b>520</b> may cause processing unit <b>510</b> to perform processes described herein. Alternatively, hardwired circuitry may be used in place of or in combination with software instructions to implement processes described herein. Thus, implementations described herein are not limited to any specific combination of hardware circuitry and software.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram of example functional components of mobile device <b>210</b>. As illustrated in <figref idref="DRAWINGS">FIG. 6</figref>, mobile device <b>210</b> may include a cache manager <b>610</b> and a cache memory <b>620</b>. Cache manager <b>610</b> and cache memory <b>620</b> may be implemented as a combination of hardware and software based on the components illustrated and described with respect to <figref idref="DRAWINGS">FIG. 5</figref>. Alternatively, cache manager <b>610</b> and cache memory <b>620</b> may be implemented as hardware based on the components illustrated and described with respect to <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0047" num="0046">Cache manager <b>610</b> may set refresh and expiration parameters. The refresh and expiration parameters may be automatically set. Alternatively, a user, of mobile device <b>210</b>, may be permitted to set the refresh and expiration parameters. In one implementation, the refresh and expiration parameters may differ for different types of video content metadata. For example, for a listing of available video content, a refresh parameter may be set to 24 hours and an expiration parameter may be set to 100 days. In another implementation, the refresh and expiration parameters may be the same for different types of video content metadata. For example, for a list of available video content and for a list of video content categories, a refresh parameter may be set to 2 days and an expiration parameter may be set to 90 days.</p>
<p id="p-0048" num="0047">Cache manager <b>610</b> may manage the storing of video content metadata in cache memory <b>620</b>, the refreshing of video content metadata within cache memory <b>620</b> (e.g., obtaining of new video content metadata to replace stale video content metadata), and the obtaining of video content metadata for storage in cache memory <b>620</b>.</p>
<p id="p-0049" num="0048">Cache memory <b>620</b> may include a local memory, of mobile device <b>210</b>, that stores video content metadata. In one implementation, cache memory <b>620</b> may store a particular amount of video content metadata. In this implementation, when cache memory <b>620</b> is full, new video content metadata may replace the oldest video content metadata. In another implementation, cache memory <b>620</b> may use another technique to determine where to store new video content metadata.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram of an example arrangement of data in cache memory <b>620</b>. As shown in <figref idref="DRAWINGS">FIG. 7</figref>, cache memory <b>620</b> may include an address field <b>710</b>, a metadata field <b>720</b>, and an age value field <b>730</b>. In another implementation, cache memory <b>620</b> may include additional fields, fewer fields, different fields, or differently arranged fields.</p>
<p id="p-0051" num="0050">Address field <b>710</b> may store an address, such a uniform resource locator (URL), associated with video content metadata available on a server, such as app server <b>220</b>. Examples of types of video content metadata have been described above. Each entry in address field <b>710</b> may correspond to a different type of video content metadata. For example, one entry in address field <b>710</b> may correspond to video content metadata relating to a list of available video content; another entry in address field <b>710</b> may correspond to video content metadata relating to a list of video content categories; a further entry in address field <b>710</b> may correspond to video content metadata relating to video content descriptions; etc.</p>
<p id="p-0052" num="0051">Metadata field <b>720</b> may store video content metadata, or a pointer to video content metadata, relating to the address in address field <b>710</b>. Examples of video content metadata might include a list of available video content, a list of video content categories, video content descriptions, etc. In one implementation, not all types of video content metadata may be stored in cache memory <b>620</b>. For example, a trailer, associated with particular video content metadata, may not be stored in cache memory <b>620</b>. The types of video content metadata to be stored in cache memory <b>620</b> may be specified by the video content application or by the user.</p>
<p id="p-0053" num="0052">Age value field <b>730</b> may store information relating to how long the corresponding video content metadata has been stored in cache memory <b>620</b>. In one implementation, age value field <b>730</b> may store a timestamp that indicates a time when the video content metadata was stored in cache memory <b>620</b>. In another implementation, age value field <b>730</b> may store a counter that increments (or decrements) to reflect a number of clock cycles (or the like) that the video content metadata has been stored in cache memory <b>620</b>.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart of an example process <b>800</b> for obtaining video content. In one implementation, process <b>800</b> may be performed by one or more components of mobile device <b>210</b>, such as processing unit <b>510</b> of mobile device <b>210</b>. In another implementation, one or more blocks of process <b>800</b> may be performed by one or more components of another device (e.g., one or more of servers <b>220</b>, <b>240</b>, or <b>260</b>), or a group of devices including or excluding mobile device <b>210</b>. Process <b>800</b> will be described with corresponding references to example user interfaces illustrated in <figref idref="DRAWINGS">FIGS. 9A and 9B</figref>.</p>
<p id="p-0055" num="0054">Process <b>800</b> may include activating video content application (block <b>810</b>). For example, a user, of mobile device <b>210</b>, may activate a video content application in a standard manner, such as by selecting an icon (or another type of identifier) associated with the video content application, selecting the name of the video content application from a list, etc.</p>
<p id="p-0056" num="0055">A user interface may be presented via which the user can select video content (block <b>820</b>). For example, the video content application may provide metadata regarding available video content in a number of different formats. As shown in <figref idref="DRAWINGS">FIG. 9A</figref>, for example, the video content application may include an option that permits the user to access &#x201c;featured&#x201d; video content, an option that permits the user to access a list of categories of video content, an option that permits the user to access a watch list, an option that permits the user to access a &#x201c;what's new&#x201d; list, and an option that permits the user to search for video content. The &#x201c;featured&#x201d; video content option, when selected, may present a list of popular video content (e.g., popular to the user based on the user's prior purchases, rentals, subscriptions, or ratings, or popular to a group of users based on recent activity of the group of users, based on ratings by the group of users, etc.), video content that is being promoted, or simply available video content. The categories option, when selected, may permit the user to peruse video content by category, such as horror, drama, comedy, R-rated, G-rated, 5-star-rated, 4-star-rated, or other categories of video content. The watch list option, when selected, may present a list of video content that has been previously added to the watch list by the user or that is recommended to the user based on video content in which the user has expressed an interest (e.g., as determined by the user's prior activity). The &#x201c;what's new&#x201d; option, when selected, may present a list of video content that has recently become available. The search option, when selected, may permit the user to search for video content by keyword.</p>
<p id="p-0057" num="0056">Returning to <figref idref="DRAWINGS">FIG. 8</figref>, a selection, with regard to particular video content, may be received (block <b>730</b>). For example, the video content application may receive selection, by the user, of particular video content from within the presented user interface. In response to the selection by the user, the video content application may present a details user interface relating to the particular video content. The details user interface may include detailed information regarding the particular video content and options for acting upon the particular video content. The detailed information might include information, such as a title of the particular video content, a release date of the particular video content (e.g., a year that the particular video content was released), a category of the particular video content (e.g., a list of one or more categories assigned to the particular video content), a length of the particular video content (e.g., a running length of the particular video content), a rating of the particular video content (assigned by the user or by a group of users), a synopsis of the particular video content, a cast list for the particular video content, a director list for the particular video content, or the like.</p>
<p id="p-0058" num="0057">The details user interface may also present the user with options to perform an action in relation to the particular video content. For example, the options might include an option to add the particular video content to the watch list, an option to preview the particular video content, an option to rent the particular video content, an option to purchase the particular video content, and an option to subscribe to a service relating to the particular video content. The option to add the particular video content to the watch list, when selected, may add the particular video content to the user's watch list. The option to preview the particular video content, when selected, may cause a trailer, or the like, to be played for the user. The option to rent the particular video content, when selected, may permit the user to access the particular video content for a particular rental period, after which the user may no longer be permitted to access the particular video content. The option to purchase the particular video content, when selected, may permit the user to access the particular video content for an indefinite period of time. The option to subscribe to a service relating to the particular video content, when selected, may permit the user to subscribe to a service via which the particular video content is available. For example, the service relating to the particular video content may correspond to a pay service, such as HBO, Cinemax, Starz, the Howard Stern channel, the NFL RedZone channel, or the like. Once the user subscribes to the service, the particular video content may be available to the user for the subscription period or until the user terminates the subscription.</p>
<p id="p-0059" num="0058">As shown in <figref idref="DRAWINGS">FIG. 9A</figref>, for example, assume that the user selects the video content entitled &#x201c;Dragonslayer.&#x201d; As shown in <figref idref="DRAWINGS">FIG. 9B</figref>, a details user interface may be presented with information regarding the video content entitled &#x201c;Dragonslayer.&#x201d; As further shown in <figref idref="DRAWINGS">FIG. 9B</figref>, the details user interface may permit the user to preview the video content, rent the video content, purchase the video content, or subscribe to a channel relating to the video content. Assume, for this example, that the user has selected to either the rent, purchase, or subscribe option.</p>
<p id="p-0060" num="0059">Examples of video content metadata are shown in <figref idref="DRAWINGS">FIGS. 9A and 9B</figref>. As described above, cache manager <b>610</b> (<figref idref="DRAWINGS">FIG. 6</figref>) may deliver cached video content metadata based on refresh and expiration parameters. The caching operation will be described in more detail with regard to <figref idref="DRAWINGS">FIGS. 11-13</figref>.</p>
<p id="p-0061" num="0060">Returning to <figref idref="DRAWINGS">FIG. 8</figref>, the user, device, or application may be authenticated (block <b>840</b>). For example, the video content application may interact with app server <b>220</b> to authenticate the user, mobile device <b>210</b>, or the video content application. For example, the video content application may solicit user login information (e.g., a user identifier (username) and password) from the user. The video content application may provide the user login information to app server <b>220</b>. App server <b>220</b> may compare the user login information to information maintained by user profile server <b>230</b> and may authenticate the user when the information matches. Additionally, or alternatively, the video content application may provide device information (e.g., a mobile device identifier) to app server <b>220</b>. App server <b>220</b> may compare the device information to information maintained by user profile server <b>230</b> and may authenticate mobile device <b>210</b> when the information matches. Additionally, or alternatively, the video content application may provide application information (e.g., an identifier associated with the video content application) to app server <b>220</b>. App server <b>220</b> may compare the application information to information maintained by user profile server <b>230</b> and may authenticate the video content application when the information matches.</p>
<p id="p-0062" num="0061">Billing information may be received (block <b>850</b>). For example, the video content application may solicit the user to provide billing information. In one implementation, the user may provide credit or debit card information. In another implementation, the user may be permitted to simply add the expense (for the rental, purchase, or subscription) to the user's account with that service provider. In yet another implementation, the user may be permitted to use a payment service, such as PayPal.</p>
<p id="p-0063" num="0062">Once the user, device, or application has been properly authenticated and billing information has been received, the particular video content may be downloaded (block <b>860</b>). For example, the video content application may receive, from app server <b>220</b>, a link (or the like) for requesting the particular content from content distribution server <b>260</b>. The video content application may follow the link and interact with content distribution server <b>260</b> to download the particular video content. Content distribution server <b>260</b> may communicate with content storage <b>250</b> to obtain the particular video content, in encrypted form, that may then be delivered to mobile device <b>210</b>. Content distribution server <b>260</b> or content storage <b>250</b> may communicate with license server <b>240</b> to obtain a license identifier corresponding to a license associated with the particular video content. Content distribution server <b>260</b> may provide the particular video content and the license identifier to the video content application. The video content application may store the downloaded particular video content, and possibly the license identifier, in a memory associated with mobile device <b>210</b> (e.g., memory <b>520</b>).</p>
<p id="p-0064" num="0063">A license for the particular video content may be obtained (block <b>870</b>). For example, the video content application may interact with license server <b>240</b>, in a secure manner, to obtain a license for the particular video content. In one implementation, the video content application may transmit the license identifier, to license server <b>240</b>, to identify the particular license that is desired. License server <b>240</b> may interact with app server <b>220</b> to identify the particular video content for which there has been a purchase, rental, subscription, and to receive user profile information associated with the user of mobile device <b>210</b>. License server <b>240</b> may also interact with the video content application to authenticate the user, device, or application in a manner similar to that described above with regard to block <b>840</b>. In one implementation, license server <b>240</b> may use digital rights management techniques to control access, via a license, to the particular video content. The license may include information regarding use of the particular video content by the user (e.g., whether the user has permanent use (via a purchase) or temporary use (via a rental or subscription)), and a decryption key to permit the encrypted particular video content to be decrypted by mobile device <b>210</b>.</p>
<p id="p-0065" num="0064">The particular video content may be made available to the user (block <b>880</b>). For example, the video content application may use the decryption key (included in/with the license from license server <b>240</b>) to decrypt the encrypted particular video content. The video content application may then notify the user that the particular video content is available for viewing whenever the user desires.</p>
<p id="p-0066" num="0065">Reference has been made above to certain operations being performed by the video content application. It should be understood that these operations may actually be performed by processing unit <b>510</b> executing the video content application.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart of an example process <b>1000</b> for defining refresh and expiration parameters. In one implementation, process <b>1000</b> may be performed by one or more components of mobile device <b>210</b>, such as processing unit <b>510</b> of mobile device <b>210</b>. In another implementation, one or more blocks of process <b>1000</b> may be performed by one or more components of another device (e.g., app server <b>220</b>), or a group of devices including or excluding mobile device <b>210</b>.</p>
<p id="p-0068" num="0067">Process <b>1000</b> may include presenting a user interface via which a user can specify refresh and expiration parameters (block <b>1010</b>). For example, cache manager <b>610</b> may present the user with a user interface that permits a user to input refresh parameter and expiration parameter values for one or more of the different types of video content metadata (e.g., a list of featured video content, a list of categories of video content, a watch list, and a what's new list, as shown in <figref idref="DRAWINGS">FIG. 9A</figref>). In one implementation, for a refresh or expiration parameter, the user may be presented with a default value and one or more alternative values from which the user may select. In another implementation, for a refresh or expiration parameter, the user may be permitted to input a value.</p>
<p id="p-0069" num="0068">Information may be received via the user interface (block <b>1020</b>). For example, cache manager <b>610</b> may receive user input, via the user interface, which may define the refresh and expiration parameters. For example, the user might select a refresh parameter and an expiration parameter for one or more of the different types of video content metadata.</p>
<p id="p-0070" num="0069">The refresh and expiration parameters may be stored (block <b>1030</b>). For example, cache manager <b>610</b> may store the refresh and expiration parameters, for one or more of the different types of video content metadata, in cache memory <b>620</b>.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIGS. 11-13</figref> illustrate a flowchart of an example process <b>1100</b> for presenting video content metadata on a display. In one implementation, process <b>1100</b> may be performed by one or more components of mobile device <b>210</b>, such as processing unit <b>510</b> of mobile device <b>210</b>. In another implementation, one or more blocks of process <b>1100</b> may be performed by one or more components of another device (e.g., app server <b>220</b>), or a group of devices including or excluding mobile device <b>210</b>.</p>
<p id="p-0072" num="0071">Process <b>1100</b> may include receiving an instruction to access video content metadata (block <b>1110</b>) (<figref idref="DRAWINGS">FIG. 11</figref>). For example, a user, of mobile device <b>210</b>, may activate a video content application in a standard manner, such as by selecting an icon (or another type of identifier) associated with the video content application, selecting the name of the video content application from a list, etc. In one implementation, activation of the video content application may cause a user interface to be presented on a display associated with mobile device <b>210</b>. The user interface may present particular (e.g., default) video content metadata on the display. Thus, in this implementation, the instruction to access video content metadata may correspond to an instruction to activate the video content application. In another implementation, the user interface may present an option for selecting particular video content metadata. In this implementation, selection of the option may correspond to the instruction to access video content metadata.</p>
<p id="p-0073" num="0072">It may be determined whether the video content metadata is stored in the cache (block <b>1120</b>). For example, cache manager <b>610</b> may determine whether cache memory <b>620</b> includes an entry that stores the video content metadata in metadata field <b>720</b> (<figref idref="DRAWINGS">FIG. 7</figref>). If the metadata is stored in the cache (block <b>1130</b>&#x2014;YES), then the age value, of the video content metadata, may be read (block <b>1140</b>). For example, cache manager <b>610</b> may read the age value from age value field <b>730</b> of the entry in cache memory <b>620</b>. Cache manager <b>610</b> may also identify the refresh and expiration parameters associated with this type of video content metadata. For example, if the video content metadata corresponds to a list of video content categories, then cache manager <b>610</b> may identify refresh and expiration parameters that correspond to the list of video content categories.</p>
<p id="p-0074" num="0073">If the age value is less than the refresh parameter (block <b>1150</b>&#x2014;YES), then the video content metadata may be read from the cache (block <b>1160</b>) and presented on a display (block <b>1170</b>). For example, during the time period when the age value is less than the refresh parameter (also referred to herein as the &#x201c;refresh period&#x201d;), cache memory <b>610</b> may read the video content metadata from cache memory <b>610</b> and may provide the video content metadata on display <b>425</b> (<figref idref="DRAWINGS">FIG. 4</figref>). In this situation, the video content application need not make a data call to a server (e.g., app server <b>220</b>) for the video content metadata. Rather, the video content metadata may be served directly from cache memory <b>620</b>. Thus, for as long as the age value is less than the refresh parameter, any requests for the video content metadata may be served directly from cache memory <b>620</b>.</p>
<p id="p-0075" num="0074">If the age value is not less than the refresh parameter (block <b>1150</b>&#x2014;NO), it may be determined whether the age value is less than the expiration parameter (block <b>1210</b>) (<figref idref="DRAWINGS">FIG. 12</figref>). If the age value is less than the expiration parameter (block <b>1210</b>&#x2014;YES), then the video content metadata may be read from the cache (block <b>1220</b>) and presented on a display (block <b>1230</b>). For example, during the time period when the age value is not less than the refresh parameter and is less than the expiration parameter (also referred to herein as the &#x201c;pre-expiration period&#x201d;), cache manager <b>610</b> may read the video content metadata from the entry in cache memory <b>620</b>, and may present the video content metadata on display <b>425</b>. In this situation, the video content metadata may not include the most recent metadata but may be current enough to serve the metadata right from cache memory <b>620</b>.</p>
<p id="p-0076" num="0075">A server may be contacted to obtain new video content metadata (block <b>1240</b>). For example, cache manager <b>610</b> may make a data call (e.g., a HTTP request) to app server <b>220</b> to request new video content metadata corresponding to the video content metadata. App server <b>220</b> may locate the appropriate video content metadata and may return that metadata to cache manager <b>610</b>.</p>
<p id="p-0077" num="0076">The video content metadata, stored in the cache, may be replaced with the new video content metadata (block <b>1250</b>). For example, cache manager <b>610</b> may receive the new video content metadata from app server <b>220</b> and may store the new video content metadata in cache memory <b>620</b> so as to replace the older version of the video content metadata. Cache manager <b>610</b> may also update the age value in age value field <b>730</b>. For example, if age value field <b>730</b> includes a timestamp, then cache manager <b>610</b> may store a new timestamp in age value field <b>730</b>. On the other hand, if age value field <b>730</b> includes a counter, then cache manager <b>610</b> may reset the counter or set the counter to a particular value.</p>
<p id="p-0078" num="0077">The new video content metadata may be presented on a display (block <b>1260</b>). In one implementation, cache manager <b>610</b> may immediately replace the displayed video content metadata with the new video content metadata. For example, cache manager <b>610</b> may simply refresh display <b>425</b> to replace the older version of the video content metadata with the new video content metadata. In another implementation, cache manager <b>610</b> may replace the older version of the video content metadata with the new video content metadata upon the occurrence of a particular event. The event may correspond to restarting the video content application (e.g., closing and reactivating the video content application), moving away from the user interface of video content application on display <b>425</b> and returning to the user interface on display <b>425</b>, receiving a new instruction to access the video content metadata (e.g., receiving selection of an option to access other video content metadata and then receiving selection of the option to access the video content metadata), restarting or rebooting mobile device <b>210</b> (e.g., turning mobile device <b>210</b> off and on), or some other event. In yet another implementation, cache manager <b>610</b> may replace the older version of the video content metadata with the new video content metadata upon expiration of a particular amount of time (e.g., replace the video content metadata thirty seconds after obtaining the new video content metadata). The particular technique, used to replace the older version of the video content metadata with new video content metadata, may be configured by the user or may be automatically set (e.g., a default technique). For example, the user may prefer one technique over another.</p>
<p id="p-0079" num="0078">If the video content metadata is not stored in the cache (block <b>1130</b>&#x2014;NO) (<figref idref="DRAWINGS">FIG. 11</figref>) or the age value is not less than the expiration parameter (block <b>1210</b>&#x2014;NO) (<figref idref="DRAWINGS">FIG. 12</figref>), a server may be contacted to obtain the video content metadata (block <b>1310</b>). For example, during the time period when the age value is not less than the expiration parameter (also referred to herein as the &#x201c;post expiration period&#x201d;) or when cache memory <b>620</b> does not store the video content metadata, cache manager <b>610</b> may make a data call (e.g., a HTTP request) to app server <b>220</b> to request the video content metadata. App server <b>220</b> may locate the appropriate video content metadata and may return that metadata to cache manager <b>610</b>.</p>
<p id="p-0080" num="0079">The video content metadata may be stored in the cache (block <b>1320</b>). For example, cache manager <b>610</b> may receive the video content metadata from app server <b>220</b> and may store the new video content metadata in cache memory <b>620</b> (replacing an older version of the video content metadata, if present in cache memory <b>620</b>). Cache manager <b>610</b> may also store an age value in age value field <b>730</b>. For example, if age value field <b>730</b> includes a timestamp, then cache manager <b>610</b> may store a timestamp in age value field <b>730</b>. On the other hand, if age value field <b>730</b> includes a counter, then cache manager <b>610</b> may set the counter to a particular value.</p>
<p id="p-0081" num="0080">The video content metadata may be presented on a display (block <b>1330</b>). For example, cache manager <b>610</b> may present the video content metadata on display <b>425</b>.</p>
<p id="p-0082" num="0081">An implementation, described herein, may store certain content metadata in a cache. During a refresh period (e.g., when an age value of the content metadata is less than a refresh parameter), the content metadata may be served from the cache with no data calls to the server. During a pre-expiration period (e.g., when an age value of the content metadata is less than an expiration parameter), the content metadata may be served from the cache and a data call may be made to the server to retrieve new content metadata that replaces the content metadata in the cache. During a post expiration period (when an age value of the content metadata is not less than the expiration parameter) or when the cache does not store the content metadata, a data call may be made to the server to obtain the content metadata.</p>
<p id="p-0083" num="0082">The foregoing description provides illustration and description, but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention.</p>
<p id="p-0084" num="0083">For example, while series of blocks have been described with regard to FIGS. <b>8</b> and <b>10</b>-<b>13</b>, the order of the blocks may be modified in other implementations. Further, non-dependent blocks may be performed in parallel.</p>
<p id="p-0085" num="0084">It will be apparent that different aspects of the description provided above may be implemented in many different forms of software, firmware, and hardware in the implementations illustrated in the figures. The actual software code or specialized control hardware used to implement these aspects is not limiting of the invention. Thus, the operation and behavior of these aspects were described without reference to the specific software code&#x2014;it being understood that software and control hardware can be designed to implement these aspects based on the description herein.</p>
<p id="p-0086" num="0085">Even though particular combinations of features are recited in the claims and/or disclosed in the specification, these combinations are not intended to limit the disclosure of the invention. In fact, many of these features may be combined in ways not specifically recited in the claims and/or disclosed in the specification. Although each dependent claim listed below may directly depend on only one other claim, the disclosure of the invention includes each dependent claim in combination with every other claim in the claim set.</p>
<p id="p-0087" num="0086">No element, act, or instruction used in the present application should be construed as critical or essential to the invention unless explicitly described as such. Also, as used herein, the article &#x201c;a&#x201d; is intended to include one or more items. Where only one item is intended, the term &#x201c;one&#x201d; or similar language is used. Further, the phrase &#x201c;based on&#x201d; is intended to mean &#x201c;based, at least in part, on&#x201d; unless explicitly stated otherwise.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method, comprising:
<claim-text>storing, in a memory associated with a mobile device, a refresh parameter and an expiration parameter;</claim-text>
<claim-text>receiving, by a processor associated with the mobile device, an instruction to access particular content metadata;</claim-text>
<claim-text>determining, by a processor associated with the mobile device and in response to the instruction, that the particular content metadata is stored in a cache memory associated with the mobile device;</claim-text>
<claim-text>determining, by a processor associated with the mobile device and based on the refresh and expiration parameters, whether the particular content metadata has been stored in the cache memory for a time period within a refresh period, within a pre-expiration period, or within a post expiration period;</claim-text>
<claim-text>presenting, by a processor associated with the mobile device, the particular content metadata from the cache memory without contacting a server when the particular content metadata has been stored in the cache memory for a time period within the refresh period;</claim-text>
<claim-text>displaying, via a display associated with the mobile device, the particular content metadata from the cache memory and contacting a server to obtain first new content metadata when the particular content metadata has been stored in the cache memory for a time period within the pre-expiration period;</claim-text>
<claim-text>obtaining, by a processor associated with the mobile device, the first new content metadata in response to contacting the server;</claim-text>
<claim-text>storing, in the cache memory, the first new content metadata;</claim-text>
<claim-text>receiving, by a processor associated with the mobile device, user input indicative of one or more preferred events relative to one or more other events,</claim-text>
<claim-text>replacing, with the first new content metadata, the displayed content metadata on the display, upon detecting a first to occur of the one or more of preferred events, wherein the one or more preferred events are selected from a group comprising:
<claim-text>closing and then reactivating a particular application on the mobile device,</claim-text>
<claim-text>removing a particular user interface from the display and then returning the particular user interface to the display,</claim-text>
<claim-text>restarting or rebooting the mobile device, and</claim-text>
<claim-text>expiration of a particular amount of time; and</claim-text>
</claim-text>
<claim-text>contacting a server to obtain second new content metadata, relating to the particular content metadata, and presenting the second new content metadata when the particular content metadata has been stored in the cache memory for a time period within the post expiration period.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where storing the refresh parameter and the expiration parameter includes:
<claim-text>receiving, from a user of the mobile device, a first value for the refresh parameter,</claim-text>
<claim-text>receiving, from the user, a second value for the expiration parameter, and</claim-text>
<claim-text>storing the first value and the second value in the memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the refresh parameter and the expiration parameter are specific to a type of the particular content metadata; and
<claim-text>where the method further comprises:
<claim-text>receiving a separate refresh parameter and a separate expiration parameter for another type of content metadata, where the other type of content metadata differs from the type of the particular content metadata.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where determining whether the particular content metadata has been stored in the cache memory for a time period within the refresh period, within the pre-expiration period, or within the post expiration period includes:
<claim-text>reading an age value that reflects an amount of time that the particular content metadata has been stored in the cache memory, and</claim-text>
<claim-text>determining whether the age value indicates that the particular content metadata has been stored in the cache memory for an amount of time that falls within the refresh period, the pre-expiration period, or the post expiration period.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, where, when the particular content metadata has been stored in the cache memory for an amount of time that falls within the pre-expiration period, the method further comprises:
<claim-text>updating the age value based on the storing of the first new content metadata.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where presenting the second new content metadata when the particular content metadata has been stored in the cache memory for a time period within the post expiration period includes:
<claim-text>replacing the particular content metadata, in the cache memory, with the second new content metadata, and</claim-text>
<claim-text>presenting, on the display, the second new content metadata without presenting the particular content metadata on the display.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A mobile device, comprising:
<claim-text>a memory to store information associated with particular content metadata and an age value that reflects an amount of time that the information has been stored in the memory; and</claim-text>
<claim-text>a processor to:
<claim-text>present a user interface configured to:
<claim-text>present, for selection by a user, a default value and at least one alternative value corresponding to a first amount of time with respect to the particular content metadata,</claim-text>
<claim-text>receive, from the user, user input indicative of an input value corresponding to the first amount of time,</claim-text>
<claim-text>present, for selection by the user, a default value and at least one alternative value corresponding to a second amount of time with respect to the particular content metadata, and</claim-text>
<claim-text>receive, from the user, user input indicative of an input value corresponding to the second amount of time;</claim-text>
</claim-text>
<claim-text>receive a request for the particular content metadata,</claim-text>
<claim-text>determine, in response to the request, that information associated with the particular content metadata is stored in the memory,</claim-text>
<claim-text>read the age value corresponding to the information associated with the particular content metadata,</claim-text>
<claim-text>present the particular content metadata without contacting a server when the age value indicates that the information, associated with the particular content metadata, has been stored in the memory for less than the default value, the at least one alternative value, or the input value corresponding to the first amount of time,</claim-text>
<claim-text>present the particular content metadata and contact a server to obtain new content metadata when the age value indicates that the information, associated with the particular content metadata, has been stored in the memory for at least the first amount of time and less than the default value, the at least one alternative value, or the input value corresponding to the second amount of time,</claim-text>
<claim-text>receive user input indicative of one or more preferred events relative to one or more other events,</claim-text>
<claim-text>replace the particular content metadata with the new content metadata upon detecting a first to occur of the one or more preferred events, wherein the one or more preferred events are selected from a group comprising:
<claim-text>closing and then reactivating a particular application via a display associated with the mobile device,</claim-text>
<claim-text>removing a particular user interface from the display and then returning the particular user interface to the display,</claim-text>
<claim-text>restarting or rebooting the mobile device, and</claim-text>
<claim-text>expiration of a particular amount of time, and</claim-text>
</claim-text>
<claim-text>contact a server to obtain new content metadata, relating to the particular content metadata, and present the new content metadata when the age value indicates that the information, associated with the particular content metadata, has been stored in the memory for at least the second amount of time.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The mobile device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, where, when the age value indicates that the information, associated with the particular content metadata, has been stored in the memory for at least the first amount of time and less than the second amount of time, the processor is to:
<claim-text>store information, associated with the new content metadata, to replace the information, associated with the particular content metadata, in the memory; and</claim-text>
<claim-text>update the age value for the new content metadata.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The mobile device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, where, when the age value indicates that the information, associated with the particular content metadata, has been stored in the memory for at least the first amount of time and less than the second amount of time, the processor is to:
<claim-text>refresh a display, associated with the mobile device, to replace the particular content metadata with the new content metadata on the display.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The mobile device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, where, when presenting the new content metadata when the age value indicates that the information, associated with the particular content metadata, has been stored in the memory for at least the second amount of time, the processor is to:
<claim-text>store information, associated with the new content metadata, in the memory, and</claim-text>
<claim-text>present, on a display associated with the mobile device, the new content metadata without presenting the particular content metadata on the display.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A non-transitory computer-readable medium containing instructions that, when executed by one or more processors, cause the one or more processors to perform a method, the method comprising:
<claim-text>presenting, via a display, a user interface configured to:
<claim-text>present, for selection by a user, a default value and at least one alternative value corresponding to a first amount of time with respect to a particular type of video content metadata,</claim-text>
<claim-text>receive, from the user, user input indicative of an input value corresponding to the first amount of time,</claim-text>
<claim-text>present, for selection by the user, a default value and at least one alternative value corresponding to a second amount of time with respect to the particular type of video content metadata, and</claim-text>
<claim-text>receive, from the user, user input indicative of an input value corresponding to the second amount of time;</claim-text>
</claim-text>
<claim-text>receiving a request for the particular type of video content metadata of a plurality of types of video content metadata;</claim-text>
<claim-text>determining, in response to the request, whether information associated with the particular type of video content metadata is stored in a memory local to the one or more processors;</claim-text>
<claim-text>presenting the particular type of video content metadata for display without contacting a server when the information, associated with the particular type of video content metadata, has been stored in the memory for less than the first amount of time;</claim-text>
<claim-text>displaying the particular type of video content metadata via the display and contacting a server to obtain first new video content metadata when the information, associated with the particular type of video content metadata, has been stored in the memory for at least the first amount of time and less than a second amount of time;</claim-text>
<claim-text>obtaining the first new video content metadata in response to contacting the server;</claim-text>
<claim-text>storing the first new video content metadata in the memory;</claim-text>
<claim-text>receiving user input indicative of one or more preferred events relative to one or more other events;</claim-text>
<claim-text>replacing, with the first new video content metadata, the displayed video content metadata on the display, upon detecting a first to occur of the one or more of preferred events, wherein the one or more preferred events are selected from a group comprising:
<claim-text>closing and then reactivating a particular application,</claim-text>
<claim-text>removing a particular user interface from the display and then returning the particular user interface to the display, and</claim-text>
<claim-text>expiration of a particular amount of time; and</claim-text>
</claim-text>
<claim-text>contacting a server to obtain new video content metadata, relating to the particular type of video content metadata, and presenting the new video content metadata for display when the information, associated with the particular type of video content metadata, has been stored in the memory for at least the second amount of time. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
