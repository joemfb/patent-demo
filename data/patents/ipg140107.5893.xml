<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627002-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627002</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11549038</doc-number>
<date>20061012</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>307</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>12</main-group>
<subgroup>08</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>711113</main-classification>
<further-classification>711E12041</further-classification>
</classification-national>
<invention-title id="d2e53">Method to increase performance of non-contiguously written sectors</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5371855</doc-number>
<kind>A</kind>
<name>Idleman et al.</name>
<date>19941200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711113</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5408644</doc-number>
<kind>A</kind>
<name>Schneider et al.</name>
<date>19950400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5860090</doc-number>
<kind>A</kind>
<name>Clark</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6334168</doc-number>
<kind>B1</kind>
<name>Islam et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6704837</doc-number>
<kind>B2</kind>
<name>Beardsley et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6785771</doc-number>
<kind>B2</kind>
<name>Ash et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7702780</doc-number>
<kind>B2</kind>
<name>Allen et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2002/0062422</doc-number>
<kind>A1</kind>
<name>Butterworth et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711114</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2002/0178331</doc-number>
<kind>A1</kind>
<name>Beardsley et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711137</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2003/0120866</doc-number>
<kind>A1</kind>
<name>Stoutamire</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711118</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2004/0250022</doc-number>
<kind>A1</kind>
<name>Jarvis et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711118</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2006/0190924</doc-number>
<kind>A1</kind>
<name>Bruening et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717104</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2007/0260846</doc-number>
<kind>A1</kind>
<name>Burton</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711216</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2008/0077762</doc-number>
<kind>A1</kind>
<name>Scott et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711170</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Xie, C. et al., &#x201c;Design and Implementation of Hierarchy Cache Using Page File,&#x201d; Wuhan University Journal of Natural Sciences, Nov. 2004, pp. 890-894, vol. 9, No. 6.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Benveniste, C.D. et al., &#x201c;Cache-Memory Interfaces in Compressed Memory Systems,&#x201d; IEEE Transactions on Computers, Nov. 2001, pp. 1106-1116, vol. 50, No. 11.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>15</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>711113</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711118</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711146</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>3</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080091875</doc-number>
<kind>A1</kind>
<date>20080417</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Mannenbach</last-name>
<first-name>David F.</first-name>
<address>
<city>Tucson</city>
<state>AZ</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Nielsen</last-name>
<first-name>Karl A.</first-name>
<address>
<city>Tucson</city>
<state>AZ</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Mannenbach</last-name>
<first-name>David F.</first-name>
<address>
<city>Tucson</city>
<state>AZ</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Nielsen</last-name>
<first-name>Karl A.</first-name>
<address>
<city>Tucson</city>
<state>AZ</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Griffiths &#x26; Seaton PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Rones</last-name>
<first-name>Charles</first-name>
<department>2186</department>
</primary-examiner>
<assistant-examiner>
<last-name>Dare</last-name>
<first-name>Ryan</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method of managing data in a cache memory storage subsystem upon a cache write operation includes determining a first number of non-contiguously written sectors on a track in the cache and comparing the first number with a second, threshold number. If the first number exceeds the second number, a full background stage operation is issued to fill the non-contiguously written sectors with unmodified data from a storage medium. A corresponding system includes a cache manager module operating on the storage subsystem. Upon a determination that a cache write operation on a track has taken place, the cache manager module determines a first number of non-contiguously written sectors on the track, compares the first number with a second, predetermined threshold number, and issues a background stage operation to fill the non-contiguously written sectors with unmodified data from a storage medium if the first number exceeds the second number.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="186.10mm" wi="128.27mm" file="US08627002-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="202.27mm" wi="143.68mm" file="US08627002-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="207.69mm" wi="179.75mm" file="US08627002-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="196.60mm" wi="193.89mm" file="US08627002-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates in general to computers, and, more particularly, to a system and method to increase performance of non-contiguously written sectors in cache storage subsystems.</p>
<p id="p-0004" num="0003">2. Description of the Prior Art</p>
<p id="p-0005" num="0004">A storage subsystem, such as the International Business Machines (IBM&#xae;) Enterprise Storage Server (ESS&#xae;), will receive Input/Output (I/O) requests directed toward an attached storage system. The attached storage system may comprise an enclosure including numerous interconnected disk drives, such as a Direct Access Storage Device (DASD), Redundant Array of Independent Disks (RAID Array), Just A Bunch of Disks (JBOD), etc. If I/O requests are received at a faster rate than they can be processed, then the storage subsystem will queue the I/O requests in a storage cache, which may comprise one or more gigabytes of volatile storage, e.g., Random Access Memory (RAM), Dynamic Random Access Memory (DRAM), etc. A copy of certain modified (write) data may also be placed in a non-volatile storage unit (NVS), such as a battery-backup volatile memory, to provide additional protection of write data in the event of a failure at the storage subsystem.</p>
<p id="p-0006" num="0005">An entry is included in a Least Recently Used (LRU) list for each track in cache. A track can be staged from the storage system for cache to return to a read request. Additionally, write data for a track may be stored in cache before being transferred to the attached storage system. When additional space in cache is needed to buffer additional requested read data and modified data, tracks indicated at the LRU end of the LRU list are destaged to disk. An entry is added to the most recently used (MRU) end of the LRU list for each track added to cache. Each entry in the LRU list comprises a control block that indicates the current status of a track, the location in cache, and the location in the storage system. An additional NVS LRU list is maintained for tracks in the NVS. The cache and NVS LRU lists include entries for tracks in both NVS and cache.</p>
<p id="p-0007" num="0006">Tracks written with &#x201c;holes&#x201d; or non-contiguously written sectors cause slow cached write performance. Holes in tracks result in cache sector misses on each write. In the worst cases, every other sector of the track becomes write modified. Destaging the tracks also results in poor disk write performance since a separate write command must be issued for each sector. On systems using RAID, the destage is further slowed down by the necessity to perform multiple drive operations for each of the single sector writes.</p>
<p id="p-0008" num="0007">In light of the foregoing, a need exists for a system and method to increase performance in the event of non-contiguously written sectors on a particular track. In addition, the system and method should take advantage of existing system resources and constraints to minimize cost and complexity while maximizing efficiency in a particular implementation.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">In one embodiment the present invention is a method of managing data in a cache memory storage subsystem upon a cache write operation comprising determining a first number of non-contiguously written sectors on a track in the cache and comparing the first number with a second, predetermined threshold number, wherein, if the first number exceeds the second number, a full background stage operation is issued to fill the non-contiguously written sectors with unmodified data from a storage medium.</p>
<p id="p-0010" num="0009">In another embodiment, the present invention is a system for managing data in a cache memory storage subsystem comprising a cache manager module operating on the storage subsystem, wherein, upon a determination that a cache write operation on a track has taken place, the cache manager module determines a fist number of non-contiguously written sectors on the track, compares the first number with a second, predetermined threshold number, and issues a background stage operation to fill the non-contiguously written sectors with unmodified data from a storage medium if the first number exceeds the second number.</p>
<p id="p-0011" num="0010">In another embodiment, the present invention is an article of manufacture including code for managing data in a cache memory storage subsystem upon a cache write operation, wherein the code is capable of causing operations to be performed, comprising: determining a first number of non-contiguously written sectors on a track in the cache, and comparing the first number with a second, predetermined threshold number, wherein, if the first number exceeds the second number, a full background stage operation is issued to fill the non-contiguously written sectors with unmodified data from a storage medium.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011">In order that the advantages of the invention will be readily understood, a more particular description of the invention briefly described above will be rendered by reference to specific embodiments that are illustrated in the appended drawings. Understanding that these drawings depict only typical embodiments of the invention and are not therefore to be considered to be limiting of its scope, the invention will be described and explained with additional specificity and detail through the use of the accompanying drawings, in which:</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a computing environment in which aspects of the invention are implemented;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> illustrates example program components used to implement cache management operations in implementations where the disks in the storage system are organized into a RAID topology; and</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an example method of managing data in a cache storage subsystem according to the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015">Some of the functional units described in this specification have been labeled as modules in order to more particularly emphasize their implementation independence. For example, a module may be implemented as a hardware circuit comprising custom VLSI circuits or gate arrays, off-the-shelf semiconductors such as logic chips, transistors, or other discrete components. A module may also be implemented in programmable hardware devices such as field programmable gate arrays, programmable array logic, programmable logic devices, or the like.</p>
<p id="p-0017" num="0016">Modules may also be implemented in software for execution by various types of processors. An identified module of executable code may, for instance, comprise one or more physical or logical blocks of computer instructions which may, for instance, be organized as an object, procedure, or function. Nevertheless, the executables of an identified module need not be physically located together, but may comprise disparate instructions stored in different locations which, when joined logically together, comprise the module and achieve the stated purpose for the module.</p>
<p id="p-0018" num="0017">Indeed, a module of executable code may be a single instruction, or many instructions, and may even be distributed over several different code segments, among different programs, and across several memory devices. Similarly, operational data may be identified and illustrated herein within modules, and may be embodied in any suitable form and organized within any suitable type of data structure. The operational data may be collected as a single data set, or may be distributed over different locations including over different storage devices, and may exist, at least partially, merely as electronic signals on a system or network.</p>
<p id="p-0019" num="0018">Reference throughout this specification to &#x201c;one embodiment,&#x201d; &#x201c;an embodiment,&#x201d; or similar language means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, appearances of the phrases &#x201c;in one embodiment,&#x201d; &#x201c;in an embodiment,&#x201d; and similar language throughout this specification may, but do not necessarily, all refer to the same embodiment.</p>
<p id="p-0020" num="0019">Reference to a signal bearing medium may take any form capable of generating a signal, causing a signal to be generated, or causing execution of a program of machine-readable instructions on a digital processing apparatus. A signal bearing medium may be embodied by a transmission line, a compact disk, digital-video disk, a magnetic tape, a Bernoulli drive, a magnetic disk, a punch card, flash memory, integrated circuits, or other digital processing apparatus memory device.</p>
<p id="p-0021" num="0020">The schematic flow chart diagrams included are generally set forth as logical flow-chart diagrams. As such, the depicted order and labeled steps are indicative of one embodiment of the presented method. Other steps and methods may be conceived that correspond in function, logic, or effect to one or more steps, or portions thereof, of the illustrated method. Additionally, the format and symbols employed are provided to explain the logical steps of the method and are understood not to limit the scope of the method. Although various arrow types and line types may be employed in the flow-chart diagrams, they are understood not to limit the scope of the corresponding method. Indeed, some arrows or other connectors may be used to indicate only the logical flow of the method. For instance, an arrow may indicate a waiting or monitoring period of unspecified duration between enumerated steps of the depicted method. Additionally, the order in which a particular method occurs may or may not strictly adhere to the order of the corresponding steps shown.</p>
<p id="p-0022" num="0021">Furthermore, the described features, structures, or characteristics of the invention may be combined in any suitable manner in one or more embodiments. In the following description, numerous specific details are provided, such as examples of programming, software modules, user selections, network transactions, database queries, database structures, hardware modules, hardware circuits, hardware chips, etc., to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize, however, that the invention may be practiced without one or more of the specific details, or with other methods, components, materials, and so forth. In other instances, well-known structures, materials, or operations are not shown or described in detail to avoid obscuring aspects of the invention.</p>
<p id="p-0023" num="0022">Turning to <figref idref="DRAWINGS">FIG. 1</figref>, a storage subsystem computing environment in which aspects of the present invention are implemented is depicted. A storage subsystem <b>2</b> receives I/O requests from hosts <b>4</b><i>a</i>, <b>4</b><i>b </i>. . . <b>4</b><i>n </i>directed to tracks in a storage system <b>6</b>, which comprises one or more hard disk drives <b>8</b><i>a</i>, <b>8</b><i>b </i>. . . <b>8</b><i>n</i>. The storage system <b>6</b> and disk drives <b>8</b><i>a</i>, <b>8</b><i>b </i>. . . <b>8</b><i>n </i>may be configured as a DASD, one or more RAID ranks, etc. The storage subsystem <b>2</b> further includes one or more central processing units (CPUs) <b>10</b><i>a</i>, <b>10</b><i>b</i>, <b>10</b><i>c </i>. . . <b>10</b><i>n</i>, a cache <b>12</b> comprising a volatile memory to store tracks, and a non-volatile storage unit REVS) <b>14</b> in which certain dirty or modified tracks in cache are buffered. The hosts <b>4</b><i>a</i>, <b>4</b><i>b </i>. . . <b>4</b><i>n </i>communicate I/O requests to the storage subsystem <b>2</b> via a network <b>16</b>, which may comprise any network known in the art, such as a Storage Area Network (SAN), Local Area Network (LAN), Wide Area Network (WAN), the Internet, an Intranet, etc. The cache <b>12</b> may be implemented in one or more volatile memory devices and the NVS <b>14</b> implemented in one or more high-speed non-volatile storage devices, such as a battery-backed-up volatile memory. A cache manager module<b>18</b> comprises either a hardware component or process executed by one of the CPUs <b>10</b><i>a</i>, <b>10</b><i>b </i>. . . <b>10</b><i>n </i>that manages the cache <b>12</b>. A stage/destage manager module <b>20</b> comprises a software or hardware component that manages stage and destage operations.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 2</figref> illustrates example program components used to implement cache management operations in implementations where the disks <b>8</b><i>a</i>, <b>8</b><i>b </i>. . . <b>8</b><i>n </i>in the storage system <b>6</b> are organized into RAID ranks. <figref idref="DRAWINGS">FIG. 2</figref> illustrates a cache LRU list <b>22</b> in which every track in cache <b>12</b> is listed, an NVS list <b>24</b> in which every track in the NVS <b>14</b> is listed, and one RAID Rank LRU list <b>26</b><i>a</i>, <b>26</b><i>b </i>. . . <b>26</b><i>n </i>for each RAID rank configured in the storage system <b>6</b>. The CPUs <b>10</b><i>a</i>, <b>10</b><i>b </i>. . . <b>10</b><i>n </i>would execute threads to perform various operations. The executing threads <b>30</b> include an LRU task thread <b>32</b> that scans the cache LRU list <b>22</b> looking for entries for modified tracks that satisfy certain criteria, such as a track in a specified RAID rank, multiple executing destage threads <b>34</b><i>a </i>and <b>34</b><i>b </i>that are called to destage a track from cache <b>12</b> to the storage system <b>6</b>, multiple executing stage threads <b>34</b><i>c </i>and background stage threads <b>34</b><i>d </i>that are called to stage a track from storage system <b>6</b> to cache <b>12</b> or execute a full background stage operation as will be later described, and other threads <b>36</b> performing any other storage subsystem <b>2</b> operation.</p>
<p id="p-0025" num="0024">In addition, <figref idref="DRAWINGS">FIG. 2</figref> illustrates a cache bit map <b>38</b>, which includes a resident portion and a modified portion <b>40</b>. Cache bit map <b>38</b> is maintained to assist in allocating file space for data in the cache. Modified portion <b>40</b> is a subset of resident portion <b>38</b>. Bit map <b>38</b> can describe the allocation of each block or sector in a tack in the cache. Modified portion <b>40</b> can be compared against resident portion <b>38</b> to determine if there are any non-contiguous sectors on a particular tack, or &#x201c;holes.&#x201d;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 3</figref> describes an example method <b>42</b> of managing data in accordance with the present invention. The method <b>42</b> begins (step <b>44</b>) by the storage subsystem querying whether a cache write operation has been completed (step <b>46</b>). The determination of whether a cache write operation has been completed can be performed by a CPU <b>10</b> or a cache manager module <b>18</b> or a similar processing component located as part of subsystem <b>2</b> or elsewhere. Cache manager module <b>18</b> essentially keeps track of the status of all tracks in cache. Cache module <b>18</b> can compare modified bit map <b>40</b> with resident bit map <b>38</b> to make a determination as to which sectors in a particular track are non-contiguous. Further, module <b>18</b> can count the number of non-contiguous instances, or holes exist in a particular track (step <b>48</b>). The number of holes can be then compared with a predetermined threshold number. In one embodiment, the predetermined threshold may be six (6) instances. If the counted number of holes exceeds the predetermined threshold (step <b>50</b>), the module <b>18</b> can issue a full background stage operation, causing unmodified data to be staged from a disk <b>8</b> or other storage medium in storage system <b>6</b> to fill in the holes (step <b>52</b>). The method <b>42</b> then begins anew.</p>
<p id="p-0027" num="0026">Reference to a &#x201c;background&#x201d; stage refers to an executing thread <b>30</b> which is run in the background or on a separate executing thread that the cache manager module <b>18</b> may be executing at a particular time. As a result of invoking a stage operation, all non-contiguous sectors in a particular track are filled with unmodified data. Because an affected track which has underwent a background stage operation has all sectors which are then filled, an entire image of data can be constructed when incorporating the particular data into a write command. The full track is essentially now in cache.</p>
<p id="p-0028" num="0027">Following a full background stage operation, the full track can be written to disk <b>8</b> or a similar storage medium with a single write command. For example, the full track can then be destaged to disk following an LRU algorithm previously described. This replaces the necessity of having to construct a single sector write command for every other modified sector in a track not subjected to the present invention.</p>
<p id="p-0029" num="0028">Again, the present invention increases host write and destage performance of modified tracks with a large number of non-contiguous sectors or holes by calculating the number of holes in the track at the completion of each cache write operation. If a large number of holes are present, a full track stage of the track is issued in the background. Following the completion of the background stage, subsequent write performance is improved because what were sector misses are now cache hits. Destage performance is also increased since the destage is now a full track write to the disks.</p>
<p id="p-0030" num="0029">At the completion of a cache write operation, a count of the number of holes in the track is calculated. If the number of holes calculated on the track is greater than a predetermined threshold, a fill track background stage is issued. Since the full track is now in cache, subsequent writes to the track are faster, since they are now cache hits. Destage performance is improved since the full track can either be grouped for a full stride write, or, if the track is destaged by itself, the track can be implemented using a full track write instead of a plurality of single sector writes.</p>
<p id="p-0031" num="0030">Software and/or hardware to implement the method previously described, such as the described full background stage, can be created using tools currently known in the art. The implementation of the described system and method involves no significant additional expenditure of resources or additional hardware than what is already in used in many storage subsystems, making the implementation cost-effective.</p>
<p id="p-0032" num="0031">Implementing and utilizing the example systems and methods as described can provide a simple, effective method of increasing performance in a computer system featuring a cache storage subsystem. While one or more embodiments of the present invention have been illustrated in detail, the skilled artisan will appreciate that modifications and adaptations to those embodiments may be made without departing from the scope of the present invention as set forth in the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for managing data in a cache of a memory storage subsystem upon receiving a cache write operation, comprising:
<claim-text>determining a first number of non-contiguously written sectors on a track of data in the cache; and</claim-text>
<claim-text>comparing the first number with a second, predetermined threshold number of non-contiguously written sectors, wherein:
<claim-text>if the first number exceeds the second number, issuing a full background stage operation to a storage medium to fill in the non-contiguously written sectors on the track of the data with unmodified data from the storage medium such that the cache includes a full track of the data, and</claim-text>
<claim-text>the unmodified data from the storage medium is data missing from the full track of the data in the cache that constitutes the non-contiguously written sectors.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further including, previous to the step of determining a first number of non-contiguously written sectors on the track of the data in the cache, detecting that the cache write operation has taken place.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further including, subsequent to the step of issuing the full background stage operation, performing a destage operation to move the full track of the data from the cache to the storage medium.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the destage operation is performed with a single write command.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the first number of non-contiguously written sectors is performed using a cache bit map that is maintained by the storage subsystem.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the cache bit map further includes a resident bit map and a modified bit map, the resident and modified bit maps compared to determine the first number of non-contiguously written sectors on the track.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A system for managing data in a cache memory storage subsystem, comprising:
<claim-text>a cache memory;</claim-text>
<claim-text>a storage medium coupled to the cache memory; and</claim-text>
<claim-text>a cache manager module coupled to the cache memory and the storage medium, wherein, upon a determination that a cache write operation on a track of data stored in the cache has taken place, the cache manager module:
<claim-text>determines a first number of non-contiguously written sectors on the track,</claim-text>
<claim-text>compares the first number with a second, predetermined threshold number of non-contiguously written sectors, and</claim-text>
<claim-text>issues a background stage operation to the storage medium to fill in the non-contiguously written sectors on the track of the data with unmodified data from the storage medium such that the cache includes a full track of the data if the first number exceeds the second number,</claim-text>
<claim-text>wherein the unmodified data from the storage medium is data missing from the full track of the data in the cache that constitutes the non-contiguously written sectors.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further including a destage manager coupled to the cache and the storage medium, the destage manager configured to perform a destage operation to move the full track of the data from the cache to the storage medium.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the destage operation is performed with a single write command.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further including a resident and modified cache bit map operating on the storage subsystem, the cache manager comparing the resident and modified bit map to determine the first number.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An non-transitory memory device including code for managing data in a cache memory storage subsystem upon a cache write operation, wherein the code is configured to cause operations to be performed comprising:
<claim-text>determining a first number of non-contiguously written sectors on a track of data in the cache; and</claim-text>
<claim-text>comparing the first number with a second, predetermined threshold number of non-contiguously written sectors, wherein:
<claim-text>if the first number exceeds the second number, issuing a full background stage operation to a storage medium to fill in the non-contiguously written sectors on the track of the data with unmodified data from the storage medium such that the cache includes a full track of the data, and</claim-text>
<claim-text>the unmodified data from the storage medium is data missing from the full track of the data in the cache that constitutes the non-contiguously written sectors.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The memory device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further including, previous to the step of determining the first number of non-contiguously written sectors on the track of the data in the cache, detecting that the cache write operation has taken place.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The memory device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further including, subsequent to the step of issuing the full background stage operation, performing a destage operation to move the full track of the data from the cache to the storage medium.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The memory device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the destage operation is performed with a single write command.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The memory device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further including comparing a resident and modified bit map to determine the first number of non-contiguously written sectors on the track, the resident and modified bit maps maintained by the storage subsystem. </claim-text>
</claim>
</claims>
</us-patent-grant>
