<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624860-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624860</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13184280</doc-number>
<date>20110715</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2010-0069123</doc-number>
<date>20100716</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>236</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>041</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345173</main-classification>
</classification-national>
<invention-title id="d2e71">Electronic device including touch screen display, interface method using the same, and computer-readable storage medium storing the same</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5856822</doc-number>
<kind>A</kind>
<name>Du et al.</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345 73</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7995030</doc-number>
<kind>B2</kind>
<name>Joung et al.</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2007/0257891</doc-number>
<kind>A1</kind>
<name>Esenther et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2009/0150775</doc-number>
<kind>A1</kind>
<name>Miyazaki et al.</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715702</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2009/0164945</doc-number>
<kind>A1</kind>
<name>Li</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2009/0309899</doc-number>
<kind>A1</kind>
<name>Tytgat</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2010/0013780</doc-number>
<kind>A1</kind>
<name>Ikeda et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2011/0164060</doc-number>
<kind>A1</kind>
<name>Miyazawa et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345660</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2011/0175830</doc-number>
<kind>A1</kind>
<name>Miyazawa et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2012/0007854</doc-number>
<kind>A1</kind>
<name>Cho</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>CN</country>
<doc-number>101127621</doc-number>
<kind>A</kind>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>CN</country>
<doc-number>101464771</doc-number>
<kind>A</kind>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>CN</country>
<doc-number>101605244</doc-number>
<kind>A</kind>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>22</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345173</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345 73</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345156</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345419</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345660</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>21</number-of-drawing-sheets>
<number-of-figures>23</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120013557</doc-number>
<kind>A1</kind>
<date>20120119</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Hyungnam</first-name>
<address>
<city>Anyang-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yoo</last-name>
<first-name>Mijun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Hyoni</first-name>
<address>
<city>Seongnam-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Uniyoung</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Cho</last-name>
<first-name>Yooseok</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Chong</last-name>
<first-name>Yuonui</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Hyungnam</first-name>
<address>
<city>Anyang-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Yoo</last-name>
<first-name>Mijun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Hyoni</first-name>
<address>
<city>Seongnam-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Uniyoung</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Cho</last-name>
<first-name>Yooseok</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Chong</last-name>
<first-name>Yuonui</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Birch, Stewart, Kolasch &#x26; Birch, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>LG Electronics Inc.</orgname>
<role>03</role>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Tzeng</last-name>
<first-name>Fred</first-name>
<department>2695</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">According to an embodiment of the present invention, an interface for controlling a display of a plurality of layers on a touch screen display includes displaying, on a touch screen display of the device, a main display layer and at least one sub display layer, detecting an object-down event at a first position within the main display layer, detecting an object-dragging event at a second position within the main display layer, and moving the main display layer along a movement direction from the first position to the second position, wherein at least one of the at least one sub display layer is displayed to be pulled to the movement direction in accordance with the movement of the main display layer.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="127.76mm" wi="133.35mm" file="US08624860-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="209.89mm" wi="152.32mm" orientation="landscape" file="US08624860-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="178.48mm" wi="140.12mm" file="US08624860-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="222.67mm" wi="123.53mm" file="US08624860-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="184.32mm" wi="138.85mm" file="US08624860-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="229.11mm" wi="120.90mm" file="US08624860-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="190.67mm" wi="99.82mm" file="US08624860-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="174.67mm" wi="140.12mm" file="US08624860-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="160.61mm" wi="142.66mm" file="US08624860-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="166.37mm" wi="142.66mm" file="US08624860-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="160.61mm" wi="101.77mm" file="US08624860-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="168.91mm" wi="127.93mm" file="US08624860-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="178.48mm" wi="140.80mm" file="US08624860-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="174.67mm" wi="127.93mm" file="US08624860-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="209.21mm" wi="110.66mm" file="US08624860-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="177.21mm" wi="137.58mm" file="US08624860-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="184.32mm" wi="134.37mm" file="US08624860-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="186.86mm" wi="137.58mm" file="US08624860-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="230.97mm" wi="120.31mm" file="US08624860-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="179.15mm" wi="143.34mm" file="US08624860-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="173.99mm" wi="144.86mm" file="US08624860-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="174.67mm" wi="127.93mm" file="US08624860-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">This application claims the benefit of the Korean Patent Application No. 10-2010-0069123, filed on Jul. 16, 2010, which is hereby incorporated by reference as if fully set forth herein.</p>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to an electronic device including a touch screen display and an interface method using the same and, more particularly, to an electronic device including a touch screen display and an interface method using the same that perform operations associated with a detected touch, when a touch is detected.</p>
<p id="p-0005" num="0004">2. Discussion of the Related Art</p>
<p id="p-0006" num="0005">Recently, the display technology depicting and displaying 3-dimensional (3D) images is being extensively researched and developed and applied in a variety of fields. Most particularly, electronic devices applying the technology of displaying 3D images so as to display 3D images, have recently been drawing a great deal of attention.</p>
<p id="p-0007" num="0006">The technology of displaying 3D images refers to a display technology using a parallax (or difference) in stereoscopic perspectives enabling a viewer to volumetrically view (or see) the displayed image due to the parallax (or difference) in both perspectives. Herein, the 3D display technology may be categorized into a shutter glass display method, a non-glasses display method, a real 3D display method, and so on. More specifically, the shutter glass display method is disadvantageous in that the viewer is required to be equipped with a separate device, such as putting on a separate pair of polarized 3D glasses. And, the non-glasses display method is disadvantageous in that the viewer can view the displayed 3D images only at a specified location. Accordingly, since diverse disadvantages exist in the shutter glass display method and the non-glasses display method, extensive development of the real 3D display method is currently in progress.</p>
<p id="p-0008" num="0007">Additionally, the recent electronic devices are being developed to have a slimmer structure in order to enable the users (or viewers) to re-position (or re-locate) their display devices with more convenience, and the recent electronic devices are being developed so as to be equipped with an input device, such as a touch pad or a touch screen, for a more convenient manipulation of the electronic device. In the recently developed electronic devices, when the touch pad or the touch screen is touched, the respective operations may be performed. Herein, such operations may correspond to selecting particular items from the display screen. Furthermore, such operations may include paging (i.e., turning pages), scrolling, panning, zooming, and so on.</p>
<p id="p-0009" num="0008">In the touch pad, the motion of an input pointer corresponds to a respective movement of the user's finger, when the user's finger moves (or slides) along the surface of the touch screen. Conversely, a touch screen corresponds to a type of display screen having a touch-sensitive transparent panel covering the display screen. When using the touch screen, (generally by using a stylus pen or his (or her) finger) the user directly points to a graphic user interface (GUI) object from the display screen, thereby selecting the corresponding GUI object.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">Accordingly, the present invention is directed to an electronic device including a touch screen display and an interface method using the same that substantially obviate one or more problems due to limitations and disadvantages of the related art.</p>
<p id="p-0011" num="0010">Another object of the present invention is to provide an electronic device including a touch screen display and an interface method using the same that cause an optical illusion of viewing a 3-dimensional image from a 2-dimensional display.</p>
<p id="p-0012" num="0011">Another object of the present invention is to provide an electronic device including a touch screen display and an interface method using the same that can enable the user to conveniently select a variety of display screens.</p>
<p id="p-0013" num="0012">Another object of the present invention is to provide an electronic device including a touch screen display and an interface method using the same that can enable the user to conveniently select a specific menu while viewing a displayed image.</p>
<p id="p-0014" num="0013">A further object of the present invention to provide a computer-readable storage medium that stores a program for executing the interface method using the electronic device including a touch screen display.</p>
<p id="p-0015" num="0014">Additional advantages, objects, and features of the invention will be set forth in part in the description which follows and in part will become apparent to those having ordinary skill in the art upon examination of the following or may be learned from practice of the invention. The objectives and other advantages of the invention may be realized and attained by the structure particularly pointed out in the written description and claims hereof as well as the appended drawings.</p>
<p id="p-0016" num="0015">To achieve these objects and other advantages and in accordance with the purpose of the invention, as embodied and broadly described herein, in an aspect of the present invention, in a method being performed by an electronic device including a touch screen display, an interface method includes the steps of includes displaying a main display layer and at least one sub display layer on the touch screen display, wherein the main display layer is positioned at a center of a display screen, and wherein the at least one sub display layer is positioned at a side of the main display layer, detecting an object-down event at a first position within the main display layer, detecting an object-dragging event at a second position within the main display layer, and moving the main display layer along a movement direction from the first position to the second position, and pulling at least one of the at least one sub display layer in accordance with the movement of the main display layer.</p>
<p id="p-0017" num="0016">Preferably, the pulled sub display layer may correspond to a sub display layer positioned in a direction opposite to the movement direction of the main display layer.</p>
<p id="p-0018" num="0017">Herein, the interface method may further include detecting an object-up event at a third position within the main display layer, and stopping the movement of the main display layer in response to detecting the object-up event.</p>
<p id="p-0019" num="0018">Preferably, the at least one sub display layer may be displayed so that the main display layer can appear to be positioned at a deeper end of the display screen.</p>
<p id="p-0020" num="0019">Preferably, the at least one sub display layer may be displayed so that a width of the at least one sub display layer can be decreased along a direction facing into the main display layer.</p>
<p id="p-0021" num="0020">Preferably, the at least one sub display layer may be respectively positioned at an upper-side, a lower-side, a left-side, and a right-side of the main display layer.</p>
<p id="p-0022" num="0021">Preferably, one of the at least one sub display layer may display a broadcast image of at least one channel.</p>
<p id="p-0023" num="0022">Preferably, one of the at least one sub display layer may display information associated with contents being displayed on the main display layer.</p>
<p id="p-0024" num="0023">Preferably, one of the at least one sub display layer may display a chat window.</p>
<p id="p-0025" num="0024">To achieve these objects and other advantages and in accordance with the purpose of the invention, as embodied and broadly described herein, in another aspect of the present invention, in a method being performed by an electronic device including a touch screen display, an interface method includes the steps of displaying a main display layer and at least one sub display layer on the touch screen display, wherein the main display layer is positioned at a center of a display screen, and wherein the at least one sub display layer is positioned at a side of the main display layer, detecting an object-down event at a first position within the at least one sub display layer, detecting an object-up event at a second position within the main display layer, and changing the sub display layer positioned at the first position and the main display layer.</p>
<p id="p-0026" num="0025">Preferably, the at least one sub display layer may be respectively positioned at an upper-side, a lower-side, a left-side, and a right-side of the main display layer.</p>
<p id="p-0027" num="0026">Preferably, one of the at least one sub display layer may display a broadcast image of at least one channel.</p>
<p id="p-0028" num="0027">Preferably, one of the at least one sub display layer may display information associated with contents being displayed on the main display layer.</p>
<p id="p-0029" num="0028">Preferably, one of the at least one sub display layer may display a chat window.</p>
<p id="p-0030" num="0029">To achieve these objects and other advantages and in accordance with the purpose of the invention, as embodied and broadly described herein, in yet another aspect of the present invention, an electronic device including a touch screen display includes a touch screen display configured to display a main display layer and at least one sub display layer on the touch screen display, wherein the main display layer is positioned at a center of a display screen, and wherein the at least one sub display layer is positioned at a side of the main display layer, and a controller is configured to detect an object-down event at a first position within the main display layer, to detect an object-dragging event at a second position within the main display layer, and to move the main display layer along a movement direction from the first position to the second position, and to pull at least one of the at least one sub display layer in accordance with the movement of the main display layer.</p>
<p id="p-0031" num="0030">Preferably, the at least one sub display layer may be displayed so that the main display layer can appear to be positioned at a deeper end of the display screen.</p>
<p id="p-0032" num="0031">Preferably, the at least one sub display layer may be displayed so that a width of the at least one sub display layer can be decreased along a direction facing into the main display layer.</p>
<p id="p-0033" num="0032">Preferably, the at least one sub display layer may be respectively positioned at an upper-side, a lower-side, a left-side, and a right-side of the main display layer.</p>
<p id="p-0034" num="0033">Preferably, one of the at least one sub display layer may display a broadcast image of at least one channel.</p>
<p id="p-0035" num="0034">Preferably, one of the at least one sub display layer may display information associated with contents being displayed on the main display layer.</p>
<p id="p-0036" num="0035">Preferably, one of the at least one sub display layer may display a chat window.</p>
<p id="p-0037" num="0036">Preferably, the pulled sub display layer may correspond to a sub display layer positioned in a direction opposite to the movement direction of the main display layer.</p>
<p id="p-0038" num="0037">Preferably, the controller detects an object-up event at a third position within the main display layer and stops the movement of the main display layer in response to detecting the object-up event.</p>
<p id="p-0039" num="0038">To achieve these objects and other advantages and in accordance with the purpose of the invention, as embodied and broadly described herein, in yet another aspect of the present invention, an electronic device including a touch screen display includes a memory configured to store at least one program, and a processor configured to execute the at least one program. Herein, the touch screen display may display a main display layer and at least one sub display layer on the touch screen display, the main display layer being positioned at a center of a display screen, and the at least one sub display layer being positioned at a side of the main display layer. Herein, the at least one program may include instructions for detecting an object-down event at a first position within the main display layer, instructions for detecting an object-dragging event at a second position within the main display layer, instructions for moving the main display layer along a movement direction from the first position to the second position, and instructions for pulling at least one of the at least one sub display layer in accordance with the movement of the main display layer.</p>
<p id="p-0040" num="0039">To achieve these objects and other advantages and in accordance with the purpose of the invention, as embodied and broadly described herein, in a further aspect of the present invention, a computer-readable storage medium having stored therein instructions, which when executed by an electronic device including a touch screen display, cause the electronic device: display a main display layer and at least one sub display layer on the touch screen display, wherein the main display layer is positioned at a center of a display screen, and wherein the at least one sub display layer is positioned at a side of the main display layer, detect an object-down event at a first position within the main display layer, detect an object-dragging event at a second position within the main display layer, and move the main display layer along a movement direction from the first position to the second position, and pull at least one of the at least one sub display layer in accordance with the movement of the main display layer.</p>
<p id="p-0041" num="0040">Since the electronic device including a touch screen display and the interface method using the same according to the present invention displays multi display layers by arranging each of the multi display layers in a volumetric layout, the present invention may provide an optical illusion of viewing a 3-dimensional (3D) display through a 2-dimensional (2D) display. Additionally, by moving and pulling display layers in accordance with the movements of a detected touch, the user may be given the impression of manipulating the electronic device through a 3D display. Furthermore, since the positions of the multi display layers can be easily changed and moved, the user may be able to conveniently select and view the wanted (or desired) screen. Finally, since the user can immediately select a wanted menu displayed on another display layer, while viewing a previously selected image, the user may be capable of selecting a wanted menu more conveniently and more quickly.</p>
<p id="p-0042" num="0041">According to an embodiment of the present invention, an interface for controlling a display of a plurality of layers on a touch screen display includes displaying, on a touch screen display of the device, a main display layer and at least one sub display layer, wherein the main display layer is positioned at a center area of the touch screen display, and wherein the at least one sub display layer is positioned at a side of the main display layer; detecting an object-down event at a first position within the main display layer; detecting an object-dragging event at a second position within the main display layer; and moving the main display layer along a movement direction from the first position to the second position, wherein at least one of the at least one sub display layer is displayed to be pulled to the movement direction in accordance with the movement of the main display layer.</p>
<p id="p-0043" num="0042">According to an embodiment of the present invention, an interface method for controlling a display of layers in a device includes displaying, on a touch screen display of the device, a plurality of layers including a main display layer and at least one sub display layer, wherein the main display layer is positioned at a center area of the touch screen display, and wherein the at least one sub display layer is positioned at a side of the main display layer, detecting an object-down event at a first position of the touch screen display within a first layer of the plurality of layers, detecting an object-up event at a second position of the touch screen display within a second layer of the plurality of layers, and changing a display state depending on locations of the first and second positions, wherein the first layer is different from the second layer.</p>
<p id="p-0044" num="0043">According to an embodiment of the present invention, an electronic device includes a touch screen display configured to display a main display layer and at least one sub display layer, wherein the main display layer is positioned at a center area of the touch screen display, and the at least one sub display layer is positioned at a side of the main display layer, and a controller configured to detect an object-down event at a first position within the main display layer, to detect an object-dragging event at a second position within the main display layer, and to move the main display layer along a movement direction from the first position to the second position, wherein at least one of the at least one sub display layer is displayed to be pulled towards the movement direction in accordance with the movement of the main display layer.</p>
<p id="p-0045" num="0044">It is to be understood that both the foregoing general description and the following detailed description of the present invention are exemplary and explanatory and are intended to provide further explanation of the invention as claimed.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0046" num="0045">The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of this application, illustrate embodiment(s) of the invention and together with the description serve to explain the principle of the invention. In the drawings:</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a block view showing a structure of an electronic device according to an embodiment of the present invention;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 2</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 2</figref><i>c </i>respectively illustrate exemplary screens each having multiple display layers displayed thereto;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 3</figref><i>c </i>respectively illustrate other exemplary screens each having multiple display layers displayed thereto;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 4</figref> illustrates process steps of an interface method moving (or re-positioning) a main display layer according to an embodiment of the present invention;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 5</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 5</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method moving (or re-positioning) the main display layer according to the embodiment of the present invention;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 6</figref> illustrates process steps of an interface method shifting a sub-display layer to a main display layer according to an embodiment of the present invention;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 7</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 7</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method shifting the sub-display layer to the main display layer according to the embodiment of the present invention;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 8</figref> illustrates process steps of an interface method shifting a main display layer to a sub-display layer according to an embodiment of the present invention;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 9</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 9</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method shifting the main display layer to the sub-display layer according to the embodiment of the present invention;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 10</figref> illustrates process steps of an interface method moving (or re-positioning) a graphic user interface (GUI) object between display layers according to an embodiment of the present invention; and</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 11</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 11</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method moving (or re-positioning) a graphic user interface (GUI) object between display layers according to the embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0058" num="0057">Reference will now be made in detail to the preferred embodiments of the present invention, examples of which are illustrated in the accompanying drawings. Wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or like parts.</p>
<p id="p-0059" num="0058">In addition, although the terms used in the present invention are selected from generally known and used terms, some of the terms mentioned in the description of the present invention have been selected by the applicant at his or her discretion, the detailed meanings of which are described in relevant parts of the description set forth herein. Furthermore, it is required that the present invention is understood, not simply by the actual terms used but by the meanings of each term lying within.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a block view showing a structure of an electronic device according to an embodiment of the present invention.</p>
<p id="p-0061" num="0060">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, the electronic device <b>100</b> according to the present invention includes a tuner <b>110</b>, demodulator <b>120</b>, a network interface <b>130</b>, a signal processor <b>140</b>, a display <b>150</b>, an audio output unit <b>160</b>, an input device <b>170</b>, a storage <b>180</b>, and a controller <b>190</b>. Herein, the electronic device <b>100</b> may correspond to a personal computer system, such as a desktop computer, a laptop computer, a tablet computer, a handheld computer, and so on. Additionally, the electronic device <b>100</b> may also corresponds to a portable device, such as a mobile phone, a smart phone, a digital broadcasting equipment (or terminal), a personal digital assistant (PDA), a portable multimedia player (PMP), a navigation system, and so on, or may correspond to a fixed electronic household appliance, such as a digital television (DTV) receiver.</p>
<p id="p-0062" num="0061">Among a plurality of radio frequency (RF) broadcast signals being received through an antenna, the tuner <b>110</b> selects an RF broadcast signal respective to a channel selected by the user (or viewer). Then, the tuner <b>110</b> converts the selected RF broadcast signal to an intermediate frequency (IF) signal or a baseband video or audio signal. For example, if the selected RS broadcast signal corresponds to a digital broadcast signal, the tuner <b>110</b> converts the selected signal to a digital IF (DIF) signal. And, if the selected RF broadcast signal corresponds to an analog signal, the tuner <b>110</b> converts the selected signal to an analog baseband video or audio signal (CVBS SIF). More specifically, the tuner <b>110</b> may process digital broadcast signals or analog broadcast signals. The analog baseband video or audio signal (CVBS SIF) outputted from the tuner <b>110</b> may be directly inputted to the signal processor <b>140</b>.</p>
<p id="p-0063" num="0062">Furthermore, the tuner <b>110</b> may also receive single-carrier RF broadcast signals according to an advanced television system committee (ATSC) method or multi-carrier RF broadcast signals according to a digital video broadcasting (DVB) method.</p>
<p id="p-0064" num="0063">According to another embodiment of the present invention, the electronic device <b>100</b> may be provided (or equipped) with at least 2 tuners. When the electronic device <b>100</b> is provided with at least 2 tuners, just as a first tuner, a second tuner selects an RF broadcast signal respective to a channel selected by the user (or viewer), among a plurality of radio frequency (RF) broadcast signals being received through an antenna, the tuner <b>110</b>. Then, the second tuner converts the selected RF broadcast signal to an intermediate frequency (IF) signal or a baseband video or audio signal.</p>
<p id="p-0065" num="0064">Additionally, among the received RF broadcast signals, the second tuner may sequentially select TS broadcast signals of all broadcast channels stored through a channel memory function, thereby converting the sequentially selected RF broadcast signals to intermediate frequency (IF) singles or baseband video or audio signals. The second tuner may periodically perform the conversion procedures of all broadcast channels. Accordingly, the electronic device <b>100</b> may display the image of the broadcast signal converted by the first tuner and may simultaneously provide images of broadcast signals respective to several broadcast channels converted by the second tuner in the form of thumbnail views. In this case, the first tuner converts the main RF broadcast signal selected by the user to an IF signal or a baseband video or audio signal. And, the second tuner may sequentially and/or periodically select all of the RF broadcast signals, with the exception for the main RF broadcast signal, thereby converting the sequentially and/or periodically selected signal to an IF signal or a baseband video or audio signal.</p>
<p id="p-0066" num="0065">The demodulator <b>120</b> receives the digital IF (DIF) signal converted by the tuner <b>110</b> so as to perform the demodulation procedure. For example, in case the digital IF signal outputted from the tuner <b>110</b> corresponds to an ATSC type signal, the demodulator <b>120</b> performs an 8-vestigial side band (8-VSB) demodulation procedure. In another example, if the signal outputted from the tuner <b>110</b> corresponds to a DVB type signal, the demodulator <b>120</b> performs a coded orthogonal frequency division modulation (COFDMA) procedure.</p>
<p id="p-0067" num="0066">Moreover, the demodulator <b>120</b> may also perform channel-decoding. In order to do so, the demodulator <b>120</b> may be provided with a trellis decoder, a deinterleaver, a Reed-Solomon (RS) decoder, and so on, so as to perform trellis decoding, deinterleaving, and Reed-Solomon (RS) decoding.</p>
<p id="p-0068" num="0067">After performing the demodulation and channel-decoding processes, the demodulator <b>120</b> may output a stream signal (TS). At this point, the stream signal may correspond to a multiplexed signal having a video signal, an audio signal, or a data signal multiplexed therein. For example, the stream signal may correspond to an MPEG-2 transport stream (TS) consisting of an MPEG-2 standard video signal multiplexed with a Dolby AC-3 standard audio signal multiplexed. More specifically, the MPEG-2 TS may include a 4-byte header and a 184-byte payload.</p>
<p id="p-0069" num="0068">The stream signal outputted from the demodulator <b>120</b> may be inputted to the signal processor <b>140</b>. The signal processor <b>140</b> performs demultiplexing and signal processing procedures on the inputted stream signal. Thereafter, the signal processor <b>140</b> outputs the video data (or video signal or image) to the display <b>150</b> and outputs the audio data (or audio signal or sound) to the audio output unit <b>160</b>.</p>
<p id="p-0070" num="0069">Furthermore, in case of a digital broadcast receiver provided with at least two tuners, the digital broadcast receiver may be provided with a number of demodulators corresponding to the number of tuners provided therein. Also, the demodulators may each be separately provided depending upon the ATSC type and the DVB type.</p>
<p id="p-0071" num="0070">The network interface <b>130</b> receives data packets that are received from a network and also transmits data packets to the network. More specifically, the network interface <b>130</b> receives IP packets that deliver broadcast data from a service provider through the network. Herein, broadcast data refer to contents, update messages notifying whether or not contents have been updated, metadata, service information data, software codes, and so on. Also, service information may include service information on real-time broadcast services and service information on internet services. Herein, internet services refer to services that can be provided via the internet, such as CoD (Content's on Demand) services, YouTube services, information services including weather forecasts, news, regional information, search services, and so on, entertainment services including games, karaoke services, and so on, and communication services including TV mailing services, TV SMS (Short Message Services), and so on. Accordingly, in the present invention, digital broadcast receivers include network TVs, web TVs, and broadband TVs. Also, broadcast services may include broadcast services being provided via groundwave (or terrestrial), satellite, and cable and may also include internet services.</p>
<p id="p-0072" num="0071">The controller <b>190</b> executes commands and performs operations associated with the electronic device <b>100</b>. For example, by using a command searched from the storage <b>180</b>, the controller <b>190</b> may control the input and output of data between the components of the electronic device <b>100</b> and may also control data reception and data processing. Herein, the controller <b>190</b> may be realized in the form of a single chip, multiple chips, or a plurality of electric assembly parts. For example, various types of architecture such as an exclusive or embedded processor, a single-purpose processor, a controller, an ASIC, and so on, may be used for the controller <b>190</b>.</p>
<p id="p-0073" num="0072">Along with an operating system, the controller <b>190</b> executes a computer code and performs operations of generating (or creating) and using data. An operating system is generally disclosed, and, therefore, a detailed description of the operating system will be omitted for simplicity. For example, the operating system may correspond to any one of a Windows OS, Unix, Linux, Palm OS, DOS, Android, and Macintosh, and so on. The operating system, another computer code, and data may exist within the storage <b>180</b>, which operates in connection to the controller <b>190</b>.</p>
<p id="p-0074" num="0073">The storage <b>180</b> generally provides a space for storing program codes and data that are used by the electronic device <b>100</b>. For example, the storage <b>180</b> may be realized in the form of a Read-Only Memory (ROM), a Random Access Memory (RAM), a hard disk drive, and so on. Program codes and data may exist in a detachable storage medium. And, when required, the program codes and data may be loaded or installed to the electronic device <b>100</b>. Herein, the detachable storage medium may include a CD-ROM, a PC-CARD, a memory card, a floppy disk, an electro-magnetic tape, a network component, and so on.</p>
<p id="p-0075" num="0074">The display <b>150</b> may operate in connected with the controller <b>190</b>. The display <b>150</b> may correspond to a liquid crystal display (LCD) (e.g., an active matrix LCD, a passive matrix LCD, and so on). In another example, the display <b>150</b> may also correspond to a monitor, such as a monochrome display, a color graphics adapter (CGA) display, an enhanced graphics adapter (EGA) display, a variable graphics-array (VGA) display, a super VGA display, a cathode ray tube (CRT), and so on. The display <b>150</b> may also correspond to a plasma display or to a display that is realized by an electronic link.</p>
<p id="p-0076" num="0075">The display <b>150</b> may display a graphic user interface (GUI) <b>153</b>, which provides an interface that can be easily and conveniently used between the user of the electronic device and the operating system, or between the user of the electronic device and an application that is currently being executed within the operating system. Herein, the GUI <b>153</b> expresses programs, files, and operation options in the form of graphic images. More specifically, a graphic image may include a window, a field, a dialog box, a menu, an icon, a button, a cursor, and a scroll bar. Such graphic images may be aligned in accordance with a pre-defined layout or may be dynamically generated (or created) in order to assist on (or help) specific measures taken by the user of the electronic device. During the operation, in order to execute functions and operations associated with various graphic images, the user may select and activate a specific graphic image. For example, the user may select a button for opening, closing, minimizing, or maximizing a window, or the user may select an icon executing (or driving) a particular program.</p>
<p id="p-0077" num="0076">The input device <b>170</b> may correspond to a touch screen positioned on the display <b>150</b> or in front of the display <b>150</b>. Herein, the touch screen may be formed as a single body with the display <b>150</b>, or the touch screen may be provided as a separate component. In case the touch screen is provided as a single body with the display <b>150</b>, the touch screen may also be referred to as the display. As the touch screen is installed in front of the display <b>150</b>, the user may directly manipulate (or maneuver) the GUI <b>153</b>. For example, the user may simply put his (or her) finger on the object that is to be controlled. In case of a touch pad, such one-to-one (1:1) correspondence cannot be provided.</p>
<p id="p-0078" num="0077">In case of using a touch pad, the touch pad is spaced apart from the display <b>150</b> and positioned in a different plane. For example, the display <b>150</b> is generally is positioned on a vertical plane, and a touch pad is generally positioned on a horizontal plane. This structure leads to a less intuitive usage of the display <b>150</b> and the touch pad. Accordingly, in comparison with the usage of a touch screen, the usage of a touch pad is more difficult and inconvenient. In addition to being configured of a touch screen, the input device <b>170</b> may also correspond to a multipoint input device.</p>
<p id="p-0079" num="0078">The controller <b>190</b> may recognize (or detect) a gesture <b>171</b> being applied to the input device <b>170</b>, thereby being capable of controlling the electronic device <b>100</b> based upon the detected gesture <b>171</b>. Herein, a gesture may be defined as a conventionalized interaction between the user and the input device <b>170</b>, wherein the gesture is mapped to at least one or more particular computing operations. More specifically, the gesture <b>171</b> may be diversely performed by the hand of the user and, more particularly, by the movements of the fingers. As an alternative to the finger movements, or in addition to the finger movements, a gesture may be performed by using a stylus pen. Hereinafter, an item that produces (or causes) the gesture <b>171</b> may be referred to as an object.</p>
<p id="p-0080" num="0079">The input device <b>170</b> receives the gesture <b>171</b>, and the controller <b>190</b> executes the commands for performing the operations associated with the gesture <b>171</b>. Furthermore, the storage <b>180</b> may include a gesture operation program <b>181</b> that may be a part of the operating system or a part of a separate application. The gesture operation program <b>181</b> generally includes a series of commands notifying at least one or more software agents of how to recognize the occurrence (or generation) of a gesture <b>171</b>, of what measure(s) to take with respect to the recognized gesture <b>171</b> and/or in response to the recognized gesture <b>171</b>.</p>
<p id="p-0081" num="0080">When the user makes one or more gestures, the input device <b>170</b> delivers the respective gesture information to the controller <b>190</b>. Then, by using a command language (or command) and, more particularly, by using the gesture operation program <b>181</b> from the storage <b>180</b>, the controller <b>190</b> interprets the gesture <b>171</b>, thereby controlling different components of the electronic device <b>100</b>, such as the storage <b>180</b>, the display <b>150</b>, the audio output unit <b>160</b>, the signal processor <b>140</b>, the network interface <b>130</b>, and the input device <b>170</b>. The gesture <b>171</b> may be identified as commands performing the operations from the application stored in the storage <b>180</b>, correcting the GUI object shown (or displayed) on the display <b>150</b>, correcting the data stored in the storage <b>180</b>, performing operations of the signal processor <b>140</b>, and so on. For example, such commands may be associated with zooming, panning, scrolling, turning pages, rotations, size adjustments, image channel changes, contents reception, internet connection, and so on. Additionally, for example, the commands may also be associated with driving (or executing) a specific program, opening a file or document, seeing a menu, selecting a menu or option, executing a command, logging-on (or signing-in) to an internet site system, authorizing access of a certified individual to a limited area within the computer system, loading a user profile associated with the alignment of icons within the wallpaper according to the user's preference, and so on.</p>
<p id="p-0082" num="0081">A wide variety of different gestures may be used. For example, a gesture may include a single point gesture or a multipoint gesture, a static or dynamic gesture, a continuous or segmented gesture, and so on. More specifically, a single point gesture corresponds to a gesture performed by a single contact point. For example, the single point gesture is performed by a single touch made by a finger or a palm of the user or by a stylus pen. A multipoint gesture corresponds to a gesture that can be made of multiple points (or contact points). For example, the multipoint gesture may be made of multiple touches, such as touches made by several fingers, one or more fingers and the palm, one or more fingers and the stylus pen, multiple stylus pens, or by a combination of at least two of the above. A static gesture corresponds to a gesture that does not include any movement. Furthermore, a continuous gesture corresponds to a gesture made of a single stroke, and a segmented gesture corresponds to a gesture consisting of a sequence of separate steps or strokes.</p>
<p id="p-0083" num="0082">Generally, the contact between the object and the touch screen a plurality of different patterns. For example, within the touch screen, the single point gesture includes an object-down event followed by an object-up event, which is performed at the same point or approximate point of the object-down event. Within the touch screen, the dynamic gesture includes an object-down event followed by at least one object-dragging event, which is then followed by an object-up event.</p>
<p id="p-0084" num="0083">According to some embodiments of the present invention, a parameter for describing processes of a finger approaching the touch screen display, the finger contacting the touch screen display, and the finger moving away from the touch screen display, is used. This parameter may correspond to at least one function among a distance between the finger and the touch screen display, a pressure of the finger touching the touch screen display, a contacting area between the finger and the touch screen display, a voltage between the finger and the touch screen display, a capacitance between the finger and the touch screen display, and other physical parameters.</p>
<p id="p-0085" num="0084">According to some embodiments of the present invention, depending upon the size of a parameter (e.g., capacitance) between the finger and the touch screen display, when this specific parameter exceeds a pre-decided threshold value, the object-down event occurs. And, while this specific parameter exceeds the pre-decided threshold value, when the position of a cursor corresponding to the position of the finger moves from point A to point B, the object-dragging event occurs. Thereafter, when the parameter falls below the pre-decided threshold value, the object-up event occurs.</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. 2</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 2</figref><i>c </i>respectively illustrate exemplary screens each having multiple display layers displayed thereto.</p>
<p id="p-0087" num="0086">Referring to <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 2</figref><i>c</i>, at least one display layers <b>210</b>, <b>211</b>, <b>212</b>, <b>213</b>, and <b>214</b> are displayed on the display screen. One display layer may correspond to one screen. Herein, an image received from one channel may be displayed, and at least one window may be displayed on one display layer. More specifically, the user selects one display layer from the plurality of display layers displayed on the screen, so that only the one selected display layer can be displayed on the screen.</p>
<p id="p-0088" num="0087">The display layer <b>210</b> positioned at the center of the display screen is referred to as a main display layer, and the display layers <b>211</b>, <b>212</b>, <b>213</b>, and <b>214</b> positioned beside the main layer are referred to as sub display layers. Herein, the sub display layers <b>211</b>, <b>212</b>, <b>213</b>, and <b>214</b> are displayed so that the main display layer can appear to be positioned at a deeper end of the screen. More specifically, the sub display layers <b>211</b>, <b>212</b>, <b>213</b>, and <b>214</b> are positioned at all sides of the main display layer so that the screen can be shown as a volumetric space. Accordingly, the main display layer can appear to be positioned at the deeper end of the display screen facing into the user.</p>
<p id="p-0089" num="0088">According to the embodiment of the present invention, the sub display layers <b>211</b>, <b>212</b>, <b>213</b>, and <b>214</b> may be displayed to face into the main display layer <b>210</b>, wherein the width of each sub display layer becomes narrower so as to display a volumetric effect. Accordingly, the user may be under the illusion of looking inside a box. Thus, the electronic device <b>100</b> may provide the user with an optical illusion of viewing a three-dimensional (3D) image.</p>
<p id="p-0090" num="0089">The sub display layer <b>211</b> located at the left-side of the main display layer <b>210</b> displays broadcast programs of multi channels. The user may select a specific broadcast program among the many broadcast programs being displayed from the sub display layer <b>211</b>, so that the selected broadcast program can be displayed on the main display layer <b>210</b>.</p>
<p id="p-0091" num="0090">The sub display layer <b>212</b> located at the upper-side of the main display layer <b>210</b> displays detailed information on the broadcast program that is being displayed.</p>
<p id="p-0092" num="0091">The sub display layer <b>213</b> located at the right-side of the main display layer <b>210</b> displays a chat window. This sub display layer <b>213</b> may display multiple chat windows, and the user may chat with another individual (or user) after selecting a specific chat window. Additionally, the user may perform operations enabling the selected chat window to be displayed in the main display layer <b>210</b>.</p>
<p id="p-0093" num="0092">The sub display layer <b>214</b> located at the bottom-side of the main display layer <b>210</b> displays information associated with contents being displayed in the main display layer <b>210</b>. According to the embodiment shown in <figref idref="DRAWINGS">FIG. 2</figref><i>b</i>, this sub display layer <b>214</b> displays player information on the player who is being displayed on the main display layer <b>210</b>.</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 3</figref><i>c </i>respectively illustrate other exemplary screens each having multiple display layers displayed thereto.</p>
<p id="p-0095" num="0094">Referring to <figref idref="DRAWINGS">FIG. 3</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 3</figref><i>c</i>, the main display layer <b>310</b> displays photo files. The user may select a specific file among the photo files being displayed on the main display layer <b>210</b>. Then, the user may enlarge the selected file and view the enlarged file.</p>
<p id="p-0096" num="0095">A sub display layer <b>311</b> displays a menu. While viewing the main display layer, the user may manipulate the menu of this sub display layer <b>311</b>, so as to allow a wanted (or desired) operation to be performed in the electronic device <b>100</b>.</p>
<p id="p-0097" num="0096">Another sub display layer <b>312</b> displays a broadcast program, and yet another sub display layer <b>313</b> displays a chat window. Furthermore, yet another sub display layer <b>314</b> displays a plurality of folders.</p>
<p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. 4</figref> illustrates process steps of an interface method moving (or re-positioning) a main display layer according to an embodiment of the present invention.</p>
<p id="p-0099" num="0098">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, the display <b>150</b> displays multi display layers (S<b>400</b>). Herein, the multi display layers may be displayed in an alignment of a main display layer and a plurality of sub display layers, as shown in <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 3</figref><i>c. </i></p>
<p id="p-0100" num="0099">The controller <b>190</b> detects an object-down event at a first position within the main display layer (S<b>410</b>).</p>
<p id="p-0101" num="0100">The controller <b>190</b> detects an object-dragging event at a second position within the main display layer (S<b>420</b>).</p>
<p id="p-0102" num="0101">The controller <b>190</b> controls the electronic device <b>100</b> so that the main display layer can be moved, thereby controlling the electronic device <b>100</b> so that the corresponding sub display layer can be pulled (S<b>430</b>). Herein, the main display layer is displayed so as to be moved in accordance with the movement of the object. More specifically, the controller <b>190</b> moves the main display layer so that a pixel being displayed at a first position of the main display layer can be moved to a second position. Then, the corresponding sub display layer is displayed so as to be pulled in accordance with the movement of the main display layer. Furthermore, the corresponding sub display layer may correspond to the sub display layer located in a direction opposite to that of the movement of the main display layer.</p>
<p id="p-0103" num="0102">Thereafter, the controller <b>190</b> detects an object-up event at a third position within the main display layer (S<b>440</b>). Herein, the object-up event may be detected from the same position as that of the object-dragging event.</p>
<p id="p-0104" num="0103">Finally, the controller <b>190</b> stops the movement of the main display layer in response to detecting the object-up event (S<b>450</b>). More specifically, the controller <b>190</b> moves the main display layer so that the pixel being displayed at a second position of the main display layer can be moved to a third position. Then, the movement of the main display layer is stopped. Furthermore, the sub display layer that is pulled in accordance with the movement of the main display layer is displayed in its pulled state.</p>
<p id="p-0105" num="0104"><figref idref="DRAWINGS">FIG. 5</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 5</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method moving (or re-positioning) the main display layer according to the embodiment of the present invention.</p>
<p id="p-0106" num="0105">Referring to <figref idref="DRAWINGS">FIG. 5</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 5</figref><i>c</i>, the controller <b>190</b> detects an object-down event at a first position <b>511</b> within the main display layer <b>510</b>. Then, the object <b>501</b> moves from the first position <b>511</b> to a second position <b>512</b>. At this point, the object <b>501</b> may move while being in contact with the touch screen display <b>500</b>, and the object <b>501</b> may move while the parameter between the object and the touch screen display exceeds a predetermined threshold value. Thereafter, when the controller <b>190</b> detects an object-dragging event at the second position <b>512</b>, the controller <b>190</b> moves the main display layer <b>510</b> along a direction of the movement from the first position <b>511</b> to the second position <b>512</b>. Thus, the sub display layer <b>520</b> is pulled in accordance with the movement of the main display layer <b>510</b>. More specifically, as one side <b>521</b> of the sub display layer <b>520</b> is fixed, and as another side <b>522</b> of the sub display layer <b>520</b> moves in accordance with the movement of the main display layer <b>510</b>, the sub display layer <b>520</b> is displayed so as to appear to be pulled.</p>
<p id="p-0107" num="0106">When the object <b>501</b> moves to a third position <b>513</b>, and when the object <b>501</b> moves away from the touch screen display <b>500</b> or when the parameter becomes smaller than the predetermined threshold value, the controller <b>190</b> detects an object-up event at the third position <b>513</b>. When the object-up event is detected, the controller <b>190</b> moves the main display layer <b>510</b> in a direction of movement from the second position <b>512</b> to the third position <b>513</b>. Thereafter, the sub display layer <b>520</b> is pulled in accordance with the movement of the main display layer <b>510</b>.</p>
<p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. 6</figref> illustrates process steps of an interface method shifting a sub-display layer to a main display layer according to an embodiment of the present invention.</p>
<p id="p-0109" num="0108">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, the display <b>150</b> displays multi display layers (S<b>600</b>). Herein, the multi display layers may be displayed in an alignment of a main display layer and a plurality of sub display layers, as shown in <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 3</figref><i>c. </i></p>
<p id="p-0110" num="0109">The controller <b>190</b> detects an object-down event at a first position within a sub display layer (S<b>610</b>).</p>
<p id="p-0111" num="0110">The controller <b>190</b> detects an object-up event at a second position within the main display layer (S<b>620</b>).</p>
<p id="p-0112" num="0111">The controller <b>190</b> changes the sub display layer located at a first position with the main display layer (S<b>630</b>). More specifically, the sub display layer located at the first position is moved to the position of the main display layer, thereby becoming the main display layer. Similarly, the main display layer is moved to the position of the sub display layer located at the first position, thereby becoming the sub display layer.</p>
<p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. 7</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 7</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method shifting the sub-display layer to the main display layer according to the embodiment of the present invention.</p>
<p id="p-0114" num="0113">Referring to <figref idref="DRAWINGS">FIG. 7</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 7</figref><i>c</i>, the controller <b>190</b> detects an object-down event at a first position <b>721</b> within the sub display layer <b>720</b>. Then, the object <b>701</b> moves from the first position <b>721</b> to a second position <b>711</b>. At this point, the object <b>701</b> may move while being in contact with the touch screen display <b>700</b>, and the object <b>701</b> may move while the parameter between the object and the touch screen display exceeds a predetermined threshold value. Thereafter, the controller <b>190</b> detects an object-up event at the second position <b>711</b> within the main display layer <b>710</b>. When the object-down event is detected at the first position <b>721</b>, and when the object-up event is detected at the second position <b>711</b>, the controller <b>190</b> changes the positions of the sub display layer <b>720</b> and the main display layer <b>710</b>. Accordingly, the sub display layer <b>720</b> becomes the main display layer.</p>
<p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. 8</figref> illustrates process steps of an interface method shifting a main display layer to a sub-display layer according to an embodiment of the present invention.</p>
<p id="p-0116" num="0115">Referring to <figref idref="DRAWINGS">FIG. 8</figref>, the display <b>150</b> displays multi display layers (S<b>800</b>). Herein, the multi display layers may be displayed in an alignment of a main display layer and a plurality of sub display layers, as shown in <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 3</figref><i>c. </i></p>
<p id="p-0117" num="0116">The controller <b>190</b> detects an object-down event at a first position within the main display layer (S<b>810</b>).</p>
<p id="p-0118" num="0117">The controller <b>190</b> detects an object-up event at a second position within a sub display layer (S<b>820</b>).</p>
<p id="p-0119" num="0118">The controller <b>190</b> calculates a difference value between the detection time of the object-down event and the detection time of the object-up event (S<b>830</b>).</p>
<p id="p-0120" num="0119">The controller <b>190</b> verifies whether or not the calculated difference value is smaller than or equal to a time value predetermined in advance (S<b>840</b>). Herein, the time value predetermined in advance may correspond to a delay time during which the object-dragging event is detected while a dynamic gesture is being performed. Alternatively, the time value predetermined in advance may correspond to a specific time decided in accordance with the user's settings, or the time value predetermined in advance may correspond to a time decided by default during the design of the program.</p>
<p id="p-0121" num="0120">When the calculated difference value is smaller than or equal to the time predetermined in advance, the controller <b>190</b> changes the main display layer and the sub display layer (S<b>850</b>). More specifically, the main display layer is moved to the position of the sub display layer located at the second position, thereby becoming the sub display layer. Similarly, the sub display layer located at the second position is moved to the position of the main display layer, thereby becoming the main display layer.</p>
<p id="p-0122" num="0121"><figref idref="DRAWINGS">FIG. 9</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 9</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method shifting the main display layer to the sub-display layer according to the embodiment of the present invention.</p>
<p id="p-0123" num="0122">Referring to <figref idref="DRAWINGS">FIG. 9</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 9</figref><i>c</i>, the controller <b>190</b> detects an object-down event at a first position <b>911</b> within the main display layer <b>910</b>. Then, the object <b>901</b> moves from the first position <b>911</b> to a second position <b>921</b>. At this point, the object <b>901</b> may move while being in contact with the touch screen display <b>900</b>, and the object <b>901</b> may move while the parameter between the object and the touch screen display exceeds a predetermined threshold value. Thereafter, the controller <b>190</b> detects an object-up event at the second position <b>921</b> within the sub display layer <b>920</b>.</p>
<p id="p-0124" num="0123">When the object-up event is detected, the controller <b>190</b> calculates a difference value between the time of occurrence of the object-down event at the first position <b>911</b> and the time of occurrence of the object-up event at the second position <b>921</b>. Thereafter, when the calculated difference value is smaller than or equal to a time value predetermined in advance, the controller <b>190</b> changes the main display layer <b>910</b> and the sub display layer <b>920</b>, as shown in <figref idref="DRAWINGS">FIG. 9</figref><i>c</i>. Accordingly, the sub display layer <b>920</b> becomes the main display layer.</p>
<p id="p-0125" num="0124"><figref idref="DRAWINGS">FIG. 10</figref> illustrates process steps of an interface method moving (or re-positioning) a graphic user interface (GUI) object between display layers according to an embodiment of the present invention.</p>
<p id="p-0126" num="0125">Referring to <figref idref="DRAWINGS">FIG. 10</figref>, the display <b>150</b> displays multi display layers (S<b>1000</b>). Herein, the multi display layers may be displayed in an alignment of a main display layer and a plurality of sub display layers, as shown in <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 3</figref><i>c. </i></p>
<p id="p-0127" num="0126">The controller <b>190</b> detects an object-down event at a first position on the touch screen display (S<b>1010</b>).</p>
<p id="p-0128" num="0127">Then, the controller <b>190</b> verifies whether or not a GUI object is displayed on the first position (S<b>1020</b>).</p>
<p id="p-0129" num="0128">when the GUI object is displayed, the controller <b>190</b> detects an object-up event at a second position on the touch screen display (S<b>1030</b>).</p>
<p id="p-0130" num="0129">The controller <b>190</b> determines whether or not the display layer of the first position and the display layer of the second position are different from one another (S<b>1040</b>).</p>
<p id="p-0131" num="0130">When the display layer of the first position and the display layer of the second position are different from one another, the controller <b>190</b> moves the GUI object to a display layer located in the second position and performs operations associated with the movement of the display layer (S<b>1050</b>). When the moved GUI object is associated with a specific content (or file), the specific content may be displayed on the display layer that has been moved. And, the corresponding content may be copied to a folder corresponding to the moved position. Furthermore, the specific content may be transmitted to a device or a device having an address corresponding to the moved position.</p>
<p id="p-0132" num="0131"><figref idref="DRAWINGS">FIG. 11</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 11</figref><i>c </i>respectively illustrate exemplary screens showing the process steps of the interface method moving (or re-positioning) a graphic user interface (GUI) object between display layers according to the embodiment of the present invention.</p>
<p id="p-0133" num="0132">Referring to <figref idref="DRAWINGS">FIG. 11</figref><i>a </i>to <figref idref="DRAWINGS">FIG. 11</figref><i>c</i>, the controller <b>190</b> detects an object-down event at the first position <b>1111</b> within the main display layer <b>1110</b>. The controller <b>190</b> verifies whether or not a display object is positioned at the first position <b>1111</b>. The presence of the display object <b>1113</b> may be verified from the screen shown in <figref idref="DRAWINGS">FIG. 11</figref><i>a</i>. Herein, the display object may correspond to a GUI object, a file object, a folder object, a picture, a channel image thumbnail screen, and so on.</p>
<p id="p-0134" num="0133">In accordance with the movement of the object <b>1101</b>, the display object <b>1110</b> is dragged, as shown in <figref idref="DRAWINGS">FIG. 11</figref><i>b</i>. Herein, the controller <b>190</b> detects the object-dragging event in accordance with the movement of the object <b>1101</b>.</p>
<p id="p-0135" num="0134">The controller <b>190</b> detects the object-up event at the second position <b>1121</b> within the sub display layer <b>1120</b>.</p>
<p id="p-0136" num="0135">When the object-up event is detected, the controller <b>190</b> positions the moved object <b>1113</b> to the second position <b>1121</b> within the sub display layer <b>1120</b> and stops the movement.</p>
<p id="p-0137" num="0136">As described above, the electronic device including a touch screen display, the interface method using the same, and the computer-readable storage medium storing the same according to the present invention have been described in detail. The present invention may be implemented as a code in the computer-readable storage medium, wherein the code can be read by the computer. The computer-readable storage medium includes all types of recording devices that are configured to store data that can be read by a computer device. Examples of the computer-readable storage media may include a ROM, a RAM, a CD-ROM, an electro-magnetic tape, a floppy disk, an optical data storage device, and so on. Furthermore, the computer-readable storage medium may also include storage media that car realized in the form of carrier waves (e.g., transmission via the Internet). Finally, the computer-readable storage medium may be dispersed to multiple computer device interconnected via network, thereby being capable of storing and executing computer-readable codes by using a dispersion method.</p>
<p id="p-0138" num="0137">It will be apparent to those skilled in the art that various modifications and variations can be made in the present invention without departing from the spirit or scope of the inventions. Thus, it is intended that the present invention covers the modifications and variations of this invention provided they come within the scope of the appended claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An interface method for controlling a display comprising a plurality of display areas in a device, the interface method comprising:
<claim-text>displaying, on a touch screen display of the device, a main display area and at least one sub display area, wherein the main display area is positioned at a center area of the touch screen display, and wherein each of the at least one sub display area is positioned at a side of the main display area;</claim-text>
<claim-text>detecting an object-down event at a first position within the main display area;</claim-text>
<claim-text>detecting an object-dragging event at a second position within the main display area; and</claim-text>
<claim-text>moving the main display area along a movement direction from the first position to the second position, wherein a sub display area of the at least one sub display area is displayed to be pulled to the movement direction in accordance with the movement of the main display area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the pulled sub display area corresponds to a sub display area positioned in a direction opposite to the movement direction of the main display area.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>detecting an object-up event at a third position within the main display area; and</claim-text>
<claim-text>terminating the movement of the main display area in response to detecting the object-up event.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sub display area is displayed so that the main display area appears to be positioned at a deeper end of the touch screen display.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sub display area is displayed so that a width of the at least one sub display area is decreased along a direction facing into the main display area.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sub display area includes a plurality of display areas respectively positioned at an upper-side, a lower-side, a left-side, and a right-side of the main display area.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein one of the at least one sub display area displays a broadcast image of at least one channel.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein one of the at least one sub display area displays information associated with contents being displayed on the main display area.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The interface method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein one of the at least one sub display area displays a chat window.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An interface method for controlling a display comprising a plurality of display areas in a device, the interface method comprising:
<claim-text>displaying, on a touch screen display of the device, the plurality of display areas including a main display area and at least one sub display area, wherein the main display area is positioned at a center area of the touch screen display, and wherein each of the at least one sub display area is positioned at a side of the main display area;</claim-text>
<claim-text>detecting an object-down event at a first position of the touch screen display within a first area of the plurality of display areas;</claim-text>
<claim-text>detecting an object-up event at a second position of the touch screen display within a second area of the plurality of display areas; and</claim-text>
<claim-text>changing a display state depending on locations of the first and second positions, wherein the first area is different from the second area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The interface method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the changing of the display state includes:
<claim-text>determining whether the object-down event at the first location is on an object of the first area; and</claim-text>
<claim-text>moving the object of the first area to the second position of the second area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The interface method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first area is the main display area and the second area is the at least one sub display area, the method further comprising:
<claim-text>changing a position of the sub display area with a position of the main display area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The interface method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first area is the at least one sub display area and the second area is the main display area, the method further comprising:
<claim-text>changing a position of the sub display area with a position of the main display area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. An electronic device, comprising:
<claim-text>a touch screen display configured to display a main display area and at least one sub display area, wherein the main display area is positioned at a center area of the touch screen display, and each of the at least one sub display area is positioned at a side of the main display area; and</claim-text>
<claim-text>a controller configured to:</claim-text>
<claim-text>detect an object-down event at a first position within the main display area,</claim-text>
<claim-text>detect an object-dragging event at a second position within the main display area, and</claim-text>
<claim-text>move the main display area along a movement direction from the first position to the second position,</claim-text>
<claim-text>wherein a sub display area of the at least one sub display area is displayed to be pulled towards the movement direction in accordance with the movement of the main display area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the at least one sub display area is displayed so that the main displayer area appears to be positioned at a deeper end of the touch screen display.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the at least one sub display area is displayed so that a width of the at least one sub display area is decreased along a direction facing into the main display area.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the at least one sub display area includes a plurality of sub display areas respectively positioned at an upper-side, a lower-side, a left-side, and a right-side of the main display area.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein one of the at least one sub display area displays a broadcast image of at least one channel.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein one of the at least one sub display area displays information associated with contents being displayed on the main display area.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein one of the at least one sub display area displays a chat window.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the pulled sub display area corresponds to a sub display area positioned in a direction opposite to the movement direction of the main display area.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The electronic device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the controller detects an object-up event at a third position within the main display area and terminates the movement of the main display area in response to detecting the object-up event. </claim-text>
</claim>
</claims>
</us-patent-grant>
