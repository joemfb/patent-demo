<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625914-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625914</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13758602</doc-number>
<date>20130204</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382233</main-classification>
<further-classification>382232</further-classification>
<further-classification>382260</further-classification>
</classification-national>
<invention-title id="d2e51">Image processing system, image processing method and program</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5454051</doc-number>
<kind>A</kind>
<name>Smith</name>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6167157</doc-number>
<kind>A</kind>
<name>Sugahara</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6222881</doc-number>
<kind>B1</kind>
<name>Walker</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7099389</doc-number>
<kind>B1</kind>
<name>Yu et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7388996</doc-number>
<kind>B2</kind>
<name>Lainema et al.</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7620261</doc-number>
<kind>B2</kind>
<name>Chiang et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7778480</doc-number>
<kind>B2</kind>
<name>Huang et al.</name>
<date>20100800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>8396307</doc-number>
<kind>B2</kind>
<name>Nakagami et al.</name>
<date>20130300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382233</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2004/0062310</doc-number>
<kind>A1</kind>
<name>Xue et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2004/0076237</doc-number>
<kind>A1</kind>
<name>Kadono et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>2001-078187</doc-number>
<kind>A</kind>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2001-224031</doc-number>
<kind>A</kind>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>JP</country>
<doc-number>2001-346207</doc-number>
<kind>A</kind>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>JP</country>
<doc-number>2003-179921</doc-number>
<kind>A</kind>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>JP</country>
<doc-number>2004-180248</doc-number>
<kind>A</kind>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>JP</country>
<doc-number>2005-033411</doc-number>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>JP</country>
<doc-number>2006-509444</doc-number>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Communicating pursuant to Article 94(3) EPC issued May 25, 2012, in the European Patent Office in corresponding European Application No. EP 06 781 551.4.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>Information Technology&#x2014;Coding of Audio-Visual Objects&#x2014;Part 10: Advance Video Coding. International Standard, Second Edition Oct. 1, 2004, pp. 149-158.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>P. List et al., &#x201c;Adaptive Deblocking Filter,&#x201d; IEEE Transactions on Circuits and Systems for Video Technology, vol. 13, No. 7, pp. 614-619 (2003).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>Supplementary European Search Report issued Feb. 15, 2011, in Munich, in corresponding EP 06 78 1551.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>Oct. 29, 2013, Extended European Search Report for related EP application No. 13184285.8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>2</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382232</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382233</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382150</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382260</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382268</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>35842601</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3484091</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348E13019</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524003</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524002</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>375 E714</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>375 E719</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11996720</doc-number>
<date>20100301</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8396307</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13758602</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130156110</doc-number>
<kind>A1</kind>
<date>20130620</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Sony Corporation</orgname>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Nakagami</last-name>
<first-name>Ohji</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Sato</last-name>
<first-name>Kazushi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Yagasaki</last-name>
<first-name>Yoichi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sherr &#x26; Jiang, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Do</last-name>
<first-name>Anh</first-name>
<department>2666</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">There is provided an image processing system and an image processing method able to suppress block distortion in the case of decoding image data encoded in unit of blocks. A controlling unit selects a filtering content to be applied to the block image data based on the encoding types of the block image data to be filtered, and a filtering unit applies filtering to the block image data to be processed according to the filtering content selected by the controlling unit.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="179.24mm" wi="253.49mm" file="US08625914-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="140.38mm" wi="179.24mm" file="US08625914-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="254.00mm" wi="193.72mm" orientation="landscape" file="US08625914-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="260.60mm" wi="163.75mm" orientation="landscape" file="US08625914-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="209.21mm" wi="201.34mm" file="US08625914-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="230.29mm" wi="162.48mm" orientation="landscape" file="US08625914-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="176.36mm" wi="172.89mm" file="US08625914-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="236.90mm" wi="174.58mm" orientation="landscape" file="US08625914-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="243.50mm" wi="172.30mm" orientation="landscape" file="US08625914-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="148.08mm" wi="106.60mm" file="US08625914-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="194.73mm" wi="177.63mm" file="US08625914-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="176.95mm" wi="185.84mm" file="US08625914-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="198.04mm" wi="188.13mm" file="US08625914-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="149.61mm" wi="149.10mm" file="US08625914-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="174.92mm" wi="173.65mm" file="US08625914-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<p id="p-0002" num="0001">This is a continuation of application Ser. No. 11/996,720, filed Mar. 1, 2010, which is incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0003" num="0002">The present invention relates to an image processing system, an image processing method, and a program, for decoding encoded image data.</p>
<heading id="h-0002" level="1">BACKGROUND ART</heading>
<p id="p-0004" num="0003">In recent years, systems (methods) based on the MPEG (Moving Picture Experts Group) and other schemes handling image data as digital and compressing the data by an orthogonal transform such as a discrete cosine transform (DCT) and motion compensation by utilizing redundancy inherent to image information for the purpose of high efficiency transfer and storage of information at that time are now spreading in both distribution of information by broadcasting stations etc. and reception of information in general homes.</p>
<p id="p-0005" num="0004">The encoding scheme called the &#x201c;H.264/AVC (Advanced Video Coding)&#x201d; which is followed the MPEG 2, 4 schemes is being proposed.</p>
<p id="p-0006" num="0005">An encoding system of the H.264/AVC applies de-block filtering to reconfigured image data in predictive encoding based on block boundary strength data Bs obtained from the image data to be encoded and a quantization parameter QP so as to generate reference image data used for the next predictive encoding. The de-block filtering is processing for suppressing block distortion occurring due to performing for example DCT processing in units of 4&#xd7;4 blocks.</p>
<p id="p-0007" num="0006">Further, the above H.264/AVO encoding system (method) adds the block boundary strength data Bs and the quantization parameter QP to the encoded data.</p>
<p id="p-0008" num="0007">The H.264/AVC decoding system applies de-block filtering to the reconfigured image data based on the block boundary strength data Bs and the quantization parameter QP added to the encoded data.</p>
<heading id="h-0003" level="1">DISCLOSER OF THE INVENTION</heading>
<heading id="h-0004" level="1">Problem to be Solved by the Invention</heading>
<p id="p-0009" num="0008">Note that even in decoding systems other than the H.264/AVC such as the MPEG 2, 4 for decoding the encoded data generated by performing orthogonal transform processing such as DOT processing in units of blocks, there are demands to perform the above de-block filtering in order to suppress block distortion.</p>
<p id="p-0010" num="0009">However, the encoded data determined to be decoded by such a decoding system does not include the above block boundary strength data Bs and quantization parameter QP. The decoding system cannot perform the de-block filtering, the block distortion remains, and the quality of the decoded image ends up falling.</p>
<p id="p-0011" num="0010">An object of the present invention is to provide an image processing system, an image processing method and a program, able to suppress block distortion even in a case of decoding an encoded image data generated in unit of blocks and to which information for defining a filtering content is not added.</p>
<heading id="h-0005" level="1">Means for Solving the Program</heading>
<p id="p-0012" num="0011">According to an embodiment of the present invention, there is provided an image processing system for decoding an encoded image data having a plurality of block encoded image data which are generated from a plurality of block image data by encoding types defined in the respective block image data, the image processing system including: a controlling unit configured to select a filtering content to be applied to the block image data based on the encoding types of the block image data to be filtered; and a filtering unit configured to apply filtering to the block image data to be processed according to the filtering content selected by the controlling unit.</p>
<p id="p-0013" num="0012">Further, according to an embodiment of the present invention, there is provided an image processing system for decoding an encoded image data having a plurality of block encoded image data which are generated from a plurality of block image data by encoding types defined in the respective block image data, the image processing system including: a controlling means for selecting a filtering content to be applied to the block image data based on the encoding types of the block image data to be filtered; and a filtering means for applying filtering to the block image data to be processed according to the filtering content selected by the controlling means.</p>
<p id="p-0014" num="0013">According to an embodiment of the present invention, there is provided an image processing system for decoding an encoded image data having a plurality of block encoded image data which are generated from a plurality of block image data by encoding types defined in the respective block image data, the image processing system including: a reversible decoding circuit configured to reversibly decode the block image data of the encoded image data to be decoded, an inverse quantization circuit configured to inversely quantize the block image data reversibly decoded by the reversible decoding circuit, an inverse orthogonal transform circuit configured to inversely orthogonal transform the block image data inversely quantized by the inverse quantization circuit, an adder circuit of generating reconfigured image data based on the block image data generated by the inverse orthogonal transform circuit and predictive image data, a controlling unit configured to select a filtering content to be applied to the block image data based on the encoding type of the block image data to be processed, and a filtering unit configured to apply filtering to the reconfigured image data generated by the adder circuit according to the filtering content selected by the controlling unit.</p>
<p id="p-0015" num="0014">Further, according to an embodiment of the present invention, there is provided an image processing system for decoding an encoded image data having a plurality of block encoded image data which are generated from a plurality of block image data by encoding types defined in the respective block image data, the image processing system including: a reversible decoding means for reversibly decoding the block image data of the encoded image data to be decoded, an inverse quantization means for inversely quantizing the block image data reversibly decoded by the reversible decoding means, an inverse orthogonal transform means for inversely orthogonal transforming the block image data inversely quantized by the inverse quantization means, an adder means for generating reconfigured image data based on the block image data generated by the inverse orthogonal transform means and predictive image data, a controlling means for selecting a filtering content to be applied to the block image data based on the encoding type of the block image data to be processed, and a filtering means for applying filtering to the reconfigured image data generated by the adder means according to the filtering content selected by the controlling means.</p>
<p id="p-0016" num="0015">According to an embodiment of the present invention, there is provided an image processing method for decoding an encoded image data having a plurality of block encoded image data which are generated from a plurality of block image data by encoding types defined in the respective block image data, the image processing method including: a first step of selecting a filtering content to be applied to the block image data based on the encoding type of the block image data to be filtered, and a second step of applying filtering to the block image data to be processed according to the filtering content selected in the first step.</p>
<p id="p-0017" num="0016">According to an embodiment of the present invention, there is provided a program to be run by a computer for decoding an encoded image data generated from a plurality of block image data by encoding types defined in the respective block image data, the program making the computer execute: a first routine of selecting a filtering content to be applied to the block image data based on the encoding type of the block image data to be filtered; and a second routine of applying filtering to the block image data to be processed according to the filtering content selected in the first routine.</p>
<heading id="h-0006" level="1">Effect of the Invention</heading>
<p id="p-0018" num="0017">According to the present invention, an image processing system, an image processing method and a program, able to suppress block distortion even in the case of decoding image data encoded in unit of blocks and to which information for defining the content of filtering is not added can be provided.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0007" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 1</figref> is a view of the configuration of a communication system of an embodiment of the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 2</figref> is a functional block diagram of a decoding system shown in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram of an AVC decoding system shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram for explaining the processing of a de-block filter shown in <figref idref="DRAWINGS">FIG. 2</figref> and <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram for explaining the processing of a de-block filter shown in <figref idref="DRAWINGS">FIG. 2</figref> and <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 6</figref> is a functional block diagram of a DEB control circuit shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram for explaining table data TABLE<b>1</b> used for acquiring parameters &#x3b1; and &#x3b2; by the DEB control circuit shown in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram for explaining table data TABLE<b>2</b> used for acquiring data Tc<b>0</b> by the DEB control circuit shown in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 9</figref> is a flow chart for explaining the processing for generation of a quantization parameter QP performed by the DEB control circuit shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 10</figref> is a flow chart for explaining the processing for generation of block boundary strength data Bs by the DEB control circuit shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 11</figref> is a flow chart continuing from <figref idref="DRAWINGS">FIG. 10</figref> for explaining the processing for generation of block boundary strength data Bs by the DEB control circuit shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 12</figref> is a flow chart continuing from <figref idref="DRAWINGS">FIG. 11</figref> for explaining the processing for generation of block boundary strength data Bs by the DEB control circuit shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 13</figref> is a diagram for explaining a first modification of the decoding system shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 14</figref> is a diagram for explaining another modification of the decoding system shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0008" level="1">LIST OF REFERENCES</heading>
<p id="p-0033" num="0000">
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0032"><b>1</b> . . . communication system, <b>2</b> . . . encoding system, <b>3</b> . . . decoding system, <b>10</b> . . . MPEG2 decoding system, <b>12</b> . . . AVC decoding system, <b>30</b> . . . storage buffer, <b>31</b> . . . reversible decoding circuit, <b>32</b> . . . inverse quantization circuit, <b>33</b> . . . inverse orthogonal transform circuit, <b>34</b> . . . adder circuit, <b>35</b> . . . flame memory, <b>36</b> . . . motion prediction/compensation circuit, <b>37</b> . . . intra-prediction circuit, <b>38</b> . . . picture rearrangement buffer, <b>39</b> . . . storage buffer, <b>41</b> . . . D/A conversion circuit, <b>47</b> . . . de-block filter, <b>50</b> . . . storage buffer, <b>51</b> . . . reversible decoding circuit, <b>52</b> . . . inverse quantization circuit, <b>53</b> . . . inverse orthogonal transform circuit, <b>54</b> . . . adder circuit, <b>55</b> . . . frame memory, <b>56</b> . . . motion prediction/compensation circuit, <b>57</b> . . . intra-prediction circuit, <b>58</b> . . . picture rearrangement buffer, <b>81</b> . . . &#x3b1;&#x2022;&#x3b2; acquisition unit, <b>82</b> . . . index calculation unit, <b>83</b> . . . tc<b>0</b> acquisition unit, <b>84</b> . . . filtering unit.</li>
    </ul>
    </li>
</ul>
</p>
<heading id="h-0009" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<heading id="h-0010" level="1">First Embodiment</heading>
<p id="p-0034" num="0033">Below, an image data communication system including an encoding system and a decoding system of an embodiment of the present invention will be explained.</p>
<p id="p-0035" num="0034">First, the relationship between the configuration of the present embodiment and the configuration of the present invention will be explained.</p>
<p id="p-0036" num="0035">A DEB control circuit <b>39</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> is an example of the controlling unit or the controlling means of the present invention, and a de-block filter <b>47</b> is an example of the filtering unit or the filtering means of the present invention.</p>
<p id="p-0037" num="0036">A macro block MB is an example of the block of the present invention, and an image data of macro block MPt is an example of the block image data of the present invention.</p>
<p id="p-0038" num="0037">Further, 4&#xd7;4 (or 8&#xd7;8) pixel block image data are one example of the sub-block image data of the present invention.</p>
<p id="p-0039" num="0038">The quantization parameter QP of the present embodiment is an example of the quantization parameter of the present invention, and a block boundary strength data Bs is an example of the block boundary strength data of the present invention.</p>
<p id="p-0040" num="0039">Further, a program PRG shown in <figref idref="DRAWINGS">FIG. 14</figref> is an example of the program of the present invention, and a memory <b>252</b> is an example of the recording medium. The recording medium may be a semiconductor memory, an optical disk, an opto-magnetic disc or a magnetic disc etc.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 1</figref> is a conceptual diagram of an image data communication system <b>1</b> of the present embodiment.</p>
<p id="p-0042" num="0041">The image data communication system <b>1</b> has an encoding system <b>2</b> provided on a transmission side and a decoding system <b>3</b> provided on a reception side of a transmission medium or a transmission path <b>5</b>.</p>
<p id="p-0043" num="0042">In the image data communication system <b>1</b>, the encoding system <b>2</b> on the transmission side generates frame image data (bit stream) compressed by an orthogonal transform such as a discrete cosine transform (DCT) or Karhunen-Loewe transform and motion compensation, modulates the frame image data, and then transmits the same via a transmission medium <b>5</b> such as an artificial satellite broadcast wave, cable TV network, telephone line network, and mobile phone line network.</p>
<p id="p-0044" num="0043">In the reception side, the received image signal is demodulated at the decoding system <b>3</b> and then the frame image data extended by the inverse transform to the orthogonal transform at the time of the modulation described above and motion compensation is generated and utilized.</p>
<p id="p-0045" num="0044">Note that the above transmission medium <b>5</b> may be a recording medium such as an optical disc, magnetic disc, and a semiconductor memory in addition to the transmission path.</p>
<p id="p-0046" num="0045">Below, the decoding system <b>3</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> will be explained.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 2</figref> is a view of the overall configuration of the decoding system <b>3</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0048" num="0047">The decoding system <b>3</b> has for example an MPEG2 decoding system <b>10</b> and AVC decoding system <b>12</b>.</p>
<p id="p-0049" num="0048">&#x3c;MPEG2 Decoding System&#x3e;</p>
<p id="p-0050" num="0049">As shown in <figref idref="DRAWINGS">FIG. 2</figref>, the MPEG2 decoding system <b>10</b> has for example a storage buffer <b>30</b>, reversible decoding circuit <b>31</b>, inverse quantization circuit <b>32</b>, inverse orthogonal transform circuit <b>33</b>, adder circuit <b>34</b>, frame memory <b>35</b>, motion prediction/compensation circuit <b>36</b>, intra-prediction circuit <b>37</b>, picture rearrangement buffer <b>38</b>, DEB control circuit <b>39</b>, and D/A conversion circuit <b>41</b>.</p>
<p id="p-0051" num="0050">The DEB control circuit <b>39</b> processes a generation of the quantization parameter QP and a generation of the block boundary strength data Bs.</p>
<p id="p-0052" num="0051">The storage buffer <b>30</b> has encoded image data S<b>9</b> encoded by the MPEG scheme input (received) from the decoding system <b>3</b> written into it.</p>
<p id="p-0053" num="0052">The reversible decoding circuit <b>31</b>, when judging that the image data of macro block MB to be processed in the image data S<b>9</b> is inter-encoded, decodes a motion vector written in its header and outputs the result to the motion prediction/compensation circuit <b>36</b>.</p>
<p id="p-0054" num="0053">The reversible decoding circuit <b>31</b>, when judging that the image data in the macro block MS to be processed in the image data S<b>9</b> is intra-encoded, decodes the intra-prediction mode information written in its header and outputs the result to the intra-prediction circuit <b>37</b>.</p>
<p id="p-0055" num="0054">Further, the reversible decoding circuit <b>31</b> decodes the encoded image data S<b>9</b> and outputs the result to the inverse quantization circuit <b>32</b>.</p>
<p id="p-0056" num="0055">Further, the reversible decoding circuit <b>31</b> outputs a quantization scale Q_SCALE of each image data in macro block MB included in the encoded image data S<b>9</b> and the MB (Macro Block) type to the DEB control circuit <b>39</b>.</p>
<p id="p-0057" num="0056">The inverse quantization circuit <b>32</b> inversely quantizes the image data (orthogonal transform coefficient) decoded at the reversible decoding circuit <b>31</b> based on the quantization scale Q_SCALE input from the reversible decoding circuit <b>31</b> and outputs the result to the inverse orthogonal transform circuit <b>33</b>.</p>
<p id="p-0058" num="0057">The inverse orthogonal transform circuit <b>33</b> applies 8&#xd7;8 pixel unit inverse orthogonal transform processing to the image data (orthogonal transform coefficient) input from the inverse quantization circuit <b>32</b> to generate a differential image data and outputs this to the adder circuit <b>34</b>.</p>
<p id="p-0059" num="0058">The adder circuit <b>34</b> adds predictive image data PI from the motion prediction/compensation circuit <b>36</b> or the intra-prediction circuit <b>37</b> and the differential image data from the inverse orthogonal transform circuit <b>33</b> to generate the image data and writes this into the frame memory <b>35</b> and the picture rearrangement buffer <b>38</b>.</p>
<p id="p-0060" num="0059">The motion prediction/compensation circuit <b>36</b> generates the predictive image data PI based on the reference image data read out from the frame memory <b>35</b> and the motion vector input from the reversible decoding circuit <b>31</b> and outputs this to the adder circuit <b>34</b>.</p>
<p id="p-0061" num="0060">The intra-prediction circuit <b>37</b> generates the predictive image data PI based on the intra-prediction mode input from the reversible decoding circuit <b>31</b> and outputs this to the adder circuit <b>34</b>.</p>
<p id="p-0062" num="0061">The picture rearrangement buffer <b>38</b> reads out the decoded image data written from the adder circuit <b>34</b> to the D/A conversion circuit <b>41</b> in the order of display after the filtering by the de-block filter <b>53</b> of the AVC decoding system <b>12</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> and <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0063" num="0062">The DEB control circuit <b>39</b> generates the block boundary strength data Bs and the quantization parameter QP based on the quantization scale Q_SCALE of each image data in macro block MB input from the reversible decoding circuit <b>31</b> and the MB type and outputs these to the de-block filter <b>53</b> of the AVC decoding system <b>12</b>.</p>
<p id="p-0064" num="0063">The processing of the DEB control circuit <b>39</b> will be explained in detail later.</p>
<p id="p-0065" num="0064">The D/A conversion circuit <b>41</b> applies D/A conversion to the image data input from the picture rearrangement buffer <b>38</b> to generate an image signal (data) S<b>10</b> and outputs this outside of the decoding system <b>3</b>.</p>
<p id="p-0066" num="0065">&#x3c;AVG Decoding System&#x3e;</p>
<p id="p-0067" num="0066">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, the AVG decoding system <b>12</b> has for example a storage buffer <b>50</b>, reversible decoding circuit <b>51</b>, inverse quantization circuit <b>52</b>, inverse orthogonal transform circuit <b>53</b>, adder circuit <b>54</b>, frame memory <b>55</b>, motion prediction/compensation circuit <b>56</b>, intra-prediction circuit <b>57</b>, picture rearrangement buffer <b>58</b>, D/A conversion circuit <b>61</b>, and de-block filter <b>47</b>.</p>
<p id="p-0068" num="0067">The storage buffer <b>50</b> has the image data S<b>13</b> encoded by the AVG scheme input (received) from the decoding system <b>3</b> written into it.</p>
<p id="p-0069" num="0068">The reversible decoding circuit <b>51</b>, when judging that the image data in the macro block MB to be processed in the image data S<b>13</b> is inter-encoded, decodes the motion vector written in its header and outputs the result to the motion prediction/compensation circuit <b>56</b>.</p>
<p id="p-0070" num="0069">The reversible decoding circuit <b>51</b>, when judging that the image data in the macro block MB to be processed in the image data S<b>13</b> is intra-encoded, decodes the intra-prediction mode information written in its header and outputs the same to the intra-prediction circuit <b>57</b>.</p>
<p id="p-0071" num="0070">Further, the reversible decoding circuit <b>51</b> decodes the image data S<b>13</b> and outputs the result to the inverse quantization circuit <b>52</b>.</p>
<p id="p-0072" num="0071">Further, the reversible decoding circuit <b>51</b> outputs the quantization parameter QP of each image data in the macro block M included in the image data S<b>13</b> and the block boundary strength data Bs to the de-block filter <b>47</b>.</p>
<p id="p-0073" num="0072">The inverse quantization circuit <b>52</b> inversely quantizes the image data (orthogonal transform coefficient) decoded at the reversible decoding circuit <b>51</b> based on the quantization parameter QP input from the reversible decoding circuit <b>31</b> and outputs the result to the inverse orthogonal transform circuit <b>53</b>.</p>
<p id="p-0074" num="0073">The inverse orthogonal transform circuit <b>53</b> applies the 4&#xd7;4 pixel unit inverse orthogonal transform processing to the image data (orthogonal transform coefficient) input from the inverse quantization circuit <b>52</b> to generate the differential image data and outputs that to the adder circuit <b>54</b>.</p>
<p id="p-0075" num="0074">The adder circuit <b>54</b> adds the predictive image data PI from the motion prediction/compensation circuit <b>56</b> or the intra-prediction circuit <b>57</b> and the differential image data from the inverse orthogonal transform circuit <b>53</b> to generate the image data and outputs this to the de-block filter <b>47</b>.</p>
<p id="p-0076" num="0075">The de-block filter <b>47</b> applies de-block filtering to the image data input from the adder circuit <b>54</b> based on the quantization parameter QP and the block boundary strength data Bs input from the inverse quantization circuit <b>52</b> and writes the processed image data into the frame memory <b>55</b> and the picture rearrangement buffer <b>38</b>.</p>
<p id="p-0077" num="0076">The motion prediction/compensation circuit <b>56</b> generates the predictive image data PI based on the reference image data read out from the frame memory <b>55</b> and the motion vector input from the reversible decoding circuit <b>51</b> and outputs this to the adder circuit <b>54</b>.</p>
<p id="p-0078" num="0077">The intra-prediction circuit <b>57</b> generates the predictive image data PI based on the intra-prediction mode input from the reversible decoding circuit <b>51</b> and outputs this to the adder circuit <b>54</b>.</p>
<p id="p-0079" num="0078">The picture rearrangement buffer <b>58</b> reads out the decoded image data written from the de-block filter <b>47</b> to the D/A conversion circuit <b>61</b> in the order of display.</p>
<p id="p-0080" num="0079">The D/A conversion circuit <b>61</b> applies D/A conversion processing to the image data input from the picture rearrangement buffer <b>58</b> to generate the image signal S<b>14</b> and outputs this outside of the decoding system <b>3</b>.</p>
<p id="p-0081" num="0080">&#x3c;De-Block Filter&#x3e;</p>
<p id="p-0082" num="0081">The de-block filter <b>47</b> applies filtering so as to reduce the block distortion included in the input image data.</p>
<p id="p-0083" num="0082">Specifically, the de-block filter <b>47</b> performs filtering in a horizontal direction and a vertical direction in units of 4&#xd7;4 block data in 16&#xd7;16 macro blocks MB as shown in <figref idref="DRAWINGS">FIG. 4</figref> based on the input quantization parameter QP and block boundary strength data Bs.</p>
<p id="p-0084" num="0083">The block boundary strength data Bs is defined as shown in <figref idref="DRAWINGS">FIG. 5</figref> by for example H.264/AVC.</p>
<p id="p-0085" num="0084">The block boundary strength data Bs is assigned the highest filter strength &#x201c;<b>4</b>&#x201d;, for example, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, in a case where either the pixel data p or q belongs to intra-encoded image data in macro blocks MB and the pixel data is located at the boundary of the macro blocks MB.</p>
<p id="p-0086" num="0085">Further, the block boundary strength data Bs is assigned the next highest filter strength to &#x201c;<b>4</b>&#x201d;, that is, &#x201c;<b>3</b>&#x201d;, for example, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, in a case where either the pixel data p or q belongs to intra-encoded image data in macro blocks MB and the pixel data is not located at the boundary of the macro blocks MB.</p>
<p id="p-0087" num="0086">Further, the block boundary strength data Bs is assigned the next highest filter strength to &#x201c;<b>3</b>&#x201d;, that is, &#x201c;<b>2</b>&#x201d;, for example, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, in a case where neither the pixel data p nor q belongs to intra-encoded image data in macro blocks MB and either pixel data has a transform coefficient.</p>
<p id="p-0088" num="0087">Further, the block boundary strength data Bs is assigned &#x201c;<b>1</b>&#x201d; for example, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, in a case where the condition that neither the pixel data p nor q belongs to intra-encoded image data in macro blocks MB and neither pixel data has a transform coefficient is satisfied and any of the conditions that the reference frames are different, the numbers of reference frames are different, and the motion vectors are different is satisfied.</p>
<p id="p-0089" num="0088">Further, the block boundary strength data Bs is assigned &#x201c;<b>0</b>&#x201d; meaning that the filtering is not carried out, for example, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, in a case where neither the pixel data p nor q belongs to intra-encoded image data in macro blocks MB, none of the pixel data has a transform coefficient, and the reference frames and the motion vectors are the same.</p>
<p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. 6</figref> is a view of the configuration of the de-block filter <b>47</b>.</p>
<p id="p-0091" num="0090">As shown in <figref idref="DRAWINGS">FIG. 6</figref>, the de-block filter <b>47</b> has for example an &#x3b1;&#x2022;&#x3b2; acquisition unit <b>81</b>, index calculation unit <b>82</b>, tc<b>0</b> acquisition unit <b>83</b>, and filtering unit <b>84</b>.</p>
<p id="p-0092" num="0091">The &#x3b1;&#x2022;&#x3b2; acquisition unit <b>81</b> acquires the data (parameters) &#x3b1; and &#x3b2; with reference to table data TABLE<b>1</b> shown in <figref idref="DRAWINGS">FIG. 7</figref> using the input quantization parameter QP as a key.</p>
<p id="p-0093" num="0092">Here, the parameters &#x3b1; and &#x3b2; are determined in value in accordance with the quantization parameter QP of each macro block as shown in <figref idref="DRAWINGS">FIG. 7</figref> by default.</p>
<p id="p-0094" num="0093">Note that the values of the parameters &#x3b1; and &#x3b2; can be adjusted by the user according to two parameters such as slice_alpha_c0_Offset_div2 and slice_beta_Offset_div2 included in the Slice header data in the image data (bit stream) to be decoded.</p>
<p id="p-0095" num="0094">The index calculation unit <b>82</b> receives as input the quantization parameter QP of the adjacent macro blocks MB(P) and MB(Q) and calculates data indexes A and B according to the following Equation (1).</p>
<p id="p-0096" num="0095">Note that, in the following Equation (1), FilterOffsetA and FilterOffsetB correspond to amounts of adjustment by the user.</p>
<p id="p-0097" num="0096">In <figref idref="DRAWINGS">FIG. 6</figref>, qPp indicates the quantization parameter QP of the macro block MB(P), and qPq indicates the quantization parameter QP of the image data in macro block MB(Q).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 1]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>gPav</i>=(<i>qPp+qPq+</i>1)&#x3e;&#x3e;1<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>index<i>A</i>=Clip3(0,51<i>,qPav</i>+FilterOffset<i>A</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>index<i>B</i>=Clip3(0,51<i>,qPav</i>+FilterOffset<i>B</i>)&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0098" num="0097">The tc<b>0</b> acquisition unit <b>83</b> acquires the data tc<b>0</b> based on the table data TABLE<b>2</b> shown in <figref idref="DRAWINGS">FIG. 8</figref> using the block boundary strength data Bs and the data indexA input from the index calculation unit <b>82</b> as the key and outputs this to the filtering unit <b>84</b>.</p>
<p id="p-0099" num="0098">The filtering unit <b>84</b> performs different filtering between a case of &#x201c;Bs&#x3c;4&#x201d; and a case of &#x201c;Bs=4&#x201d; as shown below.</p>
<p id="p-0100" num="0099">First, the case of &#x201c;Bs&#x3c;4&#x201d; will be explained.</p>
<p id="p-0101" num="0100">The filtering unit <b>84</b> performs the processing shown in the following Equation (2) to calculate the filtered pixel data p<b>0</b>&#x2032; and q<b>0</b>&#x2032;.</p>
<p id="p-0102" num="0101">In the following Equation (2), Clip3 indicates the clipping.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 2]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>0&#x2032;=Clip1(<i>p</i>0+&#x394;)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>0&#x2032;=Clip1(<i>q</i>0+&#x394;)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;=Clip3(&#x2212;<i>tc,tc</i>((((<i>q</i>0<i>&#x2212;p</i>0)&#x3c;&#x3c;2)+(<i>p</i>1<i>&#x2212;q</i>1)+4)&#x3e;&#x3e;3))&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0103" num="0102">The filtering unit <b>84</b> calculates the &#x201c;tc&#x201d; of the above Equation (2) based on the following Equation (3) when a flag chromaEdgeFlag indicates &#x201c;0&#x201d;, while calculates the same based on the following Equation (4) in a case other than the above.</p>
<p id="p-0104" num="0103">In the following Equation (3), &#x201c;( )?1:0&#x201d; indicates &#x201c;1&#x201d; when satisfying the condition in ( ) and indicates &#x201c;0&#x201d; in a case other than the above.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 3]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>tc=tc</i>0+((<i>ap</i>&#x3c;&#x3b2;)?1:0)+(<i>aq</i>&#x3c;&#x3b2;)?1:0)&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 4]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>tc=tc</i>0+1&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0105" num="0104">Further, the filtering unit <b>84</b> calculates the ap and aq of the above Equation (3) according to the following Equation (5).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 5]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>ap=|p</i>2&#x2212;<i>p</i>0<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>aq=|q</i>2<i>&#x2212;q</i>0&#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0106" num="0105">The filtering unit <b>84</b> performs the processing shown in the following Equation (6) to calculate the filtered pixel data p<b>1</b>&#x2032; when chromaEdgeFlag is 0 and ap is &#x3b2; or less and acquires the same from the following Equation (7) in a case other than the above.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 6]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>1<i>&#x2032;=p</i>1+Clip3(&#x2212;tc0<i>,tc</i>0,(<i>p</i>2+((<i>p</i>0<i>+q</i>0+1)&#x3e;&#x3e;1)&#x2212;(<i>p</i>1&#x3c;&#x3c;1))&#x3e;&#x3e;1)&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 7]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>1&#x2032;=<i>p</i>1&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0107" num="0106">The filtering unit <b>84</b> performs the processing shown in the following Equation (8) to calculate the filtered pixel data q<b>1</b>&#x2032; when chromaEdgeFlag is 0 and aq is &#x3b2; or less and acquires the same from the following Equation (9) in a case other than the above.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 8]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>1&#x2032;=<i>q</i>1+Clip3(&#x2212;<i>tc</i>0<i>,tc</i>0,(<i>q</i>2+((p0<i>+q</i>0+1)&#x3e;&#x3e;1)&#x2212;(q1&#x3c;&#x3c;1))&#x3e;&#x3e;1)&#x2003;&#x2003;(8)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 9]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>1<i>&#x2032;=q</i>1&#x2003;&#x2003;(9)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0108" num="0107">Next, the case where &#x201c;Bs=4&#x201d; will be explained.</p>
<p id="p-0109" num="0108">The filtering unit <b>84</b> calculates the pixel data p<b>0</b>&#x2032;, p<b>1</b>&#x2032;, and p<b>2</b>&#x2032; according to the following Equation (11) in the case where the flag chromaEdgeFlag indicates &#x201c;0&#x201d; and the condition of the following Equation (10) is satisfied.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 10]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>ap</i>&#x3c;&#x3b2;&#x26;&#x26;|<i>p</i>0<i>&#x2212;q</i>0|&#x3c;((&#x3b1;&#x3e;&#x3e;2)+2)&#x2003;&#x2003;(10)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 11]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>0&#x2032;=(<i>p</i>2+2&#xb7;<i>p</i>1+2&#xb7;<i>p</i>0+2<i>&#xb7;q</i>0<i>+q</i>1+4)&#x3e;&#x3e;3<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>1&#x2032;=(<i>p</i>2+<i>p</i>1<i>+p</i>0<i>+q</i>0+2)&#x3e;&#x3e;2<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>2&#x2032;=(2&#xb7;<i>p</i>3+3<i>+p</i>2+<i>p</i>1<i>+p</i>0+<i>q</i>0+4)&#x3e;&#x3e;3&#x2003;&#x2003;(11)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0110" num="0109">The filtering unit <b>84</b> calculates the pixel data p<b>0</b>&#x2032;, p<b>1</b>&#x2032;, and p<b>2</b>&#xb0; according to the following Equation (12) in the case where the flag chromaEdgeFlag indicates &#x201c;<b>0</b>&#x201d; and the condition of the following Equation (10) is not satisfied.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 12]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>0&#x2032;=(2&#xb7;<i>p</i>1<i>+p</i>0<i>+q</i>1+2)&#x3e;&#x3e;2<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>1<i>&#x2032;=p</i>1<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>2<i>&#x2032;=p</i>2&#x2003;&#x2003;(12)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0111" num="0110">The filtering unit <b>84</b> calculates the pixel data q<b>0</b>&#x2032;, q<b>1</b>&#x2032;, and q<b>2</b>&#x2032; in accordance with the following equation (14) in the case where the flag chromaEdgeFlag indicates &#x201c;<b>0</b>&#x201d; and the condition of the following Equation (13) is satisfied.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 13]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>aq&#x3c;B</i>&#x26;&#x26;|<i>p</i>0<i>&#x2212;q</i>0|&#x3c;((&#x3b1;&#x3e;&#x3e;2)+2)&#x2003;&#x2003;(13)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 14]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>0&#x2032;=(<i>p</i>1+2&#xb7;<i>p</i>0+2&#xb7;<i>q</i>0+2&#xb7;<i>q</i>1<i>+q</i>2+4)&#x3e;&#x3e;3<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>1&#x2032;=(<i>p</i>0<i>+q</i>0<i>+q</i>1<i>+q</i>2+2)&#x3e;&#x3e;2<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>2&#x2032;=(2&#xb7;<i>q</i>3+3&#xb7;<i>q</i>2<i>+q</i>1<i>+q</i>0<i>+p</i>4+4)&#x3e;&#x3e;3&#x2003;&#x2003;(14)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0112" num="0111">The filtering unit <b>84</b> calculates the pixel data q<b>0</b>&#x2032;, q<b>1</b>&#x2032;, and q<b>2</b>&#x2032; in accordance with the following equation (15) in the case where the flag chromaEdgeFlag indicates &#x201c;<b>0</b>&#x201d; and the condition of the following Equation (10) is not satisfied.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 15]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>0&#x2032;=(2<i>&#xb7;q</i>1<i>+q</i>0<i>+p</i>1+2)&#x3e;&#x3e;2<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>q</i>1<i>&#x2032;=q</i>1<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>g</i>2<i>&#x2032;=g</i>2&#x2003;&#x2003;(15)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0113" num="0112">[DEB Control Circuit]</p>
<p id="p-0114" num="0113">Below, the processing of the DEB control circuit <b>39</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> will be explained in detail.</p>
<p id="p-0115" num="0114">The DEB control circuit <b>39</b> performs processing for generation of the quantization parameter QP and processing for generation of the block boundary strength data Bs as shown below.</p>
<p id="p-0116" num="0115">First, the processing for generation of the quantization parameter QP by the DEB control circuit <b>39</b> will be explained.</p>
<p id="p-0117" num="0116"><figref idref="DRAWINGS">FIG. 9</figref> is a flow chart for explaining the processing for generation of the quantization parameter QP performed by the DEB control circuit <b>39</b> shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0118" num="0117">Step ST<b>11</b>:</p>
<p id="p-0119" num="0118">As previously explained, the DEB control circuit <b>39</b> receives as input the quantization scale Q_SCALE of each image data in macro block ME included in the MPEG 2 scheme image data <b>59</b> from the reversible decoding circuit <b>39</b>.</p>
<p id="p-0120" num="0119">Step ST<b>12</b>:</p>
<p id="p-0121" num="0120">The DEB control circuit <b>39</b> specifies the quantization parameter QP corresponding to the quantization scale Q_scale input at step ST<b>11</b>.</p>
<p id="p-0122" num="0121">The following Equation (16) stands between the H.264/AVC quantization parameter QP (range: 0 to 31) and the MPEG2 quantization scale Q_SCALE.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 16]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Q</i>_SCALE=2<sup>20</sup>/(676&#xd7;<i>A</i>(<i>QP</i>))&#x2003;&#x2003;(16)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0123" num="0122">A(QP) in the above Equation (16) is defined as in the following Equation (17) for each of QP=0 to 31.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 17]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i>(<i>QP=</i>0, . . . ,31)=[620, 553, 492, 439, 391, 348, 310, 276, 246, 219, 195, 174, 155, 138, 123, 110, 98, 87, 78, 69, 62, 55, 49, 44, 39, 35, 31, 27, 24, 22, 19, 17]&#x2003;&#x2003;(17)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0124" num="0123">From the above Equations (16) and (17), the relationships of the following Equation (18) stand.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 18]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Q</i>_SCALE(<i>QP=</i>0,31)=[2.5019, 2.8050, 3.1527, 3.5334, 3,9671, 4.4573, 5.0037, 5.6201, 6.3055, 7.0829, 7.9546, 8.9146, 10.0074, 11.2402, 12.6110, 14.1013, 15.8280, 17.8293, 19.8865, 22.4804, 25.0185, 28.2027, 31.6561, 35.2534, 39.7730, 44.3185, 50.0370, 57.4499, 64.6312, 70.5067, 81.6394, 91.2440]&#x2003;&#x2003;(18)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0125" num="0124">The DEB control circuit <b>39</b> uses the table data defining the relationships shown in the above Equation (18) using the input quantization scale Q_SCALE as a key and acquires the quantization parameter QP corresponding to that.</p>
<p id="p-0126" num="0125">Next, the range of the quantization parameter QP explained above is 0 to 31, and the range of the quantization parameter QP defined by H.264/AVC is 0 to 51, therefore a new quantization parameter QP is calculated according to the following Equation (19). This is output to the de-block filter <b>47</b>.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>[Equation 19]<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>QP=QP+</i>12&#x2003;&#x2003;(19)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0127" num="0126">Next, the processing for generation of the block boundary strength data Bs by the DEB control circuit <b>39</b> will be explained.</p>
<p id="p-0128" num="0127"><figref idref="DRAWINGS">FIG. 10</figref> to <figref idref="DRAWINGS">FIG. 12</figref> are flow charts for explaining the processing for generation of the block boundary strength data Bs by the DEB control circuit <b>39</b>.</p>
<p id="p-0129" num="0128">Step ST<b>21</b>:</p>
<p id="p-0130" num="0129">The DEB control circuit <b>39</b> receives as input the MB type (MB type designation data) of the image data in macro block MB to be processed of the MPEG scheme image data S<b>9</b> from the reversible decoding circuit <b>31</b>.</p>
<p id="p-0131" num="0130">Step ST<b>22</b>:</p>
<p id="p-0132" num="0131">The DEB control circuit <b>39</b> proceeds to step ST<b>23</b> when judging that the MB type input at step ST<b>21</b> is &#x201c;Intra&#x201d; or &#x201c;Intra+Q&#x201d;, while proceeds to step ST<b>24</b> when not judging so.</p>
<p id="p-0133" num="0132">Here, &#x201c;Intra&#x201d; indicates that the image data in macro block MB is intra-encoded.</p>
<p id="p-0134" num="0133">Further, &#x201c;Intra+Q&#x201d; indicates that the image data in macro block MB is intra-encoded, and there is a quantization updating step.</p>
<p id="p-0135" num="0134">&#x201c;Intra&#x201d; and &#x201c;Intra+Q&#x201d; of MPEG2 correspond to &#x201c;Intra&#x201d; of the H.264/AVC.</p>
<p id="p-0136" num="0135">Step ST<b>23</b></p>
<p id="p-0137" num="0136">The DEB control circuit <b>39</b> sets &#x201c;<b>4</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d; and sets &#x201c;<b>3</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>2</b>&#x201d;.</p>
<p id="p-0138" num="0137">Thereafter, the DEB control circuit <b>39</b> proceeds to step ST<b>35</b> shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0139" num="0138">Step ST<b>24</b>:</p>
<p id="p-0140" num="0139">The DEB control circuit <b>39</b> proceeds to step ST<b>25</b> when judging that the MB type input at step ST<b>21</b> is &#x201c;MC+Coded&#x201d;, &#x201c;MC+Coded+Q&#x201d;, &#x201c;NotMC+Coded&#x201d;, or &#x201c;NotM+Coded+Q&#x201d;, while proceeds to step ST<b>26</b> when not judging so.</p>
<p id="p-0141" num="0140">Here, &#x201c;MC+Coded&#x201d; means that the inter-prediction coding (motion prediction/compensation) is required, that is, inter-prediction coding was carried out. &#x201c;MC+Coded+Q&#x201d; means that the inter-prediction coding was carried out and conversion of the quantization value was carried out.</p>
<p id="p-0142" num="0141">&#x201c;NotMC+Coded&#x201d; means that motion compensation was not carried out, but only decoding of the DCT coefficient was carried out. &#x201c;NotMC+Coded&#x201d; means that motion compensation was not carried out, but conversion of the quantization value was carried out.</p>
<p id="p-0143" num="0142">&#x201c;MC+Coded&#x201d; and &#x201c;MC+Coded+Q&#x201d; of MPEG2 correspond to &#x201c;Inter16&#xd7;16&#x201d; of H.264/AVC.</p>
<p id="p-0144" num="0143">&#x201c;NotMC+Coded&#x201d; and &#x201c;NotMC+Coded+Q&#x201d; correspond to &#x201c;Direct16&#xd7;16&#x201d; of H.264/AVC.</p>
<p id="p-0145" num="0144">Step ST<b>25</b>:</p>
<p id="p-0146" num="0145">The DEB control circuit <b>39</b> sets &#x201c;<b>2</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d; and Bs &#x201c;<b>2</b>&#x201d;.</p>
<p id="p-0147" num="0146">Thereafter, the DEB control circuit <b>39</b> proceeds to step ST<b>35</b> shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0148" num="0147">Step ST<b>26</b>:</p>
<p id="p-0149" num="0148">The DEB control circuit <b>39</b> proceeds to step ST<b>27</b> when judging that the MB type input at step ST<b>21</b> is &#x201c;MC+Not Coded&#x201d;, while proceeds to step ST<b>30</b> when not judging so.</p>
<p id="p-0150" num="0149">Here, &#x201c;MC+Not Coded&#x201d; means that motion compensation is carried out, but the decoding of the DCT coefficient is not carried out.</p>
<p id="p-0151" num="0150">&#x201c;MC+Not Coded&#x201d; of MPEG2 corresponds to &#x201c;Inter16&#xd7;16&#x201d; of H.264/AVC.</p>
<p id="p-0152" num="0151">Step ST<b>27</b>:</p>
<p id="p-0153" num="0152">The DEB control circuit <b>39</b> proceeds to step ST<b>28</b> when judging that the image data in the macro block MB adjacent to the image data in the macro block MB to be processed has a valid orthogonal transform coefficient (DCT coefficient), while proceeds to step ST<b>29</b> when not judging so.</p>
<p id="p-0154" num="0153">Step ST<b>28</b>:</p>
<p id="p-0155" num="0154">The DEB control circuit <b>39</b> sets &#x201c;<b>2</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d;.</p>
<p id="p-0156" num="0155">At this time, the DEB control circuit <b>39</b> sets &#x201c;<b>0</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>2</b>&#x201d;.</p>
<p id="p-0157" num="0156">Thereafter, the DEB control circuit <b>39</b> proceeds to step ST<b>35</b> shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0158" num="0157">Step ST<b>29</b>:</p>
<p id="p-0159" num="0158">The DEB control circuit <b>39</b> sets &#x201c;<b>0</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d; and Bs &#x201c;<b>2</b>&#x201d;.</p>
<p id="p-0160" num="0159">Thereafter, the DEB control circuit <b>39</b> proceeds to step ST<b>35</b> shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0161" num="0160">Step ST<b>30</b></p>
<p id="p-0162" num="0161">When step ST<b>30</b> is reached, the MB type is &#x201c;Skip&#x201d;.</p>
<p id="p-0163" num="0162">Here, &#x201c;Skip&#x201d; means that the motion vector is not encoded.</p>
<p id="p-0164" num="0163">In MPEG2, the processing is different according to a P picture or a B picture.</p>
<p id="p-0165" num="0164">&#x201c;Skip&#x201d; of MPEG2 in a P picture corresponds to &#x201c;Temporal Direct16&#xd7;16&#x201d; of H.264/AVC.</p>
<p id="p-0166" num="0165">&#x201c;Skip&#x201d; of MPEG2 in a B picture corresponds to &#x201c;Spatial Direct16&#xd7;16&#x201d; of H.264/AVC.</p>
<p id="p-0167" num="0166">The DEB control circuit <b>39</b> proceeds to step ST<b>31</b> when judging that the present picture type is a P picture, while proceeds to step ST<b>32</b> when not judging so.</p>
<p id="p-0168" num="0167">Step ST<b>31</b>:</p>
<p id="p-0169" num="0168">The DEB control circuit <b>39</b> sets &#x201c;<b>0</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d; and Bs &#x201c;2&#x201d;.</p>
<p id="p-0170" num="0169">Thereafter, the DEB control circuit <b>39</b> proceeds to step ST<b>35</b> shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0171" num="0170">Step ST<b>32</b></p>
<p id="p-0172" num="0171">The DEB control circuit <b>39</b> proceeds to step ST<b>33</b> when judging that the image data in the macro block MB adjacent to the image data in the macro block MB to be processed has a valid orthogonal transform coefficient (DCT coefficient), while proceeds to step ST<b>34</b> when not judging so.</p>
<p id="p-0173" num="0172">Step ST<b>33</b>:</p>
<p id="p-0174" num="0173">The DEB control circuit <b>39</b> sets &#x201c;<b>2</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d;.</p>
<p id="p-0175" num="0174">At this time, the DEB control circuit <b>39</b> sets &#x201c;<b>0</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>2</b>&#x201d;.</p>
<p id="p-0176" num="0175">Thereafter, the DEB control circuit <b>39</b> proceeds to step ST<b>35</b> shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0177" num="0176">Step ST<b>34</b>:</p>
<p id="p-0178" num="0177">The DEB control circuit <b>39</b> sets &#x201c;<b>0</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d; and Bs &#x201c;<b>2</b>&#x201d;.</p>
<p id="p-0179" num="0178">Thereafter, the DEB control circuit <b>39</b> proceeds to step ST<b>35</b> shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0180" num="0179">Step ST<b>35</b>:</p>
<p id="p-0181" num="0180">The DEB control circuit <b>39</b> sets &#x201c;<b>0</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>1</b>&#x201d; and &#x201c;<b>3</b>&#x201d;.</p>
<p id="p-0182" num="0181">Below, an example of the operation of the decoding system <b>3</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> will be explained.</p>
<p id="p-0183" num="0182">Here, a case where MPEG2 scheme encoded image data S<b>9</b> is decoded will be explained.</p>
<p id="p-0184" num="0183">The encoded image data S<b>9</b> is stored in the storage buffer <b>30</b>, and then output to the reversible decoding circuit <b>31</b>.</p>
<p id="p-0185" num="0184">Next, when judging that the image data in the macro block MB to be processed in the image data S<b>9</b> is inter-encoded, the reversible decoding circuit <b>31</b> decodes the motion vector written in its header and outputs the result to the motion prediction/compensation circuit <b>36</b>.</p>
<p id="p-0186" num="0185">Further, when judging that the image data in the macro block MB to be processed in the image data S<b>9</b> is intra-encoded, the reversible decoding circuit <b>31</b> decodes the intra-prediction mode information written in its header and outputs the result to the intra-prediction circuit <b>37</b>.</p>
<p id="p-0187" num="0186">Further, the reversible decoding circuit <b>31</b> decodes the image data S<b>9</b> and outputs the result to the inverse quantization circuit <b>32</b>.</p>
<p id="p-0188" num="0187">Further, the reversible decoding circuit <b>31</b> outputs the quantization scale Q_SCALE of each image data in macro block MB included in the image data S<b>9</b> and the MB type to the DEB control circuit <b>39</b>.</p>
<p id="p-0189" num="0188">Next, the inverse quantization circuit <b>32</b> inversely quantizes the image data (orthogonal transform coefficient) decoded at the reversible decoding circuit <b>31</b> based on the quantization scale Q_SCALE input from the reversible decoding circuit <b>31</b> and outputs the result to the inverse orthogonal transform circuit <b>33</b>.</p>
<p id="p-0190" num="0189">Next, the inverse orthogonal transform circuit <b>33</b> applies the 8&#xd7;8-pixel unit inverse orthogonal transform processing to the image data (orthogonal transform coefficient) input from the inverse quantization circuit <b>33</b> to generate the differential image data and outputs that to the adder circuit <b>34</b>.</p>
<p id="p-0191" num="0190">Next, the adder circuit <b>34</b> adds the predictive image data PI from the motion prediction/compensation circuit <b>36</b> or the intra-prediction circuit <b>37</b> and the differential image data from the inverse orthogonal transform circuit <b>33</b> to generate the image data and writes this into the frame memory <b>35</b> and the picture rearrangement buffer <b>38</b>.</p>
<p id="p-0192" num="0191">In parallel to the above processing, the DEB control circuit <b>39</b> performs the processing shown in <figref idref="DRAWINGS">FIG. 9</figref> and outputs the quantization parameter QP to the de-block filter <b>47</b>.</p>
<p id="p-0193" num="0192">Further, the DEB control circuit <b>39</b> performs the processing shown in <figref idref="DRAWINGS">FIG. 10</figref> to <figref idref="DRAWINGS">FIG. 12</figref> and outputs the block boundary strength data Bs to the de-block filter <b>47</b>.</p>
<p id="p-0194" num="0193">Then, the de-block filter <b>47</b> applies the de-block filtering to the image data stored in the picture rearrangement buffer <b>38</b> based on the quantization parameter QP and the block boundary strength data Bs input from the DEB control circuit <b>39</b>.</p>
<p id="p-0195" num="0194">Thereafter, the image data is read out to the reversible decoding circuit <b>31</b> in the sequence of display and converted to the image signal S<b>10</b>.</p>
<p id="p-0196" num="0195">On the other hand, when the H.264/AVC scheme encoded image data S<b>13</b> is decoded, the AVC decoding system <b>12</b> decodes the image data S<b>13</b> in the same way as the general AVG decoding system and outputs the image signal S<b>14</b>.</p>
<p id="p-0197" num="0196">As explained above, according to the decoding system <b>3</b>, the de-block filtering by the de-block filter <b>47</b> can be applied to the MPEG2 scheme encoded image data S<b>9</b>, so the decoded high quality image signal S<b>10</b> having the block distortion suppressed can be generated.</p>
<p id="p-0198" num="0197">Further, according to the decoding system <b>3</b>, the de-block filter <b>47</b> of the AVC decoding system <b>12</b> is utilized in the MPEG2 decoding system <b>10</b>, therefore an increase in size of the system can be avoided.</p>
<heading id="h-0011" level="1">Second Embodiment</heading>
<p id="p-0199" num="0198">In the present embodiment, the MPEG2 decoding system <b>10</b> performs the following processing when the input image data S<b>9</b> is an interlace signal.</p>
<p id="p-0200" num="0199">In the MPEG2, for an interlace signal, field prediction and dual prime prediction are used in addition to the frame prediction, while for a residual signal, a frame DCT and a field DCT are used. Due to this, block distortion different from the frame signal may appear.</p>
<p id="p-0201" num="0200">When the DCT processing is carried out with the field signal in the encoding system and the image data in the macro block MB to be processed of the image data S<b>9</b> has a frame structure, as shown in <figref idref="DRAWINGS">FIG. 13</figref>, the MPEG2 decoding system <b>10</b> transforms the image data S<b>9</b> to the field structure, then performs the de-block filtering. Here, the image data in the macro block MB to be processed is converted to a field structure and becomes a block consisting of 16&#xd7;8 pixels.</p>
<p id="p-0202" num="0201">Then, the DEB control circuit <b>39</b> of the MPEG2 decoding system <b>10</b> sets the same value as the block boundary strength data Bs &#x201c;<b>0</b>&#x201d; and &#x201c;<b>2</b>&#x201d; explained in the first embodiment for the block boundary strength data Bs &#x201c;<b>1</b>&#x201d; and) &#x201c;<b>3</b>&#x201d;.</p>
<p id="p-0203" num="0202">Due to this, the de-block filtering can be applied using a block actually subjected to the DCT processing as a reference.</p>
<heading id="h-0012" level="1">Third Embodiment</heading>
<p id="p-0204" num="0203">In the present embodiment, the method of setting the block boundary strength data as according to the difference of DCT type will be explained.</p>
<p id="p-0205" num="0204">In the MPEG2, the frame DCT and field DCT can be selected for each macro block MB.</p>
<p id="p-0206" num="0205">Here, where two image date in macro blocks MB adjacent in the horizontal direction are different DCT types, the possibility of occurrence of block distortion is high. In general, an encoding system of the MPEG2 selects a frame DCT for parts with a high time correlation and selects a field DCT for parts where motion occurs between fields. This is because it is predicted that image date in adjacent macro blocks MB will differ in the properties of the images.</p>
<p id="p-0207" num="0206">For this reason, in the present modification, the DEB control circuit <b>39</b> sets for example &#x201c;<b>3</b>&#x201d; for the block boundary strength data Bs &#x201c;<b>0</b>&#x201d; in the horizontal direction when the DCT type is different between the image date in the macro block MB to be de-block filtered and the image date in the macro block MB adjacent to that in the horizontal direction. Namely, the DEB control circuit <b>39</b> performs control so as to apply a strong de-block filtering to the boundary portion in the case where the DCT type is different between the image date in the macro block MB to be de-block filtered and the image date in the macro block MB adjacent to that in the horizontal direction in comparison with the case where the DCT types are the same.</p>
<p id="p-0208" num="0207">The present invention is not limited to the above embodiments.</p>
<p id="p-0209" num="0208">Namely, it should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p>
<p id="p-0210" num="0209">For example, all or part of the functions of the decoding system <b>3</b> explained above can be executed by a processing circuit <b>253</b> such as a CPU (Central Processing Unit) according to the programming of the program PRG stored in a memory <b>252</b> as shown in <figref idref="DRAWINGS">FIG. 13</figref>.</p>
<p id="p-0211" num="0210">In this case, an interface <b>251</b> is used for the input of the image data to be decoded and the output of the processing result thereof.</p>
<p id="p-0212" num="0211">Further, in the above example, the case using MPEG-2 as the input was explained, but the present invention is not limited to this in scope. The present invention can also be applied to a general image encoding scheme represented by JPEG, MPEG, and H.26x utilizing an orthogonal transform such as a discrete cosine transform.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing system for decoding an encoded image data having a plurality of block encoded image data which are generated from a plurality of block image data by encoding types defined in the respective block image data, said image processing system comprising:
<claim-text>a controlling unit configured to select a filtering method to be applied to the block image data based on said encoding types of the block image data to be filtered; and</claim-text>
<claim-text>a filtering unit configured to apply filtering to said block image data to be processed according to said filtering method selected by said controlling unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. An image processing method of decoding an encoded image data having a plurality of block encoded image data which are generated from a plurality of block image data by encoding types defined in the respective block image data, said image processing method including:
<claim-text>a first step of selecting a filtering method to be applied to the block image data based on said encoding type of the block image data to be filtered; and</claim-text>
<claim-text>a second step of applying filtering to said block image data to be processed according to said filtering method selected in said first step. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
