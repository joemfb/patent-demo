<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626726-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626726</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12302625</doc-number>
<date>20070531</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>307</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>7</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>707693</main-classification>
<further-classification>707687</further-classification>
</classification-national>
<invention-title id="d2e53">Method and system for transformation of logical data objects for storage</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5235641</doc-number>
<kind>A</kind>
<name>Nozawa et al.</name>
<date>19930800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5285497</doc-number>
<kind>A</kind>
<name>Thatcher, Jr.</name>
<date>19940200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5305295</doc-number>
<kind>A</kind>
<name>Chu</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711202</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5623701</doc-number>
<kind>A</kind>
<name>Bakke et al.</name>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5649151</doc-number>
<kind>A</kind>
<name>Chu et al.</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5802344</doc-number>
<kind>A</kind>
<name>Menon et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5812817</doc-number>
<kind>A</kind>
<name>Hovis et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5813011</doc-number>
<kind>A</kind>
<name>Yoshida et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5813017</doc-number>
<kind>A</kind>
<name>Morris</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5860103</doc-number>
<kind>A</kind>
<name>Franaszek et al.</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5956504</doc-number>
<kind>A</kind>
<name>Jagadish et al.</name>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6021198</doc-number>
<kind>A</kind>
<name>Anigbogu et al.</name>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6092071</doc-number>
<kind>A</kind>
<name>Bolan et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6115787</doc-number>
<kind>A</kind>
<name>Obara</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6122378</doc-number>
<kind>A</kind>
<name>Yoshiura et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6148336</doc-number>
<kind>A</kind>
<name>Thomas et al.</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6154542</doc-number>
<kind>A</kind>
<name>Crandall</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6157720</doc-number>
<kind>A</kind>
<name>Yoshiura et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6349375</doc-number>
<kind>B1</kind>
<name>Faulkner et al.</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6373803</doc-number>
<kind>B2</kind>
<name>Ando et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6449689</doc-number>
<kind>B1</kind>
<name>Corcoran et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6532121</doc-number>
<kind>B1</kind>
<name>Rust et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6728722</doc-number>
<kind>B1</kind>
<name>Shaylor</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>6742176</doc-number>
<kind>B1</kind>
<name>Million et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>7069385</doc-number>
<kind>B2</kind>
<name>Fujimoto et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711119</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>7191251</doc-number>
<kind>B2</kind>
<name>Watanabe et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709245</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>7251708</doc-number>
<kind>B1</kind>
<name>Justiss et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711111</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>7444381</doc-number>
<kind>B2</kind>
<name>Malik</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709206</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>7467268</doc-number>
<kind>B2</kind>
<name>Lindemann et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711162</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2002/0078241</doc-number>
<kind>A1</kind>
<name>Vidal et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2002/0199121</doc-number>
<kind>A1</kind>
<name>Stanford-Clark</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2003/0206635</doc-number>
<kind>A1</kind>
<name>Morley et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2004/0015724</doc-number>
<kind>A1</kind>
<name>Pham et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2004/0030813</doc-number>
<kind>A1</kind>
<name>Benveniste et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>2004/0054858</doc-number>
<kind>A1</kind>
<name>Chandrasekaran et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>2004/0153642</doc-number>
<kind>A1</kind>
<name>Plotkin et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>2004/0199669</doc-number>
<kind>A1</kind>
<name>Riggs et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>2004/0218760</doc-number>
<kind>A1</kind>
<name>Chaudhuri</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>2004/0264698</doc-number>
<kind>A1</kind>
<name>Oda</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>2005/0021657</doc-number>
<kind>A1</kind>
<name>Negishi et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>2005/0102561</doc-number>
<kind>A1</kind>
<name>Graham</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>2005/0204154</doc-number>
<kind>A1</kind>
<name>Osaki</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>2005/0257062</doc-number>
<kind>A1</kind>
<name>Ignatius et al.</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>2006/0190643</doc-number>
<kind>A1</kind>
<name>Kedem et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>2006/0230014</doc-number>
<kind>A1</kind>
<name>Kedem et al.</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>2011/0037626</doc-number>
<kind>A1</kind>
<name>Fallon</name>
<date>20110200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>341 87</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00047">
<document-id>
<country>EP</country>
<doc-number>0747806</doc-number>
<kind>A2</kind>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00048">
<document-id>
<country>EP</country>
<doc-number>1300843</doc-number>
<kind>A2</kind>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00049">
<document-id>
<country>GB</country>
<doc-number>2315575</doc-number>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00050">
<document-id>
<country>JP</country>
<doc-number>1131935</doc-number>
<kind>A</kind>
<date>19890500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00051">
<document-id>
<country>JP</country>
<doc-number>8314689</doc-number>
<kind>A</kind>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00052">
<document-id>
<country>WO</country>
<doc-number>WO0201271</doc-number>
<kind>A1</kind>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00053">
<document-id>
<country>WO</country>
<doc-number>WO 2005/010878</doc-number>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>White Paper by EMC, &#x201c;Leveraging Networked storage for your business&#x201d;, Mar. 2003, USA.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>J. Ziv and A. Lempel, &#x201c;A Universal Algorithm for Sequential Data Compression,&#x201d; IEEE Transactions on Information Theory, IT-23, pp. 337-343 (1997).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>22</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>707687</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707693</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>20</number-of-drawing-sheets>
<number-of-figures>21</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60809382</doc-number>
<date>20060531</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60819369</doc-number>
<date>20060710</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60834165</doc-number>
<date>20060731</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60904782</doc-number>
<date>20070305</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100017423</doc-number>
<kind>A1</kind>
<date>20100121</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Koifman</last-name>
<first-name>Haim</first-name>
<address>
<city>Rishon Lezion</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kedem</last-name>
<first-name>Nadav</first-name>
<address>
<city>Tel Aviv</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Zohar</last-name>
<first-name>Avi</first-name>
<address>
<city>Rosh Haain</city>
<country>IL</country>
</address>
</addressbook>
<residence>
<country>IL</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Koifman</last-name>
<first-name>Haim</first-name>
<address>
<city>Rishon Lezion</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Kedem</last-name>
<first-name>Nadav</first-name>
<address>
<city>Tel Aviv</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Zohar</last-name>
<first-name>Avi</first-name>
<address>
<city>Rosh Haain</city>
<country>IL</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Griffiths &#x26; Seaton PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kim</last-name>
<first-name>Paul</first-name>
<department>2169</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/IL2007/000665</doc-number>
<kind>00</kind>
<date>20070531</date>
</document-id>
<us-371c124-date>
<date>20090804</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2007/138599</doc-number>
<kind>A </kind>
<date>20071206</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and system for transforming a logical data object for storage in a storage device operable with at least one storage protocol, creating, reading, writing, optimization and restoring thereof. Transforming the logical data object comprises creating in the storage device a transformed logical data object comprising a header and one or more allocated accommodation sections with predefined size; sequentially obtaining one or more data chunks corresponding to the transforming logical data object; verifying if obtained data chunks match certain criterion and processing the chunks in accordance with verification results thus giving rise to the processed data chunks, wherein, resulting from said processing, a processed data chunk holds transformed data if the criterion is matched and holds non-transformed data if the criterion is not matches; sequentially accommodating the processed data chunks into said accommodation sections in accordance with an order said chunks received, and facilitating mapping between the data in the logical data object and the data accommodated in the accommodation sections.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="179.24mm" wi="236.14mm" file="US08626726-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="221.57mm" wi="166.62mm" orientation="landscape" file="US08626726-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="235.46mm" wi="185.17mm" orientation="landscape" file="US08626726-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="236.73mm" wi="195.24mm" orientation="landscape" file="US08626726-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="232.58mm" wi="195.58mm" orientation="landscape" file="US08626726-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="250.78mm" wi="185.93mm" orientation="landscape" file="US08626726-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="246.80mm" wi="185.84mm" orientation="landscape" file="US08626726-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="246.30mm" wi="174.24mm" orientation="landscape" file="US08626726-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="254.76mm" wi="187.62mm" orientation="landscape" file="US08626726-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="250.95mm" wi="159.17mm" orientation="landscape" file="US08626726-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="226.57mm" wi="173.65mm" orientation="landscape" file="US08626726-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="263.48mm" wi="202.78mm" orientation="landscape" file="US08626726-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="243.76mm" wi="189.99mm" orientation="landscape" file="US08626726-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="234.87mm" wi="193.72mm" orientation="landscape" file="US08626726-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="233.09mm" wi="187.37mm" orientation="landscape" file="US08626726-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="208.03mm" wi="188.47mm" orientation="landscape" file="US08626726-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="206.25mm" wi="190.08mm" orientation="landscape" file="US08626726-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="242.06mm" wi="188.55mm" orientation="landscape" file="US08626726-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="217.25mm" wi="147.15mm" orientation="landscape" file="US08626726-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="237.24mm" wi="169.93mm" orientation="landscape" file="US08626726-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="230.97mm" wi="179.24mm" orientation="landscape" file="US08626726-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is the National Stage of International Application No. PCT/IL2007/000665 filed May 31, 2007, which claims the priority of U.S. Provisional Application No. 60/809,382, filed May 31, 2006, and U.S. Provisional Application No. 60/819,369, filed Jul. 10, 2006, and U.S. Provisional Application No. 60/834,165, filed Jul. 31, 2006, and U.S. Provisional Application No. 60/904,782, filed Mar. 5, 2007. The contents of all applications are hereby incorporated by reference in their entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">This invention relates to computing systems, and, in particular, to methods and systems capable of transforming logical data objects to be stored in computing systems and networks thereof.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">In current business environment, all types of business data are becoming more and more crucial to business success. The tremendous growth and complexity of business-generated data is driving the demand for information storage, defining the way of sharing, managing and protection of information assets.</p>
<p id="p-0005" num="0004">Typically, no single technology or architecture is able to address all the needs of any organization. Main storage technologies are described, for example, in the White Paper by EMC, &#x201c;Leveraging Networked storage for your business&#x201d;, March 2003, USA and basically can be identified by location and connection type (intra-computer storage, direct attached storage (DAS), IP, channel networks, etc.) and by the method that data is accessed. There are three basic types of storage architectures to consider in connection with methods of data access: Block Access, File Access, and Object Access.</p>
<p id="p-0006" num="0005">In block mode access architecture, the communication between a server/client and a storage medium occurs in terms of blocks; information is pulled block by block directly from the disk. The operation system keeps track of where each piece of information is on the disk, while the storage medium is usually not aware of the file system used to organize the data on the device. When data need to be read or updated, the data are directly accessed from the disk by that processor which knows where each block of data is located on the disk and how to access it. Examples of block mode access storage technologies are DAS (Direct Attached Storage), SAN (Storage Area Network), Block Storage over IP (e.g. FCIP, iFCP, iSCSI, etc.), intra-memory storage, etc.</p>
<p id="p-0007" num="0006">File access requires the server or client to request a file by name, not by physical location. As a result, a storage medium (external storage device or storage unit within a computer) is usually responsible to map files back to blocks of data for creating, maintaining and updating the file system, while the block access is handled &#x201c;behind the scenes&#x201d;. Examples of file access storage technologies are NAS (Network Attached Storage with NFS, CIFS, HTTP, etc. protocols), MPFS (Multi-Pass File Serving), intra-computer file storage, etc. The file access storage may be implemented, for example, for general purpose files, web applications, engineering applications (e.g. CAD, CAM, software development, etc.), imaging and 3D data processing, multi-media streaming, etc.</p>
<p id="p-0008" num="0007">Object access further simplifies data access by hiding all details about block, file and storage topology from the application. The object access occurs over API integrated in content management application. An example of object access storage technology is CAS (Content Addressed Storage).</p>
<p id="p-0009" num="0008">The logical data objects (data files, image files, data blocks, etc.) may be transformed for transmission and/or storage. The transformation may comprise compression, encryption, encoding, conversion, etc. and/or combinations thereof. For example, data compression techniques are used to reduce the amount of data to be stored or transmitted in order to reduce the storage capacity and transmission time respectively. Compression may be achieved by using different compression algorithms, for instance, a standard compression algorithm, such as that described by J. Ziv and A. Lempel, &#x201c;A Universal Algorithm For Sequential Data Compression,&#x201d; IEEE Transactions on Information Theory, IT-23, pp. 337-343 (1997).</p>
<p id="p-0010" num="0009">Various implementations of compressing data for storage and access to the stored data are disclosed, for example, in the following patent publications:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0010">U.S. Pat. No. 5,813,011 (Yoshida et al.) entitled &#x201c;Storage of a compressed file containing its own compression management table&#x201d;;</li>
    <li id="ul0001-0002" num="0011">U.S. Pat. No. 5,813,017 (Morris et al.) entitled &#x201c;System and method for reducing storage requirement in backup subsystems utilizing segmented compression and differencing&#x201d;;</li>
    <li id="ul0001-0003" num="0012">U.S. Pat. No. 5,956,504 (Jagadish et al.) entitled &#x201c;Method and system for compressing a data stream in a database log so as to permit recovery of only selected portions of the data stream&#x201d;;</li>
    <li id="ul0001-0004" num="0013">U.S. Pat. No. 6,092,071 (Bolan et al.) entitled &#x201c;Dedicated input/output processor method and apparatus for access and storage of compressed data&#x201d;;</li>
    <li id="ul0001-0005" num="0014">U.S. Pat. No. 6,115,787 (Obara et al.) entitled &#x201c;Disc storage system having cache memory which stores compressed data&#x201d;;</li>
    <li id="ul0001-0006" num="0015">U.S. Pat. No. 6,349,375 (Faulkner et al.) entitled &#x201c;Compression of data in read only storage and embedded systems&#x201d;;</li>
    <li id="ul0001-0007" num="0016">U.S. Pat. No. 6,449,689 (Corcoran et al.) entitled &#x201c;System and method for efficiently storing compressed data on a hard disk drive&#x201d;;</li>
    <li id="ul0001-0008" num="0017">U.S. Pat. No. 6,532,121 (Rust et al) entitled &#x201c;Compression algorithm with embedded meta-data for partial record operation augmented with expansion joints&#x201d;;</li>
    <li id="ul0001-0009" num="0018">U.S. Patent Application No. 2002/078241 (Vidal et al.) entitled &#x201c;Method of accelerating media transfer&#x201d;;</li>
    <li id="ul0001-0010" num="0019">U.S. Patent Application No. 2004/030,813 (Benveniste et al.) entitled &#x201c;Method and system for storing memory compressed data onto memory compressed disks&#x201d;;</li>
    <li id="ul0001-0011" num="0020">U.S. Patent Application No. 2004/054,858 (Sashikanth et al.) entitled &#x201c;Method and mechanism for on-line data compression and in-place updates&#x201d;;</li>
    <li id="ul0001-0012" num="0021">U.S. Patent Application No. 2006/230,014 (Amit et al.) entitled &#x201c;Method and system for compression of files for storage and operation on compressed files&#x201d;;</li>
    <li id="ul0001-0013" num="0022">U.S. Patent Application No. 2006/190,643 (Amit et al.) entitled &#x201c;Method and system for compression of data for block mode access storage&#x201d;.</li>
</ul>
</p>
<p id="p-0011" num="0023">Data stored in plaintext is open to potential malicious use (e.g. unauthorized access, misuse, theft, etc.), and known in the art solutions for perimeter and/or access control (e.g. firewalls, Virtual Private Networks, LUN masking control and zoning in SAN storage networks, NAS security control features, etc.) still leave security vulnerabilities. Encrypting data to be stored may considerably reduce security threats; such encryption may be provided by using different algorithms known in the art. The problem of providing encryption of storing data with minimal impact on data accessibility and manageability has been recognized in the Prior Art and various systems have been developed to provide a solution, for example:</p>
<p id="p-0012" num="0024">U.S. Pat. No. 5,235,641 (Kakuse et al.) entitled &#x201c;File encryption method and file cryptographic system&#x201d;;</p>
<p id="p-0013" num="0025">US Patent Application No. 2004/153,642 (Avida et al.) entitled &#x201c;Encryption based security system for network storage&#x201d;;</p>
<p id="p-0014" num="0026">US Patent application 2005/204,154 (Osald) entitled &#x201c;Method and apparatus for cryptographic conversion in a data storage system&#x201d;.</p>
<p id="p-0015" num="0027">The problem of providing compression of logical data objects combined with encryption thereof also has been recognized in the Prior Art and various systems have been developed to provide a solution, for example:</p>
<p id="p-0016" num="0028">U.S. Pat. No. 5,285,497 (Thatcher) entitled &#x201c;Methods and apparatus for scrambling and unscrambling compressed data streams&#x201d;</p>
<p id="p-0017" num="0029">U.S. Pat. No. 6,122,378 (Yoshiura et al.) entitled &#x201c;Method and device for compressing and ciphering data&#x201d;</p>
<p id="p-0018" num="0030">U.S. Pat. No. 6,154,542 (Crandall) entitled &#x201c;Method and apparatus for simultaneously encrypting and compressing data&#x201d;</p>
<p id="p-0019" num="0031">U.S. Pat. No. 6,157,720 (Yoshiura et al.) entitled &#x201c;Method and apparatus for encrypting data&#x201d;</p>
<p id="p-0020" num="0032">U.S. Patent Application No. 2004/218,760 (Chaudhuri) entitled &#x201c;System and method for data encryption and compression&#x201d;</p>
<p id="p-0021" num="0033">U.S. Patent Application No. 2004/264,698 (Oda) entitled &#x201c;Data encrypting device, data decoding device, image data storing device and image forming apparatus&#x201d;</p>
<p id="p-0022" num="0034">GB Patent Application 2,315,575 (Mansour et al.) entitled &#x201c;Encryption circuit in I/O subsystem&#x201d;</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0023" num="0035">In accordance with certain aspects of the present invention, there is provided a method of transforming a logical data object for storage in a storage device operable with at least one storage protocol, said method comprising:
<ul id="ul0002" list-style="none">
    <li id="ul0002-0001" num="0000">
    <ul id="ul0003" list-style="none">
        <li id="ul0003-0001" num="0036">in response to a respective request, creating in the storage device a transformed logical data object comprising a header and one or more allocated accommodation sections with predefined size;</li>
        <li id="ul0003-0002" num="0037">sequentially obtaining one or more data chunks corresponding to the transforming logical data object;</li>
        <li id="ul0003-0003" num="0038">verifying if obtained data chunks match certain criterion and processing the chunks in accordance with verification results thus giving rise to the processed data chunks, wherein, resulting from said processing, a processed data chunk holds transformed data if the criterion is matched and holds non-transformed data if the criterion is not matched;</li>
        <li id="ul0003-0004" num="0039">sequentially accommodating the processed data chunks into said accommodation sections in accordance with an order said chunks received; and</li>
        <li id="ul0003-0005" num="0040">facilitating mapping between the data in the logical data object and the data accommodated in the accommodation sections.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0024" num="0041">In accordance with further aspects of the present invention, a transforming technique may be compression, encryption, encoding, conversion, a combination thereof, etc. The criterion may be related to characteristics of the logical data object, characteristics of data chunks, characteristics of accommodation sections, characteristics of transforming operation, a combination thereof, etc.</p>
<p id="p-0025" num="0042">In accordance with further aspects of the present invention, the criterion may be related to a transformation time of a data chunk and/or entire logical data object.</p>
<p id="p-0026" num="0043">In accordance with further aspects of the invention, the processing may comprise more than one technique of data transformation. The transformation time criterion may be related separately to each technique, wherein the processed data chunk holds partly transformed data if the criterion is matched in relation to part of techniques of data transformation, said partial transformation is provided merely by techniques matching the criterion.</p>
<p id="p-0027" num="0044">In accordance with further aspects of the present invention, the header of transformed logical data object comprises a unique descriptor of the transformed logical data object, information related to a size of the transforming logical data object, and an indication if the transformed logical data object holds data in a non-transformed form.</p>
<p id="p-0028" num="0045">In accordance with further aspects of the present invention, the accommodation section comprises a header containing a unique identifier of the section and an indication if section holds data in a non-transformed form.</p>
<p id="p-0029" num="0046">In accordance with further aspects of the present invention, the processed data chunks are accommodated in a log form. A log of a processed data chunk comprises a log header containing information in respect of an offset of the obtained data chunk within the transforming logical data object, size of said obtained chunk, an identifier allowing associating the log with the accommodation section accommodating the log, and an indication of transformed/non-transformed form of data held in the log.</p>
<p id="p-0030" num="0047">In accordance with other aspects of the present invention, there is provided a method of compressing a logical data object for storage in a storage device operable with at least one storage protocol, said method comprising:
<ul id="ul0004" list-style="none">
    <li id="ul0004-0001" num="0000">
    <ul id="ul0005" list-style="none">
        <li id="ul0005-0001" num="0048">in response to a respective request, creating in the storage device a compressed logical data object comprising a header and one or more allocated compressed sections with predefined size;</li>
        <li id="ul0005-0002" num="0049">processing one or more sequentially obtained chunks of raw data corresponding to the compressing raw logical data object thus giving rise to the processed data chunks, wherein substantially all processed data chunks hold data in non-compressed form;</li>
        <li id="ul0005-0003" num="0050">sequentially accommodating said processed data chunks into the compressed sections in accordance with an order said chunks received, wherein providing indication that the section holds data in a non-transformed form;</li>
        <li id="ul0005-0004" num="0051">facilitating mapping between the data in the logical data object and the data accommodated in the accommodation sections;</li>
        <li id="ul0005-0005" num="0052">scanning the compressed logical data object to identify one or more compressed sections holding data in non-compressed form;</li>
        <li id="ul0005-0006" num="0053">compressing data accommodated in said identified compression section; and</li>
        <li id="ul0005-0007" num="0054">sequentially accommodating respective processed chunks holding compressed data in one or more newly allocated compressed sections.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0031" num="0055">In accordance with further aspects of the present invention, compressing the data accommodated in the compressed sections may be provided per pre-defined schedule, pre-defined events, etc.</p>
<p id="p-0032" num="0056">In accordance with other aspects of the present invention, there is provided a system capable of transforming a logical data object for storage in a storage device operable with at least one storage protocol, said system is configured to hold certain criterion to be matched during transformation and comprises:
<ul id="ul0006" list-style="none">
    <li id="ul0006-0001" num="0000">
    <ul id="ul0007" list-style="none">
        <li id="ul0007-0001" num="0057">means for creating in the storage device a transformed logical data object comprising a header and one or more allocated accommodation sections with predefined size;</li>
        <li id="ul0007-0002" num="0058">means for sequentially obtaining one or more data chunks corresponding to the transforming logical data object;</li>
        <li id="ul0007-0003" num="0059">means for verifying if obtained data chunk match certain criterion;</li>
        <li id="ul0007-0004" num="0060">means for processing the obtained chunks in accordance with verification results thus giving rise to the processed data chunks, wherein, resulting from said processing, a processed data chunk holds transformed data if the criterion is matched and holds non-transformed data if the criterion is not matched;</li>
        <li id="ul0007-0005" num="0061">means for sequentially accommodating the processed data chunks into said accommodation sections in accordance with an order said chunks received; and</li>
        <li id="ul0007-0006" num="0062">means for facilitating mapping between the data in the logical data object and the data accommodated in the accommodation sections.</li>
    </ul>
    </li>
</ul>
</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0033" num="0063">In order to understand the invention and to see how it may be carried out in practice, certain embodiments will now be described, by way of non-limiting example only, with reference to the accompanying drawings, in which:</p>
<p id="p-0034" num="0064"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic block diagram of typical storage network architecture as is known in the art;</p>
<p id="p-0035" num="0065"><figref idref="DRAWINGS">FIGS. 2</figref><i>a </i>and <b>2</b><i>b </i>are schematic diagrams of raw and compressed logical data objects in accordance with certain embodiments of the present invention;</p>
<p id="p-0036" num="0066"><figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>3</b><i>b </i>are schematic diagrams of plaintext and encrypted logical data objects in accordance with certain embodiments of the present invention;</p>
<p id="p-0037" num="0067"><figref idref="DRAWINGS">FIGS. 4</figref><i>a</i>-<b>4</b><i>d </i>are schematic diagrams of original and compressed/encrypted logical data objects in accordance with certain embodiments of the present invention;</p>
<p id="p-0038" num="0068"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic diagram of the transformed logical data object in accordance with certain embodiments of the present invention;</p>
<p id="p-0039" num="0069"><figref idref="DRAWINGS">FIGS. 6</figref><i>a </i>and <b>6</b><i>b </i>are schematic diagrams illustrating update of the transformed logical data object in accordance with certain embodiments of the present invention;</p>
<p id="p-0040" num="0070"><figref idref="DRAWINGS">FIG. 7</figref> is a generalized flowchart of creating transformed logical data object in accordance with certain embodiments of the present invention;</p>
<p id="p-0041" num="0071"><figref idref="DRAWINGS">FIG. 8</figref> is a schematic diagram of the processed logical data object accommodated in non-transformed and transformed form in accordance with certain embodiments of the present invention;</p>
<p id="p-0042" num="0072"><figref idref="DRAWINGS">FIG. 9</figref> is a generalized flowchart of write operation on a transformed logical data object in accordance with certain embodiments of the present invention;</p>
<p id="p-0043" num="0073"><figref idref="DRAWINGS">FIG. 10</figref> is a generalized flowchart of read operation on a transformed logical data object in accordance with certain embodiments of the present invention;</p>
<p id="p-0044" num="0074"><figref idref="DRAWINGS">FIG. 11</figref><i>a </i>is a generalized flowchart of read operation with specified point in time in accordance with certain embodiments of the present invention;</p>
<p id="p-0045" num="0075"><figref idref="DRAWINGS">FIG. 11</figref><i>b</i>, there a schematic diagram of index section comprising time stamps in accordance with certain embodiments of the present invention.</p>
<p id="p-0046" num="0076"><figref idref="DRAWINGS">FIGS. 12</figref><i>a</i>-<b>12</b><i>b </i>are schematic diagrams illustrating non-limiting examples of encryption transformation in accordance with certain embodiments of the present invention.</p>
<p id="p-0047" num="0077"><figref idref="DRAWINGS">FIG. 13</figref> is a schematic functional block diagram of the transformation system in accordance with certain embodiments of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS</heading>
<p id="p-0048" num="0078">In the following detailed description, numerous specific details are set forth in order to provide a thorough understanding of the invention. However, it will be understood by those skilled in the art that the present invention may be practiced without these specific details. In other instances, well-known methods, procedures, components and circuits have not been described in detail so as not to obscure the present invention. In the drawings and descriptions, identical reference numerals indicate those components that are common to different embodiments or configurations.</p>
<p id="p-0049" num="0079">Unless specifically stated otherwise, as apparent from the following discussions, it is appreciated that throughout the specification discussions, utilizing terms such as &#x201c;processing&#x201d;, &#x201c;computing&#x201d;, &#x201c;calculating&#x201d;, &#x201c;determining&#x201d;, &#x201c;generating&#x201d;, &#x201c;creating&#x201d; or the like, refer to the action and/or processes of a computer or computing system, or processor or similar electronic computing device, that manipulate and/or transform data represented as physical, such as electronic, quantities within the computing system's registers and/or memories into other data, similarly represented as physical quantities within the computing system's memories, registers or other such information storage, transmission or display devices.</p>
<p id="p-0050" num="0080">Embodiments of the present invention may use terms such as processor, computer, apparatus, system, sub-system, module, unit, device (in single or plural form) for performing the operations herein. This may be specially constructed for the desired purposes, or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as, but not limited to, any type of disk including, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), electrically programmable read-only memories (EPROMs), electrically erasable and programmable read only memories (EEPROMs), magnetic or optical cards, or any other type of media suitable for storing electronic instructions, and capable of being coupled to a computer system bus.</p>
<p id="p-0051" num="0081">The processes/devices (or counterpart terms specified above) and displays presented herein are not inherently related to any particular computer or other apparatus, unless specifically stated otherwise. Various general purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct a more specialized apparatus to perform the desired method. The desired structure for a variety of these systems will appear in the description below. In addition, embodiments of the present invention are not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the inventions as described herein.</p>
<p id="p-0052" num="0082">The references cited in the background teach many principles of encryption and compression that are applicable to the present invention. Therefore the full contents of these publications are incorporated by reference herein where appropriate for appropriate teachings of additional or alternative details, features and/or technical background.</p>
<p id="p-0053" num="0083">The term &#x201c;criterion&#x201d; used in this patent specification should be expansively construed to cover any compound criterion, including, for example, several criteria and/or their combination.</p>
<p id="p-0054" num="0084">The term &#x201c;logical data object (LO)&#x201d; used in this patent specification should be expansively construed to include any types and granularities of data units used in a computing system and handled as one unit (e.g. data files, archive files, image files, database files, memory data blocks, stream data blocks, etc.).</p>
<p id="p-0055" num="0085">Bearing this in mind, attention is drawn to <figref idref="DRAWINGS">FIG. 1</figref> illustrating a schematic diagram of typical storage network architectures as known in the art. The logical data objects (LO) from clients <b>11</b> and/or servers <b>12</b> are transferred via network <b>13</b> to storage device(s) <b>14</b> (e.g. specialized NAS file servers, general purpose file servers, SAN storage, stream storage device, etc.). The network comprises one or more communication devices <b>15</b> (e.g. switch, router, bridge, etc.) facilitating the data transfer. The storage in the illustrated network may be wholly or partly implemented using block mode access and/or file mode access storage protocols. In file mode access the logical data objects (LOs) are constituted by files, and the network is IP network (e.g. local area network (LAN), wide area network (WAN), combination thereof, etc.). In block mode access embodiments, the logical data objects are constituted by data blocks and the network is Storage Area Network (SAN) implementing, for example, Fiber Channel or iSCSI protocols. In certain embodiments the storage device <b>14</b><i>a </i>may be directly connected to a server <b>12</b> via block mode access storage protocols (e.g. SCSI, Fiber Channel, etc.). Such Direct Access Storage includes, for example, the internally attached local disk drives or externally attached RAID (redundant array of independent disks) or JBOD (just a bunch of disks), etc.</p>
<p id="p-0056" num="0086">At least part of the logical data objects may be stored in a transformed form (e.g. a compressed form and/or an encrypted form). Accordingly, they may be transformed (e.g. compressed/decompressed and/or encrypted/decrypted) on a physical or logical communication route between the clients/servers and the storage location. The transformation or part thereof may be provided, for example, by the server <b>12</b>, communication device <b>15</b>, by a transformation system <b>16</b> operatively coupled to the clients/servers and the storage device, by the storage device <b>14</b>, etc. Typically the secure keys used for encryption are held separately from the device providing encryption and/or storage, for example, they may be held at a key holding platform <b>17</b> operatively coupled with the transformation platform <b>16</b>. Likewise, coding tables and similar external data involved in the transformation process may be held separate from the processing and/or storage devices.</p>
<p id="p-0057" num="0087">Note that the invention is not bound by the specific architecture described with reference to <figref idref="DRAWINGS">FIG. 1</figref>. Those versed in the art will readily appreciate that the invention is, likewise, applicable to any computing systems and any storage network architecture facilitating transformation of one or more logical data objects on a physical and/or logical route between a computer sending data access request to the logical data object and a storage location of the appropriate transformed data, including embodiments wherein transformation (e.g. compression and/or encryption) and storage are provided at the same physical location.</p>
<p id="p-0058" num="0088"><figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>-<b>2</b><i>b</i>, <b>3</b><i>a</i>-<b>3</b><i>b</i>, and <b>4</b><i>a</i>-<b>4</b><i>d </i>illustrate schematic diagrams of original and transformed logical data objects in accordance with certain embodiments of the present invention. The transformation may comprise compression, encryption, encoding, conversion, etc. and/or combinations thereof. The transformation illustrated in <figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>-<b>2</b><i>b </i>is compression of logical data objects, in <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>b</i>&#x2014;encryption of logical data objects, and in <figref idref="DRAWINGS">FIGS. 4</figref><i>a</i>-<b>4</b><i>d </i>the illustrated transformation includes a combination of compression and encryption. For purpose of illustration only the following description is made with respect to processing logical data objects by the transformation system <b>16</b>, writing the processed data to the storage device <b>14</b>, reading the data to be de-transformed (e.g. decrypted, decompressed, etc.) from the storage device, and de-transforming them by the transformation system <b>16</b>. It should be noted, however, that the present invention is applicable in a similar manner to transformation/de-transformation provided by any purpose device operatively located on a physical and/or logical route between a computer sending access-related request (e.g. open, read, write, etc.) to the LO and a storage location of appropriate transformed data (including the end points of said route). The described functionalities of the transformation system may be provided in different ways. For example, the transformation system <b>16</b> may be integrated in one or more said devices &#x201c;inter alias&#x201d;, the functionality of the transformation system may be implemented in one or more specialized boards, distributed (fully or partly) between other modules of at least one device, etc. The integration may be provided in a different manner and implemented in software and/or firmware and/or hardware. The integration may be provided with any storage network elements (for example, file servers, enterprise and network switches, routers, storage devices, etc.), etc.</p>
<p id="p-0059" num="0089">Also it should be noted that the invention is, likewise, applicable to writing the processed data in a memory of any device on said route and later forwarding the entire transformed LO or parts thereof for storing at a storage location, as well as for forwarding the transformed data to be read from the storage location to any device on said route and further de-transformation.</p>
<p id="p-0060" num="0090">For purpose of illustration only, the following description is made with respect to an adaptive dictionary-based data compression algorithm (e.g. Lempel-Ziv). It should be noted that the invention is not bound by this algorithm and is, likewise, applicable to any other sequential data compression algorithm. Among advantages of certain embodiments using the adaptive dictionary-based compression algorithm, is gaining compression/decompression performance.</p>
<p id="p-0061" num="0091">Also for purpose of illustration only, the following description is made with respect to a block cipher using secret-key symmetric algorithm (e.g. IDEA&#x2014;International Data Encryption Algorithm). It should be noted that the invention is not bound by this algorithm and is, likewise, applicable to any other, symmetric or asymmetric, encryption algorithm capable to break a block of plaintext data into segments and to transform each plaintext segment of the block into a segment of ciphertext.</p>
<p id="p-0062" num="0092"><figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>, <b>3</b><i>a</i>, <b>4</b><i>a </i>and <b>4</b><i>b </i>illustrate schematic diagrams of original and transformed logical data objects in accordance with certain embodiments of the present invention for file mode access. The transformation system <b>16</b> is configured to intercept file call operations (file access-related requests) as well as some control transactions (e.g. set end of file) and to act as a proxy on certain transactions (e.g. keeping the throughput on most control transactions and proxy on data transactions and certain control transactions). The transformation system is capable of deriving and processing data corresponding to the intercepted file access-related request, facilitating communication with and/or within the file system for storing the processed data at the storage medium as at least one transformed file and/or facilitating de-transformation of at least part of the processed data corresponding to the intercepted file request. During &#x201c;write&#x201d; operation on the files to be processed for storage, the transformation system <b>16</b> receives from the clients <b>11</b> and/or the servers <b>12</b> through the network <b>13</b> data corresponding to said files, transforms the data and facilitates writing at the file storage device <b>14</b>. A &#x201c;read&#x201d; operation proceeds in reverse direction; the required files are retrieved by the transformation system, de-transformed (partly or entirely, in accordance with required data range) and sent to the appropriate client/server. When appropriate, the transformation system is capable to communicate with the external platform (e.g. keys holding platform <b>17</b>) for obtaining external data involved in the transformation process (e.g. secure keys and/or secure value or other metadata thereof involved in the transformation).</p>
<p id="p-0063" num="0093"><figref idref="DRAWINGS">FIGS. 2</figref><i>b</i>, <b>3</b><i>b</i>, <b>4</b><i>c </i>and <b>4</b><i>d </i>illustrate schematic diagrams of original and transformed logical data objects in accordance with certain embodiments of the present invention for block mode access. As known in the art, typical storage systems and networks are able to recognize the divided organization of storage. A storage disk or a set of disks may be conceptually divided into logical unit(s). The storage logical units (LU) can directly correspond to volume drive, to host application, storage device, etc. and constitute a logical representation of physical storage. Each logical unit has an address, known as the logical unit number (LUN), which allows it to be uniquely identified. Users can determine whether a LUN is a disk drive, a number of disk drives, a partition on a disk drive, combinations thereof, etc. In certain embodiments of the present invention, one or more LUs accommodate transformed data, while the transformation system is configured to create in respect to the storage logical units corresponding virtual logical units (VLUs) arranged to virtually represent in a non-transformed form the data stored in the storage logical unit (i.e. the original data); intercept data access-related requests addressed to the storage logical unit and address said request to the virtual logical unit; and facilitate mapping between the transformed data and their non-transformed virtual representation at the virtual logical unit. Thus, in accordance with certain aspects of the present invention, the computer's operating system (OS) will relate to the VLU as a virtual representation of non-transformed data (original LO).</p>
<p id="p-0064" num="0094">The ratio between the sizes of VLU and LU may be predefined and/or be adaptable during the transformation process. For example, as will be further detailed with reference to <figref idref="DRAWINGS">FIG. 2</figref><i>b </i>for the case of compressing transformation, the ratio between the size of LU and VLU may be defined in accordance with the expected compression rate (e.g. the size of the virtual logical unit may correspond to an estimated size of raw data which, being compressed, would substantially amount to the size of the storage logical unit) and adapted in accordance with real compression ratio.</p>
<p id="p-0065" num="0095">For purpose of illustration only, the following description is made with respect to certain embodiments wherein each chunk of original data is transformed when it arrives and is written to the storage location in the transformed form substantially without keeping data in a cache and independently of processing the other received chunks. It should be noted that the invention is, likewise, applicable, for example, when the received chunks are combined or segmented before processing and/or before writing in the storage device (e.g. in accordance with size criterion). The size of data to be transformed and the size of transformed data to be written as one portion (and/or size of original data to be written as one portion) may be configurable per certain criteria (e.g. per size of I/O buffer of the transformation system and/or storage device, characteristics of transformation engine, configurable runtime, characteristics of the storage network, type of incoming and outgoing traffic, etc.). The transformation system may provide acknowledgment of writing data to the storage location in different modes, e.g. per each written portion, per predefined/configurable number of portions, per predefined/configurable runtime, etc. depending, for example, on protocols of storage network and traffic thereof. It should be also noted that in certain embodiments of the present invention (e.g. as further detailed with reference to <figref idref="DRAWINGS">FIG. 7</figref>) data chunks fitting certain criterion may be stored in non-transformed form resulting from transformation failure or omitting the transforming processing.</p>
<p id="p-0066" num="0096">Bearing this in mind, attention is drawn to <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>illustrating a schematic diagram of raw and compressed logical data objects in accordance with certain embodiments of the present invention for file mode access. The chunks of data (<b>202</b>-<b>1</b>-<b>202</b>-<b>6</b>) comprised in uncompressed LO (raw file <b>201</b> in the illustrated embodiment) are sequentially processed into compressed data chunks (<b>207</b>-<b>1</b>-<b>207</b>-<b>6</b>) to be accommodated into blocks <b>205</b>-<b>1</b>, <b>205</b>-<b>2</b> (hereinafter referred to as compressed sections (CS)) with a predefined size. It should be noted that, as will be further detailed with reference to <figref idref="DRAWINGS">FIG. 7</figref>, some chunks of the processed data may be accommodated in non-compressed form if they do not meet certain criterion (e.g., when an obtainable compression ratio less than a predefined value, etc.).</p>
<p id="p-0067" num="0097">Said compressed sections serve as atomic elements of compression/decompression operations during input/output transactions on the files. The compression processing is provided in a manner enabling substantial identity between a decompressed compression section and the original data accommodated in said section as result of compression (e.g. in the illustrated example data resulting of decompressing the compressed section <b>205</b>-<b>1</b> will be substantially identical to the original data comprised in the chunks <b>202</b>-<b>1</b>, <b>201</b>-<b>2</b> and <b>201</b>-<b>3</b>).</p>
<p id="p-0068" num="0098">The size of the compressed sections may be configurable; larger compressed sections provide lower processing overhead and higher compression ratio, while smaller compressed sections provide more efficient access but higher processing overhead. The size of the compressed section may be predefined also in accordance with a certain time-related criterion (e.g. estimated time necessary to compress data which, being compressed, would substantially amount to the compressed section size, etc.).</p>
<p id="p-0069" num="0099">In certain embodiments of the invention the predefined size of the sections may be equal for all compressed sections (e.g., by way of non-limiting example, the compressed sections may have equal size of 1 MB). Alternatively, in certain embodiments of the invention, the predefined size may vary for different compressed sections. For example, each type of data (e.g. text, image, voice, combined, etc.) or logical data objects may correspond to predefined size of the compressed section, and the transformation system during compression may select the appropriate size of the compressed section in accordance with data type dominating in the respective portion of the raw file being compressed (and/or type of LO). Optionally, the compression process may include adaptive capabilities, providing, for example, optimized compression algorithm for compressed data chunks accommodated in different compressed sections (e.g. different compression algorithms best suited for sections with dominating voice, text, image, etc.).</p>
<p id="p-0070" num="0100">The real total size of the compressed data accommodated in the compressed section may be less than the predefined size of the compressed section as will be further described with reference to <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0071" num="0101">In accordance with certain embodiments of the present invention, the processed chunks (<b>207</b>-<b>1</b>-<b>207</b>-<b>6</b>) are accommodated in the compressed sections according to the order of receiving the respective incoming chunks (<b>202</b>-<b>1</b>-<b>202</b>-<b>6</b>), said accommodation may be provided in log form, journal form, or other form of sequential accommodation. The compressed LO (compressed file <b>203</b> in the illustrated embodiment) comprises a header <b>204</b>, one or more compressed sections <b>205</b> and one or more index sections (IS) <b>206</b>. The header <b>204</b> of the compressed file comprises a unique file descriptor, a flag indicating that the file is currently open (or a recovery status), information about the size of the raw file <b>201</b>, and, optionally, a signature indicating whether the file was processed by the transformation system <b>16</b> (also for files which were not compressed by the transformation system as not fitting certain criterion, e.g., because of obtainable compression ratio less than a predefined value), etc. In certain embodiments of the invention the header may have a fixed length. The header and index sections will be further detailed with reference to <figref idref="DRAWINGS">FIGS. 5-10</figref>.</p>
<p id="p-0072" num="0102">In other embodiments of the present invention (e.g. in certain embodiments where compressed/decompressed functionalities are integrated with the storage device, etc.) the header <b>204</b> or any of its parts and combinations thereof may constitute a part of the file system. For example, a file identifier used in a certain file system (e.g. node ID) may be used as the unique file descriptor of the compressed file, a file record in the file system may be modified and comprise additional fields, e.g. for information about the size of the raw file, said signature, etc. The index section or parts thereof may also constitute a part of the file system.</p>
<p id="p-0073" num="0103"><figref idref="DRAWINGS">FIG. 2</figref><i>b </i>illustrates a schematic diagram of raw and compressed logical data objects in accordance with certain embodiments of the present invention for the block mode access. The chunks of data comprised in uncompressed (raw) LO are sequentially processed into compressed data chunks (<b>217</b>-<b>1</b>-<b>217</b>-<b>6</b>) to be accommodated into blocks <b>215</b>-<b>1</b>, <b>215</b>-<b>2</b> (hereinafter referred to as compressed sections) with a predefined size and similar to compressed sections described with reference to <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>. Said uncompressed chunks corresponding to the processed data chunks (<b>217</b>-<b>1</b>-<b>217</b>-<b>6</b>) are virtually represented in the VLU <b>211</b> as data chunks (<b>212</b>-<b>1</b>-<b>212</b>-<b>6</b>). The compressed sections serve as atomic elements of compression/decompression operations during input/output transactions (data access-related requests) on the data blocks. The ratio between the sizes of VLU and LU may be predefined in accordance with certain criteria (e.g. per dominating type of data in the compressing data block, per maximal or minimal compression ratio obtainable for said data, etc.) or be adaptable during the compression process. By way of non-limiting example, in certain embodiments of the present invention the ratio between size of VLU and LU is estimated as 3 for e-mails, as 8 for a text formatted data, etc. In certain cases the real ratio between the compressed and raw data may be (and/or become) less than the estimated ratio. This difference may cause an overflow of the storage logical unit, as the computer's operating system (OS) will relate to the VLU still representing free space when the LU is, actually, full up. Accordingly, the transformation system <b>16</b> may be configured to detect the upcoming overflow event (e.g. by determining the actual compression rate and the free space in LU, etc.) and to facilitate enlarging the storage logical unit by predefined or calculated space if free capacity in LU does not match certain criterion (e.g. less than a predefined size). The transformation system is further configured to detect a failure of said LU enlarging (e.g. because of unavailable additional disk space, inability of the storage device to support the dynamic LU changes, etc.), change the access status of the LU to &#x2018;read only&#x2019;, and to keep this status until the free capacity in the LU matches the above criteria. Similar, the transformation system may be configured to facilitate releasing of free space in LU if the real ratio between the compressed and raw data is higher than the estimated ratio.</p>
<p id="p-0074" num="0104">Likewise described with reference to <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>, the compressed chunks are accommodated in the compressed sections according to the order of receiving the respective incoming chunks; said accommodation may be provided in log form, journal form, or other form of sequential accommodation. The compressed LO (LU <b>213</b>) comprises a header <b>214</b>, one or more compressed sections <b>215</b>, an index section <b>216</b> and a free space <b>218</b>. The header <b>214</b> comprises a unique descriptor containing a logical unit number (LUN), the size of the virtual logical unit (VLU), the size of LU (optionally), an open/recovery flag, a signature indicating whether at least part of the storing data were processed by the transformation system <b>16</b>, etc. The header may have a fixed length (e.g., by way of non-limiting example, 24 bytes including 4 bytes for the signature, 16 bytes for the unique descriptor, 4 bytes for the info about size of the corresponding virtual logical unit).</p>
<p id="p-0075" num="0105">In other embodiments of the present invention (e.g. in certain embodiments when compressed/decompressed functionalities are integrated with the storage device, etc.) the header <b>214</b> or any of its parts and combinations thereof may constitute a part of disk attributes, the index section <b>216</b> may constitute a part of the disk attributes, etc.</p>
<p id="p-0076" num="0106">Thus, chunks of data comprised in the original logical data object (LO) of any type are sequentially compressed and accommodated in the received order in one or more compressed sections with predefined size. The compression processing is configured in a manner enabling substantial identity between compression section if being decompressed and the original data accommodated in said section as a result of compression. The chunks accommodated in the same compressed section are compressed using the same dictionary. As will be further detailed with reference to <figref idref="DRAWINGS">FIG. 6</figref>, the information in the index section facilitates one-to-one relationship between each point in the original data range and the data to be read from the logs after de-transformation. The compressed data chunks are moved to the storage location in a &#x201c;sync-flush&#x201d; mode enabling all pending output to be flushed to the output (storage) buffer without a reset of compression operation. Thus sync flushing of the compression buffer enables using the same dictionary within the compressed section whilst facilitating data integrity. Sync-flush may be implemented in different ways, some of them known in the art (e.g. by applying Z_SYNC_FLUSH parameter in deflate/inflate functions provided in ZLIB compression library, ZLIB.H&#x2014;interface of the &#x2018;zlib&#x2019; general purpose compression library, version 1.2.3, Jul. 18, 2005, Copyright (C) 1995-2005 Jean-Loup Gailly and Mark Adler).</p>
<p id="p-0077" num="0107">In certain embodiments of the invention the initial k bytes of the data to be compressed are used as a dictionary. The same dictionary is further used for compression of the entire first and subsequent chunks of sequential data to be processed/compressed and accommodated in a compressed section, while the dictionary is adapted in accordance with processed data, e.g. per Lempel-Ziv algorithm. The process continues until the total size of the compressed data substantially achieves the predefined size of the compressed section. The next chunk of compressed data will be accommodated in a subsequent compressed section. The initial k bytes in said next chunk will be used for renewing the dictionary to be used for compressing the data accommodated in said subsequent compressed section. In certain embodiments of the invention a new compression sequence started in the new compressed section may use the same initial compression dictionary as the previous sequence.</p>
<p id="p-0078" num="0108">In certain embodiments of the invention the dictionaries corresponding to data in different compressed sections may be maintained as an entire dictionary comprising certain pointers to appropriate compressed sections. This entire dictionary may be accommodated in one or more index sections or be distributed between different index sections and/or compressed sections. Alternatively, the dictionary may be divided into several separately managed dictionaries corresponding to one or more compressed sections. In certain embodiments the index section may accommodate one or more dictionaries corresponding solely to data in the compressed sections associated with said index section. In some embodiments each compressed section may comprise a dictionary related to the data stored in the section.</p>
<p id="p-0079" num="0109">In certain embodiments of the invention each received portion of raw data is received, processed, compressed if it fits certain criteria, and written to the storage location almost without keeping data in a cache, and independently of processing the other received portions. In other embodiments of the present invention several received portions may be processed together and written in the storage device as one compressed portion.</p>
<p id="p-0080" num="0110">Among advantages of certain embodiments of the present invention is the ability to process and write relatively small chunks of data wherein obtaining capabilities of compression over a relatively large volume of data (compressed section); as well as enhanced compression ratio facilitated by sequential compression of data chunks using the same adaptive dictionary.</p>
<p id="p-0081" num="0111"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>illustrates a schematic diagram of original and encrypted logical data objects in accordance with certain embodiments of the present invention for file mode access. The chunks of data (<b>302</b>-<b>1</b>-<b>302</b>-<b>4</b>) comprised in a plaintext LO (plaintext file <b>301</b> in the illustrated embodiment) are sequentially processed into encrypted data chunks (<b>307</b>-<b>1</b>-<b>307</b>-<b>4</b>) to be accommodated into blocks <b>305</b>-<b>1</b>, <b>305</b>-<b>2</b> (hereinafter referred to as encrypted sections (ES) with a predefined size. It should be noted that, as will be further detailed with reference to <figref idref="DRAWINGS">FIG. 7</figref>, some chunks of the processed data may be accommodated in non-encrypted form if they do not meet certain criterion.</p>
<p id="p-0082" num="0112">Similar to the compression sections described with reference to <figref idref="DRAWINGS">FIGS. 2</figref><i>a </i>and <b>2</b><i>b</i>, said encrypted sections serve as atomic elements of encryption/decryption operations during input/output transactions on the files. The size of the encrypted sections may be configurable; smaller encrypted sections provide more efficient access but higher processing overhead. In certain embodiments of the invention the predefined size may be equal for all encrypted sections (e.g., by way of non-limiting example, the encrypted sections may have an equal size of 1 MB). Alternatively, in certain other embodiments of the invention, the predefined size of the encrypted sections may vary. For example, each type of data may correspond to predefined size of the encrypted section, and the transformation system during encryption may select the appropriate size of the encrypted section in accordance with data type dominating in the respective chunk (or a group of chunks) of the plaintext file being encrypted.</p>
<p id="p-0083" num="0113">In accordance with certain embodiments of the present invention, the processed/encrypted chunks (<b>307</b>-<b>1</b>-<b>307</b>-<b>4</b>) are accommodated in the encrypted sections in accordance with the order of receiving respective chunks of plaintext data, said accommodation may be provided in log form, journal form, etc. The encrypted LO (encrypted file <b>303</b> in the illustrated embodiment) comprises a header <b>304</b>, one or more encrypted sections <b>305</b> and one or more index sections (IS) <b>306</b>. The header <b>304</b> of the encrypted file comprises a unique file descriptor, a flag indicating that the file is currently open (or recovery status), information about the size of the plaintext file <b>301</b>, and, optionally, a signature indicating whether the file was processed by the transformation system <b>16</b> (also for files which were not encrypted by the transformation system as not fitting certain criterion, e.g., certain authorization marks, certain type of files, etc.). In certain embodiments of the invention the header may have a fixed length. The header and index sections will be further detailed with reference to <figref idref="DRAWINGS">FIGS. 5-10</figref>.</p>
<p id="p-0084" num="0114">In other embodiments of the present invention (e.g. in certain embodiments where encrypted/decrypted functionalities are integrated with the storage device, etc.) the header <b>304</b> or any of its parts and combinations thereof may constitute a part of the file system. For example, a file identifier used in a certain file system (e.g. node ID) may be used as the unique file descriptor of the encrypted file, a file record in the file system may be modified and comprise additional fields, e.g. for information about the size of the plaintext file, said signature, etc. The index section or parts thereof may also constitute a part of the file system.</p>
<p id="p-0085" num="0115"><figref idref="DRAWINGS">FIG. 3</figref><i>b </i>illustrates a schematic diagram of plaintext and encrypted logical data objects in accordance with certain embodiments of the present invention for block mode access. The chunks of data comprised in plaintext LO are sequentially processed into encrypted data chunks (<b>317</b>-<b>1</b>-<b>317</b>-<b>4</b>) to be accommodated in the received order into blocks <b>315</b>-<b>1</b>, <b>315</b>-<b>2</b> (hereinafter referred to as encrypted sections) with a predefined size and similar to encrypted sections described with reference to <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>. Said plaintext chunks corresponding to the processed data chunks (<b>317</b>-<b>1</b>-<b>317</b>-<b>4</b>) are virtually represented in the VLU <b>311</b> as data chunks (<b>312</b>-<b>1</b>-<b>312</b>-<b>4</b>).</p>
<p id="p-0086" num="0116">The encrypted LO (LU <b>313</b>) comprises a header <b>314</b>, one or more encrypted sections <b>315</b>, an index section <b>316</b> and a flee space <b>318</b>. The header <b>314</b> comprises a unique descriptor containing a logical unit number (LUN), the size of the virtual logical unit (VLU), the size of LU (optionally), an open/recovery flag, a signature indicating whether at least part of the storing data were processed by the transformation system <b>16</b>, etc. The header and index sections will be further detailed with reference to <figref idref="DRAWINGS">FIGS. 5-10</figref>.</p>
<p id="p-0087" num="0117">In other embodiments of the present invention (e.g. in certain embodiments when encryption/decryption functionalities are integrated with the storage device, etc.) the header <b>314</b> or any of its parts and combinations thereof, and/or the index section <b>316</b> may constitute a part of disk attributes.</p>
<p id="p-0088" num="0118">Thus, chunks of data comprised in the original logical data object (LO) of any type are sequentially encrypted and accommodated in the received order in one or more encrypted sections with predefined size.</p>
<p id="p-0089" num="0119">The encryption processing is configured in a manner enabling substantial identity between encryption section if being decrypted and the plaintext data accommodated in said section as a result of encryption.</p>
<p id="p-0090" num="0120">A block cipher encryption algorithm breaks plaintext data in the received chunks into fixed-size segments (e.g. 16 bytes) and encrypts each plaintext segment of the chunk into encrypted segment with fixed-size B. In the illustrated embodiment the transformation system is capable to round, when the encrypted segments, when necessary to said fixed size B (e.g. by entering padding data). The first and subsequent chunks of sequential data are encrypted with the same secure key and accommodated in an encrypted section. The process continues until the total size of the encrypted data substantially achieves the predefined size of the encrypted section. The next chunk of encrypted data will be accommodated in a subsequent encrypted section. The data in different encrypted sections may be encrypted with the same or with different secure keys. Also, as will be further detailed with reference to <figref idref="DRAWINGS">FIG. 6</figref>, the information in the index section facilitates one-to-one mapping between each point in the original data range and the data to be read from the logs after decryption.</p>
<p id="p-0091" num="0121">The encryption process will be further detailed reference to <figref idref="DRAWINGS">FIGS. 12</figref><i>a</i>) and <b>12</b><i>b</i>).</p>
<p id="p-0092" num="0122"><figref idref="DRAWINGS">FIGS. 4</figref><i>a</i>-<b>4</b><i>b </i>illustrate schematic diagrams of original and transformed logical data objects in accordance with certain embodiments of the present invention for file mode access, wherein transformation includes compression and encryption.</p>
<p id="p-0093" num="0123">The chunks of data (<b>402</b>-<b>1</b>-<b>402</b>-<b>4</b> illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>a</i>) comprised in an original LO (original file <b>401</b> in the illustrated embodiment) are sequentially transformed into data chunks (<b>408</b>-<b>1</b>-<b>408</b>-<b>4</b> illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>) accommodated into blocks <b>406</b>-<b>1</b>, <b>406</b>-<b>2</b> with a predefined size. Similar to compressed sections detailed with reference to <figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>-<b>2</b><i>b</i>, and encrypted sections detailed with reference to <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>b</i>, said blocks serve as atomic elements of compression/decompression and encryption/decryption operations during input/output transactions on the files. In the following description the term &#x201c;accommodation section (AS)&#x201d; will be used to any storing block configured to accommodate transformed data chunks (including compressed sections and encrypted sections described above) and serving as atomic elements for transforming/de-transforming operations in accordance with certain embodiments of the present invention. The accommodation sections may have equal predefined size, or, alternatively, during the transformation process the transformation system may select a predefined size for a certain accommodation section in accordance with predefined criterion.</p>
<p id="p-0094" num="0124">Processing the original chunks of data (<b>402</b>-<b>1</b>-<b>402</b>-<b>4</b>) into stored data chunks (<b>408</b>-<b>1</b>-<b>408</b>-<b>4</b>) comprises two processes: 1) compressing the original chunks into compressed data chunks (<b>403</b>-<b>1</b>-<b>403</b>-<b>4</b>), and 2) encrypting the compressed data chunks (<b>403</b>-<b>1</b>-<b>403</b>-<b>4</b>) into encrypted chunks (<b>404</b>-<b>1</b>-<b>404</b>-<b>4</b>) to be accommodated. The processes are synchronized and provided in parallel, i.e. the compression and encryption processes are coordinated with respect to time (synchronized processes) and concurrently execute autonomous sets of instructions (parallel processes) related, respectively, to compression and to encryption, while the compression, the encryption and the accommodation are provided in a manner preserving the sequence of the original chunks.</p>
<p id="p-0095" num="0125">In the embodiment illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>a </i>the synchronization of the processes is characterized by that each output chunk processed in the compression process serves as input chunk in the encryption process. Accordingly, the sequences of compressed and encrypted data chunks correspond to the sequence of the original data chunks. For example, compression of original chunks <b>402</b>-<b>1</b>-<b>402</b>-<b>3</b> into compressed chunks <b>403</b>-<b>1</b>-<b>403</b>-<b>3</b> finished and encryption of these resulted chunks into encrypted chunks <b>204</b>-<b>1</b>-<b>204</b>-<b>3</b> starts at points in time t<sub>s1</sub>-t<sub>s3 </sub>respectively. In the illustrated example the compression of the original chunk <b>402</b>-<b>4</b> into compressed chunk <b>403</b>-<b>4</b> is finished at t<sub>s4</sub>, while the encryption of the compressed chunk <b>403</b>-<b>3</b> into encrypted chunk <b>404</b>-<b>3</b> is not finished till this moment. The encryption of the sequential compressed chunk <b>403</b>-<b>4</b> into encrypted chunk <b>404</b>-<b>4</b> will start after the chunk <b>404</b>-<b>3</b> is encrypted (with delay &#x394;t after t<sub>s3 </sub>when the compression of the chunk <b>403</b>-<b>4</b> is finished).</p>
<p id="p-0096" num="0126">In certain embodiments of the invention each received chunk of original data is compressed and sent to be encrypted almost without keeping data in a cache and autonomously of processing the other received chunks. In other embodiments of the present invention a received chunk may be segmented or several received chunks may be compressed together and further encrypted as one compressed chunk.</p>
<p id="p-0097" num="0127">It should be noted that, as will be further detailed with reference to <figref idref="DRAWINGS">FIG. 7</figref>, the processing of chunks fitting certain criterion may include only compression, or only encryption, or neither of them, wherein the sequence of chunks during the processing and accommodation is retained as corresponding to the sequence of the received chunks.</p>
<p id="p-0098" num="0128">It should be noted that the invention is not bound by the illustrated way of synchronization and is, likewise, applicable to any other form of coordination in time compression and encryption processes, said coordination facilitating preserving the sequence of data chunks.</p>
<p id="p-0099" num="0129">As illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>, the processed chunks (<b>404</b>-<b>1</b>-<b>404</b>-<b>4</b>) are written to the accommodation sections (stored chunks <b>408</b>-<b>1</b>-<b>408</b>-<b>4</b>) in accordance with the order of receiving respective chunks of original data. The transformed LO (compressed and encrypted file <b>409</b> in the illustrated embodiment) comprises a header <b>405</b>, one or more accommodation sections <b>406</b> and one or more index sections (IS) <b>407</b>. The header <b>405</b> of the transformed file comprises a unique file descriptor, a flag indicating that the file is currently open (or a recovery status), information about the size of the original file <b>401</b>, and, optionally, a signature indicating whether the file was processed by the transformation system <b>16</b> (also for files which were not encrypted and/or compressed) by the transformation system as not fitting certain criterion, e.g., certain authorization marks, certain type of files, certain compression ratio, etc.). In certain embodiments of the invention the header may have a fixed length. The header and index sections will be further detailed with reference to <figref idref="DRAWINGS">FIGS. 5-10</figref>.</p>
<p id="p-0100" num="0130">In other embodiments of the present invention (e.g. in certain embodiments where encrypted/decrypted and/or compression/decompression functionalities are integrated with the storage device, etc.) the header <b>405</b> or any of its parts and combinations thereof may constitute a part of the file system. For example, a file identifier used in a certain file system (e.g. node ID) may be used as the unique file descriptor of the transformed file, a file record in the file system may be modified and comprise additional fields, e.g. for information about the size of the original file, said signature, etc. The index section or parts thereof may also constitute a part of the file system.</p>
<p id="p-0101" num="0131"><figref idref="DRAWINGS">FIGS. 4</figref><i>c</i>-<b>4</b><i>d </i>illustrate schematic diagrams of original and compressed and encrypted logical data objects in accordance with certain embodiments of the present invention for block mode access. The chunks of data comprised in the original LO are sequentially transformed into data chunks (<b>418</b>-<b>1</b>-<b>418</b>-<b>4</b> illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>d</i>) accommodated in the received order into accommodation sections <b>416</b>-<b>1</b>, <b>416</b>-<b>2</b>. Said original data chunks corresponding to the transformed data chunks (<b>418</b>-<b>1</b>-<b>418</b>-<b>4</b>) are virtually represented in the VLU <b>411</b> as data chunks (<b>412</b>-<b>1</b>-<b>412</b>-<b>4</b>) illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>c. </i></p>
<p id="p-0102" num="0132">Similar to embodiments detailed with reference to <figref idref="DRAWINGS">FIGS. 4</figref><i>a </i>and <b>4</b><i>b</i>, processing the original chunks of data (<b>412</b>-<b>1</b>-<b>412</b>-<b>4</b>) into stored data chunks (<b>418</b>-<b>1</b>-<b>418</b>-<b>4</b>) comprises two synchronized parallel processes: 1) compressing the original chunks into compressed data chunks (<b>413</b>-<b>1</b>-<b>413</b>-<b>4</b>), and 2) encrypting the compressed data chunks (<b>413</b>-<b>1</b>-<b>413</b>-<b>4</b>) into encrypted chunks (<b>414</b>-<b>1</b>-<b>414</b>-<b>4</b>) to be accommodated. Accordingly, the compression and encryption processes are coordinated with respect to time and execute autonomous sets of instructions related, respectively, to compression and to encryption, while the compression and the encryption are provided in a manner preserving the sequence of the original chunks. The synchronization of the processes is characterized by that each output chunk processed in the compression process selves as an input chunk in the encryption process. Accordingly, the sequences of compressed and encrypted data chunks correspond to the sequence of the original data chunks.</p>
<p id="p-0103" num="0133">As illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>d</i>, the processed chunks (<b>414</b>-<b>1</b>-<b>414</b>-<b>4</b>) are written to the accommodation sections (stored chunks <b>418</b>-<b>1</b>-<b>418</b>-<b>4</b>) in accordance with the order of receiving respective chunks of original data. The transformed LO (LU <b>419</b> comprising compressed and encrypted data) comprises a header <b>415</b>, one or more accommodation sections <b>416</b>, one or more index sections (IS) <b>417</b> and a free space <b>420</b>. The header <b>415</b> comprises a unique descriptor containing a logical unit number (LUN), the size of the virtual logical unit (VLU), the size of storage logical unit (optionally), an open/recovery flag, a signature indicating whether at least part of the storing data were processed by the transformation system <b>16</b>, etc.</p>
<p id="p-0104" num="0134">In other embodiments of the present invention (e.g. in certain embodiments when encryption/decryption and/or compression/decompression functionalities are integrated with the storage device, etc.) the header <b>415</b> or any of its parts and combinations thereof may constitute a part of disk attributes, the index section <b>417</b> may constitute a part of the disk attributes, etc.</p>
<p id="p-0105" num="0135">Thus, chunks of data comprised in the original logical data object (LO) of any type are sequentially transformed and accommodated in the received order in one or more accommodation sections, wherein the transformation comprises compressing and encrypting processes. Compressing the chunks may be provided similar to compressing transformation described with reference to <figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>-<i>b</i>. The initial k bytes of the data to be compressed are used as a dictionary. The same dictionary is used for compression of the first and subsequent chunks of sequential data to be compressed while the dictionary is adapted in accordance with processed data, e.g. per Lempel-Ziv algorithm. The process is continued for all chunks to be accommodated (after encryption) in a certain accommodation section (selection of a section for accommodation is further detailed with reference to <figref idref="DRAWINGS">FIG. 9</figref>). The initial k bytes of next chunk of original data to be accommodated in a subsequent accommodation section will be used for renewing the dictionary to be used for compressing the data to be accommodated in said subsequent accommodation section. In certain other embodiments of the invention a new compression sequence started in the new compressed section may use the same initial compression dictionary as the previous sequence.</p>
<p id="p-0106" num="0136">Each compressed chunk matching certain criterion is further encrypted before storing in respective accommodation section in a manner similar to detailed with reference to <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>b</i>. A block cipher encryption algorithm breaks plaintext data in the compressed chunks into fixed-size segments. The first and subsequent compressed chunks are encrypted with the same secure key and accommodated in an appropriate accommodation section. The process is continued until the total size of the encrypted data substantially achieves the predefined size of the accommodation section. The next encrypted chunk will be accommodated in a subsequent accommodation section. The data to be accommodated in different accommodation sections may be encrypted with the same or with different secure keys. The encryption process will be further detailed with reference to <figref idref="DRAWINGS">FIGS. 12</figref><i>a</i>-<b>12</b><i>b</i>. In certain embodiments of the invention the transformation system enters padding data (e.g. random characters, blanks, zeros, etc.) in one or more compressed chunks to enable the input of the block cipher to be an exact multiple of the segments size. When decrypting, the transformation system removes the padding data before decompression.</p>
<p id="p-0107" num="0137"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a schematic diagram of the transformed logical data object in accordance with certain embodiments of the present invention. As, by way of non-limiting example, was detailed with reference to <figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>-<i>b</i>, <b>3</b><i>a</i>-<i>b </i>and <b>4</b><i>a</i>-<i>d</i>, chunks of data comprised in the original logical data object (LO) of any type are transformed and sequentially accommodated in the received order in one or more accommodation sections (<b>505</b>A-<b>505</b>F) with predefined size. The accommodation sections serve as atomic elements of transforming/de-transforming operations during input/output transactions (data access-related requests) on the logical data objects. The transforming processing is configured in a manner enabling substantial identity between accommodation section if being de-transformed and the original data accommodated in said section as a result of transformation.</p>
<p id="p-0108" num="0138">The transformed LO <b>503</b> comprises the header <b>504</b>, one or more accommodation sections (<b>505</b>A-<b>505</b>F) and one or more index sections (<b>506</b>A, <b>506</b>B). The index section is not necessary if the transformed LO comprises one accommodation section only.</p>
<p id="p-0109" num="0139">In addition to the sequentially accommodated transformed data chunks, the accommodation section has a unique identifier (typically held in a header of the accommodation section). The indication of physical storage location pertaining to the accommodation section is stored in the accommodation section itself (e.g. in the header) and/or index section. The information related to external data involved in the transformation (e.g. information related to the secure key used for encryption of the data chunks comprised in the accommodation section as, for example, key ID, pointer to key physical location, metadata related to the key, etc.) may be stored in the accommodation section itself (e.g. in the section's header) and/or index section and/or header <b>504</b>.</p>
<p id="p-0110" num="0140">In certain embodiments of the present invention each accommodation section has an assigned flag (e.g. a bit flag 1 or 0) indicating use/re-use condition of the section stored in the accommodation section (e.g. in the header) and/or index section. Accordingly, each transformed chunk within a section has the same flag as the section. When accommodated, at a new physical location, the accommodation section is provided with flag 0. When accommodated at a physical location previously occupied by another accommodation section, the accommodation section is provided with a flag opposite of the flag of said another accommodation section being rewritten. Accordingly, new transformed data chunks being written to a certain physical location can be differentiated from old data chunks previously accommodated at said physical location into the old (being rewritten) accommodation section as having different flags. This process is further detailed with reference to <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0111" num="0141">For purpose of illustration only, the following description is made with respect to transformed data chunks accommodated in a log form (referred to hereinafter as logs). It should be noted that the invention is not bound by the log form and is, likewise, applicable to any other form of sequential accommodation of the processed chunks of data.</p>
<p id="p-0112" num="0142">In addition to the transformed data, each log comprises information (typically held in a log's header) in respect of an offset of the original chunk of data within the logical data object, size of said original chunk, and an identifier allowing associating the log with the accommodation section which accommodated the log (e.g. ID of the corresponding accommodation section plus flag indicating use/re-use of physical location of the section as described above, etc.). This information or parts thereof may be stored in transformed and/or non-transformed form. As will be further detailed for a case of encryption with reference to <figref idref="DRAWINGS">FIGS. 12</figref><i>a</i>-<b>12</b><i>b</i>, the logs may also comprise transformation-related information (e.g. initialization vector, key ID, etc.).</p>
<p id="p-0113" num="0143">In certain embodiments of the invention the intercepted control transaction (e.g. &#x201c;set end of file&#x201d;/truncate) are written to the accommodation section as a log sequential to the respective transformed data chunks and comprising a header with zero value of a data size field.</p>
<p id="p-0114" num="0144">The index section <b>506</b> comprises at least one entry associated with at least one accommodation section, this entry comprising pointer(s) (or other indicators) to physical storage location of the accommodation section and records related to the respective logs accommodated in the accommodation section (e.g. offset and size in the original/updated LO, association with the accommodation section, one or more flags assigned to the logs, etc.), said records referred to hereinafter as &#x201c;log records&#x201d;. Optionally the entry may comprise additional information as, for example, a signature indicating if at least part of logs accommodated in the accommodation section comprise data in non-encrypted, non-compressed or otherwise non-transformed form, one or more flags assigned to the accommodation section, dictionary used for compression of the section, information related to secure key used in the section, free size for accommodation in said accommodation section, indication of encryption, compression and/or other algorithms used during transformation (if variable), etc. In certain embodiments of the invention the index sections have equal predefined size.</p>
<p id="p-0115" num="0145">In certain embodiments of the invention the entry comprises only one, mostly updated log record in respect to each log. In other embodiments, e.g. as will be further detailed with reference to <figref idref="DRAWINGS">FIGS. 11</figref><i>a</i>-<b>11</b><i>b</i>, the entry may comprise updated and outdated records with respect to the same log.</p>
<p id="p-0116" num="0146">There are several ways of creating and/or updating the index section <b>506</b>. For example, the first index section may be created substantially when creating the transformed logical object and the following index section(s) (if any) may be created when there is no free space in the current (active) index section to accommodate a new entry. Alternatively, the first and/or the following index sections may be created at a certain time after storing the corresponding accommodation sections based on information thereof, but not later than closing the logical data object. The corresponding entries may be written/updated simultaneously with every update of the stored logical object, or at a certain later time (e.g. when starting a new accommodation section) based on data comprised in the accommodation sections, but not later than closing the logical data object. In a case of a failure, the index section(s) may be restored based on information comprised in the accommodation sections as will be further detailed with reference to <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0117" num="0147">In certain embodiments of the invention the header <b>504</b> comprises an indicator (e.g. pointer) to physical location of the first index section and each index section has an indicator to the next sequential index section. Said indicators constitute one or more links <b>507</b> connecting sequential index sections. Optionally, the header <b>504</b> may also comprise an indicator to the first accommodation section and each accommodation section may have an indicator to the next sequential accommodation section. Said indicators may constitute one or more links connecting sequential accommodation sections.</p>
<p id="p-0118" num="0148">Among advantages of certain embodiments of the present invention is the ability to transform and write variable size chunks of data wherein a predefined size accommodation section is used for de-transforming and reading.</p>
<p id="p-0119" num="0149">Referring to <figref idref="DRAWINGS">FIGS. 6</figref><i>a</i>-<i>b</i>, there are illustrated schematic diagrams of original and transformed logical data objects during an update process.</p>
<p id="p-0120" num="0150">In the example illustrated in <figref idref="DRAWINGS">FIG. 6</figref><i>a</i>, chunks of data <b>601</b>-<b>1</b>, <b>601</b>-<b>2</b> and <b>601</b>-<b>3</b> constituting the original LO are transformed, correspondently, into sequential logs <b>608</b>-<b>1</b>, <b>608</b>-<b>2</b> and <b>608</b>-<b>3</b> accommodated in the accommodation section <b>605</b>-<b>1</b>. The index section <b>606</b>-<b>1</b> comprises information related to said accommodation section and the logs thereof. By way of non-limiting example, the illustrated index section comprises accommodation section ID with a pointer to physical location (QWORD) and a list of respective records comprising offset (QWORD) and length (WORD) for each chunk of original data corresponding to the transformed chunks accommodated in the section. Generally, the index section also comprises an indicator (e.g. ID) of the next index section.</p>
<p id="p-0121" num="0151">The exemplified information in the index section means that data transformed into log <b>608</b>-<b>1</b> correspond to the range AB (offset A, length L<b>1</b>); data transformed into log <b>608</b>-<b>2</b> corresponds to the range BC (offset B, length L<b>2</b>); and data transformed into the log <b>608</b>-<b>3</b> correspond to range CD (offset C, length L<b>3</b>).</p>
<p id="p-0122" num="0152"><figref idref="DRAWINGS">FIG. 6</figref><i>b </i>illustrates an example of a case when a new data chunk <b>601</b>-<b>4</b> having length L<b>4</b> shall replace the data in the original LO starting from offset C<sub>1</sub>, where (C<sub>1</sub>+L<sub>4</sub>)=E&#x3c;D. The new chunk of data is transformed and accommodated in the accommodation section accommodating the previous transformed logs (referred to hereinafter as an active accommodation section) if said section comprises enough free space to accommodate said new log. If not, as illustrated in the example, the new accommodation section <b>605</b>-<b>2</b> will be opened to accommodate the new log <b>608</b>-<b>4</b>. The previously accommodated logs are kept unchanged, while the index section <b>606</b>-<b>1</b> is updated in a manner facilitating one-to-one relationship between each point in the original data range and the data to be read from the logs after de-transformation. In certain embodiments the index section comprises only last updated log records; in other embodiments the index section may comprise also old log records and special marking for differentiating between old and updated records. Keeping old records in addition to updated records may be useful for certain applications, for example, for continuous data protection as further detailed with reference to <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0123" num="0153">In the example illustrated in <figref idref="DRAWINGS">FIG. 6</figref><i>b </i>the index section comprises only last updated records. The updated information in the index section means that the updated range AD corresponds to the following data in the transformed logs: the range AB corresponds to data to be de-transformed from the log <b>608</b>-<b>1</b> in the accommodation section #<b>1</b> with physical location X, the range BC<sub>1 </sub>corresponds to the part of data (namely offset B, length L<b>2</b><sub>1</sub>) to be de-transformed from the log <b>608</b>-<b>2</b> in the accommodation section #<b>1</b> with physical location X, the updated range C<sub>1</sub>E corresponds to the new log <b>608</b>-<b>4</b> in the accommodation section #<b>2</b> with physical location Y, and the range ED corresponds to the part of data in log <b>608</b>-<b>3</b> (namely offset E, length L<b>3</b><sub>1</sub>) in the accommodation section #<b>1</b> with physical location X. In the illustrated example, all data comprised in the logs <b>608</b>-<b>1</b> and <b>608</b>-<b>4</b> are live, while part of the data comprised in the logs <b>608</b>-<b>2</b> (namely range C<sub>1</sub>C) and <b>608</b>-<b>3</b> (namely range CE) are outdated. Updating the index section is falter detailed with reference to <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0124" num="0154">Referring to <figref idref="DRAWINGS">FIG. 7</figref>, there is illustrated a generalized flowchart of creating transformed logical data object in accordance with certain embodiments of the present invention. Upon receiving request <b>710</b> to store a LO, the transformation system writes <b>711</b> the header of the transformed LO to appropriate storage location (e.g. next to the end of previous stored logical data object), and allocates 1<sup>st </sup>accommodation section to accommodate the processed data. The initial header's record comprises the indication of transformation status (e.g. flag &#x201c;ON&#x201d; meaning that transformation is &#x201c;in progress&#x201d;; optionally, separate flags for different processes comprised in the transformation process, etc.). The transformation system also prepares <b>712</b> information (e.g. offset, size of data, etc.) related to the data chunk to be transformed.</p>
<p id="p-0125" num="0155">In accordance with certain embodiments of the invention, the transformation system is configured to hold certain criteria to be matched during transformation. The criteria may be related to characteristics of the logical data object, data chunk and/or accommodation section and/or transforming operation or parts thereof. The criterion may be, for example, maximal length L<sub>max </sub>of data to be transformed as one log; and/or maximal time T<sub>max </sub>of receiving original data to be transformed as one log; certain relationships between original and transformed data chunks and/or LO (e.g. minimal estimated or actual compression ratio; pre-defined type and/or format of data and/or LO, etc.</p>
<p id="p-0126" num="0156">In certain embodiments of the invention the predefined criterion may be related to transformation time of a data chunk and/or entire logical data object (e.g. maximal, estimated or actual, time of transformation (or steps thereof) of data chunk. This transformation time related criterion may be limited by operational system time out, characteristics of storage network and/or storage device, reliability requirements, etc. In some embodiments this criterion may be, for example, actual transformation time of a data chunk, while in other embodiments this criterion may include, for example, chunk size, and/or type of data and/or compression algorithm and/or other characteristics and a combination thereof allowing estimating the expected transformation time of the data chunk. Accordingly, characteristics of the chunk to be obtained for comparing with this criterion may be the characteristics allowing estimating the expected transformation time or actually measured time of transformation. For transformation comprising more than one process (e.g. compression and encryption), the transformation time criterion may be related to each process separately and/or to the entire transformation process.</p>
<p id="p-0127" num="0157">The transformation system further verifies <b>713</b> if the data chunk to be transformed fits a predefined criterion. The verification comprises obtaining certain characteristics of the chunk and/or accommodation section and/or transformation operation, and comparing them with said criterion. The characteristics may be obtained, for example, by identifying certain parameters of the chunks (e.g. type of logical object, authorization marks, size, etc.), and/or by estimation of expected transformation results based upon observable characteristics (e.g. size, type of data, etc.), and/or by providing actual transformation (or parts thereof) and identifying result(s).</p>
<p id="p-0128" num="0158">If the criterion is matched, the transformation system processes <b>714</b> the data chunk and facilitates its accommodation in the accommodation section as a log comprising the data in transformed form. The previously prepared log-related information (offset, size, etc.) may be written within the log in transformed and/or non-transformed form. Said information may also comprise indication (e.g. flag) of form of data comprised in the log (e.g. transformed, not transformed, partly transformed).</p>
<p id="p-0129" num="0159">If the criterion is not matched (e.g., if the raw data chunk is transformed or supposed to be transformed during a period exceeding, for example, 30 milliseconds, and/or compressed to not less than X% (say 95%) of the original size, etc.), then the transformation system facilitates <b>715</b> accommodation of the data chunk in the accommodation section as a log comprising data in non-transformed form. For transformation comprising more than one process the data chunks may be accommodated in partly transformed form. For example, referring back to the example illustrated with reference to <figref idref="DRAWINGS">FIG. 4</figref>, the compression of the original chunk <b>402</b>-<b>4</b> into compressed chunk <b>403</b>-<b>4</b> is finished at t<sub>s4</sub>, while the encryption of the compressed chunk <b>403</b>-<b>3</b> into encrypted chunk <b>404</b>-<b>3</b> is not complete till this moment. In certain embodiments the transformation system may be configured to support transformation time-related criterion requiring zero delay between end of compression and start of encryption of the respective data chunk (and/or limited time of overall transformation process). In this case the transformation system may stop (or do not start) the encryption of the compressed chunk <b>403</b>-<b>3</b>, and accommodate the respective chunk <b>408</b>-<b>3</b> in partly transformed form. Alternatively, the transformation system may omit compressing the chunk (e.g. if there is an additional requirement to keep all data encrypted), encrypt non-compressed data comprised in the chunk <b>402</b>-<b>3</b> and accommodate the respective chunk <b>408</b>-<b>3</b> in partly transformed form.</p>
<p id="p-0130" num="0160">Among advantages of processing in accordance with the transformation time related criterion is the ability to facilitate transformation of a logical data object within a predefined time window, accordingly, to facilitate, for example, on-line transformation while keeping data integrity, accessibility and availability, etc.</p>
<p id="p-0131" num="0161">For fitting a certain criterion as, for example, maximal length L<sub>max </sub>of data to be transformed as one log and/or maximal time T<sub>max </sub>of receiving original data to be transformed as one log, the transformation system is configured to segment the received data range L and to process each segment as a separated chunk.</p>
<p id="p-0132" num="0162">Those skilled in the art will readily appreciate that in certain embodiments of the invention the operation <b>713</b> of verifying match to certain criterion may be configured to be omitted (and/or the criterion may be setup as &#x201c;any chunk&#x201d;), and accordingly, all data chunks shall be transformed by the transformation system.</p>
<p id="p-0133" num="0163">After processing (<b>714</b> or <b>715</b>) of a given data chunk is completed, the compression system prepares log-related information to be recorded in the index section.</p>
<p id="p-0134" num="0164">The transformation system further checks <b>716</b> if the raw logical data object comprises non-processed data and repeats <b>717</b> the process for the next data chunk until at least one of the following is achieved: a) all data in the LO are processed; b) there is not enough free space in the active accommodation section to accommodate the next transformed data chunk. The transformation system updates <b>718</b> the index section, sends acknowledgement to the clients <b>11</b> and/or servers <b>12</b> and, if started new AS, releases the access protection to the data in the previous accommodation section if said protection was provided on a AS level. The update of the index section may be provided substantially in parallel with acknowledgement, when allocating the new AS and/or closing the LO and/or in accordance with other predefined rules.</p>
<p id="p-0135" num="0165">As will be further detailed with reference to <figref idref="DRAWINGS">FIG. 9</figref>, if the free space in the active accommodation section is insufficient to accommodate the next data chunk (e.g. writing operation fails on target buffer overflow, estimated expected log size more than said free space, free space is less than size of data chunk to be processed or predefined part thereof, etc.), but still not all data in the LO are processed, the transformation system allocates new accommodation section and repeats <b>719</b> the operations for new data chunk(s). When all data are processed, the transformation system releases the access protection of the LO (if said protection was provided for the entire LO).</p>
<p id="p-0136" num="0166">The entries in the index section will comprise indication of transformed/non-transformed/partly transformed form of data accommodated in each of accommodation sections. This indication may be provided for entire accommodation section and/or each accommodated log. The header is provided with corresponding indication of the status of the transformed LO. In certain embodiments of the invention this indication may be flag &#x201c;OFF&#x201d; (or other similar indication) meaning that the processing is &#x201c;completed&#x201d;, regardless of form of data accommodated in the accommodation sections. In other embodiments of the invention the flag &#x201c;OFF&#x201d; may be provided only when all accommodation sections comprised in the compressed LO accommodate data in the transformed form; until this moment the flag (or other indication) in the header may be kept &#x201c;ON&#x201d; or have some special indication that the processing is completed, but still some data are non-transformed or partly transformed.</p>
<p id="p-0137" num="0167">Certain embodiments of the invention may further comprise postponed transformation of non-transformed or partly transformed data accommodated in at least one accommodation section. Such postponed transformation may be provided in accordance with a predefined/configurable time schedule (e.g. during non-working hours), per pre-defined event (e.g. administrator's request, absence of data access-related request to given LO during predefined/configurable period of time, available network bandwidths fitting predefined/configurable criteria, etc.).</p>
<p id="p-0138" num="0168">The process described with reference to <figref idref="DRAWINGS">FIG. 7</figref> may be likewise applicable for updating existing logical data objects.</p>
<p id="p-0139" num="0169">In certain embodiments of the invention, the criterion may be negative, for example data chunks may be accommodated in non-transformed or partly transformed form by default, unless they match certain criterion (e.g. data type and/or application). Implementation of such embodiments is illustrated, by way of non-limiting example, in <figref idref="DRAWINGS">FIG. 8</figref> for a case of compressing transformation.</p>
<p id="p-0140" num="0170">Upon receiving request <b>810</b> to store a LO, the transformation system writes <b>811</b> the header of the transformed LO to appropriate storage location, and allocates 1<sup>st </sup>accommodation section to accommodate the processed data. The initial header's record comprises the indication of transformation status (e.g. flag &#x201c;ON&#x201d; meaning that transformation is &#x201c;in progress&#x201d;; optionally, separate flags for different processes comprised in the transformation process, etc.). The transformation system also prepares <b>812</b> information (e.g. offset, size of data, etc.) related to the data chunk to be accommodated. The transformation system further writes <b>813</b> the data chunk to the accommodation section as a log comprising the data in non-compressed form. Optionally, before operation <b>813</b>, the transformation system verifies if the data chunk fits a predefined criterion requiring (e.g. mandatory or in accordance with further criterion) its compression before writing. The transformation system may further provide data padding to fit the entire size of accommodated data chunks to the size of AS.</p>
<p id="p-0141" num="0171">The transformation system further checks <b>814</b> if the raw logical data object comprises non-processed data, updates <b>815</b> the index section, and sends acknowledgement to the clients <b>11</b> and/or servers <b>12</b>. The process is repeated <b>816</b> for the next data chunk until all data in the LO are processed and accommodated (<b>817</b>, <b>816</b>) in one or more accommodation sections thus giving rise to the transformed logical data object stored in accordance with certain embodiments of the present invention.</p>
<p id="p-0142" num="0172">The log records in the index section comprise indication of compressed/non-compressed form of data in the accommodated logs; likewise, the indication may be provided for entire accommodation section. The transformation system is scanning the accommodation section to find out one or more AS comprising non-compressed data, provides compression of the accommodated data, and sequentially accommodates <b>818</b> the compressed data in newly allocated AS(s). The old accommodation section is released <b>818</b> as was described, for example, with reference to <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0143" num="0173">Referring to <figref idref="DRAWINGS">FIG. 9</figref>, there is illustrated a generalized flowchart of write operation on transformed logical data object (LO) in accordance with certain embodiments of the present invention. A &#x201c;write&#x201d; request <b>90</b> identifies the offset in the LO and the range L of data to write. The transformation system checks if there is an allocated accommodation section, and, if not found, allocates <b>91</b> an active accommodation section (AS accommodating the last log). Further, the transformation system checks if the data range does not exceed predefined maximal length L<sub>max </sub>of original data to be transformed as one log and creates a record comprising the offset, length and data to be transformed; assigns to this record a flag corresponding to the flag of allocated AS; and transforms <b>92</b> (e.g. compresses, encrypts, compresses &#x26; encrypts, etc.) said record. When applicable for certain transformation, the compression is provided with the same dictionary and/or the encryption is provided with the same key for encryption as the previous chunk of data.</p>
<p id="p-0144" num="0174">The resulting log is written <b>93</b> to the active accommodation section if the last comprises enough free space to accommodate the log. The respective information (if any) related to the secure key (or other external data involved in the transformation) is stored in the logs and/or in the accommodation section (e.g. section header) and/or in the index section in non-encrypted form.</p>
<p id="p-0145" num="0175">If the free space is insufficient (e.g. writing operation fails on target buffer overflow, estimated expected log size more than said free space, etc.) the transformation system allocates <b>94</b> a new accommodation section. Allocation of the new AS includes assigning the physical location and assigning the flag as described with reference to <figref idref="DRAWINGS">FIG. 5</figref>. In certain embodiments of the invention allocating of new AS may include also writing a pointer to said section in the currently active AS.</p>
<p id="p-0146" num="0176">If the free space in the active AS is insufficient to accommodate the entire log, but meets a predefined criterion (e.g. more than predefined size, more than predefined ratio of entire required space, etc.), the transformation system splits <b>95</b> the original chunk into two parts and processes them into two logs, writing one in the active AS and the second in the new AS. In certain embodiments of the invention, the transformation system de-transforms (e.g. decrypts and/or decompresses the active AS) or otherwise calculates or estimates the entire size of original data accommodated in the active AS, and estimates the size of original data to be added so that the transformed size of entire data substantially matches the predefined size of AS, thus enabling the split with maximal filling of the active AS.</p>
<p id="p-0147" num="0177">If the free space in the active AS does not meet said criteria, the entire log will be written <b>96</b> in the new accommodation section. In certain embodiments of the invention writing the first log to a new AS may be followed by marking the previously active AS as full and/or virtually &#x201c;correcting&#x201d; the length of the last log (e.g. by padding data) as if the entire size of the accommodated logs is equal to the predefined size of AS. When closing the LO, the accommodation section active to that moment (i.e. with the last accommodated chunks) may be reduced to its real size.</p>
<p id="p-0148" num="0178">After the log is written at the storage location, the transformation system sends acknowledgement <b>97</b> to the clients <b>11</b> and/or servers <b>12</b>. The update <b>98</b> of the index section may be provided substantially in parallel with acknowledgement, when allocating the new AS and/or closing the LO and/or in accordance with other predefined rules.</p>
<p id="p-0149" num="0179">If the data range L to be written exceeds the predefined maximal length L<sub>max </sub>of original data to be transformed as one log, the transformation system segments the original data in accordance with L<sub>max </sub>and repeats the process for each segmented chunk of data until all the data to be written are processed and accommodated into the accommodation section(s). Likewise, if the time of receiving the data range to be written exceeds the predefined maximal time T<sub>max </sub>of receiving original data to be transformed as one log, the transformation system segments the data range L in accordance with T<sub>max </sub>and repeats the process for each segmented chunk.</p>
<p id="p-0150" num="0180">The index section update includes adding a log record related to a new log and updating, accordingly, previous log records related to live and/or outdated data comprised in the corresponding range. Said new log record comprises information related to the offset (Pos<sub>L</sub>) and size (Size<sub>L</sub>) of the original chunk transformed into said log, as well as identification and, optionally, flag of the corresponding accommodation section. The update of appropriate log records may be provided in accordance with the following procedure:
<ul id="ul0008" list-style="none">
    <li id="ul0008-0001" num="0000">
    <ul id="ul0009" list-style="none">
        <li id="ul0009-0001" num="0181">1) look over all log records (Pos, Size) in the index section(s) for log record comprising position (Pos) such that Pos&#x2266;Pos<sub>L</sub>&#x3c;Pos+Size<sub>L</sub>:
        <ul id="ul0010" list-style="none">
            <li id="ul0010-0001" num="0182">a. if found, update such log record to (Pos, Pos<sub>L</sub>&#x2212;Pos), and go to 2);</li>
            <li id="ul0010-0002" num="0183">b. if not found&#x2014;end update.</li>
        </ul>
        </li>
        <li id="ul0009-0002" num="0184">2) compare Size<sub>L </sub>with Size&#x2212;Pos<sub>L</sub>&#x2212;Pos:
        <ul id="ul0011" list-style="none">
            <li id="ul0011-0001" num="0185">a. if more, find all log records (Pos<sub>1</sub>, Size<sub>1</sub>) such that Pos<sub>L</sub>&#x2266;Pos<sub>1</sub>&#x3c;Pos<sub>L</sub>+Size<sub>L</sub>. Among said log records find log record with maximal position, update it to (Pos<sub>L</sub>+Size<sub>L</sub>, Size<sub>1</sub>&#x2212;(Size<sub>L</sub>&#x2212;Pos<sub>1</sub>)), delete other log records among said log records and end update;</li>
            <li id="ul0011-0002" num="0186">b. if less, add log record (Pos<sub>L</sub>+Size<sub>L</sub>, Size&#x2212;(Pos<sub>L</sub>+Size<sub>L</sub>&#x2212;Pos)) and end update;</li>
            <li id="ul0011-0003" num="0187">c. if equal, end update.</li>
        </ul>
        </li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0151" num="0188">Those skilled in the art will readily appreciate that the invention is, likewise, applicable to any other procedure of index section update facilitating one-to-one relationship between data in the original range and data to be de-transformed from the logs. For example, the update may be provided in accordance with the following recursive procedure:
<ul id="ul0012" list-style="none">
    <li id="ul0012-0001" num="0000">
    <ul id="ul0013" list-style="none">
        <li id="ul0013-0001" num="0189">1) prepare new log record comprising position (Pos<sub>L</sub>) and size (Size<sub>L</sub>).</li>
        <li id="ul0013-0002" num="0190">2) look over all log records (Pos, Size) in the index section(s) for log record comprising position (Pos) such that Pos&#x2266;Pos<sub>L</sub>&#x3c;Pos+Size<sub>L</sub>:
        <ul id="ul0014" list-style="none">
            <li id="ul0014-0001" num="0191">a. if found, update such log record to (Pos, Pos<sub>L</sub>&#x2212;Pos), and go to 3);</li>
            <li id="ul0014-0002" num="0192">b. if not found, add log record (Pos<sub>L</sub>, Size<sub>L</sub>) to the index table and end update.</li>
        </ul>
        </li>
        <li id="ul0013-0003" num="0193">3) compare Size<sub>L </sub>with Size&#x2212;Pos<sub>L</sub>&#x2212;Pos:
        <ul id="ul0015" list-style="none">
            <li id="ul0015-0001" num="0194">a. if more, add log record (Pos<sub>L</sub>, Size&#x2212;Pos<sub>L</sub>&#x2212;Pos). Change Pos<sub>L </sub>to new Pos<sub>L</sub><sup>1</sup>=Pos+Size and change Size<sub>L </sub>to Size<sub>L</sub><sup>1</sup>=Size<sub>L</sub>&#x2212;(Pos<sub>L</sub><sup>1</sup>&#x2212;Pos<sub>L</sub>) and return to 2).</li>
            <li id="ul0015-0002" num="0195">b. if less, add log records (Pos<sub>L</sub>, Size<sub>L</sub>) and (Pos<sub>L</sub>+Size<sub>L</sub>, Size&#x2212;(Pos<sub>L</sub>+Size<sub>L</sub>&#x2212;Pos)) and end update;</li>
            <li id="ul0015-0003" num="0196">c. if equal, add log record (Pos<sub>L</sub>, Size<sub>L</sub>) and end update.</li>
        </ul>
        </li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0152" num="0197">It should be noted that among advantages of certain embodiments of the present invention is the ability of writing the new data without decrypting and/or decompressing or otherwise de-transforming already written data and/or otherwise rewriting the written data. Only new data are transformed and accommodated, while the index section is updated accordingly and is configured to assist in reading the transformed logical data object.</p>
<p id="p-0153" num="0198">Referring to <figref idref="DRAWINGS">FIG. 10</figref>, there is illustrated a generalized flowchart of read operation on transformed logical data object (LO) in accordance with certain embodiments of the present invention.</p>
<p id="p-0154" num="0199">The read operation starts with read request <b>100</b> identifying the offset of data in the LO and the range of data to read. The transformation system <b>16</b> addresses all index sections (e.g. sequentially starting from the last section or from the currently open; or opening all together, etc.) to find out <b>101</b> all last updated entries related to the data within the range. As was detailed with reference to <figref idref="DRAWINGS">FIG. 5</figref>, the last-updated entries in the index section facilitate one-to-one relationship between the data in the range and the live (mostly updated) data to be extracted from the transformed data chunks (logs). Accordingly, the transformation system sequentially de-transforms <b>102</b> (e.g. decrypts, decompresses, etc.) one of the accommodation sections corresponding to found entries, finds the required data <b>83</b>. In certain embodiments of the invention the operation <b>102</b> starts with accommodation section comprising data from the very end of the range to be read. The operations <b>102</b>-<b>103</b> are repeated <b>104</b> to the next accommodation section(s) until all data from the range have been found. The found data are arranged <b>105</b> in accordance with their order in the range. After the data are ready, they may be sent <b>106</b> to an application.</p>
<p id="p-0155" num="0200">In certain embodiments of the invention the stored transformed logical object may be optimized. The optimization may be provided by scanning the accommodation sections (e.g. by analyzing entries in the index section(s)) to find out one or more AS comprising more than predefined percent (e.g. 90%) of outdated data. Such AS are de-transformed, the live data are extracted and transformed and stored in the active accommodation section as a new log(s) and the old accommodation section is released. The transformation system keeps the list of released accommodation sections and uses the corresponding physical location when allocating a new accommodation section. As was described with reference to <figref idref="DRAWINGS">FIG. 5</figref>, the new allocated AS and logs thereof will have the flag opposite to the flag of the old accommodation section. Said optimization may be provided when closing the logical object, per predefined schedule, pre-defined event(s), etc.</p>
<p id="p-0156" num="0201">Among advantages of certain embodiments of the present invention is the capability to recover (and/or create) an index section in accordance with information comprised in the accommodation section. For example, if the recovery flag of the opening logical data object is &#x201c;ON&#x201d;, the transformation system initiates a recovery process. The recovery process starts with checking if the transformed logical object comprises one or more non-indexed accommodation sections (i.e. the accommodation sections do not comprise at least one log having a corresponding log record in at least one index section).</p>
<p id="p-0157" num="0202">During recovery, the logs in such non-indexed AS are sequentially de-transformed in reverse order starting from the last log until (if) a log with an opposite flag is found (i.e. a log that belongs to the old and released AS, and comprises outdated data). The transformation system generates entries corresponding to the de-transformed logs, saves them in the memory and/or writes to the index section. The logs are transformed back (and/or are temporary kept de-transformed, e.g. decrypted, decompressed, etc., if the recovered accommodation section comprises data to be read) and the recovery flag is switched to &#x201c;OFF&#x201d;.</p>
<p id="p-0158" num="0203">A failure may also occur when, for example, a new log has been provided with the corresponding log record in the index section, but other appropriate entries have not been updated yet. When reading such a transformed logical object, the transformation system may find inconsistency between data (more than one entry for the same point in the range) and correct the index section in accordance with the mostly updated entries (corresponding to latest logs related to the same range).</p>
<p id="p-0159" num="0204">Referring to <figref idref="DRAWINGS">FIG. 11</figref><i>a</i>, there is illustrated a generalized flowchart of read operation in response to data request with specified point in time to be read. As was detailed with reference to <figref idref="DRAWINGS">FIGS. 2-9</figref>, the new data chunks are transformed and written for storage without de-transforming and/or otherwise rewriting already written data, while the index section is updated accordingly. Each entry of the index section comprises pointer(s) (or other indicators) to physical storage location of the accommodation section and one or more log records. Also it was detailed that, simultaneously with the last-updated records, the entry may comprise previously-updated (and/or original) records related to the same logs and special marking for differentiating between old and updated records. In accordance with certain embodiments of the present invention each log record comprises or is otherwise associated with time stamps indicating the time of updating said log record and respective offset and length of data to be read in accordance with said log record, wherein the entry comprises one or more log records with respect to the same log and bearing different time stamps. Among advantages of such technique is a capability of keeping every change made to data and time thereof, which allows a user or an administrator to access historical data by specifying the desired point in time or time range.</p>
<p id="p-0160" num="0205">The read operation starts with read request <b>110</b> indicating the desired point in time to be accessed and identifying the respective offset and length of data to be read. The transformation system <b>16</b> addresses all index sections (e.g. sequentially starting from the last section or from the currently open; or opening all together, etc.) to find out <b>111</b> corresponding entries, i.e. entries related to the data within the range and comprising log records with time stamps prior or equal to the desired time T. The transformation system further selects <b>112</b> the last updated entries/log records among said corresponding entries/log records, sequentially de-transforms <b>113</b> (e.g. decrypts, decompresses, etc.) one of the accommodation sections corresponding to the selected entries, finds the required data <b>114</b> and keeps them in cache. The operations <b>113</b>-<b>114</b> are repeated <b>115</b> to the next accommodation section(s) until all data from the range and corresponding to desired point in time have been found. The found data are arranged <b>116</b> in accordance with their order in the range. After the data are ready, they may be sent <b>117</b> to an application.</p>
<p id="p-0161" num="0206">Likewise, the read operation may be provided for several desired points in time simultaneously. It should be noted that although the described embodiments allow reading different versions of the original data, there is still kept a one-to-one relationship between each point in the original data range and the data to be read from the logs after de-transformation.</p>
<p id="p-0162" num="0207">The transformation system may further provide optimization of the stored transformed logical object in a manner similar to detailed with reference to <figref idref="DRAWINGS">FIG. 10</figref>. The optimization may be provided by analyzing entries in the index section(s)) to find out one or more outdated AS, i.e. AS comprising more than predefined percent (e.g. 90%) of data associated with time stamps meeting certain criterion, such data are considered outdated. The criterion may be related to time (e.g. time stamps prior to predefined and/or pre-configurable time), and/or number of time stamps related to the same point in the original data (i.e. not more than three time stamps and, accordingly, backward saved changes), and/or certain events (e.g. providing full backup of the stored data), etc. Such outdated AS is de-transformed, the live data are extracted and transformed and stored in the active accommodation section as a new log(s) keeping originally associated time stamps, and the old accommodation section is released. Said optimization may be provided when closing the logical object, per predefined schedule, pre-defined event(s), etc.</p>
<p id="p-0163" num="0208">Referring to <figref idref="DRAWINGS">FIG. 11</figref><i>b</i>, there is illustrated a schematic diagram of index section illustrated with reference to <figref idref="DRAWINGS">FIG. 6</figref><i>b </i>and comprising time stamps in accordance with certain embodiments of the present invention.</p>
<p id="p-0164" num="0209">As was illustrated with reference to <figref idref="DRAWINGS">FIGS. 6</figref><i>a</i>-<i>b</i>, chunks of data <b>601</b>-<b>1</b>, <b>601</b>-<b>2</b> and <b>601</b>-<b>3</b> constituting the original LO were transformed into sequential logs <b>608</b>-<b>1</b>, <b>608</b>-<b>2</b> and <b>608</b>-<b>3</b> accommodated in the accommodation section #<b>1</b>. New data chunk <b>601</b>-<b>4</b> having length L<b>4</b> has further replaced the data in the original LO starting from offset C<sub>1</sub>, where (C<sub>1</sub>+L<b>4</b>)=E&#x3c;D. The index section <b>118</b> illustrated in <figref idref="DRAWINGS">FIG. 11</figref><i>b </i>comprises log records with time stamps, the log records informing the range AB (offset A, length L<b>1</b>) was transformed into log <b>608</b>-<b>1</b> accommodated at 11:00, the range BC (offset B, length L<b>2</b>) was transformed into log <b>608</b>-<b>2</b> accommodated at 11:01; the range CD (offset C, length L<b>3</b>) was transformed into the log <b>608</b>-<b>3</b> accommodated at 11:16. Accommodation at 12:03 of log <b>608</b>-<b>4</b> corresponding to the updated range C<sub>1</sub>E (offset C<sub>1</sub>, length L<b>4</b>) was followed by update of relevant log records. Accordingly, log records of the log <b>608</b>-<b>2</b> and <b>608</b>-<b>3</b> were updated at 12:03. The updated log records mean that the log <b>608</b>-<b>2</b> comprises live data corresponding to offset B, length L<b>2</b><sub>1</sub>, and the log <b>608</b>-<b>3</b> comprises live data corresponding to offset E, length L<b>3</b><sub>1</sub>. If the read request comprises, for example, desired time 12:30, the transformation system will find all log records with time stamp less than 12:30 and will select the last-updated (<b>608</b>-<b>1</b>-<b>1</b>, <b>608</b>-<b>2</b>-<b>2</b>, <b>608</b>-<b>3</b>-<b>2</b>, <b>608</b>-<b>42</b>) records indicating what data are relevant to the desired point in time. If the read request comprises, for example, desired time 11:10, the transformation system will find all log records with time stamp less than 11:100 and will select the last-updated (<b>608</b>-<b>1</b>-<b>1</b>, <b>608</b>-<b>2</b>-<b>1</b>) accordingly.</p>
<p id="p-0165" num="0210">Referring to <figref idref="DRAWINGS">FIG. 12</figref><i>a</i>, there is a schematic diagram illustrating a non-limiting example of encrypting a plaintext chunk (e.g. original chunk, compressed chunk, otherwise transformed chunk) in accordance with certain embodiments of the present invention.</p>
<p id="p-0166" num="0211">In the illustrated embodiment the transformation system is capable to break a plaintext chunk into segments with fixed-size A (when necessary, the segments are rounded to said fixed size) and to encrypt each plaintext segment of the chunk into encrypted segment with fixed-size B, rounding the encrypted segments, when necessary, to said fixed size B. In the illustrated embodiments A=B=16 byte. When rounding, the transformation system enters padding data (e.g. random characters, blanks, zeros, and nulls) to satisfy the data segment size requirements. In such embodiments the size of accommodation section may be defined as a multiple of the fixed size B.</p>
<p id="p-0167" num="0212">As was detailed with reference to <figref idref="DRAWINGS">FIGS. 3-6</figref>, the logs accommodated in the same accommodation section are encrypted with the same secure key. The security may be further increased by introducing additional cryptographic variance for different logs, e.g. initialization vector (IV). The initialization vector is a non-secret continuously changing number used as an initializing input algorithm for the encryption of a plaintext block sequence. Accordingly, in certain embodiments of the present invention, the transformation system is configured to obtain (e.g. generate as a random number) initialization vectors to be used together with secure key for encryption of the compressed chunks into encrypted logs. The IVs are accommodated in headers of respective logs.</p>
<p id="p-0168" num="0213">By way of non-limiting example, the transformation system may implement known in the art Advanced Encryption Standard (AES) by US National Institute of Standards and Technology (NIST). The AES algorithm is capable of using cryptographic keys of 128, 192, and 256 bits to encrypt and decrypt data in blocks of 128 bits. As known in the art, certain modes of AES algorithm enable to use the initialization vector (IV) linearly added to (XORed with) the first chunk of plaintext or included in front of the plaintext prior to encryption with the secure key. Accordingly, the transformation system may be configured to generate (e.g. randomly) initialization vectors for the first log in each accommodation section, and further generate the IVs for sequential logs by applying XOR operation.</p>
<p id="p-0169" num="0214">As the accommodation section serves as an atomic element of encryption/decryption operations, the initial IV and secure key related information may be held, in certain embodiments, in an accommodation section header with no need for accommodation in the logs headers.</p>
<p id="p-0170" num="0215">As illustrated by way of non-limiting example in <figref idref="DRAWINGS">FIG. 12</figref><i>a</i>, plaintext chunks (e.g. original chunks, compressed chunks, otherwise transformed chunks, etc.) <b>1201</b>-<b>1</b> (size 33 bytes), <b>1201</b>-<b>2</b> (size 50 bytes) and <b>1201</b>-<b>3</b> (size 17 bytes) are encrypted with the same key into respective sequential logs <b>1207</b>-<b>1</b> (size 48 bytes, including 15 bytes of padding data+header), <b>1207</b>-<b>2</b> (size 64 bytes, including 14 bytes of padding data+header) and <b>1207</b>-<b>3</b> (size 32 bytes, including 15 bytes of padding data+header) accommodated in the accommodation section <b>1205</b>-<b>1</b>. As illustrated, the sizes of the encrypted data in the logs are rounded as multiples of 16. Each log comprises information (e.g. in a log header) about actual size of original data encrypted in respective log and, optionally, respective initialization vector and size of chunk before encryption (if differs from the original chunk). The information related to the secure key and initial initialization vector may be stored in the accommodation section (e.g. AS header) and/or index section and/or header <b>1204</b> of the transformed logical data object.</p>
<p id="p-0171" num="0216">In accordance with certain embodiments of the present invention illustrated in <figref idref="DRAWINGS">FIG. 12</figref><i>b</i>, plaintext chunks <b>1201</b>-<b>1</b> (size 33 bytes), <b>1201</b>-<b>2</b> (size 50 bytes) and <b>1201</b>-<b>3</b> (size 17 bytes) are encrypted by the same encryption engine as in <figref idref="DRAWINGS">FIG. 12</figref><i>a</i>, but in a manner enabling to substantially eliminate padding data in the encrypted logs. A first plaintext chunk is divided in two parts, the first part being referred to hereinafter as &#x201c;primary data&#x201d;, comprises sequential data starting from the offset and satisfies the data segment size requirements (e.g. multiples of 16 bytes), and the second part comprises the rest of the data less than said data segment size and is referred to hereinafter as &#x201c;tail data&#x201d; (in the examples illustrated there are less than 16 bytes). The first part is encrypted and accommodated in the accommodation section in a manner described with reference to <figref idref="DRAWINGS">FIGS. 3-6</figref>; the respective log is referred to hereinafter as &#x201c;primary log&#x201d;. The second part with tail data is processed as a separate sequential chunk and is accommodated in the accommodation section in encrypted (or, alternatively, non-encrypted) form as a log (referred to hereinafter as &#x201c;tail log&#x201d;). The logs <b>1221</b> in the accommodation section correspond to the divided chunk <b>1211</b>, wherein the numbers in bold italics illustrate the respective data sizes.</p>
<p id="p-0172" num="0217">When processing a next chunk, the encryption system obtains the plaintext tail data from the tail log, adds said tail data at the beginning of said next chunk, divides the generated combination in primary data and tail data in a manner above; then encrypts the primary data in the primary log and the tail data in the tail log using the same secure key. The new primary log shall be accommodated at a position after the previous primary log. Total actual size of plaintext data accommodated in the logs is updated respectively (to 83 bytes in the current example). Total actual size of respective plaintext data is held and maintained in the header of the accommodation section and/or encrypted logical data object. As the size of encrypted data in the primary logs is equal to the size of plaintext primary data, it is not necessary to keep in the logs information about actual size of respective plaintext data. The information related to the secure key and initial initialization vector may be stored in the encrypted section (e.g. AS header) and/or index section and/or header <b>1204</b> of the encrypted logical data object.</p>
<p id="p-0173" num="0218">The process is repeated for each next chunk until there is enough accommodating place in the accommodation section, e.g. the logs <b>1222</b> in the accommodation section correspond to the chunk <b>1211</b> and the divided chunk <b>1212</b> while the primary log <b>1232</b> is positioned as continuation of previous primary log <b>1231</b>; the logs <b>1223</b> in the accommodation section correspond to the chunk <b>1211</b>, the chunk <b>1212</b> and the divided chunk <b>1213</b>, while the primary log <b>1233</b> is positioned as continuation of previous primary log <b>1232</b>. Thus, the accommodation section comprises a sequence of primary logs followed by one (or zero) tail log.</p>
<p id="p-0174" num="0219">It should be noted that the method of processing a plaintext chunk to be stored as encrypted logs is applicable in a similar manner to any method and system for encryption of logical data objects for storage comprising sequential accommodation of encrypted chunks.</p>
<p id="p-0175" num="0220"><figref idref="DRAWINGS">FIG. 13</figref> illustrates a schematic functional block diagram of the transformation system <b>16</b> in accordance with certain embodiments of the present invention. The transformation system comprises a Client Input/Output (I/O) block <b>131</b> coupled to a session manager <b>132</b>. The I/O block gets data access-related requests (e.g. read, write, set end of file/truncate, etc.) and forwards them to the session manager.</p>
<p id="p-0176" num="0221">A session starts by access request to a logical data object (e.g. LUN capacity request as, for example, SCSI LUN capacity request command; open file request, etc.) and ends by disconnect request (e.g. &#x201c;LUN disconnect&#x201d;, &#x201c;close file&#x201d;, etc.) received from the same IP address (user). The session manager <b>132</b> holds all the session's private data as, for example, source session address, session counters, session status, all instances for the buffers in use, etc. The session manager also handles blocking all the relevant resources when the logical data object is open and releasing said resources on disconnect. The session manager transfers all requests to a dispatcher <b>133</b> operatively coupled to the session manager. The dispatcher <b>133</b> is operatively coupled to a logical data object manager <b>134</b>, a buffer manager <b>135</b> and a transformation unit <b>136</b>. The dispatcher <b>133</b> communicates with the logical data object manager <b>134</b> for data related transactions (e.g. Read, Write, set end of file, etc.) and the transformation unit <b>136</b> for transforming operations in accordance with certain embodiments of the present invention.</p>
<p id="p-0177" num="0222">The transformation unit is capable of compressing, encrypting and/or otherwise transforming data, and sending them to a physical disk through a storage I/O <b>138</b>; as well as of reading data from the physical disk through the storage I/O, De-transforming (e.g. decrypting and/or decompressing) the respective buffer and, optionally, of segmenting and/or combining original and/or partly transformed data chunks for further processing. The transformation unit may comprise one or more transformation blocks responsible for certain transforming operations (e.g. compression-decompression block <b>136</b>-<b>1</b> operatively coupled with the encryption/decryption block <b>136</b>-<b>2</b>), and is configured to facilitate data transfer and necessary synchronization between said blocks. The transformation unit is also configured to report size of original logical data object (and free storage capacity) in reply to &#x201c;Capacity status&#x201d;.</p>
<p id="p-0178" num="0223">The transformation unit <b>136</b> is also configured to communicate with one or more external platforms storing external information related to data involved in the transformation process (e.g. the secure keys for receiving the keys and/or metadata thereof); to receive said the information, extract or generate the necessary data (e.g. key ID) and to manage thereof. The received information may be temporary accommodated in a trusted memory within the transformation system, wherein the transformation unit block may provide a management of said information (e.g. to manage accommodation of certain keys in said memory for certain time period in accordance with a certain policy). In certain embodiments of the invention the encryption/decryption block <b>136</b>-<b>2</b> may further generate one or more encryption initialization vectors to be used for encryption (e.g. together with secure keys).</p>
<p id="p-0179" num="0224">The logical data object manager <b>134</b> is responsible for the ordering and memory sharing by different logical data objects and parts thereof.</p>
<p id="p-0180" num="0225">The buffer manager <b>135</b> manages memory buffer resources and is responsible for allocating and releasing memory buffer for operations of other blocks. The transformation system further comprises an integrity manager <b>137</b> coupled to the session manager, the buffer manager and the data block manager. The integrity manager is responsible for synchronization and general control of all processes in the transformation system as, for example keeping the integrity of the logical data objects, etc. It is also responsible for flashing the memory buffer to the physical disk(s) through the storage physical I/O interface <b>138</b>, and reading when needed from the disk(s).</p>
<p id="p-0181" num="0226">Those skilled in the art will readily appreciate that the invention is not bound by the configuration of <figref idref="DRAWINGS">FIGS. 13</figref>; equivalent and/or modified functionality may be consolidated or divided in another manner and may be implemented in software, firmware, hardware, or any combination thereof.</p>
<p id="p-0182" num="0227">It is to be understood that the invention is not limited in its application to the details set forth in the description contained herein or illustrated in the drawings. The invention is capable of other embodiments and of being practiced and carried out in various ways. Hence, it is to be understood that the phraseology and terminology employed herein are for the purpose of description and should not be regarded as limiting. As such, those skilled in the art will appreciate that the conception upon which this disclosure is based may readily be utilized as a basis for designing other structures, methods, and systems for carrying out the several purposes of the present invention.</p>
<p id="p-0183" num="0228">It will also be understood that the system according to the invention may be a suitably programmed computer. Likewise, the invention contemplates a computer program being readable by a computer for executing the method of the invention. The invention further contemplates a machine-readable memory tangibly embodying a program of instructions executable by the machine for executing the method of the invention.</p>
<p id="p-0184" num="0229">Those skilled in the art will readily appreciate that various modifications and changes can be applied to the embodiments of the invention as hereinbefore described without departing from its scope, defined in and by the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of transforming a logical data object for storage in a storage device operable with at least one storage protocol, said method comprising:
<claim-text>in response to a respective request, creating in the storage device a transformed logical data object comprising a header and a plurality of storage sections with a predefined size;</claim-text>
<claim-text>obtaining a plurality of data chunks corresponding to the transformed logical data object; determining if the plurality of obtained data chunks exceed a predetermined threshold based on one of a time to compress each obtained data chunk and an amount of available storage space in a particular storage section that is dependent upon whether the particular storage section includes sufficient storage space to store a next uncompressed data chunk queued for storage;</claim-text>
<claim-text>compressing each obtained data chunk if the predetermined threshold based on time is not exceeded and not compressing each obtained data chunk if the predetermined threshold based on time is exceeded;</claim-text>
<claim-text>compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is exceeded and not compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is not exceeded, wherein compressing comprises:
<claim-text>compressing each obtained data chunk, and</claim-text>
<claim-text>accumulating the compressed data chunks to form compressed blocks, the compressed data chunks accumulated until a size of a compressed block includes the predefined size;</claim-text>
</claim-text>
<claim-text>storing each compressed block into said storage sections subsequent to accumulating said compressed data chunks, said compressed blocks stored in an order said plurality of obtained data chunks are received for storage; and</claim-text>
<claim-text>facilitating mapping between the data in the logical data object and the data stored in the storage sections.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said compressing further comprises applying one of an encryption technique, an encoding technique, a conversion technique, and a combination thereof to each obtained data chunk if the predetermined threshold is not exceeded.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined threshold is related to at least one characteristic selected from a group comprising characteristics of the logical data object, characteristics of each obtained data chunk, characteristics of each storage section, characteristics of a transforming operation, and a combination thereof.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined threshold related to the time to compress each obtained data chunk is 30 milliseconds.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined threshold related to the compressed size is 95% of an original size of each obtained data chunk.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the predetermined threshold related to the time to compress each obtained data chunk is 30 milliseconds.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising applying one of an encryption technique, an encoding technique, a conversion technique, and a combination thereof to each obtained data chunk if the predetermined threshold is not exceeded, and the threshold time is related separately to each technique.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the compressed obtained data chunk comprises a first portion of compressed data and a second portion of uncompressed data if the predetermined threshold is exceeded in relation to part of techniques of data compression, wherein said first portion is provided by techniques related to the predetermined threshold.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein one or more characteristics of the logical data object are selected from a group comprising a type of logical data object, a size of the logical data object, and an authorization mark associated with the logical data object.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determination is provided for each compressed obtained data chunk.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mapping is provided with a help of at least one index section constituting a part of the compressed logical data object, said index section comprising at least one entry holding at least information related to compressed obtained data chunks stored in at least one storage section, an indication of compressed/uncompressed form of data held in said obtained data chunks, and indication of physical storage location pertaining to said storage section.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predefined size is equal for all storage sections.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the size of the storage section is selected from a list of predefined sizes in accordance with predetermined criterion.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the header of the compressed logical data object comprises a unique descriptor of the transformed logical data object, information related to a size of the compressed logical data object, and an indication if the compressed logical data object holds data in an uncompressed form.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the storage section comprises a header containing a unique identifier of the storage section and an indication if the storage section holds data in an uncompressed form.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the compressed data chunks are stored in a log form.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein a log of a particular obtained data chunk comprises a log header containing information in respect of an offset of the particular obtained data chunk within the compressed logical data object, a size of said particular obtained data chunk, an identifier allowing associating the log with the storage section storing the log, and an indication of compressed/uncompressed form of data held in the log.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> operable with at least file access storage protocol.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> operable with at least block mode access storage protocol.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A system for transforming a logical data object for storage in a storage device operable with at least one storage protocol, said system comprising:
<claim-text>means for creating in the storage device a transformed logical data object comprising a header and a plurality of storage sections with a predefined size;</claim-text>
<claim-text>means for obtaining a plurality of data chunks corresponding to the transformed logical data object;</claim-text>
<claim-text>means for determining if the plurality of obtained data chunks exceed a predetermined threshold based on one of a time to compress each obtained data chunk and an amount of available storage space in a particular storage section that is dependent upon whether the particular storage section includes sufficient storage space to store a next uncompressed data chunk queued for storage;</claim-text>
<claim-text>means for compressing each obtained data chunk if the predetermined threshold based on time is not exceeded and not compressing each obtained data chunk if the predetermined threshold based on time is exceeded;</claim-text>
<claim-text>means for compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is exceeded and not compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is not exceeded, wherein compressing comprises:
<claim-text>compressing each obtained data chunk, and</claim-text>
<claim-text>accumulating the compressed data chunks to form compressed blocks, the compressed data chunks accumulated until a size of a compressed block includes the predefined size;</claim-text>
</claim-text>
<claim-text>means for storing each compressed block into said storage sections in an order said plurality of obtained data chunks are received for storage; and</claim-text>
<claim-text>means for facilitating mapping between the data in the logical data object and the data stored in the storage sections.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. A program storage device readable by machine, tangibly embodying a program of instructions executable by the machine to perform method steps of transforming a logical data object for storage in a storage device operable with at least one storage protocol, said method comprising:
<claim-text>in response to a respective request, creating in the storage device a transformed logical data object comprising a header and a plurality of storage sections with a predefined size;</claim-text>
<claim-text>obtaining a plurality of data chunks corresponding to the transformed logical data object;</claim-text>
<claim-text>determining if the plurality of obtained data chunks exceed a predetermined threshold based on one of a time to compress each obtained data chunk and an amount of available storage space in a particular storage section that is dependent upon whether the particular storage section includes sufficient storage space to store a next uncompressed data chunk queued for storage;</claim-text>
<claim-text>compressing each obtained data chunk if the predetermined threshold based on time is not exceeded and not compressing each obtained data chunk if the predetermined threshold based on time is exceeded;</claim-text>
<claim-text>compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is exceeded and not compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is not exceeded, wherein compressing comprises:
<claim-text>compressing each obtained data chunk, and</claim-text>
<claim-text>accumulating the compressed data chunks to form compressed blocks, the compressed data chunks accumulated until a size of a compressed block includes the predefined size;</claim-text>
</claim-text>
<claim-text>storing each compressed block into said storage sections subsequent to accumulating said compressed data chunks, said compressed blocks stored in an order said plurality of obtained data chunks are received for storage; and</claim-text>
<claim-text>facilitating mapping between the data in the logical data object and the data stored in the storage sections.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. A computer program product comprising a computer useable medium having computer readable program code embodied therein for transforming a logical data object for storage in a storage device operable with at least one storage protocol, said computer program product comprising:
<claim-text>in response to a respective request, creating in the storage device a transformed logical data object comprising a header and a plurality of storage sections with a predefined size;</claim-text>
<claim-text>obtaining a plurality of data chunks corresponding to the transformed logical data object;</claim-text>
<claim-text>determining if the plurality of obtained data chunks exceed a predetermined threshold based on one of a time to compress each obtained data chunk and an amount of available storage space in a particular storage section that is dependent upon whether the particular storage section includes sufficient storage space to store a next uncompressed data chunk queued for storage;</claim-text>
<claim-text>compressing each obtained data chunks if the predetermined threshold based on time is not exceeded and not compressing each obtained data chunk if the predetermined threshold based on time is exceeded;</claim-text>
<claim-text>compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is exceeded and not compressing each obtained data chunk if the predetermined threshold based on the amount of available storage space is not exceeded, wherein compressing comprises;
<claim-text>compressing each obtained data chunk, and</claim-text>
<claim-text>accumulating the compressed data chunks to form compressed blocks, the compressed data chunks accumulated until a size of a compressed block includes the predefined size;</claim-text>
</claim-text>
<claim-text>storing each compressed block into said storage sections subsequent to accumulating said compressed data chunks, said compressed blocks stored in an order said plurality of obtained data chunks are received for storage; and</claim-text>
<claim-text>facilitating mapping between the data in the logical data object and the data stored in the storage sections. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
