<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626732-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626732</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12499030</doc-number>
<date>20090707</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>533</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>30</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>707705</main-classification>
</classification-national>
<invention-title id="d2e53">Method and system for navigating and selecting media from large data sets</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6601061</doc-number>
<kind>B1</kind>
<name>Holt et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>  1  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7289102</doc-number>
<kind>B2</kind>
<name>Hinckley et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7516129</doc-number>
<kind>B2</kind>
<name>Risberg et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>  1  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2001/0018858</doc-number>
<kind>A1</kind>
<name>Dwek</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2002/0010740</doc-number>
<kind>A1</kind>
<name>Kikuchi et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2002/0026331</doc-number>
<kind>A1</kind>
<name>Case</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2002/0120506</doc-number>
<kind>A1</kind>
<name>Hagen</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 14</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2002/0129693</doc-number>
<kind>A1</kind>
<name>Wilks</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2003/0086699</doc-number>
<kind>A1</kind>
<name>Benyamin et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2003/0120673</doc-number>
<kind>A1</kind>
<name>Ashby et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2004/0001092</doc-number>
<kind>A1</kind>
<name>Rothwein et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345763</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2004/0231495</doc-number>
<kind>A1</kind>
<name>Huang et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2004/0268250</doc-number>
<kind>A1</kind>
<name>Danker et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715526</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2005/0049941</doc-number>
<kind>A1</kind>
<name>Kaplan</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2006/0062137</doc-number>
<kind>A1</kind>
<name>Ross</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2006/0101350</doc-number>
<kind>A1</kind>
<name>Scott</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715779</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2006/0112081</doc-number>
<kind>A1</kind>
<name>Qureshi</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2006/0161545</doc-number>
<kind>A1</kind>
<name>Pura</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  7</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>23</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>707  7</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707705</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715779</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345763</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>12</number-of-drawing-sheets>
<number-of-figures>13</number-of-figures>
</figures>
<us-related-documents>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11212527</doc-number>
<date>20050826</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7574434</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12499030</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60656777</doc-number>
<date>20050225</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090276691</doc-number>
<kind>A1</kind>
<date>20091105</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Galuten</last-name>
<first-name>Albhy</first-name>
<address>
<city>Santa Monica</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Galuten</last-name>
<first-name>Albhy</first-name>
<address>
<city>Santa Monica</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Haverstock &#x26; Owens LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
<assignee>
<addressbook>
<orgname>Sony Electronics Inc.</orgname>
<role>02</role>
<address>
<city>Park Ridge</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Leroux</last-name>
<first-name>Etienne</first-name>
<department>2161</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Some embodiments of the invention provide a method of accessing a data set. The data set includes a set of data elements. The method collects the data elements of the data set. The method receives a lens item. The lens item provides a set of parameters for searching the data set. The method searches the data set by using the lens item to identify a data subset. The method sorts a list of data elements based on the data subset. The sorting generates an ordered list. The method filters the data subset. Filtering the data subset comprises excluding the data elements that are not relevant to the lens item. The method presents the ordered list in a first column of a matrix. The matrix has several cells. The cells of the matrix are based on the data subset. The method selects column headings for the matrix and populates the cells of the matrix. Some embodiments provide a system for providing access to a data set. The system has a set of data elements that comprises a first data source. The system has a first device for collecting the set of data elements. The first device receives a first lens item for searching the data elements. The first device filters the data elements by using the first lens item to generate a first subset. The first device presents the first subset in a variety of views for navigation through the first subset.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="152.15mm" wi="116.33mm" file="US08626732-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="164.34mm" wi="117.43mm" file="US08626732-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="157.31mm" wi="116.16mm" file="US08626732-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="233.26mm" wi="162.39mm" orientation="landscape" file="US08626732-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="234.78mm" wi="161.54mm" orientation="landscape" file="US08626732-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="240.28mm" wi="165.69mm" file="US08626732-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="126.24mm" wi="119.55mm" file="US08626732-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="163.15mm" wi="121.75mm" file="US08626732-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="240.79mm" wi="152.99mm" file="US08626732-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="212.43mm" wi="146.98mm" file="US08626732-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="226.65mm" wi="149.52mm" file="US08626732-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="234.10mm" wi="179.07mm" file="US08626732-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="178.48mm" wi="147.91mm" file="US08626732-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This patent application is a divisional of co-pending U.S. patent application Ser. No. 11/212,527, filed on Aug. 26, 2005, entitled &#x201c;METHOD AND SYSTEM FOR NAVIGATING AND SELECTING MEDIA FROM LARGE DATA SETS,&#x201d; which claims priority under 35 U.S.C. &#xa7;119(e) of the co-pending, co-owned U.S. Provisional Patent Application No. 60/656,777, filed Feb. 25, 2005, entitled &#x201c;METHOD AND SYSTEM FOR NAVIGATING AND SELECTING MEDIA FROM LARGE DATA SETS. The U.S. patent application Ser. No. 11/212,527, filed on Aug. 26, 2005, entitled METHOD AND SYSTEM FOR NAVIGATING AND SELECTING MEDIA FROM LARGE DATA SETS and the U.S. Provisional Patent Application No. 60/656,777, filed Feb. 25, 2005, entitled &#x201c;METHOD AND SYSTEM FOR NAVIGATING AND SELECTING MEDIA FROM LARGE DATA SETS,&#x201d; are both hereby incorporated by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates to accessing data. In particular, the present invention relates to the field of quickly accessing various multiple data types by searching, sorting, filtering, and by using other methods.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Storage technology continues to grow in size and decrease in cost. Currently, a typical consumer and many enterprises have many thousands or even millions of different stored media elements. These stored media elements typically include audio, video, image, and other multimedia files. Many of the stored media elements have associated metadata, while some do not. The metadata associated with various stored media will only increase with the proliferation of the stored media and with the use of both the stored media and associated metadata. For instance, companies such as CDDB currently use consumers to add metadata associated with the consumers' stored audio data such as compact disc (CD) recordings. That data is made available to other owners of the same CD recording to populate the information regarding the other CD owners' stored audio data. There are also new technologies that use heuristic algorithms to classify media by using its associated content, e.g. by using sunsets, waterfalls, or portraits in photos to classify the photos by content, or by using voice recognition to classify films by content. Further, more explicit metadata are being added to media elements every day. For instance, tags for the director, publisher, actors, etc., are being added to various digital media to further identify the work.</p>
<p id="p-0005" num="0004">A user of the stored media, whether in the form of an individual consumer or a large enterprise, faces some challenges when attempting to locate a desired item among many stored media elements. Today, users can search the Internet by using, for example, a general purpose search engine. Additionally, users are beginning to more effectively search their own hard drives and other storage media. These searches are based on a few key words and do not use a robust set of metadata. Moreover, even as the metadata associated with various media elements improves, there is no simple mechanism for finding specific content from among the volumes of stored media, which in some instances, take the form of tens of thousands of audio files, clips, television shows, movies, image files, books, games, personal files and documents that a particular user needs to access at any given time. For instance, a typical home consumer currently has access to personal media players that store a few thousand media elements, e.g., audio files. However, these are only navigable using crude interfaces that are typically far removed from the associative manner in which people typically remember and recall data. Associative storage and recall of data typically involves a temporal component. For instance, I was doing this at that time near when I was doing this other thing.</p>
<p id="p-0006" num="0005">Moreover, the user interfaces currently associated with large data sets, e.g., stored libraries of music, movies, books, which are the collected works of an equally large number of directors, actors, musicians, writers, etc., are lacking in the ability to quickly find and sort the various data appropriately. These deficiencies of large media devices rival or even surpass the deficiencies of the rudimentary interfaces typical of handheld portable players. For instance, most current home media viewers, tuners, and/or players are controlled by using a remote control. However, A/V component remote controls have not typically been designed, or known, for the ability to manage large data sets.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">Some embodiments of the invention provide a method of accessing a data set. The data set includes a set of data elements. The method collects the data elements of the data set. The method receives a lens item. The lens item provides a set of parameters for searching the data set. The method searches the data set by using the lens item to identify a data subset. The method sorts a list of data elements based on the data subset. The sorting generates an ordered list. The method filters the data subset. Filtering the data subset comprises excluding the data elements that are not relevant to the lens item. The method presents the ordered list in a first column of a matrix. The matrix has several cells. The cells of the matrix are based on the data subset. The method selects column headings for the matrix and populates the cells of the matrix.</p>
<p id="p-0008" num="0007">Some embodiments provide a method of selecting a first data element in a data set. The data set includes several data elements. The method collects several data elements. The method limits the data set of data elements to a subset. The method excludes a second data element from the subset. The method selects a set of columns. A column has several data elements. The method orders the data elements in a list for a column in the set of columns. The method presents the ordered list in a matrix that includes the selected set of columns. The method selects column headings for each column in the matrix and populates several cells in the matrix.</p>
<p id="p-0009" num="0008">Some embodiments provide a system for providing access to a data set. The system has a set of data elements that comprises a first data source. The system has a first device for collecting the set of data elements. The first device receives a first lens item for searching the data elements. The first device filters the data elements by using the first lens item to generate a first subset. The first device presents the first subset in a variety of views for navigation through the first subset.</p>
<p id="p-0010" num="0009">Some embodiments provide a user interface device. The user interface device has a communications module for collecting a data set. The data set is available from several sources. The user interface device includes a processor for executing a set of instructions that limit the data set into a first subset based on a first lens item. The user interface device has a storage module for storing the first subset and a display screen for presenting a matrix. The matrix comprises a set of data cells. The matrix represents the first subset. The user interface device includes a set of controls for navigating through the matrix of data cells.</p>
<p id="p-0011" num="0010">Some embodiments provide a user interface for presentation of data. The user interface has a lens field for receiving and presenting a lens item. The lens item includes a data element. The user interface also includes a matrix of data cells that represent a subset of a larger data set. The matrix has a first column and a set of column headings. The lens item has a relationship to one or more data cells in the matrix and the matrix presents an organization of the data cells based on the relationship.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011">The novel features of the invention are set forth in the appended claims. However, for purpose of explanation, several embodiments of the invention are set forth in the following figures.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> is a process flow that illustrates a method of presenting data according to some embodiments of the invention.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> is a process flow that illustrates a method of presenting data according to some embodiments of the invention.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a lens field containing a lens item and a data matrix with column headings that are relevant to the lens item according to some embodiments of the invention.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a landscape view of a data matrix representing a data subset.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a portrait view of the data matrix of <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 6</figref> is a process flow that illustrates a method of presenting an expanded data subset.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 7</figref> illustrates a user interface device providing a portrait view of a data subset.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 8</figref> illustrates a front view of a user interface device rotated to provide a landscape view of a data subset.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 9</figref> illustrates another orientation of a user interface device providing a landscape view of a data subset.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 10</figref> illustrates a user interface device communicating with a plurality of devices through a network, according to some embodiments of the invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 11</figref> illustrates a user interface device binding and communicating with an external display device.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 12</figref> illustrates a user interface device communicating with a plurality of external devices.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 13</figref> is a process flow that illustrates the bind process of some embodiments.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0026" num="0025">In the following description, numerous details are set forth for purpose of explanation. However, one of ordinary skill in the art will realize that the invention may be practiced without the use of these specific details. In other instances, well-known structures and devices are shown in block diagram form in order not to obscure the description of the invention with unnecessary detail. Section I below describes the methods some embodiments employ to navigate through a large data set. Section II describes the data matrix some embodiments present for convenient data access, viewing, and navigation. Section III describes the user interface devices of some embodiments and Section IV lists some particular advantages of the invention.</p>
<p id="p-0027" num="0026">Some embodiments of the invention provide a method and system for accessing data. These embodiments search, sort, filter, display, and/or render the data dynamically and/or associatively. In some embodiments the data includes media data, including multimedia. The data of some embodiments is based on metadata. In some embodiments, the metadata is associated with a data subset. Some embodiments heuristically derive the metadata to associate to the data subset, while some embodiments retrieve the metadata from a source external to the data subset. Some embodiments present the data in a subset represented by a matrix. The matrix format of these embodiments is similar to a spreadsheet format. In these embodiments, the data in a cell of the matrix updates dynamically based on a number of parameters. The dynamic presentation of the data allows a user quick and intuitive access to the data and to the sub-levels of nested data.</p>
<p id="p-0028" num="0027">Some embodiments provide an interface for searching, filtering, sorting, rendering, and/or displaying data. The interface of some embodiments is referred to as a lens interface. The lens interface of these embodiments provides a means to query for specific data and cull other data that is not of interest and/or deemed not relevant. Specifically, the lens interface of some embodiments includes a filter function. The filter function of some embodiments operates by using a large set of content elements and associated metadata. In these embodiments, the filter function limits a subset of the data set to only those data elements that have relevance to a set of predetermined and/or dynamic parameters. The filter function of some embodiments operates by using the associated metadata.</p>
<p id="p-0029" num="0028">The lens interface is typically used to quickly parse through a large data set. The large data set is typically comprised of data elements stored at a plurality of data sources. The data sources of some embodiments include a home and/or local server, a single computer or multiple computers connected on a local area network, one or more portable device(s), and/or one or more data sources on a wide area network, or a network of networks such as the Internet. Data sources on the Internet include one or more content provider services or are related to search technologies.</p>
<p id="p-0030" num="0029">The lens interface of some embodiments includes a display function for displaying a subset of data in a manner that is readily understandable. In particular, some embodiments present a large set of data in smaller subsets. Even so, the smaller data subsets of these embodiments typically contain numerous fields. Thus, the lens interface of some embodiments provides a user with convenient presentations of the data subset, as well as a set of navigational tools. The lens interface of these embodiments is set to perform actions on a set of specific fields. For instance, in some embodiments where the data involves electronic content, the lens interface is set to provide the data by a data category or by an individual data element. In some embodiments, the data crosses genres. The lens interface of these embodiments provides the heterogeneous data in a coherent fashion.</p>
<p id="p-0031" num="0030">Some embodiments allow the lens interface to find a relevant data item and then base further functionality on that item. The functional data element is referred to as the lens item in some embodiments. In these embodiments, the data set is then searched, sorted, and/or filtered by using the currently identified and/or selected lens item. In some embodiments the functionality is based on associations. In these embodiments, the associated data are presented in the lens interface. Some embodiments order the presented data subset(s). The lens interface of some embodiments provides the ability to view a sorted and filtered data subset in various orders, e.g., alphabetical, temporal (based upon, for example, date of creation, time of last rendering, etc.), and/or by another ordering. These embodiments are particularly effective in leveraging the associative nature of recall and memory. In some embodiments, the process repeats such that a data element presented in a data subset is selected as the next lens item for providing an additional layer of functionality, and so forth.</p>
<p id="p-0032" num="0031">Some embodiments provide a user interface device to access, navigate, present, and/or view the data in particular ways according to user preference. Some embodiments provide additional functionality based on the orientation of the user interface device. The user interface device of some embodiments enables a user to navigate and/or manipulate a large data set with minimal user input. In some embodiments, the user interface device provides a binding function to bind the user interface to external devices including external displays. The binding function of some embodiments allows the user to access and/or control the external devices.</p>
<p id="p-0033" num="0032">The user interface device of some embodiments allows a user to navigate at variable speeds through information, for example, through the data matrices mentioned above. Some embodiments provide the ability to dynamically adjust the aspect ratio of the presented data in an internal and/or external display. Some embodiments include interfaces for both a small form portable device and for larger devices such as, e.g., an external display, television, projector, monitor, personal computer, or other external device. Some embodiments operate as a remote control device for one or more external devices.</p>
<p id="h-0007" num="0000">I. Method of Accessing, Organizing, and/or Presenting Data</p>
<p id="p-0034" num="0033">Some embodiments provide a method of accessing, organizing, and presenting for viewing an entire data set. Typically the data set is large. For some embodiments, the accessing, organizing, and presenting includes dynamically searching, sorting, and filtering the large data set such that only those item(s) of interest out of the entire large data set are presented for viewing at a particular time.</p>
<p id="p-0035" num="0034">A. Example using a Data Category as the Lens Item</p>
<p id="p-0036" num="0035">Some embodiments provide for a field of focus for performing such tasks as searching, sorting, and filtering. In some embodiments, the focus field is referred to as a lens field. In these embodiments, an item within the focus field is called the lens item. <figref idref="DRAWINGS">FIG. 1</figref> is a process flow that illustrates the method that some embodiments employ to access, organize, and present the data. As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the process <b>100</b> of these embodiments begins at step <b>105</b> where data is collected from the available data sources. These data sources include, for example, home servers, personal computers in the form of desktop and laptop or notebook computers, portable devices, and Internet services, that contain or are associated with various multiple media elements. When the data have been collected from the available sources, the process <b>100</b> transitions to step <b>110</b>, where a lens item is received. As mentioned above, the lens item is a data element by which the user focuses the organization and presentation of the data. Upon receiving the lens item, the process <b>100</b> transitions to step <b>115</b>, where the collected data set is searched. Some embodiments search for relationships by using the lens item. In some embodiments, the relationships are associative. Next, the collected data are sorted at the step <b>120</b>. After the data are sorted, the sorted data is filtered using the lens item at the step <b>125</b>. If, for instance, the lens item is a particular category of data, the filtering at step <b>125</b> limits the data to those data elements that are members of the category. Some embodiments limit the data to the lens item by removing those data elements that are not members of the category, while some embodiments limit the data by excluding the irrelevant data. For instance, if the lens item of interest is the category &#x201c;Songwriters,&#x201d; the list of data elements is limited to songwriters, their songs, and the recordings of those songs. The data subset for songwriters does not include photos, musicians, movies, directors, etc., that are not typically associated with the songwriters category. Some embodiments exclude the non-typical associations.</p>
<p id="p-0037" num="0036">Once the data is filtered at step <b>125</b>, an ordered list containing the set of filtered data elements that remain after filtering is presented at the step <b>130</b>. Some embodiments present the ordered list alphabetically by name, while some embodiments present the ordered list chronologically by date of release, or creation, and/or by the time of last rendering by the current system. Further, some embodiments present the ordered list based on heuristically defined algorithms that relate to the content of the ordered data, such as, for example, to color, content mood, and embedded text. Some embodiments present the ordered list in the first column of a data matrix. In these embodiments, at step <b>135</b>, column headings are selected based on the metadata associated with the individual data elements in each additional column of the data matrix. For example, if the first column is a list of songs, the related columns are typically based on metadata associated with the songs. Typical column headings for data associated with songs include, for example, composer, lyricist, recording artist, and date of release.</p>
<p id="p-0038" num="0037">After the column headings are selected at step <b>135</b>, the cells in each column are populated with the relevant metadata at step <b>140</b>. Some embodiments populate the cells based on the intersection of the data element in the leftmost (first) column for a particular row and the metadata defined in the column heading associated with that particular cell. For example, if the lens item in the first column is the category &#x201c;Songs&#x201d; and a first cell in the first column contains &#x201c;Sergeant Pepper's Lonely Hearts Club Band,&#x201d; then a second cell along the same row as the first cell, under a second column entitled &#x201c;Artist,&#x201d; contains the &#x201c;Beatles.&#x201d; After the cells are populated, the process <b>100</b> concludes.</p>
<p id="p-0039" num="0038">In some embodiments, the sorting at step <b>120</b> includes ordering the data in the columns from most to least useful. The ordering of some embodiments is based on a set of predetermined relevancies, which are set by a software design that implements the process <b>100</b>. For instance, if the first column heading is &#x201c;Movie Title,&#x201d; the next most important column heading by default in some embodiments is &#x201c;Lead Actor,&#x201d; followed in some embodiments by &#x201c;Supporting Actor,&#x201d; followed by &#x201c;Director,&#x201d; and so forth. In some embodiments, ordering is based on user selectable preferences. These user specified column headings are similar to the predetermined column headings described above except the user in these embodiments sets the relevancies at various times by using a set of user configurable preferences. In some embodiments, ordering is based on usage. As the user selects data elements from various columns for playback or to act as the lens item, these embodiments track from which column headings data are most often selected and place those column headings further to the left. Some embodiments place the most often selected column(s) closest to the first column.</p>
<p id="p-0040" num="0039">Some embodiments include a combination of the ordering described above. For instance, the software designer initially sets the defaults, which are then later changed through direct manipulation by the user and/or by the process implementation to reflect the usage behavior of the particular user.</p>
<p id="p-0041" num="0040">B. Example using an Individual Data Element as the Lens Item</p>
<p id="p-0042" num="0041">In some embodiments, the lens item contains an individual data element, such as, for example, a particular song, a writer, a chapter in a book, or an artist. In these embodiments, the presented data elements are limited to those with a predetermined relationship to the lens item. For example, if a song serves as the lens item, a set of playlists presented to the user are limited to only those playlists that contain the particular song serving as the lens item. If an actor is the lens item, a set of movies presented to the user is limited to those movies in which the actor appeared, or to which the actor serving as the lens item had some predefined relationship. If a feature of a photograph serves as the lens item, a set of photographs presented to the user is limited to only those photographs that contain the particular feature of interest. In some embodiments, data relevant to the lens item crosses genres or data types. For example, a user interested in a particular person provides the person of interest's name as the lens item. In some cases, the available data set contains information that the particular person of interest has performed as a musician, as an actor, and is also a writer of magazine articles. These embodiments present a reduced subset from the set of all data available to the user. The data subset of these embodiments typically contains a set of the column headings that are properly associated with the person's name.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 2</figref> is a process flow that illustrates the method employed by some of the embodiments described above. As shown in this figure, the process <b>200</b> begins at step <b>205</b>, where the available data that is associated with the media of interest is collected. As mentioned above, the data is typically available from a variety of sources that include home servers, personal computers, portable devices, and network sources, including Internet services. After the data are collected, the data are limited to those data elements for which the lens item is relevant at the step <b>210</b>. In some embodiments, relevance is established when the lens item is part of the metadata for a particular data element. For example, if the lens item is a songwriter, the relevant data elements are typically limited to the songs that the song writer wrote. At the step <b>215</b>, the irrelevant data elements are excluded. In some embodiments, the irrelevant data elements comprise the data elements for which the lens item is not a metadata element.</p>
<p id="p-0044" num="0043">Once the data are limited and the irrelevant data are removed or excluded at the step <b>215</b>, the first column and its appropriate heading are selected for the matrix related to the data element serving as the lens item at the step <b>220</b>. For instance, in some embodiments, the first column heading for song writers is &#x201c;Songs,&#x201d; while the first column heading for actors is typically &#x201c;Movies&#x201d; or &#x201c;TV Shows.&#x201d; The first column of some embodiments contains the metadata field for which the lens item was most popular. Thus, if the lens item contains a person who is both a writer and a singer, but who sang in more songs than acted in films, the first column heading is typically the &#x201c;Songs&#x201d; heading, followed by the &#x201c;Movies&#x201d; heading. In these embodiments, the order of additional columns is specified.</p>
<p id="p-0045" num="0044">After selecting the first column and possibly one or more adjacent column(s), the order of the data elements for each column is specified at the step <b>225</b>. In some embodiments, the order of each column is alphabetical by name, while in some embodiments the order is by date of release or creation, and/or by time of last rendering by the system currently accessing the data. Some embodiments base the order on heuristically defined algorithms such as, for example, color, content mood, and embedded text.</p>
<p id="p-0046" num="0045">Once the order is specified at step <b>225</b>, the ordered list is presented as the first column of the display at the step <b>230</b>. Then, at the step <b>235</b>, the appropriate column headings are selected based on the metadata that are associated with the individual elements contained in each additional column. For example, if the first column contains a list of songs, the related (adjacent) columns typically contain metadata associated with the songs. Such associated metadata typically provide additional information regarding each song such as the composer, lyricist, recording artist, date of release, etc., for each song listed in the first column.</p>
<p id="p-0047" num="0046">After the appropriate column headings are selected at the step <b>235</b>, the cells are populated at the step <b>240</b>. The process <b>200</b> then concludes. As mentioned above, in some embodiments, the process <b>200</b> further orders the data contained in each column, e.g., from most to least useful. Some embodiments provide an additional level of granularity of searching by using a lens item in a lens aware environment. In these embodiments, a user either searches the whole data set or a more limited data set represented by the elements filtered by using the lens item.</p>
<p id="h-0008" num="0000">II. Data Matrix</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIGS. 3</figref>, <b>4</b>, and <b>5</b> illustrate the columns and rows of a matrix presented to the user of some of the embodiments described above. Specifically, <figref idref="DRAWINGS">FIG. 3</figref> shows an unpopulated matrix <b>300</b> comprising a lens field <b>305</b>, a first row <b>310</b>, a first column <b>315</b>, and additional adjacent columns, such as, for example, a second column <b>320</b>, a third column <b>325</b>, a fourth column <b>330</b>, a fifth column <b>335</b>, and a sixth column <b>340</b>). For the embodiments illustrated in <figref idref="DRAWINGS">FIG. 3</figref>, the lens field <b>305</b> is typically located above the first row <b>310</b>. A user typically enters a lens item for access, presentation, and/or retrieval of data elements relevant to the entered lens item of interest. For instance, as shown in <figref idref="DRAWINGS">FIG. 3</figref>, a user has entered the lens item &#x201c;John Doe&#x201d; into the lens field <b>305</b>. Some embodiments compile a data subset from the set of all data from the available data sources by using the lens item and by using the processes <b>100</b> and <b>200</b> illustrated in <figref idref="DRAWINGS">FIGS. 1 and 2</figref>, respectively.</p>
<p id="p-0049" num="0048">Accordingly, the first column <b>305</b> shown in <figref idref="DRAWINGS">FIG. 3</figref> contains an ordered list of data elements, in this example, songs, from a data subset that includes songs relevant to John Doe. The first row <b>310</b> of some embodiments is typically reserved for the appropriate column headings of the associated metadata in each column. Thus, in the example illustrated in <figref idref="DRAWINGS">FIG. 3</figref>, the representative headings include Song, Composer, Producer, Musicians, Release, and Playlist. Thus, <figref idref="DRAWINGS">FIG. 3</figref> illustrates the state of the matrix <b>300</b> after the column headings have been selected but before the cells of the matrix <b>300</b> have been populated, as in the steps <b>135</b> and <b>235</b> in <figref idref="DRAWINGS">FIGS. 1 and 2</figref>, respectively. In some embodiments, the default column headings are preset based on the context, for example, &#x201c;Playlist&#x201d; where the content of the column contains music, or &#x201c;Movie Titles&#x201d; when the content comprises movies.</p>
<p id="p-0050" num="0049">The additional columns <b>320</b>-<b>340</b> adjacent to the first column <b>315</b> are for additional data that are relevant to the data contained in each row of the first column <b>315</b>. The additional columns <b>320</b>-<b>340</b> of some embodiments are also context sensitive, for example, have column headings that are dependent upon the nature of the content contained in each column. In some embodiments, the columns wrap such that the column to the right of the last far right column will appear as the last far right column as the user scrolls from left to right, through the columns presented in the display. For instance, the last column illustrated in <figref idref="DRAWINGS">FIG. 3</figref> is the &#x201c;Playlist&#x201d; column <b>340</b>, while the &#x201c;Composer&#x201d; column <b>320</b> is adjacent to the first column <b>315</b>. In some embodiments, the &#x201c;Composer&#x201d; column <b>320</b> will appear adjacent to the right of the &#x201c;Playlist&#x201d; column <b>340</b>, and so forth, as the user scrolls left-to-right through the presented columns in the matrix <b>300</b>.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIGS. 4 and 5</figref> illustrate a subset of text metadata presented for display by some embodiments of the invention. These figures, illustrate two matrices <b>400</b> and <b>500</b> after the cells of the matrices <b>400</b> and <b>500</b> have been populated, for instance, after the processes <b>100</b> and <b>200</b> illustrated in <figref idref="DRAWINGS">FIGS. 1 and 2</figref>, respectively, have concluded.</p>
<p id="p-0052" num="0051">Specifically, <figref idref="DRAWINGS">FIG. 4</figref> illustrates the compiled data subset presented in landscape view, while <figref idref="DRAWINGS">FIG. 5</figref> illustrates a portrait view of the same data subset. As shown in these figures, the data is laid out as a matrix, similar to a spreadsheet format. The advantage of the landscape view is that more columns are displayed, while the portrait view presents more rows from the data subset for display in the matrix. The data in each cell of the matrices <b>400</b> and <b>500</b> are dynamically based on a number of parameters that are described below. As shown in <figref idref="DRAWINGS">FIG. 4</figref>, the matrix <b>400</b> comprises a lens field <b>405</b>, a first row <b>410</b>, a first column <b>415</b>, and additional adjacent columns (i.e., a second column <b>420</b>, a third column <b>425</b>, a fourth column <b>430</b>, a fifth column <b>435</b>, and a sixth column <b>440</b>).</p>
<p id="p-0053" num="0052">The first column <b>415</b> of the embodiments represented by the illustration in <figref idref="DRAWINGS">FIG. 4</figref>, contains songs listed alphabetically. However, one of ordinary skill will recognize that the data is ordered differently in other embodiments, for instance, by date of release. Other list orderings include by date of creation for material such as photos, by time last rendered for audio, video, and image files, or other subjective heuristically defined algorithms, such as, for example, color and mood. In different embodiments, different types of data occupy the first column <b>415</b>.</p>
<p id="p-0054" num="0053">A. Types of Metadata and Corresponding Appropriate Column Headings</p>
<p id="p-0055" num="0054">As mentioned above, the data includes a variety of types. In some embodiments, the data are related to music, video, images, and other media and/or multimedia information. A brief review of some exemplary matrix formats for the various data types of some embodiments, follows. For music-type data, the column headings that reflect the associated metadata in each column includes, in some embodiments: Playlist(s), Album, Song, Artist, Genre, Composer, Writer, Musiciai(s), Conductor, Arranger, Producer(s), Date Released, and/or date last Played or Rendered, and Cover Art Director, Photographer, and/or Artist. For video-type data, which includes film, television, shorts, commercials, the appropriate column headings and associated metadata typically include: Shows, Lead Actor(s), Supporting Actor(s), Director(s), Date of Release, Producer(s), and Writer(s). For image-type data, the column headings and associated metadata of some embodiments include, for example, Slide Show, Date Taken, Place Taken, and time last Rendered.</p>
<p id="p-0056" num="0055">The metadata and/or column heading(s) of some embodiments are user defined, such as, for example, &#x201c;Participants in Photo,&#x201d; &#x201c;Eiffel Tower Pics,&#x201d; and &#x201c;Aunt Jenny on Vacation.&#x201d; In some embodiments, the metadata is heuristically generated, such as, for example, graphical metadata for identifying particular features in the images such as sunsets, water, portraits, etc., that are based on color, mood, or other predetermined and/or user defined criteria. In some embodiments the column headings are generated based on additional metadata types, for instance, appropriate column headings are &#x201c;Game Title&#x201d; and &#x201c;Game Level&#x201d; for game-based metadata. In some embodiments, the additional columns are related to text and/or documents and include such column headings as, for example: &#x201c;Books,&#x201d; &#x201c;Stories,&#x201d; &#x201c;Periodicals,&#x201d; &#x201c;Newspapers,&#x201d; &#x201c;Personal Documents,&#x201d; and &#x201c;Spreadsheets.&#x201d;</p>
<p id="p-0057" num="0056">B. Navigation through the Data by using the Lens Item, Field, and Matrix</p>
<p id="p-0058" num="0057">Navigation through a large data set by a user is performed in some embodiments by scrolling cell-wise through the matrix and/or by selecting one or more cells in the matrix. Movement through the matrix includes left, right, up, and down cell-wise scrolling. In some embodiments, the selection of a cell enables the contents of the cell to serve as a lens item. These embodiments facilitate the access and presentation of additional information that is relevant to the current data presentation or tangentially in a new data area. Some embodiments permit the highlighting of a cell to enable additional functionality by using the highlighted cell's data contents, for instance, to jump to a different data subset or organization of the large data set. For instance, <figref idref="DRAWINGS">FIG. 4</figref> illustrates a highlighted cell that contains data for &#x201c;Harry Belafonte.&#x201d; In some embodiments, the data in this cell are selected to provide further information. In some embodiments, the contents of the selected cell appear in the lens field <b>405</b>, and the matrix <b>400</b> is updated to reflect further information regarding Harry Belafonte.</p>
<p id="p-0059" num="0058">The area above or below the first row <b>410</b> is reserved in some embodiments for the lens field <b>405</b>. The lens field <b>405</b>, is the location in the user interface of some embodiments where a user may insert and/or modify the lens item. The lens item provides the criteria by which some embodiments perform several data access, organization, and/or presentation functions such as the search, sort, and filtering described above in relation to <figref idref="DRAWINGS">FIGS. 1 and 2</figref>. A data element which is entered into the lens field <b>405</b>, becomes the lens item, which, for example, in some embodiments serves as the focus for determining relevant data from the set of available data. The data set is searched, sorted, and/or filtered to yield a subset of only relevant data that is of interest. The matrix <b>400</b> is then presented to the user for viewing and additional data access, organization, and/or presentation functions. The lens field <b>405</b> of some embodiments is not limited by the dimensions of the matrix used to present the data.</p>
<p id="p-0060" num="0059">The cell at the intersection of the first column <b>415</b> and the first row <b>410</b> is the first cell. When a cell is selected in the matrix <b>400</b>, the data contents of the selected cell move to the lens field <b>405</b> and also to the first cell. All other columns <b>420</b>-<b>440</b> maintain position to the right of the selected cell, which becomes the first cell, in some embodiments. As described above, the column headings of some embodiments wrap. The columns and rows of the matrix typically follow the ordering rules described above. Also mentioned above, the data are listed in various ways, such as, for example, alphabetical order, date of release, and/or date last rendered.</p>
<p id="p-0061" num="0060">When navigating through the matrix <b>400</b>, such as, for example, scrolling cell-wise up, down, left, or right, the columns and rows scroll to make the new columns and rows visible. Most rows and columns of the matrices representing the large data set and even the smaller data subsets are not visible at any one time. Even though the first cell is scrolled out of view in some embodiments, the data in the visible columns and rows still maintain position relative to the lens field <b>405</b>, which remains visible throughout navigation of the matrix <b>400</b>. The column headings in the first row <b>410</b> of some embodiments also remains visible during navigation so that the user is constantly reminded of the organization of the voluminous data being presented.</p>
<p id="p-0062" num="0061">The lens field <b>405</b> of some embodiments contains a category. For instance, the lens item in the lens field <b>405</b> of these embodiments, includes an item that also appears as a column heading in some embodiments. When the lens field <b>405</b> contains a category, the first column <b>415</b> typically remains in place when scrolling to the left or right to the additional screen area that did not fit within the viewable area of the particular display. In these embodiments, the data elements listed in the first column <b>415</b> are limited to the members of the category currently serving as the lens item.</p>
<p id="p-0063" num="0062">C. Changing the Lens Item</p>
<p id="p-0064" num="0063">As soon as a data subset is selected for viewing and/or navigation, e.g., once the category of songwriters is selected for navigating via scrolling, the data set associated with that whole category is moved to memory. Some embodiments move to memory only a subset of the entire set of available data. In some embodiments, this first memory subset is a larger subset than will eventually be displayed if a new lens item is chosen. In some embodiments, a database of the previous lens items and each previous associated data subset is compiled and organized in such a way as to enable the caching of spatially and/or temporally related data. In some embodiments, the same data subset is replicated multiple times so that it is ready for presentation on the display screen as quickly as possible, as the needed associated data is accessed. Alternatively, or in conjunction with these embodiments, the data subsets relevant to the previous lens items are kept in a format that enables them to be quickly accessed.</p>
<p id="p-0065" num="0064">In some embodiments, a user pauses while scrolling through the data matrix to allow the highlighting to settle for a moment on a particular cell. In some embodiments, the newly highlighted cell automatically becomes the current lens item. In these embodiments, a second memory subset based on the category of the highlighted cell is loaded to a different memory location. When a cell is selected for migration to the lens field, such as, for example, when the cell's contents are selected to serve as the next lens item during data set navigation, some embodiments minimize the latency of the data access by a number of additional methods. For instance, if the current lens item has already served previously as a lens item, the previously stored data subset relevant to the redundant lens item is already available, such as, for example, from memory, and accessible for immediate presentation. Even if the current lens item has not previously served as a lens item, and its relevant data subset has not been previously presented, some embodiments pre-cache in a buffer the current relevant information for presentation and/or rendering with minimal latency from the buffer.</p>
<p id="p-0066" num="0065">In some embodiments, the data structure is laid out in such a way that the lens item is displayed first with the data elements of the relevant subset displayed from nearest to furthest. In some embodiments, the relationship is spatially based to insure that the part of the relevant data subset that is within the visible window of the particular display is presented first. The display screen size of some embodiments, is relatively small in comparison to the entire data set and the relevant data subset. In these embodiments, the user is provided a high quality experience by the quick updates presented on the small viewable display screen. In the event that the new lens item to be displayed is the result of the user scrolling through the data matrix by using, for example, a scroll back function, the relevant data subset will likely be already cached from having been previously displayed, while the needed relevant data subset requested by, for example, a scroll forward function, is typically pre-cached.</p>
<p id="p-0067" num="0066">D. The Expand Icon</p>
<p id="p-0068" num="0067">As illustrated in <figref idref="DRAWINGS">FIGS. 4 and 5</figref>, the matrix <b>400</b> and <b>500</b> of some embodiments includes an expansion icon <b>445</b> and <b>545</b>, respectively. The expansion icon of these embodiments provides a third dimension for navigation within the matrix of some embodiments. In these embodiments, many data elements contained in the cells of the matrix have multiple members and some columns of the matrix represent super categories or sets and super sets of other elements. For example, a playlist typically has several songs associated with the playlist, while a movie has multiple actors in the movie. Television series typically consist of multiple individual shows, books contain chapters, series of books contain individual books, and games often have multiple episodes, stages, or levels.</p>
<p id="p-0069" num="0068">However, because the display screen size of the physical embodiments typically used to view the data matrix is limited, the default position for the expansion icon of some embodiments is closed. When the expansion icon of these embodiments is closed, the cell having the closed expansion icon presents only a single data element, such as, for example, the lead actor of the movie, or the first song of the playlist. In the embodiments shown in <figref idref="DRAWINGS">FIGS. 4 and 5</figref>, a cell that contains multiple members has a downward pointing arrow <b>445</b> and <b>545</b> in the right portion of the cell. In these embodiments, a user views the additional relevant items associated with the particular cell having the closed expansion icon, by clicking on the closed expansion icon to open it. Some embodiments provide the additional information by populating additional row(s) in the matrix. In some of these embodiments, the arrow changes to an upward pointing arrow to indicate that the expansion icon has been selected. However, one of ordinary skill will recognize that the expanded hidden data elements of the cell is presented differently in different embodiments, such as, for example, through a drop down list.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 6</figref> illustrates a process <b>600</b> employed by some embodiments to expand a cell's data contents. The process <b>600</b> begins at the step <b>605</b>, where a data subset is selected for expansion. As mentioned above, the data subset in these embodiments typically only contains relevant data out of the entire large set of data from the available sources. The data subset typically includes the elements that are initially visible, for example, the lead actor, in addition to the elements that are not visible, for example, all the actors in the particular movie. Although the hidden data is not displayed, the entire data subset is typically cached to memory. Next, at the step <b>610</b>, the expansion icon is selected, to open the hidden data elements represented by the particular cell in the matrix. Then, at the step <b>615</b>, the number of rows needed to display the additional data is calculated. Once the number of additional rows needed is calculated, the rows below the selected cell are moved downward to make room for the calculated number of additional rows needed at the step <b>620</b>. After the number of rows below the selected cell is increased, the additional rows' cells are populated with the relevant data that was previously hidden from view at the step <b>625</b>. The process <b>600</b> then concludes.</p>
<p id="p-0071" num="0070">When a column containing an expanded cell is not the first column, the cells of adjacent columns in the expanded rows do not always contain and/or present data. When a column containing an expanded cell is the first column, the rest of the row is typically not blank, particularly where the column is a super column, such as, for example, a column containing data that has nested sublayers and/or subsets of data. For instance, if a playlist is expanded into its individual songs, the adjacent columns typically contain relevant associated data such as, for example, the artist and/or composer, for each song. The additional relevant information typically populates the adjacent cells of each row as illustrated above. Further, selecting the expand icon arrow of a cell while it is expanded, closes the open list and hides the additional members of the list, but typically leaves the now hidden data elements in memory cache.</p>
<p id="p-0072" num="0071">E. Display of the Data Matrix When Scrolling</p>
<p id="p-0073" num="0072">When scrolling slowly, the presented data matrix appears to crawl across the display screen. When scrolling more quickly, the selected cell, that is the cell highlighted in the data matrix of some embodiments, traverses a whole display screen of cells at a time. In these embodiments, the lens field typically remains fixed while the lens item within the field updates dynamically to reflect the latest data element currently highlighted and/or selected in the matrix currently being viewed with higher scrutiny. In some embodiments, when scrolling is performed very quickly, only the first letter or letters are displayed in the selected cell until scrolling stops or slows enough for a user to read the changing contents of the updating views of the matrix in the display screen. Because the display screen of some embodiments' user interface is designed to navigate large sets of data, some embodiments truncate the display based on the speed of scrolling so that the user can effectively determine the current navigational position in the matrix that is presented in the display screen.</p>
<p id="p-0074" num="0073">In some embodiments, when scrolling through a temporally ordered list, the relevant dates are displayed instead of the individual elements. The data elements may have little relevance other than the temporal sequence of the date ordering. The row-by-row information presented in these embodiments is confusing because of the varied data. However, some embodiments present the dates in the order Year, Month, Day so that only the end of the displayed row will change most often while scrolling through the date ordered list. These embodiments provide a more convenient presentation of the data.</p>
<p id="h-0009" num="0000">III. User Interface Device</p>
<p id="p-0075" num="0074">Some embodiments provide a user interface that allows a user to intuitively navigate through a large data set with minimal effort, and/or minimal user input. More specifically, some embodiments provide a user interface device as the means for a user to access, navigate, organize, and view the large data set in smaller subsets. <figref idref="DRAWINGS">FIG. 7</figref> illustrates such a user interface device <b>700</b>. As shown in this figure, the user interface device <b>700</b> includes a device display <b>705</b>, an enter button <b>710</b>, a communication module <b>715</b>, a scroll wheel <b>720</b>, a sort button <b>725</b>, a bind button <b>730</b>, a back button <b>735</b>, and a forward button <b>740</b>.</p>
<p id="p-0076" num="0075">A. Communicating with External Devices and Sources such as Storages and Networks.</p>
<p id="p-0077" num="0076">The communication module <b>715</b> of some embodiments includes a data port for communication with other devices and/or network services. For instance, the communication module <b>715</b> of some embodiments communicates and integrates with several displays or other domestic appliances, such as, for example, DVD players, VCRs, cable boxes, stereos, and DVRs, by using, for example, infrared (IR) and/or radio frequency (RF) communication. The communication module <b>715</b> of some embodiments communicates with networked devices through a docking port, wire lines, or wireless communication, such as, for example, IR, RF, microwave, 802.11, and Bluetooth&#xae;. Network and non-network devices with which the communications port <b>715</b> connects include, for example, digital music players, computers, laptops, cell phones, PDAs, and digital cameras. Some embodiments support multiple simultaneous connections.</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. 10</figref> illustrates the user interface device <b>700</b> of some embodiments connecting to a variety of external devices. Specifically, the user interface device <b>700</b> connects via a transceiver <b>1005</b> that is connected through a network <b>1010</b> to a variety of devices that include a computer <b>1015</b> and a server <b>1020</b>. One of ordinary skill will recognize that the connections occur differently in different embodiments, such as, for example, wired, docked, wireless, and remote. In some embodiments, the connections are for sending, receiving, and/or both to and/or from the external devices. For instance, at times the user interface device <b>700</b> connects to the external devices to collect and/or receive data from one or more data sources, while at times the user interface device <b>700</b> connects to the external devices to send and/or render data to the external devices. For instance, the user interface device <b>700</b> of some embodiments attaches to a nearby audio system or component for rendering audio content presented in the data matrices compiled and presented as described above. In some embodiments, the attached audio system has access to its own store of content and metadata, while in some embodiments the external audio equipment has access to the content and metadata that is stored in the user interface device <b>700</b>. Some embodiments of the device <b>700</b> connect to external displays or entertainment centers for providing and/or rendering the data in other ways.</p>
<p id="p-0079" num="0078">B. Binding to External Devices such as Monitors and Displays</p>
<p id="p-0080" num="0079">As mentioned above, the communication module <b>715</b> is used by some embodiments to connect or bind to a variety of displays, devices, and/or peripherals that are external to the user interface device <b>700</b>. <figref idref="DRAWINGS">FIG. 11</figref> illustrates the user interface device <b>700</b> of some embodiments binding and transmitting information to an external display screen <b>1100</b>. In these embodiments, the external display screen <b>1100</b> provides a number of functions, for instance, rendering of certain media data elements browsed and selected by using the user interface device <b>700</b>.</p>
<p id="p-0081" num="0080">In some embodiments, the user interface device <b>700</b> is used for remote control of one or more external devices. The user interface device <b>700</b> of these embodiments is capable of selecting an external video display from a set of displays and binding to the selected display. In some embodiments, the binding is for display only and does not affect the content associated with the attached display, while in some embodiments, binding to the external display device is for rendering the media data. If the attached display is to render content, it either has access to its own store of content and metadata or it displays the content and metadata that is stored in the user interface device <b>700</b>. As mentioned above, the user interface device <b>700</b> of some embodiments further includes additional features for interaction with a user and a set of external devices such as entertainment system components. These features include the additional buttons of a remote control device, in some embodiments. Such a user interface device controls and/or renders data content on one or more external devices. In some embodiments, the user selects from a set of external devices over a variety of communications modes, such as, for example, IR, RF, and 802.11. The remote control feature of some embodiments is further described below in relation to <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0082" num="0081">In some embodiments, once data elements are selected for rendering, their media content are rendered on either the remote display, audio/video component system, and/or another external device. Regardless of whether the user interface device of these embodiments is used to drive an external device, such as an external display, the user interface device <b>700</b> of some embodiments has a built in device display <b>705</b>. The device display <b>705</b> displays data and information fields, such as, for example, a full display of options and data matrices such as the matrices described above, or just information as needed, for instance, to select from a number of available external devices, display screens, and/or monitors.</p>
<p id="p-0083" num="0082">1. Bind Button</p>
<p id="p-0084" num="0083">The bind button <b>730</b> of some embodiments is used for binding the buttons and scroll wheel(s) of the user interface device <b>700</b> to an external device such as, for example, an external display. The bind button <b>730</b> binds the user interface to the external device to allow the user to access or control the external device. Some embodiments perform binding by using a bind process <b>1300</b> illustrated in <figref idref="DRAWINGS">FIG. 13</figref>. The bind process <b>1300</b> of <figref idref="DRAWINGS">FIG. 13</figref> begins at the step <b>1305</b>, where a user presses the bind button <b>730</b> and the user interface device <b>700</b> discovers the external device. The process <b>1300</b> of some embodiments uses a discovery device. The discovery device of some embodiments typically involves a wireless mechanism, such as, for example, IR for line of sight, RF or IR repeater, if the line of sight is interrupted by a physical feature, such as a wall. The process <b>1300</b> of these embodiments typically discovers the external device by pointing the user interface device <b>700</b> at the external device such as an external display, or a television, for instance.</p>
<p id="p-0085" num="0084">Once the external device is discovered, the communications protocol is established at the step <b>1310</b>. In some embodiments, the data communication between the user interface device <b>700</b> and the external device uses the same protocol(s) as the discovery device of the step <b>1305</b>, while the communications protocol of some embodiments is different. For instance, the discovery mechanism of some embodiments uses IR for ease of pointing and selecting, but the data communications channel uses 802.11 because of the required throughput. When the communications protocol has been established, it is determined at the step <b>1315</b> whether more than one data subset is available. If more than one data subset is not available, then at the step <b>1320</b>, the external device responds by presenting (displaying, playing, and/or rendering) the available data. If there is more than one subset of available data, then, at the step <b>1325</b>, the appropriate data subset is selected from among any possible combination of the available data subsets. In some embodiments, the data subsets are the data associated with:</p>
<p id="p-0086" num="0085">(1) the external device, if the external device is a portable device with its own storage;</p>
<p id="p-0087" num="0086">(2) the external device, if the external device is a display that is directly connected to a set of data, and/or</p>
<p id="p-0088" num="0087">(3) the network, if the external device is associated with either a local or wide area network that is accessible from the external device, or in some cases, by using a remote control unit for the external device. Once the available data subset is selected, the external device presents the selected data subset at the step <b>1320</b>. The process <b>1300</b> then concludes.</p>
<p id="p-0089" num="0088">C. Orientation</p>
<p id="p-0090" num="0089">In some embodiments, the device display <b>705</b> displays the data in particular ways according to a user preference setting or an orientation of the user interface device <b>700</b>. In some embodiments, the user interface device <b>700</b> further includes an orientation module <b>745</b> for determining whether the device <b>700</b> is held vertically, with the scroll wheel <b>720</b> positioned to a side, or horizontally, with the scroll wheel <b>720</b> positioned on the top or bottom in relation to the device <b>700</b>. In some embodiments, the orientation module <b>745</b> further determines if the user interface device <b>700</b> has been rotated clockwise or counter-clockwise. Orientation and rotation determining means are both known in the art and include, for example, IC chips, mercury switches, and gyroscopes. Further, the orientation module <b>745</b> of some embodiments includes an accelerometer means to determine the speed at which the user interface device <b>700</b> is being rotated. The significance in some embodiments of the user interface device's orientation will be described in the next section.</p>
<p id="p-0091" num="0090">D. Navigation by using the Scroll Wheel</p>
<p id="p-0092" num="0091">The scroll wheel <b>720</b> of some embodiments is a knurled wheel set, which is typically rotatably mounted in the side of the case of the user interface device <b>700</b>. The scroll wheel <b>720</b> of some embodiments is also clickable, meaning the wheel <b>720</b> is depressed similar to a button to enable or execute a function. The scroll wheel <b>720</b> allows viewing of data that does not fit in one page view of the device display <b>705</b>. In some embodiments, the wheel <b>720</b> is mounted on the right side of the user interface device <b>700</b>, while in some embodiments the wheel <b>720</b> is mounted on the left side or, alternatively, both sides. In some embodiments, one scroll wheel provides multiple functions that are user selectable based on various parameters, for instance, the orientation of the user interface device <b>700</b>. Some embodiments provide several separate scroll wheels, such as, for example, four separate wheels, to separate the functions of one wheel into four user selectable wheels. In the embodiments having four separate scroll wheels, each wheel is positioned on each side of the device <b>700</b>. Regardless of the location or number of wheels, the functionality of the scroll wheel <b>720</b> of some embodiments is as follows.</p>
<p id="p-0093" num="0092">When the user interface device <b>700</b> is in the portrait orientation, as in <figref idref="DRAWINGS">FIG. 7</figref>, rotating the wheel <b>720</b> up moves the highlighting, that is around the currently selected (highlighted) cell, up through the cells of the presented matrix. Further, when the next to the top row is reached the highlighting remains fixed at that row such that the cells scroll upward under the fixed row. Rotating the wheel <b>720</b> down moves the highlighting downward and when the next to the bottom row is reached the highlighting remains fixed at that row such that the cells scroll downward under the fixed row. Clicking the wheel <b>720</b> moves the contents of the selected cell to the lens field <b>705</b>, in some embodiments. In some embodiments, the contents of the selected cell is moved to the lens field <b>705</b> by using another button, such as, for example, the enter button <b>710</b>.</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. 8</figref> illustrates the user interface device <b>800</b> rotated to a horizontal landscape position. <figref idref="DRAWINGS">FIG. 9</figref> illustrates that the landscape orientation is achieved by rotating the user interface device <b>900</b> to either of its horizontal sides. As illustrated in <figref idref="DRAWINGS">FIG. 8</figref>, when the user interface device <b>800</b> is positioned in the landscape position, rotating the wheel <b>820</b> scrolls the data left or right. More specifically, rotating the wheel <b>820</b> to the right moves the highlighting to the right through the cells. In these embodiments, when the rightmost column is reached, the highlighting remains fixed and the cells scroll to the left out from under the fixed column. Rotating the wheel <b>820</b> left moves the highlighting left and when the leftmost column is reached, the highlighting remains fixed and the cells scroll to the right under the fixed column. As mentioned above, one of ordinary skill will recognize several variations of the embodiments that do not depart from the present invention, such as, for example, variations in the number, placement, and function of the scroll wheels, buttons, and other implementation details of the device(s) described above.</p>
<p id="p-0095" num="0094">Additionally, clicking the scroll wheel <b>820</b> has numerous functions, in different embodiments. In some embodiments, clicking the scroll wheel <b>820</b> executes an expand/contract function similar to that described above in relation to the expansion icon, while in some embodiments, the expand/contract function is performed by another button, e.g. the enter button <b>810</b>. Also described above, clicking the scroll wheel <b>820</b> of some embodiments selects a data element for the lens item and moves the contents of the selected cell into the lens field <b>805</b>. The scroll wheel <b>820</b> of some embodiments further features the following functions, in addition to others:</p>
<p id="p-0096" num="0095">(1) Variable&#x2014;the longer the wheel is held in an up or down rotated position, the faster a function is performed, such as, for example, scrolling. The wheel of these embodiments is spring loaded and returns to center when released.</p>
<p id="p-0097" num="0096">(2) Multi-jog, up or down&#x2014;two jogs increases the rate of a function and three jogs provides an even greater increase. In these embodiments, the wheel is typically spring loaded and returns to center when released.</p>
<p id="p-0098" num="0097">(3) Continuously Variable&#x2014;the wheel spins freely, with optional detents, and increases the function performed with the angle of its rotation. For instance, in some embodiments, the first motion, for example, between 10&#xb0; and 40&#xb0;, creates a slow scrolling effect, e.g., line-by-line. However, continuing to rotate the wheel in the same direction increases the scroll speed, e.g., page-by-page. Reversing direction slows the scroll speed until it finally stops and then accelerates in the opposite direction.</p>
<p id="p-0099" num="0098">In some embodiments, the physical feel of the wheel is such that a user easily navigates (scrolls) slowly in one direction and then scrolls back slightly, not necessarily the exact number of degrees or speed as the movement in the original direction, and the scrolling will slow or stop in either direction. In the same way, the user of some embodiments navigates forward through a data matrix. By rotating the wheel further in the same direction, the matrix will scroll faster forward. The user of these embodiments similarly slows or stops scrolling by rotating the wheel back slightly. The motion of the wheel is such that changing speeds or stopping is intuitive and convenient. In some embodiments, clicking the scroll wheel at any speed stops the scrolling. Clicking the scroll wheel again (double-clicking) in some embodiments moves the contents of the currently selected cell into the lens field for navigation based on the new criteria.</p>
<p id="p-0100" num="0099">The sort button <b>825</b> of some embodiments changes the ordering of the currently presented data subset. In some embodiments, the ordering is context sensitive depending on the data content of the subset. For example, the content based ordering of some embodiments switches between, for example, alphabetical ordering, release date, photo taken-on-date, and/or date last rendered. Less common orderings are available in some embodiments by pressing the sort button <b>825</b> in conjunction with another button, for example, the enter button <b>810</b>. Less common or more sophisticated orderings include, for example, mood (for music); color (for pictures); genre (for television shows, music, articles).</p>
<p id="p-0101" num="0100">E. Additional Embodiments of the User Interface Device</p>
<p id="p-0102" num="0101">1. Voice Activation</p>
<p id="p-0103" num="0102">Some embodiments of the user interface device include voice or audio recognition that permit a user to activate the features of the user interface device by voice command, for example, by speaking into the device commands such as &#x201c;up, faster . . . faster, pause.&#x201d; These embodiments include a recognition module that receives and interprets commands to perform various functions described above such as, for example, scroll the data, select lens items, rotate the text, communicate with other devices, and update the data set.</p>
<p id="p-0104" num="0103">2. Remote Control Devices</p>
<p id="p-0105" num="0104">The user interface device of some embodiments provides control of one or more external devices in addition to access and functionality to navigate through data in an intuitive and efficient manner. <figref idref="DRAWINGS">FIG. 12</figref> illustrates the user interface device <b>1200</b> of some embodiments communicating with a plurality of representative external devices <b>1205</b>. As shown in <figref idref="DRAWINGS">FIG. 12</figref>, the user interface device <b>1200</b> of some of these embodiments includes many buttons of standard remote control devices and/or portable players, for example, play, pause, fast forward, rewind, and menu. Although described in relation to the user interface device of the embodiments described above, one of ordinary skill will recognize that any or all of the described functions and features of the user interface device is capable of incorporation into any number of devices, such as a portable media player, or a remote control device, as, for example, for a television, VCR, and/or audio component.</p>
<p id="p-0106" num="0105">3. Display Screen&#x2014;Dynamic Aspect Ratio</p>
<p id="p-0107" num="0106">In some embodiments, the display screen has horizontal text regardless of how it is turned. For instance, the display screen presents a landscape view regardless of the orientation of the device, for example, with the buttons above, below, to the left or right. In the portrait view of some embodiments, there is typically room for more rows than columns and in landscape view, more columns than rows. The method of keeping the text horizontal includes the following steps in some embodiments: (1) determining if the device is held in a substantially vertical orientation, whether it was previously in a landscape or portrait view; (2) aligning the text in the display, and the appropriate dimensions of the cells, so that the text reads in the appropriate direction for the language being used, such as, for example, from left-to-right for the English language. The result is that if the device is rotated 90 degrees, the text will rotate 90 degrees in the opposite direction to remain legible; (3) if the device is not held in a substantially vertical orientation, a predetermined default view is adopted by some embodiments, for example, either portrait or landscape; (4) when the device is rotated at a reasonable speed of rotation, such as, for example, 15 RPM, over greater than 70 degrees, the text rotates 90 degrees in the opposite direction.</p>
<p id="p-0108" num="0107">Additionally, in some embodiments, the functionality of the scroll wheel(s) is affected by the rotation of the display screen such that when the display screen switches from a landscape to a portrait view, vertical scroll wheels act as horizontal scroll wheels and horizontal scroll wheels act as vertical scroll wheels.</p>
<p id="p-0109" num="0108">4. Example</p>
<p id="p-0110" num="0109">The following illustrates an example of how a user interacts with some embodiments. The user interface device of some embodiments initially presents a portrait view of a matrix that represents a particular data subset. The data subset includes movies in alphabetical order. In this instance, the user interface device collected the movie data subset by connecting, for example, to a personal computer, a home DVD jukebox, and an online video subscriber service via the Internet. The movie data subset is large and a number of items are displayed at once as a user of the device scrolls quickly through the data. The user scrolls through the ordering of movies by using the scroll wheel on a vertical side of the device. The user stops at a particular movie and turns the device 90 degrees while still holding a thumb or finger on the same scroll wheel.</p>
<p id="p-0111" num="0110">When the device rotates, the aspect ratio of the presented view changes from a portrait to a landscape view. The user is then presented fewer movies in the ordered list in the landscape view, however, the user does not require a listing of many movies because the user has already chosen a movie to view in greater detail. Instead, the user of these embodiments is presented a view containing more associated categories for each movie. By using the same scroll wheel, which was oriented initially as a vertical scroll wheel but is now oriented as a horizontal scroll wheel, the user scrolls across the categories to reveal additional the data (in columns) that do not fit within the horizontal/landscape view.</p>
<p id="p-0112" num="0111">When the user reaches the column for the actor category, for instance, the user clicks the scroll wheel to expand the category to show all the actors in the particular movie. The user of some embodiments further rotates the device back 90 degrees to present more data elements in the actor category for the particular movie by using the vertically longer portrait mode. The user scrolls down through the actors and selects a (first) actor by again clicking the wheel. However, the user is currently clicking the wheel in the vertical device mode. The (first) actor currently selected by the clicking moves to the lens field and becomes the new lens item. The user views the data elements associated with the selected actor now serving as the current lens item, in even greater detail. The user then scrolls, in some embodiments, to the data field listing the movies in which the particular selected actor has played a part. Here, the user click selects on a second movie to move the second movie to the lens field. Likewise, the user chooses a second actor, a director, or a composer, for example, associated with the second movie to present and view data relevant to the selected person in the second movie in greater detail. One of ordinary skill will recognize the various manners in which this process continues. Further, in this scenario, the user selects a particular image or movie from the presented data matrix for rendering. Initially, the user chooses to render the selected data, for example, a movie, on the built in device display. Then, however, the user decides to select an external home theater system for rendering the movie by using the user interface device.</p>
<p id="h-0010" num="0000">IV. Advantages</p>
<p id="p-0113" num="0112">The lens field of some embodiments has the benefit of allowing the lens item to change very quickly, as well as move and jump dynamically while navigating through a potentially massive data set. The user of these embodiments effectively &#x201c;surfs&#x201d; through the data using an associative approach that more closely models the way by which memory and recall works. Typically, people remember things associatively and temporally. For example, one might recall seeing a particular product on sale, a tea set, in a store window on a particular street on a night of dining on the street, Main Street, with a particular friend, John. Without the additional associative cues, it is more difficult for the individual to recall the name of the store or the street address, in a vacuum, without any additional information.</p>
<p id="p-0114" num="0113">The ability to surf through the data using associative and temporal cues has a significant impact on how quickly and successfully a user finds the needed information. The method of some embodiments leverages the information of primary, secondary, tertiary, relevance that is already known to the user. In contrast, general purpose search engines typically perform simple naked keyword look ups, in a vacuum, without additional cues regarding associative relationships.</p>
<p id="p-0115" num="0114">Another benefit of the present invention is the reduction of latency. Specifically, the present invention reduces the latency caused by the reformatting and redisplaying of data on the particular display screen being used. For instance, some embodiments reduce display latency and provide fluid scrolling of the data matrix. Additionally, some embodiments minimize latency of data searching and presentation by buffering and/or associatively caching. For instance, the most recent views are stored in memory so that the steps of navigation can be traced backwards by using a back function and retraced forward by using a forward function of some embodiments. Some embodiments will store up to 40 previous views, while other embodiments will store another number of previous views. In some embodiments, the stored views provide a &#x201c;history&#x201d; that persists between the data navigation sessions. Traversing navigation screens often takes a circuitous path that is difficult to reconstruct. The ability to retrace previous steps assists a user in locating data in additional ways, for instance, based on chronological histories.</p>
<p id="p-0116" num="0115">The concept of zoom has not been used as an intuitive mechanism for focusing on specific areas of large data sets. Some embodiments enable the user to set the viewable area to an appropriate size not only for the resolution of the particular viewing display screen but also to limit the field of view to parsable chunks of data for each particular user. These embodiments are particularly useful when viewing on a high resolution external display where the size of the font can be adjusted based on how close the user is to the display screen.</p>
<p id="p-0117" num="0116">Moreover, the methods described above present a novel approach. Searching and navigation features have not typically been applied in non-computer environments. More specifically, searching by using the methods and apparatus described above are particularly fruitful when looking for data in large data sets. Some embodiments streamline user control and input. In some embodiments, a small keyboard is attached to the user interface device or other viewing apparatus of some embodiments to further enhance the searching and navigation functions. In some of these embodiments, the small keyboard is folded down for storage and optionally revealed to facilitate user input for faster searching.</p>
<p id="p-0118" num="0117">While the invention has been described with reference to numerous specific details, one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. Thus, one of ordinary skill in the art will understand that the invention is not to be limited by the foregoing illustrative details, but rather is to be defined by the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A user interface device, the user interface device comprising:
<claim-text>a communications module for collecting a data set independent of a user-entered search query, the data set available from a plurality of different types of hardware sources;</claim-text>
<claim-text>a processor for executing a set of instructions that limit the data set into a first subset based on a first lens item;</claim-text>
<claim-text>a storage module for storing the first subset;</claim-text>
<claim-text>a display screen for presenting a matrix comprising a set of data cells, the matrix representing the first subset; and</claim-text>
<claim-text>a set of controls for navigating through the matrix of data cells.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The user interface device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the communication module comprises a wireless protocol.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The user interface device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the user interface device binds to an external device, the external device for presentation of data.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The user interface device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the external device renders the data.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The user interface device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the user interface device controls the external device.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The user interface device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the set of controls comprises a set of buttons, wherein the binding attributes certain functions for controlling the external device to particular controls in the set of controls.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The user interface device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the set of controls comprises a scroll wheel.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The user interface device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the scroll wheel includes one or more functions selected from a set comprising clickable, variable speed rotation of the wheel, jog, and shuttle.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The user interface device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising an orientation module, wherein the orientation module determines the rotational orientation of the user interface device.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The user interface device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the orientation module determines the direction and rate of rotation for the user interface device.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The user interface device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the presentation of the matrix is based on the orientation of the user interface device.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The user interface device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the function of the set of controls is based on the orientation of the user interface device.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The user interface device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a voice recognition module for receiving audio commands that control the user interface device.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A user interface for presentation of data, the user interface comprising:
<claim-text>a lens field for receiving a lens item, the lens item comprising a data element, and presenting the lens item;</claim-text>
<claim-text>a matrix of data cells, the data cells for representing a subset of a larger data set collected independent of a user-entered search query, the matrix having a first column and a set of column headings, wherein the lens item has a relationship to one or more data cells in the matrix, and further wherein the matrix presents an organization of the data cells based on the relationship, further wherein the lens item comprises a category and non-members of the category are excluded from the matrix.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The user interface of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein a particular data cell in the matrix is selected for presentation in the lens field.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The user interface of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the user interface updates based on the selected particular data cell.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The user interface of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein a plurality of data cells in the matrix comprise metadata.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The user interface of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the matrix scrolls to reveal hidden data.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The user interface of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising an expansion icon, the expansion icon used for revealing hidden data.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The user interface of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the first column is ordered based on a relationship to the lens item.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The user interface of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the column headings are determined based on the data contained in the cells of the columns.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The user interface of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the data cells in the matrix are populated by cross referencing each column heading with the cells in each row of the first column.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. A user interface device, the user interface device comprising:
<claim-text>a communications module for collecting a data set independent of a user-entered search query, the data set available from a plurality of different types of hardware sources;</claim-text>
<claim-text>a processor for executing a set of instructions that limit the data set into a first subset based on a first lens item, wherein the first lens item comprises a category and non-typical associations of the category are excluded from the first subset;</claim-text>
<claim-text>a storage module for storing the first subset;</claim-text>
<claim-text>a display screen for presenting a matrix comprising a set of data cells, the matrix representing the first subset; and</claim-text>
<claim-text>a set of controls for navigating through the matrix of data cells.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
