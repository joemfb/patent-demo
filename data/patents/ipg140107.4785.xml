<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625878-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625878</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13087490</doc-number>
<date>20110415</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>269</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382141</main-classification>
<further-classification>382190</further-classification>
</classification-national>
<invention-title id="d2e53">Method and system of rail component detection using vision technology</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4779095</doc-number>
<kind>A</kind>
<name>Guerreri</name>
<date>19881000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>340904</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6163755</doc-number>
<kind>A</kind>
<name>Peer et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701301</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7216060</doc-number>
<kind>B1</kind>
<name>Yano et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702184</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7406400</doc-number>
<kind>B2</kind>
<name>Yano et al.</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702184</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7411660</doc-number>
<kind>B2</kind>
<name>Cho et al.</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356  301</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7463348</doc-number>
<kind>B2</kind>
<name>Chung</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3562371</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7570794</doc-number>
<kind>B2</kind>
<name>Swanger et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382141</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7616329</doc-number>
<kind>B2</kind>
<name>Villar et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356625</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7659972</doc-number>
<kind>B2</kind>
<name>Magnus et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3562371</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7692800</doc-number>
<kind>B2</kind>
<name>Sanpitak</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356614</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7714886</doc-number>
<kind>B2</kind>
<name>Kilian et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348135</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7755660</doc-number>
<kind>B2</kind>
<name>Nejikovsky et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348143</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>8081320</doc-number>
<kind>B2</kind>
<name>Villar et al.</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356606</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>8493446</doc-number>
<kind>B2</kind>
<name>Li et al.</name>
<date>20130700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348148</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2004/0263624</doc-number>
<kind>A1</kind>
<name>Nejikovsky et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2006/0017911</doc-number>
<kind>A1</kind>
<name>Villar et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356  401</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2007/0217670</doc-number>
<kind>A1</kind>
<name>Bar-Am</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382141</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2008/0012860</doc-number>
<kind>A1</kind>
<name>Klefenz et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345441</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2009/0196486</doc-number>
<kind>A1</kind>
<name>Distante et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382141</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2010/0026551</doc-number>
<kind>A1</kind>
<name>Szwilski et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>342 22</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2011/0064273</doc-number>
<kind>A1</kind>
<name>Zarembski et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382104</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2012/0263342</doc-number>
<kind>A1</kind>
<name>Haas et al.</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2013/0101221</doc-number>
<kind>A1</kind>
<name>Fujiki et al.</name>
<date>20130400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382195</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2013/0176435</doc-number>
<kind>A1</kind>
<name>Haas et al.</name>
<date>20130700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348148</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>International Search Report and Written Opinion, PCT Application No. PCT/US2012/33706, p. 1-8 (Jul. 2, 2012).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Rujiao, D. et al. &#x201c;Automatic Inspection Method of Steady Arm Slope Based on Computer Vision&#x201d; IEEE, International Conference on Measuring Technology and Mechatronics Automation, pp. 714-718. DOI 10.1109/ICMTM A.2010.424 (Mar. 2010).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Hart, M. J. et al. &#x201c;A Machine Vision System for Monitoring Railcar Health: Preliminary Results&#x201d; TD-04-008. Technology Digest: Timely Technology Transfer, pp. 1-4 (Jun. 2004).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Edwards, J. R. et al. &#x201c;Development of Machine Vision Technology for Railcar Safety Appliance Inspection&#x201d; University of Illinois at Urbana-Champaign, pp. 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>24</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382141</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382190</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>18</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120263342</doc-number>
<kind>A1</kind>
<date>20121018</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Haas</last-name>
<first-name>Norman</first-name>
<address>
<city>Mount Kisco</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Li</last-name>
<first-name>Ying</first-name>
<address>
<city>Mohegan Lake</city>
<state>CT</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Otto</last-name>
<first-name>Charles A.</first-name>
<address>
<city>Lansing</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Pankanti</last-name>
<first-name>Sharathchandra</first-name>
<address>
<city>Darien</city>
<state>CT</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Haas</last-name>
<first-name>Norman</first-name>
<address>
<city>Mount Kisco</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Li</last-name>
<first-name>Ying</first-name>
<address>
<city>Mohegan Lake</city>
<state>CT</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Otto</last-name>
<first-name>Charles A.</first-name>
<address>
<city>Lansing</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Pankanti</last-name>
<first-name>Sharathchandra</first-name>
<address>
<city>Darien</city>
<state>CT</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Tuchman</last-name>
<first-name>Ido</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Dougherty</last-name>
<first-name>Anne V.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Patel</last-name>
<first-name>Jayesh A</first-name>
<department>2669</department>
</primary-examiner>
<assistant-examiner>
<last-name>Kholdebarin</last-name>
<first-name>Iman K</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method, system, and computer program product for automatically inspecting railroad tracks. The method includes assessing a configuration of rail components depicted in an image by comparing the configuration of the rail components to known hazards. The method also includes determining a severity of detected problems in the configuration of the rail components, using a computer processor.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="172.13mm" wi="153.50mm" file="US08625878-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="279.40mm" wi="205.49mm" orientation="landscape" file="US08625878-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="192.79mm" wi="173.99mm" file="US08625878-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="198.97mm" wi="163.41mm" file="US08625878-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="160.10mm" wi="173.99mm" file="US08625878-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="164.08mm" wi="182.12mm" file="US08625878-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="222.84mm" wi="131.06mm" file="US08625878-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="214.71mm" wi="167.22mm" file="US08625878-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="196.77mm" wi="142.83mm" file="US08625878-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="240.88mm" wi="93.98mm" file="US08625878-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="221.40mm" wi="141.39mm" file="US08625878-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">The present invention is directed to the field of railroad track inspection, and more specifically to a method and system of rail component detection using vision technology.</p>
<p id="p-0003" num="0002">To maintain safe and efficient operations, railroads must inspect their tracks for physical defects on a regular basis. Track inspections are not only required by Federal Railroad Administration (FRA) regulations, but also enforced by individual railroad companies, usually with more stringent requirements, to maintain track health to a higher standard. Such track inspection normally covers a wide spectrum of tests, ranging from detecting surface cracks on the rail, measuring rail profile and gauge size, to monitoring the conditions of joint bars, spikes and anchors. Some of these inspections, such as the measurement of the position, curvature and alignment of the track, have already been automated using a track geometry car, yet others, such as monitoring the spiking and anchor patterns, and detecting raised or missing spikes and anchors, are still manually and visually conducted by railroad track inspectors.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0004" num="0003">An example embodiment of the present invention is a method for automatically inspecting railroad tracks. The method includes assessing a configuration of rail components depicted in an image by comparing the configuration of the rail components to safety requirements for the rail components. The method also includes determining a severity of detected problems in the configuration of the rail components, using a computer processor.</p>
<p id="p-0005" num="0004">Another embodiment of the invention is a system for automatically inspecting railroad tracks. The system includes a processor and a memory coupled to the processor. The memory includes computer readable program code embodied on it which is configured to assess a configuration of rail components located in an image by comparing the configuration of the rail components to safety requirements for the rail components and determine the severity of problems in the configuration of the rail components.</p>
<p id="p-0006" num="0005">A further embodiment of the invention is a computer program product for automatically inspecting railroad tracks. The computer program product includes a computer readable storage medium having computer readable program code embodied on it. The computer readable program code is configured to assess a configuration of rail components located in an image by comparing the configuration of the rail components to safety requirements for the rail components and determine the severity of problems in the configuration of the rail components.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0007" num="0006">These and other aspects, features, and advantages of the present invention will become apparent upon further consideration of the following detailed description of the invention when read in conjunction with the drawing figures, in which:</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example architecture of a system of automatic railroad track inspection.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart illustrating an example method for automatically inspecting railroad tracks, as contemplated by the present invention.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart illustrating an example implementation of the region-based method of rail component localization, as contemplated by the present invention.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating an example implementation of the edge-based method of rail component localization, as contemplated by the present invention.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a system for automatically inspecting railroad tracks.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an example system for automatically inspecting railroad tracks as contemplated by the present invention.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 7</figref> shows an example of various rail components in a captured video frame as contemplated by the present invention.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 8A</figref> illustrates an example of a Hough transform performed on an example image as contemplated by the present invention.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 8B</figref> is an example magnitude map which is plotted according to aspects of the present invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 8C</figref> illustrates an example of summed magnitude map as contemplated by the present invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 9A</figref> illustrates the spike search region in an example embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 9B</figref> shows the resulted voting space from an example embodiment of the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 10A</figref> is an example spike search region as contemplated the present invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 10B</figref> shows the Sobel edge map of this image region in an example embodiment of the present invention.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 10C</figref> illustrates four detected Regions of Interest (ROI) in an example embodiment of the present invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 11A</figref> is an example of the anchor detection process as contemplated by the present invention.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 11B</figref> illustrates a plot of the magnitude map of an example implementation of the present invention.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 11C</figref> illustrates an anchor detection plot as contemplated by the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0026" num="0025">It is of great interest to railroad companies to enhance the current manual inspection process using machine vision technology for more efficient, effective and objective inspections. It also helps lower maintenance cost and improve track capacity. Aspects of the current invention include 1) monitoring of spiking and anchor patterns; 2) detection of spikes whose heads are raised above the tie plate by more than one inch, as well as spikes that are deadheads; 3) detection of displaced anchors that have moved more than a half inch away from the tie; and 4) detection of any missing bolts, as well as missing nuts and washers, from rail joint bars.</p>
<p id="p-0027" num="0026">Here, a spiking pattern refers to the layout of spikes on a tie plate, which hold it in place to prevent the rail from latitudinal movement. Specific spiking patterns are required for specific classes of tracks (as well as their degrees of curvature). Applying wrong or non-compliant spiking patterns could potentially lead to derailment. On the other hand, anchors are placed underneath the rail on both sides of a tie to prevent it from longitudinal movement. Typically, how often anchors should be used defines an anchor pattern. Depending on the rail type and the degree of curvature, a specific anchor pattern will be required. Using non-compliant anchor patterns could lead to buckled rail.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example architecture of a system of automatic railroad track inspection. The system <b>100</b> includes four major modules, namely, data acquisition <b>102</b>, track condition monitoring <b>104</b>, defect severity analysis and temporal condition analysis <b>106</b>, and the long-term predictive assessment module <b>108</b>. In a particular embodiment of the present invention, the data acquisition module <b>102</b> is in charge of capturing videos <b>110</b> using multiple cameras that are mounted on a moving track inspection vehicle. It also records positioning information <b>112</b> and synchronizes it with the video <b>110</b>. Various image and video analytics <b>114</b> may then be launched from the track condition monitoring module <b>104</b> to detect important rail components including tie plate <b>116</b>, spike <b>118</b>, spike hole <b>118</b>, anchor <b>120</b>, joint bar and joint bar bolt <b>122</b>. Next, abnormal spiking and anchor patterns <b>124</b>, as well as problematic spikes <b>126</b> and displaced anchors <b>128</b>, can be recognized in the exception identification submodule <b>130</b>.</p>
<p id="p-0029" num="0028">The severity of such defects may then be further analyzed in the defect severity analysis and temporal condition analysis module <b>106</b>, and aggregated along the timeline to detect consecutive or repetitive exceptions that warrant immediate report. Such exception information along with positioning data, are sent to a server <b>132</b> for maintenance planning purpose. Meanwhile, a comparative and trend analysis of track component condition is performed in the long-term predictive assessment module <b>108</b>.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart illustrating an example method for automatically inspecting railroad tracks, as contemplated by the present invention. The method <b>200</b> includes separating foreground objects from background objects in the image, where foreground objects include a rail, a spike, a clip, a tie, a tie plate, and/or an anchor, and where background objects include ballast and/or sky, at block <b>202</b>. The method <b>200</b> further includes, at block <b>204</b>, identifying rail components in the image. At block <b>206</b>, the method <b>200</b> further includes detecting the current condition of the rail components. The method <b>200</b> also includes assessing a configuration of rail components depicted in an image by comparing the configuration of the rail components to safety requirements for the rail components, at block <b>208</b>. The safety requirements may originate from, for example, government regulations or private railroad companies. The safety requirements may include the amount of surface cracks on the rail, the rail profile and gauge size, and the conditions of joint bars, spikes and anchors. At block <b>210</b>, the method <b>200</b> includes determining a severity of detected problems in the configuration of the rail components, using a computer processor.</p>
<p id="p-0031" num="0030">In an embodiment of the invention, the method <b>200</b> is included in a four layer hierarchical framework where separating foreground objects from background objects and identifying rail components of the method <b>200</b>, at blocks <b>202</b> and <b>204</b>, comprise rail component localization. The second layer of the hierarchy, rail component condition detection, includes, at block <b>206</b>, detecting the current condition of the rail components. The third layer of the hierarchy, configuration state detection, includes assessing a configuration of rail components depicted in an image, at block <b>208</b>. The fourth layer of the hierarchy, severity detection, includes determining the severity of detected problem in the configuration of the rail components, at block <b>210</b>.</p>
<p id="p-0032" num="0031">Rail component localization, at blocks <b>202</b> and <b>204</b>, may be accomplished by different methods contemplated by the present invention. A purpose of rail component localization is to separate foreground objects, which may include rail, spikes, clips, ties, tie plates, and anchors from background objects which may include ballast and sky. The methods of rail component localization may be used individually or in combination to improve overall accuracy.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 3</figref> is a flowchart illustrating an example implementation of the region-based method of rail localization, as contemplated by the present invention. The region-based method <b>300</b> may include dividing the image into a set of cells, at block <b>302</b>. In an embodiment of the invention, the image is divided into M&#xd7;N cells. Texture features may be extracted from each cell, at block <b>304</b>. The texture features may be used to represent that particular cell. Texture features may include Gabor, Gabor wavelet, wavelet, color, and histogram of oriented gradients. The method <b>300</b> may include, at block <b>306</b>, grouping the set of cells into classes based on texture. In an embodiment of the invention, grouping may take a supervised or unsupervised approach. Supervised approaches may include Support Vector Machine (SVM) and Gaussian Mixture Models (GMM) while unsupervised approaches may include K-means based clustering. At block <b>308</b>, the method <b>300</b> may further include binarizing the image. In an embodiment of the invention, the binarized image has white portions representing areas of the image that make up the class that has the greatest number of members.</p>
<p id="p-0034" num="0033">The method <b>300</b> may also include detecting a tie plate from the image, at block <b>310</b>. In an embodiment of the invention, detecting the tie plate may include finding the bottom line of a rail. In this embodiment, detecting the tie plate may also include identifying a region that contains a majority of pixels from a class, where the class has the greatest number of members. In a further embodiment, identifying a region that contains a majority of pixels from a class is accomplished by identifying the region that contains the greatest number of white pixels.</p>
<p id="p-0035" num="0034">The method <b>300</b> may further include detecting anchors on the left and right side of the tie plate. In embodiments of the invention various approaches are taken including template-based matching, scale-invariant-feature-transform (SIFT)-based matching or machine learning based approaches including Support Vector Machine (SVM) or AdaBoost.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating an example implementation of the edge-based method of rail localization, as contemplated by the present invention. The method <b>400</b> may include detecting horizontal lines in the image, at block <b>402</b>. Detecting horizontal lines may include using the Hough transform. The method <b>400</b> may also include interpreting the horizontal lines detected to determine the location of the rail and the vertical position of the tie plate, at block <b>404</b>. This may be based on prior knowledge of the rail's structure. At block <b>406</b>, the method <b>400</b> may include determining the horizontal bounds of the tie plate. Determining the horizontal bounds of the tie plate may include detecting vertical lines defining a left boundary and a right boundary of the tie plate using the Hough transform. Determining the horizontal bounds of the tie plate may further include analyzing the distribution of points which voted for the line at the bottom of the tie plate.</p>
<p id="p-0037" num="0036">Rail component condition detection, at block <b>206</b>, may use similar image processing approaches to detecting the current conditions of localized rail components. These conditions may include moving or broken ties; present, missing, or loose spikes; missing, broken, or shifted tie plates; or missing or loose anchors. In an embodiment of the current invention, assessing the configuration of rail components, at block <b>206</b>, further includes detecting the absence of rail components.</p>
<p id="p-0038" num="0037">Configuration state detection, at block <b>208</b>, may include applying knowledge from federal regulations or domain experts. This may include information such as three moving ties indicates a problem of loose track, missing spikes for twelve consecutive ties should call for attention, and three missing bolts may indicate a moving fish plate.</p>
<p id="p-0039" num="0038">Derivation of severity, at block <b>210</b>, may include determining the severity of problems on a rail and proposing a time frame to correct the problem. In an embodiment of the invention, determining the severity of problems in the configuration, at block <b>210</b>, is based on a discrepancy between an expected configuration model and a state of the configuration of the rail components. The expected configuration model may be based on the surroundings. Surroundings may include factors such as terrain and land conditions. When determining severity the system may, for example, choose one of four levels. The first level may indicate that a discovered problem would need to be repaired immediately. The second level may indicate that a discovered problem would need to be repaired soon. The third level may indicate that a repair may be needed during the next inspection. The fourth level may indicate that repair may be needed during the next scheduled maintenance window or for use during planning.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a system for automatically inspecting railroad tracks. The system <b>500</b> includes a processor <b>502</b> and a memory <b>504</b> coupled to the processor.</p>
<p id="p-0041" num="0040">The memory <b>504</b> may have computer readable program code <b>506</b>. The computer readable program code <b>506</b> may be configured to perform various tasks for the system <b>500</b>. One such task may include assessing a configuration of rail components located in an image by comparing the configuration of the rail components to safety requirements for the rail components. Another task includes determining the severity of problems in the configuration of the rail components. In a further embodiment of the invention another task includes linking geographical location data with the image.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an example system for automatically inspecting railroad tracks as contemplated by the present invention. The cameras in the system may include Point Grey Dragonfly2, which provide flexibility in terms of image resolution, frame rate, color mode and the option of using region-of-interest. Four cameras may be used in total, imaging lateral views of the gauge and field sides of both rails. The field of view may be chosen to be 24 inches to obtain 50% overlap of images when traveling at 10 miles per hour, while ensuring total coverage of the track elements we are inspecting.</p>
<p id="p-0043" num="0042">The four cameras can be mounted on aluminum racks with two degrees of freedom, and the racks may be attached to the rear bumper of a hi-rail truck using trailer hitch pins for quick removability. When the truck travels on the rail, the four captured video streams may be sent over FireWire (1394a) networks to the computer, which may be placed along with a UPS and an inverter in the black 19-inch rack inside the truck. The computer may be a 3.0 GHz Pentium DuoCore, with 2 GB of RAM. Due to the high data volume and limited bandwidths of both the Firewire bus and PCI bus, an image resolution of 640&#xd7;350 may be chosen with 12 bits of monochrome intensity per pixel, and a frame rate of 20 FPS. An FFDShow encoder may be used to compress the video data before writing them to the disk. A more powerful computer with Solid State Drive may be used as well, to allow the system to accommodate higher inspection speeds.</p>
<p id="p-0044" num="0043">The video capture tool may contain three major modules including configuration, capture engine and positioning recorder. Specifically, the configuration module can manage camera parameters as well as other user configuration details. The capture engine can issue commands to the cameras, grab image frames and save them into multiple video files. Note that in order to cope with illumination changes and avoid producing either over-exposed or under-exposed images, this module may also analyze the histogram of each frame, then either adaptively adjust the camera parameters including the shutter speed and gain, or linearly stretches the histogram to enhance the image quality, before encoding the frame and writing it to the disk. Finally, the positioning recorder may log latitude and longitude data every second, which then may be synchronized with the video data based on the time stamps.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 7</figref> shows an example of various rail components in a captured video frame as contemplated by the present invention. Detecting the tie plate can be the very first step in video analytics, as once it is identified all other components can be located relative to its location.</p>
<p id="p-0046" num="0045">In an embodiment of the present invention, the rail occupies the upper portion of the image, and may present a very distinct horizontal dividing line from the rest, as shown in <figref idref="DRAWINGS">FIG. 7</figref>. On the other hand, when a tie plate is present, its bottom edge may present another approximately horizontal line. A Hough transform may be used to detect these two lines.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 8A</figref> illustrates an example of a Hough transform performed on an example image as contemplated by the present invention. One detection example is shown in <figref idref="DRAWINGS">FIG. 8A</figref> where the two horizontal lines <b>802</b> are obtained using a transform-based approach. The two vertical edges of the tie plate <b>804</b> may be found by distinguishing the tie plate region from the ballast area, in the following three steps.</p>
<p id="p-0048" num="0047">Step 1: For the image region between the two detected horizontal lines, an edge map may be computed using the Sobel operator, then the edge magnitude may be summed for each column. <figref idref="DRAWINGS">FIG. 8B</figref> is an example magnitude map which is plotted according to aspects of the present invention.</p>
<p id="p-0049" num="0048">Step 2: For each column, magnitudes may be summed within a window that is centered on it. The window size may approximately equal that of a tie plate. Note that once the imaging setup is fixed, a rough estimate about the tie plate's width can be made based on the image geometry. The height of the tie plate though, could vary depending on the type of plates. <figref idref="DRAWINGS">FIG. 8C</figref> illustrates an example magnitude map as contemplated by the present invention. In the magnitude map <b>800</b>, from which we see that there is a distinct local minimum <b>806</b>, which may exactly correspond to the midpoint of the tie plate, indicated by the vertical line.</p>
<p id="p-0050" num="0049">Step 3: Find the minimum in the above plot, and the tie plate's left and right edges <b>804</b> may be derived based on the window size. The final localization result is shown in <figref idref="DRAWINGS">FIG. 8A</figref>, indicated by the rectangle.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 9A</figref> illustrates the spike search region in an example embodiment of the present invention. To detect spikes, a search region is defined that is slightly expanded beyond the tie plate region <b>902</b>. A Hough transform may be applied to detect the roughly elliptical shape of spike heads within it. In particular, considering that all spike heads may be of similar size and shape under fixed imaging conditions, the center of an ellipse of approximately fixed size and eccentricity may be searched for. This may be achieved by letting each edge point vote for the shape of the ellipse within a small range of radii, with an assumption of a fixed ratio of major axis to minor axis. <figref idref="DRAWINGS">FIG. 9B</figref> shows the resulted voting space from an example embodiment of the present invention. In <figref idref="DRAWINGS">FIG. 9B</figref>, three bright spots are shown corresponding to the three spike heads.</p>
<p id="p-0052" num="0051">Finally, the center of each spike head may be detected by repeatedly identifying distinct and well-separated points that receive the most votes, based on some threshold. The bounding box of the spike may then be derived based on the center position and the corresponding search radius being applied. <figref idref="DRAWINGS">FIG. 9A</figref> shows the three detected spike heads <b>904</b>.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 10A</figref> is an example spike hole search region as contemplated the present invention. Detecting spike holes that are not filled up by spikes can help determine the spiking pattern of a tie plate. Based on the observation that: a) spike holes tend to present stronger edges than the spike heads, and b) they have approximately symmetrical shapes (square), a three-step detection approach can be used.</p>
<p id="p-0054" num="0053">Step 1: Given a detected tie plate, extract an extended tie plate region (ETPR) so as to include any possible spike heads in the rail side.</p>
<p id="p-0055" num="0054">Step 2: Detect the top four region(s) of interest (ROI) within this ETPR, in terms of the total amount of edge magnitude. The size of ROI approximately equals that of a spike hole. Considering that there could be at most one spike hole in each quadrant of ETPR, this may be achieved by detecting the top ROI in each quadrant. <figref idref="DRAWINGS">FIG. 10B</figref> shows the Sobel edge map of this image region in an example embodiment of the present invention. <figref idref="DRAWINGS">FIG. 10C</figref> illustrates four detected ROI in an example embodiment of the present invention. In <figref idref="DRAWINGS">FIG. 10C</figref>, the four detect ROI are indicated by filled squares. As we can see, these four ROI indeed capture the most edge-rich regions with one referring to the actual spike hole and the other three to spike heads.</p>
<p id="p-0056" num="0055">Step 3: Given the edge map of each ROI, the following check may be performed: 1) whether the object contained within it has a symmetrical shape. If yes, then very likely it corresponds to a spike hole (see <figref idref="DRAWINGS">FIG. 10B</figref>). This may be done by extracting two parameters from it, namely, the ratio of hCC over AC, and the ratio of vCC over AC. Here, AC refers to the maximum of its auto-correlation, and hCC/vCC refers to the maximum of the cross-correlation between its horizontally/vertically flipped image and itself. Apparently, the larger the two parameters, the more likely the object is symmetrical; and 2) whether most of the prominent edge points reside close to the four boundaries of the ROI. If yes, then it may very likely contain a spike hole.</p>
<p id="p-0057" num="0056">For the example shown in <figref idref="DRAWINGS">FIG. 10A-C</figref>, after the above step of validation, only the ROI that corresponds to the spike hole remains.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 11A</figref> is an example of the anchor detection process as contemplated by the present invention. Anchors may normally be fastened against both sides of a tie. Consequently, the two search regions <b>1102</b> are defined relative to the detected tie plate <b>1104</b> as shown in <figref idref="DRAWINGS">FIG. 11A</figref>. A similar approach may be applied as was used for the tie plate detection to search anchors. Specifically, given all edge points within a search region, non-horizontal gradients may be discarded. The edge magnitudes of the remaining edge points may be summed up for each column. <figref idref="DRAWINGS">FIG. 11B</figref> illustrates a plot of the magnitude map of an example implementation of the present invention. <figref idref="DRAWINGS">FIG. 11C</figref> illustrates an anchor detection plot as contemplated by the present invention. For each column, all magnitudes may be summed up within an anchor-sized window which centers on it, as shown in <figref idref="DRAWINGS">FIG. 11C</figref>. Finally, the maximum from this magnitude accumulation map may be found, and if it exceeds a certain threshold, the corresponding column may be returned as the center of the anchor.</p>
<p id="p-0059" num="0058">Testing</p>
<p id="p-0060" num="0059">Several trips were taken to side tracks and main lines to capture data. For each capture session, the hi-rail vehicle was run between 0.25 mile to 1.5 miles at up to 10 mph, then it was backed up to let us capture another session.</p>
<p id="p-0061" num="0060">Video data under was collected different weather conditions (brightly sunny, partly cloudy and overcast), at different times of day (morning, noon and afternoon) and on different days, as well as with different track alignments (tangent/straight and curved). The collected data also contains a large variety of fastener types: regular tie plates, mountain tie plates (extra large ones), different spiking and anchor patterns, raised spikes, displaced anchors, etc.</p>
<p id="p-0062" num="0061">To facilitate performance evaluation, an annotation tool was developed to gather the ground truth. Specifically, each object was be annotated by its tight bounding box, along with its condition (e.g. normal, raised, displaced, etc.). The annotations for each video were saved in an XML file.</p>
<p id="p-0063" num="0062">The concept of a correct match between an annotation and a detection are defined. Specifically, their bounding boxes are denoted as A<sub>bb </sub>and D<sub>bb</sub>, respectively, a correct match was required to meet three criteria as stated in Table 1.</p>
<p id="p-0064" num="0063">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="35pt" align="left"/>
<colspec colname="2" colwidth="182pt" align="left"/>
<thead>
<row>
<entry namest="1" nameend="2" rowsep="1">TABLE 1</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>1.</entry>
<entry>
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
  <mrow>
    <mrow>
      <mi>The</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.8em" height="0.8ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mi>intersection</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.8em" height="0.8ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mi>ratio</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.8em" height="0.8ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mfrac>
        <mrow>
          <msub>
            <mi>A</mi>
            <mi>bb</mi>
          </msub>
          <mo>&#x22c2;</mo>
          <msub>
            <mi>D</mi>
            <mi>bb</mi>
          </msub>
        </mrow>
        <msub>
          <mi>A</mi>
          <mi>bb</mi>
        </msub>
      </mfrac>
    </mrow>
    <mo>&#x2265;</mo>
    <mrow>
      <mn>60</mn>
      <mo>&#x2062;</mo>
      <mi>%</mi>
    </mrow>
  </mrow>
  <mo>,</mo>
</mrow>
</math>
</maths>
</entry>
</row>
<row>
<entry> </entry>
</row>
<row>
<entry>2.</entry>
<entry>
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mrow>
  <mrow>
    <mrow>
      <mi>The</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.8em" height="0.8ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mi>non</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mtext>-</mtext>
      </mstyle>
      <mo>&#x2062;</mo>
      <mi>intersection</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.8em" height="0.8ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <mi>ratio</mi>
      <mo>&#x2062;</mo>
      <mstyle>
        <mspace width="0.8em" height="0.8ex"/>
      </mstyle>
      <mo>&#x2062;</mo>
      <msub>
        <mi>D</mi>
        <mi>bb</mi>
      </msub>
    </mrow>
    <mo>-</mo>
    <mfrac>
      <mrow>
        <msub>
          <mi>A</mi>
          <mi>bb</mi>
        </msub>
        <mo>&#x22c2;</mo>
        <msub>
          <mi>D</mi>
          <mi>bb</mi>
        </msub>
      </mrow>
      <msub>
        <mi>A</mi>
        <mi>bb</mi>
      </msub>
    </mfrac>
  </mrow>
  <mo>&#x2264;</mo>
  <mrow>
    <mn>30</mn>
    <mo>&#x2062;</mo>
    <mi>%</mi>
    <mo>&#x2062;</mo>
    <munder>
      <mo>,</mo>
      <mi>_</mi>
    </munder>
  </mrow>
</mrow>
</math>
</maths>
</entry>
</row>
<row>
<entry> </entry>
</row>
<row>
<entry>3.</entry>
<entry>The entity types of the two objects match with each other.</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0065" num="0064">For a match, if the first two criteria fail but the last criterion is met, it is an under-match; on the other hand, if the first two are met but the last one fails, it is a miss-match. Note that if a detection does not overlap with any annotation, it is called an unmatched detection. Finally, when there are multiple detections passing the first two criteria with respect to one specific annotation, it is matched with the detection that gives the largest overlap ratio, which is calculated as:</p>
<p id="p-0066" num="0065">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mrow>
  <mfrac>
    <mrow>
      <msub>
        <mi>A</mi>
        <mrow>
          <mi>bb</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
        </mrow>
      </msub>
      <mo>&#x22c2;</mo>
      <msub>
        <mi>D</mi>
        <mi>bb</mi>
      </msub>
    </mrow>
    <mrow>
      <mrow>
        <mo>(</mo>
        <mrow>
          <msub>
            <mi>A</mi>
            <mi>bb</mi>
          </msub>
          <mo>-</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <msub>
                <mi>A</mi>
                <mi>bb</mi>
              </msub>
              <mo>&#x22c2;</mo>
              <msub>
                <mi>D</mi>
                <mi>bb</mi>
              </msub>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>)</mo>
      </mrow>
      <mo>+</mo>
      <mrow>
        <mo>(</mo>
        <mrow>
          <msub>
            <mi>D</mi>
            <mi>bb</mi>
          </msub>
          <mo>-</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <msub>
                <mi>A</mi>
                <mi>bb</mi>
              </msub>
              <mo>&#x22c2;</mo>
              <msub>
                <mi>D</mi>
                <mi>bb</mi>
              </msub>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mrow>
  </mfrac>
  <mo>.</mo>
</mrow>
</math>
</maths>
</p>
<p id="p-0067" num="0066">Three metrics are defined for measuring the component detection performance, namely, detection rate (DR), false positive rate (FPR) and false negative rate (FNR). Specifically, for a particular object type O (e.g. spike), these three measurements are calculated as follows: 1) DR(O) equals the number of correct matches of O over its total number of annotations; 2) FPR(O) equals the number of unmatched detections of O over its total number of detections; 3) FPR(O|O&#x2032;) equals the number of mismatches where objects are detected as type O yet annotated as type O&#x2032;, over the total number of detections of O; and 4) FNR(O) equals the total number of unmatched, under-matched, and mismatched annotations of O, over the total number of annotations of O.</p>
<p id="p-0068" num="0067">Table 2 shows the performance numbers in the form of a confusion matrix. Due to the limited amount of annotation, this evaluation is obtained from test videos that cover a track segment containing in total, 797 tie plates, 2287 spikes, 901 spike holes, and 1483 anchors. From the table we see that overall, an average detection rate of 98.2% over all tie plates, spikes, spike holes and anchors has been achieved. Specifically, tie plate has the highest detection rate (100%), and the spike hole has the lowest (94.23%). On the other hand, the average false positive and false negative rates are 1.57% and 1.78%, respectively.</p>
<p id="p-0069" num="0068">The most false alarms come from spike hole detector. On the other hand, false alarms of the spike detector are usually caused by foreign objects on the tie plate. The missed detections for spikes, spike holes or anchors, are mainly caused by the weak edge information. This could happen when the material inside the spike hole appears to be of same color/texture to that of the tie plate, or one side of spike head and anchor do not sufficiently stand out from the background, due to the changes of view aspect and lighting conditions.</p>
<p id="p-0070" num="0069">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="35pt" align="left"/>
<colspec colname="1" colwidth="182pt" align="center"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" rowsep="1">TABLE 2</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>Detection</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="6">
<colspec colname="1" colwidth="35pt" align="left"/>
<colspec colname="2" colwidth="35pt" align="left"/>
<colspec colname="3" colwidth="49pt" align="left"/>
<colspec colname="4" colwidth="42pt" align="left"/>
<colspec colname="5" colwidth="28pt" align="left"/>
<colspec colname="6" colwidth="28pt" align="left"/>
<tbody valign="top">
<row>
<entry>Ground</entry>
<entry>Tie Plate</entry>
<entry>Spike</entry>
<entry>Spike</entry>
<entry>Anchor</entry>
<entry/>
</row>
<row>
<entry>Truth</entry>
<entry>(tp)</entry>
<entry>(spk)</entry>
<entry>Hole</entry>
<entry>(achr)</entry>
<entry>Nothing</entry>
</row>
<row>
<entry namest="1" nameend="6" align="center" rowsep="1"/>
</row>
<row>
<entry>Tie</entry>
<entry>DR (tp) =</entry>
<entry/>
<entry/>
<entry/>
<entry>FNR</entry>
</row>
<row>
<entry>Plate</entry>
<entry>100%</entry>
<entry/>
<entry/>
<entry/>
<entry>(tp) =</entry>
</row>
<row>
<entry/>
<entry/>
<entry/>
<entry/>
<entry/>
<entry>0%</entry>
</row>
<row>
<entry>Spike</entry>
<entry/>
<entry>DR (spk) =</entry>
<entry>FPR</entry>
<entry/>
<entry>FNR</entry>
</row>
<row>
<entry/>
<entry/>
<entry>99.3%</entry>
<entry>(hole|spk) =</entry>
<entry/>
<entry>(spk) =</entry>
</row>
<row>
<entry/>
<entry/>
<entry/>
<entry>0%</entry>
<entry/>
<entry>0.7%</entry>
</row>
<row>
<entry>Spike</entry>
<entry/>
<entry>FPR</entry>
<entry>DR (hole) =</entry>
<entry/>
<entry>FNR</entry>
</row>
<row>
<entry>Hole</entry>
<entry/>
<entry>(spk|hole) =</entry>
<entry>94.23%</entry>
<entry/>
<entry>(hole) =</entry>
</row>
<row>
<entry/>
<entry/>
<entry>0%</entry>
<entry/>
<entry/>
<entry>5.77%</entry>
</row>
<row>
<entry>Anchor</entry>
<entry/>
<entry/>
<entry/>
<entry>DR</entry>
<entry>FNR</entry>
</row>
<row>
<entry/>
<entry/>
<entry/>
<entry/>
<entry>(achr) =</entry>
<entry>(achr) =</entry>
</row>
<row>
<entry/>
<entry/>
<entry/>
<entry/>
<entry>99.33%</entry>
<entry>0.67%</entry>
</row>
<row>
<entry>Nothing</entry>
<entry>FPR (tp) =</entry>
<entry>FPR (spk) =</entry>
<entry>FPR</entry>
<entry>FPR</entry>
</row>
<row>
<entry/>
<entry>0.22%</entry>
<entry>1.56%</entry>
<entry>(hole) =</entry>
<entry>(achr) =</entry>
</row>
<row>
<entry/>
<entry/>
<entry/>
<entry>4.4%</entry>
<entry>0.09%</entry>
</row>
<row>
<entry namest="1" nameend="6" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0071" num="0070">As will be appreciated by one skilled in the art, aspects of the invention may be embodied as a system, method or computer program product. Accordingly, aspects of the invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a &#x201c;circuit,&#x201d; &#x201c;module&#x201d; or &#x201c;system.&#x201d; Furthermore, aspects of the invention may take the form of a computer program product embodied in one or more computer readable medium(s) having computer readable program code embodied thereon.</p>
<p id="p-0072" num="0071">Any combination of one or more computer readable medium(s) may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples (a non-exhaustive list) of the computer readable storage medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a computer readable storage medium may be any tangible medium that can contain, or store a program for use by or in connection with an instruction execution system, apparatus, or device.</p>
<p id="p-0073" num="0072">A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein, for example, in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms, including, but not limited to, electromagnetic, optical, or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate, propagate, or transport a program for use by or in connection with an instruction execution system, apparatus, or device.</p>
<p id="p-0074" num="0073">Program code embodied on a computer readable medium may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, RF, etc., or any suitable combination of the foregoing.</p>
<p id="p-0075" num="0074">Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as Java, Smalltalk, C++ or the like and conventional procedural programming languages, such as the &#x201c;C&#x201d; programming language or similar programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).</p>
<p id="p-0076" num="0075">Aspects of the invention are described with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems) and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.</p>
<p id="p-0077" num="0076">These computer program instructions may also be stored in a computer readable medium that can direct a computer, other programmable data processing apparatus, or other devices to function in a particular manner, such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function/act specified in the flowchart and/or block diagram block or blocks.</p>
<p id="p-0078" num="0077">The computer program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other devices to cause a series of operational steps to be performed on the computer, other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.</p>
<p id="p-0079" num="0078">The flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.</p>
<p id="p-0080" num="0079">While the preferred embodiments to the invention has been described, it will be understood that those skilled in the art, both now and in the future, may make various improvements and enhancements which fall within the scope of the claims which follow. Thus, the claims should be construed to maintain the proper protection for the invention first described.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08625878-20140107-M00001.NB">
<img id="EMI-M00001" he="6.69mm" wi="42.67mm" file="US08625878-20140107-M00001.TIF" alt="embedded image " img-content="table" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08625878-20140107-M00002.NB">
<img id="EMI-M00002" he="6.69mm" wi="53.68mm" file="US08625878-20140107-M00002.TIF" alt="embedded image " img-content="table" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08625878-20140107-M00003.NB">
<img id="EMI-M00003" he="6.69mm" wi="76.20mm" file="US08625878-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for automatically inspecting railroad tracks comprising:
<claim-text>assessing a configuration of rail components depicted in an image by comparing the configuration of the rail components to safety requirements for the rail components;</claim-text>
<claim-text>dividing the image into a set of cells;</claim-text>
<claim-text>extracting texture features from each cell from the set of cells;</claim-text>
<claim-text>grouping the set of cells into classes based on the texture features from each cell;</claim-text>
<claim-text>binarizing the image based on class grouping of the texture features from each cell; and</claim-text>
<claim-text>determining a severity of detected problems in the configuration of the rail components, using a computer processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the severity of detected problems in the configuration is based on a discrepancy between an expected configuration model and a state of the configuration of the rail components.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the expected configuration model is based on a surrounding.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the expected configuration model is obtained from a database.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising:
<claim-text>detecting a tie plate from the image; and</claim-text>
<claim-text>detecting anchors on the left and right side of the tie plate.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein grouping the set of cells into classes based on texture is accomplished using at least one of Support Vector Machine (SVM), Gaussian Mixture Models (GMM), and K-means.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein detecting a tie plate from the image comprises:
<claim-text>finding the bottom line of a rail; and</claim-text>
<claim-text>identifying a region that contains a majority of pixels from a class of the classes of the set of cells, where the class has a greatest number of members.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein detecting anchors comprises at least one of template based matching, scale-invariant-feature-transform-based matching, and machine-learning based approaches.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref> further comprising:
<claim-text>detecting horizontal lines in the image;</claim-text>
<claim-text>interpreting the horizontal lines detected to determine a location of the rail and a vertical position of the tie plate; and</claim-text>
<claim-text>determining a horizontal boundary of the tie plate.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein detecting the horizontal lines comprises using the Hough transform.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein determining the horizontal boundary of the tie plate includes detecting vertical lines defining a left boundary and a right boundary of the tie plate using the Hough transform.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein determining the horizontal boundary of the tie plate includes analyzing the distribution of points which voted for the line at the bottom of the tie plate.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising, separating foreground objects from background objects in the image, where foreground objects include at least one of a rail, a spike, a spike hole, a clip, a tie, a tie plate, and an anchor, and where background objects include at least one of a ballast object and a sky object.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising, identifying other rail components in the image including spikes, spike holes, joint bars, joint bar bolts, nuts and washers.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising, detecting the current condition of the rail components.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein detecting the current condition of the rail components comprises detecting the absence of rail components.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein identifying spikes comprises searching for any elliptical centers voted by edge points within a range of radius with an assumption of a fixed ratio of major axis to minor axis.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein identifying spike holes comprises searching for any regions-of-interest within an extended tie plate region that present strong edges with symmetric shapes.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A system for automatically inspecting railroad tracks comprising:
<claim-text>a processor;</claim-text>
<claim-text>a memory coupled to the processor, the memory having computer readable program code embodied therewith, the computer readable program code configured to:
<claim-text>assess a configuration of rail components located in an image by comparing the configuration of the rail components to safety requirements for the rail components;</claim-text>
<claim-text>dividing the image into a set of cells;</claim-text>
<claim-text>extracting texture features from each cell from the set of cells;</claim-text>
<claim-text>grouping the set of cells into classes based on the texture features from each cell;</claim-text>
<claim-text>binarizing the image based on class grouping of the texture features from each cell; and</claim-text>
<claim-text>determine the severity of problems in the configuration of the rail components.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein the computer readable program code is further configured to link geographical location data with the image.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the computer readable program code is further configured to determine the severity of problems in the configuration is based on a discrepancy between an expected configuration model and a state of the configuration of the rail components.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The system of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the expected configuration model is obtained from a database.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. A computer program product for automatically inspecting railroad tracks, the computer program product comprising:
<claim-text>a non-transitory computer readable storage medium having computer readable program code embodied therewith, the computer readable program code configured to:</claim-text>
<claim-text>assess a configuration of rail components located in an image by comparing the configuration of the rail components to safety requirements for the rail components;</claim-text>
<claim-text>divide the image into a set of cells;</claim-text>
<claim-text>extract texture features from each cell from the set of cells;</claim-text>
<claim-text>group the set of cells into classes based on the texture features from each cell;</claim-text>
<claim-text>binarize the image based on class grouping of the texture features from each cell; and</claim-text>
<claim-text>determine the severity of problems in the configuration of the rail components.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The computer program product of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein determining the severity of the problems in the configuration is based on a discrepancy between an expected configuration model and a state of the configuration of the rail components. </claim-text>
</claim>
</claims>
</us-patent-grant>
