<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625668-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625668</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11644188</doc-number>
<date>20061222</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2006-002973</doc-number>
<date>20060110</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1717</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>11</main-group>
<subgroup>02</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>37524013</main-classification>
<further-classification>37524029</further-classification>
<further-classification>37524026</further-classification>
</classification-national>
<invention-title id="d2e71">Information processing apparatus and video decoding method of information processing apparatus</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5534927</doc-number>
<kind>A</kind>
<name>Shishikui et al.</name>
<date>19960700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3484001</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5796438</doc-number>
<kind>A</kind>
<name>Hosono</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348458</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6853752</doc-number>
<kind>B2</kind>
<name>Tan et al.</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6907079</doc-number>
<kind>B2</kind>
<name>Gomila et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7028203</doc-number>
<kind>B2</kind>
<name>Nakai</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713340</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7050504</doc-number>
<kind>B2</kind>
<name>Joch et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524026</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7126989</doc-number>
<kind>B2</kind>
<name>Hagai et al.</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524013</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7161982</doc-number>
<kind>B2</kind>
<name>Kimoto</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524013</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7542092</doc-number>
<kind>B2</kind>
<name>Ohsawa</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348372</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2001/0017977</doc-number>
<kind>A1</kind>
<name>Umeda</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2001/0036320</doc-number>
<kind>A1</kind>
<name>Tan et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2002/0094028</doc-number>
<kind>A1</kind>
<name>Kimoto</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524014</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2003/0206587</doc-number>
<kind>A1</kind>
<name>Gomila</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2004/0158878</doc-number>
<kind>A1</kind>
<name>Ratnakar et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2004/0184549</doc-number>
<kind>A1</kind>
<name>Webb</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524029</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2006/0067406</doc-number>
<kind>A1</kind>
<name>Kitada et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2006/0203909</doc-number>
<kind>A1</kind>
<name>Kitada et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524012</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2007/0147515</doc-number>
<kind>A1</kind>
<name>Kawashima et al.</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2007/0160129</doc-number>
<kind>A1</kind>
<name>Fujisawa et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>375240</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2007/0160140</doc-number>
<kind>A1</kind>
<name>Fujisawa et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524012</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2007/0201555</doc-number>
<kind>A1</kind>
<name>Kikuchi et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524013</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2007/0223585</doc-number>
<kind>A1</kind>
<name>Fujisawa et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524013</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2008/0084491</doc-number>
<kind>A1</kind>
<name>He et al.</name>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34833313</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2008/0137753</doc-number>
<kind>A1</kind>
<name>He</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>CN</country>
<doc-number>1489867</doc-number>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>CN</country>
<doc-number>1695378</doc-number>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>EP</country>
<doc-number>1453319</doc-number>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>JP</country>
<doc-number>5122681</doc-number>
<date>19930500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>JP</country>
<doc-number>2001-275110</doc-number>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>JP</country>
<doc-number>2003179921</doc-number>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>JP</country>
<doc-number>2003-304538</doc-number>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>JP</country>
<doc-number>2004180248</doc-number>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>JP</country>
<doc-number>2004-242308</doc-number>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>JP</country>
<doc-number>2005033724</doc-number>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>WO</country>
<doc-number>03050758</doc-number>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>Dhondt et al., Flexible macroblock ordering as a content adaptation tool in H.264/AVC, Oct. 2005, SPIE vol. 6015 601506-1 col. 7; Ln.45. ( http://dircweb.kingston.ac.uk/papers/dissanayake2008<sub>&#x2014;</sub>56267220/chaminda<sub>&#x2014;</sub>7.pdf ).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>ISO/IEC 14496-10:2003, &#x201c;Information Technology, Coding of Audio-Visual Objects&#x2014;Part 10: Advanced Video Coding&#x201d;.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>H.264/AVC Textbook (Impress Communications Corporation.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>Japanese Patent Application No. 2006-002973, Notice of Reasons for Rejection, mailed Jun. 1, 2010, (English Translation).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>First Office Action with English Translation in a Corresponding Chinese Application, No. 2006100636262 dated Nov. 21, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>Japanese Patent Application No. 2005-375203, Notice of Reasons for Rejection, mailed Jun. 1, 2010 (English Translation).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00042">
<othercit>U.S. Appl. No. 11/638,856, Non-Final Office Action, mailed Jul. 25, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>ITU-T Recommendation H. 264(2003), &#x201c;Advanced Video Coding for Generic Audiovisual Services&#x201d;, Mar. 2005, pp. 181-196.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>13</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348333-400</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>375240</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>16</number-of-drawing-sheets>
<number-of-figures>17</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070160140</doc-number>
<kind>A1</kind>
<date>20070712</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Fujisawa</last-name>
<first-name>Tatsuro</first-name>
<address>
<city>Ome</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kikuchi</last-name>
<first-name>Yoshihiro</first-name>
<address>
<city>Ome</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kawashima</last-name>
<first-name>Yuji</first-name>
<address>
<city>Ome</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Fujisawa</last-name>
<first-name>Tatsuro</first-name>
<address>
<city>Ome</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Kikuchi</last-name>
<first-name>Yoshihiro</first-name>
<address>
<city>Ome</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Kawashima</last-name>
<first-name>Yuji</first-name>
<address>
<city>Ome</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Blakely, Sokoloff, Taylor &#x26; Zafman LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Kabushiki Kaisha Toshiba</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Vaughn, Jr.</last-name>
<first-name>William C</first-name>
<department>2481</department>
</primary-examiner>
<assistant-examiner>
<last-name>Perez</last-name>
<first-name>Luis M</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">According to one embodiment, information processing apparatus which decodes compressed and encoded video stream by software, selectively generates one of intra and inter prediction image on the basis of encoding mode of decoding object from video stream and decoded images thereof, generates a residual error decoded image on the basis of a quantization parameter of decoding object from video stream, generates decoded image by adding intra and inter prediction image selectively generated, and residual error decoded image, applies deblocking filter process for reducing block distortion onto decoded image, extracts at least one of information on a quantization parameter and information on encoding mode of decoding object from video stream, determines whether or not filter process is skipped on the basis of extracted information thereof, and selectively skips filter process on the basis of a result of determination, and selectively switches determination and processing of skip to be valid or invalid.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="109.47mm" wi="165.95mm" file="US08625668-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="198.29mm" wi="157.90mm" file="US08625668-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="219.63mm" wi="162.31mm" orientation="landscape" file="US08625668-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="250.87mm" wi="169.67mm" file="US08625668-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="126.24mm" wi="145.71mm" file="US08625668-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="215.39mm" wi="153.16mm" file="US08625668-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="227.67mm" wi="152.74mm" file="US08625668-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="249.68mm" wi="148.84mm" file="US08625668-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="237.15mm" wi="149.27mm" file="US08625668-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="214.04mm" wi="147.91mm" file="US08625668-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="234.70mm" wi="150.03mm" file="US08625668-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="211.50mm" wi="149.44mm" file="US08625668-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="241.22mm" wi="151.72mm" file="US08625668-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="210.74mm" wi="150.71mm" file="US08625668-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="236.90mm" wi="144.19mm" file="US08625668-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="212.26mm" wi="151.55mm" file="US08625668-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="239.10mm" wi="150.37mm" file="US08625668-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is based upon and claims the benefit of priority from Japanese Patent Application No. 2006-002973, filed Jan. 10, 2006, the entire contents of which are incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">1. Field</p>
<p id="p-0004" num="0003">One embodiment of the invention relates to an information processing apparatus in which video decoding processing for decoding a compressed and encoded video stream is achieved by software, and a video decoding method thereof.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">As standard technologies for encoding a video stream, H.261 and H.263 of the International Telecommunication Union Telecommunication Standardization Sector (ITU-T), Moving Picture Experts Group (MPEG)-1, MPEG-2, and MPEG-4 of the International Organization for Standardization (ISO), and the like, have been developed. As a next-generation video encoding method in which the technologies such as H.261 to H.263, MPEG-1 to MPEG-4, and the like have been succeeded, and further developed, there is the H.264 which has been standardized by the ISO and the ITU jointly. In the H.264, a deblocking filter for relieving a distortion generated at a block boundary is used as one of filters in loop, which enhances a picture quality improvement effect at a low bit rate particularly (refer to ITU-T Recommendation H.264 (2003), &#x201c;Advanced Video Coding for generic audiovisual services&#x201d;|ISO/IEC 14496-10: 2003, &#x201c;Information technology, Coding of audio-visual objects&#x2014;Part 10: Advanced video coding&#x201d;, and H.264/AVC textbook (Impress Communications Corporation)).</p>
<p id="p-0007" num="0006">On the other hand, personal computers having the same AV functions as those of audio-video (AV) equipment such as digital versatile disc (DVD) players and TV devices have been developed. In such a personal computer, a software decoder which decodes a compressed and encoded video stream by software is used. By the use of a software decoder, it is possible to decode a compressed and encoded video stream by a processor (CPU) without dedicated hardware being provided thereto.</p>
<p id="p-0008" num="0007">In an information processing apparatus such as the above-described personal computer, assume that video decoding processing according to standardization specifications based on the H.264 is achieved by software. In this case, a proportion of the throughput of the deblocking filter accounting the entire decoding processing is high. For this reason, real-time decoding processing is made unable to be in time when a load on an entire system is high, and there is possibility that defects are brought about in which frames are dropped, movement of an object is made extremely slow, and the like. In particular, in a battery-driven information processing apparatus, such as a notebook-type personal computer, an electric power consumption is made higher when a load is made larger in a battery-driving mode, which makes a driving time extremely short.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS</heading>
<p id="p-0009" num="0008">A general architecture that implements the various features of the invention will now be described with reference to the drawings. The drawings and the associated descriptions are provided to illustrate embodiments of the invention and not to limit the scope of the invention.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 1</figref> is a perspective view showing an example of an outside of a computer according to one embodiment of the present invention;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram showing a system configuration example of the computer of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram showing a functional configuration example of a video playback application program for use in the computer of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram showing a configuration example in a case where the invention is applied to video decoding processing according to standardization specifications based on the H.264 as a software decoder achieved by the video playback application program of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram showing a structural example of a content information processing system including the video decoding apparatus shown in <figref idref="DRAWINGS">FIG. 4</figref> as a video decoding unit;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart showing a basic processing example of a deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart showing another basic processing example of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart showing a processing example in a case according to pattern <b>3</b> in skip determination by information on a quantization parameter, as a first embodiment of a skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart showing a processing example in a case according to pattern <b>2</b> in skip determination by information on a quantization parameter, as a second embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart showing a processing example in a case according to pattern <b>1</b> of a third method in skip determination by information on an encoding mode, as a third embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing a processing example in a case according to pattern <b>2</b> of the third method in skip determination by information on an encoding mode, as a fourth embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing a processing example in a case according to pattern <b>1</b> of a fourth method in skip determination by information on an encoding mode, as a fifth embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart showing a processing example in a case according to pattern <b>2</b> (or <b>3</b>) of the fourth method in skip determination by information on an encoding mode, as a sixth embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart showing a processing example in a case according to pattern <b>1</b> of a first method in skip determination by information on an encoding mode, as a seventh embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 15</figref> is a flowchart showing a processing example in a case according to pattern <b>2</b> of the first method in skip determination by information on an encoding mode, as an eighth embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 16</figref> is a flowchart showing a processing example in a case according to pattern <b>1</b> of a second method in skip determination by information on an encoding mode, as a ninth embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>; and</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 17</figref> is a flowchart showing a processing example in a case according to pattern <b>3</b> (or <b>2</b>) of the second method in skip determination by information on an encoding mode, as a tenth embodiment of the skip determining method of the deblocking filter skip determining unit in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0027" num="0026">Various embodiments according to the invention will be described hereinafter with reference to the accompanying drawings. In general, according to one embodiment of the invention, an information processing apparatus which decodes a compressed and encoded video stream by software, comprising: means for selectively generating one of an intra prediction image and an inter prediction image on the basis of an encoding mode of a decoding object from the video stream and decoded images thereof; means for generating a residual error decoded image on the basis of a quantization parameter of a decoding object from the video stream; means for generating a decoded image by adding the intra prediction image and the inter prediction image selectively generated by the prediction decoding means, and the residual error decoded image generated by the residual error decoding means; means for applying deblocking filter process for reducing a block distortion onto the decoded image generated by the residual error adding means; means for extracting at least one of information on a quantization parameter and information on an encoding mode of the decoding object from the video stream, and for determining whether or not the filter process is skipped, on the basis of extracted information thereof; means for selectively skipping the filter process on the basis of a result of the determination of skip; and means for selectively switching the determination and processing of skip to be valid or invalid.</p>
<p id="p-0028" num="0027">Hereinafter, embodiments of the present invention will be descried with reference to the drawings.</p>
<p id="p-0029" num="0028">First, a configuration example of an information processing apparatus according to one embodiment of the present invention will be described with reference to <figref idref="DRAWINGS">FIGS. 1 and 2</figref>. The information processing apparatus is realized as, for example, a notebook type personal computer <b>10</b>.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 1</figref> is a front view showing a state in which a display unit of the notebook type personal computer <b>10</b> is opened as seen from the front. The computer <b>10</b> is composed of a computer main body <b>11</b> and a display unit <b>12</b>. A display device composed of a liquid crystal display (LCD) <b>17</b> is built into the display unit <b>12</b>, and a display screen of the LCD <b>17</b> is positioned at substantially the center of the display unit <b>12</b>.</p>
<p id="p-0031" num="0030">The display unit <b>12</b> is attached so as to be freely rotatable between an open position and a closed position with respect to the computer main body <b>11</b>. The computer main body <b>11</b> has a thin box form case. A keyboard <b>18</b>, a power button <b>14</b> for turning the computer <b>10</b> power-on/off, an input operation panel <b>15</b>, a touch pad <b>16</b>, and the like are arranged on the upper surface of the computer main body <b>11</b>.</p>
<p id="p-0032" num="0031">The input operation panel <b>15</b> is an input device for inputting an event corresponding to a pushed button, and has a plurality of buttons for respectively starting a plurality of functions. A TV starting button <b>15</b>A and a digital versatile disc (DVD) starting button <b>15</b>B as well are included in the group of these buttons. The TV starting button <b>15</b>A is a button for starting a TV function for carrying out playback and recording of broadcast program data such as a digital TV broadcast program. When the TV starting button <b>15</b>A is pressed down by a user, an application program for executing the TV function is automatically started. The DVD starting button <b>15</b>B is a button for playing back video contents recorded on a DVD. When the DVD starting button <b>15</b>B is pressed down by a user, an application program for playing back video contents is automatically started.</p>
<p id="p-0033" num="0032">Next, a system configuration example of the computer <b>10</b> will be described with reference to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0034" num="0033">As shown in <figref idref="DRAWINGS">FIG. 2</figref>, the computer <b>10</b> has a CPU <b>111</b>, a north bridge <b>112</b>, a main memory <b>113</b>, a graphics controller <b>114</b>, a south bridge <b>119</b>, a BIOS-ROM <b>120</b>, a hard disk drive (HDD) <b>121</b>, an optical disk drive (ODD) <b>122</b>, a digital TV broadcasting tuner <b>123</b>, an embedded controller/keyboard controller IC (EC/KBC) <b>124</b>, a network controller <b>125</b>, and the like.</p>
<p id="p-0035" num="0034">The CPU <b>111</b> is a processor provided for controlling operations of the computer <b>10</b>, and executes various application programs such as an operating system (OS) and a video playback application program <b>201</b> which are loaded from the hard disk drive (HDD) <b>121</b> to the main memory <b>113</b>.</p>
<p id="p-0036" num="0035">The video playback application program <b>201</b> is software for decoding and playing back compressed and encoded video data. The video playback application program <b>201</b> is a software decoder according to the H.264/AVC standard. The video playback application program <b>201</b> has a function for decoding a video stream compressed and encoded in an encoding method defined by the H.264/AVC standard (for example, a digital TV broadcast program received by the digital TV broadcasting tuner <b>123</b>, vide contents according to the high definition (HD) standard read from the optical disk drive (ODD) <b>122</b>, and the like).</p>
<p id="p-0037" num="0036">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, the video playback application program <b>201</b> has a load detecting module <b>211</b>, a decode control module <b>212</b>, and a decode executing module <b>213</b>.</p>
<p id="p-0038" num="0037">The decode executing module <b>213</b> is a decoder for executing decode processing defined by the H.264/AVC standard. The load detecting module <b>211</b> is a module for detecting a load on the computer <b>10</b>. The load detecting module <b>211</b> detects a current loading dose of the computer <b>10</b> by inquiring of an operating system (OS) <b>200</b> about a current load of the computer <b>10</b>. A loading dose of the computer <b>10</b> is determined on the basis of, for example, a usage rate of the CPU <b>111</b>.</p>
<p id="p-0039" num="0038">Further, a loading dose of the computer <b>10</b> can be determined on the basis of a combination of a usage rate of the CPU <b>111</b> and a usage rate of the memory <b>113</b>. Usually, a memory of a certain definite size or more is required for executing a software decoder smoothly. When a usage rate of the memory in the system is made higher, decoding performance of the software decoder is deteriorated due to paging of the OS. Therefore, by detecting a loading dose, namely the amount of load of the computer <b>10</b>, on the basis of a combination of a usage rate of the CPU <b>111</b> and a usage rate of the memory <b>113</b>, it is possible to precisely determine whether or not a current loading dose of the computer <b>10</b> is a loading dose which poses a problem for executing the software decoder (in a high-loaded state).</p>
<p id="p-0040" num="0039">The decode control module <b>212</b> controls contents of decode processing executed by the decode executing module <b>213</b> in accordance with a load on the computer <b>10</b> detected by the load detecting module <b>211</b>.</p>
<p id="p-0041" num="0040">Specifically, when a loading dose of the computer <b>10</b> is less than or equal to a reference value determined in advance, the decode control module <b>212</b> controls contents of decode processing to be executed by the decode executing module <b>213</b> such that the decode processing defined by the H.264/AVC standard is executed by the CPU <b>111</b>. On the other hand, when a loading dose of the computer <b>10</b> is larger than the reference value (in a high-loaded state), the decode control module <b>212</b> controls contents of decode processing to be executed by the decode executing module <b>213</b> such that a part of the decode processing defined by the H.264/AVC standard is replaced with SKIPPED or simplified processing.</p>
<p id="p-0042" num="0041">Video data decoded by the video playback application program <b>201</b> are sequentially written into a video memory <b>114</b>A of the graphics controller <b>114</b> via a display driver <b>202</b>. Consequently, the decoded video data are displayed on the LCD <b>17</b>. The display driver <b>202</b> is software for controlling the graphics controller <b>114</b>.</p>
<p id="p-0043" num="0042">Further, the CPU <b>111</b> executes a system BIOS (Basic Input Output System) stored in the BIOS-ROM <b>120</b> as well. The system BIOS is a program for controlling hardware.</p>
<p id="p-0044" num="0043">The north bridge <b>112</b> is a bridge device for connecting a local bus of the CPU <b>111</b> and the south bridge <b>119</b>. A memory controller for access-controlling the main memory <b>113</b> as well is built in the north bridge <b>112</b>. Further, the north bridge <b>112</b> further has a function of executing communication with the graphics controller <b>114</b> via an accelerated graphics port (AGP) bus or the like.</p>
<p id="p-0045" num="0044">The graphics controller <b>114</b> is a display controller for controlling the LCD <b>17</b> used as a display monitor of the computer <b>10</b>. The graphics controller <b>114</b> generates a display signal to be transmitted to the LCD <b>17</b> from image data written in the video memory (VRAM) <b>114</b>A.</p>
<p id="p-0046" num="0045">The south bridge <b>119</b> controls respective devices on a low pin count (LPC) bus, and respective devices on a peripheral component interconnect (PCI) bus. Further, the south bridge <b>119</b> has an integrated drive electronics (IDE) controller for controlling the HDD <b>121</b> and the ODD <b>122</b> built-in. Moreover, the south bridge <b>119</b> has a function for controlling the digital TV broadcasting tuner <b>123</b> and a function for access-controlling the BIOS-ROM <b>120</b> as well.</p>
<p id="p-0047" num="0046">The HDD <b>121</b> is a storage device which stores various software and data. The optical disk drive (ODD) <b>123</b> is a drive unit for driving a storage medium such as a DVD on which video contents are stored. The digital TV broadcasting tuner <b>123</b> is a receiving apparatus for receiving broadcast program data such as a digital TV broadcast program from the outside.</p>
<p id="p-0048" num="0047">The embedded controller/keyboard controller IC (EC/KBC) <b>124</b> is a one-chip microcomputer in which an embedded controller for managing electric power and a keyboard controller for controlling the keyboard (KB) <b>13</b> and the touch pad <b>16</b> are integrated. The embedded controller/keyboard controller IC (EC/KBC) <b>124</b> has a function of turning the computer <b>10</b> power-on/power-off in accordance with an operation of the power button <b>14</b> by a user. Moreover, the embedded controller/keyboard controller IC (EC/KBC) <b>124</b> can turn the computer <b>10</b> power-on in accordance with an operation of the TV starting button <b>15</b>A or the DVD starting button <b>15</b>B by a user. The network controller <b>125</b> is a communication device which executes communication with an external network such as, for example, the Internet.</p>
<p id="p-0049" num="0048">Next, a functional configuration of the software decoder achieved by the video playback application program will be described with reference to <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram showing a structural example when the present invention is applied to a software decoder in accordance with standardization specifications based on the H.264, as one embodiment of a video decoding apparatus relating to the present invention. In <figref idref="DRAWINGS">FIG. 1</figref>, an input stream is a video stream which has been compressed and encoded in accordance with the H.264 standard, and is transmitted to a variable-length decoding unit (called an entropy decoding unit as well) <b>301</b>. The variable-length decoding unit <b>301</b> encodes an input stream so as to be a varying length, and generates syntax. An inverse quantization unit <b>302</b> and an inverse transform unit <b>303</b> generate a residual image from a result of encoding of a video encoded stream based on the generated syntax.</p>
<p id="p-0051" num="0050">An encoding mode control unit <b>304</b> discriminates an encoding mode based on the input stream from the variable-length decoding unit <b>301</b>, and selectively controls to drive a intra prediction unit <b>305</b> and a inter prediction unit <b>306</b> based on a result of discrimination. The intra prediction unit <b>305</b> and the inter prediction unit <b>306</b> respectively generate predicted images in a screen and between screens in accordance with an encoding mode designated by the encoding mode control unit <b>304</b>. Generated predicted images are selectively transmitted to a residual adding unit <b>307</b>. The residual adding unit <b>307</b> adds a predicted image from the intra prediction unit <b>305</b> or the inter prediction unit <b>306</b>, and a residual image from the inverse transform unit <b>303</b> to generate a decoded image. The generated decoded image is provided as a reference in the intra prediction unit <b>305</b>.</p>
<p id="p-0052" num="0051">Further, a deblocking filter skip determining unit <b>310</b> extracts information on a quantization parameter such as a quantization step or the like, and information on an encoding mode from the variable-length decoding unit <b>301</b>, and determines whether or not deblocking filter process is carried out onto the generated decoded image generated in the residual adding unit <b>307</b>. The determining method will be described later. Here, in a case in which deblocking filter process is carried out, the decoded image is inputted to a deblocking filter unit <b>308</b>, and a reconstructed image is prepared by carrying out filter process, and is stored in a picture memory <b>309</b>. When deblocking filter process is not carried out, the decoded image is directly stored as a reconstructed image in the picture memory <b>309</b>. The reconstructed image stored in the picture memory <b>309</b> is outputted as an output image and provided as a reference in the inter prediction unit <b>306</b>.</p>
<p id="p-0053" num="0052">There is a feature of the present invention in the point that, when a throughput is reduced by skipping a deblocking filter having high processing load, in consideration of deterioration in picture quality, an attempt is made to reduce a throughput while preventing deterioration in picture quality as much as possible by skipping only portions predicted with less deterioration in picture quality. To describe concretely, in order to prevent deterioration in picture quality, (1) Only portions on which a filter effect is weak are skipped (portions on which a filter effect is strong are not skipped), and (2) Portions from which errors run through the following portions are not skipped (only independent portions are skipped) are principles.</p>
<p id="p-0054" num="0053">In skip determination of a deblocking filter, information on a quantization parameter and information on an encoding mode obtained from an input stream by the variable-length decoding unit <b>101</b> are utilized. In a deblocking filter, there are features that the larger the quantization parameter is, the easier the filtering is, and the larger the information on an encoding mode (Bs value) is, the easier the filtering is. In the present invention, skip of filter process is effectively carried out by utilizing these features.</p>
<p id="p-0055" num="0054">Here, a quantization parameter is a degree of quantizing an orthogonal transformation coefficient (DCT coefficient) in a macro-block, and when this value is too large, a noise called a block-noise is generated. In accordance with ease of generating of a block-noise, i.e., as a quantization parameter is made larger, a filter effect is made stronger. As quantization parameters in the H.264 standard, a quantization parameter of a slice and a quantization parameter of a macro-block are stipulated.</p>
<p id="p-0056" num="0055">(Skip Determination by Information on a Quantization Parameter)</p>
<p id="p-0057" num="0056">When skip determination is carried out by information on a quantization parameter, a central value of quantization parameters and a predetermined threshold value are compared. The deblocking filter is skipped when the following relation is satisfied:</p>
<p id="p-0058" num="0057">the central value of quantization parameters&#x3c;the threshold value.</p>
<p id="p-0059" num="0058">As the central value of quantization parameters, there are the following five patterns.</p>
<p id="p-0060" num="0059">Pattern 1: A skip range of filter process is made to be in units of pictures, and a central value is regarded as an average value of quantization parameters of slices belonging to a reference picture.</p>
<p id="p-0061" num="0060">Pattern 2: A skip range of filter process is made to be in units of pictures, and a central value is regarded as an average value of quantization parameters of macro-blocks belonging to a reference picture.</p>
<p id="p-0062" num="0061">Pattern 3: A skip range of filter process is made to be in units of slices, and a central value is regarded as a quantization parameter of a reference slice.</p>
<p id="p-0063" num="0062">Pattern 4: A skip range of filter process is made to be in units of slices, and a central value is regarded as an average value of quantization parameters of macro-blocks belonging to a reference slice.</p>
<p id="p-0064" num="0063">Pattern 5: A skip range of filter process is made to be in units of macro-blocks, and a central value is regarded as a quantization parameter of a reference macro-block.</p>
<p id="p-0065" num="0064">As the threshold value, three are the following three types.</p>
<p id="p-0066" num="0065">(1) A constant (which is a fixed value, or is set based on an extent of a loaded condition)</p>
<p id="p-0067" num="0066">(2) An average value of central values in past (decoded) pictures or slices</p>
<p id="p-0068" num="0067">(3) A value in which an offset value (a constant) is added to an average value of central values in past (decoded) pictures or slices</p>
<p id="p-0069" num="0068">(Skip Determination by Information on an Encoding Mode)</p>
<p id="p-0070" num="0069">Next, first to fourth methods in a case in which skip determination is carried out by information on an encoding mode will be described.</p>
<p id="p-0071" num="0070">In the first method by an encoding mode, when decoding objects are slices in I picture (hereinafter, I slices), deblocking filter process is not skipped. This is because a filter effect is strong in an intra-predicted macro-block, and deterioration in picture quality due to skip is made large. In this method, there are the following two patterns.</p>
<p id="p-0072" num="0071">Pattern 1: A skip range of filter process is made to be in units of slices, and when a reference slice is an I slice, filter process is not skipped.</p>
<p id="p-0073" num="0072">Pattern 2: A skip range of filter process is made to be in units of pictures, and when a number or a ratio of I slices belonging to a reference picture is larger than a threshold value, filter process is not skipped. As a threshold value, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or an average value of a number (or a ratio) of I slices in past pictures (or a value in which an offset value (a constant) is added to an average value) is utilized.</p>
<p id="p-0074" num="0073">In the second method by an encoding mode, when decoding objects are intra-predicted macro-blocks, deblocking filter process is not skipped. As described above, this is because a filter effect in an intra-predicted macro-block is strong, and deterioration in picture quality due to skip is made large. In this method, there are the following three patterns.</p>
<p id="p-0075" num="0074">Pattern 1: A skip range of filter process is made to be in units of macro-blocks, and when a reference macro-block is an intra-predicted macro-block, filter process is not skipped.</p>
<p id="p-0076" num="0075">Pattern 2: A skip range of filter process is made to be in units of slices, and when a number of intra-predicted macro-blocks belonging to a reference slice is larger than a threshold value, filter process is not skipped. As a threshold value, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or an average value of a number (or a ratio) of intra-predicted macro-blocks belonging to past (decoded) slices (or a value in which an offset value (a constant) is added to an average value) is utilized.</p>
<p id="p-0077" num="0076">Pattern 3: A skip range of filter process is made to be in units of pictures, and when a number of intra-predicted macro-blocks belonging to a reference picture is larger than a threshold value, filter process is not skipped. As a threshold value, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or an average value of a number (or a ratio) of intra-predicted macro-blocks belonging to past (decoded) pictures (or a value in which an offset value (a constant) is added to an average value) is utilized.</p>
<p id="p-0078" num="0077">In the third method by an encoding mode, when decoding objects are slices in B picture (hereinafter, B slices), deblocking filter process is skipped. The reason for this is that, because pictures are not referred in B slices, deterioration in picture quality does not extend to the following pictures, and because a throughput is high, an effect of skip is large. In this method, there are the following two patterns.</p>
<p id="p-0079" num="0078">Pattern 1: A skip range of filter process is made to be in units of slices, and when a reference slice is a B slice, filter process is skipped.</p>
<p id="p-0080" num="0079">Pattern 2: A skip range of filter process is made to be in units of pictures, and when a number of B slices belonging to a reference picture is larger than a threshold value, filter process is skipped. As a threshold value, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or an average value of a number (or a ratio) of B slices belonging to past (encoded) pictures (or a value in which an offset value (a constant) is added to an average value) is utilized.</p>
<p id="p-0081" num="0080">In the fourth method by an encoding mode, when decoding objects are bi-directional predicted macro-blocks of a B picture (hereinafter, bi-directional predicted (B) macro-blocks), because pictures are not referred, and a throughput is large, filter process is skipped. In this method, there are the following three patterns.</p>
<p id="p-0082" num="0081">Pattern 1: A skip range of filter process is made to be in units of macro-blocks, and when a reference macro-block is a bi-directional predicted (B) macro-block, filter process is skipped.</p>
<p id="p-0083" num="0082">Pattern 2: A skip range of filter process is made to be in units of slices, and when a number of bi-directional predicted (B) macro-blocks belonging to a reference slice is larger than a threshold value, filter process is skipped. As a threshold value, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or an average value of a number (or a ratio) of bi-directional predicted (B) macro-blocks belonging to past (decoded) slices (or a value in which an offset value (a constant) is added to an average value) is utilized.</p>
<p id="p-0084" num="0083">Pattern 3: A skip range of filter process is made to be in units of pictures, and when a number of bi-directional predicted (B) macro-blocks belonging to a reference picture is larger than a threshold value, filter process is skipped. As a threshold value, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or an average value of a number (or a ratio) of bi-directional predicted (B) macro-blocks belonging to past (decoded) pictures (or a value in which an offset value (a constant) is added to an average value) is utilized.</p>
<p id="p-0085" num="0084">In accordance with the above-described processing for skip determination of deblocking filter process, it is possible to reduce a throughput while preventing picture quality from being largely deteriorated. Moreover, because there are a very small number of changes in a conventional structure, structure of the present invention can be easily built in.</p>
<p id="p-0086" num="0085">In the above-described video decoding methods, as compared with the conventional method, an amount of throughput in the processing for determination carried out in the deblocking filter skip determining unit <b>310</b> is increased. However, because this is considered to be an extremely small amount for the entire deblocking filter process which can be skipped, it will be possible to largely reduce a throughput as a whole.</p>
<p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. 5</figref> shows a configuration example of the information processing apparatus including the software decoder shown in <figref idref="DRAWINGS">FIG. 4</figref> as a video decoding unit <b>401</b>. This information processing apparatus has a processing load detection unit <b>402</b>. The processing load detection unit <b>402</b> acquires, not only information on processing load in video decoding processing from the video decoding unit <b>401</b>, but also information on the other processing load of the system in decoding processing for voice/audio signals, rendering processing, and the like; calculates an entire load on the basis of the input information on load; and notifies the video decoding unit <b>401</b> of the information on load. Further, in battery-driving, the processing load detection unit <b>402</b> receives, for example, notification of a remaining battery level. When a remaining battery level is less than an allowable remaining level, the processing load detection unit <b>402</b> causes the video decoding unit <b>401</b> to execute the control of skip of deblocking filter processing regardless of a situation of the processing load. Further, in AC power-driving, it is preferable that skip of deblocking filter process is automatically turned off, and an attempt is made to improve picture quality.</p>
<p id="p-0088" num="0087">The information on load is inputted to the deblocking filter skip determining unit <b>310</b> in <figref idref="DRAWINGS">FIG. 4</figref>, in the video decoding unit <b>401</b>. Basic processing examples of the determining unit <b>310</b> are shown in <figref idref="DRAWINGS">FIG. 6</figref> and <figref idref="DRAWINGS">FIG. 7</figref>. Note that, in <figref idref="DRAWINGS">FIG. 7</figref>, steps which are the same as those in <figref idref="DRAWINGS">FIG. 6</figref> are denoted by the same reference numerals.</p>
<p id="p-0089" num="0088">In the processing example shown in <figref idref="DRAWINGS">FIG. 6</figref>, when a start of skip determination is instructed in decoding processing, a skip range of filter process is set to be a loop in units of pictures, slices, or macro-blocks (step S<b>11</b>), and it is determined whether or not the processing is under a high-loaded condition (step S<b>12</b>). When it is determined that the processing is under a high-loaded condition, it is determined whether or not the skip range meets the conditions for skip according to the aforementioned methods based on information on an encoding mode and a quantization parameter of an decoding object (step S<b>13</b>). When it meets the conditions, processing is skipped deblocking filter process of the decoding object (step S<b>14</b>). When it is determined that it does not meet the conditions for skip at step S<b>13</b>, the processing at step S<b>14</b> is passed, and the routine proceeds to processing for the following decoding object. Further, when it is determined that the processing is not under a high-loaded condition at step S<b>12</b>, because it is possible to execute deblocking filter process in real time, the processing for skip determination is terminated, and deblocking filter process is executed.</p>
<p id="p-0090" num="0089">In contrast thereto, in the processing example shown in <figref idref="DRAWINGS">FIG. 7</figref>, when it is determined that the processing is under a high-loaded condition at step S<b>12</b> for determining a high-loaded condition, a threshold value for determining conditions is set based on an extent of load (step S<b>21</b>), and it is determined whether or not it meets the conditions for skip in the same way at the step S<b>13</b> by using the threshold value (step S<b>22</b>).</p>
<p id="p-0091" num="0090">Namely, in both of the procedures of the above-described two processing examples, by appropriately controlling filter process in accordance with a loaded condition for each decoding object, skip of deblocking filter process is not carried out when a load on an entire system is low or a system has a high processing capacity. Deblocking filter process is executed when decoding processing in real time is sufficiently possible. Therefore, it is possible to effectively skip filter process while preventing unnecessary deterioration in picture quality.</p>
<p id="p-0092" num="0091">Hereinafter, some of methods for skip determination of the deblocking filter skip determining unit <b>310</b> will be described by sampling an embodiment for each condition for skip.</p>
<p id="p-0093" num="0092">(First Embodiment)</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart showing a processing example in a case of the pattern <b>3</b> in skip determination by information on a quantization parameter described above, as a first embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of slices (step S<b>31</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>32</b>), and when the processing is under a high-loaded condition, a quantization parameter of a slice serving as a decoding object is set as a central value (step S<b>33</b>), and (an average value of quantization parameters of decoded slices)+a constant (an offset value) is set as a threshold value (step S<b>34</b>), and it is determined whether or not the central value is less than the threshold value (step S<b>35</b>). When the central value is less than the threshold value, processing is skipped deblocking filter process of the slice serving as a decoding object (step S<b>36</b>), and a quantization parameter of the slice serving as a decoding object is stored, and the routine proceeds to skip determination for the following slice unit (step S<b>37</b>). When it is determined that the central value is not less than the threshold value at the step S<b>35</b>, the processing at step S<b>36</b> is skipped. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>32</b>, processing is carried out such that deblocking filter process is executed onto the slice serving as a decoding object.</p>
<p id="p-0095" num="0094">(Second Embodiment)</p>
<p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart showing a processing example in a case of the pattern <b>2</b> in skip determination by information on a quantization parameter described above, as a second embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of pictures (step S<b>41</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>42</b>), and when the processing is under a high-loaded condition, (an average value of quantization parameters of macro-blocks belonging to a picture serving as a decoding object) is set as a central value (step S<b>43</b>), and a constant is set as a threshold value (step S<b>44</b>), and it is determined whether or not the central value is less than the threshold value (step S<b>45</b>). When the central value is less than the threshold value, processing is skipped deblocking filter process of the picture serving as a decoding object (step S<b>46</b>). When it is determined that the central value is not less than the threshold value at the step S<b>45</b>, the processing at step S<b>46</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>42</b>, processing is carried out such that deblocking filter process is executed onto the picture serving as a decoding object.</p>
<p id="p-0097" num="0096">(Third Embodiment)</p>
<p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart showing a processing example in a case of the pattern <b>1</b> of the third method in skip determination by information on an encoding mode described above, as a third embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of slices (step S<b>51</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>52</b>), and when the processing is under a high-loaded condition, it is determined whether or nor an decoding object is a B slice (step S<b>53</b>), and when the decoding object is a B slice, processing is skipped deblocking filter process of the slice serving as a decoding object (step S<b>54</b>), and the routine proceeds to skip determination for the following slice unit. When it is determined that the decoding object is not a B slice at step S<b>53</b>, the processing at step S<b>54</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>52</b>, processing is carried out such that deblocking filter process is executed onto the slice serving as a decoding object.</p>
<p id="p-0099" num="0098">(Fourth Embodiment)</p>
<p id="p-0100" num="0099"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing a processing example in a case of the pattern <b>2</b> of the third method in skip determination by information on an encoding mode described above, as a fourth embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of pictures (step S<b>61</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>62</b>), and when the processing is under a high-loaded condition, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or a value in which a constant is added to an average value of ratios of B slices in past (decoded) pictures is set as a threshold value (step S<b>63</b>), and it is determined whether or not a ratio of B slices in a picture serving as a decoding object is larger than a threshold value (step S<b>64</b>). When a ratio of B slices is larger than the threshold value, processing is skipped deblocking filter process of the picture serving as a decoding object (step S<b>65</b>), and the routine proceeds to skip determination for the following picture unit. When it is determined that a ratio of B slices is not larger than the threshold value at step S<b>64</b>, the processing at step S<b>65</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>62</b>, processing is carried out such that deblocking filter process is executed onto the picture serving as a decoding object.</p>
<p id="p-0101" num="0100">(Fifth Embodiment)</p>
<p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing a processing example in a case of the pattern <b>1</b> of the fourth method in skip determination by information on an encoding mode described above, as a fifth embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of macro-blocks (step S<b>71</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>72</b>), and when the processing is under a high-loaded condition, it is determined whether or not a decoding object is a bi-directional predicted (B) macro-block (step S<b>73</b>). When the decoding object is a bi-directional predicted (B) macro-block, processing is skipped deblocking filter process of the macro-block serving as a decoding object (step S<b>74</b>), and the routine proceeds to skip determination for the following macro-block unit. When it is determined that the decoding object is not a bi-directional predicted (B) macro-block at step S<b>73</b>, the processing at step S<b>74</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>72</b>, processing is carried out such that deblocking filter process is executed onto the macro-block serving as a decoding object.</p>
<p id="p-0103" num="0102">(Sixth Embodiment)</p>
<p id="p-0104" num="0103"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart showing a processing example in a case of the pattern <b>2</b> (or <b>3</b>) of the fourth method in skip determination by information on an encoding mode described above, as a sixth embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of pictures (or slices) (step S<b>81</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>82</b>), and when the processing is under a high-loaded condition, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or a value in which a constant is added to an average value of ratios of B slices in past (decoded) pictures (or slices) is set as a threshold value (step S<b>83</b>), and it is determined whether or not a ratio of B slices in a picture (or a slice) serving as a decoding object is larger than a threshold value (step S<b>84</b>). When a ratio of B slices is larger than the threshold value, processing is skipped deblocking filter process of the picture (or the slice) serving as a decoding object (step S<b>85</b>), and the routine proceeds to skip determination for the following picture (or slice) unit. When it is determined that a ratio of B slices is not larger than the threshold value at step S<b>84</b>, the processing at step S<b>85</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>82</b>, processing is carried out such that deblocking filter process is executed onto the picture (or the slice) serving as a decoding object.</p>
<p id="p-0105" num="0104">(Seventh Embodiment)</p>
<p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart showing a processing example in a case of the pattern <b>1</b> of the first method in skip determination by information on an encoding mode described above, as a seventh embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of slices (step S<b>91</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>92</b>), and when the processing is under a high-loaded condition, it is determined whether or nor an decoding object is an I slice (step S<b>93</b>). When it is determined that the decoding object is not an I slice, processing is skipped deblocking filter process of the slice serving as a decoding object (step S<b>94</b>), and the routine proceeds to skip determination for the following slice unit. When it is determined that the decoding object is an I slice at step S<b>93</b>, the processing at step S<b>94</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>92</b>, processing is carried out such that deblocking filter process is executed onto the slice serving as a decoding object.</p>
<p id="p-0107" num="0106">(Eighth Embodiment)</p>
<p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. 15</figref> is a flowchart showing a processing example in a case of the pattern <b>2</b> of the first method in skip determination by information on an encoding mode described above, as an eighth embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of pictures (step S<b>101</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>102</b>), and when the processing is under a high-loaded condition, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or a value in which a constant is added to an average value of ratios of I slices in past (decoded) pictures is set as a threshold value (step S<b>103</b>), and it is determined whether or not a ratio of I slices in a picture serving as a decoding object is less than the threshold value (step S<b>104</b>). When a ratio of I slices is less than the threshold value, processing is skipped deblocking filter process of the picture serving as a decoding object (step S<b>105</b>), and the routine proceeds to skip determination for the following picture unit. When it is determined that a ratio of I slices is not less than the threshold value at step S<b>104</b>, the processing at step S<b>105</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>102</b>, processing is carried out such that deblocking filter process is executed onto the picture serving as a decoding object.</p>
<p id="p-0109" num="0108">(Ninth Embodiment)</p>
<p id="p-0110" num="0109"><figref idref="DRAWINGS">FIG. 16</figref> is a flowchart showing a processing example in a case of the pattern <b>1</b> of the second method in skip determination by information on an encoding mode described above, as a ninth embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of macro-blocks (step S<b>111</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>112</b>), and when the processing is under a high-loaded condition, it is determined whether or not a decoding object is an intra-predicted macro-block (step S<b>113</b>). When it is determined that the decoding object is not an intra-predicted macro-block, processing is skipped deblocking filter process of the macro-block serving as a decoding object (step S<b>114</b>), and the routine proceeds to skip determination for the following macro-block unit. When it is determined that the decoding object is an intra-predicted macro-block at step S<b>113</b>, the processing at step S<b>114</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>112</b>, processing is carried out such that deblocking filter process is executed onto the macro-block serving as a decoding object.</p>
<p id="p-0111" num="0110">(Tenth Embodiment)</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 17</figref> is a flowchart showing a processing example in a case of the pattern <b>3</b> (or <b>2</b>) of the second method in skip determination by information on an encoding mode described above, as a tenth embodiment. In this embodiment, a skip range of filter process is set to be a loop in units of pictures (or slices) (step S<b>121</b>). Next, it is determined whether or not the processing is under a high-loaded condition (step S<b>122</b>), and when the processing is under a high-loaded condition, a constant (which is a fixed value, or is set based on an extent of a loaded condition), or a value in which a constant is added to an average value of ratios of intra-predicted macro-blocks in past (decoded) pictures (or slices) is set as a threshold value (step S<b>123</b>), and it is determined whether or not a ratio of intra-predicted macro-blocks in a picture (or a slice) serving as a decoding object is less than the threshold value (step S<b>124</b>). When a ratio of intra-predicted macro-blocks is less than the threshold value, processing is skipped deblocking filter process of the picture (or the slice) serving as a decoding object (step S<b>125</b>), and the routine proceeds to skip determination for the following picture (or slice) unit. When it is determined that a ratio of intra-predicted macro-blocks is not less than the threshold value at step S<b>124</b>, the processing at step S<b>125</b> is passed. Further, when it is determined that the processing is not under a high-loaded condition at the step S<b>122</b>, processing is carried out such that deblocking filter process is executed onto the picture (or the slice) serving as a decoding object.</p>
<p id="p-0113" num="0112">The first to tenth embodiments have been described above. However, the other patterns described above as well can be executed in the same way. Further, more efficient skip can be executed by combining individual patterns of skip determination by information respectively on a quantization parameter and an encoding mode.</p>
<p id="p-0114" num="0113">Note that the present invention can be achieved as, not only a video decoding apparatus as described above, but also a video decoding method having characteristic steps which are included in such a video decoding method. Further, those steps can be realized as a program to be executed by a computer. Then, such a program can be distributed via recording media such as CD-ROMs and the like, and a transmission medium such as the Internet and the like.</p>
<p id="p-0115" num="0114">While certain embodiments of the inventions have been described, these embodiments have been presented by way of example only, and are not intended to limit the scope of the inventions. Indeed, the novel methods and systems described herein may be embodied in a variety of forms; furthermore, various skips, substitutions and changes in the form of the methods and systems described herein may be made without departing from the spirit of the inventions. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of the inventions.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An information processing apparatus which decodes a compressed and encoded video stream, comprising:
<claim-text>means for selectively generating one of an intra prediction image and an inter prediction image based on an encoding mode of at least one decoding object from the video stream;</claim-text>
<claim-text>means for generating a residual error decoded image based on a quantization parameter of the decoding object from the video stream;</claim-text>
<claim-text>means for generating a decoded image by adding
<claim-text>(1) the selected one of the intra prediction image and the inter prediction image and</claim-text>
<claim-text>(2) the residual error decoded image generated by the means for generating the residual error decoding image;</claim-text>
</claim-text>
<claim-text>means for applying a deblocking filter process for reducing a block distortion onto the decoded image generated by the residual error adding means;</claim-text>
<claim-text>means for extracting information, the information being at least one of
<claim-text>(i) information on a quantization parameter and</claim-text>
<claim-text>(ii) information on the encoding mode of the decoding object from the video stream;</claim-text>
</claim-text>
<claim-text>means for determining whether or not the filter process is skipped based on the extracted information; and means for selectively skipping the filter process on the basis of a result provided by the means for determining;</claim-text>
<claim-text>wherein the means for determining whether or not the filter process is skipped is based on a power supply being used by the information processing apparatus, where the filter process is performed when a commercial power supply driving is used, and the filter process is skipped based on a remaining battery level when power is supplied by a battery.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the means for further determining
<claim-text>whether or not the filter process is skipped by performing a determination of skip by specifying a central value of quantization parameters of the decoding object to be compared with a threshold value serving as a reference for determination, and</claim-text>
<claim-text>carries out the determination of skip on the basis of a comparison result thereof; and</claim-text>
<claim-text>the threshold value is an average value of the central values of quantization parameters in decoded past pictures or slices, or a value obtained by adding an offset value to the average value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the means for determining whether or not the filter process is skipped performs a determination of skip in units of slices, in units of macro-blocks, in units of an arbitrary number of macro-blocks, or in units of pictures of the decoded image.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the means for determining whether or not the filter process is skipped determines that the filter process is not skipped when the information on the encoding mode of the decoding object is at least a slice in a reference picture by only prediction-in-screen.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the means for determining whether or not the filter process is skipped determines that the filter process is not skipped when the information on the encoding mode of the decoding object is at least a predicted macro-block in-screen.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the means for determining whether or not the filter process is skipped determines that the filter process is skipped when the information on the encoding mode of the decoding object is at least a slice in a non-reference picture.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The information processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the means for determining whether or not the filter process is skipped determines that the filter process is skipped when the information on the encoding mode of the decoding object is at least a bidirectional predicted macro-block (a bidirectional predicted macro-block in-screen).</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A video decoding method for decoding a compressed and encoded video stream, the method comprising:
<claim-text>selectively generating one of an intra prediction image and an inter prediction image on the basis of an encoding mode of at least one decoding object from the video stream;</claim-text>
<claim-text>generating a residual error decoded image based on a quantization parameter of a decoding object from the video stream;</claim-text>
<claim-text>generating a decoded image by adding the one of the intra prediction image and the inter prediction image selectively generated, and the residual error decoded image;</claim-text>
<claim-text>applying a filter process for reducing a block distortion onto the decoded image;</claim-text>
<claim-text>extracting at least one of information on a quantization parameter and information on an encoding mode of the decoding object from the video stream;</claim-text>
<claim-text>determining whether or not the filter process is skipped based on extracted information thereof; and</claim-text>
<claim-text>selectively skipping the filter process based on a result of the determination:</claim-text>
<claim-text>wherein the determining whether or not the filter process is skipped based on a power supply being used by the information processing apparatus, wherein the filter process is performed when a commercial power supply driving is used, and the filter process is skipped based on a remaining battery level when power is supplied by a battery.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The video decoding method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the determining whether or not the filter process is skipped considers if power is being supplied by the battery and information on a remaining battery level.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The video decoding method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the filter process is a deblocking filter process.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The video decoding method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the determining whether or not the filter process is skipped further comprises performing a determination of skip by specifying a central value of quantization parameters of the decoding object to be compared with a threshold value serving as a reference for determination, and carrying out the determination of skip on the basis of a comparison result thereof, and the threshold value is an average value of the central values of quantization parameters in decoded past pictures or slices, or a value obtained by adding an offset value to the average value.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A non-transitory computer-readable memory containing program instructions that, when executed by a processor, perform functions for decoding a compressed and encoded video stream, comprising:
<claim-text>selectively generating one of an intra prediction image and an inter prediction image on the basis of an encoding mode of at least one decoding object from the video stream;</claim-text>
<claim-text>generating a residual error decoded image on the basis of a quantization parameter of a decoding object from the video stream;</claim-text>
<claim-text>generating a decoded image by adding the intra prediction image and the inter prediction image selectively generated, and the residual error decoded image;</claim-text>
<claim-text>applying deblocking filter process for reducing a block distortion onto the decoded image; and</claim-text>
<claim-text>extracting information including at least one of information on a quantization parameter and information on an encoding mode of the decoding object from the video stream, determining whether or not the filter process is skipped on the basis of the extracted information, and selectively skipping the filter process on the basis of a result of the determination;</claim-text>
<claim-text>wherein the determining whether or not the filter process is skipped based on a power supply being used by the information processing apparatus, wherein the deblocking filter process is performed when a commercial power supply driving is used, and the filter process is skipped based on a remaining battery level when power is supplied by a battery.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The non-transitory computer-readable memory according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the memory containing program instructions that, when executed by the processor, perform a determination of skip by specifying a central value of quantization parameters of the decoding object to be compared with a threshold value serving as a reference for determination, and carrying out the determination of skip on the basis of a comparison result thereof, and the threshold value is an average value of the central values of quantization parameters in decoded past pictures or slices, or a value obtained by adding an offset value to the average value. </claim-text>
</claim>
</claims>
</us-patent-grant>
