<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622284-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622284</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12976837</doc-number>
<date>20101222</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>163</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>19</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20120101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>Q</subclass>
<main-group>30</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>Q</subclass>
<main-group>90</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>46</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>7</main-group>
<subgroup>10</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>7</main-group>
<subgroup>14</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>235375</main-classification>
<further-classification>235385</further-classification>
<further-classification>235454</further-classification>
<further-classification>382190</further-classification>
</classification-national>
<invention-title id="d2e53">Determining and recording the locations of objects</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5602380</doc-number>
<kind>A</kind>
<name>Bishay</name>
<date>19970200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6045046</doc-number>
<kind>A</kind>
<name>Detwiler</name>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6305607</doc-number>
<kind>B1</kind>
<name>Katz et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7298626</doc-number>
<kind>B1</kind>
<name>Senogles et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>361752</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7551849</doc-number>
<kind>B1</kind>
<name>Abad</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7712671</doc-number>
<kind>B2</kind>
<name>Cattrone et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>8107736</doc-number>
<kind>B2</kind>
<name>Brown et al.</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382190</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2005/0010499</doc-number>
<kind>A1</kind>
<name>Farkas et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 28</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2006/0210115</doc-number>
<kind>A1</kind>
<name>Nemet</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382104</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2007/0095907</doc-number>
<kind>A1</kind>
<name>Robinson et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235385</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2007/0100713</doc-number>
<kind>A1</kind>
<name>Del Favero et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2008/0216003</doc-number>
<kind>A1</kind>
<name>Onishi</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715764</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2008/0306787</doc-number>
<kind>A1</kind>
<name>Hamilton et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705  7</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2010/0027894</doc-number>
<kind>A1</kind>
<name>Dahari</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382218</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2010/0086192</doc-number>
<kind>A1</kind>
<name>Grigsby et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2011/0025504</doc-number>
<kind>A1</kind>
<name>Lyon et al.</name>
<date>20110200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3405721</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2011/0047263</doc-number>
<kind>A1</kind>
<name>Martins et al.</name>
<date>20110200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>22</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>235375</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235385</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235383</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235454</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>23546201</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>23546208-46211</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>23546241</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>23547201-47203</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382181</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382183</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382190</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382209</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382217</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382218</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>705 28</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>361724-727</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>361752</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>361790</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>361796</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3405721</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Hansen</last-name>
<first-name>Zachary J.</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Hansen</last-name>
<first-name>Zachary J.</first-name>
<address>
<city>Seattle</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Baker Botts L.L.P.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Amazon Technologies, Inc.</orgname>
<role>02</role>
<address>
<city>Reno</city>
<state>NV</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lee</last-name>
<first-name>Michael G</first-name>
<department>2876</department>
</primary-examiner>
<assistant-examiner>
<last-name>Ellis</last-name>
<first-name>Suezu</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">In certain embodiments, one or more images of a container may be received. The following may be repeated for one or more device codes of one or more devices of an image of the one or more images: locating a device code in the image; reading a device identifier from the device code; determining a device location according to the location of the device code in the image; and associating the device identifier and the device location to yield a device identifier-location association. The one or more device identifier-location associations may be stored.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="142.24mm" wi="195.58mm" file="US08622284-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="278.98mm" wi="196.26mm" file="US08622284-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="271.70mm" wi="171.28mm" file="US08622284-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="255.27mm" wi="190.92mm" file="US08622284-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">An object may have a code that can be scanned by an operator to obtain information describing the object. For example, a product may have a bar code that can be scanned to obtain the price of the product. A code may provide any suitable information about an object. For example, a bar code may provide information identifying the object, such as an object identifier. In certain situations, the object identifier may be used to record other information about the object, such as the location of the object.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0003" num="0002">For a more complete understanding of the present invention and its features and advantages, reference is now made to the following description, taken in conjunction with the accompanying drawings, in which:</p>
<p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example of a system configured to determine and record locations of one or more devices in a container according to certain embodiments;</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of an image processor that may be used with the system of <figref idref="DRAWINGS">FIG. 1</figref> according to certain embodiments;</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an example of a method of determining and recording locations of one or more devices in a container according to certain embodiments; and</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIGS. 4A through 4C</figref> illustrate examples of methods of determining and expressing a device location according to certain embodiments.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0003" level="1">DETAILED DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007">In certain situations, an object may have a code, such as a bar code, that can be scanned in order to obtain information describing the object, for example, an object identifier. In certain situations, the location of the object may be associated with the object identifier in order to record the object's location.</p>
<p id="p-0009" num="0008">As an example, a computer rack may hold multiple computing devices. The computing devices may have bar codes that can be scanned in order to obtain device identifiers of the computing devices. The device identifier of a device may be associated with the device's location on the computer rack to record the location of the device.</p>
<p id="p-0010" num="0009">In certain situations, manually scanning devices of computer racks may be burdensome. A computer rack may be one of multiple computer racks of a datacenter, and a datacenter may be one of multiple datacenters of a datacenter cluster. A computer rack may include 25 to 50 or even over 50 devices to be scanned. In addition, a datacenter may include 25 to 50 or even over 50 computer racks, and a datacenter cluster may include 5 to 10 or even over 10 datacenters, which increases the burden of scanning devices.</p>
<p id="p-0011" num="0010">Moreover, in certain situations, scanning devices and recording locations may be subject to operator error. For example, an operator may fail to scan a code, thus failing to obtain the device identifier. In addition, devices may be required to be scanned in a certain manner in order to match the device with the correct location on a computer rack. For example, the devices of a computer rack may be required to be scanned in a particular order, such as starting at a top shelf and scanning from left to right, then moving to the shelf below the top shelf and scanning from left to right, and so on. The scanning may yield a sequence of device identifiers in an order that indicates the location of the devices in the rack. If an operator fails to scan a code or scans the codes out of an expected order, however, the locations of the devices may be incorrectly identified.</p>
<p id="p-0012" num="0011">Certain embodiments of the disclosure may ease the burden of obtaining device identifiers and device locations. For example, certain embodiments receive an image of a container (such as a computer rack) that stores devices (such as computing devices). Certain embodiments locate device codes in the image, read device identifiers from the device codes, and determine device locations according to the location of the device codes in the image. Certain embodiments associate the device identifiers and the device locations and store the one or more device identifier-location associations. Certain embodiments may reduce involvement by a human operator, which may reduce human error.</p>
<p id="p-0013" num="0012">Although certain examples describe a container as a computer rack and devices as computing devices, this disclosure contemplates determining locations of any suitable objects in any suitable situation. For example, the locations of products in a warehouse, components in a computer, or equipment in a box may be determined. Other examples are presented in this disclosure.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example of a system <b>10</b> configured to determine and record locations of one or more devices <b>24</b> in a container <b>20</b>. In certain embodiments, system <b>10</b> captures an image of devices <b>24</b> in container <b>20</b>, where devices <b>24</b> have device codes <b>28</b>. For one or more device codes <b>28</b>, system <b>10</b> locates a device code <b>28</b> in the image. System <b>10</b> then determines a device identifier of device <b>24</b> from device code <b>28</b> and determines a device location using device code <b>28</b>. System <b>10</b> associates the device identifier and the device location to yield a device identifier-location association (such as a mapping) that records the location of device <b>24</b>.</p>
<p id="p-0015" num="0014">Certain embodiments of this disclosure operate on physical objects. In certain embodiments, an object may reflect and/or emit electromagnetic waves (such as visible light) such that an image may be taken of the object. Examples of objects include container <b>20</b> and devices <b>24</b>, described in more detail below. In certain embodiments, objects have object identifiers that can be used to identify the objects. An identifier may include a sequence of characters. Examples of identifiers may include serial numbers, code numbers (such as manufacturer code numbers or customer requested code numbers), or other suitable identifiers.</p>
<p id="p-0016" num="0015">Certain embodiments of this disclosure utilize codes that can provide information about objects, such as object identifiers. In certain embodiments, codes may include geometric patterns that can be read to provide the information. For example, a code may be a barcode that has a particular pattern of geometric shapes (such as squares, dots, polygons, bars, or other shapes) that can be optically scanned to obtain the information. In certain embodiments, codes may be read using optical character recognition.</p>
<p id="p-0017" num="0016">A code may be any suitable size. In certain embodiments, the size of the code may be selected according to the size of the object and the capability to read the code. For example, the code may be small enough to be affixed to the object, but large enough to be able to be scanned and read by system <b>10</b>. In certain embodiments, the code may be affixed directly to the object, but in other embodiments need not be affixed to the object.</p>
<p id="p-0018" num="0017">In the illustrated example, container <b>20</b> has container code <b>26</b>. Container <b>20</b> holds devices <b>24</b>, which may each have device codes <b>28</b>. In the illustrated example, system <b>10</b> includes a camera <b>40</b> and an image processor <b>42</b>. Camera <b>40</b> and image processor <b>42</b> may communicate in any suitable manner, for example over wireless and/or wired links.</p>
<p id="p-0019" num="0018">Container <b>20</b> may be a physical object that can hold other objects such as devices <b>24</b>. Examples of containers <b>20</b> include containers (such as computer racks, storage and display cases, boxes, and shelving systems), buildings (such as warehouses, stores, and parking lots), products with components (such as computers, automobiles, and appliances), and other objects that can hold objects. In certain embodiments, container <b>20</b> may include regions (such as areas or volumes) where objects may be located. Examples of regions include all or a portion of any of the following: a shelf, a slot, a cabinet, a cell, a space, and other region where an object may be located.</p>
<p id="p-0020" num="0019">In certain embodiments, container <b>20</b> may have a container identifier. Container <b>20</b> may have a container code <b>26</b> that may be scanned to obtain information about container <b>20</b>, such as the container identifier. In certain embodiments, a container code <b>26</b> may also operate as a device code <b>28</b>. The container identifiers and codes may be similar to the identifiers and codes described previously.</p>
<p id="p-0021" num="0020">Container <b>20</b> may have a container location where container <b>20</b> is physically located. Container location may be expressed in any suitable manner. In certain embodiments, container location may include parameters that identify the location. For example, a computer rack located in a region G of a datacenter DC of a datacenter cluster DCC may have a container location expressed as (DCC, DC, G).</p>
<p id="p-0022" num="0021">A device <b>24</b> may be any suitable physical object. Examples of devices <b>24</b> include computer equipment or computing devices (such as switches, drives, routers, servers, computing processing units, cables, and other computer equipment), products (such as consumer products), components of an object (such as ports, drives, and disks), and other objects. Device <b>24</b> may have a device identifier that identifies device <b>24</b>. Device <b>24</b> may have a device code <b>28</b> that can be read to obtain information about device <b>24</b>, such as the device identifier. In certain embodiments, a device code <b>28</b> may also operate as a container code <b>26</b>. The device identifiers and codes may be similar to the codes and identifiers described previously.</p>
<p id="p-0023" num="0022">The device location identifies the location where device <b>24</b> is located. The device location may be expressed in any suitable manner. In certain embodiments, the device location may include parameters that identify the location. For example, a computing device located in a slot S of a rack R of a datacenter DC may have a device location expressed as (DC, R, S). In certain embodiments, the device location may include all or a portion of the container identifier. For example, device location (DC, R, S) includes a portion of container location (DCC, DC, G).</p>
<p id="p-0024" num="0023">In certain embodiments, a container <b>20</b> may include a first device <b>24</b> that serves as a container <b>20</b> for a second device <b>24</b>. For example, a computer rack may serve as a container <b>20</b> for a computing device, which may serve as a container <b>20</b> for components within the computing device. In the embodiments, the device code <b>28</b> of the first device <b>24</b> may also operate as a container code <b>26</b>.</p>
<p id="p-0025" num="0024">Camera <b>40</b> captures an image of (such as photographs or images) an object by recording light reflected and/or emitted from the object. The light may be from the visible or other portion of the spectrum. Images may be still photographs or moving images such as videos or movies. Camera <b>40</b> may output image data <b>70</b> generated from the recorded light, which may be used to reproduce and/or analyze the image. In this disclosure, operations described as being performed on an image may be performed by processing image data <b>70</b>. For example, a target may be located in an image by performing feature detection on image data <b>70</b>. Examples of camera <b>40</b> include digital cameras such as camera phones, digital single lens reflex cameras, compact cameras, and bridge digital cameras.</p>
<p id="p-0026" num="0025">Camera <b>40</b> may capture an image of container <b>20</b> in any suitable manner. For example, a human operator may operate camera <b>40</b> to capture the image. As another example, camera <b>40</b> may be mounted on a moving robotic device that automatically moves camera <b>40</b> into position and captures the image of container <b>20</b>. As another example, camera <b>40</b> may be mounted in a substantially stationary manner at a location to image container <b>20</b>.</p>
<p id="p-0027" num="0026">In certain embodiments, image processor <b>42</b> may locate targets, such as container <b>20</b> and device codes <b>28</b>, in the image. Image processor <b>42</b> may determine device identifiers from the device codes and may determine the device locations proximate to or at the location of the device code. Image processor <b>42</b> may map the device identifiers and the device locations to yield a device identifier-location associations (such as mappings). An example of image processor <b>42</b> is described in more detail with reference to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of an image processor <b>42</b> that may be used with system <b>10</b>. In the example, image processor <b>42</b> includes one or more interfaces (IFs) <b>50</b>, logic <b>52</b>, and memory <b>54</b>. Logic <b>52</b> includes one or more processors <b>60</b> and applications such as a quality control module <b>62</b>, a target detector <b>64</b>, a code reader <b>66</b>, and a location engine <b>68</b>. Memory <b>54</b> stores image data <b>70</b>, one or more templates <b>72</b>, and device identifier-location mappings <b>74</b>.</p>
<p id="p-0029" num="0028">In certain embodiments, image processor <b>42</b> receives image data <b>70</b> of an image from camera <b>40</b> and processes image data <b>70</b> to analyze the image. Image data <b>70</b> may have any suitable format. For example, image data <b>70</b> may be digital data that digitally represents an image. The digital data may be vector or raster type data.</p>
<p id="p-0030" num="0029">Quality control module <b>62</b> determines whether an image is satisfactory. An image may be determined to be satisfactory in any suitable manner. In certain examples, quality control module <b>62</b> may perform prefiltering. In certain embodiments, an image may be evaluated by comparing it with a reference image that is assumed to be of satisfactory or higher quality. For example, an image of a bar code may be compared to a reference bar code image. In certain embodiments, the image may be judged according to image quality factors, which may be selected such that code reader <b>66</b> can read an identifier from a code. Examples of image quality factors include sharpness, noise, dynamic range, contrast, distortion, and/or other image quality factors that may be used to determine whether code reader <b>66</b> can read the code.</p>
<p id="p-0031" num="0030">In certain examples, quality control module <b>62</b> may determine whether an image is satisfactory based on whether modules of image processor <b>42</b> (such as target detector <b>64</b>, code reader <b>66</b>, and/or location engine <b>68</b>) can operate on the image data to provide an output. For example, if a module cannot operate on an image, quality control module <b>62</b> may determine that the image is unsatisfactory. If an image is not satisfactory, quality control <b>62</b> may request that another image of container <b>20</b> be taken. For example, image processor <b>42</b> may send a message to camera <b>40</b> indicating that the image was not satisfactory.</p>
<p id="p-0032" num="0031">Target detector <b>64</b> may locate targets, such as container and device codes, in an image. Targets may be located in any suitable manner. In certain embodiments, target detector <b>64</b> may use feature detection to detect features (such as edges and corners) that are indicative of the shape and/or size of a particular target. For example, edges and corners that form a rectangular shape of a size in a particular range (such as 4 to 8, 8 to 10, 10 to 16, or greater then 16 feet<sup>2</sup>) may be indicative of a container <b>20</b>. As another example, edges and corners that form a rectangular shape of a size in a particular range (such as 0.25 to 0.5, 0.5 to 1, 1 to 2, 2 to 4, 4 to 8, or greater then 8 feet<sup>2</sup>) may be indicative of a device <b>24</b>. As another example, edges and corners that form a rectangular shape of a size in a particular range (such as less than 1 to 2, 2 to 4, 4 to 10 inch<sup>2</sup>), may be indicative of a code.</p>
<p id="p-0033" num="0032">Code reader <b>66</b> may read identifiers from codes, for example, a device identifier from device code <b>28</b> or a container identifier from container code <b>26</b>. Code reader <b>66</b> may read an identifier from a code in any suitable manner. In certain embodiments, code reader <b>66</b> may translate code patterns in an code image to values understood by a computing system. For example, optical character recognition (OCR) may be used to translate digital images into machine-encoded text.</p>
<p id="p-0034" num="0033">Location engine <b>68</b> may determine a device location with respect to the location of device code <b>28</b>. The device location may be determined in any suitable manner. In certain embodiments, device code <b>28</b> may be affixed to device <b>24</b>, and the device location may be assumed to be at or at least proximate to device code <b>28</b>. In other embodiments, device code <b>28</b> may point to device <b>24</b> (which may or may not be located by target detector <b>64</b>), and device <b>24</b> may be assumed to be in the location indicated by device code <b>28</b>.</p>
<p id="p-0035" num="0034">In certain embodiments, an image depicts a device code <b>28</b> and/or device <b>24</b> in spatial relation to other objects, such as container <b>20</b> or other device codes <b>28</b> and/or devices <b>24</b>. The spatial relationships in an image may be used to determine the location of device <b>24</b> with respect to the other objects in the physical world apart from the image. For example, if device <b>24</b> is depicted to be on a top shelf of container <b>20</b> in an image, device <b>24</b> may be determined to be on the top shelf of container <b>20</b> in the physical world. As another example, if a first device <b>24</b> is depicted to be above a second device <b>24</b> in an image, device <b>24</b> may be determined to be above the second device <b>24</b> in the physical world.</p>
<p id="p-0036" num="0035">Spatial relationships may also be used to determine the location of device <b>24</b> specified in a coordinate system. For example, a device <b>24</b> may be depicted in the image to be at (x,y) of a coordinate system based on container <b>20</b>, where x measures distance from a left hand border of container <b>20</b> and y measures distance from a top border of container <b>20</b>. Device <b>24</b> may then be determined to be x distance from the left hand border of container <b>20</b> and y distance from the top border of container <b>20</b> in the physical world.</p>
<p id="p-0037" num="0036">Location engine <b>68</b> may express a device location in any suitable manner. For example, the device location may be expressed with respect to container <b>20</b> or other devices <b>24</b>. As another example, the device location may be specified in a coordinate system that is based on container <b>20</b> or other devices <b>24</b>. Examples of methods for determining and expressing device locations are described in more detail with reference to <figref idref="DRAWINGS">FIGS. 4A through 4C</figref>.</p>
<p id="p-0038" num="0037">Continuing with <figref idref="DRAWINGS">FIG. 2</figref>, in certain examples, location engine <b>68</b> may use a template <b>72</b> that matches devices container <b>20</b> to determine the location of a device in container <b>20</b>. A template may describe locations (or &#x201c;cells&#x201d;) of container <b>20</b> where a device <b>24</b> could be located, but in which a device <b>24</b> might or might not be currently located. For example, a template <b>73</b> of a computer rack may describe slots, shelves, or regions of the computer rack where devices <b>24</b> could be located.</p>
<p id="p-0039" num="0038">The container template <b>72</b> that matches container <b>20</b> may be identified in any suitable manner. For example, a container template <b>72</b> may include container identifiers of containers <b>20</b> that template <b>72</b> matches, so the container identifier of a particular container <b>20</b> may be used to identify a matching template <b>72</b>. As another example, each container template <b>72</b> may include image features of containers <b>20</b> that the template <b>72</b> matches, so the image features of a particular container <b>20</b> may be used to identify a matching template <b>72</b>.</p>
<p id="p-0040" num="0039">Location engine <b>68</b> may associate (such as map) the device identifiers and the device locations to yield device identifier-location associations (such as mappings). The device identifier-location mapping <b>74</b> of a device may be used to determine the location of the device, given the device identifier. The device identifier-location mapping of a device may also be used to determine the device identifier of the device, given the device location.</p>
<p id="p-0041" num="0040">For example, location engine <b>68</b> may receive a request for the location of a device with a given device identifier. Location engine <b>68</b> may determine the device location from a device identifier-location mapping for the given device identifier and may report the device location. In addition, location engine <b>68</b> may receive a request for the device identifier of a device at a given location. Location engine <b>68</b> may determine the device identifier from a device identifier-location mapping for the given location and may report the device identifier.</p>
<p id="p-0042" num="0041">Location engine <b>68</b> may convert the device location from a stored format to another format to report the location to a user. For example, the device location may be stored as expressed in a coordinate system, but may be converted to a location with respect to container <b>20</b> or other devices <b>24</b> to report to a user. Examples of ways to represent and convert device locations are described in more detail with reference to <figref idref="DRAWINGS">FIGS. 4A and 4B</figref>.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an example of a method of determining and recording locations of one or more devices <b>24</b> in a container <b>20</b>. In certain embodiments, the method may be computer-implemented and/or may be performed by system <b>10</b>.</p>
<p id="p-0044" num="0043">The method starts at step <b>110</b>, where an image is captured. The image may be captured in any suitable manner. In certain embodiments, camera <b>42</b> takes a digital photograph of container <b>20</b> and sends image data <b>70</b> to image processor <b>42</b>. Camera <b>42</b> may also send a camera identifier that identifies camera <b>40</b> sending image data <b>70</b>. The image is received at step <b>114</b>.</p>
<p id="p-0045" num="0044">The image may be satisfactory at step <b>118</b>. For example, quality control <b>62</b> may determine whether the image is satisfactory. If the image is not satisfactory, the method proceeds to step <b>120</b>, where another image capture is requested. For example, quality control <b>62</b> may send a message to camera <b>40</b> identified by camera identifier requesting that another image be taken. If the image is satisfactory at step <b>118</b>, the method proceeds to step <b>124</b>.</p>
<p id="p-0046" num="0045">In certain embodiments, quality control <b>62</b> may operate at one or more steps of steps <b>124</b> through <b>134</b>. If a module (such as target detector <b>64</b>, code reader <b>66</b>, and/or location engine <b>68</b>) cannot operate on the image to provide an output, quality control <b>62</b> may determine that the image is unsatisfactory and request that another image be taken.</p>
<p id="p-0047" num="0046">Container <b>20</b> may be located in the image at step <b>124</b>. Container <b>20</b> may be located in any suitable manner. For example, target detector <b>64</b> may use feature detection to locate container <b>20</b>. Container code <b>26</b> is located in the image at step <b>125</b>. Container code <b>26</b> may be located in any suitable manner. For example, target detector <b>64</b> may use feature detection to locate container code <b>26</b>. The container identifier may be read from the container code at step <b>126</b>. In certain embodiments, the container identifier may be used to locate a template <b>72</b> that describes cells of container <b>10</b>. In certain embodiments, step <b>125</b> and <b>126</b> may be performed to identify a template <b>72</b>, and step <b>124</b> may be omitted.</p>
<p id="p-0048" num="0047">Steps <b>128</b> through <b>140</b> may be repeated for one or more device codes <b>28</b> of the image. A device code <b>28</b> is located in the image at step <b>128</b>. Device code <b>28</b> may be located in any suitable manner. For example, target detector <b>64</b> may locate device code <b>28</b> using feature detection. The device identifier is read from device code <b>28</b> at step <b>130</b>. The device identifier may be read in any suitable manner. For example, code reader <b>66</b> may read the device identifier from device code <b>28</b>.</p>
<p id="p-0049" num="0048">The device location is determined at step <b>134</b>. In certain embodiments, location engine <b>68</b> may determine the device location in any suitable manner. <figref idref="DRAWINGS">FIGS. 4A through 4C</figref> describe examples of determining the device location. The device identifier and location are stored at step <b>138</b>. The device identifier may be mapped to the device location as a device identifier-location mapping. The device identifier-location mapping <b>74</b> may be used to determine the location of a device given the device identifier, or may be used to determine the device identifier of a device, given the device location.</p>
<p id="p-0050" num="0049">There may be a next device code <b>28</b> in the image at step <b>140</b>. If there is a next device code <b>28</b>, the method returns to step <b>128</b> to locate the next device code <b>28</b>. If there is no next device code <b>28</b> in the image, the method proceeds to step <b>144</b>.</p>
<p id="p-0051" num="0050">A request for a device location may be received at step <b>144</b>. The request may be received in any suitable manner. For example, a user may send a request for a device location that may include a device identifier. Location engine <b>68</b> may use a device identifier-location mapping <b>74</b> to determine the device location given the device identifier. The device location may be converted at step <b>148</b> to a format that may be reported. The converted device location is reported at step <b>150</b>. In certain embodiments, interface <b>50</b> may be used to report the device location. The method then ends.</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIGS. 4A through 4C</figref> illustrate examples of methods of determining and expressing the device location. The illustrated examples show images of container <b>20</b> (with rack identifier R) with devices <b>24</b> (with device identifiers A, B, C, . . . , N). In the examples, rack R is located in datacenter DC.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 4A</figref> illustrates an example of determining and expressing a device location in a container coordinate system based on container <b>20</b>. A container coordinate system may be defined with respect to container <b>20</b> by mapping an origin and coordinate axes to parts of container <b>20</b>. In the illustrated example, the origin of the coordinate system is mapped to an upper left-hand corner of container <b>20</b>. A x-axis is mapped to a top border of container <b>20</b>, and a y-axis is mapped to a left-hand side border of container <b>20</b>. The units of the x axis may be the width of container <b>20</b>, and the units of the y axis may be a rack unit (U), which may be 1.75 inches.</p>
<p id="p-0054" num="0053">In the example, a device location may be expressed as (DC, R, x, y). In the example, the device locations may be expressed as:</p>
<p id="p-0055" num="0054">Device A: (DC, R, 0, 1)</p>
<p id="p-0056" num="0055">Device B: (DC, R, 0, 2)</p>
<p id="p-0057" num="0056">Device C: (DC, R, &#xbd;, 2)</p>
<p id="p-0058" num="0057">Device N: (DC, R, 0, n)</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 4B</figref> illustrates an example of determining and expressing a device location with respect to a particular device <b>24</b>. In certain embodiments, the device location may be determined with respect to an origin device coordinate system based on a device <b>24</b> designated as an origin device. In the illustrated example, device A is selected as the origin device. The device locations of the devices may be expressed as:</p>
<p id="p-0060" num="0059">Device A: (DC, R, 0, 0)</p>
<p id="p-0061" num="0060">Device B: (DC, R, first device under device A, left hand side of A)</p>
<p id="p-0062" num="0061">Device C: (DC, R, first device under device A, right hand side of A)</p>
<p id="p-0063" num="0062">Device N: (DC, R, nth device under device A)</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 4C</figref> illustrates an example of determining and expressing a device location using container cells of container <b>20</b>. A container cell may be a region of container <b>20</b> in which a device <b>24</b> could be located. A cell may have a cell identifier that may be used as the device location. In certain embodiments, container template <b>72</b> that matches container <b>20</b> may be used to determine the layout of the container cells.</p>
<p id="p-0065" num="0064">In the illustrated example, template <b>72</b> of rack R may describe the layout of cells <b>1</b> through n. The device locations may be:</p>
<p id="p-0066" num="0065">Device A: (DC, R, cell 1)</p>
<p id="p-0067" num="0066">Device B: (DC, R, cell 2A)</p>
<p id="p-0068" num="0067">Device C: (DC, R, cell 2B)</p>
<p id="p-0069" num="0068">Device N: (DC, R, cell n)</p>
<p id="p-0070" num="0069">In certain embodiments, the device location may be converted from one representation to another representation. For example, the device location may be converted from a location expressed in a coordinate system to a location expressed with respect to another device <b>24</b> or container <b>20</b>. In certain embodiments, the device location may be stored in one representation and then converted to another representation for presentation to a user.</p>
<p id="p-0071" num="0070">A location may be converted in any suitable manner, for example, by applying a conversion function (such as a mathematical function) to the location to yield a converted location. In certain embodiments, device locations expressed as coordinates in a coordinate system may be converted to device locations relative to other devices. For example, in the coordinate system of <figref idref="DRAWINGS">FIG. 4A</figref>, a device with y=k may be under a device with a y=k&#x2212;1 and above a device with a y=k+1. A device with a lower x value may be to the left of a device with a higher x value.</p>
<p id="p-0072" num="0071">In certain embodiments, device locations expressed as coordinates in the coordinate system may be converted to cell locations. For example, in the coordinate system of <figref idref="DRAWINGS">FIG. 4A</figref>, a device with a y=k may be in a cell that is under a cell with a device location y=k&#x2212;1, and above a cell with a device location of y=k+1.</p>
<p id="p-0073" num="0072">Modifications, additions, or omissions may be made to the systems and apparatuses disclosed herein without departing from the scope of the invention. The components of the systems and apparatuses may be integrated or separated. For example, camera <b>40</b> and image processor <b>42</b> may be integrated or separated. Moreover, the operations of the systems and apparatuses may be performed by more, fewer, or other components. For example, the operations of target detector <b>64</b> and code reader <b>66</b> may be performed by one component, or the operations of location engine <b>68</b> may be performed by more than one component. Additionally, operations of the systems and apparatuses may be performed using any suitable logic comprising software, hardware, and/or other logic. As used in this document, &#x201c;each&#x201d; refers to each member of a set or each member of a subset of a set.</p>
<p id="p-0074" num="0073">Modifications, additions, or omissions may be made to the methods disclosed herein without departing from the scope of the invention. The methods may include more, fewer, or other steps. Additionally, steps may be performed in any suitable order.</p>
<p id="p-0075" num="0074">A component of the systems and apparatuses disclosed herein may include an interface, logic, memory, and/or other suitable element. An interface receives input, sends output, processes the input and/or output, and/or performs other suitable operation. An interface may comprise hardware and/or software.</p>
<p id="p-0076" num="0075">Logic performs the operations of the component, for example, executes instructions to generate output from input. Logic may include hardware, software, and/or other logic. Logic may be encoded in one or more tangible media and may perform operations when executed by a computer. Certain logic, such as a processor (or processing unit), may manage the operation of a component. Examples of a processor include one or more computers, one or more microprocessors, one or more applications, and/or other logic.</p>
<p id="p-0077" num="0076">In particular embodiments, the operations of the embodiments may be performed by one or more computer readable media encoded with a computer program, software, computer executable instructions, and/or instructions capable of being executed by a computer. In particular embodiments, the operations of the embodiments may be performed by one or more computer readable media storing, embodied with, and/or encoded with a computer program and/or having a stored and/or an encoded computer program.</p>
<p id="p-0078" num="0077">A memory (or memory unit) stores information. A memory may comprise one or more non-transitory, tangible, computer-readable, and/or computer-executable storage media. Examples of memory include computer memory (for example, Random Access Memory (RAM) or Read Only Memory (ROM)), mass storage media (for example, a hard disk), removable storage media (for example, a Compact Disk (CD) or a Digital Video Disk (DVD)), database and/or network storage (for example, a server), and/or other computer-readable medium.</p>
<p id="p-0079" num="0078">Components of the systems and apparatuses may be coupled by any suitable communication network. A communication network may comprise all or a portion of one or more of the following: a public switched telephone network (PSTN), a public or private data network, a local area network (LAN), a metropolitan area network (MAN), a wide area network (WAN), a local, regional, or global communication or computer network such as the Internet, a wireline or wireless network, an enterprise intranet, other suitable communication link, or any combination of any of the preceding.</p>
<p id="p-0080" num="0079">Although this disclosure has been described in terms of certain embodiments, alterations and permutations of the embodiments will be apparent to those skilled in the art. Accordingly, the above description of the embodiments does not constrain this disclosure. Other changes, substitutions, and alterations are possible without departing from the spirit and scope of this disclosure, as defined by the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system comprising:
<claim-text>one or more interfaces operable to:
<claim-text>receive one or more images of a computer rack;</claim-text>
</claim-text>
<claim-text>one or more memory units operable to:
<claim-text>store the one or more images of the computer rack; and</claim-text>
</claim-text>
<claim-text>one or more processing units operable to:
<claim-text>access a particular image of the one or more images;</claim-text>
<claim-text>repeat the following for each of one or more device codes of the particular image to yield a device identifier-location association for each of the one or more device codes:
<claim-text>locate a device code in the particular image;</claim-text>
<claim-text>read a device identifier from the device code;</claim-text>
<claim-text>determine a device location of a computing device based at least in part on the location of the device code in the particular image, the device location being a coordinate location of the device code in the particular image;</claim-text>
<claim-text>associate the device identifier and the device location to yield a device identifier-location association; and</claim-text>
<claim-text>store the device identifier-location association;</claim-text>
</claim-text>
<claim-text>access a template associated with the computer rack; and</claim-text>
<claim-text>convert, based at least in part on the accessed template associated with the computer rack, a particular device location of a particular computing device from the coordinate location of the device code in the particular image to a location with respect to the computer rack.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>,
<claim-text>wherein the location with respect to the computer rack comprises a spatial relationship between the location of the device code in the particular image and the location of the computer rack in the particular image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the particular image is accessed in response to a determination that a previously-accessed image of the one or more images is not satisfactory.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processing modules are further operable to:
<claim-text>receive a request for a requested device location associated with a given device identifier; and</claim-text>
<claim-text>determine the requested device location from a device identifier-location association for the given device identifier.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, the receiving the one or more images further comprising:
<claim-text>receiving the one or more images from a camera operable to image the computer rack.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A computer-implemented method comprising:
<claim-text>receiving one or more images of a container;</claim-text>
<claim-text>accessing a particular image of the one or more images;</claim-text>
<claim-text>repeating, using one or more processing units, the following for each of one or more device codes of the particular image to yield a device identifier-location association for each of the one or more device codes:
<claim-text>locating a device code in the particular image;</claim-text>
<claim-text>reading a device identifier from the device code;</claim-text>
<claim-text>determining a device location based at least in part on the location of the device code in the particular image, the device location being a coordinate location of the device code in the particular image;</claim-text>
<claim-text>associating the device identifier and the device location to yield a device identifier-location association; and</claim-text>
<claim-text>storing the device identifier-location association;</claim-text>
</claim-text>
<claim-text>accessing a template associated with the container; and</claim-text>
<claim-text>converting, based at least in part on the accessed template associated with the container, a particular device location of a particular computing device from the coordinate location of the device code in the particular image to a location with resect to the container.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:
<claim-text>locating a container code in the particular image of the one or more images, wherein the template associated with the container is accessed based at least in part on the container code.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>,
<claim-text>wherein the location with respect to the container comprises a spatial relationship between the location of the device code in the particular image and the location of the container in the particular image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>,
<claim-text>wherein the location with respect to the container comprises a spatial relationship between the location of the device code in the particular image and the location of an origin device of the one or more devices in the particular image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>,
<claim-text>wherein the location with respect to the container is expressed as one of a plurality of container cells of the container.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:
<claim-text>receiving a request for a requested device location associated with a given device identifier; and</claim-text>
<claim-text>determining the requested device location from a device identifier-location association for the given device identifier.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>,
<claim-text>wherein converting the particular device location of the particular computing device from the coordinate location of the device code in the particular image to a location with respect to the container is performed in response to a request for the particular device location associated with the device identifier of the particular computing device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the particular image is accessed in response to a determination that a previously-accessed image of the one or more images is not satisfactory.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The computer-implemented method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, the receiving the one or more images further comprising:
<claim-text>receiving the one or more images from a camera operable to image the container.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. One or more non-transitory computer-readable media comprising logic, the logic when executed by one or more processing units operable to perform operations comprising:
<claim-text>accessing one or more images of a container;</claim-text>
<claim-text>locating the container in a particular image of the one or more images;</claim-text>
<claim-text>repeating the following for each of one or more device codes of the particular image to yield a device location for each of the one or more device codes:
<claim-text>locating a device code in the particular image;</claim-text>
<claim-text>determining a device location based at least in part on the location of the device code in the particular image, the device location being a coordinate location of the device code in the particular image;</claim-text>
<claim-text>converting, based at least in art on an accessed template associated with the container, the determined device location from the coordinate location of the device code in the particular image to a location with respect to the container; and</claim-text>
<claim-text>recording the one or more device locations.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the logic when executed by one or more processing units is further operable to:
<claim-text>associate a device identifier of each device and a device location of each device to yield one or more device identifier-location associations.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein the location with respect to the container comprises a spatial relationship between the location of the device code in the particular image and the location of the container in the particular image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein the location with respect to the container comprises a spatial relationship between the location of the device code in the particular image and the location of an origin device of the one or more devices in the particular image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein the location with respect to the container is expressed as one of a plurality of container cells of the container.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the logic when executed by one or more processing units is further operable to:
<claim-text>associate a device identifier of each device and a device location of each device to yield one or more device identifier-location associations; and</claim-text>
<claim-text>receive a request for a requested device location associated with a given device identifier; and</claim-text>
<claim-text>determine the requested device location from a device identifier-location association for the given device identifier.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>,
<claim-text>wherein converting the particular device location of the particular computing device from the coordinate location of the device code in the particular image to a location with respect to the container is performed in response to a request for the particular device location associated with the device identifier of the particular computing device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the particular image is accessed in response to a determination that a previously-accessed image of the one or more images is not satisfactory. </claim-text>
</claim>
</claims>
</us-patent-grant>
