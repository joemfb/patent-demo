<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625934-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625934</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13331872</doc-number>
<date>20111220</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>195</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>32</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382300</main-classification>
<further-classification>382274</further-classification>
<further-classification>382275</further-classification>
<further-classification>382291</further-classification>
<further-classification>358  326</further-classification>
<further-classification>358  327</further-classification>
<further-classification>358525</further-classification>
</classification-national>
<invention-title id="d2e53">Method and apparatus for detecting displacement with sub-pixel accuracy</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5640200</doc-number>
<kind>A</kind>
<name>Michael</name>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5729008</doc-number>
<kind>A</kind>
<name>Blalock et al.</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6664948</doc-number>
<kind>B2</kind>
<name>Crane et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6996291</doc-number>
<kind>B2</kind>
<name>Nahum</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7502515</doc-number>
<kind>B2</kind>
<name>Gu et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7738699</doc-number>
<kind>B2</kind>
<name>Tsuruoka et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382169</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7751645</doc-number>
<kind>B2</kind>
<name>Reneker et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382275</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>8111307</doc-number>
<kind>B2</kind>
<name>Deever et al.</name>
<date>20120200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348246</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>8130278</doc-number>
<kind>B2</kind>
<name>Border et al.</name>
<date>20120300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482086</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>8290263</doc-number>
<kind>B2</kind>
<name>Tsuruoka et al.</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382169</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>TW</country>
<doc-number>I225622</doc-number>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Bing Pan et al., &#x201c;Development of Sub-Pixel Displacements Registration Algorithms in Digital Image Correlation&#x201d;, Advances in Mechanics, vol. 35, No. 3, Aug. 25, 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>24</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382274</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382275</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382278</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382282</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382291</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382300</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  326</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  327</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358525</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>18</number-of-drawing-sheets>
<number-of-figures>27</number-of-figures>
</figures>
<us-related-documents>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12020699</doc-number>
<date>20080128</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8090221</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13331872</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120127077</doc-number>
<kind>A1</kind>
<date>20120524</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Chen</last-name>
<first-name>Hsin Chia</first-name>
<address>
<city>Hsin-Chu County</city>
<country>TW</country>
</address>
</addressbook>
<residence>
<country>TW</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kao</last-name>
<first-name>Ming Tsan</first-name>
<address>
<city>Hsin-Chu County</city>
<country>TW</country>
</address>
</addressbook>
<residence>
<country>TW</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Chen</last-name>
<first-name>Hsin Chia</first-name>
<address>
<city>Hsin-Chu County</city>
<country>TW</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Kao</last-name>
<first-name>Ming Tsan</first-name>
<address>
<city>Hsin-Chu County</city>
<country>TW</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Pixart Imaging Inc.</orgname>
<role>03</role>
<address>
<city>Hsin-Chu County</city>
<country>TW</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kassa</last-name>
<first-name>Yosef</first-name>
<department>2669</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method of detecting displacement with sub-pixel accuracy includes the steps of: capturing a first array image and a second array image; interpolating the first array image to form a reference image; interpolating the second array image to form a comparison image; comparing the reference image with the comparison image so as to obtain a displacement. The present invention also provides an apparatus for detecting displacement with sub-pixel accuracy.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="162.31mm" wi="145.71mm" file="US08625934-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="212.09mm" wi="163.41mm" orientation="landscape" file="US08625934-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="224.96mm" wi="195.41mm" file="US08625934-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="171.70mm" wi="183.30mm" file="US08625934-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="194.82mm" wi="160.19mm" file="US08625934-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="232.58mm" wi="125.56mm" orientation="landscape" file="US08625934-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="199.31mm" wi="178.82mm" orientation="landscape" file="US08625934-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="194.82mm" wi="187.11mm" orientation="landscape" file="US08625934-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="271.10mm" wi="180.09mm" orientation="landscape" file="US08625934-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="273.64mm" wi="183.90mm" orientation="landscape" file="US08625934-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="278.13mm" wi="182.63mm" orientation="landscape" file="US08625934-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="276.18mm" wi="182.03mm" orientation="landscape" file="US08625934-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="278.13mm" wi="178.14mm" orientation="landscape" file="US08625934-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="251.21mm" wi="126.24mm" file="US08625934-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="197.36mm" wi="94.23mm" file="US08625934-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="176.19mm" wi="114.72mm" file="US08625934-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="210.23mm" wi="110.24mm" file="US08625934-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="155.11mm" wi="153.84mm" file="US08625934-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="201.25mm" wi="142.24mm" file="US08625934-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application is a continuation-in-part application of U.S. Ser. No. 12/020,699, filed on Jan. 28, 2008, the full disclosure of which is incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">This invention generally relates to a method and an apparatus for detecting image displacement, and more particularly, to a method and an apparatus for detecting displacement with sub-pixel accuracy.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">A conventional method for detecting sub-pixel displacement, e.g. Taiwan patent number I225622 entitled &#x201c;A method for detecting sub-pixel motion for optic navigation device&#x201d;, calculates the sub-pixel motion by the equations of approximately linear model of first order Taylor Expansion. The method includes the steps of: capturing a first and a second images at different time; choosing a plurality of pixels in the first image as reference pixels; calculating the partial derivatives of the reference pixels using the approximately linear model of first order Taylor Expansion from the two images and generating a plurality of first order equations; and calculating the sub-pixel motion according to the plurality of first order equations. However in practical operation, because the method for detecting displacement by using the equations of approximately linear model of first order Taylor Expansion leaves out higher order terms, errors may be introduced during detection and the method is only suitable for the cases with small displacements. When the displacements become larger, errors contained in the detected displacements become more apparent. In addition, because the partial derivatives have higher sensitivity to noise, the detected results can be easily affected by pixel noise.</p>
<p id="p-0007" num="0006">Another conventional method for calculating relative displacement, e.g. U.S. Pat. No. 5,729,008 entitled &#x201c;Method and device for tracking relative movement by correlating signals from an array of photoelements&#x201d; as shown in <figref idref="DRAWINGS">FIG. 1</figref>, captures a first frame <b>91</b> of 7&#xd7;7 pixels by an scanning device and defines a searching block <b>93</b> of 5&#xd7;5 pixels in the central area of the first frame <b>91</b>. The image device captures a second frame <b>92</b> in which the searching block <b>93</b> is shifted toward different directions so as to obtain images <b>940</b>&#x2dc;<b>948</b>. A relative movement can be calculated according to a correlation between the searching block <b>93</b> in the images <b>940</b>&#x2dc;<b>948</b> and the second frame <b>92</b>. However in practical operation, since the smallest movement which can be obtained by this conventional method is a distance between two adjacent pixels of the image device, it is unable to determine a tiny movement when the tiny movement is smaller than the distance of one pixel width.</p>
<p id="p-0008" num="0007">According to the above reasons, it is necessary to further improve the aforementioned conventional method and apparatus for detecting pixel motion so as to solve the problems existed in the art.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">It is an object of the present invention to provide a method and an apparatus for detecting displacement with sub-pixel accuracy which can increase the searching area and the resolution of the image by means of interpolation.</p>
<p id="p-0010" num="0009">It is another object of the present invention to provide a method and an apparatus for detecting displacement with sub-pixel accuracy which can increase the searching efficiency by means of a two-stage searching process.</p>
<p id="p-0011" num="0010">In order to achieve the above objects, the present disclosure provides a method of detecting displacement with sub-pixel accuracy for detecting a displacement of an optical navigation device with respect to a surface on which the optical navigation device is disposed, and the optical navigation device includes an image capturing unit, an interpolation unit and a processing unit. The method includes the steps of: moving the optical navigation device on the surface and capturing a first array image and a second array image with the image capturing unit; interpolating a first predetermined portion of the first array image to form a reference image with the interpolation unit; interpolating a second predetermined portion of the second array image to form a comparison image with the interpolation unit; and comparing the reference image with the comparison image by using the processing unit so as to obtain the displacement of the optical navigation device with respect to the surface thereby controlling a cursor or an aiming point accordingly.</p>
<p id="p-0012" num="0011">According to another aspect of the present disclosure, there is further provided a method of detecting displacement with sub-pixel accuracy for detecting a displacement of an optical navigation device with respect to a surface on which the optical navigation device is disposed, and the optical navigation device includes an image capturing unit, an interpolation unit and a processing unit. The method includes the steps of: moving the optical navigation device on the surface and capturing a first array image and a second array image with the image capturing unit; performing a first searching and comparison in the second array image by using the processing unit; interpolating a first predetermined portion of the first array image to form a reference image with the interpolation unit; interpolating a second predetermined portion of the second array image to form a comparison image with the interpolation unit; performing a second searching and comparison in the comparison image by using the processing unit; and calculating the displacement of the optical navigation device with respect to the surface by using the processing unit thereby controlling a cursor or an aiming point accordingly.</p>
<p id="p-0013" num="0012">According to an alternative aspect of the present disclosure, there is further provided a method of detecting displacement with sub-pixel accuracy for detecting a displacement of an optical navigation device with respect to a surface on which the optical navigation device is disposed, and the optical navigation device includes an image capturing unit, an interpolation unit and a processing unit. The method includes the steps of: moving the optical navigation device on the surface and capturing a first array image and a second array image with the image capturing unit; interpolating a first predetermined portion of the first array image to form a reference image with the interpolation unit; interpolating a second predetermined portion of the second array image to form a comparison image with the interpolation unit; performing a first searching and comparison in the comparison image by using the processing unit; performing a second searching and comparison in the comparison image by using the processing unit; and calculating the displacement of the optical navigation device with respect to the surface by using the processing unit thereby controlling a cursor or an aiming point accordingly.</p>
<p id="p-0014" num="0013">The present disclosure further provides an optical navigation device for detecting displacement with sub-pixel accuracy including an imaging capturing unit, an interpolation unit, a storage unit and a processing unit. The imaging capturing unit is for capturing a first array image and a second array image of a surface on which the optical navigation device is moving. The interpolation unit is for interpolating a predetermined portion of the first array image and the second array image to respectively form a reference image and a comparison image. The storage unit is for storing the first array image, the second array image, the reference image and the comparison image. The processing unit is for comparing the first array image with the second array image, and/or comparing the reference image with the comparison image so as to obtain a displacement of the optical navigation device with respect to the surface thereby controlling a cursor or an aiming point accordingly, wherein the processing unit is configured to define a first reference searching block in the first array image and define a first searching block in the second array image, and then successively search all pixels in the second array image with the first searching block and compare the first reference searching block with the first searching block so as to obtain a smallest sum of absolute values of all the differences in gray level value between every pixels in the first searching block and the pixels at corresponding positions in the first reference searching block to obtain the displacement, and/or is configured to define a second reference searching block in the reference image and define a second searching block in the comparison image, and then successively search all pixels in the comparison image with the second searching block and compare the second reference searching block with the second searching block so as to obtain a smallest sum of absolute values of all the differences in gray level value between every pixels in the second searching block and the pixels at corresponding positions in the second reference searching block to obtain the displacement.</p>
<p id="p-0015" num="0014">The method and apparatus for detecting displacement with sub-pixel accuracy of the present invention can increase the searching region by means of interpolation and detect a tiny displacement having sub-pixel level accuracy. The detected results can be transmitted to an image display, e.g. a TV screen, a computer screen, a game machine screen and a projection screen, through a transmitting interface so as to correspondingly control a cursor or the aiming point of a pointer. Embodiments of the apparatus for detecting displacement with sub-pixel accuracy include an optical mouse and a navigation device.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015">Other objects, advantages, and novel features of the present invention will become more apparent from the following detailed description when taken in conjunction with the accompanying drawings.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> shows a schematic view of a conventional method for calculating relative movements.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> shows a schematic view of an apparatus for detecting displacement with sub-pixel accuracy according to one embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3</figref> shows a block diagram of an apparatus for detecting displacement with sub-pixel accuracy according to one embodiment of the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 4</figref> shows a schematic view of the interpolation used in the method for detecting displacement with sub-pixel accuracy according to the embodiment of the present invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 5</figref> shows a flow chart of the method for detecting displacement with sub-pixel accuracy according to the embodiment of the present invention.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6</figref> shows a schematic view of the intensity distribution on a surface used in the embodiment of the present invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 7</figref><i>a </i>shows a schematic view of the gray level distribution of the first array image captured by the image capturing unit according to the embodiment of the present invention.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7</figref><i>b </i>shows a schematic view of the gray level distribution of the second array image captured by the image capturing unit according to the embodiment of the present invention.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 8</figref><i>a </i>shows a schematic view of the gray level distribution of one row of the first array image captured by the image capturing unit and that of the reference image according to the embodiment of the present invention, wherein the upper row shows one row of the first array image and the first reference searching block while the lower row shows one row of the reference image and the second reference searching block.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 8</figref><i>b </i>shows a schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the upper row shows one row of the second array image and the first searching block while the lower row shows one row of the comparison image and the second searching block.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 8</figref><i>c </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block moves rightward by 2 columns of intensity interval and the second searching block moves rightward by 1 column of intensity interval.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 8</figref><i>d </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block further moves rightward by 2 columns of intensity interval and the second searching block further moves rightward by 1 column of intensity interval.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 8</figref><i>e </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block further moves rightward by 2 columns of intensity interval and the second searching block further moves rightward by 1 column of intensity interval.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 8</figref><i>f </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block has finished the searching of the second array image and the second searching block further moves rightward by 1 column of intensity interval.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 8</figref><i>g </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block finished the searching of the second array image and the second searching block further moves rightward by 1 column of intensity interval.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 8</figref><i>h </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block finished the searching of the second array image and the second searching block further moves rightward by 1 column of intensity interval.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 8</figref><i>i </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block finished the searching of the second array image and the second searching block further moves rightward by 1 column of intensity interval.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 8</figref><i>j </i>shows another schematic view of the gray level distribution of one row of the second array image captured by the image capturing unit and that of the comparison image according to the embodiment of the present invention, wherein the first searching block finished the searching of the second array image and the second searching block has finished the searching of the comparison image.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 9</figref> shows a schematic view of the comparison image and the searching points of the fourth reference point in the second searching block, wherein the second searching block has to search 81 times.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 10</figref> shows a flow chart of the method for fast detecting displacement with sub-pixel accuracy according to the embodiment of the present invention.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 10</figref><i>a </i>shows a schematic view of the first searching points of the method for fast detecting displacement with sub-pixel accuracy according to the embodiment of the present invention, wherein the first searching needs 25 times.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 10</figref><i>b </i>shows a schematic view of the second searching points of the method for fast detecting displacement with sub-pixel accuracy according to the embodiment of the present invention, wherein the second searching needs 9 times.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 11</figref> shows a flow chart of another method for fast detecting displacement with sub-pixel accuracy according to the embodiment of the present invention.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 11</figref><i>a </i>shows a schematic view of the first searching points of another method for fast detecting displacement with sub-pixel accuracy according to the embodiment of the present invention, wherein the first searching needs 25 times.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 11</figref><i>b </i>shows a schematic view of the second searching points of another method for fast detecting displacement with sub-pixel accuracy according to the embodiment of the present invention, wherein the second searching needs 9 times.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 12</figref> shows a schematic diagram of the interpolation used in the method of detecting displacement with sub-pixel accuracy according to an alternative embodiment of the present invention.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 13</figref> shows a flow chart of the method of detecting displacement with sub-pixel accuracy according to an alternative embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
<p id="p-0044" num="0043">It should be noticed that, wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or like parts</p>
<p id="p-0045" num="0044">Referring to <figref idref="DRAWINGS">FIGS. 2 and 3</figref>, they respectively illustrate a schematic view and a block diagram of an apparatus for detecting displacement with sub-pixel accuracy <b>1</b> according to the embodiment of the present invention. Embodiments of the apparatus <b>1</b> include, but not limited to, an optical mouse and a navigation device. In the illustration of the present invention, an optical mouse shown in <figref idref="DRAWINGS">FIG. 2</figref> is served as an exemplary embodiment of the apparatus for detecting displacement with sub-pixel accuracy <b>1</b>. The apparatus <b>1</b> has a shell <b>100</b> having an opening &#x201c;H&#x201d; disposed at the bottom surface thereof and is placed on a surface &#x201c;S&#x201d;, e.g. the surface of a table or a mouse pad, during operation. A light source <b>101</b>, an image capturing unit <b>102</b>, an interpolation unit <b>103</b>, a storage unit <b>104</b>, a processing unit <b>105</b>, a transmitting unit <b>106</b> and at least one lens <b>107</b> are disposed inside the shell <b>100</b>. Embodiments of the light source <b>101</b> include, but not limited to, a light emitting diode (LED) and a laser diode, e.g. an infrared LED or an infrared laser diode. The light source <b>101</b> lights the surface &#x201c;S&#x201d; through the opening &#x201c;H&#x201d; of the shell <b>100</b> and the light reflected from the surface &#x201c;S&#x201d; enters the shell <b>100</b> again through the opening &#x201c;H&#x201d;. Embodiments of the image capturing unit <b>102</b> include a Charge-Coupled Device (CCD) image sensor, a Complementary Metal-Oxide-Semiconductor (CMOS) image sensor and the like. The image capturing unit <b>102</b> continuously captures optical images of the surface &#x201c;S&#x201d; through the opening &#x201c;H&#x201d; and converts the optical images into a plurality of array images.</p>
<p id="p-0046" num="0045">In one embodiment, the array images are stored in the storage unit <b>104</b> at first and then the stored array images are interpolated, e.g. bilinear interpolation, by the interpolation unit <b>103</b> so as to form at least one reference image and a plurality of comparison images which will then be stored back into the storage unit <b>104</b>. In another embodiment, the array images are directly interpolated by the interpolation unit <b>103</b> to form at least one reference image and a plurality of comparison images which then will be stored in the storage unit <b>104</b>. The processing unit <b>105</b> defines a reference searching block in the reference image, which is stored in the storage unit <b>104</b>, and defines a searching block in the comparison images, which are also stored in the storage unit <b>104</b>, and then controls the searching block to search the whole comparison image and to simultaneously compare the searching block with the reference searching block during searching process so as to calculate a displacement of the shell <b>100</b> with respect to the surface &#x201c;S&#x201d;. The detailed descriptions of the searching and interpolation processes will be illustrated in the following paragraphs. The calculated displacement is then transmitted to an image display (not shown), e.g. a computer screen, a TV screen, a game machine screen or a projection screen, through the transmitting unit <b>106</b> so as to perform a corresponding control on the image display, such as a motion control of a cursor on a computer screen or a motion control of the aiming pointer of a pointing device. In addition, a lens <b>107</b> may be disposed in front of the light source <b>101</b> so as to adjust the lighting area of the light source <b>101</b>, and a lens <b>107</b> may be disposed in front of the image capturing unit <b>102</b> so as to improve the detecting efficiency of the image capturing unit <b>102</b>.</p>
<p id="p-0047" num="0046">Referring to <figref idref="DRAWINGS">FIGS. 2</figref>, <b>3</b> and <b>4</b>, the interpolation process will be illustrated hereinafter. The image capturing unit <b>102</b> captures light from the surface &#x201c;S&#x201d; at a first time to form a first array image <b>21</b> which is an array image of 8&#xd7;8 pixels in this embodiment. Before interpolation, the pixel at the top-left corner of the first array image <b>21</b> has a gray level value of x[m,n]; its lower adjacent pixel has a gray level value of x[m+1,n]; its right adjacent pixel has a gray level value of x[m,n+1]; its diagonal adjacent pixel has a gray level value of x[m+1,n+1] and every pixels of the first array image <b>21</b> have corresponding gray level values. The central area of the first array image <b>21</b> having 4&#xd7;4 pixels is defined as a first reference searching block <b>211</b> and the pixel at the top-left corner of the first reference searching block <b>211</b> is defined as a first reference point <b>212</b> having an initial coordinate of [x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>1</sub>,y<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>1</sub>]. The first array image <b>21</b> is then interpolated by the interpolation unit <b>103</b>, for example, according to equation (1):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>x[</i>2<i>m+p,</i>2<i>n+q</i>]=(1&#x2212;<i>t</i>)&#xd7;(1<i>&#x2212;u</i>)&#xd7;<i>x[</i>2<i>m,</i>2<i>n]+t</i>&#xd7;(1&#x2212;<i>u</i>)&#xd7;<i>x[</i>2<i>m+</i>2,2<i>n</i>]+(1<i>&#x2212;t</i>) &#xd7;<i>u&#xd7;x[</i>2<i>m,</i>2<i>n+</i>2<i>]+t&#xd7;u&#xd7;x[</i>2<i>m+</i>2,2<i>n+</i>2],&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0048" num="0047">where (t,u)=(p/2,q/2); 0&#x2266;p&#x2266;2 and 0&#x2266;q&#x2266;2.</p>
<p id="p-0049" num="0048">A reference image <b>22</b> can be obtained after the interpolation process, wherein the pixel at the top-left corner of the reference image <b>22</b> has a gray level value of x[2m,2n]; the second pixel below the pixel [2m,2n] has a gray level value of x[2 m+p,2n]; the right second pixel of the pixel [2m,2n] has a gray level value of x[2m,2n+q]; and the diagonal second pixel of the pixel [2m,2n] has a gray level value of x[2 m+p,2n+q]. In this embodiment, the reference image <b>22</b> contains a plurality of non-interpolated pixels having gray pixel values identical to the pixels in the first array image <b>21</b> (shown as the blank pixels in <figref idref="DRAWINGS">FIG. 4</figref>, e.g. x[m,n] having a gray pixel value identical to x[2m,2n]), and a plurality of interpolated pixels which are referred to sub-pixels in the present invention (e.g. the pixels filled with oblique lines shown in <figref idref="DRAWINGS">FIG. 4</figref>). The first reference searching block <b>211</b> is converted to the second reference searching block <b>221</b> of 7&#xd7;7 pixels after interpolation and the pixel at the top-left corner of the second reference searching block <b>221</b> is defined as a second reference point <b>222</b> with an initial coordinate [x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>2</sub>,y<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>2</sub>]. It should be noted that, it is only an exemplary embodiment of the present invention to interpolate one sub-pixel between two adjacent pixels. In other embodiments, any number of sub-pixels, rather than one sub-pixel, can be interpolated into two adjacent pixels without departing from the spirit of the present invention.</p>
<p id="p-0050" num="0049">The image capturing unit <b>102</b> captures light reflected from the surface &#x201c;S&#x201d; at a second time to form a second array image <b>23</b> which will then be interpolated by the interpolation unit <b>103</b> to form a comparison image <b>24</b>. Since the interpolation process is identical to the process forming the reference image <b>22</b>, the detailed descriptions will not be illustrated herein. Similarly, the comparison image <b>24</b> contains a plurality of non-interpolated pixels having gray pixel values identical to the pixels in the second array image <b>23</b> (e.g. the blank pixels shown in <figref idref="DRAWINGS">FIG. 4</figref>) and a plurality of interpolated pixels which are referred to sub-pixels in the present invention (e.g. the pixels filled with oblique lines shown in <figref idref="DRAWINGS">FIG. 4</figref>). Then, the processing unit <b>105</b> defines a first searching block <b>231</b> in the second array image <b>23</b> which has the same pixel area as the first reference searching block <b>211</b>, and defines a third reference point <b>232</b> inside the first searching block <b>231</b> with a position corresponding to that of the first reference point <b>212</b> in the first reference searching block <b>211</b>. The processing unit <b>105</b> defines a second searching block <b>241</b> in the comparison image <b>24</b> which has the same pixel area as the second reference searching block <b>221</b>, and defines a fourth reference point <b>242</b> inside the second searching block <b>241</b> with a position corresponding to that of the second reference point <b>222</b> in the second reference searching block <b>221</b>. In should be noted that, the position of the first reference point <b>212</b> inside the first reference searching block <b>211</b>, the position of the second reference point <b>222</b> inside the second reference searching block <b>221</b>, the position of the third reference point <b>232</b> inside the first searching block <b>231</b> and the position of the fourth reference point <b>242</b> inside the second searching block <b>241</b> are not limited to this embodiment, and each reference point can be defined at any position inside the corresponding block.</p>
<p id="p-0051" num="0050">In the description herein, for comparison purpose, the displacement detection based on images without interpolation of conventional method and the displacement detection method based on images with interpolation of the present invention are respectively illustrated. In conventional method, i.e. the displacement detection method based on images without interpolation, the first searching block <b>231</b> successively searches all pixels of the second array image <b>23</b> and simultaneously compares with the first reference searching block <b>211</b>, as shown in <figref idref="DRAWINGS">FIG. 4</figref>. According to the initial coordinate [x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>1</sub>,y<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>1</sub>] of the first reference point <b>212</b>, the searching area of the first searching block <b>231</b> in the second array image <b>23</b> is [x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>1</sub>&#x2212;2, x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>1</sub>+2,y<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>1</sub>+2], i.e. the searching times of the first searching block <b>231</b> in the second array image <b>23</b> and the comparison times of the first searching block <b>231</b> with the first reference searching block are 25 times. The comparison is to calculate a sum of the absolute values of the differences in gray level value between every pixels in the first reference searching block <b>211</b> and the pixels at corresponding positions in the first searching block <b>231</b>. Totally, 25 sums can be obtained and the smallest one of the 25 sums of the absolute values of all the differences is defined as the best matching (optimal), and the displacement will be calculated according to the optimal case. The detailed descriptions will be illustrated in the following paragraphs.</p>
<p id="p-0052" num="0051">However in the present invention, i.e. the displacement detection based on images with interpolation, the second searching block <b>241</b> successively searches all pixels of the comparison image <b>24</b> and simultaneously compares with the second reference searching block <b>221</b>, as shown in <figref idref="DRAWINGS">FIG. 4</figref>. According to the initial coordinate [x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>2</sub>,y<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>2</sub>] of the second reference point <b>222</b>, the searching area of the second searching block <b>241</b> in the comparison image <b>24</b> is [x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>2</sub>&#x2212;4, x<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>2</sub>+4,y<sub>start</sub><sub><sub2>&#x2014;</sub2></sub><sub>2</sub>&#x2212;4,y<sub>start</sub><sub><sub2>&#x2014;</sub2></sub>+4], i.e. the searching times of the second searching block <b>241</b> in the comparison image <b>24</b> and the comparison times of the second searching block <b>241</b> with the second reference searching block are 81 times. The comparison is to calculate a sum of the absolute values of the differences in gray level value between every pixels in the second reference searching block <b>221</b> and the pixels at corresponding positions in the second searching block <b>241</b>. Totally, 81 sums can be obtained and the smallest one of the 81 sums of the absolute values of all the differences is defined as the best matching (optimal), and the displacement will be calculated according to the optimal case. In this manner, the searching area can be increased after interpolation so as to improve the image resolution.</p>
<p id="p-0053" num="0052">Referring to <figref idref="DRAWINGS">FIG. 5</figref>, it shows a flow chart of the method for detecting displacement with sub-pixel accuracy according to one embodiment of the present invention. The method includes the steps of: capturing a plurality of array images (step A<b>1</b>); storing the array images (step <b>2</b>); interpolating (step A<b>3</b>); storing the interpolated images (step A<b>4</b>); searching and comparison (step A<b>5</b>); and calculating a displacement (step A<b>6</b>).</p>
<p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIGS. 5</figref>, <b>6</b> and <b>7</b><i>a </i>and <b>7</b><i>b</i>, the method for detecting displacement with sub-pixel accuracy will be illustrated hereinafter. In this embodiment, the surface &#x201c;S&#x201d; is illuminated by the light source <b>101</b> and a brightness variation with 16 columns is formed thereon as shown in <figref idref="DRAWINGS">FIG. 6</figref>, wherein pixels at each column have identical brightness and an interval between two adjacent columns is identical to one-half of the distance between two adjacent pixels of the sensing array (not shown) of the image capturing unit <b>102</b>. Although the sensing array shown in this embodiment has 8&#xd7;8 pixels, the total pixel number in actual product is determined by the resolution of the sensing array. At first time t<sub>1</sub>, the capturing unit <b>102</b> captures the brightness of even columns on the surface &#x201c;S&#x201d; so as to form a first array image <b>21</b>, as shown in <figref idref="DRAWINGS">FIG. 7</figref><i>a</i>, wherein each circle represents a pixel of the sensing array and the number inside each circle denotes the brightness (gray level value) of that pixel. At second time t<sub>2</sub>, the apparatus <b>1</b> moves leftward, according to <figref idref="DRAWINGS">FIG. 6</figref>, by one column distance (one-half of the distance between two adjacent pixels of the sensing array of the image capturing unit <b>102</b>), and the image capturing unit <b>102</b> captures the brightness of odd columns on the surface &#x201c;S&#x201d; so as to form a second array image <b>23</b>, as shown in <figref idref="DRAWINGS">FIG. 7</figref><i>b </i>(step A<b>1</b>). The first array image <b>21</b> and the second array image <b>23</b> can be stored into the storage unit <b>104</b> first (step A<b>2</b>), or they can be directly interpolated by the interpolation unit <b>103</b> (step A<b>3</b>) and then be stored in the storage unit <b>104</b> (step A<b>4</b>).</p>
<p id="p-0055" num="0054">Referring <figref idref="DRAWINGS">FIGS. 7</figref><i>a</i>, <b>7</b><i>b </i>and <b>8</b><i>a </i>to <b>8</b><i>j</i>, since all pixels in each column of the array image detected by the image capturing unit <b>102</b> have identical brightness, for simplification purpose, only one row, e.g. first row, of the first array image <b>21</b> and the second array image <b>23</b> is taken as an example for illustration. In <figref idref="DRAWINGS">FIG. 8</figref><i>a</i>, upper row denotes the first row <b>213</b> of the first array image <b>21</b>, wherein the rectangle with solid line represents the first reference searching block <b>211</b> of 1&#xd7;4 pixels and the left first pixel is defined as the first reference point <b>212</b>; lower row denotes the interpolated first row <b>223</b> of the reference image <b>22</b> (not shown), wherein the rectangle with dotted line represents the second reference searching block <b>221</b> of 1&#xd7;7 pixels and the left first pixel is defined as the second reference point <b>222</b>. In each figure of <figref idref="DRAWINGS">FIGS. 8</figref><i>b </i>to <b>8</b><i>j</i>, upper row denotes the first row <b>233</b> of the second array image <b>23</b>, wherein the rectangle with solid line represents the first searching block <b>231</b> of 1&#xd7;4 pixels and the left first pixel is defined as the third reference point <b>232</b>, and the first searching block <b>231</b> successively searches all pixels of the first row <b>233</b> of the second array image <b>23</b> (by two columns of brightness each step); lower row denotes the first row <b>243</b> of the interpolated comparison image <b>24</b> (not shown), wherein the rectangle with dotted line represents the second searching block <b>241</b> of 1&#xd7;7 pixels and the left first pixel is defined as the fourth reference point <b>242</b>, and the second searching block <b>241</b> successively searches all pixels of the first row <b>243</b> of the comparison image <b>24</b> (by one column of brightness each step).</p>
<p id="p-0056" num="0055">In conventional method, i.e. without interpolation, the first searching block <b>231</b> successively searches the second array image <b>23</b> and simultaneously compares with the first reference searching block <b>211</b>. During comparison, differences in gray level value between every pixels [0,0,0,0] in the first searching block <b>231</b> and every pixels [0,0,128,128] in the first reference searching block <b>211</b> are calculated, as shown in <figref idref="DRAWINGS">FIG. 8</figref><i>b</i>, and a sum of the absolute values of all the differences is calculated to be 256. Then, successively calculate the sums of the absolute values of all the differences in gray level value between every pixels in the first searching block <b>231</b> of <figref idref="DRAWINGS">FIGS. 8</figref><i>c </i>to <b>8</b><i>f </i>and every pixels [0,0,128,128] in the first reference searching block <b>211</b>, and several sums 192, 64, 64 and 192 can be obtained. The best matching defined by the present invention is the first searching block <b>231</b> having the smallest sum of the absolute values of all the differences; therefore, 2 best matching can be obtained which have a sum of 64 as shown in <figref idref="DRAWINGS">FIGS. 8</figref><i>d </i>and <b>8</b><i>e </i>in the conventional method without interpolation. The displacement is defined as a vector from the first reference point <b>212</b> to the third reference point <b>232</b> shown in <figref idref="DRAWINGS">FIG. 8</figref><i>d</i>, i.e. the apparatus <b>1</b> has no displacement; meanwhile, the displacement is also defined as the vector from the first reference point <b>212</b> to the third reference point <b>232</b> shown in <figref idref="DRAWINGS">FIG. 8</figref><i>e </i>(moving rightward by one column of brightness), i.e. the apparatus <b>1</b> moving leftward by one column of brightness. Accordingly, in conventional method, since the interpolation is not performed, the apparatus <b>1</b> may not be able to correctly estimate the moving direction and the displacement.</p>
<p id="p-0057" num="0056">In the present invention, i.e. with interpolation, the second searching block <b>241</b> successively searches the comparison image <b>24</b> and simultaneously compares with the second reference searching block <b>221</b>. During comparison, differences in gray level value between every pixels [0,0,0,0,0,0,0] in the second searching block <b>241</b> and every pixels [0,0,0,64,128,128,128] in the second reference searching block <b>221</b> are calculated, as shown in <figref idref="DRAWINGS">FIG. 8</figref><i>b</i>, and a sum of the absolute values of all the differences is obtained to be 448. Then, successively calculate the sums of the absolute values of all the differences in gray level value between every pixels in the second searching block <b>241</b> of <figref idref="DRAWINGS">FIGS. 8</figref><i>c </i>to <b>8</b><i>j </i>and every pixels [0,0,0,64,128,128,12] in the second reference searching block <b>221</b>, and several sums 416, 352, 256, 128, 64, 128, 256 and 352 can be obtained. The best matching defined by the present invention is the second searching block <b>241</b> having the smallest sum of the absolute values of all the differences. In this embodiment, since the interpolation is processed firstly and then the displacement is estimated, only one best matching (optimal) can be obtained which has a sum of 64 (<figref idref="DRAWINGS">FIG. 8</figref><i>g</i>). The displacement is defined as the vector from the second reference point <b>222</b> to the fourth reference point <b>242</b> shown in <figref idref="DRAWINGS">FIG. 8</figref><i>g </i>(moving rightward by one column of brightness), i.e. the apparatus <b>1</b> moving leftward by one column of brightness. Accordingly, by processing interpolation, the present invention can accurately estimate the moving direction and displacement of the apparatus <b>1</b> to sub-pixel accuracy level.</p>
<p id="p-0058" num="0057">Referring to <figref idref="DRAWINGS">FIGS. 4</figref>, <b>9</b>, <b>10</b> and <b>10</b><i>a </i>to <b>10</b><i>b</i>, as described above, after interpolation, the second searching block <b>241</b> needs to search 81 times for a 15&#xd7;15 pixels area, as shown in <figref idref="DRAWINGS">FIG. 9</figref>, wherein each fourth reference point <b>242</b> has a corresponding second searching block <b>241</b>. It can be easily seen from <figref idref="DRAWINGS">FIG. 9</figref> that the fourth reference point <b>242</b> needs to search 81 positions. In order to reduce searching and comparison times, the present invention further provides a method for fast detecting displacement with sub-pixel accuracy as shown in <figref idref="DRAWINGS">FIGS. 10</figref>, <b>10</b><i>a </i>and <b>10</b><i>b</i>. The method includes the steps of: capturing a plurality of array images (step B<b>1</b>); storing the array images (step B<b>2</b>); performing the first searching and comparison (step B<b>3</b>); interpolating (step B<b>4</b>); storing the interpolated images (step B<b>5</b>); performing the second searching and comparison (step B<b>6</b>); and finally calculating a displacement (step B<b>7</b>). The differences between <figref idref="DRAWINGS">FIG. 10</figref> and <figref idref="DRAWINGS">FIG. 5</figref> is that, the first searching block <b>231</b> successively searches the second array image <b>23</b> before the captured array images (step B<b>1</b>) are interpolated so as to obtain a first optimal searching block which has a corresponding third reference point <b>232</b> (step B<b>3</b>), e.g. pixel <b>234</b> shown in <figref idref="DRAWINGS">FIG. 10</figref><i>a</i>. This step needs to search and compare for 25 times. Then the second array image <b>23</b> is interpolated (step B<b>4</b>) and the pixel <b>234</b> is converted to the pixel <b>244</b> after interpolation. It can be understood that, in this embodiment, the pixel <b>244</b> is a non-interpolated pixel and thus pixels <b>234</b> and <b>244</b> have identical gray level values or brightness values. Then the fourth reference point <b>242</b> successively searches the pixel <b>244</b> and its adjacent 8 pixels in the comparison image <b>24</b>, and the second searching block <b>241</b> corresponded to the fourth reference point <b>242</b> is compared with the second reference searching block <b>221</b> so as to obtain a second optimal searching block which has a corresponding fourth reference point <b>242</b>, e.g. pixel <b>245</b> shown in <figref idref="DRAWINGS">FIG. 10</figref><i>b</i>. The pixel <b>245</b> is served as the last optimal reference point (step B<b>6</b>), and this step needs to search and compare for 9 times. Accordingly, in this embodiment, it is necessary to search and compare only for totally 25+9=34 times. Finally, calculate a distance between the last optimal searching point (pixel <b>245</b>) and the second reference point <b>222</b> to be served as the displacement (step B<b>7</b>). In this manner, searching and comparison times can be significantly decreased so as to increase the calculating speed of the displacement. In addition, other procedures are similar to that of the method for detecting displacement with sub-pixel accuracy shown in <figref idref="DRAWINGS">FIG. 5</figref> and they will not be described herein in detail.</p>
<p id="p-0059" num="0058">Referring to <figref idref="DRAWINGS">FIGS. 4</figref>, <b>9</b>, <b>11</b>, <b>11</b><i>a </i>and <b>11</b><i>b</i>, they show another method for fast detecting displacement with sub-pixel accuracy of the present invention. The method includes the steps of: capturing a plurality of array images (step C<b>1</b>); interpolating (step C<b>2</b>), storing the interpolated images (step C<b>3</b>); performing the first searching and comparison (step C<b>4</b>); performing the second searching and comparison (step C<b>5</b>); and finally calculating a displacement (step C<b>6</b>). After the image capturing unit <b>102</b> captures the first array image <b>21</b> and the second array image <b>23</b> (step C<b>1</b>), they are directly interpolated by the interpolation unit <b>103</b> so as to form the reference image <b>22</b> and the comparison image <b>24</b> (step C<b>2</b>) which are then stored into the storage unit <b>104</b> (unit C<b>3</b>). The processing unit <b>105</b> defines the second reference searching block <b>221</b> and the second reference point <b>222</b> in the reference image <b>22</b>, and defines the second searching block <b>241</b> and the fourth reference point <b>242</b> in the comparison image <b>24</b> (<figref idref="DRAWINGS">FIG. 4</figref>). Then the processing unit <b>105</b> controls the second searching block <b>241</b> to successively search the comparison image <b>24</b> and compare with the second reference searching block <b>221</b>. In this embodiment, the processing unit <b>105</b> controls the fourth reference point <b>242</b> to search only predetermined positions in the comparison image <b>24</b>, e.g. the positions of circles shown in <figref idref="DRAWINGS">FIG. 11</figref><i>a </i>(the fourth reference point <b>242</b>), and this step needs to search 25 positions, wherein each fourth reference point <b>242</b> has a corresponding second searching block <b>241</b>. Accordingly, it is able to obtain a third optimal searching block which has a corresponding fourth reference point <b>242</b>, e.g. pixel <b>246</b> shown in <figref idref="DRAWINGS">FIG. 11</figref><i>a</i>, and this step needs to search and compare for 25 times (step C<b>4</b>). This is the main difference with respect to the method for detecting displacement with sub-pixel accuracy shown in <figref idref="DRAWINGS">FIG. 5</figref>, i.e. the fourth reference point <b>242</b> searches only the predetermined pixels. Next, the processing unit <b>105</b> controls the fourth reference point <b>242</b> to search only the pixels <b>246</b> and its surrounding un-searched pixels, e.g. adjacent 8 pixels, and the second searching block <b>241</b> corresponded to the fourth reference point <b>242</b> is compared with the second reference searching block <b>221</b> so as to find a fourth optimal searching block which has a corresponding fourth reference point <b>242</b>, e.g. pixel <b>247</b> shown in <figref idref="DRAWINGS">FIG. 11</figref><i>b</i>. The pixel <b>247</b> is served as the last optimal reference point (step C<b>5</b>) and this step needs to search and compare for 9 times. In this embodiment, it is necessary to search and compare only for 25+9=34 times. Finally, calculate a distance between the last optimal searching point (pixel <b>247</b>) and the second reference point <b>222</b> to be served as the displacement (step B<b>7</b>). In this manner, searching and comparison times can also be significantly decreased so as to increase the calculating speed of the displacement. In addition, other procedures are similar to that of the method for detecting displacement with sub-pixel accuracy shown in <figref idref="DRAWINGS">FIG. 5</figref> and they will not be described herein in detail.</p>
<p id="p-0060" num="0059">As mentioned above, in the present disclosure more than one sub-pixels may be interpolated between two pixels in the array images captured by the image capturing unit <b>102</b> so as to improve the accuracy of detecting displacement, e.g. one sub-pixel interpolation has half-pixel accuracy, three sub-pixels interpolation has quarter-pixel accuracy. However, when a number of interpolated sub-pixels is increased, the data amount of storage and calculation is significantly increased at the same time. Therefore, the method of detecting displacement with sub-pixel accuracy of the present disclosure may previously determine a predetermined portion in the array images captured by the image capturing unit <b>102</b> according to at least one previously calculated displacement, e.g. the immediately previous displacement. In other words, in the present disclosure only the predetermined portion of the array images captured by the image capturing unit <b>102</b> will be interpolated by the interpolation unit <b>103</b>.</p>
<p id="p-0061" num="0060">For example please refer to <figref idref="DRAWINGS">FIG. 12</figref>, it shows a schematic diagram of the interpolation used in the method of detecting displacement with sub-pixel accuracy according to an alternative embodiment of the present disclosure. Please refer to <figref idref="DRAWINGS">FIGS. 2</figref>, <b>3</b> and <b>12</b>, in the interpolation process of this embodiment, the image capturing unit <b>102</b> captures light from the surface &#x201c;S&#x201d; at a first time to form a first array image <b>21</b> (e.g. an array image having 8&#xd7;8 pixels), and a central area of the first array image <b>21</b> having 4&#xd7;4 pixels is defined as a first reference searching block <b>211</b> and a pixel at the top-left corner of the first reference searching block <b>211</b> is defined as a first reference point <b>212</b>. The processing unit <b>105</b> determines a first predetermined portion <b>21</b>&#x2032; in the first array image <b>21</b> (e.g. an image area having 6&#xd7;6 pixels) according to previously calculated displacement. The first predetermined portion <b>21</b>&#x2032; is then interpolated by the interpolation unit <b>103</b>, for example, according to equation (1) to interpolate at least one sub-pixel. It is appreciated that all values used in the present embodiment are only exemplary.</p>
<p id="p-0062" num="0061">A reference image <b>22</b>&#x2032; is obtained after the interpolation of the first predetermined portion <b>21</b>&#x2032;. In this embodiment, the reference image <b>22</b>&#x2032; contains a plurality of non-interpolated pixels having gray pixel values identical to those pixels in the first predetermined portion <b>21</b>&#x2032; (blank pixels shown in <figref idref="DRAWINGS">FIG. 12</figref>), and a plurality of interpolated pixels which are referred to the sub-pixels herein (e.g. pixels filled with oblique lines shown in <figref idref="DRAWINGS">FIG. 12</figref>). The first reference searching block <b>211</b> is converted to a second reference searching block <b>221</b> of 7&#xd7;7 pixels after the interpolation and a pixel at the top-left corner of the second reference searching block <b>221</b> is defined as a second reference point <b>222</b>.</p>
<p id="p-0063" num="0062">The image capturing unit <b>102</b> captures light reflected from the surface &#x201c;S&#x201d; at a second time to form a second array image <b>23</b>. The processing unit <b>105</b> determines a second predetermined portion <b>23</b>&#x2032; in the second array image <b>23</b> (e.g. an image area having 6&#xd7;6 pixels) according to previously calculated displacement. The second predetermined portion <b>23</b>&#x2032; is interpolated by the interpolation unit <b>103</b> to form a comparison image <b>24</b>&#x2032;, and the interpolation process is identical to that of forming the reference image <b>22</b>&#x2032;. Similarly, the comparison image <b>24</b>&#x2032; contains a plurality of non-interpolated pixels having gray pixel values identical to those pixels in the second predetermined portion <b>23</b>&#x2032; (e.g. blank pixels shown in <figref idref="DRAWINGS">FIG. 12</figref>), and a plurality of interpolated pixels which are referred to the sub-pixels herein (e.g. pixels filled with oblique lines shown in <figref idref="DRAWINGS">FIG. 12</figref>). The processing unit <b>105</b> defines a first searching block <b>231</b> in the second array image <b>23</b> which has the same pixel area as the first reference searching block <b>211</b>, and defines a third reference point <b>232</b> in the first searching block <b>231</b> with a position corresponding to that of the first reference point <b>212</b> in the first reference searching block <b>211</b>. The processing unit <b>105</b> further defines a second searching block <b>241</b> in the comparison image <b>24</b>&#x2032; which has the same pixel area as the second reference searching block <b>221</b>, and defines a fourth reference point <b>242</b> in the second searching block <b>241</b> with a position corresponding to that of the second reference point <b>222</b> in the second reference searching block <b>221</b>. It should be noted that, the position of the first reference point <b>212</b> in the first reference searching block <b>211</b>, the position of the second reference point <b>222</b> in the second reference searching block <b>221</b>, the position of the third reference point <b>232</b> in the first searching block <b>231</b> and the position of the fourth reference point <b>242</b> in the second searching block <b>241</b> are not limited to this embodiment, and each reference point may be any point inside its corresponding block.</p>
<p id="p-0064" num="0063">In other words, the difference between this embodiment and <figref idref="DRAWINGS">FIG. 4</figref> is that a predetermined portion in the associated array image is previously determined according to previously calculated displacement. In this manner, when the number of sub-pixels interpolated between two pixels in the array images captured by the image capturing unit <b>102</b> is increased, it is able to effectively decrease the data amount of storage and calculation and to improve the accuracy of detecting displacement.</p>
<p id="p-0065" num="0064">Please refer to <figref idref="DRAWINGS">FIG. 13</figref>, it shows a flow chart of the method of detecting displacement with sub-pixel accuracy according to an alternative embodiment of the present disclosure. The method includes the steps of: capturing a plurality of array images (Step A<b>1</b>); storing the plurality of array images (Step A<b>2</b>); determining a predetermined portion in the array images respectively (Step A<b>21</b>); interpolating the predetermined portions (Step A<b>3</b>); storing the interpolated images (Step A<b>4</b>); searching and comparison (Step A<b>5</b>); and calculating a displacement (Step A<b>6</b>). Details of this embodiment are similar to those of <figref idref="DRAWINGS">FIG. 5</figref> and associated illustrations but different from that in this embodiment only the previously determined predetermined portion of the array images are interpolated in the interpolation process rather than the whole array images.</p>
<p id="p-0066" num="0065">Similarly, in the embodiments related to <figref idref="DRAWINGS">FIGS. 10 and 11</figref>, it is also able to previously select a predetermined portion in the array images according to previously calculated displacement and to interpolate only the predetermined portion so as to effectively decrease the data amount of storage and calculation. For example, in the Step B<b>4</b> of <figref idref="DRAWINGS">FIG. 10</figref> only a predetermined portion of the first array image <b>21</b> and the second array image <b>23</b> (e.g. the first predetermined portion <b>21</b>&#x2032; and the second predetermined portion <b>23</b>&#x2032;) is respectively interpolated instead of the whole first array image <b>21</b> and second array image <b>23</b>. Similarly, in the Step C<b>2</b> of <figref idref="DRAWINGS">FIG. 13</figref> only a predetermined portion of the first array image <b>21</b> and a predetermined portion of the second array image <b>23</b> (e.g. the first predetermined portion <b>21</b>&#x2032; and the second predetermined portion <b>23</b>&#x2032;) are interpolated respectively instead of the whole first array image <b>21</b> and second array image <b>23</b>. Since this alternative embodiment differs from <figref idref="DRAWINGS">FIGS. 10 and 11</figref> only in the step of interpolating and is similar thereto in other steps, details of other steps will not be repeated herein.</p>
<p id="p-0067" num="0066">In an alternative embodiment, the image arrays captured by the image capturing unit <b>102</b> may be filtered at first and then be interpolated by the interpolation unit <b>103</b> to form the reference image and the comparison image respectively. Next, the filtered reference image and comparison image are quantized as a quantized reference image in which each pixel has one of at least two values and a quantized comparison image, and finally the displacement of the optical navigation device with respect to the surface &#x201c;S&#x201d; may be obtained according to the digitized reference image and the digitized comparison image.</p>
<p id="p-0068" num="0067">As described above, since the conventional method calculating movement based on Taylor Expansion has larger error when the movement becomes larger, it has the problem of unable to estimate the movement correctly. The method and apparatus for detecting displacement with sub-pixel accuracy of the present can increase the searching area by means of interpolation and improve the image resolution.</p>
<p id="p-0069" num="0068">Although the invention has been explained in relation to its preferred embodiment, it is not used to limit the invention. It is to be understood that many other possible modifications and variations can be made by those skilled in the art without departing from the spirit and scope of the invention as hereinafter claimed.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of detecting displacement with sub-pixel accuracy for detecting a displacement of an optical navigation device with respect to a surface on which the optical navigation device is disposed, the optical navigation device comprising an image capturing unit, an interpolation unit and a processing unit, the method comprising:
<claim-text>moving the optical navigation device on the surface and capturing a first array image and a second array image with the image capturing unit;</claim-text>
<claim-text>interpolating a first predetermined portion of the first array image to form a reference image with the interpolation unit;</claim-text>
<claim-text>interpolating a second predetermined portion of the second array image to form a comparison image with the interpolation unit; and</claim-text>
<claim-text>comparing the reference image with the comparison image by using the processing unit so as to obtain the displacement of the optical navigation device with respect to the surface.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the interpolating process is implemented according to the following equation:
<claim-text>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>x[</i>2<i>m+p,</i>2<i>n+q</i>]=(1&#x2212;<i>t</i>)&#xd7;(1&#x2212;<i>u</i>)&#xd7;<i>x[</i>2<i>m,</i>2<i>n]+t</i>&#xd7;(1&#x2212;<i>u</i>)&#xd7;<i>x</i>[2<i>m+</i>2,2<i>n</i>]+(1&#x2212;<i>t</i>)&#xd7;<i>u&#xd7;x[</i>2<i>m,</i>2<i>n+</i>2<i>]+t&#xd7;u&#xd7;x[</i>2<i>m+</i>2,2<i>n+</i>2],<?in-line-formulae description="In-line Formulae" end="tail"?>
</claim-text>
<claim-text>where (t,u)=(p/2,q/2); 0&#x2266;p&#x2266;2 and 0&#x2266;q&#x2266;2;</claim-text>
<claim-text>wherein [m,n] is the pixel coordinate of the first array image and the second array image before the interpolating process; [2 m+p,2n+q] is the interpolated pixel coordinate of the reference image and the comparison image after the interpolating process; x[2m+p,2n+q], x[2m,2n], x[2m+2,2n], x[2m,2n+2] and x[2m+2,2n+2] are gray level values or brightness values of corresponding pixel coordinates.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of comparing the reference image with the comparison image by using the processing unit further comprises:
<claim-text>defining a reference searching block and a second reference point in the reference image, wherein the reference searching block has a predetermined pixel area and the second reference point is a pixel inside the predetermined pixel area;</claim-text>
<claim-text>defining a searching block and a fourth reference point in the comparison image, wherein the searching block has the same pixel area as the reference searching block and a position of the fourth reference point in the searching block corresponds to that of the second reference point in the reference searching block;</claim-text>
<claim-text>successively searching all pixels of the comparison image with the searching block and simultaneously comparing the searching block with the reference searching block so as to obtain an optimal searching block; and</claim-text>
<claim-text>calculating a distance between the fourth reference point of the optimal searching block and the second reference point to be served as the displacement.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein said comparing the searching block with the reference searching block is to calculate differences in gray level value between every pixels in the searching block and the pixels at corresponding positions in the reference searching block, and to calculate a sum of the absolute values of all the differences.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the optimal searching block is the searching block having the smallest sum of the absolute values of all the differences when comparing the searching block with the reference searching block.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A method of detecting displacement with sub-pixel accuracy for detecting a displacement of an optical navigation device with respect to a surface on which the optical navigation device is disposed, the optical navigation device comprising an image capturing unit, an interpolation unit and a processing unit, the method comprising:
<claim-text>moving the optical navigation device on the surface and capturing a first array image and a second array image with the image capturing unit;</claim-text>
<claim-text>performing a first searching and comparison in the second array image by using the processing unit;</claim-text>
<claim-text>interpolating a first predetermined portion of the first array image to form a reference image with the interpolation unit;</claim-text>
<claim-text>interpolating a second predetermined portion of the second array image to form a comparison image with the interpolation unit;</claim-text>
<claim-text>performing a second searching and comparison in the comparison image by using the processing unit; and</claim-text>
<claim-text>calculating the displacement of the optical navigation device with respect to the surface by using the processing unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the step of performing a first searching and comparison in the second array image by using the processing unit further comprises:
<claim-text>defining a first reference searching block and a first reference point in the first array image, wherein the first reference searching block has a predetermined pixel area and the first reference point is a pixel in the predetermined pixel area;</claim-text>
<claim-text>defining a first searching block and a third reference point in the second array image, wherein the first searching block has the same pixel area as the first reference searching block and a position of the third reference point in the first searching block corresponds to that of the first reference point in the first reference searching block; and</claim-text>
<claim-text>successively searching all pixels of the second array image with the first searching block and simultaneously comparing the first searching block with the first reference searching block so as to obtain a first optimal searching block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein said comparing the first searching block with the first reference searching block is to calculate differences in gray level value between every pixels in the first searching block and the pixels at corresponding positions in the first reference searching block, and to calculate a sum of the absolute values of all the differences.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first optimal searching block is the first searching block having the smallest sum of the absolute values of all the differences when comparing the first searching block with the first reference searching block.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the step of performing a second searching and comparison in the comparison image by using the processing unit further comprises:
<claim-text>defining a second reference searching block and a second reference point in the reference image, wherein the second reference searching block has a predetermined pixel area and the second reference point is a pixel inside the predetermined pixel area;</claim-text>
<claim-text>defining a second searching block and a fourth reference point in the comparison image, wherein the second searching block has the same pixel area as the second reference searching block and a position of the fourth reference point in the second searching block corresponds to that of the second reference point in the second reference searching block; and</claim-text>
<claim-text>successively searching the third reference point and a predetermined searching area surrounding the third reference point in the first optimal searching block with the fourth reference point, and simultaneously comparing the second searching block corresponded to the fourth reference point with the second reference searching block so as to obtain a second optimal searching block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the method to compare the second searching block with the second reference searching block is to calculate differences in gray level value between every pixels in the second searching block and the pixels at corresponding positions in the second reference searching block, and to calculate a sum of the absolute values of all the differences.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the second optimal searching block is the second searching block having the smallest sum of the absolute values of all the differences when comparing the second searching block with the second reference searching block.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the method to calculate the displacement by using the processing unit is to calculate a distance between the fourth reference point of the second optimal searching block and the second reference point.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the predetermined searching area comprises the pixels surrounding the third reference point of the first optimal searching block in the comparison image.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A method of detecting displacement with sub-pixel accuracy for detecting a displacement of an optical navigation device with respect to a surface on which the optical navigation device is disposed, the optical navigation device comprising an image capturing unit, an interpolation unit and a processing unit, the method comprising:
<claim-text>moving the optical navigation device on the surface and capturing a first array image and a second array image with the image capturing unit;</claim-text>
<claim-text>interpolating a first predetermined portion of the first array image to form a reference image with the interpolation unit;</claim-text>
<claim-text>interpolating a second predetermined portion of the second array image to form a comparison image with the interpolation unit;</claim-text>
<claim-text>performing a first searching and comparison in the comparison image by using the processing unit;</claim-text>
<claim-text>performing a second searching and comparison in the comparison image by using the processing unit; and</claim-text>
<claim-text>calculating the displacement of the optical navigation device with respect to the surface by using the processing unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the step of performing a first searching and comparison in the comparison image by using the processing unit further comprises:
<claim-text>defining a reference searching block and a second reference point in the reference image, wherein the reference searching block has a predetermined pixel area and the second reference point is a pixel inside the predetermined pixel area;</claim-text>
<claim-text>defining a searching block and a fourth reference point in the comparison image, wherein the searching block has the same pixel area as the reference searching block and a position of the fourth reference point in the searching block corresponds to that of the second reference point in the reference searching block; and</claim-text>
<claim-text>successively searching predetermined pixels in the comparison image with the fourth reference point and simultaneously comparing the searching block corresponded to the fourth reference point with the reference searching block so as to obtain a first optimal searching block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the method to compare the searching block with the reference searching block is to calculate differences in gray level value between every pixels in the searching block and the pixels at corresponding positions in the reference searching block, and to calculate a sum of the absolute values of all the differences.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the first optimal searching block is the searching block having the smallest sum of the absolute values of all the differences when comparing the searching block with the reference searching block.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the step of performing a second searching and comparison further comprises:
<claim-text>successively searching the fourth reference point and a predetermined searching area surrounding the fourth reference point in the first optimal searching block with the fourth reference point, and simultaneously comparing the searching block corresponded to the fourth reference point with the reference searching block so as to obtain a second optimal searching block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein said comparing the searching block with the reference searching block is to calculate differences in gray level value between every pixels in the searching block and the pixels at corresponding positions in the reference searching block, and to calculate a sum of the absolute values of all the differences.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the second optimal searching block is the searching block having the smallest sum of the absolute values of all the differences when comparing the searching block with the reference searching block.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the method to calculate the displacement by using the processing unit is to calculate a distance between the fourth reference point of the second optimal searching block and the second reference point.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of detecting displacement with sub-pixel accuracy as claimed in <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the predetermined searching area comprises the unsearched pixels adjacent to the fourth reference point of the first optimal searching block in the comparison image.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. An optical navigation device for detecting displacement with sub-pixel accuracy, comprising:
<claim-text>an imaging capturing unit for capturing a first array image and a second array image of a surface on which the optical navigation device is moving;</claim-text>
<claim-text>an interpolation unit for interpolating a predetermined portion of the first array image and the second array image to respectively form a reference image and a comparison image;</claim-text>
<claim-text>a storage unit for storing the first array image, the second array image, the reference image and the comparison image; and</claim-text>
<claim-text>a processing unit for comparing the first array image with the second array image, and/or comparing the reference image with the comparison image so as to obtain a displacement of the optical navigation device with respect to the surface,
<claim-text>wherein the processing unit is configured to</claim-text>
<claim-text>define a first reference searching block in the first array image and define a first searching block in the second array image, and then</claim-text>
<claim-text>successively search all pixels in the second array image with the first searching block and compare the first reference searching block with the first searching block so as to obtain a smallest sum of absolute values of all the differences in gray level value between every pixels in the first searching block and the pixels at corresponding positions in the first reference searching block to obtain the displacement, and/or is configured to</claim-text>
<claim-text>define a second reference searching block in the reference image and define a second searching block in the comparison image, and then successively</claim-text>
<claim-text>search all pixels in the comparison image with the second searching block and compare the second reference searching block with the second searching block so as to obtain a smallest sum of absolute values of all the differences in gray level value between every pixels in the second searching block and the pixels at corresponding positions in the second reference searching block to obtain the displacement. </claim-text>
</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
