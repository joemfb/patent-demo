<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626515-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626515</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12295451</doc-number>
<date>20070330</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1176</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>L</subclass>
<main-group>19</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>704500</main-classification>
</classification-national>
<invention-title id="d2e53">Apparatus for processing media signal and method thereof</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5166685</doc-number>
<kind>A</kind>
<name>Campbell et al.</name>
<date>19921100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5524054</doc-number>
<kind>A</kind>
<name>Spille et al</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5579396</doc-number>
<kind>A</kind>
<name>Iida et al.</name>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5632005</doc-number>
<kind>A</kind>
<name>Davis et al.</name>
<date>19970500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5703584</doc-number>
<kind>A</kind>
<name>Hill, et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6118875</doc-number>
<kind>A</kind>
<name>M&#xf8;ller et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6307941</doc-number>
<kind>B1</kind>
<name>Tanner et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6574339</doc-number>
<kind>B1</kind>
<name>Kim</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6711266</doc-number>
<kind>B1</kind>
<name>Aylward</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6973130</doc-number>
<kind>B1</kind>
<name>Wee et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7555434</doc-number>
<kind>B2</kind>
<name>Nomura et al.</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7916873</doc-number>
<kind>B2</kind>
<name>Villemoes et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381 22</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>7974713</doc-number>
<kind>B2</kind>
<name>Disch et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>700 94</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>8054981</doc-number>
<kind>B2</kind>
<name>Roden et al.</name>
<date>20111100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381 23</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2003/0236583</doc-number>
<kind>A1</kind>
<name>Baumgarte et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2004/0071445</doc-number>
<kind>A1</kind>
<name>Tarnoff et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2004/0196770</doc-number>
<kind>A1</kind>
<name>Touyama et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2005/0074127</doc-number>
<kind>A1</kind>
<name>Herre et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2005/0180579</doc-number>
<kind>A1</kind>
<name>Baumgarte et al.</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2005/0195981</doc-number>
<kind>A1</kind>
<name>Faller et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2006/0115100</doc-number>
<kind>A1</kind>
<name>Faller et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2006/0133618</doc-number>
<kind>A1</kind>
<name>Villemoes et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2006/0153408</doc-number>
<kind>A1</kind>
<name>Faller et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2007/0055510</doc-number>
<kind>A1</kind>
<name>Hilpert et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704230</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>CN</country>
<doc-number>1669359</doc-number>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>EP</country>
<doc-number>1455345</doc-number>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>JP</country>
<doc-number>09-275544</doc-number>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>JP</country>
<doc-number>2001-188578</doc-number>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>JP</country>
<doc-number>2005-533426</doc-number>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>JP</country>
<doc-number>08-065169</doc-number>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>JP</country>
<doc-number>08-202397</doc-number>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>KR</country>
<doc-number>10-2001-0001993</doc-number>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>KR</country>
<doc-number>10-2001-0009258</doc-number>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>RU</country>
<doc-number>2119259</doc-number>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>RU</country>
<doc-number>2129336</doc-number>
<date>19990400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>TW</country>
<doc-number>289885</doc-number>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>TW</country>
<doc-number>550541</doc-number>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>TW</country>
<doc-number>200304120</doc-number>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>TW</country>
<doc-number>200405673</doc-number>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>TW</country>
<doc-number>594675</doc-number>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>WO</country>
<doc-number>9949574</doc-number>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>WO</country>
<doc-number>WO 03/007656</doc-number>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>WO</country>
<doc-number>2003-090208</doc-number>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00044">
<document-id>
<country>WO</country>
<doc-number>2004-008805</doc-number>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00045">
<document-id>
<country>WO</country>
<doc-number>2004-019656</doc-number>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00046">
<document-id>
<country>WO</country>
<doc-number>2004-036549</doc-number>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00047">
<document-id>
<country>WO</country>
<doc-number>2004-036954</doc-number>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00048">
<document-id>
<country>WO</country>
<doc-number>2004-036955</doc-number>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00049">
<document-id>
<country>WO</country>
<doc-number>2004036548</doc-number>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00050">
<document-id>
<country>WO</country>
<doc-number>W02007058510</doc-number>
<kind>A1</kind>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>European Office Action for Application No. 07745723.2 dated Mar. 2, 2010, 9 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00052">
<othercit>Taiwan Patent Office, Office Action in Taiwanese patent application 096102410, dated Jul. 2, 2009, 5 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00053">
<othercit>Russian Notice of Allowance for Application No. 2008114388, dated Aug. 24, 2009, 13 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>Taiwan Examiner, Taiwanese Office Action for Application No. 96104544, dated Oct. 9, 2009, 13 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>Breebaart, et al.: &#x201c;Multi-Channel Goes Mobile: MPEG Surround Binaural Rendering&#x201d; In: Audio Engineering Society the 29th International Conference, Seoul, Sep. 2-4, 2006, pp. 1-13. See the abstract, pp. 1-4, figures 5,6.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00056">
<othercit>Breebaart, J., et al.: &#x201c;MPEG Spatial Audio Coding/MPEG Surround: Overview and Current Status&#x201d; In: Audio Engineering Society the 119th Convention, New York, Oct. 7-10, 2005, pp. 1-17. See pp. 4-6.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00057">
<othercit>Faller, C., et al.: &#x201c;Binaural Cue Coding-Part II: Schemes and Applications&#x201d;, IEEE Transactions on Speech and Audio Processing, vol. 11, No. 6, 2003, 12 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00058">
<othercit>Faller, C.: &#x201c;Coding of Spatial Audio Compatible with Different Playback Formats&#x201d;, Audio Engineering Society Convention Paper, Presented at 117th Convention, Oct. 28-31, 2004, San Francisco, CA.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00059">
<othercit>Faller, C.: &#x201c;Parametric Coding of Spatial Audio&#x201d;, Proc. of the 7th Int. Conference on Digital Audio Effects, Naples, Italy, 2004, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00060">
<othercit>Herre, J., et al.: &#x201c;Spatial Audio Coding: Next generation efficient and compatible coding of multi-channel audio&#x201d;, Audio Engineering Society Convention Paper, San Francisco, CA , 2004, 13 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00061">
<othercit>Herre, J., et al.: &#x201c;The Reference Model Architecture for MPEG Spatial Audio Coding&#x201d;, Audio Engineering Society Convention Paper 6447, 2005, Barcelona, Spain, 13 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00062">
<othercit>International Search Report in International Application No. PCT/KR2006/000345, dated Apr. 19, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00063">
<othercit>International Search Report in International Application No. PCT/KR2006/000346, dated Apr. 18, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00064">
<othercit>International Search Report in International Application No. PCT/KR2006/000347, dated Apr. 17, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00065">
<othercit>International Search Report in International Application No. PCT/KR2006/000866, dated Apr. 30, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00066">
<othercit>International Search Report in International Application No. PCT/KR2006/000867, dated Apr. 30, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00067">
<othercit>International Search Report in International Application No. PCT/KR2006/000868, dated Apr. 30, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00068">
<othercit>International Search Report in International Application No. PCT/KR2006/001987, dated Nov. 24, 2006, 2 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00069">
<othercit>International Search Report in International Application No. PCT/KR2006/002016, dated Oct. 16, 2006, 2 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00070">
<othercit>International Search Report in International Application No. PCT/KR2006/003659, dated Jan. 9, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00071">
<othercit>International Search Report in International Application No. PCT/KR2006/003661, dated Jan. 11, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00072">
<othercit>International Search Report in International Application No. PCT/KR2007/000340, dated May 4, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00073">
<othercit>International Search Report in International Application No. PCT/KR2007/000668, dated Jun. 11, 2007, 2 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00074">
<othercit>International Search Report in International Application No. PCT/KR2007/000672, dated Jun. 11, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00075">
<othercit>International Search Report in International Application No. PCT/KR2007/000675, dated Jun. 8, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00076">
<othercit>International Search Report in International Application No. PCT/KR2007/000676, dated Jun. 8, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00077">
<othercit>International Search Report in International Application No. PCT/KR2007/000730, dated Jun. 12, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00078">
<othercit>International Search Report in International Application No. PCT/KR2007/001560, dated Jul. 20, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00079">
<othercit>International Search Report in International Application No. PCT/KR2007/001602, dated Jul. 23, 2007, 1 page.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00080">
<othercit>Scheirer, E. D., et al.: &#x201c;AudioBIFS: Describing Audio Scenes with the MPEG-4 Multimedia Standard&#x201d;, IEEE Transactions on Multimedia, Sep. 1999, vol. 1, No. 3, pp. 237-250. See the abstract.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00081">
<othercit>Vannanen, R., et al.: &#x201c;Encoding and Rendering of Perceptual Sound Scenes in the Carrouso Project&#x201d;, AES 22nd International Conference on Virtual, Synthetic and Entertainment Audio, Paris, France, 9 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00082">
<othercit>Vannanen, Riitta, &#x201c;User Interaction and Authoring of 3D Sound Scenes in the Carrouso EU project&#x201d;, Audio Engineering Society Convention Paper 5764, Amsterdam, The Netherlands, 2003, 9 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00083">
<othercit>Faller and Baumgarte, &#x201c;Efficient Representation of Spatial Audio using Perceptual Parametrization,&#x201d; <i>Proceedings of the 2001 IEEE Workshop on the Applications of Signal Processing to Audio and Acoustics</i>, 2001, 4 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>13</number-of-claims>
<us-exemplary-claim>13</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>704500</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60787516</doc-number>
<date>20060331</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60787172</doc-number>
<date>20060330</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090164227</doc-number>
<kind>A1</kind>
<date>20090625</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Oh</last-name>
<first-name>Hyen O</first-name>
<address>
<city>Gyeonggi-do</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Pang</last-name>
<first-name>Hee Suk</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Dong Soo</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lim</last-name>
<first-name>Jae Hyun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Jung</last-name>
<first-name>Yang Won</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Oh</last-name>
<first-name>Hyen O</first-name>
<address>
<city>Gyeonggi-do</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Pang</last-name>
<first-name>Hee Suk</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Dong Soo</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Lim</last-name>
<first-name>Jae Hyun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Jung</last-name>
<first-name>Yang Won</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Fish &#x26; Richardson P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>LG Electronics Inc.</orgname>
<role>03</role>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Jackson</last-name>
<first-name>Jakieda</first-name>
<department>2657</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/KR2007/001560</doc-number>
<kind>00</kind>
<date>20070330</date>
</document-id>
<us-371c124-date>
<date>20081024</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2007/114594</doc-number>
<kind>A </kind>
<date>20071011</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The present invention relates to an apparatus for processing a media signal and method thereof. A method of processing a media signal according to the present invention includes extracting a downmix signal from a bitstream, extracting at least one of first spatial information and second spatial information from the bitstream, and generating multi-channels using the extracted spatial information and the downmix signal. And, the present invention provides a decoding method and apparatus for generating various kinds of multi-channels.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="141.56mm" wi="235.88mm" file="US08626515-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="210.90mm" wi="112.86mm" orientation="landscape" file="US08626515-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="223.01mm" wi="114.81mm" orientation="landscape" file="US08626515-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="222.76mm" wi="142.24mm" orientation="landscape" file="US08626515-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="234.87mm" wi="152.15mm" orientation="landscape" file="US08626515-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="224.37mm" wi="120.14mm" orientation="landscape" file="US08626515-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="192.45mm" wi="140.46mm" orientation="landscape" file="US08626515-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="190.58mm" wi="137.08mm" orientation="landscape" file="US08626515-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to an apparatus for processing a media signal and method thereof.</p>
<heading id="h-0002" level="1">BACKGROUND ART</heading>
<p id="p-0003" num="0002">In the present invention, media signals include an audio signal and a video signal. And, the audio signal is explained as an example in the following description.</p>
<p id="p-0004" num="0003">Currently, 2-channel signal is most frequently generated and user. Yet, the use of multi-channel signals gradually increases. In the /following description, an audio signal including at least three channels is called a multi-channel signal to be discriminated from the 2-channel signal. In general, an encoder compresses a multi-channel signal into a mono- or stereo-type downmix signal instead of compressing channels of the multi-channel signal individually. A downmixing unit of the encoder extracts spatial information by downmixing multi-channels. The encoder transfers the compressed downmix signal and the spatial information to a decoder or stores them in a storage medium. The spatial information is used in reconstructing an original multi-channel signal from the compressed downmix signal. In case of using an encoder and decoder for 2-channel signal compression and reconstruction, the encoder generates a downmix signal and spatial information from a 2-channel signal and then transfers a bitstream including them to the decoder. The decoder upmixes the transferred bitstream to generate the original 2-channel signal. In case that the encoder and decoder are used for compression and reconstruction of a multi-channel signal, the encoder generates a downmix signal and spatial information from the multi-channel signal and then transfers a bitstream including the downmix signal and spatial information to the decoder. The decoder then upmixes the transferred bitstream to generate the original multi-channel signal.</p>
<heading id="h-0003" level="1">DISCLOSURE OF THE INVENTION</heading>
<heading id="h-0004" level="1">Technical Objects</heading>
<p id="p-0005" num="0004">Accordingly, the present invention is directed to an apparatus for processing a media signal and method thereof that substantially obviate one or more of the problems due to limitations and disadvantages of the related art.</p>
<p id="p-0006" num="0005">An object of the present invention is to provide an encoding method and apparatus, by which spatial information for audio signal reconstruction having an audio quality close to an audio signal prior to downmixing can be generated.</p>
<p id="p-0007" num="0006">Another object of the present invention is to provide an encoding method and apparatus, by which a bitstream including both spatial information used in generating a 2-channel signal and spatial information used in generating a multi-channel signal can be provided and generated.</p>
<p id="p-0008" num="0007">Another object of the present invention is to provide a decoding method and apparatus, by which a 2-channel signal or a multi-channel signal can be selectively generated.</p>
<heading id="h-0005" level="1">Technical Solution</heading>
<p id="p-0009" num="0008">The present invention extracts a downmix signal from a bitstream and also extracts at least one of first spatial information and second spatial information from the bitstream. And, the present invention provides a method and apparatus for generating specific multi-channels using the extracted spatial information and the extracted downmix signal.</p>
<heading id="h-0006" level="1">Advantageous Effects</heading>
<p id="p-0010" num="0009">The present invention can provide an encoding method and apparatus for generating spatial information to reconstruct an audio signal having an audio quality close to a former audio signal prior to downmixing.</p>
<p id="p-0011" num="0010">The present invention can provide a bitstream including both spatial information used in generating a 2-channel signal and spatial information used in generating a multi-channel signal. And, the present invention can provide an encoding method and apparatus for generating the bitstream.</p>
<p id="p-0012" num="0011">And, the present invention can provide a decoding method and apparatus capable of generating a 2-channel signal or a multi-channel signal selectively.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0007" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a first encoding apparatus according to one embodiment of the present invention.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a second encoding apparatus according to another embodiment of the present invention.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a third encoding apparatus for generating spatial information using a decoded downmix signal according to one embodiment of the present invention.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of a fourth encoding apparatus for generating spatial information using a decoded downmix signal according to another embodiment of the present invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram of a bitstream of an audio signal according to one embodiment of the present invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram of a first decoding apparatus according to one embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram of a second encoding apparatus according to another embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0008" level="1">BEST MODE FOR CARRYING OUT THE INVENTION</heading>
<p id="p-0020" num="0019">To achieve these and other advantages and in accordance with the purpose of the present invention, as embodied and broadly described, a method of processing a media signal includes extracting a downmix signal from a bitstream, extracting at least one of first spatial information and second spatial information from the bitstream, and generating multi-channels using the extracted spatial information and the downmix signal.</p>
<p id="p-0021" num="0020">To further achieve these and other advantages and in accordance with the purpose of the present invention, a method of processing a media signal includes generating a first downmix signal from multi-channels, generating a second downmix signal from the first downmix signal, generating first spatial information using the multi-channels and the first downmix signal or the multi-channels and the second downmix signal, generating second spatial information using the first downmix signal and the second downmix signal, and generating a bitstream including the first spatial information and the second spatial information.</p>
<p id="p-0022" num="0021">To further achieve these and other advantages and in accordance with the purpose of the present invention, a method of processing a media signal includes generating a first downmix signal from multi-channels, generating a second downmix signal from the first downmix signal, encoding the second downmix signal, decoding the encoded second downmix signal, generating second spatial information using the first downmix signal and the decoded second downmix signal, and generating first spatial information using the multi-channels and the decoded second downmix signal.</p>
<p id="p-0023" num="0022">To further achieve these and other advantages and in accordance with the purpose of the present invention, a method of processing a media signal includes generating a first downmix signal from multi-channels, generating a second downmix signal from the first downmix signal, encoding the second downmix signal, decoding the encoded second downmix signal, generating second spatial information using the first downmix signal and the decoded second downmix signal, generating a modified first downmix signal using the decoded second downmix signal and the second spatial information, and generating first spatial information using the modified first downmix signal and the multi-channels.</p>
<p id="p-0024" num="0023">To further achieve these and other advantages and in accordance with the purpose of the present invention, an apparatus for processing a signal includes a downmix signal extracting unit extracting a downmix signal from a bitstream, an information extracting unit extracting at least one of second spatial information for generating two channels from the downmix signal and first spatial information for generating at least three channels from the downmix signal from the bitstream, and a channel generating unit generating either the two channels or the at least three channels using the extracted information and the downmix signal.</p>
<p id="p-0025" num="0024">To further achieve these and other advantages and in accordance with the purpose of the present invention, a bitstream structure includes first spatial information extracted in the course of generating a first downmix signal including at least two channels from multi-channels and second spatial information extracted in the course of generating a second downmix signal from the first downmix signal.</p>
<p id="p-0026" num="0025">To further achieve these and other advantages and in accordance with the purpose of the present invention, a storage medium including the bitstream structure.</p>
<p id="p-0027" num="0026">To further achieve these and other advantages and in accordance with the purpose of the present invention, a signal processing apparatus includes a first downmixing unit generating a first downmix signal from multi-channels, a second downmixing unit generating a second downmix signal from the first downmix signal, a first spatial information generating unit generating first spatial information using the multi-channels and the first downmix signal or the multi-channels and the second downmix signal, a second spatial information generating unit generating second spatial information using the first downmix signal and the second downmix signal, and a multiplexing unit generating a bitstream including the first spatial information and the second spatial information.</p>
<p id="p-0028" num="0027">To further achieve these and other advantages and in accordance with the purpose of the present invention, a signal processing apparatus includes a downmixing unit generating a downmix signal from multi-channels, an encoding unit encoding the downmix signal, a decoding unit decoding the encoded downmix signal, and a spatial information generating unit generating spatial information using the multi-channels and the decoded downmix signal.</p>
<heading id="h-0009" level="1">Mode for Invention</heading>
<p id="p-0029" num="0028">Reference will now be made in detail to the preferred embodiments of the present invention, examples of which are illustrated in the accompanying drawings. For facilitation in understanding the present invention, an audio signal encoding method and apparatus are explained prior to an audio signal decoding method and apparatus. Yet, the decoding method and apparatus according to the present invention are not limited by an encoding method and apparatus that will be explained in the following description. And, the present invention is applied to a coding scheme for generating two channels using spatial information and a coding scheme for generating multi-channels using spatial information as well as MP3 (MPEG 1/2-layer III) and AAC (advanced audio coding).</p>
<p id="p-0030" num="0029">An encoding apparatus for compressing a 2-channel signal receives the 2-channel signal, downmixes the received signal into a moo signal, and extracts spatial information indicating a relation with the 2-channel signal. An encoding apparatus for compressing a multi-channel signal downmixes the multi-channel signal into one or two audio signals and extract information indicating a relation with the multi-channel signal. An encoding apparatus is cable to generates a 2-channel signal by downmixing a multi-channel signal or generates a mono signal by downmixing the 2-channel signal again. In this case, the encoding apparatus extracts spatial information from the relation between the multi-channel signal and the 2-channel signal in downmixing the multi-channel signal into the 2-channel signal or extracts spatial information from the relation between the 2-channel signal and the mono signal in downmixing the 2-channel signal into the mono signal. An encoding apparatus is able to separately transfer spatial information for reconstructing 2-channel signal and spatial information for reconstructing multi-channel signal to a decoding apparatus. Alternatively, the encoding apparatus generates a bitstream including spatial information for reconstructing 2-channel signal and spatial information for reconstructing multi-channel signal and then transfer the bitstream to the decoding apparatus. In case that a signal the decoding apparatus is able to generate is either the 2-channel signal or the multi-channel signal, the decoding apparatus having received the bitstream including the spatial information for reconstructing the 2-channel signal and the spatial information for reconstructing the multi-channel signal extracts the spatial information for reconstruct the generatable channel signal from the bitstream only and is then able to reconstruct the channel signal using the extracted spatial information. In case that the decoding apparatus is capable of reconstruct both of the 2-channel signal and the multi-channel signal, the decoding apparatus extracts spatial information required for generating a channel signal selected by a user from the bitstream only and is then able to generate the channel signal selected by the user using the extracted spatial information.</p>
<p id="p-0031" num="0030">An encoding method and apparatus for generating a bitstream including spatial information for reconstructing <b>2</b>-channel signal and spatial information for reconstructing multi-channel signal are explained with reference to <figref idref="DRAWINGS">FIG. 1</figref> and <figref idref="DRAWINGS">FIG. 2</figref> as follows.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a first encoding apparatus according to one embodiment of the present invention.</p>
<p id="p-0033" num="0032">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, a first encoding apparatus includes a first downmixing unit <b>100</b>, a second downmixing unit <b>110</b>, a downmix signal encoding unit <b>120</b>, a first spatial information generating unit <b>130</b>, a second spatial information generating unit <b>140</b>, and a multiplexing unit <b>150</b>.</p>
<p id="p-0034" num="0033">The first downmixing unit <b>100</b> receives a multi-channel signal and then downmixes the received signal. into a first downmix signal having channels less than those of the multi-channel signal. And, the second downmixing unit <b>110</b> downmixes the first downmix signal into a second downmix signal having channels less than those of the first downmix signal.</p>
<p id="p-0035" num="0034">Each of the downmixing units <b>100</b> and <b>110</b> can use an OTT (one-to-two) box or a TTT (two-to-three) box to transform two channels into one channel or transform three channels into two channels. The OTT or TTT box is a conceptional box included in an audio signal decoding apparatus to be used in generating multi-channels using a downmix signal and spatial information. The OTT box transforms one signal into two signals using spatial information. The TTT box transforms two signals into three signals using spatial information. In the following description, the OTT or TTT box is called a signal transforming unit. To correspond the OTT or TTT box used for the audio signal decoding apparatus, an OTT or TTT box is included in the downmixing unit <b>100</b> or <b>110</b> of the audio signal encoding apparatus to be used in outputting one or two down mix signals from inputted multi-channels.</p>
<p id="p-0036" num="0035">The first/second downmix signal can be artificially generated instead of being generated by the downmixing unit <b>100</b>/<b>110</b>. Since the second downmix signal is a signal including channels less than those of the first downmix signal, in case that the second downmix signal is a mono signal, the first downmix signal should include at least two channels. In case that the first downmix signal is a 2-channel signal, the multi-channel signal should include at least three channels.</p>
<p id="p-0037" num="0036">The downmix signal encoding unit <b>120</b> compresses the second downmix signal and then sends the compressed downmix signal to the multiplexing unit <b>150</b>. The first spatial information generating unit <b>130</b> generates first spatial information using the multi-channel signal and the second downmix signal and then sends the first spatial information to the multiplexing unit <b>150</b>.</p>
<p id="p-0038" num="0037">Spatial information is the information indicating a relation with a channel in downmixing a channel signal. And, the spatial information is used for a decoding apparatus to reconstruct an original channel signal from a downmix signal. First spatial information generated from downmixing a multi-channel signal includes CLD (channel level differences), ICC (interchannel correlations), CPC (channel prediction coefficients), or the like. The CLD indicates an energy difference between audio signals. The ICC indicates correlation or similarity between audio signals. And, the CPC indicates a coefficient for predicting an audio signal using another signal. The second spatial information generating unit <b>140</b> generates second spatial information using the first downmix signal and the second downmix signal and then sends the second spatial information to the multiplexing unit <b>150</b>. In case that the first downmix signal is a 2-channel signal, the second spatial information can include IID (interchannel intensity difference) indicating an energy difference between two channels, IPD (interchannel phase difference) indicating a phase difference between two channels, ICC (interchannel correlation) indicating correlation between two channels, and the like.</p>
<p id="p-0039" num="0038">Spatial information is the information extracted in the course of downmixing a channel signal according to a predetermined tree structure. In this case, the predetermined tree structure means the tree structure agreed between a decoding apparatus and an encoding apparatus. Spatial information is able to include tree structure information. In this case, the tree structure information is the information for a type of a tree structure. According to the type of the tree structure, the number of multi-channels, a per channel downmix sequence, and the like can be changed.</p>
<p id="p-0040" num="0039">The multiplexing unit <b>150</b> generates a bitstream including the first spatial information and the second spatial information and then transfers the generated bitstream to the decoding apparatus together with or separately from a downmix signal.</p>
<p id="p-0041" num="0040">The encoding apparatus is able to transfer the second downmix signal in a PCM signal format to the decoding apparatus. In this case, the multiplexing unit <b>150</b> generates a bitstream including the first spatial information and the second spatial information and then transfers the generated bitstream to the decoding apparatus together with or separately from a PCM signal. In case of transferring both of the PCM signal and the spatial information to the decoding apparatus, the multiplexing unit <b>150</b> generates one bitstream by embedding the first spatial information and the second spatial information in the PCM signal and then transfers the generated bitstream to the decoding apparatus.</p>
<p id="p-0042" num="0041">And, the encoding apparatus is able to insert an identifier in the bitstream, In this case, the identifier indicates whether the transferred bitstream includes the second spatial information for the 2-channel signal generation, the first spatial information for the multi-channel signal generation, or both of the first spatial information and the second spatial information.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a second encoding apparatus according to another embodiment of the present invention.</p>
<p id="p-0044" num="0043">Referring to <figref idref="DRAWINGS">FIG. 2</figref>, a second encoding apparatus includes a first downmixing unit <b>200</b>, a second downmixing unit <b>210</b>, a downmix signal encoding unit <b>220</b>, a first spatial information generating unit <b>230</b>, a second spatial information generating unit <b>240</b>, and a multiplexing unit <b>250</b>.</p>
<p id="p-0045" num="0044">The first downmixing unit <b>200</b> receives a multi-channel signal and then downmixes the received signal into a first downmix signal having channels less than those of the multi-channel signal. And, the second downmixing unit <b>210</b> downmixes the first downmix signal into a second downmix signal having channels less than those of the first downmix signal.</p>
<p id="p-0046" num="0045">The downmix signal encoding unit <b>220</b> compresses the second downmix signal and then sends the compressed signal to the multiplexing unit <b>250</b>. The second downmix signal can be transferred in a PCM signal format to a decoding apparatus without passing through the downmix signal encoding unit <b>220</b>.</p>
<p id="p-0047" num="0046">The first spatial information generating unit <b>230</b> generates first spatial information using the multi-channel signal and the first downmix signal. The second spatial information generating unit generates second spatial information using the first downmix signal and the second downmix signal. And, the first spatial information generating unit <b>230</b> and the second spatial information generating unit <b>240</b> send the first spatial information and the second spatial information to the multiplexing unit <b>250</b>, respectively.</p>
<p id="p-0048" num="0047">The multiplexing unit <b>150</b> generates a bitstream by multiplexing the compressed downmix signal, the first spatial information, and the second spatial information together and then transfers the generated bitstream to the decoding apparatus.</p>
<p id="p-0049" num="0048">The encoding apparatus separately generates a stream of the downmix signal, a stream for the first spatial information, and a stream for the second spatial information and then respectively transfers the separate streams to the decoding apparatus. Alternatively, the encoding apparatus generates a bitstream including the first spatial information and the second spatial information and then transfers the generated bitstream to the decoding apparatus together with the downmix signal.</p>
<p id="p-0050" num="0049">The second encoding apparatus differs from the first encoding apparatus, which generates the first spatial information using the multi-channel signal and the second downmix signal, in generating the first spatial information using the multi-channel signal and the first downmix signal. So, the first spatial information generated by the first encoding apparatus differs from the first spatial information generated by the second encoding apparatus.</p>
<p id="p-0051" num="0050">The decoding apparatus, which has received the downmix signal and the spatial information generated by the encoding apparatus explained in <figref idref="DRAWINGS">FIG. 1</figref> or <figref idref="DRAWINGS">FIG. 2</figref>, reconstructs the 2-channel signal or the multi-channel signal using the spatial information and the downmix signal. The decoding apparatus decodes the downmix signal encoded and transferred by the encoding apparatus and then reconstructs the 2-channel signal or the multi-channel signal using the decoded downmix signal and the spatial information. So, an audio signal reconstructed by the decoding apparatus differs from an audio signal prior to downmixing in an audio quality. To prevent this, the encoding apparatus is able to generate spatial information using the downmix signal used for the decoding apparatus to reconstruct the audio signal.</p>
<p id="p-0052" num="0051">An encoding method and apparatus for generating spatial information using a downmix signal user for a decoding apparatus to reconstruct an audio signal are explained with reference to <figref idref="DRAWINGS">FIG. 3</figref> and <figref idref="DRAWINGS">FIG. 4</figref> as follows.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a third encoding apparatus for generating spatial information using a decoded downmix signal according to one embodiment of the present invention.</p>
<p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, a third encoding apparatus includes a first downmixing unit <b>300</b>, a second downmixing unit <b>310</b>, a downmix signal encoding unit <b>320</b>, a downmix signal decoding unit <b>330</b>, a first spatial information generating unit <b>350</b>, a second spatial information generating unit <b>340</b>, and a multiplexing unit <b>360</b>.</p>
<p id="p-0055" num="0054">The third encoding apparatus differs from the first encoding apparatus in including the downmix signal decoding unit <b>330</b>.</p>
<p id="p-0056" num="0055">The first downmixing unit <b>300</b> downmixes a multi-channel signal into a first downmix signal and the second downmixing unit <b>310</b> downmixes the first downmix signal into a second downmix signal. The downmix signal encoding unit <b>320</b> encodes the second downmix signal. The downmix signal decoding unit <b>330</b> decodes the encoded second downmix signal. The second spatial information generating unit <b>340</b> generates second spatial information using the first downmix signal and the decoded second downmix signal.</p>
<p id="p-0057" num="0056">The first encoding apparatus has a common feature with the third encoding apparatus in that the second spatial information is generated using the relation between the first downmix signal and the second downmix signal. Yet, the third encoding apparatus differs from the first encoding apparatus, which generates the second spatial information using the second downmix signal downmixed by the second downmixing unit <b>110</b>, in encoding the second downmix signal, decoding the encoded second downmix signal, and then generating the second spatial information using the decoded second downmix signal. And, the second spatial information generated by the first encoding apparatus differs from the second spatial information generated by the third encoding apparatus.</p>
<p id="p-0058" num="0057">The first spatial information generating unit <b>350</b> generates first spatial information using the multi-channel signal and the decoded second downmix signal. Unlike the first encoding apparatus generates the first spatial information using the second downmix signal, the third encoding apparatus encodes the second downmix signal, decodes the encoded signal again, and then generates the second spatial information using the decoded second downmix signal. Thus, the first encoding apparatus and the third encoding apparatus differ from each other. And, the first spatial information of the first encoding apparatus differs from that of the third encoding apparatus as well.</p>
<p id="p-0059" num="0058">The multiplexing unit <b>360</b> multiplexes the encoded downmix signal, the first spatial information, and the second spatial information together and then transfers the multiplexed signal to the decoding apparatus.</p>
<p id="p-0060" num="0059">The decoding apparatus decodes the second downmix signal encoded and transferred by the encoding apparatus and then reconstructs the 2-channel signal or the multi-channel signal by applying at least one of the first spatial information and the second spatial information to the decoded downmix signal. So, the channel signal reconstructed by the decoding apparatus has an audio quality closer to the audio signal prior to being downmixed by the encoding apparatus.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of a fourth encoding apparatus for generating spatial information using a decoded downmix signal according to another embodiment of the present invention.</p>
<p id="p-0062" num="0061">Referring to <figref idref="DRAWINGS">FIG. 4</figref>, a fourth encoding apparatus includes a first downmixing unit <b>400</b>, a second downmixing unit <b>410</b>, a downmix signal encoding unit <b>420</b>, a downmix signal decoding unit <b>430</b>, a first spatial information generating unit <b>460</b>, a second spatial information generating unit <b>440</b>, a first downmix signal generating unit <b>450</b>, and a multiplexing unit <b>470</b>.</p>
<p id="p-0063" num="0062">The fourth encoding apparatus differs from the second encoding apparatus in including the downmix signal decoding unit <b>430</b> and the first downmix signal generating unit <b>450</b>.</p>
<p id="p-0064" num="0063">The first downmixing unit <b>400</b> downmixes a multi-channel signal into a first downmix signal and the second downmixing unit <b>410</b> downmixes the first downmix signal into a second downmix signal. The downmix signal encoding unit <b>420</b> encodes the second downmix signal and then sends it to the downmix signal decoding unit <b>430</b>. The downmix signal decoding unit <b>430</b> decodes the encoded downmix signal and then sends it to the second spatial information generating unit <b>440</b>. The second spatial information generating unit <b>440</b> generates second spatial information using the first downmix signal and the decoded second downmix signal.</p>
<p id="p-0065" num="0064">The fourth encoding apparatus differs from the second encoding apparatus, which generates the second spatial information using the second downmix signal without being encoded and decoded, in generating the second spatial information using the downmix signal encoded by the downmix signal encoding unit <b>420</b> and then decoded by the downmix signal decoding unit <b>430</b> again.</p>
<p id="p-0066" num="0065">The first downmix signal generating unit <b>450</b> generates a modified first downmix signal using the second downmix signal decoded by the downmix signal decoding unit <b>430</b> and the second spatial information. The modified first downmix signal differs from the first downmix signal downmixed by the first downmixing unit <b>400</b> in being generated from the encoded and re-decoded second downmix signal and the second spatial information generated using the encoded and re-decoded second downmix signal.</p>
<p id="p-0067" num="0066">The first spatial information generating unit <b>460</b> generates first spatial information using the modified first downmix signal and the multi-channel signal. The first spatial information generating unit <b>460</b> differs from the second encoding apparatus, which generates the first spatial information using the first downmix signal intactly, in generating the first spatial information using the modified first downmix signal generated by the first downmix signal generating unit <b>450</b>. And, the first spatial information generated by the first spatial information generating unit <b>460</b> differs from the first spatial information generated by the second encoding apparatus. The multiplexing unit <b>470</b> generates a bitstream including both of the first spatial information and the second spatial information.</p>
<p id="p-0068" num="0067">And, the fourth encoding apparatus transfers the bitstream including the spatial information to the decoding apparatus together with or separately from the second downmix signal.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram of a bitstream of an audio signal according to one embodiment of the present invention.</p>
<p id="p-0070" num="0069">Referring to <figref idref="DRAWINGS">FIG. 5</figref>, an audio signal according to the present invention includes a downmix signal <b>500</b> and a spatial information signal <b>600</b>. The audio signal exists in an ES elementary stream) form having frames arranged therein.</p>
<p id="p-0071" num="0070">The downmix signal <b>500</b> and the spatial information signal <b>600</b> can be transferred in different ES forms to a decoding apparatus, respectively. Alternatively, they can be transferred in one ES form having the downmix and spatial information signals <b>500</b> and <b>600</b> combined together. In case of transferring the downmix signal <b>500</b> and the spatial information signal <b>600</b> in a combined form to the decoding apparatus, the spatial information signal <b>600</b> can be included in a location of ancillary data or extension data of the downmix signal <b>500</b>.</p>
<p id="p-0072" num="0071">The audio signal can include a codec identifier to enable a decoding apparatus to recognize basic information for audio codec without interpreting the audio signal. The codec identifier is the information indicating what kind of coding scheme is used in encoding the audio signal. The codec identifier can be included in a header <b>610</b> or spatial information <b>620</b> of the spatial information signal <b>600</b>. And, the codec identifier can include a spatial information identifier. In this case, the spatial information identifier is the information indicating whether a bitstream includes second spatial information to generate 2-channel signal from the audio signal, first spatial information to generate multi-channel signal from the audio signal, or both of the first spatial information and the second spatial information. so, the decoding apparatus is able to detect a type of the audio signal generatable from the downmix signal and the like and the like using the spatial information identifier.</p>
<p id="p-0073" num="0072">The spatial information signal <b>600</b> can include the header <b>610</b> and the spatial information <b>620</b>. Alternatively, the spatial information signal <b>600</b> can include the spatial information <b>620</b> only without including the header <b>610</b>. Namely, the spatial information signal <b>600</b> is able to use a frame including the header <b>610</b> or a frame not including the header <b>610</b> together.</p>
<p id="p-0074" num="0073">In case that the audio signal includes spatial information to generate multi-channel signal and spatial information to generate 2-channel signal, the header <b>610</b> can include a 2-channel signal header <b>611</b> and a multi-channel signal header <b>613</b>.</p>
<p id="p-0075" num="0074">In case that a signal reconstructible by the decoding apparatus is the 2-channel signal, the decoding apparatus decodes second spatial information <b>623</b> to generate the 2-channel signal using the 2-channel signal header <b>611</b> and then reconstructs the 2-channel signal using the decoded second spatial information <b>623</b>.</p>
<p id="p-0076" num="0075">In case that a signal reconstructible by the decoding apparatus is the multi-channel signal, the decoding apparatus decodes spatial information to generate the multi-channel signal using the multi-channel signal header <b>613</b>. The spatial information for the multi-channel signal reconstruction can include the second spatial information <b>623</b> as well as the first spatial information <b>621</b>. In case that the decoding apparatus reconstructs the 2-channel signal and then reconstructs the multi-channel signal from the reconstructed 2-channel signal, the multi-channel signal can be reconstructed using the second spatial information <b>623</b> for the 2-channel signal reconstruction and the first spatial information <b>621</b> for reconstructing the multi-channel signal from the 2-channel signal step by step. And, the spatial information signal can include the aforesaid tree structure information as well.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram of a first decoding apparatus according to one embodiment of the present invention.</p>
<p id="p-0078" num="0077">Referring to <figref idref="DRAWINGS">FIG. 6</figref>, a first decoding apparatus includes a demultiplexing unit <b>700</b>, a downmix signal decoding unit <b>720</b>, a 2-channel signal generating unit <b>710</b>, and a multi-channel signal generating unit <b>730</b>.</p>
<p id="p-0079" num="0078">The demultiplexing unit <b>700</b> parses a downmix signal and then sends the parsed signal to the downmix signal decoding unit <b>720</b>. The downmix signal can be a mono signal. And, the downmix signal can be a signal on a frequency domain. The frequency domain can be a QMF domain.</p>
<p id="p-0080" num="0079">The downmix signal decoding unit <b>720</b> decodes the downmix signal and then outputs the decoded downmix signal intactly. The downmix signal decoding unit <b>720</b> upmixes the downmix signal into a 2-channel signal or a multi-channel signal using spatial information and then outputs the upmixed signal. In case that the downmix signal is a PCM signal, the downmix can be outputted intact without passing through the downmix signal decoding unit <b>720</b>.</p>
<p id="p-0081" num="0080">A decoding apparatus is able to detect what kind of spatial information is included in a bitstream using a spatial information identifier included in the bitstream.</p>
<p id="p-0082" num="0081">If a downmix signal is a mono signal and if a signal generatable by the first decoding apparatus is one of a 2-channel signal and a multi-channel signal, the decoding apparatus decides whether the downmix signal is a signal capable of generating the 2-channel signal or the multi-channel signal using a spatial information identifier. If the decoding apparatus decides that both spatial information for 2-channel signal generation and spatial information for multi-channel signal generation are included in a bitstream, the decoding apparatus extracts spatial information for specific signal generation from the spatial information for 2-channel signal generation and the spatial information for multi-channel signal generation only and is then able to generate a channel signal using the extracted information.</p>
<p id="p-0083" num="0082">If a downmix signal is a PCM signal, the first spatial information <b>621</b> and the second spatial information <b>623</b> can be transmitted by being embedded in the downmix signal. In this case, the demultiplexing unit <b>700</b> is able to extract the first spatial information <b>621</b> and the second spatial information <b>623</b> from the downmix signal.</p>
<p id="p-0084" num="0083">In case that the decoding apparatus is capable of generating 2-channel signal only, the demultiplexing unit <b>700</b> of the decoding apparatus parses the second spatial information <b>623</b> for 2-channel signal generation in the transferred spatial information and then sends the parsed information to the 2-channel signal generating unit <b>710</b>. In case that the decoding apparatus is capable of generating multi-channel signal only, the demultiplexing unit <b>700</b> of the decoding apparatus parses the first spatial information <b>621</b> for multi-channel signal generation in the transferred spatial information and then sends the parsed information to the multi-channel signal generating unit <b>730</b>. Namely, if the decoding apparatus generates a multi-channel signal directly from a downmix signal and spatial information instead of generating multi-channel signal from 2-channel signal, the decoding apparatus need not use the second spatial information <b>623</b>. So, the decoding apparatus extracts the first spatial information <b>621</b> only to use.</p>
<p id="p-0085" num="0084">In case that the decoding apparatus is able to generate both 2-channel signal and multi-channel signal, the decoding apparatus is able to extract spatial information for user-selected channel signal generation by receiving control information from a user.</p>
<p id="p-0086" num="0085">In case that a signal generatable by the decoding apparatus is 2-channel signal or a user selects 2-channel signal generation, the 2-channel signal generating unit <b>710</b> generates 2-channel signal using the second spatial information <b>623</b> parsed and sent by the demultiplexing unit <b>700</b> and the decoded downmix signal and then outputs the generated signal. The 2-channel signal generating unit <b>710</b> generates the 2-channel signal by upmixing a mono downmix signal using a signal transforming unit (not shown in the drawing), and more particularly, an OTT box. In this case, the multi-channel signal generating unit <b>730</b> needs riot to operate. The demultiplexing unit <b>700</b> can generate an identifier controlling an operation of the multi-channel signal generating unit <b>730</b> and send the generated identifier to the multi-channel signal generating unit <b>730</b>. Hereinafter, the identifier controlling an operation of the 2-channel signal generating unit <b>710</b> or the multi-channel signal generating unit <b>730</b> is named an operation control identifier. The multi-channel signal generating unit <b>730</b> does not operate according to the operation control identifier received from the demultiplexing unit <b>700</b>. And, it is unnecessary to consider the first spatial information <b>621</b>.</p>
<p id="p-0087" num="0086">In case that a signal generatable by the decoding apparatus is multi-channel signal or a user selects multi-channel signal generation, the multi-channel signal generating unit <b>730</b> generates multi-channel signal using the first spatial information <b>621</b> and then outputs the generated signal. The multi-channel signal generating unit <b>730</b> upmixes a downmix signal using a plurality of signal transforming units. As mentioned in the foregoing description, the signal transforming unit includes an OTT box or a TTT box. In this case, since the 2-channel signal generating unit <b>710</b> needs not to operate, the demultiplexing unit <b>700</b> generates an operation control identifier and then sends the generated operation control identifier to the 2-channel signal generating unit <b>710</b> to control an operation of the 2-channel signal generating unit <b>710</b>. The 2-channel signal generating unit <b>710</b> does not operate according to the operation control identifier. And, it is unnecessary to consider the second spatial information <b>623</b>.</p>
<p id="p-0088" num="0087">The decoding apparatus can further include a modified spatial information generating unit (not shown in the drawing). The modified spatial information generating unit identifies a type of modified spatial information using spatial information and generates modified spatial information of the type identified based on the spatial information. In this case, the modified spatial information means the spatial information that is newly generated using spatial information. The modified spatial information can be generated by combining spatial information. The modified spatial information generating unit is able to generate modified spatial information using tree structure information, output channel information and the like included in the spatial information. The output channel information is the information for a speaker interconnecting with the decoding apparatus and can include the number of output channels, position information for each output channel, and the like. The output channel information is inputted to the decoding apparatus in advance by a manufacturer or can be inputted by a user.</p>
<p id="p-0089" num="0088">The decoding apparatus decides whether the number of original multi-channels downmixed by the encoding apparatus is equal to the number of channels to be generated using the tree structure information and the output channel information. Hereinafter, the original multi-channels downmixed by the encoding apparatus are named first multi-channels. If the number of the first multi-channels downmixed by the encoding apparatus is different from the number of multi-channels to be generated, the decoding apparatus is able to modify spatial information using the modified spatial information generating unit. In this case, the modified spatial information can be generated by combining the aforesaid CLD, ICC, CPC, IPC, and the like. The decoding apparatus is able to generate multi-channels of which number differs from the number of the first multi-channels using the modified spatial information and the downmix signal.</p>
<p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram of a second encoding apparatus according to another embodiment of the present invention.</p>
<p id="p-0091" num="0090">Referring to <figref idref="DRAWINGS">FIG. 7</figref>, a second decoding apparatus includes a demultiplexing unit <b>800</b>, a downmix signal decoding unit <b>810</b>, a 2-channel signal generating unit <b>820</b>, and a multi-channel signal generating unit <b>830</b>.</p>
<p id="p-0092" num="0091">The demultiplexing unit <b>800</b> parses a downmix signal from a bitstream transferred from an encoding apparatus or a bitstream recorded in a storage medium and then sends the parsed signal to the downmix signal decoding unit <b>810</b>.</p>
<p id="p-0093" num="0092">The downmix signal decoding unit <b>810</b> decodes the downmix signal and outputs the decoded signal as a mono signal or generates 2-channel signal or multi-channel signal using spatial information.</p>
<p id="p-0094" num="0093">In case that the decoding apparatus is able to generate 2-channel signal or that 2-channel signal generation is selected by a user despite that the decoding apparatus is able generate both 2-channel signal and multi-channel signal, the demultiplexing unit <b>800</b> extracts second spatial information <b>623</b> for 2-channel signal generation and then sends the extracted information to the 2-channel signal generating unit.</p>
<p id="p-0095" num="0094">The 2-channel signal generating unit <b>820</b> generates 2-channel signal using the second spatial information <b>623</b> and the decoded downmix signal.</p>
<p id="p-0096" num="0095">Since the second spatial information <b>623</b> is applied to the downmix signal on a frequency domain, the 2-channel signal should be converted to a signal on a time domain in order for the decoding apparatus to output the 2-channel signal. The decoding apparatus is able to use FFT (fast Fourier transform), DFT (discrete Fourier transform), QMF or hybrid function, or the like in converting a time domain to a frequency domain, and vice versa. And, the decoding apparatus output a domain-converted 2-channel signal.</p>
<p id="p-0097" num="0096">In case that the decoding apparatus generates the 2-channel signal only, it is unnecessary to generate multi-channel signal. So, the demultiplexing unit <b>800</b> generates an operation control identifier in order for the multi-channel signal generating unit <b>830</b> not to operate and then sends the generated identifier to the multi-channel signal generating unit <b>830</b>. The multi-channel signal generating unit <b>830</b> does not operate according to the operation control identifier. And, it is unnecessary to consider the first spatial information <b>621</b> for the multi-channel signal generation.</p>
<p id="p-0098" num="0097">In case that the decoding apparatus is able to generate multi-channel signal or that multi-channel signal generation is selected by a user, the demultiplexing unit <b>800</b> extracts spatial information for the multi-channel signal generation. Since the second decoding apparatus generates multi-channel signal using 2-channel signal unlike the first decoding apparatus, the demultiplexing unit <b>800</b> extracts both second spatial information <b>623</b> for 2-channel signal generation and first spatial information <b>621</b> for generating multi-channel signal from the 2-channel signal. So, the first spatial information used by the first decoding apparatus is discriminated from the first spatial information used by the second decoding apparatus. In particular, the second spatial information used by the second decoding apparatus is the spatial information required for generating the multi-channel signal from the 2-channel signal, whereas the first spatial information used by the first decoding apparatus is the spatial information required for generating multi-channels from the downmix signal.</p>
<p id="p-0099" num="0098">The 2-channel signal generating unit <b>820</b> generates 2-channel signal using the second spatial information <b>623</b> and the decoded downmix signal and then sends the generated signal to the multi-channel signal generating unit <b>830</b>.</p>
<p id="p-0100" num="0099">The multi-channel signal generating unit <b>830</b> is able to generate multi-channel signal using the 2-channel signal sent by the 2-channel signal generating nit <b>820</b> and the first spatial information <b>621</b> extracted by the demultiplexing unit <b>800</b>. In case that the 2-channel signal generation and the multi-channel signal generation are carried out on the same domain, i.e., a frequency domain, the multi-channel signal generating unit <b>830</b> is able to generate multi-channel signal using 2-channel signal on the frequency domain. In this case, the frequency domain includes a QMF domain, a hybrid domain, or the like. In particular, the multi-channel signal generating unit <b>830</b> is able to generate multi-channel signal by applying the first spatial information <b>621</b> to the 2-channel signal having a domain not converted to a time domain. In this case, it is unnecessary to convert the 2-channel signal to a signal on the time domain. And, a user is able to select and use the 2-channel signal or the multi-channel signal using the first decoding apparatus, the second decoding apparatus, or the like.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of decoding an audio signal, comprising:
<claim-text>extracting a downmix signal from a bitstream by a downmix signal extracting unit, wherein the bitstream includes first spatial information and second spatial information;</claim-text>
<claim-text>extracting at least one of the first spatial information and the second spatial information from the bitstream by a spatial information extracting unit, wherein the first spatial information is information for generating a multi-channel audio signal having at least three channels and wherein the second spatial information is information for generating a stereo audio signal having two channels, wherein the first spatial information includes parameters of channel level differences (CLD), interchannel correlations (ICC), channel prediction coefficients (CPC), and wherein the second spatial information includes parameters of interchannel intensity differences (IID), interchannel phase difference (IPD) and ICC; and</claim-text>
<claim-text>generating at least one of the multi-channel audio signal and the stereo audio signal using the extracted downmix signal and one of the first and second spatial information by a channel generating unit,</claim-text>
<claim-text>wherein when the multi-channel audio signal is generated, the downmix signal is upmixed using the first spatial information and the second spatial information is ignored,</claim-text>
<claim-text>wherein when the stereo audio signal is generated, the downmix signal is upmixed using the second spatial information and the first spatial information is ignored.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generating the stereo audio signal comprises upmixing the downmix signal using a signal transforming unit if the second spatial information is extracted.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>modifying the first spatial information to generate modified spatial information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the modifying the first spatial information further includes:
<claim-text>combining parameters in the first spatial information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the generating audio signal further includes generating a second audio signal using the modified spatial information and the downmix signal, wherein the downmix signal is a signal generated from downmixing the multi-channel audio signal and wherein a channel number of the second audio signal differs from a channel number of the multi-channel audio signal.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the downmix signal comprises a mono signal.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the extracting the first or second spatial information and the generating the audio signal are carried out according to a user's selection or a generable channel type by an apparatus for performing the method.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A method of encoding an audio media signal, comprising:
<claim-text>generating a downmix signal by downmixing the audio signal, wherein the audio signal is at least one of a stereo audio signal and an multi-channel audio signal, by a downmixing unit;</claim-text>
<claim-text>generating first spatial information and second spatial information by a spatial information generating unit, the first spatial information for decoding the multi-channel audio signal having at least three channels using the downmix signal, and the second spatial information for decoding the stereo audio signal having two channels using the downmix signal,</claim-text>
<claim-text>wherein the first spatial information includes parameters of channel level differences (CLD), interchannel correlations (ICC), channel prediction coefficients (CPC), and wherein the second spatial information includes parameters of interchannel intensity differences (IID), interchannel phase difference (IPD) and ICC; and</claim-text>
<claim-text>generating a bitstream including the first spatial information and the second spatial information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. An apparatus for decoding an audio signal, comprising:
<claim-text>a downmix signal extracting unit for extracting a downmix signal from a bitstream, wherein the bitstream includes first spatial information and second spatial information;</claim-text>
<claim-text>a spatial information extracting unit for extracting at least one of the first spatial information and the second spatial information from the bitstream, wherein the first spatial information is information for generating a multi-channel audio signal having at least three channels and wherein the second spatial information is information for generating a stereo audio signal having two channels, wherein the first spatial information includes parameters of channel level differences (CLD), interchannel correlations (ICC), channel prediction coefficients (CPC), and wherein the second spatial information includes parameters of interchannel intensity differences (IID), interchannel phase difference (IPD) and ICC; an</claim-text>
<claim-text>a channel generating unit for generating at least one of the multi-channel audio signal or the stereo audio signal using the downmix signal and one of the first and second spatial information,</claim-text>
<claim-text>wherein when the multi-channel audio signal is generated, the downmix signal is upmixed by a processor using the first spatial information and the second spatial information is ignored, wherein when the stereo audio signal is generated, the downmix signal is upmixed by the processor using the second spatial information and the first spatial information is ignored.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the spatial information extracting unit further comprises:
<claim-text>a spatial information modifying unit for modifying the extracted first spatial information to generate modified spatial information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the spatial information modifying unit combines parameters in the first spatial information for the modifying.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the channel generating unit generates a second audio signal using the modified spatial information and the downmix signal, wherein the downmix signal is a signal generated from downmixing the multi-channel audio signal and wherein a channel number of the second audio signal differs from a number of the multi-channel audio signal.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. An apparatus of encoding an audio signal, comprising:
<claim-text>a downmixing unit for generating a downmix signal by downmixing the audio signal, wherein the audio signal is at least one of stereo audio signal and multi-channel audio signal;</claim-text>
<claim-text>a first spatial information generating unit for generating first spatial information for decoding the multi-channel audio signal having at least three multi-channels using the downmix signal;</claim-text>
<claim-text>a second spatial information generating unit for generating second spatial information for decoding the stereo audio signal having two channels using the downmix signal, wherein the first spatial information includes parameters of channel level differences (CLD), interchannel correlations (ICC), channel prediction coefficients (CPC), and wherein the second spatial information includes parameters of interchannel intensity differences (IID), interchannel phase difference (IPD) and ICC; and</claim-text>
<claim-text>a multiplexing unit for generating, by a processor, a bitstream including the first spatial information and the second spatial information. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
