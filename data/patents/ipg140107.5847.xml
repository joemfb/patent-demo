<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626955-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626955</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12240899</doc-number>
<date>20080929</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>855</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>173</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709250</main-classification>
<further-classification>709238</further-classification>
</classification-national>
<invention-title id="d2e53">Directing packets to a processor unit</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7415035</doc-number>
<kind>B1</kind>
<name>Muller et al.</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2005/0060462</doc-number>
<kind>A1</kind>
<name>Ota</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710260</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2005/0080923</doc-number>
<kind>A1</kind>
<name>Elzur</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709238</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2007/0038818</doc-number>
<kind>A1</kind>
<name>Greenfield et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2007/0070904</doc-number>
<kind>A1</kind>
<name>King et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370235</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0230489</doc-number>
<kind>A1</kind>
<name>Cornett et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370412</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2008/0002724</doc-number>
<kind>A1</kind>
<name>Grewal et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370401</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2009/0182836</doc-number>
<kind>A1</kind>
<name>Aviles et al.</name>
<date>20090700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709213</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>WO</country>
<doc-number>2008/002945</doc-number>
<kind>A1</kind>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>WO</country>
<doc-number>2010/036656</doc-number>
<kind>A2</kind>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>WO</country>
<doc-number>2010/036656</doc-number>
<kind>A3</kind>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>International Preliminary Report on Patentability for International Patent Application No. PCT/US2009/057881, Mailed Apr. 7, 2011, 6 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>International Search Report and Written Opinion for International Patent Application No. PCT/US2009/057881, Mailed Apr. 12, 2010, 11 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Veal, Bryan et al., &#x201c;Performance Scalability of a Multi-Core Web Server&#x201d;, ANCS '07, Dec. 3-4, 2007, Orlando, FL, 10 pages, ref pp. 57-66.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Supplemental European Search Report received for European Patent Application No. 09816762.0 mailed on Oct. 9, 2012, 11 pages of Supplemental Search Report.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Cline et al. &#x201c;TCP Onloading for Data Center Servers&#x201d; vol. 37, Issue 11, Nov. 1, 2004, pp. 46-56.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>22</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709213</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709226</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709231</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709238-239</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709250</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370230</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370235</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370389</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370412-413</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>710260</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100083259</doc-number>
<kind>A1</kind>
<date>20100401</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Veal</last-name>
<first-name>Bryan</first-name>
<address>
<city>Hillsboro</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Foong</last-name>
<first-name>Annie</first-name>
<address>
<city>Aloha</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Veal</last-name>
<first-name>Bryan</first-name>
<address>
<city>Hillsboro</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Foong</last-name>
<first-name>Annie</first-name>
<address>
<city>Aloha</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Intel Corporation</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Shaw</last-name>
<first-name>Peling</first-name>
<department>2444</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A computer system may comprise a plurality of cores that may process the tasks determined by the operating system. A network device may direct a first set of packets to a first core using a flow-spreading technique such as receive side scaling (RSS). However, the operating system may re-provision a task from the first core to a second core to balance the load, for example, on the computer system. The operating system may determine an identifier of the second core using a new data field in the socket calls to track the identifier of the second core. The operating system may provide the identifier of the second core to a network device. The network device may then direct a second set of packets to the second core using the identifier of the second core.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="136.74mm" wi="167.81mm" file="US08626955-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="166.79mm" wi="149.61mm" orientation="landscape" file="US08626955-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="223.77mm" wi="143.09mm" orientation="landscape" file="US08626955-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.62mm" wi="139.62mm" orientation="landscape" file="US08626955-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="191.26mm" wi="142.16mm" orientation="landscape" file="US08626955-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">A processing unit of a computer system may comprise multiple processing cores. The cores may comprise execution units exposed by the architecture. The computer system may be coupled to other computer systems and may transfer data units to the other computer systems. As the data transfer speeds increase (e.g., 10 Giga-bit per second), the tasks that consume the data units may be scheduled, dynamically. The scheduling policy of the operating system (OS) may transfer the task supported by a first core to a second core to balance the load. However, flow-spreading or mapping techniques such as receive side scaling (RSS) may direct the data units to the first core, which may not be supporting tasks that require the data units. Such a mismatch may degrade the performance of the computer system.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0003" num="0002">The invention described herein is illustrated by way of example and not by way of limitation in the accompanying figures. For simplicity and clarity of illustration, elements illustrated in the figures are not necessarily drawn to scale. For example, the dimensions of some elements may be exaggerated relative to other elements for clarity. Further, where considered appropriate, reference labels have been repeated among the figures to indicate corresponding or analogous elements.</p>
<p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a computer platform <b>100</b> in accordance with an embodiment.</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an operation of an operating system, which may cause the data units to be directed to a core supporting tasks in accordance with an embodiment.</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an operation of the network device, which may direct the data units to a core supporting tasks in accordance with an embodiment.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a flow tracer, which may efficiently track the flows in the network device in accordance with an embodiment.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an operation of the flow tracer, which may efficiently track the flows in the network device in accordance with an embodiment.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 6</figref> illustrates a set-associative flow table used to efficiently track the flows in the network device in accordance with other embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0003" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0010" num="0009">The following description describes directing data units to a core supporting tasks. In the following description, numerous specific details such as logic implementations, resource partitioning/sharing/duplication implementations, types and interrelationships of system components, and logic partitioning/integration choices are set forth in order to provide a more thorough understanding of the present invention. It will be appreciated, however, by one skilled in the art that the invention may be practiced without such specific details. In other instances, control structures, gate level circuits, and full software instruction sequences have not been shown in detail in order not to obscure the invention. Those of ordinary skill in the art, with the included descriptions, will be able to implement appropriate functionality without undue experimentation.</p>
<p id="p-0011" num="0010">References in the specification to &#x201c;one embodiment&#x201d;, &#x201c;an embodiment&#x201d;, &#x201c;an example embodiment&#x201d;, etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily include the particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Further, when a particular feature, structure, or characteristic is described in connection with an embodiment, it is submitted that it is within the knowledge of one skilled in the art to effect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described.</p>
<p id="p-0012" num="0011">Embodiments of the invention may be implemented in hardware, firmware, software, or any combination thereof. Embodiments of the invention may also be implemented as instructions stored on a machine-readable medium, which may be read and executed by one or more processors. A machine-readable medium may include any mechanism for storing or transmitting information in a form readable by a machine (e.g., a computing device). For example, a machine-readable medium may include read only memory (ROM); random access memory (RAM); magnetic disk storage media; optical storage media; flash memory devices; electrical, optical, acoustical or other forms of propagated signals (e.g., carrier waves, infrared signals, digital signals, etc.), and others. Further, firmware, software, routines, instructions may be described herein as performing certain actions. However, it should be appreciated that such descriptions are merely for convenience and that such actions in fact result from computing devices, processors, controllers, or other devices executing the firmware, software, routines, instructions, etc.</p>
<p id="p-0013" num="0012">An embodiment of a computer platform <b>100</b> is illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. The computing platform <b>100</b> may comprise a plurality of processing cores such as core <b>101</b>-A, <b>101</b>-B, and <b>101</b>-K, an operating system <b>150</b>, and a network device <b>190</b>.</p>
<p id="p-0014" num="0013">In one embodiment, the cores <b>101</b> may support one or more applications such as file transfer protocol (ftp), or e-mail, or Telnet. In one embodiment, the cores <b>101</b> may provision resources to execute tasks of the application. In one embodiment, the core <b>101</b> may represent a fine-grained unit of execution exposed by the architecture and may comprise a hardware thread, a core, a central processing unit (CPU), and similar other units. In one embodiment, the core <b>101</b>-A may support a task <b>110</b>-A. In one embodiment, the task <b>110</b>-A while provisioned on the core <b>101</b>-A may use a socket <b>105</b> to communicate with the operating system <b>150</b>.</p>
<p id="p-0015" num="0014">In one embodiment, the task <b>110</b>-A, which initially was provisioned on the core <b>101</b>-A may be re-provisioned or rescheduled from the core <b>101</b>-A to core <b>101</b>-K, for example. In one embodiment, the re-provisioning may occur in response to receiving a signal from the operating system <b>150</b>. In one embodiment, the re-provisioned task <b>110</b>-A supported by the core <b>101</b>-K may use a socket <b>115</b> to communicate with the operating system <b>150</b>. In one embodiment, socket <b>105</b> and <b>115</b> may support data structures, which may track characteristics and state of a flow. In one embodiment, the sockets <b>105</b> and <b>115</b> may comprise a new data structure such as a CID tracking data field to track the identifier of the core (Core ID), which supports the task <b>110</b>. In one embodiment, the socket <b>105</b> may provide the identifier of the core <b>101</b>-A as the CID while the task <b>110</b>-A is supported by the core <b>101</b>-A. After re-provisioning the task <b>110</b>-A from the core <b>101</b>-A to <b>101</b>-K, the socket <b>115</b> may provide the identifier of the core <b>101</b>-K as the CID.</p>
<p id="p-0016" num="0015">In one embodiment, the operating system <b>150</b> may manage the processing resources of the cores <b>101</b>-A to <b>101</b>-K. In one embodiment, the OS <b>150</b> may schedule the hardware resources such as the threads to perform a task of an application. In one embodiment, at a first time point, the operating system <b>150</b> may schedule the task <b>110</b>-A of an application on the core <b>101</b>-A. At a second time point, the operating system <b>150</b> may re-provision or reschedule the task <b>110</b>-A from the core <b>101</b>-A to <b>101</b>-K by sending a re-provisioning signal to the core <b>101</b>-A and <b>101</b>-K. In one embodiment, the OS <b>150</b> may re-provision the task <b>110</b>-A from the core <b>101</b>-A to <b>101</b>-K to balance the load of the computing system <b>100</b>. In one embodiment, the OS <b>150</b> may use resource scheduling policies to provision and re-provision the tasks to balance the load of the computer platform <b>100</b>.</p>
<p id="p-0017" num="0016">In one embodiment, the operating system <b>150</b> may use sockets such as <b>105</b> and <b>115</b> as an interface between the application and the network. In one embodiment, the operating system <b>150</b> may extract the core identifier (CID) stored in the CID data field of a socket system call and may provide the CID to the network device <b>190</b>. In one embodiment, the socket system call may be initiated by a resource supporting the task <b>110</b>-A.</p>
<p id="p-0018" num="0017">In one embodiment, the network device <b>190</b> may comprise a network controller <b>170</b>, a network interface <b>180</b>, and a memory <b>185</b>. In one embodiment, the network interface <b>180</b> may couple the computing system <b>100</b> to a network. In one embodiment, the network interface <b>180</b> may receive incoming data units from the network and store the incoming data units to a buffer indicated by the buffer details provided by the network controller <b>170</b>. In one embodiment, the network interface <b>180</b> may store the incoming data units in a buffer <b>155</b>-A based on the buffer details received from the network controller <b>170</b>. In one embodiment, the incoming data units stored in the buffer <b>155</b>-A may be retrieved by the core <b>101</b>-A. In one embodiment, the network interface <b>180</b> may transfer the outgoing data units stored in the buffer <b>165</b>-A to the network.</p>
<p id="p-0019" num="0018">In one embodiment, the network controller <b>170</b> may comprise logic <b>174</b> and a flow tracker <b>178</b>. In one embodiment, the flow tracker <b>178</b> may adopt techniques to reduce the storage requirement of a flow table, which may store flow-to-core mapping. In one embodiment, the flow tracker <b>178</b> may adopt techniques such as combining flow table with a RSS indirection table created using flow spreading techniques such as receive side scaling (RSS). In one embodiment, such combining techniques may use the flow table as an exception to RSS results. In other embodiment, the flow tracker <b>178</b> may use replacement policies such as least recently used (LRU) to replace the aged entries with the new entries. In yet other embodiment, the flow tracker <b>178</b> may use set associativity techniques to trade-off between complexity and performance to store the entries in the flow table. In one embodiment, the search results of the flow table may provide the core identifier to which the incoming data units may be sent.</p>
<p id="p-0020" num="0019">In one embodiment, the logic <b>174</b> may use flow-spreading or mapping techniques such as receive side scaling (RSS) to determine the destination core to which the first set of data units may be sent. In one embodiment, the logic <b>174</b> may use RSS technique to determine that the first set of data units may be sent to the core <b>101</b>-A. In one embodiment, the logic <b>174</b> may provide buffer details to the network interface <b>180</b> that provide details of the buffer <b>155</b>-A into which the incoming data units may be stored.</p>
<p id="p-0021" num="0020">In one embodiment, the logic <b>174</b> may receive a CID from the operating system <b>150</b>. In one embodiment, the CID may indicate the identifier of the core, which may support the re-provisioned task. In one embodiment, the logic <b>174</b> may receive a CID comprising the identifier of the core <b>101</b>-K. In one embodiment, the logic <b>174</b> may determine the buffers associated with the core <b>101</b>-K and may send the buffer details to the network interface <b>180</b>. In one embodiment, the logic <b>174</b> may determine that the buffer <b>155</b>-K and <b>165</b>-K are associated with the core <b>101</b>-K and may send the starting address of the buffer <b>155</b>-K for storing incoming data units.</p>
<p id="p-0022" num="0021">In one embodiment, such an approach may cause the incoming data units to reach the core <b>101</b>-K, which supports the task <b>110</b>-A. In one embodiment, the task <b>110</b>-K may be the consumer of the incoming data units. As a result of directing the data units to the core, which consumes the data units, the performance of the computer platform <b>100</b> may be enhanced.</p>
<p id="p-0023" num="0022">An operation of the operating system <b>150</b>, which may cause the data units to be directed to the core <b>101</b>-K in accordance with an embodiment, is illustrated in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0024" num="0023">In block <b>210</b>, the operating system <b>150</b> may check if the task <b>110</b>-A performing a task is to be relocated to a next core and control passes to block <b>250</b> if the task is to be re-provisioned. In one embodiment, the OS <b>150</b> may check if the task <b>110</b>-A is to be re-provisioned from the core <b>110</b>-A to <b>110</b>-K. In one embodiment, the OS <b>150</b> may determine that the task <b>110</b>-A is to be re-provisioned to the core <b>101</b>-K in accordance with a scheduling policy to balance the workload. In one embodiment, control may pass to block <b>250</b>.</p>
<p id="p-0025" num="0024">In block <b>250</b>, the OS <b>150</b> may determine an identifier of the next core (CID). In one embodiment, the OS <b>150</b> may determine the identifier of the next core using the socket calls made by the task <b>110</b>-K. In one embodiment, the socket <b>115</b> may support data fields that determine or track the identifier of the core supporting the task <b>101</b>-K. In one embodiment, the OS <b>150</b> may determine the identifier of the core <b>101</b>-A as the core <b>101</b>-K is supporting the task <b>110</b>-K, which is re-provisioned.</p>
<p id="p-0026" num="0025">In block <b>280</b>, the OS <b>150</b> may provide the identifier of the next core to the network device <b>190</b>. In one embodiment, the OS <b>150</b> may provide the identifier of the core <b>101</b>-K to the network device <b>190</b>.</p>
<p id="p-0027" num="0026">An operation of the network device <b>190</b>, which may direct the data units to the next core supporting the task in accordance with an embodiment, is illustrated in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0028" num="0027">In block <b>310</b>, the network device <b>190</b> may receive a first packet or first set of packets from the network. In block <b>320</b>, the network device <b>190</b> may map a flow, associated with the first packet, to a first core using flow spreading techniques. In one embodiment, the network device <b>190</b> may map the first packet or a first set of packets to the core <b>101</b>-A using receive side scaling (RSS) technique, for example.</p>
<p id="p-0029" num="0028">In block <b>330</b>, the network device <b>190</b> may direct the first packet or first set of packets to the first core <b>101</b>-A. In one embodiment, the network device <b>190</b> may store the first packet into a buffer <b>155</b>-A that may be retrieved by the first core <b>101</b>-A.</p>
<p id="p-0030" num="0029">In block <b>340</b>, the network device <b>190</b> may receive a next packet or a second set of packets from the network. In block <b>350</b>, the network device <b>190</b> may check if an identifier of the next core is received and control passes to block <b>370</b> if the identifier is received and to block <b>380</b> otherwise. In one embodiment, the network device <b>190</b> may receive the identifier of the next core from the OS <b>150</b>.</p>
<p id="p-0031" num="0030">In block <b>370</b>, the network device <b>190</b> may direct the next packet or the second set of packets to the next core <b>101</b>-K. In block <b>380</b>, the network device <b>190</b> may direct the next packet to the first core <b>101</b>-A.</p>
<p id="p-0032" num="0031">A flow tracker <b>178</b>, which may efficiently track the flow in accordance with an embodiment is illustrated in <figref idref="DRAWINGS">FIG. 4</figref>. In one embodiment, the techniques used in tracking the flow may efficiently store the data. In one embodiment, the flow tracker <b>178</b> may comprise a hash function <b>410</b>, a hash mask <b>420</b>, a RSS indirection table <b>430</b>, a flow table <b>440</b>, and a selector <b>460</b>.</p>
<p id="p-0033" num="0032">In one embodiment, the hash function <b>410</b> may receive a packet header and extract flow data from the packet. In one embodiment, the flow data may represent a flow identifier (flow ID) included in the packet header.</p>
<p id="p-0034" num="0033">In one embodiment, the hash mask <b>420</b> may receive the flow identifier (flow ID) from the hash function <b>410</b> and may generate a table index, which may point to one of the entries in the RSS indirection table <b>430</b>. In one embodiment, the RSS indirection table <b>430</b> may comprise a list of core identifier (core ID <b>435</b>) populated by the logic <b>174</b> using flow-spreading techniques such as receive side scaling.</p>
<p id="p-0035" num="0034">In one embodiment, entries in the RSS indirection table <b>430</b> may map multiple flows to a core and the RSS technique may not effectively track individual flows. Also, changing an entry in the RSS indirection map <b>430</b> may remap multiple flows. In one embodiment, the network device <b>190</b> may also be provided with a capability to track individual flow to track the flows that changed from the RSS indirection table entries.</p>
<p id="p-0036" num="0035">In one embodiment, the flow table <b>440</b> may comprise two fields flow ID <b>444</b> and a core identifier (core ID <b>448</b>). In one embodiment, the flow table <b>440</b> may be populated by the logic <b>174</b> using the core identifiers received from the OS <b>150</b>. In one embodiment, the flow table <b>440</b> may map individual flows to a core. In one embodiment, a new entry in the flow table <b>440</b> may be created in response to receiving a core identifier from the OS <b>150</b>.</p>
<p id="p-0037" num="0036">In one embodiment, for an incoming packet, the selector <b>460</b> may match the flow ID with the entries in the flow table <b>440</b> and on detecting a match for the flow ID, an associated core ID may be selected. In one embodiment, the selected core ID may be used to direct the packet to the core <b>101</b>-K, for example. In one embodiment, the selector <b>460</b> may use the RSS indirection table <b>430</b> to determine the core ID if no match is found to the flow ID extracted from the packet header. In one embodiment, the selector <b>460</b> may select the core ID indicated by the table entry generated by the hash mask <b>420</b>.</p>
<p id="p-0038" num="0037">The operation of a flow tracker <b>170</b>, which may be used to direct the packet to a core supporting a task in accordance with an embodiment is illustrated in <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0039" num="0038">In block <b>510</b>, the hash function <b>410</b> may receive a packet and extract a packet header from the packet. In block <b>530</b>, the hash function <b>410</b> may extract a flow identifier (flow ID) from the packet header.</p>
<p id="p-0040" num="0039">In block <b>540</b>, the selector <b>460</b> may check if the flow identifier is present in the flow table <b>440</b> and control passes to block <b>560</b> if the flow identifier is present in the flow table <b>440</b> and to block <b>590</b> otherwise.</p>
<p id="p-0041" num="0040">In block <b>560</b>, the selector <b>460</b> may provide a core identifier associated with the matching flow identifier to the logic <b>174</b>. In block <b>580</b>, the selector <b>460</b> may provide a core identifier using the RSS indirection table <b>430</b> to the logic <b>174</b>.</p>
<p id="p-0042" num="0041">In other embodiment, in order to keep the entries in the flow table finite, the entries in the table <b>440</b> may be replaced, by the logic <b>174</b>, using a replacement policy such as the least recently used (LRU) policy. In one embodiment, an entry of the table <b>440</b> may be marked as &#x201c;recently used&#x201d; if an incoming packet includes a matching flow identifier. In one embodiment, the least recently used active flows may be replaced with new flows as the next incoming packets get mapped to cores. Such an approach may identify ageing of the entries and by replacing the most aged entries, the flow table <b>440</b> may be maintained to accommodate the recently used entries.</p>
<p id="p-0043" num="0042">In yet other embodiment, the entries in the table <b>440</b> may be stored using set-associativity, illustrated in <figref idref="DRAWINGS">FIG. 6</figref>. In one embodiment, the flow table <b>440</b> may comprise one or more ways such as a way <b>610</b>-A to <b>610</b>-K and sets such as a set <b>620</b>-A to <b>620</b>-L. In one embodiment, the intersection of a way <b>610</b> and a set <b>620</b> may comprise an entry. In one embodiment, the set <b>620</b>-A may comprise entries <b>630</b>-AA to <b>630</b>-KA in the ways <b>610</b>-A to <b>610</b>-K, respectively. Like-wise, a set <b>620</b>-B may comprise entries <b>630</b>-AB to <b>630</b>-KB and a set <b>620</b>-L may comprise entries <b>630</b>-AL to <b>630</b>-KL. In one embodiment, each entry <b>630</b> may comprise one or more fields such as validity, age, tag, and core-identifier. In one embodiment, the entry <b>630</b>-AA may comprise fields such as a validity <b>640</b>, an age <b>650</b>, a tag <b>660</b>, and a core identifier <b>670</b>.</p>
<p id="p-0044" num="0043">While replacing the entry <b>630</b>-AA and updating age <b>650</b>, the logic <b>174</b> may check a limited number of entries <b>630</b>-AA to <b>630</b>-KA within the set <b>620</b>-A. In one embodiment, the sets <b>620</b> may be indexed and the entries may be tagged using flow identifier generated using the hash function <b>410</b>. In one embodiment, using the flow identifier generated from a hash function <b>410</b> may provide uniform mapping of flow to the sets <b>620</b>.</p>
<p id="p-0045" num="0044">In one embodiment, the network device <b>190</b>, while directing the packet to the next core as depicted in block <b>370</b> of <figref idref="DRAWINGS">FIG. 3</figref>, may generate a new entry <b>635</b>, for example. The new entry <b>635</b> may comprise fields such as tag <b>665</b> and/or a core identifier <b>675</b> and the values of the new entry <b>635</b> may be inserted into the flow table <b>440</b>. In one embodiment, the new entry <b>635</b> may map to one of the sets <b>620</b>-A to <b>620</b>-L. In one embodiment, the tag <b>665</b> of the new entry <b>635</b> may not equal the tag field of any entry in the sets <b>620</b>-A to <b>620</b>-L and as a result the validity of at least one set <b>620</b> may be marked invalid.</p>
<p id="p-0046" num="0045">In one embodiment, the logic <b>174</b> may replace the tag <b>660</b> and the core identifier <b>670</b> of an invalid entry <b>630</b>-AA with the tag <b>665</b> and the core identifier <b>675</b> of the new entry <b>635</b>. In one embodiment, the logic <b>174</b> may configure the age <b>650</b> to a least value to represent that the entry <b>630</b>-M is a youngest entry (or the most recently updated entry) and may also configure the validity <b>640</b> to represent that the new entry <b>635</b> has replaced the entry <b>630</b>-AA. In one embodiment, the logic <b>174</b> may replace one of the entries <b>630</b> with the new entry <b>635</b> and the entry <b>630</b> that is to be replaced may be selected based on the value stored in the age fields of the entries <b>630</b>.</p>
<p id="p-0047" num="0046">In one embodiment, the entry <b>630</b> with oldest age value may be selected for replacement. In one embodiment, if a value in the tag field of the entry <b>630</b>, selected for replacement, equals a value of the tag of the new entry, the validity value may be retained while replacing the value of the core identifier field of the entry <b>630</b> with the core identifier value of the new entry <b>635</b>. Also, the value of age field may be set to represent that the new entry is the youngest.</p>
<p id="p-0048" num="0047">Certain features of the invention have been described with reference to example embodiments. However, the description is not intended to be construed in a limiting sense. Various modifications of the example embodiments, as well as other embodiments of the invention, which are apparent to persons skilled in the art to which the invention pertains are deemed to lie within the spirit and scope of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A non-transitory computer readable medium containing instructions, which when executed, cause a processor to:
<claim-text>store data associating respective packet flows with respective ones of multiple processor units;</claim-text>
<claim-text>store data associating a first packet flow with a first of the multiple processor units;</claim-text>
<claim-text>cause packets in the first packet flow to be directed to the first of the multiple processor units based on the data associating the first packet flow with the first of the multiple processor units;</claim-text>
<claim-text>determine a second, different, one of the multiple processor units based on a socket call, the socket corresponding to the first packet flow, the socket call to determine an id of the second, different, one of the multiple processor units;</claim-text>
<claim-text>store data to associate the first packet flow with the second of the multiple processor units;</claim-text>
<claim-text>cause packets in the first packet flow to be directed to the second of the multiple processor units based on the data associating the first packet flow with the second of the multiple processor units determined to be associated with the socket call; and</claim-text>
<claim-text>if a packet belongs to a packet flow not represented in the data associating respective packet flows with respective ones of multiple processor units, causing the packet to be directed to a one of the multiple processor units based on a receive side scaling indirection table indexed by a hash of packet header flow data, wherein the receive side scaling indirection table is capable of mapping multiple packet flows to the same receive side scaling indirection table entry.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the socket call comprises an operating system call invoked in response to an application executed by the second one of the multiple processor units.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions, which when executed, cause the processor to determine a second, different, one of the multiple processor units associated with the socket call comprise instructions which when executed, cause the processor to determine a unit id.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions, which when executed, cause the processor to cause packets in the packet flow to be directed to the first of the multiple processor units comprise instructions, which when executed, cause the processor to perform a hash operation on flow id data in a packet header.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions, which when executed, cause the processor to re-provision an application from the first of the multiple processor units to the second of the multiple processor units, the application to cause the socket call to be invoked.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the multiple processor units comprise multiple respective processor cores.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions, which when executed, cause the processor to store data to associate the packet flow with the second of the multiple processor units comprise instructions to store data based on data included in a packet header and an associated id of the second of the multiple processor units.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A device, comprising circuitry to:
<claim-text>store data associating respective packet flows with respective ones of multiple processor units;</claim-text>
<claim-text>store data associating a first packet flow with a first of the multiple processor units;</claim-text>
<claim-text>cause packets in the first packet flow to be directed to the first of the multiple processor units based on the data associating the first packet flow with the first of the multiple processor units;</claim-text>
<claim-text>determine a second, different, one of the multiple processor units based on a socket call, the socket corresponding to the first packet flow, the socket call to determine an id of the second, different, one of the multiple processor units;</claim-text>
<claim-text>store data to associate the first packet flow with the second of the multiple processor units;</claim-text>
<claim-text>cause packets in the first packet flow to be directed to the second of the multiple processor units based on the data associating the first packet flow with the second of the multiple processor units determined to be associated with the socket call; and</claim-text>
<claim-text>if a packet belongs to a packet flow not represented in the data associating respective packet flows with respective ones of multiple processor units, cause the packet to be directed to a one of the multiple processor units based on a receive side scaling indirection table indexed by a hash of packet header flow data, wherein the receive side scaling indirection table is capable of mapping multiple packet flows to the same receive side scaling indirection table entry.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the socket call comprises an operating system call invoked in response to an application executed by the second one of the multiple processor units.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein circuitry to determine a second, different, one of the multiple processor units associated with the socket call comprises circuitry to determine a unit id.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein circuitry to cause packets in the packet flow to be directed to the first of the multiple processor units comprises circuitry to perform a hash operation on flow id data in a packet header.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the multiple processor units comprise multiple respective processor cores.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the circuitry to store data to associate the packet flow with the second of the multiple processor units comprises circuitry to store data based on data included in a packet header and an associated id of the second of the multiple processor units.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the device comprises a network interface controller.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the device comprises the multiple processor units.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A method comprising:
<claim-text>storing data associating respective packet flows with respective ones of multiple processor units;</claim-text>
<claim-text>storing data associating a first packet flow with a first of the multiple processor units;</claim-text>
<claim-text>causing packets in the first packet flow to be directed to the first of the multiple processor units based on the data associating the first packet flow with the first of the multiple processor units;</claim-text>
<claim-text>determining a second, different, one of the multiple processor units based on a socket call, the socket corresponding to the first packet flow, the socket call to determine an id of the second, different, one of the multiple processor units;</claim-text>
<claim-text>storing data to associate the first packet flow with the second of the multiple processor units;</claim-text>
<claim-text>causing packets in the first packet flow to be directed to the second of the multiple processor units based on the data associating the first packet flow with the second of the multiple processor units determined to be associated with the socket call; and</claim-text>
<claim-text>if a packet belongs to a packet flow not represented in the data associating respective packet flows with respective ones of multiple processor units, causing the packet to be directed to a one of the multiple processor units based on a receive side scaling indirection table indexed by a hash of packet header flow data, wherein the receive side scaling indirection table is capable of mapping multiple packet flows to the same receive side scaling indirection table entry.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the socket call comprises an operating system call invoked in response to an application executed by the second one of the multiple processor units.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the determining a second, different, one of the multiple processor units associated with a socket call comprises determining a unit id.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the causing packets in the packet flow to be directed to the first of the multiple processor units comprises causing a hash operation on flow id data in a packet header.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising re-provisioning an application from the first of the multiple processor units to the second of the multiple processor units, the application to cause the socket call to be invoked.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the multiple processor units comprise multiple respective processor cores.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the storing data to associate the packet flow with the second of the multiple processor units comprises storing data based on data included in a packet header and an associated id of the second of the multiple processor units. </claim-text>
</claim>
</claims>
</us-patent-grant>
