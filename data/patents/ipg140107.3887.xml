<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624954-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624954</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13097481</doc-number>
<date>20110429</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>251</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>14</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348 1407</main-classification>
<further-classification>348 1401</further-classification>
</classification-national>
<invention-title id="d2e53">Methods and systems for sharing content via a collaboration screen</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5400069</doc-number>
<kind>A</kind>
<name>Braun et al.</name>
<date>19950300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1416</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5956180</doc-number>
<kind>A</kind>
<name>Bass et al.</name>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>359479</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7605719</doc-number>
<kind>B1</kind>
<name>Wenger et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7703013</doc-number>
<kind>B1</kind>
<name>Bauermeister et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2008/0246834</doc-number>
<kind>A1</kind>
<name>Lunde et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1409</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2008/0297589</doc-number>
<kind>A1</kind>
<name>Kurtz et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1416</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2010/0257457</doc-number>
<kind>A1</kind>
<name>De Goes</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00008">
<othercit>Lueble et al&#x2dc;&#x201c;Collaborative Environments Supported by large Screen Displays&#x201d;&#x2dc;CSCE'02&#x2dc;Nov. 2002&#x2dc;pp. 2.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00009">
<othercit>Pavlovych et al&#x2dc;&#x201c;Effect of Screen Configuration and Interaction Devices in Shared Display Groupware&#x201d;&#x2dc;HCC'O8&#x2dc;Oct. 31, 2008&#x2dc;pp. 49-56.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00010">
<othercit>Sullivan et al&#x2dc;&#x201c;Active Collaboration Room&#x201d;&#x2dc;Cisco White Paper&#x2dc;May 2010&#x2dc;pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348 1401- 1416</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 E5144</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 E5104</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 E5137</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715761</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>455566</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345  11</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345178</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120274727</doc-number>
<kind>A1</kind>
<date>20121101</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Robinson</last-name>
<first-name>Ian N.</first-name>
<address>
<city>Pebble Beach</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Tan</last-name>
<first-name>Kar-Han</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Gelb</last-name>
<first-name>Daniel George</first-name>
<address>
<city>Redwood City</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Robinson</last-name>
<first-name>Ian N.</first-name>
<address>
<city>Pebble Beach</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Tan</last-name>
<first-name>Kar-Han</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Gelb</last-name>
<first-name>Daniel George</first-name>
<address>
<city>Redwood City</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hewlett-Packard Developement Company, L.P.</orgname>
<role>02</role>
<address>
<city>Houston</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kuntz</last-name>
<first-name>Curtis</first-name>
<department>2656</department>
</primary-examiner>
<assistant-examiner>
<last-name>Joshi</last-name>
<first-name>Sunita</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Video conferencing methods and systems that enable shared content to be displayed in a separate window within a screen or in a separate display are described. In one aspect, a method for establishing a video conference with shared content using a computing device includes capturing images of a first participant through a screen using a camera. The screen is located between the first participant and the camera. The method also includes projecting images of a second participant on the screen to be viewed by the first participant using a projector, and displaying shared content separate from the images of the second participant. The shared content is to be presented in different format than the images of the second participant presented on the screen.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="162.31mm" wi="199.98mm" file="US08624954-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="140.38mm" wi="155.70mm" file="US08624954-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="202.52mm" wi="171.11mm" orientation="landscape" file="US08624954-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="206.33mm" wi="173.06mm" orientation="landscape" file="US08624954-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="135.89mm" wi="162.73mm" file="US08624954-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="244.18mm" wi="166.62mm" file="US08624954-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="189.06mm" wi="167.22mm" orientation="landscape" file="US08624954-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="195.41mm" wi="180.09mm" orientation="landscape" file="US08624954-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="191.01mm" wi="149.35mm" orientation="landscape" file="US08624954-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">This disclosure relates to video-conferencing technology.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Video conferencing enables participants located at two or more sites to simultaneously interact via two-way video and audio transmissions. A video conference can be as simple as a conversation between two participants located at different sites or involve discussions between many participants each located at different sites and include any shared content such as a video presentation. As high-speed network connectivity has become more widely available at lower cost and the cost of video capture and display technologies continues to decrease, video conferencing conducted over networks between participants in faraway places has become increasing popular. Video conferencing is typically conducted using video cameras and webcams to capture images of the participants; computer monitors, televisions, and projectors to display video images of the participants and any shared video content; microphones and speakers to capture and project voices; and computers to process and send the video and audio signals over a network.</p>
<p id="p-0004" num="0003">However, many video-conferencing systems are limited with respect to the manner in which shared content, such as photographs, are displayed. For example, consider video-conferencing systems implemented with a screen and a projector to project images of participants and shared content onto the screen. The projector projects the shared content and the participants as a single image onto the same screen. As a result, the resolution of the photographs is lower than desired. Designers and users of video-conference technologies continue to seek improvements in the video-conferencing experience.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 1</figref> shows an example of two video-conferencing participants interacting through a screen.</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 2</figref> shows a top-plan view and schematic representation of an example visual-collaborative system.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 3</figref> shows a top-plan view and schematic representation of an example visual-collaborative system.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 4</figref> shows an example of two video-conferencing participants interacting through the screen with a separate display for presenting shared content.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIGS. 5A-5B</figref> show a local participant repositioning and using a display positioned off to the side of a screen.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 6</figref> shows a top-plan view and schematic representation of an example visual-collaborative system.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 7</figref> shows a top-plan view and schematic representation of an example visual-collaborative system.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 8</figref> shows a schematic representation of a computing device.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0013" num="0012">Video conferencing methods and systems that enable shared content to be displayed in a separate window within a screen or in a separate display are described. The separate window or display can be used to present shared content with a desired format.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1</figref> shows an example of two video-conferencing participants interacting through a screen <b>102</b>. The screen <b>102</b> enables a local participant <b>104</b> to interact with a remotely located participant <b>106</b>. The remote participant <b>106</b> can be presented on the screen <b>102</b> to appear substantially life size to the local participant <b>104</b>. A camera <b>108</b> is positioned behind the screen <b>102</b> at approximately eye level to the local participant <b>104</b>, and the screen <b>102</b>, described below, enables the camera <b>108</b> to capture images of the local participant <b>104</b> through the screen <b>102</b>. The camera <b>108</b> can be positioned at a distance from the rear surface of the screen <b>102</b>, so that its viewpoint is roughly equivalent to that of the remote participant <b>106</b>. In order to capture gestures made by the local participant <b>104</b>, the camera <b>108</b> can be positioned so that camera's field of view encompasses approximately the entire screen <b>102</b>. Images of the participants <b>104</b> and <b>106</b> are captured at their respective sites and processed so that perceived eye contact and accurate gaze awareness is created between the participants. For example, as shown in <figref idref="DRAWINGS">FIG. 1</figref>, the image of the remote participant <b>106</b> is projected onto the screen <b>102</b> so that when the local participant <b>104</b> looks at the remote participant's face, local participant <b>102</b> looks along a line of sight represented by dashed line <b>110</b> that passes approximately between the eyes of the remote participant's image and into the lens of the camera <b>108</b>. As a result, the local participant <b>104</b> perceives eye contact with the remote participant <b>106</b>, and by looking into the lens of the camera <b>108</b>, that same experience can be recreated at the remote participant's site.</p>
<p id="p-0015" num="0014">In the example shown in <figref idref="DRAWINGS">FIG. 1</figref>, the screen <b>102</b> is also used to present shared content within a window <b>112</b> projected onto the screen <b>102</b>. The window <b>112</b> can also be presented at the remote participant's sites with the correct orientation. In order to display the window <b>112</b> for the local participant <b>104</b> with a desired resolution and/or degree of blending with the image of the remote participant presented on the screen <b>102</b>, two separate projectors can be used.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2</figref> shows a top-plan view and schematic representation of an example visual-collaborative system <b>200</b>. The system <b>200</b> includes the screen <b>102</b>, the camera <b>108</b>, a projector <b>202</b>, a window projector <b>204</b>, and a computing device <b>206</b>. The projector <b>202</b> projects the image of the remote participant <b>106</b>, and the window projector <b>204</b> projects only the window <b>112</b>. The camera <b>108</b> and projectors <b>202</b> and <b>204</b> are connected to the computing device <b>206</b>, and the camera <b>108</b> and projectors <b>202</b> and <b>204</b> are positioned to face the rear surface <b>208</b> of the screen <b>102</b>. In certain system <b>200</b> embodiments, the screen <b>102</b> can be composed of a relatively low concentration of light diffusing particles that diffuses light striking the rear surface <b>208</b> within a range of angles. The projectors <b>202</b> and <b>204</b> are positioned to project images onto the rear surface <b>208</b> within this range of angles to enable the local participant <b>102</b> facing the front surface <b>210</b> of the screen <b>102</b> to see the images projected by the projectors <b>202</b> and <b>204</b>. The screen <b>102</b> also transmits light scattered from objects that face the front surface <b>210</b>. In other words, the camera <b>108</b> is positioned to face the rear surface <b>208</b> so that light scattered off of objects that face the front surface <b>210</b> pass through the screen <b>102</b> and are captured as images by the camera <b>108</b>. Alternatively, the screen <b>102</b> can be a holographic film that accepts light from the projector <b>202</b> within a first range of angles and transmits light that is visible to the local participant <b>104</b> within a second range of viewing angles. The holographic film is otherwise transparent. In this case, the widow projector <b>204</b> can be configured to project from a location close to the projector <b>202</b>.</p>
<p id="p-0017" num="0016">The camera <b>108</b> generates a video data stream encoding images captured through the screen <b>102</b>. The video streams can then be sent over a network, such as the Internet or a local area network, to the remote participant's site for video processing. The computing device <b>206</b> also receives video data streams encoding images captured at the remote participant's site and the shared content and processes the video streams so that the shared content is projected by the window projector <b>204</b> onto the window <b>112</b> and the images captured of the remote participant <b>106</b> are projected onto the screen <b>102</b>.</p>
<p id="p-0018" num="0017">In order to prevent ambient light from striking the rear surface <b>208</b> and reducing the contrast between the projected and captured images, the system <b>200</b> can include a housing (not shown) that encloses the camera <b>108</b> and projectors <b>202</b> and <b>204</b>. The screen <b>102</b> is located within an opening of the housing to only allow light to enter and exit the housing through the screen <b>102</b>.</p>
<p id="p-0019" num="0018">As shown in <figref idref="DRAWINGS">FIG. 2</figref>, the system <b>200</b> includes filters A and B. The two A filters are positioned so that light output from the projectors <b>202</b> and <b>204</b> passes through the A filters, and the filter B is positioned so that light captured by the camera <b>108</b> passes through filter B. The filters A and B prevent light produced by the projectors <b>202</b> and <b>204</b> and scattered back by the screen <b>102</b> toward the camera <b>108</b> from interfering with light transmitted through the screen <b>102</b> and captured by the camera <b>108</b>. Note that the filters A and B are shown separately from the projectors <b>202</b> and <b>204</b> for the sake of convenience. In practice, the filters A and B can also be incorporated into the camera <b>108</b> and projectors <b>202</b> and <b>204</b> optical components.</p>
<p id="p-0020" num="0019">In certain embodiments, filter B transmits a first set of wavelength ranges that when combined create the visual sensation of a much broader range of colors in images captured by the camera <b>108</b>, while the A filters transmit a second set of wavelength ranges that are different from the first set of wavelength ranges. The second set of wavelength ranges can also be used to create the visual sensation of a much broader range of colors. In other words, the A and B filters in combination block the wavelength ranges that are used to create images on the screen <b>102</b> from entering the camera <b>108</b>. Even though the wavelength ranges used to produce images on the screen <b>102</b> are different from the wavelengths of light used to capture images by the camera <b>108</b>, the projectors <b>202</b> and <b>204</b> can still use the colors transmitted through the two A filters to project full color images, and light transmitted through filter B can still be used to capture full color images. It is the component wavelengths of the light used to project and capture the full color images that are prevented from interfering.</p>
<p id="p-0021" num="0020">In other embodiments, the A and B filters can be polarizing filters that prevent the light produced by the projectors <b>202</b> and <b>204</b> from interfering with light transmitted through the screen <b>102</b> and captured by the camera <b>108</b>. For example, the A and B filters can be linear polarizing filters oriented so that A filters pass only horizontally polarized light and the B filter passes only vertically polarized light, or the A and B filters can be circular polarizing filters where the A filters pass only right-circularly polarized light and the B filter passes only left-circularly polarized light.</p>
<p id="p-0022" num="0021">In certain embodiments, in order to prevent the window <b>112</b> from overlapping with a portion of the full screen <b>102</b> image of the remote participant, the projector <b>202</b> projects the image of the remote participant <b>106</b> with a blank region in which the window <b>112</b> is to be projected onto the screen <b>102</b> using the window projector <b>204</b>. For example, as shown in <figref idref="DRAWINGS">FIG. 2</figref>, when the participants <b>104</b> and <b>106</b> desire to present shared content in the separate window <b>112</b>, the projector <b>202</b> projects the image of the remote participant onto the rear surface <b>208</b> of the screen <b>102</b> with a blank region <b>212</b> of a particular size and shape and located away from the center of the screen <b>102</b>. The window projector <b>204</b> projects the window <b>112</b> onto the blank region <b>112</b> with the same size and shape as the blank region <b>212</b>.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 3</figref> shows a top-plan view and schematic representation of an example visual-collaborative system <b>300</b>. The system <b>300</b> is similar to the system <b>200</b> with many of the same components including camera <b>108</b>, projectors <b>202</b> and <b>204</b>, A and B filters, and a computing device <b>206</b>, but the screen <b>102</b> associated with the system <b>200</b> is replaced by a front projection screen <b>302</b>. The camera <b>108</b> faces the rear surface <b>304</b> of the screen <b>302</b> and captures images through the screen <b>302</b>. The projectors <b>202</b> and <b>204</b> project images onto the front surface <b>306</b> of the screen <b>302</b>. In particular, the projector <b>202</b> projects the image of the remote participant onto the front surface <b>306</b> of the screen <b>302</b> with a blank region <b>308</b> of a particular size and shape and located away from the center of the screen <b>102</b>. The window projector <b>204</b> projects the window <b>112</b> onto the blank region <b>112</b> with the same size and shape as the blank region <b>308</b>.</p>
<p id="p-0024" num="0023">The relative intensities of the window <b>112</b> and the image of the remote participant <b>106</b> can be separately controlled. For example, when the local participant <b>104</b> desires to pay close attention to the content displayed in the window <b>112</b>, the participant <b>104</b> can increase the intensity level of the window <b>112</b> above that of the image of the remote participant <b>106</b> presented on the screen <b>102</b>. In addition, the window projector <b>204</b> can be a high-resolution projector that can be adjusted to display the shared content with a higher resolution than the image of the remote participant <b>106</b> presented on the display <b>102</b> or adjusted to display the shared content with approximately the same resolution and intensity as the projector <b>202</b>. The window projector <b>204</b> can be configured to project shared content with a higher dynamic range of colors than the projector <b>202</b>. The window projector <b>204</b> can be configured to project images with a larger color gamut than the projector <b>202</b>. The window projector <b>204</b> can be operated to alternate projecting right-eye and left-eye views to produce three-dimensional images for the local participant <b>104</b>. In other embodiments, a second window projector (not shown) can be included in the systems <b>200</b> and <b>300</b> such that the window projector <b>204</b> and the second window projector can project right-eye and left-eye views of three-dimensional images to create a three-dimensional viewing experience for the local participant <b>104</b>.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 4</figref> shows an example of two video-conferencing participants interacting through the screen <b>102</b> and includes a separate display <b>402</b> for displaying shared content. As described above with reference to <figref idref="DRAWINGS">FIGS. 1-3</figref>, the screen <b>102</b> enables the local participant <b>104</b> to interact with the remote participant <b>106</b> in life size and the camera <b>108</b> is positioned behind the screen <b>102</b> at approximately the local participant's eye level to create the perception of eye contact between the local participant <b>102</b> and the remote participant <b>106</b>. As shown in the example of <figref idref="DRAWINGS">FIG. 4</figref>, the display <b>402</b> is connected to a frame <b>404</b> surrounding the screen <b>102</b> or wall by top and bottom hinges <b>406</b> and <b>408</b>. The display <b>402</b> is mounted and positioned in a lower portion of the screen <b>102</b> so that the local participant <b>104</b> can view the shared content and view the remote participant <b>106</b>. The top and bottom hinges <b>406</b> and <b>408</b> enable the local participant to adjust the horizontal position of the display <b>402</b>.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 5A</figref> shows a top-view of the local participant <b>104</b> in the process of repositioning the display <b>402</b> off to the side of the screen <b>102</b>. <figref idref="DRAWINGS">FIG. 5B</figref> shows the display <b>402</b> positioned to the side of the screen <b>102</b> and an analogous display <b>410</b> positioned in a similar manner and presenting the same shared content at the remote participant's site. In this example, the participants <b>104</b> and <b>106</b> can each refer to the same shared content side by side without covering portions of their respective screens. Alternatively, the hinges <b>406</b> and <b>408</b> can be replaced by a single hinge arm that allows the display <b>402</b> to be moved horizontally and vertically.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 6</figref> shows a top-plan view and schematic representation of an example visual-collaborative system <b>600</b>. The system <b>600</b> is similar to the system <b>200</b> in that the system <b>600</b> includes the rear projection screen <b>102</b>, projector <b>202</b>, camera <b>108</b>, and computing device <b>206</b> that are operated in the same manner described above with reference to <figref idref="DRAWINGS">FIG. 2</figref>. However, the window projector <b>204</b> of the system <b>200</b> is replaced in the system <b>600</b> by an opaque, flat panel display <b>602</b>. As shown in the example of <figref idref="DRAWINGS">FIG. 6</figref>, the projector <b>202</b>, camera <b>108</b>, and display <b>602</b> are connected to the computing device <b>206</b>. The camera <b>108</b> generates a video data stream encoding images captured through the screen <b>102</b>. The video streams can be sent over a network to the remote participant's site for video processing. The computing device <b>206</b> also receives video data streams encoding images captured at the remote participant's site. The projector <b>202</b> projects the video streams of the remote participant onto the screen <b>102</b> and any shared content is presented on the display <b>602</b>.</p>
<p id="p-0028" num="0027">The display <b>602</b> can be a high-resolution display to display shared content with a higher resolution than the images projected by the projector <b>202</b>. The display <b>602</b> can also display shared content with a higher dynamic range of colors than the projector <b>202</b>. The display <b>602</b> can be configured to display images with a larger color gamut than the projector <b>202</b>. The display <b>602</b> can be a three-dimensional display or a glasses-free, three-dimensional display.</p>
<p id="p-0029" num="0028">The display <b>602</b> can include a touchscreen so that when the display <b>402</b> is positioned in front of the screen <b>102</b>, as shown in <figref idref="DRAWINGS">FIG. 6</figref>, it is still possible for the local participant <b>104</b> to convey gestures regarding the shared to the remote participant's display. For example, as shown in <figref idref="DRAWINGS">FIG. 6</figref>, it is not possible to capture a portion of the local participant's image obscured by the display <b>602</b>. However, the touchscreen of the display <b>602</b> can be used to generate a cursor on the remote participant's display when the local participant <b>104</b> touches the touchscreen of the display <b>602</b> to identify the subject matter the local participant <b>104</b> would like to call to the attention of the remote participant <b>106</b>. At the location on the touchscreen touched by the local participant <b>104</b>, a cursor appears at approximately the same location on the display of the remote participant <b>106</b>. Alternatively, the local participant <b>104</b> can write or draw on the screen of the display <b>602</b> with a stylus or the local participant's finger and corresponding markings appear in the same locations on the display of the remote participant <b>106</b>.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 7</figref> shows a top-plan view and schematic representation of an example visual-collaborative system <b>700</b>. The system <b>700</b> is similar to the system <b>600</b>, except the opaque display <b>602</b> is replaced by a high-resolution, transparent display <b>702</b>. The background of the remote participant's site projected onto the screen <b>102</b> may interfere with viewing the shared content presented on the transparent display <b>702</b>. As a result, the projector <b>202</b> can be operated as described above with reference to <figref idref="DRAWINGS">FIG. 2</figref> to project a blank or white region with the same size and shape and location of the display <b>702</b> to enhance the quality of the shared content presented on the display <b>702</b>. In certain embodiments, the transparent display <b>702</b> can be a transparent organic light-emitting diode (&#x201c;OLED&#x201d;) display When the display <b>702</b> is a transparent OLED-based display, the projector <b>202</b> can be operated to present a black region on the screen <b>102</b> behind the display <b>702</b> In other embodiments, the transparent display <b>702</b> can be a transparent liquid crystal display. When the display <b>702</b> is a transparent LCD-based display, the projector <b>202</b> can be operated to present a white region on the screen <b>102</b> behind the display <b>702</b>. In embodiments using a transparent display <b>702</b>, the filter B of the camera <b>108</b> may not have to be configured to reject light from the display <b>702</b>, because the area in the camera-captured image that corresponds to the display is replaced by a blank rectangle as a background for the display at the receiving system.</p>
<p id="p-0031" num="0030">The display <b>702</b> can be a high-resolution display to present shared content with a higher resolution than the images projected by the projector <b>202</b>. The display <b>702</b> can also present shared content with a higher dynamic range of colors than the projector <b>202</b>. The display <b>702</b> can be configured to present images with a larger color gamut than the projector <b>202</b>. The display <b>702</b> can be a three-dimensional display or a glasses-free, three-dimensional display.</p>
<p id="p-0032" num="0031">The video-conferencing systems <b>200</b>, <b>300</b>, and <b>600</b> may also include a signal means to assist the local participant <b>104</b> and remote participant <b>106</b> to set up their respective shared content displays in the same way. For example, when the shared content is projected in the window <b>112</b> described above with reference to systems <b>200</b> and <b>300</b>, the window projector <b>204</b> of the local participant <b>104</b> and a similar window projection of the remote participant <b>106</b> conic on at approximately the same time and project the shared content so that the shared content windows appear to be opposite one another. Alternatively, when the shared content is presented on the display <b>402</b> off to the side, as shown in <figref idref="DRAWINGS">FIG. 5B</figref>, the local participant <b>104</b> and the remote participant <b>106</b> are prompted to set up the displays <b>402</b> and <b>410</b> appropriately. In another embodiment, the system <b>600</b> may include sensors that detect the position of the display <b>402</b> in front of the screen <b>102</b>.</p>
<p id="p-0033" num="0032">Methods described above can also work with video-conferencing systems that provide for different forms of displaying shared content or do not include a window projector or separate display. For example, suppose the local participant <b>104</b> is using one of the systems <b>200</b>, <b>300</b>, and <b>600</b> described above and the remote participant <b>106</b> uses a video-conferencing system that is not capable of separately displaying shared content in either a separate window on a screen or on a separate display. The remote participant <b>106</b> can open a shared content window in a matching position to that of the local participant <b>104</b> using the same projector the remote participant uses to project the image of the local participant <b>104</b> onto the remote participant's screen.</p>
<p id="p-0034" num="0033">The computing device <b>206</b> can be a desktop computer, a laptop, or any other suitable device configured to carry out video and image processing. In certain embodiments, the computing device <b>206</b> can be integrated in the projector <b>202</b> or the camera <b>108</b>. <figref idref="DRAWINGS">FIG. 8</figref> shows a schematic representation of a computing device <b>800</b>. The device <b>800</b> may include one or more processors <b>802</b>; one or more projector interfaces <b>804</b>; a video or camera interface <b>806</b>; one or more network interfaces <b>808</b>, such as a Local Area Network LAN, a wireless 802.11x LAN, a 3G mobile WAN or a WiMax WAN; and one or more computer-readable mediums <b>810</b>. Each of these components is operatively coupled to one or more buses <b>812</b>. For example, the bus <b>812</b> can be an EISA, a PCI, a USB, a FireWire, a NuBus, or a PDS.</p>
<p id="p-0035" num="0034">The computer-readable medium <b>810</b> can be any suitable medium that participates in providing instructions to the processor <b>802</b> for execution. For example, the computer-readable medium <b>810</b> can be non-volatile media, such as an optical disk, a magnetic disk, or a magnetic disk drive; and volatile media, such as memory. The computer-readable medium <b>810</b> can also store computer-readable instructions, including word processors, browsers, email, Instant Messaging, media players, and telephony software.</p>
<p id="p-0036" num="0035">The computer-readable medium <b>810</b> may also store an operating system <b>814</b>, such as Mac OS, MS Windows, Unix, or Linux; network applications <b>816</b>; and a video-conferencing application <b>818</b>. The operating system <b>814</b> can be multi-user, multiprocessing, multitasking, multithreading, and real-time. The operating system <b>814</b> can also perform basic tasks such as recognizing input from input devices, such as a keyboard, a keypad, or a mouse; sending output to a projector and a camera; keeping track of files and directories on medium <b>810</b>; controlling peripheral devices, such as disk drives, printers, image capture device; and managing traffic on the one or more buses <b>812</b>. The network applications <b>816</b> includes various components for establishing and maintaining network connections, such as computer-readable instructions for implementing communication protocols including TCP/IP, HTTP, Ethernet, USB, and FireWire.</p>
<p id="p-0037" num="0036">The video-conference application <b>818</b> provides various computer-readable instruction components for sharing content between video conference participants, as described above. In certain embodiments, some or all of the processes performed by the application <b>818</b> can be integrated into the operating system <b>814</b>. In certain embodiments, the processes can be at least partially implemented in digital electronic circuitry, or in computer hardware, or in any combination thereof.</p>
<p id="p-0038" num="0037">Video conferencing methods and systems are not intended to be limited to the system components described above. Video conferencing methods and systems can be implemented using any one of the various systems and methods for filtering, projecting, sharing content, capturing images, and variety of screens and displays described in the following three U.S. patent applications owned by the Hewlett Packard Co., all three of which are hereby incorporated by reference in their entirety: U.S. patent application filed on Apr. 29, 2009 having U.S. Ser. No. 12/432,550; U.S. patent application filed on Jan. 28, 2009, having U.S. Ser. No. 12/321,996; and U.S. patent application filed Jan. 27, 2010 having U.S. Ser. No. 12/694,743.</p>
<p id="p-0039" num="0038">The foregoing description, for purposes of explanation, used specific nomenclature to provide a thorough understanding of the disclosure. However, it will be apparent to one skilled in the art that the specific details are not required in order to practice the systems and methods described herein. The foregoing descriptions of specific examples are presented for purposes of illustration and description. They are not intended to be exhaustive of or to limit this disclosure to the precise forms described. Obviously, many modifications and variations are possible in view of the above teachings. The examples are shown and described in order to best explain the principles of this disclosure and practical applications, to thereby enable others skilled in the art to best utilize this disclosure and various examples with various modifications as are suited to the particular use contemplated. It is intended that the scope of this disclosure be defined by the following claims and their equivalents:</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for establishing a video conference with shared content, the method comprising:
<claim-text>capturing images of a first participant through a screen using a camera, wherein the captured images are to be communicated to a second participant;</claim-text>
<claim-text>projecting, by a first projector, images of the second participant on the screen, wherein the first projector is to cause a blank region to be displayed on the screen at an inset location of the projected images of the second participant; and</claim-text>
<claim-text>projecting, by a second projector, the shared content onto the blank region, the projected shared content having approximately a same size and shape as the blank region, wherein the shared content comprises content that is shared between the first participant and the second participant.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein projecting the shared content onto the blank region further comprises projecting the shared content with a higher intensity level than the intensity level of the images of the second participant.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein projecting the shared content onto the blank region further comprises projecting the shared content with a higher dynamic range than the projected images of the second participant.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein projecting the shared content onto the blank region further comprises projecting the shared content with a larger color gamut than the projected images of the second participant.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein projecting the shared content onto the blank region further comprises projecting the shared content for three-dimensional viewing.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising causing the blank region to be displayed in a location of the screen that is away from a center of the screen.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A method for establishing a video conference with shared content, the method comprising:
<claim-text>capturing images of a first participant through a screen using a camera, wherein the captured images are to be communicated to a second participant;</claim-text>
<claim-text>projecting, by a projector, images of the second participant on the screen;</claim-text>
<claim-text>projecting, by the projector, a predetermined region on the screen to have a uniform color, wherein the predetermined region is inset within the projected images of the second participant on the screen; and</claim-text>
<claim-text>displaying the shared content on a transparent flat panel display, wherein the transparent flat panel display is positioned in front of the predetermined region projected onto the screen and wherein the predetermined region on the screen has approximately a same size and shape as the transparent flat panel display, wherein the shared content comprises content that is shared between the first participant and the second participant.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the transparent flat panel display is positioned on an opposite side of the screen as the projector.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the transparent flat panel display is positioned at a location offset from a center of the screen.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the transparent flat panel display further comprises one of a transparent light-emitting diode display and a transparent liquid crystal display.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the predetermined region has a quadrilateral shape and the uniform color of the predetermined region is one of black and white.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein displaying the shared content on the transparent flat panel display further comprises displaying the shared content with a higher intensity level than the intensity level of the projected images of the second participant on the screen.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein displaying the shared content on the transparent flat panel display further comprises displaying the shared content with a higher dynamic range than the projected images of the second participant.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein displaying the shared content on the transparent flat panel display further comprises displaying the shared content with a larger color gamut than the projected images of the second participant.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein displaying the shared content on the transparent flat panel display further comprises displaying the shared content on the transparent flat panel display for three-dimensional viewing.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A non-transitory computer-readable medium having instructions encoded thereon for establishing a video conference with shared content, wherein the instructions are to cause one or more processors to:
<claim-text>cause a camera to capture images of a first participant through a screen to be communicated to a second participant;</claim-text>
<claim-text>cause a first projector to project images of a second participant on the screen while causing a blank region to be displayed on the screen at an inset location of the projected images of the second participant; and</claim-text>
<claim-text>cause a second projector to project shared content onto the blank region, the projected shared content having approximately a same size and shape as the blank region, and wherein the shared content comprises content that is shared between the first participant and the second participant.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the second projector is to project the shared content onto the blank region with at least one of a higher intensity level, higher dynamic range, and larger color gamut than the first projector is to project the images of the second participant.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the second projector is to project the shared content onto the blank region for three-dimensional viewing.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the second projector is to further cause the blank region to be displayed at a location of the screen that is away from a center of the screen. </claim-text>
</claim>
</claims>
</us-patent-grant>
