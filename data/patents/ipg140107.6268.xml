<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627414-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627414</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12720008</doc-number>
<date>20100309</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>912</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>7</main-group>
<subgroup>04</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>12</main-group>
<subgroup>14</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>29</main-group>
<subgroup>06</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>9</main-group>
<subgroup>32</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>167</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>726  4</main-classification>
<further-classification>726  7</further-classification>
<further-classification>726 23</further-classification>
<further-classification>726 27</further-classification>
<further-classification>713165</further-classification>
<further-classification>713166</further-classification>
<further-classification>713168</further-classification>
<further-classification>709212</further-classification>
<further-classification>709217</further-classification>
</classification-national>
<invention-title id="d2e53">Methods and apparatuses for user-verifiable execution of security-sensitive code</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2007/0067435</doc-number>
<kind>A1</kind>
<name>Landis et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00002">
<othercit>Singaravelu, L. et al., Reducing TCB Complexity for Security-Sensitive Applications: Three Case Studies, Eurosys '06, Apr. 18-21, 2006, Leuven, Belgium, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00003">
<othercit>Ta-Min, R. et al., Splitting Interfaces: Making Trust Between Applications and Operating Systems Configurable, Department of Computer Science, University of Toronto, 1-14, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00004">
<othercit>Wahbe, R. et al., Efficient Software-Based Fault Isolation, Computer Science Division, University of California, SIGOPS, 1993, 203-216.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00005">
<othercit>Yang, J. et al., Using Hypervisor to Provide Data Secrecy for User Applications on a Per-Page Basis, VEE '08, Mar. 5-7, 2008, Seattle, Washington, 71-80.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00006">
<othercit>TPM Main Part 1: Design Principles, Specification Version 1.2, Level 2 Revision 103, Jul. 9, 2007, TCG 2003-2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00007">
<othercit>TPM Main Part 2: TPM Structures, Specification Version 1.2, Level 2 Revision 103, Oct. 26, 2006, TCG 2003-2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00008">
<othercit>TPM Main Part 3: Commands, Specification Version 1.2, Level 2 Revision 103, Oct. 26, 2006, TCG 2003-2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00009">
<othercit>AMD64 Technology: AMD64 Architecture Programmer's Manual vol. 2: System Programming, Publication No. 24593, Revision 3.14, Sep. 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00010">
<othercit>The Invisible Things Lab's blog: Attacking Intel Trusted Execution Technology, Jan. 5, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>National Computer Security Center: A Guide to Understanding Covert Channel Analysis of Trusted Systems, Nov. 1993, Version 1.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Abadi, M. et al., Control-Flow Integrity: Principles, Implementations, and Applications, Microsoft, 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Arbaugh, W. et al., A Secure and Reliable Bootstrap Architecture, IEEE, 1997.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Barak, B. et al., On the (Im)possibility of Obfuscating Programs, Aug. 1998.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Berger, S. et al., vTPM: Virtualizing the Trusted Platform Module, USENIX Association, Security '06: 15th USENIX Security Symposium, 305-320, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Bhargava, R. et al., Accelerating Two-Dimensional Page Walks for Virtualized Systems, ASPLOS '08, Mar. 1-5, 2008, Seattle, Washington, 26-35.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Bond, M., Diagnosing and Tolerating Bugs in Deployed Systems, University of Texas, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Brumley, D. et al., Privtrans: Automatically Partitioning Programs for Privilege Separation, Carnegie Mellon University, USENIX Security Symposium, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>Chen, X. et al., Overshadow: A Virtualization-Based Approach to Retrofitting Protection in Commodity Operating Systems, ASPLOS '08, Mar. 1-5, 2008, Seattle, Washington.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>Chen, H. et al., Tamper-Resistant Execution in an Untrusted Operating System Using a Virtual Machine Monitor, Parallel Processing Institute, Fudan University, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>Chen, B. et al., Certifying Program Execution with Secure Processors, MIT Laboratory for Computer Science, In Proceedings of HotOS, 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>Clarke, E. et al., A Tool for Checking ANSI-C Programs, Carnegie Mellon University, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00023">
<othercit>Cox, L. et al., Pocket Hypervisors: Opportunities and Challenges, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00024">
<othercit>Datta, A. et al., A Logic of Secure Systems and its Application to Trusted Computing, Carnegie Mellon University, IEEE Computer Society, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>Dewan, P. et al., A Hypervisor-Based System for Protecting Software Runtime Memory and Persistent Storage, SpringSin, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Dolev, D. et al., On the Security of Public Key Protocols, Department of Computer Science, Stanford University, May 1981.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Garfinkel, T. et al., Terra: A Virtual Machine-Based Platform for Trusted Computing, SOSP '03, Oct. 19-22, 2003, New York.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>NCSC-TG-030, Library No. S-240,572, Version 1, National Computer Security Center, Nov. 1993.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>Intel Virtualization Technology Specification for the IA-32 Intel Architecture, C97063-002, Apr. 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>Intel Trusted Execution Technology (Intel TXT): Software Development Guide, Dec. 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00031">
<othercit>Kauer, Bernhard, OSLO: Improving the Security of Trusted Computing. Department of Computer Science, Technische Universitat Dresden, Aug. 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00032">
<othercit>Klein, G. et al., seL4: Formal Verification of an OS Kernel, ACM Symposium on Operating System Principles, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00033">
<othercit>Lampson, Butler W., A Note on the Confinement Problem, Xerox Palo Alto Research Center, 1973.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Litty, L. et al., Hypervisor Support for Identifying Covertly Executing Binaries, USENIX Association, 17th USENIX Security Symposium, 243-258, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Fournet, C. et al., A Security-Preserving Compiler for Distributed Programs: From Information-Flow Policies to Cryptographic Mechanisms, CCS '09, Nov. 9-13, 2009, Chicago, Illinois, 1-10.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>McCamant, S. et al Evaluating SFI for a CISC Architecture, 1-16, 15th USENIX Security Symposium, 209-224, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>McLean, John, A General Theory of Composition for a Class of &#x201c;Possibilistic&#x201d; Properties, IEEE Transactions on Software Engineering, vol. 22 (1): 53-67, 1996.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>McCune, J. et al., Flicker: An Execution Infrastructure for TCB Minimization, EuroSys '08, Apr. 1-4, 2008, Glasgow, Scotland.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>McCune, J. et al., Minimal TCB Code Execution (Extended Abstract), IEEE Symposium on Security and Privacy, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>McCune, J. et al., How Low Can You Go?: Recommendations for Hardware-Supported Minimal TCB Code Execution, ASPLOS'08, Mar. 1-5, 2008, Seattle, Washington.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>Misra, S. et al., Relationships Between Selected Software Measures and Latent Bug-Density: Guidelines for Improving Quality, Springer-Verlag Berlin Heidelberg, 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00042">
<othercit>Nguyen, V. et al., A Model and Temporal Proof System for Networks of Processes, ACM, 1984.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>Owicki, S. et al., Proving Liveness Properties of Concurrent Programs, ACM Transactions on Programming Languages and Systems, vol. 4 (3): 455-495, 1982.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00044">
<othercit>Petroni, Jr., N. et al., Copilot&#x2014;a Coprocessor-based Kernel Runtime Integrity Monitor, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00045">
<othercit>Rahita, R. et al Dynamic Software Application Protection, Intel Corporation, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00046">
<othercit>Kennell, R. et al., Establishing the Genuinity of Remote Computer Systems, USENIX Association, Proceedings of the 12th USENIX Security Symposium, Washington, DC, Aug. 4-8, 2003, 295-310.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>Sailer, R. et al., Design and Implementation of a TCG-based Integrity Measurement Architecture, USENIX Association, Proceedings of the 13th USENIX Security Symposium, San Diego, CA, Aug. 9-13, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>Sadeghi, A. et al., TCG Inside?&#x2014;A Note on the TPM Specification Compliance, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>Schneider, F., Enforceable Security Policies, Cornell University, ACM Transactions on Information and System Security, vol. 3 (1): 30-50, 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00050">
<othercit>Seshadri, A. et al., Pioneer: Verifying Code Integrity and Enforcing Untampered Code Execution on Legacy Systems, SOSP '05, Oct. 23-26, 2005, Brighton, United Kingdom.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>Shacham, Hovav, The Geometry of Innocent Flesh on the Bone: Return-into-libe Without Function Calls (on the x86), Sep. 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00052">
<othercit>Shankar, U. et al., Side Effects are not Sufficient to Authenticate Software, Report No. UCB/CSD-04-1363, Sep. 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00053">
<othercit>Shi, E. et al BIND: A Fine-grained Attestation Service for Secure Distributed Systems, May 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>Seshadri, A. et al., SecVisor: A Tiny Hypervisor to Provide Lifetime Kernel Code Integrity for Commodity OSes, SOSP '07, Oct. 14-17, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>Small, C. et al., MiSFIT: A Tool for Constructing Safe Extensible C++ Systems, Harvard University, 3rd USENIX Conference on Object-Orientated Technology (COOTS), 1997.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>35</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>726 17</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726  4</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726  7</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 23</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 27</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713165</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713166</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713168</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709212</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709217</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>31</number-of-drawing-sheets>
<number-of-figures>32</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61273454</doc-number>
<date>20090804</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61273448</doc-number>
<date>20090804</date>
</document-id>
</us-provisional-application>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>McCune</last-name>
<first-name>Jonathan M.</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Perrig</last-name>
<first-name>Adrian M.</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Datta</last-name>
<first-name>Anupam</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Gligor</last-name>
<first-name>Virgil Dorin</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Li</last-name>
<first-name>Yanlin</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Parno</last-name>
<first-name>Bryan Jeffrey</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="007" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Vasudevan</last-name>
<first-name>Amit</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="008" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Qu</last-name>
<first-name>Ning</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>McCune</last-name>
<first-name>Jonathan M.</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Perrig</last-name>
<first-name>Adrian M.</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Datta</last-name>
<first-name>Anupam</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Gligor</last-name>
<first-name>Virgil Dorin</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Li</last-name>
<first-name>Yanlin</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Parno</last-name>
<first-name>Bryan Jeffrey</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="007" designation="us-only">
<addressbook>
<last-name>Vasudevan</last-name>
<first-name>Amit</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="008" designation="us-only">
<addressbook>
<last-name>Qu</last-name>
<first-name>Ning</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Fox Rothschild LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Carleton</last-name>
<first-name>Dennis M.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Carnegie Mellon University</orgname>
<role>02</role>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Moorthy</last-name>
<first-name>Aravind</first-name>
<department>2492</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A computer including a processor and a verification device. The processor in the computer performs the steps of authenticating a secure connection between a hypervisor and the verification device, measuring the identity of at least a portion of a select guest before the select guest executes any instruction, and sending a measurement of the identity of the select guest to the verification device. The verification device compares the policy stored in the verification device with the measurement of the select guest received by the verification device. The steps of authenticating, measuring, sending, and comparing are performed after receiving a signal indicative of a request to execute the select guest and without rebooting the computer.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="142.24mm" wi="217.51mm" file="US08627414-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="226.06mm" wi="156.97mm" orientation="landscape" file="US08627414-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="166.20mm" wi="166.88mm" orientation="landscape" file="US08627414-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="155.96mm" wi="165.18mm" orientation="landscape" file="US08627414-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="199.05mm" wi="167.47mm" orientation="landscape" file="US08627414-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="228.35mm" wi="165.78mm" orientation="landscape" file="US08627414-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="184.23mm" wi="167.47mm" orientation="landscape" file="US08627414-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="186.61mm" wi="163.15mm" orientation="landscape" file="US08627414-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="218.78mm" wi="152.32mm" file="US08627414-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="186.18mm" wi="141.14mm" file="US08627414-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="220.05mm" wi="147.40mm" file="US08627414-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="191.43mm" wi="147.07mm" file="US08627414-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="199.73mm" wi="157.23mm" file="US08627414-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="199.98mm" wi="147.40mm" file="US08627414-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="219.46mm" wi="154.94mm" file="US08627414-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="232.49mm" wi="168.15mm" orientation="landscape" file="US08627414-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="184.32mm" wi="116.84mm" file="US08627414-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="246.13mm" wi="167.30mm" file="US08627414-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="183.22mm" wi="156.04mm" file="US08627414-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="206.76mm" wi="152.48mm" file="US08627414-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="210.57mm" wi="164.85mm" file="US08627414-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="138.51mm" wi="146.73mm" file="US08627414-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="225.38mm" wi="149.69mm" file="US08627414-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="210.90mm" wi="152.65mm" orientation="landscape" file="US08627414-20140107-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="239.52mm" wi="148.67mm" orientation="landscape" file="US08627414-20140107-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="122.34mm" wi="145.37mm" orientation="landscape" file="US08627414-20140107-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00026" num="00026">
<img id="EMI-D00026" he="146.73mm" wi="147.07mm" orientation="landscape" file="US08627414-20140107-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00027" num="00027">
<img id="EMI-D00027" he="209.55mm" wi="144.78mm" orientation="landscape" file="US08627414-20140107-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00028" num="00028">
<img id="EMI-D00028" he="161.21mm" wi="116.50mm" orientation="landscape" file="US08627414-20140107-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00029" num="00029">
<img id="EMI-D00029" he="197.02mm" wi="156.89mm" orientation="landscape" file="US08627414-20140107-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00030" num="00030">
<img id="EMI-D00030" he="174.33mm" wi="164.51mm" orientation="landscape" file="US08627414-20140107-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00031" num="00031">
<img id="EMI-D00031" he="226.65mm" wi="133.60mm" orientation="landscape" file="US08627414-20140107-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims priority from U.S. Provisional Patent Application No. 61/273,454, filed Aug. 4, 2009, which is incorporated herein by reference. This application is related to U.S. provisional patent application No. 61/273,448, filed Aug. 4, 2009 and U.S. patent application Ser. No. 11/545,924, filed Oct. 10, 2006.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?GOVINT description="Government Interest" end="lead"?>
<heading id="h-0002" level="1">STATEMENT REGARDING FEDERALLY-SPONSORED RESEARCH AND DEVELOPMENT</heading>
<p id="p-0003" num="0002">This invention may have been made with government support under contracts DAAD19-02-1-0389 and W911NF-09-1-0273, awarded by the Army Research Office. The United States government may have certain rights in this invention.</p>
<?GOVINT description="Government Interest" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0003" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0004" num="0003">The present invention is directed generally to methods and apparatuses for user-verifiable execution of security-sensitive code and, more particularly, for such methods and apparatuses for use on untrusted computer platforms.</p>
<heading id="h-0004" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0005" num="0004">The increasing complexity of computer systems makes them vulnerable to a variety of attacks. The dominant current approach to deal with such malware is to compare execution patterns with malware patterns (i.e., malware signatures). Unfortunately, this has led to an &#x201c;arms race,&#x201d; where malware developers flood the defenders with polymorphic and ever-changing malware.</p>
<p id="p-0006" num="0005">Current commodity operating systems and the majority of applications lack assurance that the secrecy and integrity of security-sensitive code and data remain intact. Absent is any guarantee of code integrity, which implies that users, administrators, and other systems must blindly trust that a given system platform or application protects its sensitive data&#x2014;trust that is all too often misplaced.</p>
<p id="p-0007" num="0006">Three fundamental causes of this problem are: (1) increased size and complexity of commodity operating systems over time, which effectively eliminates the possibility of precise, formal verification of the entire code base, (2) retention of object code compatibility of operating system and application APIs, which implies their immutability in time despite the presence of demonstrable design flaws, and (3) new business models for developing operating systems and applications rely extensively on mixed-provenance code bases; i.e., code provided by different development organizations with different business interests. This rules out global guarantees of security properties since a single point of control and responsibility over a platform's code base does not exist any longer.</p>
<p id="p-0008" num="0007">A significant source of increased size and complexity is support for &#x201c;plug and play&#x201d; code that changes system configuration by adding new devices and system administrative functions to the base operating system. Undoubtedly operating system ease of extensibility is a fundamental requirement for innovation. However, complexity is often further increased by removing inter-module and inter-layer boundaries to enhance system performance for these applications. Unfortunately, verification of the code base and the analysis of its penetration resistance cannot be effectively performed for code bases that are almost continuously extended in time with their modules reaching sizes that exceed one million lines of monolithic code. It is not just the Windows code base that was extended over the past 20 years: in the mid 1980s UNIX for PCs had 50 K SLOC in the Kernel (and 120 K in security-relevant components); today it has over 1 M SLOC.</p>
<p id="p-0009" num="0008">Retention of object-code compatibility for applications suggests that design flaws cannot be readily eliminated without breaking an execution environment. In time, lack of object code compatibility tends to destroy the very market base sought by a system provider, such as whenever users of that environment have to recompile their code with a new set of APIs. Often users cannot perform recompilation since very seldom do they own the source code of their applications. In effect, if flawed APIs become immutable, &#x201c;compatibility with previous mistakes&#x201d; becomes a pervasive challenge to building trusted systems. Numerous examples of conflicts between API definitions and security properties exist, ranging from APIs that have built-in covert channels that would otherwise not exist [National Computer Security Center. A guide to understanding covert channel analysis of trusted systems. Technical Report NCSC-TG-030 Version 1, National Computer Security Center, November 1993.], to APIs that enable outright penetration of an operating system [M. Howard and D. LeBlanc. Writing Secure Code: Second Edition. Microsoft Press, 2003.], and to cryptographic APIs that enable discovery of secrets [M. D. Bond. Diagnosing and Tolerating Bugs in Deployed Systems. PhD thesis, University of Cambridge, 2008.]. The challenge of how to remove or neutralize API flaws without introducing object-code incompatibility for extant applications has been a subject of intense research (viz., over half-a-dozen workshops in the API security area).</p>
<p id="p-0010" num="0009">Mixed-provenance code within an operating system or application means that code analysis, verification, and unit testing of the resulting system cannot possibly be performed, since no single party would own, and have access to, all the system source code. A code provider and a code user have different, often conflicting business interests: the code provider does not have any incentive to address the verification concerns of the code user since the provider cannot be expected to satisfy global system properties; whereas the code user may know all global system properties but has no access to the many providers' code bases to verify them. Thus, externally provided modules could only be monolithically API-tested for coarse, global properties by the code user&#x2014;hardly a reassuring feature for a computing base upon which security-sensitive applications are expected to rely. The inner working of at least some NVIDIA drivers are a mystery to Microsoft while Microsoft's higher-level security concerns are far removed from NVIDIA's design priorities. Yet those drivers affect the overall system security as much as any other code. Similar security dilemmas appear at the application level; e.g., in the financial and banking applications it is estimated that 70% of all software is of mixed provenance.</p>
<p id="p-0011" num="0010">These three fundamental obstacles to the development of trusted commodity operating systems and applications suggest that we will not achieve the level of assurance necessary to run security-sensitive code and data on these platforms in the near future. Yet, commodity operating systems and applications offer unmatched incentives for use by both casual users and developers, and hence will remain a dominant presence in the marketplace. First, commodity systems have become and will continue to be the major common platforms for innovation. Hence, the latest technology advances are likely to occur on these platforms and thus they can hardly be set aside. Second, they provide a rich development environment by offering powerful application and device support. Third, they combine productivity software (e.g., office, web, mail) with entertainment (e.g., games, socialization) in a marketplace that values consolidation of computing and communication services.</p>
<p id="p-0012" num="0011">Challenge 1.</p>
<p id="p-0013" num="0012">The major challenge we face is not to develop new secure operating system platforms, though this remains a worthy long-term goal. Nor is it to eliminate all software flaws from an existing platform, though this too remains a worthy, if somewhat elusive, goal. Instead, the major challenge is to develop system-level techniques that enable users to run applications containing security-sensitive code and data on untrusted commodity platforms, which may be plagued by malware (e.g., rootkits, Trojan Horse programs, software key-loggers, screen-scrapers), and yet provide strong, user-verifiable assurances of secrecy and integrity selectively for the applications' security-sensitive code and data. That is, a developer should be able to specify precisely and select the security-sensitive code and data of an application, and provide guarantees, which can be verified by a user external to the untrusted platform, that the desired security properties of the selected code and data are maintained even in the presence of malware. Moreover, the verification of these guarantees should be available at any time, not just at system boot, and should be easy to perform by a casual user. Finally, the mechanisms that provide these capabilities should not impose significant, or even user-perceptible, performance degradation.</p>
<p id="p-0014" num="0013">Security Properties.</p>
<p id="p-0015" num="0014">A second challenge that arises in running security-sensitive code and maintaining the data of an application on an untrusted platform is that of specifying what security properties can be supported. Clearly, some security properties cannot be supported either in theory or in practice. For instance, certain code-obfuscation models that do not take advantage of any underlying system security features (i.e., are implementation-independent) can be theoretically ruled out [B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan, and K. Yang. On the (Im)possibility of obfuscating programs. In Advances in Cryptology (CRYPTO), August 1998.]. Other properties, such as those of noninterference and other information-flow control policies (e.g., elimination or control of covert channel use), may be theoretically viable but either impractical in or insignificant to an application.</p>
<p id="p-0016" num="0015">There is a need to support a very large class of security properties that fall into the class of &#x201c;safety&#x201d; properties [S. Gupta and V. Gligor. Towards a theory of penetration-resistant systems and its applications. In Proceedings of the Computer Security Foundations Workshop, June 1991.], [S. Gupta and V. Gligor. Experience with a penetration analysis method and tool. In Proceedings of the National Computer Security Conference, October 1992.], [V. Nguyen, D. Gries, and S. Owicki. A model and temporal proof system for networks of processes. In Proceedings of the ACM Symposium on Principles of Programming Languages (POPL), pages 121-131, 1985.], [S. Owicki and L. Lamport. Proving liveness properties of concurrent programs. ACM Trans. Program. Lang. Syst., 4(3):455-495, 1982.]. There are three important reasons for this. First, most security polices can be expressed as safety properties [F. B. Schneider. Enforceable security policies. ACM Trans. Inf. Syst. Secur., 3(1):30-50, 2000.], and while information-flow policies are a notable exception [J. McLean. A general theory of composition for a class of &#x201c;possibilistic&#x201d; properties. IEEE Trans. Softw. Eng., 22(1):53-67, 1996.], most of these policies can be approximated as safety properties; e.g., all mandatory access controls implemented to date are such approximations. Second, most penetration-resistance properties can also be expressed as safety properties, since they are typically represented via state-transition models [M. Bishop. Computer Security Art and Science. Addison Wesley, 2003.]. Finally, the only &#x201c;liveness&#x201d; properties that concern the selected sections of application code whose security needs to be protected are automatically converted into &#x201c;safety&#x201d; properties in our system. That is, the protected execution of these sections is bracketed by &#x201c;timeouts&#x201d; so that termination of their execution is always guaranteed [F. B. Schneider. Enforceable security policies. ACM Trans. Inf. Syst. Secur., 3(1):30-50, 2000.].</p>
<p id="p-0017" num="0016">Challenge 2.</p>
<p id="p-0018" num="0017">Another core challenge is that any security system that is added needs to be compatible with current applications and IT workflows. For example, end-users do not want to abandon their legacy software and OS to switch to a new system to gain better security. Thus, we need to ensure that our mechanisms are compatible with current operating environments and applications.</p>
<p id="p-0019" num="0018">Related Research in Software-Based Attestation.</p>
<p id="p-0020" num="0019">Genuinity is a technique that explores the problem of detecting the difference between a simulator-based computer system and an actual computer system [R. Kennell and L. H. Jamieson. Establishing the genuinity of remote computer systems. In Proceedings of the USENIX Security Symposium, 2004.]. Genuinity relies on the premise that simulator-based program execution is bound to be slower because a simulator has to simulate the CPU architectural state in software, in addition to simulating the program execution. A special checksum function computes a checksum over memory, while incorporating different elements of the architectural state into the checksum. By the above premise, the checksum function should run slower in a simulator than on an actual CPU. While this statement is probably true when the simulator runs on an architecturally different CPU than the one it is simulating, an adversary having an architecturally similar CPU can compute the Genuinity checksum within the allotted time while maintaining all the necessary architectural state in software. As an example, in their implementation on the x86, Kennell and Jamieson [R. Kennell and L. H. Jamieson. Establishing the genuinity of remote computer systems. In Proceedings of the USENIX Security Symposium, 2004.] propose to use special registers, called Model Specific Registers (MSR), that hold various pieces of the architectural state like the cache and TLB miss count. The MSRs can only be read and written using the special RDMSR and WRMSR instructions. We found that these instructions have a long latency (approximately 300 cycles). An adversary that has an x86 CPU could simulate the MSRs in software and still compute the Genuinity checksum within the allotted time, even if the CPU has a lower clock speed than what the adversary claims. Also, researchers have documented weaknesses in the Genuinity approach [U. Shankar, M. Chew, and J. Tygar. Side effects are not sufficient to authenticate software. In Proceedings of the 13th USENIX Security Symposium, 2004.].</p>
<p id="p-0021" num="0020">Related Research in Hardware-Based Attestation.</p>
<p id="p-0022" num="0021">The Integrity Measurement Architecture (IMA) is a SRTM-based technique that relies on the TPM chip standardized by the Trusted Computing Group [R. Sailer, X. Zhang, T. Jaeger, and L. van Doom. Design and implementation of a TCG-based integrity measurement architecture. In Proceedings of the USENIX Security Symposium, August 2004.]. That technique enables a remote verifier to verify what software was loaded into the memory of a platform. However, a malicious peripheral could overwrite code that was just loaded into memory with a DMA-write, thereby breaking the load-time attestation guarantee. The Terra system uses a Trusted Virtual Machine Monitor (TVMM) to partition a tamper-resistant hardware platform into multiple virtual machines (VM) that are isolated from each other [T. Garfinkel, B. Pfaff, J. Chow, M. Rosenblum, and D. Boneh. Terra: A virtual machine-based platform for trusted computing. In Proceedings of the Symposium on Operating System Principles, 2003.]. CPU-based virtualization and protection are used to isolate the TVMM from the VMs and the VMs from each other. Although the authors only discuss load-time attestation using a TPM, Terra is capable of performing run-time attestation on the software stack of any of the VMs by asking the TVMM to take integrity measurements at any time. All the properties provided by Terra are based on the assumption that the TVMM is uncompromised when it is started and that it cannot be compromised subsequently. Terra uses the load-time attestation property provided by TCG to guarantee that the TVMM is uncompromised at start-up. Since this property of TCG is compromised, none of the properties of Terra hold. Even if TCG were capable of providing the load-time attestation property, the TVMM could be compromised at run-time if there are vulnerabilities in its code. The Copilot approach relies on an add-in card connected to the PCI bus to perform periodic integrity measurements of the in-memory Linux kernel image [N. L. Petroni, Jr., T. Fraser, J. Molina, and W. A. Arbaugh. Copilot&#x2014;a coprocessor-based kernel runtime integrity monitor. In Proceedings of the USENIX Security Symposium, 2004.]. These measurements are sent to the trusted verifier through a dedicated side channel. The verifier uses the measurements to detect unauthorized modifications to the kernel memory image. The Copilot PCI card cannot access CPU-based state such as the pointer to the page table and pointers to interrupt and exception handlers. Without access to such CPU state, it is impossible for the PCI card to determine exactly what resides in the memory region that the card measures. The adversary can exploit this lack of knowledge to hide malicious code from the PCI card. For instance, the PCI card assumes that the Linux kernel code begins at virtual address 0xc0000000, since it does not have access to the CPU register that holds the pointer to the page tables. While this assumption is generally true on 32-bit systems based on the Intel x86 processor, the adversary can place a correct kernel image starting at address 0xc0000000 while in fact running a malicious kernel from another memory location. (The authors of Copilot are aware of this attack.) It is not possible to prevent this attack without access to the CPU state.</p>
<p id="p-0023" num="0022">The Cerium [B. Chen and R. Morris. Certifying program execution with secure procesors. In Proceedings of HotOS, 2003.] approach uses hardware extensions to the execution platform to provide a remote host with the guarantee of verifiable code execution. Cerium relies on a physically tamper-resistant CPU with an embedded public-private key pair and a micro-kernel that runs from the CPU cache. Unfortunately, Cerium remains a paper design and was never built. The BIND system [E. Shi, A. Perrig, and L. van Doom. BIND: A time-of-use attestation service for secure distributed systems. In Proceedings of IEEE Symposium on Security and Privacy, May 2005.] requires that the execution platform provides support for DRTM and was designed for an early version of AMD Secure Virtual Machine (SVM) processors. The Open Secure Loader (OSLO) [B. Kauer. OSLO: Improving the security of Trusted Computing. In Proceedings of the USENIX Security Symposium, August 2007.] employs the AMD SVM SKINIT instruction to eliminate the BIOS and boot loader from the TCB and establish a DRTM for trusted boot. The Flicker system provides an approach for secure execution and externally-verifiable code execution that relies on DRTM mechanisms offered by modern AMD and Intel processors [J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and H. Isozaki. Flicker: An execution infrastructure for TCB minimization. In Proceedings of the ACM European Conference in Computer Systems (EuroSys), April 2008.].</p>
<p id="p-0024" num="0023">Accordingly, there is a need for improved security for sensitive code and data, particularly for improvements that are easy to use. Those and other advantages of the present invention will be described in more detail hereinbelow.</p>
<heading id="h-0005" level="1">BRIEF SUMMARY OF THE INVENTION</heading>
<p id="p-0025" num="0024">The present invention offers a different approach than that offered in the prior art. In particular, the present invention defines a secure execution environment and provides specific mechanisms to detect any attempted violation of its security properties.</p>
<p id="p-0026" num="0025">One key insight is that users tend to perform security-sensitive transactions infrequently. Furthermore, modern hardware allows for rapid and secure switching between two completely different computing environments. As a result, according to one embodiment, the present invention can include a system to provide several security modes on a single computer system. In such a system, users can activate a &#x201c;secure mode&#x201d; before performing security-sensitive transactions, and then return to a non-secure mode for other activities and with fewer restrictions than in the secure mode.</p>
<p id="p-0027" num="0026">One goal of research that lead to the present invention was to obtain user-verifiable execution properties for software executing on an untrusted host, potentially containing malicious software. We investigated a technique for User-Verifiable Execution of Security-sensitive Code on Untrusted Platforms (UVESCUP) in the presence of malware. This technique allows an entity (the verification device) to obtain assurance that the execution of an arbitrary piece of code, called the target executable, on a local or remote computing device is not tampered with by any malware that may be present on the computing device. The research performed had three specific overall technical objectives.</p>
<p id="p-0028" num="0027">The first technical objective was to produce the design of a user-verifiable execution of security sensitive code on untrusted platforms (1) in the presence of malware, and (2) under minimal assumptions regarding the physical security and administrative (e.g., insider) trust. This goal is important since any network-connected computing platform is subject to malware attacks, and since the use of state-of-the-art physical protection mechanisms (e.g., tamper-proof TPMs) cannot fully protect against malware and physical attacks launched by insiders.</p>
<p id="p-0029" num="0028">The second technical objective of the UVESCUP technology is reducing the use of secrets (i.e., secret keys) in either hardware or software. This goal is important for two reasons. First, minimizing the use of secrets automatically minimizes the potential attack surface of our mechanism. Second, use of secrets in any basic security mechanism poses a significant bootstrapping problem: their protection cannot be provided by assuming other, more basic underlying mechanisms because these mechanisms do not necessarily exist or can be impractical.</p>
<p id="p-0030" num="0029">The third technical objective is to increase the usability of security mechanisms with UVESCUP. This is important because experience with design and operation of secure systems for the past three decades indicates that a major risk factor in the use of security mechanisms is user/administrator error. Being keenly aware of the importance of human factors to security mechanism design and use, we performed a usability analysis of our design. This is important because invariably configuration errors lead to breaches of even the strongest security mechanisms. For example, configuration mismatches between what the trusted verifier of UVESCUP assumes and what the underlying platform supports can lead to circumvention of the implemented security mechanisms. Thus a key goal of the UVESCUP technology is the transparent verification of the required platform configuration</p>
<p id="p-0031" num="0030">As a result, the present invention can include a trusted verifier that can validate the correct execution of the secure environment on the untrusted host through attestation mechanisms. The verification device can be integrated or it can be removable. The present invention can also include a variety of mechanisms for both hardware-based and software-based attestation.</p>
<p id="p-0032" num="0031">The following features may be included with the present invention for software-based attestation: no secrets are involved which enables recovery after system compromise; execution on legacy systems; low cost because no special hardware is needed; and updatability in case of detected vulnerabilities.</p>
<p id="p-0033" num="0032">The present invention may also include one or more of the following features.</p>
<p id="p-0034" num="0033">1. The present invention may be implemented for user-verifiable execution of security-sensitive code on untrusted platforms (UVESCUP) on commodity operating systems and in the presence of malware and under minimal assumptions regarding physical and administrative trust.</p>
<p id="p-0035" num="0034">2. The present invention minimizes the use of secrets (e.g., secret cryptographic keys) in our system. Secrets are targets from the perspective of the attacker. Further, at the lowest level of system design, it may be impossible or impractical to assume pre-existing shared secrets.</p>
<p id="p-0036" num="0035">3. The present invention is user friendly. An unusable security system will suffer from perpetual misconfiguration, and may introduce more problems than it solves by way of instilling a false sense of security and additional user overhead.</p>
<p id="p-0037" num="0036">In addition to the above, we consider a more concrete definition of security-sensitive code, expand our use of hardware-supported attestation and virtualization, and additionally use software-based attestation to support legacy hardware and as a recovery mechanism in the event of compromise.</p>
<p id="p-0038" num="0037">Security-Sensitive Code.</p>
<p id="p-0039" num="0038">Legacy applications that depend on the availability of a flawed (from a security design perspective) API (e.g., Windows or Linux) may still be considered security-sensitive. However, the level and kind of protection that can be provided for these applications is different from the protections available to new code developed in accordance with today's best practices. Thus, an objective of our system is to offer the best possible protection in either scenario: to both legacy (and potentially fundamentally flawed) and newly developed security-sensitive code. We further strive for ease-of-adoptability with respect to our protection mechanisms for newly-developed code. This way, critical components of legacy applications can more readily be extracted or ported into our maximum security environment.</p>
<p id="p-0040" num="0039">Hardware-Based Attestation.</p>
<p id="p-0041" num="0040">Computing platforms equipped with the latest (v1.2) Trusted Platform Module [Trusted Computing Group. Trusted platform module main specification, Part 1: Design principles, Part 2: TPM structures, Part 3: Commands. Version 1.2, Revision 103, July 1007.] (TPM) and an appropriate CPU and chipset are capable of creating a dynamic root of trust (DRTM) for executing an arbitrary piece of code in isolation from everything else on the system except for the CPU, memory, and chipset [Advanced Micro Devices. AMD64 architecture programmer's manual: Volume 2: System programming. AMD Publication no. 24593 rev. 3.14, September 2007.], [Intel Corporation. Intel trusted execution technology&#x2014;software development guide. Document number 315168-005, June 2008.]. The use of DRTM and the invoked code is recorded in the TPM so that it can be used in an attestation to an external entity. We leverage the DRTM mechanism to securely bootstrap a hypervisor, sometimes called &#x201c;TrustVisor&#x201d;, that provides isolation and attestation facilities for guests of diverse pedigree. Though attacks have been demonstrated against TPM-equipped platforms [B. Kauer. OSLO: Improving the security of Trusted Computing. In Proceedings of the USENIX Security Symposium, August 2007.].</p>
<p id="p-0042" num="0041">Software-Based Attestation.</p>
<p id="p-0043" num="0042">Software-based attestation mechanisms (e.g., SWATT [A. Seshadri, A. Perrig, L. van Doom, and P. Khosla. SWATT: Software-based attestation for embedded devices. In Proceedings of the IEEE Symposium on Security and Privacy, May 2004.] and Pioneer [A. Seshadri, M. Luk, E. Shi, A. Perrig, L. VanDoorn, and P. Khosla. Pioneer: Verifying integrity and guaranteeing execution of code on legacy platforms. In Proceedings of the Symposium on Operating Systems Principals, 2005]) offer many advantages. However, some examples of these mechanisms offer similar security properties to hardware-based DRTM but have a different set of requirements. Software-based attestation requires an authentic communication channel with extremely low latency, which rules out verification across the Internet. However, software-based attestations is perfectly viable even on older hardware that does not support hardware-based DRTM. Thus, these technologies are complementary along several axes. First, software-based attestation enables our secure execution environment on older hardware. Second, software-based attestation can serve as a recovery mechanism in the event that an adversary somehow learns (e.g., via expensive or time-consuming side-channel or timing attacks) the hardware TPM chip's secrets. In this case, we can use software-based attestation to reconfigure the platform's TPM chip and re-establish trust in the platform.</p>
<p id="p-0044" num="0043">Secure Browser Environment.</p>
<p id="p-0045" num="0044">To enable users to visit their trusted web sites in a secure fashion, the present invention may include a system that leverages a hypervisor, sometimes called &#x201c;TrustVisor&#x201d;, and a verification device, sometime called the &#x201c;USB verifier&#x201d;. The secure browser environment of the present invention will protect against malware interfering when a user visits her trusted web site(s).</p>
<p id="p-0046" num="0045">In this embodiment, the present invention may set up TrustVisor on the system to switch between several OS partitions, each partition for a different security level. To verify the correct operation of TrustVisor and to provide a trusted path for a security indicator to the user, we leverage the trusted USB verifier. Through the use of hardware based attestation (or more specifically, an attestation to a late launch or dynamic root of trust operation) the USB verifier ensures the correct operation of TrustVisor. A switch on the USB verifier provides a trusted path for input, and triggers secure switching between different OS partitions.</p>
<p id="p-0047" num="0046">To enable users to use their computers as they have become accustomed, TrustVisor provides an untrusted partition of an OS, permitting installation and execution of arbitrary software. For the secure partitions, TrustVisor will measure all OS and application components, to ensure code integrity and to prevent execution of any unapproved software. Furthermore, TrustVisor may write-protect all code on the system to protect that code against arbitrary write operations (this measure by itself will prevent the majority of current malware, including all kernel-level rootkits that we are aware ot).</p>
<p id="p-0048" num="0047">The OS and applications that execute in the trusted partition are still commodity OSes and applications. As a result, they are still plagued by vulnerabilities. To further protect the execution for the secure partitions, we ensure that network communication only occurs with approved sites over secure SSL connections. As a result, according to one embodiment of the present invention, no source other than the user's trusted sites can send network packets to the OS and applications within the secure OS. Consequently, only those trusted web sites could launch an attack. To achieve these properties, TrustVisor contains an SSL inspector or proxy, only permitting SSL network connections that use a specifically approved certificate.</p>
<p id="p-0049" num="0048">In summary, the present invention can be made easy to use, only requiring users to realize when they intend to visit a secure web site, and to switch to a secure partition by pressing a button on the USB verifier. Even with minimal user diligence, this environment will offer a very high level of security.</p>
<p id="p-0050" num="0049">Trusted Path to Security-Sensitive Code.</p>
<p id="p-0051" num="0050">To achieve very strong security properties for execution on commodity operating systems, the present invention may include a system for executing security-sensitive code modules within applications with very strong protections. For example, TrustVisor provides a safe execution environment for security-sensitive code modules without trusting the OS or the application that invokes the code module. TrustVisor will protect security-sensitive code and data on untrusted commodity platforms from malware, e.g., kernel-level rootkits. More specifically, TrustVisor protects the integrity and execution of security-sensitive code, and confidentiality and integrity of the data used by that code; as well as attest these properties to remote entities.</p>
<p id="p-0052" num="0051">This system enables many applications, but is particularly well suited when the security-sensitive code is small and self-contained. For example, a webserver serving SSL/TLS-based connections needs to protect its private signature key. If the OS or application is compromised, the attacker can steal the private key and impersonate the web server. In our system, the code accessing the private key can be confined to a self-contained code module protected by a secure hypervisor, and the http server code can call that code module for setting up SSL/TLS connection state. In this setting, even if the OS or http server are compromised, the secrecy of the private key is guaranteed, as well as the integrity of the code that is allowed to access it.</p>
<p id="p-0053" num="0052">The present invention may include an execution environment that will make it easy to encapsulate sensitive code within an application into a security-sensitive code module protected by TrustVisor. OEMs will be able to achieve very strong execution guarantees as well as secrecy and integrity for data within these security-sensitive code modules.</p>
<p id="p-0054" num="0053">The present invention can also include or be embodied as computer-readable instructions such as software, firmware, hardware, and other embodiments which, when executed by a processor, causes the processor to perform certain actions according to the present invention. In one embodiment, the present invention includes an apparatus including a processor, memory, an input device, and an output device, and the memory includes computer-readable instructions which, when executed, cause the processor to perform the methods described herein.</p>
<p id="p-0055" num="0054">Many other variations are possible with the present invention, and those and other teachings, variations, and advantages of the present invention will become apparent from the description and figures of the invention.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWING</heading>
<p id="p-0056" num="0055">Embodiments of the present invention will now be described, by way of example only, with reference to the accompanying drawings for the purpose of illustrating the embodiments, and not for purposes of limiting the invention.</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 1</figref> illustrates one embodiment of a computer according to the present invention.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 2</figref> illustrates another embodiment of the present invention in which several computers are connected together via a network.</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 3</figref> illustrates one embodiment of a computing platform that may be created and used with the present invention.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 4</figref> illustrates one embodiment of how the processor interacts with the verification device.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIGS. 5A and 5B</figref> illustrate one embodiment of a process according to the present invention that is performed by the processor for execution of the secure guest.</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 6</figref> illustrates one embodiment of a process according to the present invention that is performed by the verification device after receiving information related to the select guest from the processor.</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIGS. 7A</figref>, <b>7</b>B, and <b>7</b>C illustrate one embodiment of a method performed by the processor after the execution of the select guest.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 8</figref> illustrates one embodiment of a process according to the present invention that is performed by the verification device after receiving information related to the select guest from the processor.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 9</figref> illustrates one embodiment of how the processor interacts with the verification device to control the operation of the select guests and the legacy guests.</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. 10A</figref> illustrates a routing process that is used to determine whether the user wants to execute the select guest or the legacy guest.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 10B</figref> represents one embodiment of the process according to the present invention when the user requests to execute the select guest.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 10C</figref> illustrates one embodiment of a process according to the present invention that is performed by the processor after receiving the signal from the verification device.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 10D</figref> illustrates one embodiment of the process according to the present invention when the user requests to execute the legacy guest.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 11</figref> illustrates one embodiment of the step of authenticating a secure connection between the hypervisor and the verification device.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 12</figref> illustrates additional steps that may be performed by the verification device.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 13</figref> illustrates one embodiment of another method performed by the processor when there is an attempt to establish a network connection between one of the guests and an endpoint on the network.</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. 14</figref> illustrates one embodiment of a method that may be performed by the processor in connection with the embodiment illustrated in <figref idref="DRAWINGS">FIG. 3D</figref></p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 15</figref> illustrates one embodiment of coarse-grained protections according to the present invention.</p>
<p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. 16</figref> illustrates one embodiment of hyper-partitioning of storage devices according to the present invention.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 17</figref> illustrates one embodiment of a verification device for more than two mutually distrusting environments.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 18</figref> illustrates one embodiment of Trusted Environment Network Protection.</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. 19</figref> illustrates one embodiment of a fine-grained protection architecture with TrustVisor.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 20</figref> illustrates one embodiment of a basic sequence of events for a particular SSCB.</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. 21</figref> illustrates one embodiment of a comparison of the three execution modes of code with TrustVisor.</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. 22</figref> illustrates one embodiment of an attestation protocol by which a remote party (which may be a local verification device) verifies that a particular attestation represents a legitimate run of a SSCB.</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. 23</figref> illustrates one embodiment of a system architecture demonstrating three different guest types running on TrustVisor.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. 1</figref> illustrates one embodiment of a computer <b>110</b> according to the present invention. In that embodiment, the computer <b>110</b> includes a processor <b>112</b>, memory <b>114</b>, an input device <b>116</b>, an output or display device <b>118</b>, and a verification device <b>120</b>. The processor <b>112</b> is connected to the memory <b>114</b>, the input device <b>116</b>, and the output device <b>118</b>. The memory <b>114</b> includes computer readable instructions, such as computer hardware, software, firmware, or other forms of computer-readable instructions which, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform certain functions, as described herein. The computer <b>110</b> may also include one or more other devices not shown herein. Although this embodiment is illustrated with the verification device <b>120</b> as part of the computer <b>110</b>, the verification device <b>120</b> may be separate from the computer <b>110</b>.</p>
<p id="p-0084" num="0083">The processor <b>112</b> receives input from the input device <b>116</b>, provides signals to control the output device <b>118</b>, and provides and receives other signals such as, for example, signals to and from the verification device <b>120</b>. The processor <b>112</b> also performs certain functions, as described herein.</p>
<p id="p-0085" num="0084">The memory <b>114</b> can be any form of computer-readable memory, and may store information in magnetic form, optical form, electrical form, or other forms. The memory <b>114</b> includes computer-readable instructions which, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform certain functions, as described herein.</p>
<p id="p-0086" num="0085">The memory <b>114</b> may have many variations. For example, the memory <b>114</b> may be separate from the processor <b>112</b> or the memory <b>114</b> may be integrated with the processor <b>112</b>. The memory <b>114</b> may also include one memory device or the memory <b>114</b> may include more than one memory device. For example, the memory <b>114</b> may include one or more memory devices of non-volatile memory and it may also include one or more memory devices of volatile memory. For example, the memory <b>114</b> may include a storage media device <b>130</b> for long term data storage, such as a magnetic disk drive, an optical drive, or flash memory. The memory <b>114</b> may also include RAM <b>132</b> or other memory devices for other functions. Other combinations and variations of memory <b>114</b> may also be used with the present invention.</p>
<p id="p-0087" num="0086">The input device <b>116</b> may be a keyboard, a touchscreen, a computer mouse, or other forms of inputting information from a user. The input device <b>116</b> may also be used for inputting information from a source other than a human user, such as a data port for receiving input from another computer.</p>
<p id="p-0088" num="0087">The output device <b>118</b> may be a video display or other forms of outputting information to a user. The output device <b>118</b> may also be lights, speakers, or other forms of output that can be used to convey information to, or to get the attention of, a user The output device <b>118</b> may also be used for outputting information to something other than a human user, such as a data port.</p>
<p id="p-0089" num="0088">The verification device <b>120</b> includes a processor <b>122</b> and memory <b>124</b>. The verification device <b>120</b> may also include an input device <b>126</b> and an output device <b>128</b>. In some embodiments, the verification device <b>120</b> will be relatively small for reasons described herein. For example, keeping the verification device <b>120</b> small and simple can offer advantages for the security offered by the device <b>120</b>. Also, if the verification device <b>120</b> is removable from the computer <b>110</b> and meant to be portable with a user, then a relatively small size is advantageous. However, a small size is not required and it is possible for the verification device <b>120</b> to be larger and to include other features and functions, particularly if the verification device <b>120</b> is integrated into the computer or if the verification device <b>120</b> is not meant to be portable with the user. In the case of a removable verification device <b>120</b>, it may also include a communications interface <b>140</b> that is not permanently attached to the computer <b>110</b>, such as a USB port, an infrared transmitter/receiver or other communications interfaces that allow the verification device <b>120</b> to be connected and disconnected by the user. In those embodiments, the computer <b>110</b> will also have a communications interface <b>140</b> that is complimentary to the communications interface <b>140</b> of the verification device <b>120</b>.</p>
<p id="p-0090" num="0089">The verification device <b>120</b> may be integrated with the other parts of the computer <b>110</b>, or the verification device <b>120</b> may be removable and portable by a user. In one embodiment, the verification device <b>120</b> plugs into a port of the computer, such as a USB port or any other port that may be part of a computer and accessible by a user.</p>
<p id="p-0091" num="0090">The verification device <b>120</b> includes information or policies about other parts of the computer <b>110</b>. For example, the verification device <b>120</b> may include policies about the secure guest <b>312</b> (see <figref idref="DRAWINGS">FIG. 3</figref>) and the hypervisor <b>316</b> (see <figref idref="DRAWINGS">FIG. 3</figref>), as well as other information. The verification device may include a policy for each guest, or it may include policies that are shared by more than one guest. For example, the policies may include known good identity measurements for the select guest <b>312</b>, the hypervisor <b>316</b>, and other parts of the computer <b>110</b>.</p>
<p id="p-0092" num="0091">The policies may also include a list of trusted endpoints on a network <b>210</b> (see <figref idref="DRAWINGS">FIG. 2</figref>) for guests that have a network interface or which otherwise have access to a network <b>210</b>. The verification device <b>120</b> may, for example, include a single list of trusted endpoints on the network <b>210</b>, or it may include a list of trusted endpoints for each guest, or it may include multiple lists of trusted endpoints, some of which are unique to a particular guest and some of which are shared by more than one guest. Each policy may apply to a different guest or some policies may be shared by more than one guest.</p>
<p id="p-0093" num="0092">The policies may also identify other guests with which a particular guest may share information or otherwise communicate. For example, there may be a policy for a select guest <b>312</b> identifying the other guests with which the select guest <b>312</b> may share information.</p>
<p id="p-0094" num="0093">The verification device <b>120</b> may or may not permit policies or other information to be added, deleted, or modified. For example, in one embodiment the verification device <b>120</b> allows updates to be made to trusted endpoints on a network <b>210</b>. In another embodiment, the verification device <b>120</b> is read-only in order to reduce the risk of the verification device <b>120</b> being compromised.</p>
<p id="p-0095" num="0094">The processor <b>122</b> in the verification device <b>120</b> performs certain functions, as described herein. The processor <b>122</b> in the verification device <b>120</b> is connected to and communicates with the processor <b>112</b>.</p>
<p id="p-0096" num="0095">The memory <b>124</b> in the verification device can be any form of computer-readable memory, and may store information in magnetic form, optical form, electrical form, or other forms. The memory <b>124</b> may have many variations, such as those described above with regard to memory <b>114</b>. For example, the memory <b>124</b> in the verification device may be separate from the processor <b>122</b> in the verification device, or the memory <b>124</b> in the verification device may be integrated with the processor <b>122</b> in the verification device. The memory <b>124</b> in the verification device may also include more than one memory device, which may be integrated with the processor <b>122</b> in the verification device, separate from the processor <b>122</b> in the verification device, or both. Other variations are also possible.</p>
<p id="p-0097" num="0096">The memory <b>124</b> includes computer readable instructions which, when executed by the processor <b>122</b> in the verification device, cause the processor <b>122</b> in the verification device to perform certain functions, as described herein.</p>
<p id="p-0098" num="0097">The input device <b>126</b> and the output device <b>128</b> may be the same or different than the input <b>116</b> and output <b>118</b> devices of the computer <b>110</b>. For example, the verification device <b>120</b> may be a relatively small device and, as a result, the input <b>126</b> and output <b>128</b> devices may be correspondingly small and simplified. For example, rather than a keyboard or a computer mouse, the input device <b>126</b> may include one or more buttons or switches for input from a user, such as an analog switch or a multi-position knob. Similarly, rather than a full video display, the output device <b>128</b> may include one or more lights, buzzer or other device to provide feedback to the user. Alternatively, the verification device <b>120</b> may also have larger and/or more complex input <b>126</b> and output <b>128</b> devices. In one embodiment, the verification device <b>120</b> may include &#x201c;soft keys&#x201d; and an electronic display, such as may be used with a PDA or smart phone. In other embodiments, the verification device <b>120</b> may include a combination of soft keys and physical buttons or switches. Other variations are also possible.</p>
<p id="p-0099" num="0098">Many variations are possible with the computer <b>110</b> according to the present invention. For example, more than one processor <b>112</b>, memory <b>114</b>, input device <b>116</b>, output device <b>118</b>, and verification device <b>120</b> (as well more than one of each component in the verification device <b>120</b>), may be present in or with the computer <b>110</b>. In addition, devices not shown in <figref idref="DRAWINGS">FIG. 1</figref> may also be included in the computer <b>110</b>, and devices shown in <figref idref="DRAWINGS">FIG. 1</figref> may be combined or integrated together into a single device, or in some cases omitted. Similar variations and modifications are also possible with other embodiments described and illustrated herein.</p>
<p id="p-0100" num="0099">The present invention may be embodied in many forms. For example, the present invention may be an embedded system such as software on a chip. In another embodiment, the present invention may be embodied as one or more devices located in one or more parts of the invention illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. For example, the present invention may be embodied as computer-readable instructions (e.g, software on a chip, software in a portable or integrated memory device, hard-wired instructions embodied in a hardware device, or other variations). In another embodiment, the present invention may be embodied as one or more discrete computers. The present invention may also be embodied as computer-readable instructions (e.g., computer software, firmware, or hardware). The computer-readable instructions may be stored in memory devices which may be integrated or embedded into another device, or which may be removable and portable. Other variations and embodiments are also possible.</p>
<p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. 2</figref> illustrates another embodiment of the present invention in which several computers <b>110</b> are connected together via a network <b>210</b>. The network <b>210</b> provides a connection between the several computers <b>110</b>. The computers <b>110</b> may be referred to as &#x201c;endpoints&#x201d; on the network <b>210</b>. In other words, from the perspective of one of the computers <b>110</b> on the network <b>210</b>, the other computers <b>110</b> are endpoints on the network <b>210</b> with which a network connection can be made.</p>
<p id="p-0102" num="0101">The network <b>210</b> may be, for example, the Internet, a local area network, a wide area network, a metro area network, or other types of networks. The network <b>210</b> may be a wired network (such as an electrical network or an optical network), a wireless network, or a combination of different kinds of networks.</p>
<p id="p-0103" num="0102">As described above, the present invention may be embodied as software, hardware, firmware, or in other forms. The present invention may, for example, be embodied in some or in all of the computers <b>110</b> in the network <b>210</b>. For example, only one computer <b>110</b> may include a verification device <b>120</b>, while the other computers <b>110</b> on the network <b>210</b> may operate without verification devices <b>120</b>. In other embodiments, several or all of the computers <b>110</b> may include verification devices <b>120</b>. In other embodiments, the network <b>210</b> itself may include one or more parts embodying the present invention, including verification devices <b>120</b>.</p>
<p id="p-0104" num="0103"><figref idref="DRAWINGS">FIG. 3A</figref> illustrates one embodiment of a computing platform <b>310</b> that may be created and used with the present invention. The computing platform <b>310</b> may be created, for example, when the computer-readable instructions in the memory <b>114</b> of the computer <b>110</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to create the computing platform <b>310</b>.</p>
<p id="p-0105" num="0104">In the illustrated embodiment, the computing platform <b>310</b> includes a select guest <b>312</b>, a legacy guest <b>314</b>, and a hypervisor <b>316</b>. The computing platform <b>310</b> may also include one or more network interfaces <b>320</b>. The select guest <b>312</b>, the legacy guest <b>314</b>, and the hypervisor <b>316</b> may each have one or more characteristics, such as a privilege level, an identity, and other characteristics.</p>
<p id="p-0106" num="0105">In one embodiment, the hypervisor <b>316</b> has a privilege level that is more privileged than that of both the select guest <b>312</b> and the legacy guest <b>314</b>, and the hypervisor <b>316</b> supports both the select guest <b>312</b> and the legacy guest <b>314</b>.</p>
<p id="p-0107" num="0106">The select guest <b>312</b> is a guest which is meant to be kept secure from certain other parts of the computer <b>110</b>. For example, the select guest <b>312</b> may be an application which is used for secure financial transactions, or for exchanging personal and sensitive information with a healthcare provider, or information or an application for use, review, or processing by the user in a secure environment.</p>
<p id="p-0108" num="0107">The legacy guest <b>314</b>, in contrast, is a guest which is not assumed to be secure or free from undesirable conditions such as infection by malware.</p>
<p id="p-0109" num="0108">The hypervisor <b>316</b> has access to both the select guest <b>312</b> and the legacy guest <b>314</b> and controls information and access available to the select <b>312</b> and legacy <b>314</b> guest. The hypervisor <b>316</b> can also perform other tasks such as, for example, partitioning memory <b>114</b>. In one embodiment, the hypervisor <b>316</b> partitions a unique portion of the memory <b>114</b> for the exclusive use of the select guest <b>312</b>, partitions a unique portion of the memory <b>114</b> for the exclusive use of the legacy guest <b>314</b>, and partitions a unique portion of the memory <b>114</b> for the exclusive use of the hypervisor <b>316</b>. Many other embodiments are also possible, such as partitioning memory <b>114</b> for more than one select guest <b>312</b>, more than one legacy guest <b>314</b>, and more than one hypervisor <b>316</b>. The unique portions of memory <b>114</b> may be different parts of the same memory device or it may be parts of different memory devices, or combinations thereof. Furthermore, the hypervisor <b>316</b> may also partition memory for shared use by those devices, and the hypervisor <b>316</b> may partition memory for exclusive or shared use by other parts of the computer <b>110</b>.</p>
<p id="p-0110" num="0109">The network interfaces <b>320</b> are shown in both the select guest <b>312</b> and the legacy guest <b>314</b> and provide a connection to the network <b>210</b>. In other embodiments, less than all of the guests may include a network interface <b>320</b>. In some embodiments, neither guest has a network interface <b>320</b>. In some embodiments, the physical network interface <b>320</b> for one or more of the guests may be located in the verification device <b>120</b>. This is advantageous because it allows the hypervisor <b>316</b> to control access between the guests and the network interface <b>320</b>. In other embodiments, the network interface for one or more of the guests may be located outside of the verification device <b>120</b>, such as in another part of the computer. As in the case of the network interface <b>320</b> being located in the verification device <b>120</b>, this embodiment may also allow the hypervisor <b>316</b> to control access between the guests and the network interface <b>320</b>.</p>
<p id="p-0111" num="0110">The computing platform <b>310</b> may take many forms. For example, the computing platform <b>310</b> may include one or more select guests <b>312</b>, one or more legacy guests <b>314</b>, and one or more hypervisors <b>316</b>. Furthermore, the computing platform <b>310</b> may include other features not illustrated herein.</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 3B</figref> illustrates another embodiment of the computing platform <b>310</b> in which there is more than one select guest <b>312</b>, more than one legacy guest <b>314</b>, and more than one hypervisor <b>316</b>. Many variations are possible with the present invention, including numbers and combinations of select guests <b>312</b>, legacy guests <b>314</b>, hypervisors <b>316</b>, and network interfaces <b>320</b> other than those illustrated herein. For example, the present invention may be used with two select guests <b>312</b>, three legacy guests <b>314</b>, one hypervisor <b>316</b>, and a network interface in every guest, as well as other combinations.</p>
<p id="p-0113" num="0112">The properties and characteristics of the select guest <b>312</b>, legacy guest <b>314</b>, hypervisors <b>316</b>, and network interfaces <b>320</b> may be as described above. For example, each select guest <b>312</b> can have a privilege level, an identity, and other information, which may be the same for each select guest <b>312</b> or it may be different. The same is true for the legacy guests <b>314</b>, hypervisors <b>316</b>, and network interfaces <b>320</b>.</p>
<p id="p-0114" num="0113">In one embodiment, the hypervisor <b>316</b> supports the select guest <b>312</b> and the legacy guests <b>314</b>, and both of the hypervisors <b>316</b> have a privilege level that is more privileged that the privilege level of the select guests. <b>312</b> and legacy guests <b>314</b>. Also, the hypervisors <b>316</b> may partition unique of shared portions of the memory <b>114</b> for the exclusive or shared use of the select <b>312</b> and legacy <b>314</b> guests. The verification device <b>120</b> may include a policy for each of the select <b>312</b> and legacy <b>314</b> guests.</p>
<p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. 3C</figref> illustrates another embodiment of a computing platform <b>310</b> that may be created and used with the present invention. The computing platform <b>310</b> controls access between the select <b>312</b> and legacy <b>314</b> guests and one or more devices. In the illustrated embodiment there are two devices and they are storage media devices <b>130</b>, although more or fewer than two devices may be used with the present invention, and devices other than storage media devices may be used with the present invention.</p>
<p id="p-0116" num="0115">In the illustrated embodiment there are two allocated devices and those devices are storage media devices <b>130</b>, although other devices may also be shared. The hypervisor <b>316</b> allocates the two devices <b>130</b> for exclusive use by the select <b>312</b> and legacy <b>314</b> guests, respectively.</p>
<p id="p-0117" num="0116">The present invention may be used with two separate physical devices <b>130</b> allocated to the select <b>312</b> and legacy <b>314</b> guests, respectively. Alternatively, the present invention may also be used where a single device <b>130</b> has two parts that are allocated to the select <b>312</b> and legacy <b>314</b> guests, respectively. For example, the hypervisor <b>316</b> may partition different parts of a single data storage media device <b>130</b> to provide a unique portion of memory for the exclusive use of the select guest <b>312</b> and a unique portion of memory for the exclusive use of the legacy guest <b>314</b></p>
<p id="p-0118" num="0117">The hypervisor <b>316</b> may also control access between the select <b>312</b> and legacy <b>314</b> guests and the one or more storage media devices <b>130</b>. For example, the hypervisor <b>316</b> may detect when one of the guests <b>312</b>, <b>314</b> sends instructions (e.g., write instructions or read instructions) to the storage media device(s) <b>130</b>. When the hypervisor <b>316</b> detects that instructions are coming from the select guest <b>312</b>, the hypervisor <b>316</b> sends the instructions to the allocated device or partition for the select guest <b>312</b> and, if applicable, sends the data from the storage media device <b>130</b> to the select guest <b>312</b>. Similarly, when the hypervisor <b>316</b> detects that instructions are coming from the legacy guest <b>312</b>, the hypervisor <b>316</b> sends the instructions to the allocated device or partition for the legacy guest <b>314</b> and, if applicable, sends the data from the storage media device <b>130</b> to the legacy guest <b>314</b>.</p>
<p id="p-0119" num="0118">The present invention may also include one or more base devices which are used by both the select <b>312</b> and legacy <b>314</b> guests. In that embodiment, the hypervisor partitions the same base device for use by both the select <b>312</b> and legacy <b>314</b> guests.</p>
<p id="p-0120" num="0119"><figref idref="DRAWINGS">FIG. 3D</figref> illustrates another embodiment of a computing platform <b>310</b> that may be created and used with the present invention. The computing platform <b>310</b> controls access between the select <b>312</b> and legacy <b>314</b> guests and a shared device. In the illustrated embodiment the device is a storage media device <b>130</b>, although other devices may also be used with the present invention.</p>
<p id="p-0121" num="0120">The present invention may be used to allow the select guest <b>312</b> to store encrypted data on the shared storage media device <b>130</b> and to protect that data from unauthorized access. This will be described in more detail hereinbelow with reference to <figref idref="DRAWINGS">FIG. 14</figref>.</p>
<p id="p-0122" num="0121"><figref idref="DRAWINGS">FIG. 4</figref> illustrates one embodiment of how the processor <b>112</b> interacts with the verification device <b>120</b> to control the operation of the select guests <b>312</b> and the legacy guests <b>314</b>. In the illustrated embodiment, the process represents a situation in which there is first a request to execute the select guest <b>312</b>, followed by a request to execute the legacy guest <b>314</b>, followed by a request to execute the select guest again.</p>
<p id="p-0123" num="0122"><figref idref="DRAWINGS">FIGS. 5A and 5B</figref> illustrate one embodiment of a process according to the present invention that is performed by the processor <b>112</b>.</p>
<p id="p-0124" num="0123"><figref idref="DRAWINGS">FIG. 5A</figref> illustrates one embodiment of a process according to the present invention that is performed by the processor <b>112</b> after the processor <b>112</b> receives a signal indicating a request to execute the select guest <b>312</b>. A request to execute the select guest <b>312</b> may be received immediately after creating the computing platform <b>310</b>, or the request may be received at a later time after the processor <b>112</b> has perform other tasks, such as executing one or more legacy guests <b>314</b>. After receiving the request, the processor <b>112</b> sends certain information related to the select guest <b>312</b> to the verification device <b>120</b>.</p>
<p id="p-0125" num="0124"><figref idref="DRAWINGS">FIG. 6</figref> illustrates one embodiment of a process according to the present invention that is performed by the verification device <b>120</b> after receiving information related to the select guest <b>312</b> from the processor <b>112</b>. The verification device <b>120</b> determines whether the select guest <b>312</b> should be executed and sends a signal back to the processor <b>112</b>.</p>
<p id="p-0126" num="0125"><figref idref="DRAWINGS">FIG. 5B</figref> illustrates one embodiment of a process according to the present invention that is performed by the processor <b>112</b> after receiving the signal from the verification device <b>120</b>.</p>
<p id="p-0127" num="0126"><figref idref="DRAWINGS">FIG. 7A</figref> illustrates one embodiment of a process according to the present invention that is performed by the processor <b>112</b> when the processor <b>112</b> receives a request to execute the legacy guest <b>314</b> when the select guest <b>312</b> is executing.</p>
<p id="p-0128" num="0127"><figref idref="DRAWINGS">FIG. 7B</figref> illustrates one embodiment of a process according to the present invention that is performed by the processor <b>112</b> when the processor <b>112</b> receives a request to execute the select guest <b>312</b> when the legacy guest <b>314</b> is executing. As in <figref idref="DRAWINGS">FIG. 5A</figref>, the processor <b>112</b> sends certain information related to the select guest <b>312</b> to the verification device.</p>
<p id="p-0129" num="0128"><figref idref="DRAWINGS">FIG. 8</figref> illustrates one embodiment of a process according to the present invention that is performed by the verification device <b>120</b> after receiving information related to the select guest <b>312</b> from the processor <b>112</b>. The verification device <b>120</b> determines whether the select guest <b>312</b> should be executed and sends a signal back to the processor <b>112</b>.</p>
<p id="p-0130" num="0129"><figref idref="DRAWINGS">FIG. 7C</figref> illustrates one embodiment of a process according to the present invention that is performed by the processor <b>112</b> after receiving the signal from the verification device <b>120</b>.</p>
<p id="p-0131" num="0130">The process may continue by proceeding to either the process of <figref idref="DRAWINGS">FIG. 7A</figref> or the process of <figref idref="DRAWINGS">FIG. 7B</figref>, depending on whether the next request is one to execute the legacy guest <b>314</b> or the select guest <b>312</b>.</p>
<p id="p-0132" num="0131">Each of <figref idref="DRAWINGS">FIGS. 5-8</figref> will now be described in more detail.</p>
<p id="p-0133" num="0132"><figref idref="DRAWINGS">FIGS. 5A and 5B</figref> illustrate one embodiment of another method performed by the processor <b>112</b>. The method may be performed after the computing platform <b>310</b> is created and when a user wants to execute the select guest <b>312</b>. The method may be performed, for example, when the computer-readable instructions in the memory <b>114</b> of the processor <b>112</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform the following steps.</p>
<p id="p-0134" num="0133">Step <b>510</b> includes receiving a signal indicative of a request to execute the select guest <b>312</b>. The signal may be initiated by a guest in the computing platform <b>310</b>, or it may be initiated by a human user, or it may be initiated by some other part of the computer <b>110</b> or by another computer.</p>
<p id="p-0135" num="0134">Step <b>512</b> includes authenticating a secure connection between the hypervisor <b>316</b> and the verification device <b>120</b>. This step is performed after receiving the signal indicative of the request to execute the select guest <b>312</b>.</p>
<p id="p-0136" num="0135">Step <b>514</b> includes measuring the identity of at least a portion of the select guest <b>312</b>. This step may measure the identity of the entire select guest <b>312</b> or it may measure the identity of less than all of the select guest <b>312</b>. This measurement is made when the select guest is in a known state, such as before the select guest <b>312</b> executes any instructions. This measurement of the select guest <b>312</b> can be used to determine if the select guest is in a proper state or if it has been modified or otherwise compromised. For example, if malware has infected the select guest <b>46</b>, the measurement of the identity of the select guest <b>46</b> will be different than the measurement of the uninfected select guest <b>46</b>. The hypervisor <b>316</b> may measure all guests (e.g., select guests <b>312</b> and legacy guests <b>314</b>) prior to any of the guests being executed. In this way, the hypervisor <b>316</b> has an identity measurement for all of the guests. Alternatively, the hypervisor <b>316</b> may measure identities of guests at other times, such as immediately before each guest is executed, or at other times.</p>
<p id="p-0137" num="0136">Step <b>516</b> includes sending the measurement of the identity of the select guest <b>312</b> to the verification device <b>46</b> wherein it will be compared with a policy stored in the verification device <b>120</b>. Alternatively, this comparison can be performed by the processor <b>112</b>, although the verification device <b>120</b> may be more secure than the processor <b>112</b> and, therefore, the use of the verification device <b>120</b> may be preferred.</p>
<p id="p-0138" num="0137">The steps performed by the verification device <b>120</b> after receiving the measurement of the identity of the select guest <b>312</b> are described below with reference to <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0139" num="0138">Step <b>518</b> includes receiving a signal from the verification device <b>120</b> indicative of whether to execute the select guest <b>312</b>.</p>
<p id="p-0140" num="0139">Step <b>520</b> includes executing the select guest <b>312</b> if the signal from the verification device <b>120</b> indicates that the select guest <b>312</b> should be executed.</p>
<p id="p-0141" num="0140">If, however, the signal from the verification device <b>120</b> indicates that the select guest <b>312</b> should not be executed, then step <b>520</b> may not be executed. For example, the computer <b>110</b> may include a default in which the select guest <b>312</b> is never executed in these circumstances. Alternatively, the computer <b>110</b> may include an override such as, for example, if the user provides additional input to execute the select guest even after the user receives a signal indicating that the measurement of the select guest <b>312</b> received by the verification device <b>120</b> does not corresponds with the policy stored in the verification device <b>120</b>. This input from the user may be provided, for example, through an input on the verification device <b>120</b> as described below with regard to <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0142" num="0141">Steps <b>512</b>, <b>514</b>, and <b>516</b> are performed after step <b>510</b>, receiving the signal indicative of the request to execute the select guest <b>312</b>. A recent measurement of the select guest <b>312</b> is desirable in order to avoid a situation in which the select guest <b>312</b> is compromised after measurement and before execution. These steps are also performed without rebooting the computer <b>110</b>. This is important because rebooting the computer <b>110</b> is time consuming and it is desirable to reduce the time that the user is required to wait. However, the present invention can be used in different embodiments, such as where the computer <b>110</b> is rebooted.</p>
<p id="p-0143" num="0142"><figref idref="DRAWINGS">FIG. 6</figref> illustrates one embodiment of a method performed by the processor <b>122</b> of the verification device <b>120</b>. The method may be performed between steps <b>516</b> and <b>518</b> of <figref idref="DRAWINGS">FIG. 5</figref> to verify that the select guest <b>312</b> is still secure and not compromised. The method may be performed, for example, when the computer-readable instructions in the memory <b>124</b> of the verification device <b>120</b>, when executed by the processor <b>122</b> in the verification device <b>120</b>, cause the processor <b>122</b> in the verification device <b>120</b> to perform the following steps.</p>
<p id="p-0144" num="0143">Step <b>610</b> includes receiving the measurement of the select guest <b>312</b> from the processor <b>112</b> in the computer <b>110</b>. The measurement and the sending of the measurement are described above in <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0145" num="0144">Step <b>612</b> includes comparing the policy stored in the verification device <b>120</b> with the measurement of the select guest <b>312</b> received by the verification device <b>120</b>. This step compares the measured value with the known value stored as a policy in the verification device <b>120</b> and determines whether the measurement of the select guest <b>312</b> received by the verification device <b>120</b> corresponds with the policy stored in the verification device <b>120</b>.</p>
<p id="p-0146" num="0145">Step <b>614</b> includes providing a human-perceptible indication of whether the measurement of the select guest <b>312</b> received by the verification device <b>120</b> corresponds with the policy stored in the verification device <b>120</b>. This step may be omitted in some embodiments. In other embodiments including more than one select guests <b>312</b>, this step may be or may also include providing a human-perceptible indication of which of a plurality of select guests <b>312</b> is selected for execution.</p>
<p id="p-0147" num="0146">Step <b>616</b> includes receiving an input from a user indicative of confirmation to execute the selection guest <b>312</b>. The human confirmation in this step may be confirmation to execute the select guest <b>312</b> after it is determined that the measurement of the select guest <b>312</b> received by the verification device <b>120</b> corresponds with the policy stored in the verification device <b>120</b>. Alternatively, the human confirmation in this step may be confirmation to override a situation in which the measurement of the select guest <b>312</b> received by the verification device <b>120</b> does not correspond with the policy stored in the verification device <b>120</b>, but in which the user still wants to execute the select guest <b>312</b> despite the potential problem with the select guest <b>312</b>. This step may be omitted in some embodiments. For example, the present invention may not require input from the user in certain situations, such as when the policy stored in the verification device <b>120</b> corresponds with the measurement of the identity of the select guest <b>312</b> that was received by the verification device <b>120</b>. In another embodiment, the present invention may provide a warning but not require user input before executing the select guest <b>312</b>, even if the select guest <b>312</b> appears to be compromised.</p>
<p id="p-0148" num="0147">Step <b>618</b> includes sending a signal to the processor <b>112</b> indicative of whether to execute the select guest <b>312</b>. The signal to execute the select guest <b>312</b> may be based on whether the measurement of the select guest <b>312</b> received by the verification device <b>120</b> corresponds with the policy stored in the verification device <b>120</b>. Alternatively, the signal to execute the select guest <b>312</b> may be based on the confirmation from the user in step <b>616</b>.</p>
<p id="p-0149" num="0148">Steps <b>610</b> and <b>612</b> are performed after step <b>510</b>, receiving the signal indicative of the request to execute the select guest <b>312</b>. A recent measurement of the select guest <b>312</b> is desirable in order to avoid a situation in which the select guest <b>312</b> is compromised after measurement and before execution. These steps are also performed without rebooting the computer <b>110</b>. This is important because rebooting the computer <b>110</b> is time consuming and it is desirable to reduce the time that the user is required to wait. However, the present invention can be used in different embodiments, such as where the computer <b>110</b> is rebooted.</p>
<p id="p-0150" num="0149">The order of the steps do not need to be exactly as illustrated herein. For example, although step <b>614</b> is illustrated as being performed before step <b>618</b>, in other embodiments step <b>614</b> may be performed after step <b>618</b>.</p>
<p id="p-0151" num="0150"><figref idref="DRAWINGS">FIGS. 7A</figref>, <b>7</b>B, and <b>7</b>C illustrate one embodiment of a method performed by the processor <b>112</b> after the execution of the select guest <b>312</b>. The method may be performed, for example, when the computer-readable instructions in the memory <b>114</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform the following steps.</p>
<p id="p-0152" num="0151">Step <b>710</b> includes receiving a signal indicative of a request to execute the legacy <b>314</b> when the select guest is already executing (i.e., after step <b>520</b>). This signal may be initiated by a human user or by a non-human user. For example, this step may include receiving a signal initiated by one of the guests <b>312</b>, <b>314</b> in the computing platform <b>310</b>. The select guest <b>312</b> may request the execution of the legacy guest <b>314</b>, or one legacy guest <b>314</b> may request the execution of another legacy guest <b>314</b>. Alternatively, this step may include receiving an input at the verification device <b>120</b> from a human user indicative of a request to execute the legacy device <b>314</b>. In that case, the input at the verification device <b>120</b> will be sent to the processor <b>112</b> for the operation of this step.</p>
<p id="p-0153" num="0152">Step <b>712</b> includes stopping the execution of the select guest <b>312</b>. The may be pausing the execution of the select guest <b>312</b> or terminating the execution of the select guest <b>312</b>.</p>
<p id="p-0154" num="0153">Step <b>714</b> includes executing the legacy guest <b>314</b> after stopping the select guest <b>312</b>.</p>
<p id="p-0155" num="0154">After the legacy guest <b>314</b> is executed, the computer <b>110</b> may receive another request to execute the select guest <b>312</b>, which can involve resuming or restarting the execution of the select guest <b>312</b>. In that case, the following steps may be performed, which are similar to steps <b>510</b> to <b>516</b> and, as a result, some details described with reference to <figref idref="DRAWINGS">FIG. 5</figref> will not be repeated here.</p>
<p id="p-0156" num="0155">Step <b>716</b> includes receiving a signal indicative of a request to execute the select guest <b>312</b>. This can be a request to resume the execution of the select guest <b>312</b> if the select guest <b>312</b> was previously paused, or it can be a request to restart execution of the select guest <b>312</b> if the select guest was previously terminated. This signal may be initiated by a human user or a non-human. For example, the signal may be initiated by one of the guests <b>312</b>, <b>314</b> in the computing platform <b>310</b>. Alternatively, the request may be initiated by a human user, such as by providing input through the verification device <b>120</b> or though some other part of the computer <b>110</b>.</p>
<p id="p-0157" num="0156">Step <b>718</b> includes stopping the execution of the legacy guest <b>314</b>. As described above, stopping may be pausing or terminating the execution of the legacy guest <b>314</b>. Although this step is indicated as being performed in a particular part of the process, it may be performed at other parts of the process. However, in order to reduce the risk of the legacy guest <b>314</b> corrupting the select guest <b>312</b>, the legacy guest <b>314</b> is preferable stopped before executing the select guest <b>312</b>.</p>
<p id="p-0158" num="0157">Step <b>720</b> includes authenticating a secure connection between the hypervisor <b>316</b> and the verification device <b>120</b>.</p>
<p id="p-0159" num="0158">Step <b>722</b> includes sending a measurement of the identity of the select guest <b>312</b> to the verification device <b>120</b>. If the select guest <b>312</b> was previously paused, then this measurement may be the last or most recent measurement before the select guest <b>312</b> was executed. Alternatively, if the select guest <b>312</b> was terminated in step <b>712</b>, then the select guest <b>312</b> may be measured again. In any event, the most recent measurement is usually used in order to utilize the most up to date information. However, it is possible to use the present invention with information that is not the most recent.</p>
<p id="p-0160" num="0159">Step <b>724</b> includes receiving a signal from the verification device <b>120</b> indicative of whether to execute the select guest <b>312</b>.</p>
<p id="p-0161" num="0160">Step <b>726</b> includes executing the select guest <b>312</b> if the signal from the verification device <b>120</b> indicates that the select guest <b>312</b> should be executed. However, as described above, the present invention allows for variations and alternative embodiments.</p>
<p id="p-0162" num="0161"><figref idref="DRAWINGS">FIG. 8</figref> illustrates one embodiment of a method performed by the processor <b>122</b> in the verification device <b>120</b> between steps <b>722</b> and <b>724</b> in <figref idref="DRAWINGS">FIG. 7</figref>. These steps are analogous to the steps in <figref idref="DRAWINGS">FIG. 6</figref> and, therefore, some details of these steps described with reference to <figref idref="DRAWINGS">FIG. 6</figref> are not repeated here. The method may be performed, for example, when the computer-readable instructions in the memory <b>124</b>, when executed by the processor <b>122</b>, cause the processor <b>122</b> to perform the steps.</p>
<p id="p-0163" num="0162">Step <b>810</b> includes receiving the measurement of the identity of the select guest <b>312</b> from the processor <b>112</b>.</p>
<p id="p-0164" num="0163">Step <b>812</b> includes comparing the policy stored in the verification device <b>120</b> with the measurement of the identity of the select guest <b>312</b> that was received by the verification device <b>120</b>.</p>
<p id="p-0165" num="0164">Step <b>814</b> includes providing a human-perceptible indication of whether the measurement of the select guest <b>312</b> received by the verification device <b>120</b> corresponds with the policy stored in the verification device <b>120</b>. This step may be omitted in some embodiments.</p>
<p id="p-0166" num="0165">Step <b>816</b> includes receiving an input from a user indicative of confirmation to execute or to resume execution of the select guest <b>312</b>. This step may be omitted in some embodiments. For example, the present invention may not require input from the user in certain situations, such as when the policy stored in the verification device <b>120</b> corresponds with the measurement of the identity of the select guest <b>312</b> that was received by the verification device <b>120</b>.</p>
<p id="p-0167" num="0166">Step <b>818</b> includes sending a signal to the processor <b>112</b> indicative of whether to execute the select guest <b>312</b>.</p>
<p id="p-0168" num="0167">These steps may be performed without rebooting the computer <b>110</b>, as described above. Some of the steps may be omitted and other steps may be performed along with those illustrated.</p>
<p id="p-0169" num="0168"><figref idref="DRAWINGS">FIG. 9</figref> illustrates one embodiment of how the processor <b>112</b> interacts with the verification device <b>120</b> to control the operation of the select guests <b>312</b> and the legacy guests <b>314</b>. This figure illustrates a more generalize process flow that that illustrated in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0170" num="0169"><figref idref="DRAWINGS">FIG. 10A</figref> illustrates a routing process that is used to determine whether the user wants to execute the select guest <b>312</b> or the legacy guest <b>314</b>.</p>
<p id="p-0171" num="0170"><figref idref="DRAWINGS">FIG. 10B</figref> represents one embodiment of the process according to the present invention when the user requests to execute the select guest <b>312</b>. After receiving the request, the processor <b>112</b> sends certain information related to the select guest <b>312</b> to the verification device <b>120</b>.</p>
<p id="p-0172" num="0171"><figref idref="DRAWINGS">FIGS. 6 and 8</figref> illustrate embodiments of a process according to the present invention that is performed by the verification device <b>120</b> after receiving information related to the select guest <b>312</b> from the processor <b>112</b>. The verification device <b>120</b> determines whether the select guest <b>312</b> should be executed and sends a signal back to the processor <b>112</b>.</p>
<p id="p-0173" num="0172"><figref idref="DRAWINGS">FIG. 10C</figref> illustrates one embodiment of a process according to the present invention that is performed by the processor <b>112</b> after receiving the signal from the verification device <b>120</b>. After the process of <figref idref="DRAWINGS">FIG. 10C</figref> is completed, it returns to <figref idref="DRAWINGS">FIG. 10A</figref>.</p>
<p id="p-0174" num="0173"><figref idref="DRAWINGS">FIG. 10D</figref> illustrates one embodiment of the process according to the present invention when the user requests to execute the legacy guest <b>314</b>.</p>
<p id="p-0175" num="0174"><figref idref="DRAWINGS">FIGS. 10A-D</figref> will now be described in more detail.</p>
<p id="p-0176" num="0175"><figref idref="DRAWINGS">FIG. 10A</figref> illustrates one embodiment of a method that may be performed by the processor <b>112</b>. The method may be performed after the computing platform <b>310</b> is created. The method may be performed, for example, when the computer-readable instructions in the memory of the processor <b>112</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform the following steps.</p>
<p id="p-0177" num="0176">Step <b>1010</b> includes determining whether there has been a request to start the select guest <b>312</b>. If there has been such a request, the process move to step <b>1012</b>. If there has not been such a request, then the process moves to step <b>1014</b>.</p>
<p id="p-0178" num="0177">Step <b>1012</b> includes beginning the process of starting the select guest <b>312</b>, as described in <figref idref="DRAWINGS">FIG. 10B</figref>.</p>
<p id="p-0179" num="0178">Step <b>1014</b> includes determining whether there has been a request to start the legacy guest <b>314</b>. If there has been such a request, the process move to step <b>1016</b>. If there has not been such a request, then the process moves to step <b>1010</b>.</p>
<p id="p-0180" num="0179">Step <b>1016</b> includes beginning the process of starting the legacy guest <b>314</b>, as described in <figref idref="DRAWINGS">FIG. 10D</figref>.</p>
<p id="p-0181" num="0180">The process may include steps in addition to those illustrated.</p>
<p id="p-0182" num="0181"><figref idref="DRAWINGS">FIG. 10B</figref> illustrates one embodiment of a method that may be performed by the processor <b>112</b>. The method may be performed, for example, when the computer-readable instructions in the memory of the processor <b>112</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform the following steps.</p>
<p id="p-0183" num="0182">Step <b>510</b>/<b>716</b> were previously described and include receiving a signal indicative of a request to execute the select guest. In some embodiments, this step may be eliminated or included in step <b>1010</b>.</p>
<p id="p-0184" num="0183">Step <b>1020</b> includes determining whether the legacy guest <b>314</b> is executing. If it is, then the process proceeds to step <b>718</b> to stop the execution of the legacy guest <b>314</b>. If it is not executing, the process proceeds to steps <b>512</b>/<b>720</b>.</p>
<p id="p-0185" num="0184">Step <b>718</b> has previously been described and includes stopping the legacy guest <b>314</b>.</p>
<p id="p-0186" num="0185">Steps <b>712</b>/<b>720</b> have been previously described and include authenticating a secure connection.</p>
<p id="p-0187" num="0186">Step <b>1030</b> determines whether there is a need to measure the identity of the select guest <b>312</b>. If there is a need, the process proceeds to step <b>514</b>. If there is not a need, the process proceeds to steps <b>516</b>/<b>722</b>.</p>
<p id="p-0188" num="0187">Step <b>514</b> has been previously described and includes measuring the identity of the select guest <b>312</b>.</p>
<p id="p-0189" num="0188">Steps <b>516</b>/<b>722</b> have been previously described and include sending the measurement of the identity of the select guest <b>312</b> to the verification device <b>120</b>. As described herein, this measurement may be a new measurement taken in step <b>512</b>, or a measurement that was take sometime before step <b>1030</b>.</p>
<p id="p-0190" num="0189"><figref idref="DRAWINGS">FIG. 10C</figref> illustrates one embodiment of a method that may be performed by the processor <b>112</b>. The method may be performed, for example, when the computer-readable instructions in the memory of the processor <b>112</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform the following steps.</p>
<p id="p-0191" num="0190">Steps <b>518</b>/<b>724</b> have been previously described and include receiving a signal from the verification device indicative of whether to execute the select guest <b>312</b>.</p>
<p id="p-0192" num="0191">Step <b>1040</b> determines whether the signal received from the verification device <b>120</b> indicates to execute the select guest <b>312</b>. If so, the process proceeds to steps <b>520</b>/<b>726</b>. If not, the process proceeds to step <b>1050</b>.</p>
<p id="p-0193" num="0192">Steps <b>520</b>/<b>726</b> have been previously described and include executing the select guest <b>312</b> when the processor <b>112</b> receives a signal from the verification device <b>120</b> indicating that the select guest <b>312</b> should be executed.</p>
<p id="p-0194" num="0193">Step <b>1050</b> includes not executing the select guest <b>312</b> when the processor <b>112</b> receives a signal from the verification device <b>120</b> indicating that the select guest <b>312</b> should not be executed.</p>
<p id="p-0195" num="0194"><figref idref="DRAWINGS">FIG. 10D</figref> illustrates one embodiment of a method that may be performed by the processor <b>112</b>. The method may be performed, for example, when the computer-readable instructions in the memory of the processor <b>112</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform the following steps.</p>
<p id="p-0196" num="0195">Step <b>710</b> has been previously described and includes receiving a signal indicative of a request to execute the legacy guest <b>314</b>. In some embodiments, this step may be eliminated or included in step <b>1014</b>.</p>
<p id="p-0197" num="0196">Step <b>1030</b> determines whether the select guest <b>312</b> is executing. If so, the process proceeds to step <b>712</b>. If not, the process proceeds to step <b>714</b>.</p>
<p id="p-0198" num="0197">Step <b>712</b> has been previously described and includes stopping the select guest <b>312</b>.</p>
<p id="p-0199" num="0198">Step <b>714</b> has been previously described and includes executing the legacy guest <b>314</b>.</p>
<p id="p-0200" num="0199">Many variations and modifications are possible with the present invention. In embodiments including more than one select guest <b>312</b>, more than one legacy guest <b>314</b>, more than one hypervisor <b>316</b>, or other variations of the present invention are utilized, the process steps described herein may be modified appropriately. For example, in embodiments including more than one select guest <b>312</b>, step <b>510</b> may be modified to be receiving a signal indicative of a request to execute one of the plurality of select guests <b>312</b>, step <b>514</b> may be modified to be measuring the identity of at least a portion of the select guest <b>312</b> corresponding to the signal indicative of the request to execute one of the plurality of select guests <b>312</b>, and step <b>516</b> may be modified to be sending a measurement of the identity of the select guest <b>312</b> corresponding to the signal indicative of the request to execute one of the plurality of select guests <b>312</b>. Other changes to other steps may also be made in a similar fashion. Several other variations and modifications are discussed below.</p>
<p id="p-0201" num="0200"><figref idref="DRAWINGS">FIG. 11</figref> illustrates one embodiment of the step of authenticating a secure connection between the hypervisor <b>316</b> and the verification device <b>120</b>, such as in steps <b>512</b> and <b>720</b>. In that embodiment, authenticating includes the following steps.</p>
<p id="p-0202" num="0201">Step <b>1110</b> includes measuring the identity of at least a portion of the hypervisor <b>316</b>. The identity of the entire hypervisor <b>316</b> may be measured, or the identity of less than all of the hypervisor <b>316</b> may be measured.</p>
<p id="p-0203" num="0202">Step <b>1112</b> includes sending the measurement of the identity of the hypervisor <b>316</b> to the verification device <b>120</b>.</p>
<p id="p-0204" num="0203">Steps <b>1110</b> and <b>1112</b> are performed after step <b>510</b>, receiving the signal indicative of the request to execute the select guest. Steps <b>1110</b> and <b>1112</b> are also performed without rebooting the computer <b>110</b>. As described above, it is desirable to measure a recent identity and it is also desirable to avoid rebooting the computer <b>110</b>. However, the present invention can be used in different embodiments, such as where the computer <b>110</b> is rebooted. Also, the processor <b>112</b> of the computer <b>110</b> may perform the step of measuring the identity of the hypervisor <b>316</b> before the hypervisor <b>316</b> executes any instructions or step <b>1110</b> may be performed after the hypervisor <b>316</b> executes.</p>
<p id="p-0205" num="0204">Steps <b>1110</b> and <b>1112</b> are used to determine whether the hypervisor <b>316</b> has been compromised. These steps are preferably used in combination with the steps shown in <figref idref="DRAWINGS">FIG. 12</figref>.</p>
<p id="p-0206" num="0205"><figref idref="DRAWINGS">FIG. 12</figref> illustrates additional steps that may be performed by the verification device <b>120</b>. These steps are complimentary to the steps of <figref idref="DRAWINGS">FIG. 11</figref> and they may be performed by the verification device <b>120</b> before or after the steps illustrated in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0207" num="0206">Step <b>1210</b> includes receiving the measurement of the hypervisor <b>316</b> from the processor <b>120</b> of the computer <b>110</b>.</p>
<p id="p-0208" num="0207">Step <b>1212</b> includes comparing the policy stored in the verification device <b>120</b> with the measurement of the hypervisor <b>316</b> received by the verification device <b>120</b>.</p>
<p id="p-0209" num="0208">Steps <b>1210</b> and <b>1212</b> are performed after step <b>1112</b>, sending the measurement of the identity of the hypervisor <b>316</b> to the verification device <b>120</b>. Steps <b>1210</b> and <b>1212</b> are also performed without rebooting the computer <b>110</b>. As described above, it is also desirable to avoid rebooting the computer <b>110</b>. However, the present invention can be used in different embodiments, such as where the computer <b>110</b> is rebooted.</p>
<p id="p-0210" num="0209"><figref idref="DRAWINGS">FIG. 13</figref> illustrates one embodiment of another method performed by the processor <b>112</b>. The method may be performed when there is an attempt to establish a network connection between one of the guests <b>312</b>, <b>314</b> and an endpoint on the network <b>210</b>. In this embodiment, the verification device <b>120</b> includes a policy for the guest in question, and that policy includes a list of trusted endpoints on the network <b>210</b>. The method may be performed, for example, when the computer-readable instructions in the memory <b>114</b> of the processor <b>112</b>, when executed by the processor <b>112</b>, cause the processor <b>112</b> to perform the following steps.</p>
<p id="p-0211" num="0210">Step <b>1310</b> includes identifying a network connection between a guest having a network interface and an endpoint on the network <b>210</b>. This step may include identifying the network connection after the network connection is initiated by the endpoint of the network <b>210</b> and before data transmitted by the guest is permitted to reach the network interface <b>320</b>. The guest may be either a select guest <b>312</b> or a legacy guest <b>314</b>.</p>
<p id="p-0212" num="0211">Step <b>1312</b> includes identifying the endpoint of the network connection. In other words, this step includes identifying where on the network the guest is trying to connect or where on the network a computer <b>110</b> is trying to connect to the guest.</p>
<p id="p-0213" num="0212">Step <b>1314</b> includes determining whether the network connection to the endpoint is permitted by the policy of trusted endpoints stored in the verification device.</p>
<p id="p-0214" num="0213">Many variations are possible with the present invention. For example, The network interface <b>320</b> may be located in the verification device <b>120</b> or outside of the verification device <b>120</b>, as discussed above.</p>
<p id="p-0215" num="0214">Steps <b>1310</b>, <b>1312</b>, and <b>1314</b> may be performed before data transmitted by the guest is permitted to reach the network interface. This may be done, for example, to better control communication and to better protect the computer <b>110</b>.</p>
<p id="p-0216" num="0215"><figref idref="DRAWINGS">FIG. 14</figref> illustrates one embodiment of a method that may be performed by the processor <b>112</b> in connection with the embodiment illustrated in <figref idref="DRAWINGS">FIG. 3D</figref>.</p>
<p id="p-0217" num="0216">Step <b>1410</b> includes the select guest <b>312</b> storing encrypted data on a storage media device <b>130</b>.</p>
<p id="p-0218" num="0217">Step <b>1412</b> includes the select guest <b>312</b> sending an encryption key and an identity measurement to the hypervisor <b>316</b>. The encryption key corresponds to the encrypted data and the identity measurement corresponds to a guest permitted to receive the encryption key from the hypervisor <b>316</b>.</p>
<p id="p-0219" num="0218">Step <b>1414</b> includes the hypervisor <b>316</b> receiving a request to access the encrypted data from a requesting guest. The requesting guest may be the select guest <b>312</b> that stored the encrypted data or the requesting guest may be a different select guest or a legacy guest <b>314</b>.</p>
<p id="p-0220" num="0219">Step <b>1416</b> includes the hypervisor <b>316</b> measuring the identity of the requesting guest before the requesting guest executes any instructions. For example, the hypervisor <b>316</b> may measure all guests (e.g., select guests <b>312</b> and legacy guests <b>314</b>) prior to any of the guests being executed. In this way, the hypervisor <b>316</b> has an identity measurement for all of the guests who may potentially request access to the encrypted data. Alternatively, the hypervisor <b>316</b> may measure identities of guests at other times, such as immediately before each guest is executed, or at other times.</p>
<p id="p-0221" num="0220">Step <b>1418</b> includes the hypervisor <b>316</b> providing the encryption key to the requesting guest if the measurement of the identity of the requesting guest corresponds with the identity measurement received from the select guest. If, however, the identity of the requesting guest does not correspond with the identity measurement provided by the select guest, then the hypervisor <b>316</b> does not provide the encryption key to the requesting guest.</p>
<heading id="h-0008" level="1">Exemplary Embodiments</heading>
<p id="p-0222" num="0221">The present invention will now be described in terms of several specific embodiments. These embodiments are illustrative of the present invention, but the present invention is not limited to the specific embodiments illustrated and described herein.</p>
<p id="p-0223" num="0222">Technical Approach</p>
<p id="p-0224" num="0223">The basic technical approach that will be described herein is two-pronged. First, we provide coarse-grained protections for full legacy OS and application suites (described below under the heading &#x201c;Coarse-Grained Protections&#x201d;). Second, we provide a fine-grained protected execution environment with powerful, efficient, and yet minimal trusted computing primitives for the execution of special-purpose security-sensitive codeblocks, called SSCBs (described below under the heading &#x201c;Fine-Grained Protections&#x201d;). We have been developing both the coarse-grained and fine-grained execution environments in parallel. Ultimately, these complimentary approaches will enable defense-in-depth by enforcing best practices configuration for legacy software environments while simultaneously allowing newly developed SSCBs to execute with state of the art code integrity, execution integrity, and data secrecy and integrity.</p>
<p id="p-0225" num="0224">The present invention also includes the combination of both systems so that the appropriate granularity of protections are available for all software that executes on the system. The lowest layer of software in our system is a hypervisor <b>316</b>, sometimes called TrustVisor <b>316</b>.</p>
<p id="p-0226" num="0225">Coarse-Grained Protections</p>
<p id="p-0227" num="0226"><figref idref="DRAWINGS">FIG. 15</figref> illustrates one embodiment of coarse-grained protections according to the present invention. In that embodiment, the platfoim <b>310</b> is partitioned into multiple environments <b>312</b>, <b>314</b>, but only one environment executes at a time. A verification device <b>120</b> indicates which environment is active and can be used to select between them. The shaded portions represent components that must be trusted.</p>
<p id="p-0228" num="0227">The trusted <b>312</b> and untrusted <b>314</b> environments may include operating systems, applications, and other components. The illustrated embodiment shows that the trusted environment <b>312</b> includes an operating system <b>1510</b> and three applications <b>1512</b>. Similarly, the untrusted environment includes an operating system <b>1520</b> and three applications <b>1522</b>. The trusted <b>312</b> and untrusted <b>314</b> environments according to the present invention may be different from that illustrated, such as by include more or fewer applications or by including things in addition to operating systems and applications.</p>
<p id="p-0229" num="0228">At a high level, we provide coarse-grained protections by splitting system execution into multiple guest <b>312</b>, <b>314</b>, sometimes referred to as &#x201c;environments&#x201d;, that execute non-concurrently. Different environments may be trusted for different tasks. This design is based on the belief that the user has a set of tasks (e.g., games, photo editing, browsing for entertainment) that she wants to run with maximum performance, and that she has a set of tasks that are security sensitive (e.g., banking, healthcare) which she wants to run with maximum security and which are infrequent and less performance-critical. The performance-sensitive applications run in the untrusted environment <b>314</b>, which runs at near-native speed, while security-sensitive applications run in their own trusted environment <b>312</b>, which is kept clean and protected by TrustVisor <b>316</b>. In some embodiments, the user may be allowed to have multiple security-sensitive environments <b>312</b>.</p>
<p id="p-0230" num="0229">According to one embodiment, the coarse-grained component of the TrustVisor <b>316</b> architecture is based on four core concepts: (i) hyper-partitioning: system resources are partitioned as opposed to being virtualized. Among other benefits, this results in greater performance, since it minimizes resource interpositioning, and it eliminates many side channel attacks possible with virtualization; (ii) hyper-switching: device states are saved and restored across environment switches; (iii) external verification and trusted path: the state of the system (trusted or untrusted) is communicated to the user in a secure and easy to understand fashion; and (iv) trusted environment protection: TrustVisor <b>316</b> limits code execution in the trusted environment to a finite set of trusted applications and ensures that network communication is only permitted with trusted sites.</p>
<p id="p-0231" num="0230">Hyper-Partitioning.</p>
<p id="p-0232" num="0231">Since the untrusted environment <b>314</b> may be infected with malware, TrustVisor <b>316</b> must isolate the trusted environment(s) <b>312</b> from the untrusted environment <b>314</b>. Further, TrustVisor <b>316</b> must isolate itself from both environments so that its functionality cannot be deliberately or inadvertently modified. To achieve this isolation, TrustVisor <b>316</b> partitions the CPU in time by only allowing one environment to execute at a time. Memory <b>114</b> and device partitioning are explained below.</p>
<p id="p-0233" num="0232">Using partitioning as opposed to virtualization has many benefits. First, it allows the untrusted environment <b>314</b> to run with full generality at native speed, since it has full access to the CPU and system devices. Second, whenever environments with different trust levels share resources (e.g., when using virtualization), side channels exist that might allow information in the trusted environment <b>312</b> to leak to malware in the untrusted environment <b>312</b> [B. Lampson. A note on the confinement problem. Communications of the ACM, 16(10):613-615, 1973.]. Partitioning eliminates most of these side-channels. Finally, partitioning keeps the TrustVisor <b>316</b> codebase tiny, since it does not require device drivers supporting different devices from various vendors [P. Karger and D. Safford. I/O for virtual machine monitors: Security and performance issues. IEEE Security and Privacy, 6(5):16-23, 2008.]. A small code base permits formal analysis of TrustVisor <b>316</b> to rule out potential vulnerabilities.</p>
<p id="p-0234" num="0233"><figref idref="DRAWINGS">FIG. 16</figref> illustrates one embodiment of Hyper-Partitioning of Storage devices <b>130</b> according to the present invention. In this embodiment there are two devices <b>130</b>, one for each of the trusted <b>312</b> and the untrusted <b>314</b> environments. These devices are sometimes known as &#x201c;allocated&#x201d; devices because they are allocated for the use of a particular environment. Devices which are shared between environments are sometimes known as &#x201c;base&#x201d; devices.</p>
<p id="p-0235" num="0234">In this embodiment, both the trusted <b>312</b> and the untrusted <b>314</b> environments believe they are using the same device <b>130</b>, in this case a disk drive, in the system. In reality, TrustVisor <b>316</b> intercepts the device selection requests and redirects disk operations to the appropriate disk <b>130</b>, based on the current environment. Although this embodiment will be discussed in terms of storage devices, the present invention may be used with partitioned devices <b>130</b> other than storage devices.</p>
<p id="p-0236" num="0235">TrustVisor <b>316</b> partitions the available physical memory <b>114</b>, <b>130</b> in the system into three areas: the TrustVisor <b>316</b> memory region, the untrusted environment's <b>314</b> memory region, and the trusted environment's <b>312</b> memory region. For example, the TrustVisor <b>316</b> may employ Nested Page Tables to restrict each environment to its own memory region. In other words, the NPT for the untrusted environment <b>314</b> does not map physical memory pages that belong to the trusted environment <b>312</b> and vice versa. Further, it employs hardware-based DMA-protection within each environment to prevent DMA-based access beyond each environment's memory regions.</p>
<p id="p-0237" num="0236">In this embodiment, partitioning will be described in terms of partitioning a storage media device <b>130</b>. However, the present invention may also be used to partition other memory, such as memory <b>114</b>. In some embodiments the present invention may be used to partition all forms of memory <b>114</b>, <b>130</b>, and in other embodiments the present invention may be used to partition less than all forms of memory.</p>
<p id="p-0238" num="0237">With hyper-partitioning, both the untrusted <b>314</b> and trusted <b>312</b> environments may use the same set of physical devices <b>116</b>, <b>118</b>, <b>130</b>. Thus, TrustVisor <b>316</b> must ensure that device states are saved and restored across environment switches using hyper-switching. Devices that do not store persistent data, such as video <b>118</b>, audio <b>118</b>, and input <b>116</b> devices can be swapped in this manner.</p>
<p id="p-0239" num="0238">However, storage devices <b>130</b> may contain persistent, sensitive data from the trusted environment <b>312</b>, or malicious data from the untrusted environment <b>314</b>. Thus, TrustVisor <b>316</b> ensures that each environment is provided with its own set of storage devices <b>130</b> and/or partitions. For example, TrustVisor <b>316</b> can assign a different hard drive <b>130</b> to each environment. Alternately, TrustVisor <b>316</b> can assign a different partition on the same hard drive <b>130</b> to each environment. The challenge is to create this partition without virtualizating the storage devices <b>130</b>, while providing strong isolation that cannot be bypassed by a malicious OS.</p>
<p id="p-0240" num="0239">TrustVisor <b>316</b> efficiently partitions storage devices <b>130</b> by interposing on device selection, rather than device usage. It takes advantage of the fact that modern storage devices <b>130</b> rely on a controller that implements the storage protocol (e.g., ATA, SATA) and directs storage operations to the attached devices. When the operating system writes to the storage controller's I/O registers (a standard set for a given controller type), TrustVisor <b>316</b> intercepts the write and manipulates the device controller to select the appropriate device for the currently executing environment (see <figref idref="DRAWINGS">FIG. 16</figref>). All other device operations (e.g., reads and writes) proceed unimpeded by TrustVisor <b>316</b>. A similar scheme can be adopted for two partitions on the same hard disk by manipulating sector requests.</p>
<p id="p-0241" num="0240">Leaving security-sensitive data on the trusted disk unencrypted depends on a trusted BIOS. Otherwise, malicious code may boot first and access data without TrustVisor <b>316</b> to interpose on device selection. Thus, according to one embodiment of the present invention, TPM-based disk encryption is used so that data on the sensitive disk will only be accessible if TrustVisor <b>316</b> has been loaded.</p>
<p id="p-0242" num="0241">Hyper-Switching.</p>
<p id="p-0243" num="0242">Since TrustVisor <b>316</b> does not employ device virtualization, switching between the untrusted <b>314</b> and the trusted <b>312</b> environment (and vice versa) is a challenge. In modern OSes, device drivers store device configuration information in memory and expect the internal state of the devices to match that configuration. Hence, simply saving the memory contents of one environment and replacing it with the other will not suffice.</p>
<p id="p-0244" num="0243">In one embodiment, TrustVisor <b>316</b> uses the ACPI Sleep States (employed by all modern OSes) to switch between the trusted <b>312</b> and untrusted <b>314</b> environments. When a sleep command is initiated (e.g., when the user closes the lid on a laptop), the OSPM first informs all currently executing user and kernel-mode applications and drivers about the sleep signal. They, in turn, store the configuration information needed restore the system when it awakes. The device drivers use the OSPM to set desired device power levels. The OSPM then signals the ACPI Subsystem, which ultimately performs chipset-specific operations to transition the system into the desired sleep state. The OSPM polls the ACPI Subsystem for a wake signal to determine when it should reverse the process and wake the system.</p>
<p id="p-0245" num="0244">With hyper-switching, TrustVisor <b>316</b> performs an environment switch by transitioning the current environment to sleep and waking up another. Assuming the user starts in the untrusted environment <b>314</b>, we briefly describe the steps involved in a hyper-switch. When the user rotates the selector <b>126</b> on the USB verifier <b>120</b> to initiate a switch to a particular trusted environment <b>312</b>, the USB verifier <b>120</b> communicates with TrustVisor <b>316</b> which in turn instructs the OSPM in the untrusted environment <b>314</b> to put the system to sleep. When the OSPM in the untrusted environment <b>314</b> issues the sleep command to the ACPI Subsystem, TrustVisor <b>316</b> intercepts the command, resets all devices, updates the output on the USB verifier <b>120</b>, and issues a wake command to the OSPM in the trusted environment <b>312</b>.</p>
<p id="p-0246" num="0245">External Verification and Trusted Path.</p>
<p id="p-0247" num="0246">While TrustVisor <b>316</b> always knows which environment is currently operating, it must create a trusted path to the user to convey this information in a way she can easily understand and trust. Otherwise, the user might be tricked into performing security-sensitive operations in the untrusted environment <b>314</b>. One approach to conveying whether the system is in the trusted <b>312</b> or the untrusted <b>314</b> environment would be via the display. However, this approach would require TrustVisor <b>316</b> to include a display driver, and malware in the untrusted environment <b>314</b> might try to trick the user by manipulating the parts of the display that it had legitimate access to. TrustVisor <b>316</b> eliminates such attacks by using a simple, external device <b>120</b> to control the environment switching and to display the result of the switch to the user. Further, TrustVisor <b>316</b> ensures that the external device <b>120</b> can verify that it is interacting with a correct version of TrustVisor <b>316</b>, preventing malware from misleading the device <b>120</b>.</p>
<p id="p-0248" num="0247">The USB Verifier.</p>
<p id="p-0249" num="0248">The user employs a device <b>120</b>, sometimes called the verification device <b>120</b> and sometimes called the USB verifier <b>120</b>, to switch between trusted and untrusted environments. This device <b>120</b> may be external to the computer <b>110</b>, such as a removable device that connects via a USB port or some other connection, or the device <b>120</b> may be integral with the computer <b>110</b>. References to a &#x201c;USB verifier&#x201d; generally refer to an embodiment using a removable device <b>120</b> that connects via a USB port, although the present invention may also be used with connections other than USB ports and the invention may be used with non-removable devices <b>120</b>.</p>
<p id="p-0250" num="0249">The following describes characteristics of one embodiment of the present invention to enable the user to trust the USB verifier <b>120</b>:</p>
<p id="p-0251" num="0250">1. Correct Operation.</p>
<p id="p-0252" num="0251">Software executing on the USB verifier <b>120</b> must be robust against compromise. By minimizing the code for the USB verifier <b>120</b>, we make it amenable to formal analysis.</p>
<p id="p-0253" num="0252">2. Minimal Input Capabilities.</p>
<p id="p-0254" num="0253">To minimize complexity (and hence user confusion), we wish to minimize the number of input options.</p>
<p id="p-0255" num="0254">3. Minimal Output Capabilities.</p>
<p id="p-0256" num="0255">To reduce confusion, the user should be able to easily learn which environment she is working in.</p>
<p id="p-0257" num="0256"><figref idref="DRAWINGS">FIG. 17</figref> illustrates one example of a USB verifier <b>120</b> according to the present invention. In this embodiment, the USB verifier <b>120</b> may be used for more than two mutually distrusting environments. This device <b>120</b> connects to the user's main computer or PC via a USB interface. The USB verifier <b>130</b> is equipped with a red and green LED <b>128</b>, a selector <b>126</b> to choose which environment should be executing, and a buzzer <b>128</b> to alert the user when the LEDs have changed.</p>
<p id="p-0258" num="0257">To achieve these properties, the USB verifier <b>120</b> consists of a single selector <b>126</b>, two LEDs <b>128</b>, and a buzzer <b>128</b>. The selector <b>126</b> can be turned to indicate the environment that the user currently desires. When the green LED <b>128</b> is lit, the verifier <b>120</b> has confirmed that the trusted environment <b>312</b> chosen by the user via the selector <b>126</b> and the environment that is actually executing are the same. The red LED <b>128</b> indicates that the untrusted environment is active. Because it takes a non-negligible amount of time to switch environments (i.e., after she adjusts the selector <b>126</b>), the USB Verifier <b>120</b> uses a blinking red LED <b>128</b> to indicate processing. Thus, the user need only remember to check that the green LED <b>128</b> is lit before performing security-sensitive tasks. The USB Verifier <b>120</b> uses the buzzer <b>128</b> to attract the user's attention whenever the LEDs <b>128</b> change states. It can also create an alarm buzz if the USB Verifier <b>120</b> is unable to verify the correctness of TrustVisor <b>316</b> or if the system encounters a fatal error. As with other specific examples of the present invention, specific types of output <b>128</b> (e.g., red LED, green LED, buzzer) are exemplary and the present invention may use different numbers, and types of outputs <b>128</b>. Similarly, the specific functions described with regard to the output <b>128</b> may be modified.</p>
<p id="p-0259" num="0258">Secure Channel.</p>
<p id="p-0260" num="0259">To accurately verify the state of the system (trusted or untrusted), the USB verifier <b>120</b> must be able to communicate securely with TrustVisor <b>316</b>. More precisely, it should not be possible for an adversary to impersonate or undetectably modify TrustVisor <b>316</b>. TrustVisor <b>316</b> achieves this goal using a combination of CPU protections and hardware attestation (via a TPM).</p>
<p id="p-0261" num="0260">To create a secure channel for communicating with the USB verifier <b>120</b>, TrustVisor <b>316</b> uses CPU protections to reserve a USB controller and to prevent both environments from accessing it. Using USB as an interface is intuitive for users, and it eliminates the need for an external power source for the USB verifier <b>120</b>.</p>
<p id="p-0262" num="0261">To convince the USB verifier <b>120</b> that it is communicating with TrustVisor <b>316</b>, we use TPM-based attestation [Trusted Computing Group. Trusted platform module main specification, Part 1: Design principles, Part 2: TPM structures, Part 3: Commands. Version 1.2, Revision 103, July 2007.]. Initially, TrustVisor <b>316</b> is started using a dynamic root of trust [Advanced Micro Devices. AMD64 architecture programmer's manual: Volume 2: System programming. AMD Publication no. 24593 rev. 3.14, September 2007.], [Intel Corporation. Intel trusted execution technology&#x2014;software development guide. Document number 315168-005, June 2008.], which records a measurement of TrustVisor <b>316</b> in the TPM. When the USB verifier <b>120</b> is connected to the system, it sends a challenge (a cryptographic nonce) to TrustVisor <b>316</b>. TrustVisor <b>316</b> uses the TPM to generate a quote (essentially a signed statement describing the software state of the system) that it transmits to the USB verifier <b>120</b>, which checks the attestation. If verification fails, the USB verifier <b>120</b> halts, sets the LED <b>128</b> state to blinking red and emits an alarm buzz. If it succeeds, the USB verifier <b>120</b> emits an attention buzz and sets the LED <b>128</b> state to solid red if the untrusted environment <b>314</b> is running or to solid green if a trusted environment <b>312</b> is running.</p>
<p id="p-0263" num="0262">Since it is connected via USB, the USB verifier <b>120</b> can also detect when the system is rebooted, since on a reboot, a USB controller sends all attached USB devices a reset signal. When this happens, the USB verifier <b>120</b> emits the attention buzz and sets the LED state to blinking red, since it can no longer vouch for the state of the system. It then performs the procedure described above to verify that TrustVisor <b>316</b> is back in control and to learn which environment is currently active.</p>
<p id="p-0264" num="0263">Trusted environment <b>312</b> Protection.</p>
<p id="p-0265" num="0264">TrustVisor's <b>316</b> trusted environments <b>312</b> run a commodity OS and applications. TrustVisor <b>316</b> verifies the integrity of all the files of a particular trusted environment <b>312</b> during TrustVisor's <b>316</b> installation. Further, TrustVisor <b>316</b> trusts the software in the trusted environment <b>312</b> to not leak data deliberately. However, vulnerabilities within the OS or an application in a trusted environment <b>312</b> can be exploited either locally or remotely to execute malicious code. Further, since the trusted environments <b>312</b> and untrusted environment <b>314</b> use the same devices, the untrusted environment <b>314</b> could change a device's firmware to act maliciously. TrustVisor <b>316</b> uses hardware DMA protections, approved code execution, and network protection to ensure that only trusted code (including device firmware code) can be executed and only trusted sites can be visited while in the trusted environment <b>312</b>.</p>
<p id="p-0266" num="0265">Approved Code Execution.</p>
<p id="p-0267" num="0266">For non-firmware code, TrustVisor <b>316</b> uses page protections within the physical memory page tables to enforce a W xor X policy on physical memory pages used within the trusted environment <b>312</b>. Thus, a page within the trusted environment <b>312</b> may be executed or written, but not both. Prior to converting a page to executable status, TrustVisor <b>316</b> checks the memory region against a list of trusted software. Execution is permitted only if this check succeeds.</p>
<p id="p-0268" num="0267">It is known to enforce a similar policy only on the kernel [A. Seshadri, M. Luk, N. Qu, and A. Perrig. SecVisor: A tiny hypervisor to provide lifetime kernel code integrity for commodity OSes. In Proceedings of the ACM Symposium on Operating Systems Principles (SOSP), October 2007.]. Other researchers use it to determine what applications are running [L. Litty, H. A. Lagar-Cavilla, and D. Lie. Hypervisor support for identifying covertly executing binaries. In USENIX Security Symposium, 2008.]. In contrast, TrustVisor <b>316</b> uses these page protections to ensure that potentially untrusted code is always measured before it is invoked. In other words, the present invention may be used to isolate bad code rather than preventing bad code from running.</p>
<p id="p-0269" num="0268">For device firmware code, TrustVisor <b>316</b>, during installation, scans all of the hardware installed on the system and enumerates all system and device firmware code regions. It assumes this code has not yet been tampered with and uses physical memory page tables to prevent either environment from writing to these regions.</p>
<p id="p-0270" num="0269">Network Protection.</p>
<p id="p-0271" num="0270"><figref idref="DRAWINGS">FIG. 18</figref> illustrates one embodiment of the present invention for use with connecting to sites on the network. According to one embodiment, the trusted environment <b>312</b> Network Protection. TrustVisor's <b>316</b> protocol analyzer only permits SSL sessions to trusted sites.</p>
<p id="p-0272" num="0271">Since users perform many security-sensitive activities online, applications executing in a trusted environment <b>312</b> need to communicate with remote sites via the network. However, permitting network communication exposes the trusted environment <b>312</b> to external attacks. Remote attackers may exploit flaws in the OS's network stack, or the user may inadvertently access a malicious site. While the approved code execution described above prevents many code-based attacks, the trusted environment <b>312</b> may still be vulnerable to data-based attacks [H. Shacham. The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86). In ACM CCS, 2007.].</p>
<p id="p-0273" num="0272">To forestall such attacks, TrustVisor <b>316</b> restricts the trusted environment <b>312</b> to communicate only with a limited set of trusted sites. It imposes these restrictions by interposing on all network traffic to or from the trusted environment <b>312</b> (see <figref idref="DRAWINGS">FIG. 18</figref>). TrustVisor <b>316</b> uses hardware CPU and physical memory protections to prevent the trusted environment <b>312</b> from seeing or accessing any physical network devices present in the system. Network communication is permitted via a virtual network interface that TrustVisor <b>316</b> installs in the guest OS. This interface forwards packets to TrustVisor <b>316</b>, which analyzes the packets and then forwards them onto the physical network interface.</p>
<p id="p-0274" num="0273">TrustVisor <b>316</b> uses packet analysis to determine which network packets are permitted. In one embodiment, TrustVisor <b>316</b> only allows SSL and DNS network packets to pass through. All other packets are dropped. The rationale for this approach is that any site with sensitive data should be using SSL to protect it in transit, although the present invention is not limited to this embodiment. When an SSL session is initiated, TrustVisor <b>316</b> determines if the request is a valid SSL connection request. If it is, TrustVisor <b>316</b> validates the site's SSL certificate and checks it against the list of trusted sites. If any of these checks fail, the packet is dropped. Incoming packets are permitted only if they belong to an existing SSL session or are in response to an earlier DNS request. Note that DNS attacks are forestalled by SSL certificate verification.</p>
<p id="p-0275" num="0274">Fine-Grained Protections</p>
<p id="p-0276" num="0275">A primary component of our technical approach is to enable the execution of self-contained (e.g., statically linked) security-sensitive codeblocks (SSCBs) in total isolation from a legacy OS and DMA-capable devices. One embodiment of the present invention provides facilities for remote attestation and the long-term protection of sensitive state. This constitutes fine-grained protection tailored for small, special-purpose code modules.</p>
<p id="p-0277" num="0276"><figref idref="DRAWINGS">FIG. 19</figref> illustrates one embodiment of the present invention for use in a fine-grained protection architecture with TrustVisor <b>316</b>. The shaded components are trusted. A TrustVisor-aware application can register a SSCB with TrustVisor <b>316</b>, so that it will be executed in isolation from the untrusted legacy OS and applications. The untrusted legacy OS remains responsible for controlling the platform's devices. The only interface exposed to a SSCB by TrustVisor <b>316</b> is that of a &#x3bc;TPM. The system's physical TPM is shared by TrustVisor <b>316</b> and the untrusted OS using the TPM's locality mechanism.</p>
<p id="p-0278" num="0277">One example of an application where such capabilities are desirable is an SSL-enabled webserver, where the private SSL/TLS signing key is rendered inaccessible to all but a dedicated code module. This way, even if the remainder of the web server or the OS on which it runs becomes compromised, the secrecy of the private key is preserved. However, such an environment imposes considerable performance requirements on the isolation mechanism, as it must be able to sustain real-world levels of SSL/TLS session establishment.</p>
<p id="p-0279" num="0278">A powerful mechanism supporting isolated execution of SSCBs is the creation of a dynamic root of trust enabled by modern TPM-equipped platforms [Advanced Micro Devices. AMD64 architecture programmer's manual: Volume 2: System programming. AMD Publication no. 24593 rev. 3.14, September 2007.], [Intel Corporation. Intel trusted execution technology&#x2014;software development guide. Document number 315168-005, June 2008.]. Unfortunately, today's dynamic root of trust mechanisms impose considerable performance overhead [J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and H. Isozaki. Flicker: An execution infrastructure for TCB minimization. In Proceedings of the ACM European Conference in Computer Systems (EuroSys), April 2008.], and are not suitable for frequent use on a busy server. We enhance this mechanism to provide excellent performance and to further enable remote attestation of SSCBs loaded for execution.</p>
<p id="p-0280" num="0279">We wish to provide the security advantages of a system employing a dynamic root of trust mechanism, but without paying a severe performance penalty if the mechanism is heavily used. We further wish to maintain compatibility with available legacy operating system and application software, but exclude this software from the TCB. One solution is to leverage available hardware virtualization support to provide memory isolation and DMA protection for SSCBs. In one embodiment, we implement a small TrustVisor <b>316</b> (<figref idref="DRAWINGS">FIG. 19</figref>) to virtualize a machine's physical memory, enforce memory isolation between different SSCBs and untrusted code, protect against malicious DMA reads and writes, and enable remote attestation and long-term protected storage. We use dynamic root of trust only once per boot cycle to invoke TrustVisor <b>316</b>.</p>
<p id="p-0281" num="0280">To distinguish between legacy code and SSCBs, we devise a registration mechanism by which untrusted applications can register certain code and data as security-sensitive. <figref idref="DRAWINGS">FIG. 20</figref> illustrates a timeline of an application registering a SSCB, and executing it one or more times.</p>
<p id="p-0282" num="0281">To provide long-term protection of secrets required by SSCBs, and to enable remote attestation that a particular SSCB has executed, one embodiment of TrustVisor <b>316</b> is designed to also export a minimal TPM-like interface to SSCBs. We call this interface a micro-TPM (&#x3bc;TPM), and TrustVisor <b>316</b> supports a &#x3bc;TPM instance for each registered SSCB.</p>
<p id="p-0283" num="0282">The present invention in general, and TrustVisor <b>316</b> in particular, may have more than one basic operating mode. <figref idref="DRAWINGS">FIG. 21</figref> illustrates one embodiment of a comparison of the three execution modes of code with TrustVisor <b>316</b>: host mode, legacy guest mode, and secure guest mode. In host mode, TrustVisor <b>316</b> itself is executing. In legacy guest mode, either the untrusted OS or the untrusted portion of an application is executing. In secure guest mode, a registered SSCB is executing with TrustVisor's <b>316</b> protections. This embodiment will now be described in more detail</p>
<p id="p-0284" num="0283">Host mode refers to execution of TrustVisor <b>316</b> code at the system's highest privilege level. TrustVisor <b>316</b> in turn supports two guest modes. In legacy guest mode, a commodity x86 operating system and its applications can execute without requiring any awareness of the presence of TrustVisor <b>316</b>. The legacy OS manages all peripheral devices on the system (network, disk, display, USB, etc.), with the TPM as the only shared device. TrustVisor <b>316</b> accesses the TPM via its Locality 2 interface [Trusted Computing Group. Trusted platform module main specification, Part 1: Design principles, Part 2: TPM structures, Part 3: Commands. Version 1.2, Revision 103, July 2007.], and prevents the legacy OS from accessing this interface, opting instead to give the legacy OS access to the TPM's Locality 1 interface (TPM chips are memory mapped to multiple physical addresses, each corresponding to a different privilege level called a locality, where 4 is most privileged and 1 is least privileged [Trusted Computing Group. Trusted platform module main specification, Part 1: Design principles, Part 2: TPM structures, Part 3: Commands. Version 1.2, Revision 103, July 2007.]; TrustVisor can prevent the guest from accessing the Locality 2-4 interfaces by unmapping the relevant memory regions). In secure guest mode, a SSCB executes in total isolation from the legacy OS and its applications. When a SSCB is registered, TrustVisor <b>316</b> extends a measurement (cryptographic hash) of the SSCB into the first &#x3bc;PCR in the SSCB's corresponding &#x3bc;TPM instance. All input and output parameters are marshaled by TrustVisor <b>316</b> into protected memory before the SSCB begins executing. As we merge our coarse-grained and fine-grained protections into a single instance of TrustVisor <b>316</b>, the guests receiving coarse-grained protections will execute in legacy guest mode.</p>
<p id="p-0285" num="0284">Hardware Memory Protections.</p>
<p id="p-0286" num="0285">A main function of TrustVisor <b>316</b> is to isolate SSCBs from untrusted code by supporting both legacy guest mode and secure guest mode (<figref idref="DRAWINGS">FIG. 21</figref>). However, in either mode, any code in the guest must not be allowed to compromise the code integrity of TrustVisor <b>316</b>. Note that the legacy OS may also reprogram DMA-capable devices in a compromise attempt. To defend against these attacks, TrustVisor <b>316</b> runs as a hypervisor at the system's highest privilege level. TrustVisor <b>316</b> virtualizes the guest's physical memory to provide isolation between TrustVisor <b>316</b> and the legacy system, and between the legacy system and SSCBs. TrustVisor <b>316</b> programs the device exclusion vector [Advanced Micro Devices. AMD64 architecture programmer's manual: Volume 2: System programming. AMD Publication no. 24593 rev. 3.14, September 2007.] (DEV) to protect itself and registered SSCBs against DMA accesses.</p>
<p id="p-0287" num="0286">TrustVisor <b>316</b> uses page tables to control MMU-based memory protections. We choose page tables, rather than other MMU-based protections (e.g., segmentation), because page tables are supported by many current CPU architectures. To virtualize physical memory, TrustVisor <b>316</b> maintains page tables that translate guest physical addresses into host physical (aka &#x201c;machine&#x201d;) addresses. These page tables are located in TrustVisor's <b>316</b> own memory region, thereby preventing any code in the guest from tampering with the page translation. Indeed, the code in the guest need not even be aware of this virtualization. To reduce complexity and keep the TCB small, TrustVisor <b>316</b> leverages hardware virtualization with support for nested page tables (NPT) provided by recent AMD x86 CPUs and enforced by the system's MMU (memory-management unit). Intel offers similar support called Extend Page Tables, which TrustVisor <b>316</b> can be readily extended to leverage [Intel Corporation. Intel virtualization technology specification for the IA-32 Intel architecture. Intel Publication no. C97063-002, April 2005.]. This design enforces data secrecy and integrity even if a compromised legacy OS modifies its page tables (guest virtual address to guest physical address), since the guest physical address space is restricted to specifically exclude all of TrustVisor's <b>316</b> sensitive memory regions.</p>
<p id="p-0288" num="0287">Code and Execution Integrity for SSCBs.</p>
<p id="p-0289" num="0288">It is the responsibility of application developers to privilege separate their programs into sensitive and untrusted portions, although automatic privilege separation may be possible in some instances to ease the burden on the developer [D. Brumley and D. Song. Privtrans: Automatically partitioning programs for privilege separation. In Proceedings of USENIX Security Symposium, 2004.]. The untrusted code can register sensitive code with TrustVisor <b>316</b>, so that all memory regions (both code and data) corresponding to a particular SSCB will be isolated and measured by TrustVisor <b>316</b>. The measurement of the SSCB is extended into the &#x3bc;TPM instance associated with this registered SSCB.</p>
<p id="p-0290" num="0289">SSCB Registration.</p>
<p id="p-0291" num="0290">TrustVisor <b>316</b> may implement an application-level hyper call interface for registering SSCBs. The registration interface accepts a specification for all the functions provided by a SSCB, thereby allowing application programmers to specify sets of functions as security-sensitive. The specification includes a list of function entry points, and input and output parameter formats. This information allows TrustVisor <b>316</b> to verify that the specified addresses are legal (i.e., they belong to the calling application's address space), and marshal and unmarshal the parameters between legacy mode and secure mode when the functions inside the SSCB are invoked.</p>
<p id="p-0292" num="0291">During registration, the memory pages that correspond to the SSCB&#x2014;including pages for the stack, heap, and other execution requirements for the SSCB&#x2014;are protected by TrustVisor <b>316</b> and become inaccessible to the untrusted OS, application, and even DMA requests from devices. It is at this point&#x2014;&#x201c;Register SSCB&#x201d; in FIG. <b>20</b>&#x2014;that code integrity protections for the SSCB become active. TrustVisor <b>316</b> ensures that no other code on the system can tamper with this SSCB's memory pages. Further, the TCB includes only TrustVisor <b>316</b> and the SSCB itself.</p>
<p id="p-0293" num="0292">Once the pages are inaccessible to untrusted code, TrustVisor <b>316</b> computes a measurement (cryptographic hash) over the contents of these pages and extends it into the first &#x3bc;PCR of the &#x3bc;TPM instance associated with this registered SSCB.</p>
<p id="p-0294" num="0293">SSCB Invocation.</p>
<p id="p-0295" num="0294">Following registration, the untrusted legacy application and underlying OS cannot read, write, or directly execute the memory containing the SSCB that it registered. However, the functions inside the SSCB can still be invoked using what appears to be an ordinary function call. Any function call to code inside the SSCB will trap to TrustVisor <b>316</b>. TrustVisor <b>316</b> then performs the following three steps before transferring control to the called function inside the SSCB:</p>
<p id="p-0296" num="0295">1. Identify which registered SSCB contains the current called sensitive function.</p>
<p id="p-0297" num="0296">2. Switch the guest from legacy mode to secure mode, with secure mode configured so that only the pages containing this SSCB are accessible.</p>
<p id="p-0298" num="0297">3. Prepare the secure-mode execution environment (including marshaling input parameters from the untrusted application and setting up the SSCB's stack pointer) for the sensitive function call.</p>
<p id="p-0299" num="0298">SSCB Termination.</p>
<p id="p-0300" num="0299">When a SSCB has completed executing and returns back to the calling legacy application, TrustVisor <b>316</b> once again gets control. This happens because any attempt to execute code in secure mode outside the SSCB causes a trap into TrustVisor <b>316</b>. TrustVisor <b>316</b> performs the following two steps before transferring control back to the legacy application:</p>
<p id="p-0301" num="0300">1. Marshall any returned parameters and make them available to the calling untrusted application.</p>
<p id="p-0302" num="0301">2. Switch the guest from secure guest mode to legacy guest mode, in which the pages containing the SSCB are once again inaccessible from legacy guest mode.</p>
<p id="p-0303" num="0302">The SSCB's execution state is left intact, so that the corresponding untrusted application can invoke it a second time with different input parameters, or in response to an attestation request.</p>
<p id="p-0304" num="0303">SSCB Unregistration.</p>
<p id="p-0305" num="0304">Unregistration can only be initiated by the application that originally registered a particular SSCB. During unregistration, TrustVisor <b>316</b> zeros all execution state associated with that SSCB. This includes its stack, heap, and TrustVisor-internal state such as the relevant page table entries and &#x3bc;TPM state. The relevant pages are once again marked accessible to guest mode (the untrusted application and OS).</p>
<p id="p-0306" num="0305">Data Secrecy and Integrity Mechanisms.</p>
<p id="p-0307" num="0306">Here we describe how TrustVisor <b>316</b> may protect the secrecy and integrity of data, where data can be internal TrustVisor <b>316</b> state as well as the state of SSCBs. We distinguish two intervals during which data protection is required: residence in volatile storage (RAM) while a particular SSCB is executing, and residence on non-volatile storage while untrusted code is executing.</p>
<p id="p-0308" num="0307">Data in Volatile Storage.</p>
<p id="p-0309" num="0308">Here, volatile storage refers to data in memory that is protected by TrustVisor <b>316</b> and the system's MMU and DEV. The same mechanisms that provide code integrity for TrustVisor <b>316</b> and executing SSCBs apply here to protect the secrecy and integrity of data.</p>
<p id="p-0310" num="0309">TrustVisor <b>316</b>-internal state is protected by keeping it in the region of memory that is accessible only to code in host mode (<figref idref="DRAWINGS">FIG. 21</figref>). TrustVisor <b>316</b> configures the NPTs such that guest physical memory simply excludes the physical pages that contain TrustVisor <b>316</b> state. There is no way for code in the guest to address the pages containing the sensitive state. Likewise, TrustVisor <b>316</b> programs the system's device exclusion vector (DEV) to prevent access to these pages by DMA-capable devices.</p>
<p id="p-0311" num="0310">While a SSCB is registered, TrustVisor <b>316</b> ensures that the machine physical pages that contain SSCB state are unmapped from the legacy OS's guest physical memory space. Data and code pages are treated differently. Any attempt by the legacy OS to read, write, or execute the data pages will trap to TrustVisor <b>316</b>, which will prevent the access. Executing the code pages that belong to any SSCB is legal, and is handled as described earlier in this section. Likewise, a SSCB that wishes to output any of its state to the untrusted world can do so simply by returning it as an output parameter.</p>
<p id="p-0312" num="0311">Data in Non-Volatile Storage.</p>
<p id="p-0313" num="0312">Part of the TrustVisor <b>316</b> model is that the legacy OS manages all devices on the system. Thus, any data that is to be put into non-volatile storage will be under the control of the untrusted legacy OS. This requirement will arise during the lifetime of a system with TrustVisor <b>316</b> whenever that system reboots, and whenever a SSCB needs to save state for extended periods of time, across many runs.</p>
<p id="p-0314" num="0313">To protect the secrecy and integrity of data under these conditions, cryptography is required. In brief, sensitive data that must be protected on non-volatile storage must be encrypted and integrity protected.</p>
<p id="p-0315" num="0314">Numerous algorithms exist for authenticated encryption&#x2014;the real challenge is to protect the relevant cryptographic keys.</p>
<p id="p-0316" num="0315">We employ two levels of protection for cryptographic keys with TrustVisor <b>316</b>. TrustVisor <b>316</b> protects its own secrets using cryptographic keys protected by the system's Trusted Platform Module, and exposes a similar interface to SSCBs that they can use to protect the encryption keys for their secrecy- or integrity-protected data.</p>
<p id="p-0317" num="0316">&#x3bc;TPM Functions.</p>
<p id="p-0318" num="0317">We observe that many applications are still valuable with a greatly reduced set of TPM functions. The software &#x3bc;TPM interface exposed by TrustVisor <b>316</b> exports the following TPM-like functions:</p>
<p id="p-0319" num="0318">1. TV_Extend for measuring data,</p>
<p id="p-0320" num="0319">2. TV_GetRand for getting random bytes,</p>
<p id="p-0321" num="0320">3. TV_Seal and TV_Unseal for sealing and unsealing data based on measurements, and</p>
<p id="p-0322" num="0321">4. TV_Quote to attest recorded measurements using digital signatures.</p>
<p id="p-0323" num="0322">The secrecy and integrity of sealed data is protected by symmetric cryptographic primitives performed in TrustVisor <b>316</b>. These mechanisms are a significant source of TrustVisor's <b>316</b> efficiency for trusted computing operations. Previous systems rely on the TPM's low-cost CPU to perform asymmetric sealing and quote operations (e.g., Flicker [J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and H. Isozaki. Flicker: An execution infrastructure for TCB minimization. In Proceedings of the ACM European Conference in Computer Systems (EuroSys), April 2008), whereas TrustVisor <b>316</b> executes the TV-family of trusted computing operations on the platform's primary CPU, and uses efficient symmetric primitives for TV Seal and TV Unseal.</p>
<p id="p-0324" num="0323">Roots of Trust for Integrity Measurement.</p>
<p id="p-0325" num="0324">Integrity measurement is the act of keeping track of the cryptographic hash of all software that has been loaded for execution in the TCB. For a particular application's SSCB, this amounts to TrustVisor <b>316</b> and the SSCB itself. Measurements of TrustVisor <b>316</b> are kept in the system's physical TPM. Measurements of a SSCB are kept in the &#x3bc;TPM instance corresponding to that SSCB.</p>
<p id="p-0326" num="0325">Integrity measurement is an essential requirement for data protection and remote attestation. Without integrity measurement and a TPM, there is no facility to protect the cryptographic keys that provide data secrecy and integrity when the data is kept on non-volatile storage under the control of untrusted code. Without integrity measurement, there is no trustworthy source of information about what code has been loaded for execution to use in remote attestations.</p>
<p id="p-0327" num="0326">Further, our mechanism for maintaining (and attesting and sealing with respect to) integrity measurements is a significant contribution to minimizing the TCB. Existing systems to virtualize the TPM suffer from an excessive TCB, as we describe in the section entitled &#x201c;Related Research&#x201d;. We observe that many applications are still valuable with the reduced set of TPM functions described above.</p>
<p id="p-0328" num="0327">Ultimately, trust in a system running TrustVisor <b>316</b> stems from TPM-based attestation to the use of dynamic root of trust (DRTM) to invoke TrustVisor <b>316</b> via the SKINIT instruction. TrustVisor <b>316</b> accesses the TPM chip via its Locality 2 [Trusted Computing Group. Trusted platform module main specification, Part 1: Design principles, Part 2: TPM structures, Part 3: Commands. Version 1.2, Revision 103, July 2007.] interface and exposes Locality 1 access to the physical TPM chip to the untrusted guest OS (<figref idref="DRAWINGS">FIG. 19</figref>) to maintain compatibility with existing suites of TPM applications (e.g., TrouSerS (http://trousers.sourceforge.net/)).</p>
<p id="p-0329" num="0328">Each &#x3bc;TPM instance includes the necessary &#x201c;micro&#x201d; Platform Configuration Registers (&#x3bc;PCRs) to keep track of a single SSCB's measurements. TrustVisor <b>316</b> performs the initial measurement of the SSCB and extends it into the first &#x3bc;PCR in the &#x3bc;TPM instance associated with the registered SSCB. This mechanism is designed to replicate the functionality of the dynamic root of trust provided by the system's physical TPM.</p>
<p id="p-0330" num="0329">Attestation and Trust Establishment.</p>
<p id="p-0331" num="0330">Here we describe how attestation enables a remote entity to establish trust in TrustVisor <b>316</b>, and subsequently in SSCBs executing on top of TrustVisor <b>316</b>. Building on the two-level integrity measurement mechanism described, we also design a two-part attestation mechanism. First, we use TPM-based attestation to demonstrate that a dynamic root of trust was employed to launch TrustVisor <b>316</b> with hardware-enforced isolation. Second, we use the &#x3bc;TPM functionality built into TrustVisor <b>316</b> to demonstrate that a particular SSCB was registered and executed with TrustVisor <b>316</b>-enforced isolation.</p>
<p id="p-0332" num="0331">TPM-Generated Attestation.</p>
<p id="p-0333" num="0332">An external verifier that receives a TPM-generated attestation covering the PCRs into which TrustVisor <b>316</b>-relevant binaries and data have been extended conveys the following information to the verifier:</p>
<p id="p-0334" num="0333">A dynamic root of trust (e.g., AMD's SKINIT instruction) was used to bootstrap the execution of TrustVisor <b>316</b>.</p>
<p id="p-0335" num="0334">TrustVisor <b>316</b> received control immediately following the establishment of the dynamic root of trust.</p>
<p id="p-0336" num="0335">The precise version of TrustVisor <b>316</b> that is executing is identifiable by its measurement (cryptographic hash) in one of the PCRs.</p>
<p id="p-0337" num="0336">TrustVisor <b>316</b> generated an identity key for its &#x3bc;TPM based on the current TPM AIK.</p>
<p id="p-0338" num="0337">Note that the verifier must learn the identity of the TPM's AIK by some authentic mechanism, such as a PKI, pre-configuration by an administrator, OEM, or system owner.</p>
<p id="p-0339" num="0338">&#x3bc;TPM-/TrustVisor <b>316</b>-Generated Attestation.</p>
<p id="p-0340" num="0339">An attestation from TrustVisor <b>316</b> consists of the output of a TV Quote operation, along with additional untrusted data to facilitate the verifier's making sense out of the values in the pPCRs. The verifier must first decide to trust TrustVisor <b>316</b> based on a TPM attestation. If TrustVisor <b>316</b> is untrusted, then no trusted environment <b>312</b> can be constructed on top of TrustVisor <b>316</b>. A verifier learns the following information as it analyzes the contents of the &#x3bc;PCRs:</p>
<p id="p-0341" num="0340">&#x3bc;PCR [0] always begins with 20 bytes of zeros extended with the measurement of the registered SSCB. Thus, the verifier can learn precisely which SSCB was registered and invoked during this session on TrustVisor <b>316</b>.</p>
<p id="p-0342" num="0341">The values in the remaining &#x3bc;PCRs and any other values extended into &#x3bc;PCR [0] are specific to the SSCB that executed, and will not have been influenced by TrustVisor <b>316</b>.</p>
<p id="p-0343" num="0342">The set of &#x3bc;PCRs selected for inclusion in TV Quote (and a nonce provided by the remote verifier to ensure freshness) will be signed by TrustVisor's <b>316</b> &#x3bc;TPM identity key &#x3bc;AIK, generated by TrustVisor <b>316</b>.</p>
<p id="p-0344" num="0343">Note that the verifier can confirm precisely which SSCB executed, and that a SSCB constructed to measure its inputs and outputs enables the verifier to learn that the Execution Integrity of this SSCB is intact.</p>
<p id="p-0345" num="0344">The Attestation Protocol.</p>
<p id="p-0346" num="0345"><figref idref="DRAWINGS">FIG. 22</figref> illustrates one embodiment of the attestation protocol by which a remote party (which may be a local verification device <b>120</b>) verifies that a particular attestation represents a legitimate run of a SSCB. This may be used, for example, to convince an external verifier that a particular SSCB ran on a particular system with TrustVisor's <b>316</b> protections.</p>
<p id="p-0347" num="0346">Putting it all Together: Coarse- and Fine-Grained Protections</p>
<p id="p-0348" num="0347"><figref idref="DRAWINGS">FIG. 23</figref> illustrates one embodiment of a system architecture demonstrating three different guest types running on TrustVisor <b>316</b>. Shaded regions indicate the trusted computing base for fine-grained protections. The leftmost guest's operating system is completely untrusted, and may be executing malware denoted E. However, TrustVisor <b>316</b>-aware applications, such as App A, may still invoke SSCBs and generate subsequent attestations to their execution integrity. The center guest runs and trusts a commodity operating system but that OS has been carefully configured for a minimal set of operations&#x2014;in this case the bare essentials to support a banking application B. Since B's OS is too large to formally verify and may still be subject to compromise, B can employ SSCBs and execute them with TrustVisor's <b>316</b> protections. The rightmost guest is similar to the center guest but has been tailored to a healthcare application that does not leverage any TrustVisor <b>316</b>-protected SSCBs.</p>
<p id="p-0349" num="0348"><figref idref="DRAWINGS">FIG. 23</figref> shows the architecture of a system supporting both coarse- and fine-grained protections. Coarse-grained protections can be employed to keep various instances of legacy operating systems and applications apart. Page-level integrity checks and W&#x2295;X permissions can prevent unknown code or code with known vulnerabilities from executing. Inside any of these environments, new applications or legacy applications with their security-critical code privilege-separated can leverage SSCBs to get the maximum level of protection for data secrecy and integrity. Our &#x3bc;TPM's attestation facilities can demonstrate the execution integrity of the code that runs in a SSCB to consume inputs, and produce outputs. All of these properties can be verified by the local USB verification device (<figref idref="DRAWINGS">FIG. 17</figref>), which exposes a simple interface to the user. They can also be attested over the network to arbitrary parties, thereby bolstering the security of Internet-scale applications.</p>
<p id="p-0350" num="0349">Software-Based Attestation for Legacy Hardware and Recovery</p>
<p id="p-0351" num="0350">Our coarse- and fine-grained protection mechanisms require the presence of current-generation x86 hardware with virtualization and attestation support. Older hardware that lacks these facilities can be supported using software-based techniques to create a dynamic root of trust. The primary drawback of the software based techniques is that tight timing requirements preclude use across the Internet. However, a local verification device (e.g., <figref idref="DRAWINGS">FIG. 17</figref>) can be readily employed to confirm that the user's system is in an approved state.</p>
<p id="p-0352" num="0351">Software-based attestation is also a powerful recovery mechanism. TPMs and the x86 systems that we consider are low-cost, commodity devices. It is unrealistic to think that they will withstand all attacks. For example, side-channels such as timing or electro-magnetic emissions may enable a sophisticated adversary to compromise hardware secrets in the platform's TPM. Software-based attestation can be used to confirm that a new root of trust has been established for execution on the platform, thereby enabling the system's TPM to be reconfigured for further use.</p>
<p id="p-0353" num="0352">Although the present invention has been described in terms of specific embodiments, the present invention may include many variations and modifications. Several additional embodiments and variations are identified below, although the present invention is not limited to these additional embodiments and the present invention is not limited to the previous embodiments described.</p>
<p id="p-0354" num="0353">In one embodiment, the present invention may include the implementation of the hardware-based tools for remote attestation and verification of untampered remote execution of security-sensitive code. Remote execution of security-sensitive code is intended to take advantage of the hardware support offered by commercially available platforms, such as Intel and AMD processors.</p>
<p id="p-0355" num="0354">In another embodiment, the present invention may include implementation of the software-based tools for local attestation and verification of untampered remote execution of security-sensitive code. Local execution of security-sensitive code is intended to take advantage of the user's proximity to the execution environment and the use of verification devices (e.g., of the size of a USB memory stick) with a human interface. The mechanisms used in this area need not rely on the physical security of TPM-based hardware since user proximity assures sufficient physical security. Hence minimizing the use of secrets becomes an achievable goal.</p>
<p id="p-0356" num="0355">In another embodiment, the present invention may include implementation of the first two applications requiring secure execution of sensitive code, namely (1) secure web browsing to a set of trusted websites, whereby a user can verify that any sensitive information she provides to the remote webserver arrives with its secrecy and integrity protected, and (2) an environment for OEMs to develop security-sensitive codeblocks complete with support for a trusted path to the user. This gives OEMs a secure platform on which new services can be deployed and existing services can be verifiably hardened against attack, even if the user's system is corrupted by malware. These applications will be implemented on a commercially available operating system platform such as Linux or Windows.</p>
<p id="p-0357" num="0356">In another embodiment, the present invention may include the implemented tools in a casual user environment supported by a commercially available platform.</p>
<p id="p-0358" num="0357">In another embodiment, the present invention may include the implementation of several client and server platforms that are distributed across the Internet or some other network for secure remote login. In addition, the present invention may be used to protect against attacks launched by malware and/or malicious insiders, both locally and remotely.</p>
<p id="p-0359" num="0358">In another embodiment, the present invention includes tools for user-verifiable execution of security-sensitive code on untrusted platforms is to enhance the integrity and security of commercial software products. These tools may be, for example, usable by independent parties without direct supervision from tool developers. The tools can provide significant assurance in the secure execution of sensitive software applications unhampered by the presence of malware.</p>
<p id="p-0360" num="0359">In another embodiment, the present invention includes a user device that allows the verification of correct execution of security-sensitive applications. The present invention may also include applications that will be a secure browsing environment targeted for use by end-users, and an environment for building a trusted path to security-sensitive codeblocks within applications targeted for use by OEMs. The present invention may also include other user-verifiable applications that will also run unencumbered by malware on commercial platforms such as Linux and Windows.</p>
<p id="p-0361" num="0360">In another embodiment, the present invention includes a secure browser environment as a stand-alone consumer product, a system to provide trusted path to security-sensitive code for OEMs, and other products and embodiments. Several embodiments of the present invention will be briefly described below.</p>
<p id="p-0362" num="0361">In addition, the examples provided herein are illustrative and not limiting, and other variations and modifications of the present invention are contemplated. Those and other variations and modifications of the present invention are possible and contemplated, and it is intended that the foregoing specification and the following claims cover such modifications and variations.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer, comprising:
<claim-text>a processor;</claim-text>
<claim-text>memory connected to the processor and including computer-readable instructions which, when executed by the processor, cause the processor to create a computing platform having:</claim-text>
<claim-text>a select guest having a privilege level and an identity, said select guest to be kept secure from other parts of said computer;</claim-text>
<claim-text>a legacy guest having a privilege level, said legacy guest not assumed to be secure;</claim-text>
<claim-text>a hypervisor, wherein:</claim-text>
<claim-text>the hypervisor supports both the select guest and the legacy guest;</claim-text>
<claim-text>the hypervisor has a privilege level that is more privileged than the privilege level of the select guest;</claim-text>
<claim-text>the hypervisor has a privilege level that is more privileged than the privilege level of the legacy guest;</claim-text>
<claim-text>the hypervisor partitions a unique portion of the memory for the exclusive use of the select guest;</claim-text>
<claim-text>the hypervisor partitions a unique portion of memory for the exclusive use of the legacy guest;</claim-text>
<claim-text>the hypervisor partitions a unique portion of memory for the exclusive use of the hypervisor;</claim-text>
<claim-text>a verification device connected to the processor and including a processor and memory, wherein the memory of the verification device includes computer-readable instructions and wherein the memory of the verification device includes a policy for the select guest;</claim-text>
<claim-text>wherein the computer-readable instructions in the memory of the computer, when executed by the processor of the computer, cause the processor of the computer to perform the steps of:</claim-text>
<claim-text>receiving a signal indicative of a request to execute the select guest;</claim-text>
<claim-text>authenticating a secure connection between the hypervisor and the verification device after receiving the signal indicative of the request to execute the select guest;</claim-text>
<claim-text>measuring the identity of at least a portion of the select guest before the select guest executes any instruction;</claim-text>
<claim-text>sending a measurement of the identity of the select guest to the verification device;</claim-text>
<claim-text>wherein the computer-readable instructions in the memory of the verification device, when executed by the processor in the verification device, cause the processor in the verification device to perform the steps of:</claim-text>
<claim-text>receiving the measurement of the select guest from the processor in the computer;</claim-text>
<claim-text>comparing the policy stored in the verification device with the measurement of the select guest received by the verification device;</claim-text>
<claim-text>wherein the steps of authenticating, measuring, sending, receiving the measurement, and comparing are performed after receiving the signal indicative of the request to execute the select guest and without rebooting the computer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the computer-readable instructions in the memory of the verification device, when executed by the processor in the verification device, cause the processor in the verification device to perform the step of:
<claim-text>sending a signal indicative of whether to execute the select guest after comparing the policy stored in the verification device with the measurement of the select guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the hypervisor has an identity;</claim-text>
<claim-text>the verification device includes a policy for the hypervisor;</claim-text>
<claim-text>authenticating a secure connection between the hypervisor and the verification device includes:</claim-text>
<claim-text>measuring the identify of at least a portion of the hypervisor; and</claim-text>
<claim-text>sending the measurement of the identity of the hypervisor to the verification device;</claim-text>
<claim-text>the steps of measuring the identify of at least a portion of the hypervisor and sending the measurement of the identity of the hypervisor to the verification device are performed after receiving the signal indicative of the request to execute the select guest and without rebooting the computer;</claim-text>
<claim-text>the computer-readable instructions in the memory of the verification device, when executed by the processor in the verification device, cause the processor in the verification device to perform the steps of:</claim-text>
<claim-text>receiving the measurement of the hypervisor from the processor in the computer; and</claim-text>
<claim-text>comparing the policy stored in the verification device with the measurement of the hypervisor received by the verification device; and</claim-text>
<claim-text>the steps of receiving the measurement of the hypervisor and comparing the policy stored in the verification device with the measurement of the hypervisor received by the verification device are performed after sending the measurement of the identity of the hypervisor to the verification device and without rebooting the computer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the hypervisor has an identity; and</claim-text>
<claim-text>the computer-readable instructions in the memory of the computer, when executed by the processor of the computer, cause the processor of the computer to perform the step of measuring the identity of the hypervisor before the hypervisor executes any instructions.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>at least one of the select guest and legacy guest includes a network interface connected to a network outside of the computer;</claim-text>
<claim-text>the policy stored in the verification device includes a list of trusted endpoints on the network for the guest having the network interface;</claim-text>
<claim-text>wherein the computer-readable instructions in the memory of the computer, when executed by the processor of the computer, cause the processor of the computer to perform the steps of:</claim-text>
<claim-text>identifying a network connection between the guest having the network interface and an endpoint on the network;</claim-text>
<claim-text>identifying the endpoint of the network connection;</claim-text>
<claim-text>determining whether the network connection to the endpoint is permitted by the policy of trusted endpoints stored in the verification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The computer of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein identifying the network connection between the guest having the network interface and the endpoint on the network includes identifying the network connection after the network connection is initiated by the endpoint of the network and before data transmitted by the guest is permitted to reach the network interface.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the policy of trusted endpoints stored in the verification device can be modified to add and remove trusted endpoints.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the policy identifies other guests with which the select guest may share information.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal indicative of the request to execute the select guest is initiated by a guest in the computing platform.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal indicative of the request to execute the select guest is initiated by a human user.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The computer of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the computer-readable instructions in the memory of the verification device, when executed by the processor in the verification device, cause the processor in the verification device to perform the step of:
<claim-text>providing a human-perceptible indication of whether the measurement of the select guest received by the verification device corresponds with the policy stored in the verification device, wherein providing the human-perceptible indication is performed after comparing the policy stored in the verification device with the measurement of the select guest that was received by the verification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the computing platform has a plurality of select guests, wherein each select guest has a privilege level and an identity;</claim-text>
<claim-text>the hypervisor supports each of the plurality of select guests;</claim-text>
<claim-text>the hypervisor has a privilege level that is more privileged than the privilege level of the plurality of select guests;</claim-text>
<claim-text>the hypervisor partitions a unique portion of the memory for the exclusive use of each of the plurality of select guests;</claim-text>
<claim-text>the verification device includes a policy for each of the plurality of select guests;</claim-text>
<claim-text>the step of receiving the signal indicative of the request to execute the select guest includes receiving a signal indicative of a request to execute one of the plurality of select guests; the step of measuring the identity of at least a portion of the select guest before the select guest executes any instruction includes measuring the identity of at least a portion of the select guest corresponding to the signal indicative of the request to execute one of the plurality of select guests;</claim-text>
<claim-text>the step of sending a measurement of the identity of the select guest to the verification device includes sending a measurement of the identity of the select guest corresponding to the signal indicative of the request to execute one of the plurality of select guests.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising after receiving the signal indicative of the request to execute one of the plurality of select guests:
<claim-text>providing a human-perceptible indication of which of the plurality of select guests is selected for execution, wherein providing a human-perceptible indication is provided by the verification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising executing the select guest after comparing the policy stored in the verification device with the measurement of the select guest that was received by the verification device.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The computer of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>a storage media device that is shared by both the select guest and the legacy guest; the select guest stores encrypted data on the storage media device;</claim-text>
<claim-text>the select guest sends an encryption key and an identity measurement to the hypervisor, wherein the encryption key corresponds to the encrypted data and the identity measurement corresponds to a guest permitted to receive the encryption key;</claim-text>
<claim-text>the hypervisor receives a request to access the encrypted data from a requesting guest;</claim-text>
<claim-text>the hypervisor measures the identity of the requesting guest before the requesting guest executes any instructions;</claim-text>
<claim-text>the hypervisor provides the encryption key to the requesting guest if the measurement of the identity of the requesting guest corresponds with the identity measurement received from the select guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The computer of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the select guest and the requesting guest are different guests.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The computer of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising providing a human-perceptible indication of whether the measurement of the select guest received by the verification device corresponds with the policy stored in the verification device.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The computer of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising receiving an input from the user indicative of confirmation to execute the select guest, wherein the input from the user indicative of the user's confirmation to execute the select guest is received:
<claim-text>after providing the human-perceptible indication of whether the measurement of the select guest received by the verification device corresponds with the policy stored in the verification device, and</claim-text>
<claim-text>before executing the select guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The computer of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the computer-readable instructions in the memory of the computer, when executed by the processor of the computer, cause the processor of the computer to perform the steps of:
<claim-text>receiving a signal indicative of a request to execute the legacy guest, wherein the signal indicative of the request to execute the legacy guest is received after executing the select guest;</claim-text>
<claim-text>pausing the execution of the select guest after receiving the signal indicative of the request to execute the legacy guest; and</claim-text>
<claim-text>executing the legacy guest after pausing the execution of the select guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The computer of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein receiving the signal indicative of the request to execute the legacy guest includes receiving an input at the verification device from a human user indicative of the request to execute the legacy guest.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The computer of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein receiving the signal indicative of the request to execute the legacy guest includes receiving a signal initiated by one of the guests in the computing platform.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The computer of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein:
<claim-text>the computer readable-instructions in the memory of the computer, when executed by the processor of the computer, cause the processor of the computer to perform the steps of:</claim-text>
<claim-text>receiving a signal indicative of a request to resume executing the select guest after executing the legacy guest;</claim-text>
<claim-text>authenticating a secure connection between the hypervisor and the verification device after receiving the signal indicative of the request to resume executing the select guest; sending a most recent measurement of the identity of the select guest to the verification device after authenticating the secure connection between the hypervisor and the verification device;</claim-text>
<claim-text>wherein the computer-readable instructions in the memory of the verification device, when executed by the processor in the verification device, cause the processor in the verification device to perform the steps of:</claim-text>
<claim-text>receiving the most recent measurement of the identity of the select guest from the processor in the computer;</claim-text>
<claim-text>comparing the policy stored in the verification device with the most recent measurement of the identity of the select guest that was received by the verification device;</claim-text>
<claim-text>wherein the steps of authenticating, sending, receiving the most recent measurement, and comparing are performed after receiving the signal indicative of a request to execute the select guest and without rebooting the computer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The computer of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising pausing execution of the legacy guest after receiving the signal indicative of the request to resume executing the select guest.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The computer of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the computer-readable instructions in the memory of the verification device, when executed by the processor in the verification device, cause the processor in the verification device to perform the steps of:
<claim-text>providing a human-perceptible indication of whether the most recent measurement of the select guest received by the verification device corresponds with the policy stored in the verification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The computer of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising:
<claim-text>receiving an input from a human user indicative of confirmation to execute the select guest, wherein the input indicative of confirmation to execute the select guest is received:</claim-text>
<claim-text>after providing a human-perceptible indication of whether the most recent measurement of the select guest received by the verification device corresponds with the policy stored in the verification device, and</claim-text>
<claim-text>before executing the select guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The computer of <claim-ref idref="CLM-00025">claim 25</claim-ref>, further comprising resuming execution of the select guest, wherein resuming execution of the select guest is performed:
<claim-text>after pausing the execution of the legacy guest; and</claim-text>
<claim-text>after receiving an input from the human user indicative of confirmation to execute the select guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The computer of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising resuming execution of the select guest, wherein resuming execution of the select guest is performed:
<claim-text>after pausing the execution of the legacy guest; and</claim-text>
<claim-text>without receiving an input from a human user indicative of confirmation to execute the select guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The computer of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising resuming execution of the select guest, wherein resuming execution of the select guest is performed:
<claim-text>after pausing the execution of the legacy guest; and</claim-text>
<claim-text>without receiving an input from a human user indicative of confirmation to execute the select guest if the measurement of the select guest received by the verification device corresponds with the policy stored in the verification device.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The computer of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising:
<claim-text>resuming execution of the select guest, wherein resuming execution of the select guest is preformed:</claim-text>
<claim-text>after pausing the execution of the legacy guest; and</claim-text>
<claim-text>after comparing the policy stored in the verification device with the measurement of the select guest that was sent to the verification device by the processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The computer of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the signal indicative of the request to resume executing the select guest is initiated by a guest in the computing platform.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The computer of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the signal indicative of the request to resume executing the select guest is initiated by a human user.</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein there is more than one legacy guest.</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>a first allocated device connected to the computer;</claim-text>
<claim-text>a second allocated device connected to the computer;</claim-text>
<claim-text>a base device connected to the computer;</claim-text>
<claim-text>wherein:</claim-text>
<claim-text>the hypervisor partitions the first allocated device for exclusive use by the select guest;</claim-text>
<claim-text>the hypervisor partitions the second allocated device for exclusive use by the legacy guest; and</claim-text>
<claim-text>the hypervisor partitions the base device for use by both the select guest and the legacy guest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. The computer of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein both the unique portion of the memory for exclusive use by the select guest and the unique portion of the memory for exclusive use by the legacy guest are different portions of a common data storage device.</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. The computer of <claim-ref idref="CLM-00034">claim 34</claim-ref>, wherein:
<claim-text>the hypervisor detects when one of the guests sends write instructions to a storage base device;</claim-text>
<claim-text>the hypervisor sends the write instructions to the unique portion of the memory for excusive use by the select guest when the write instructions come from the select guest;</claim-text>
<claim-text>the hypervisor sends the write instructions to the unique portion of the memory for exclusive use by the legacy guest when the write instructions come from the legacy guest.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
