<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627419-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627419</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12122628</doc-number>
<date>20080516</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>795</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>21</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>726  5</main-classification>
<further-classification>713182</further-classification>
</classification-national>
<invention-title id="d2e53">Multiple image reverse turing test</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6195698</doc-number>
<kind>B1</kind>
<name>Lillibridge et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2004/0199597</doc-number>
<kind>A1</kind>
<name>Libbey et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2004/0230843</doc-number>
<kind>A1</kind>
<name>Jansen</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713202</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2005/0066201</doc-number>
<kind>A1</kind>
<name>Goodman et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713202</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2005/0114705</doc-number>
<kind>A1</kind>
<name>Reshef et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713201</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2005/0120201</doc-number>
<kind>A1</kind>
<name>Benaloh et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2005/0138376</doc-number>
<kind>A1</kind>
<name>Fritz et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2007/0094717</doc-number>
<kind>A1</kind>
<name>Srinivasan et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>726  5</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2007/0201745</doc-number>
<kind>A1</kind>
<name>Wang</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2007/0250920</doc-number>
<kind>A1</kind>
<name>Lindsay</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>726  7</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2008/0066014</doc-number>
<kind>A1</kind>
<name>Misra</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2008/0301778</doc-number>
<kind>A1</kind>
<name>Fritz et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>726  4</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>12</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>726  2-  7</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 16- 19</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 22</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 23</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 25- 29</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713150</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713155</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713168</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715700</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715701</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715760</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715764</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715769</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715770</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715809</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715810</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715846</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60931866</doc-number>
<date>20070525</date>
</document-id>
</us-provisional-application>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>VanDeMar</last-name>
<first-name>Michael J</first-name>
<address>
<city>Largo</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>VanDeMar</last-name>
<first-name>Michael J</first-name>
<address>
<city>Largo</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Miller</last-name>
<first-name>Tiffany C.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<examiners>
<primary-examiner>
<last-name>Barron, Jr.</last-name>
<first-name>Gilberto</first-name>
<department>2432</department>
</primary-examiner>
<assistant-examiner>
<last-name>Nobahar</last-name>
<first-name>Abdulhakim</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">In a Reverse Turing Test an applicant seeking access to a computer process is presented with an image containing human-readable data that is intended to be inaccessible to an automated process or bot. In an improved Reverse Turing Test the applicant is presented with multiple sub-images that have to be rearranged in order to yield the overall image. This does not substantially increase a human applicant's difficulty in dealing with the test, but makes it much more difficult for a bot to interpret the image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="251.97mm" wi="186.27mm" file="US08627419-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="274.32mm" wi="196.68mm" file="US08627419-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="211.67mm" wi="157.82mm" file="US08627419-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="205.99mm" wi="121.67mm" file="US08627419-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="260.52mm" wi="123.36mm" file="US08627419-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The present invention relates generally to the field of electronic security methods, and in particular to a method for determining whether an applicant for use of a secured computer, computer system or computer process is a human or is an automated process. More specifically, the invention involves human skills of using a combination of image assembly from individual parts and visual recognition of the assembled image.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">It is often desirable or necessary to determine if a particular applicant seeking to use an electronic service remotely is in fact a human being, and not an automated system. For example, web sites on the Internet that offer access for free to humans but want to restrict automated programs (sometimes referred to as &#x201c;bots&#x201d;) from abusing their system need a way to distinguish between the two. This is often the case in situations where normal human usage would put an acceptable load on a server that automated processes could easily exceed. Additionally, in many cases bots are designed to use computer system services for purposes that they are not intended for, such as mass registering for free email accounts that are then used to send unsolicited advertising.</p>
<p id="p-0004" num="0003">Currently, a commonly used automated method for making the determination of whether an applicant for access to a secured service or computer system is a human or is a bot is what is known as a reverse Turing test (RTT). This can involve presenting the applicant with an image (or a data set convertible into an image), which can, for example, contain either a string of characters or a picture of a readily recognizable object, and having the user identify what is presented in the image. Typically the images presented to the users are distorted in an attempt to make it more difficult for Optical Character Recognition (OCR) software, and other visual recognition programs, to determine what the image is (thereby allowing automated systems to fool the process of identifying whether a user is in fact human). One of the problems being encountered is that as the methods for identifying text and images by computer programs advance, the images must be obfuscated or distorted more and more, increasing the difficulty for a human user to identify the images as well. Therefore a method of increasing the difficulty for a machine or bot to pass an RTT, without increasing the difficulty for a human user, is highly desirable.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0005" num="0004">A method of distinguishing a human user from a machine is provided. The method comprises using an algorithm to generate a data set representative of an image containing data that is visually identifiable by a human. The image is divided into multiple sub-images. In a preferred embodiment the data set comprising the sub-images is then communicated to the applicant's computer where all the sub-images are preferably presented simultaneously by means of a graphic user interface (GUI) that provides means to manipulate the positioning, size, or alignment of the various sub images. This may be done, for example by recourse to a Dynamic Hypertext Markup Language (DHTML) web page, a Flash multimedia program, or a web page written in some future standard of HTML or other web layout language that inherently allows for the user to reposition and manipulate elements contained within it. Through the use of a keyboard, mouse, or similar input device conventionally used with a human user's computer, a human applicant can manipulate the position, alignment, and rotation of the sub-images in such a way that the original image can be reassembled.</p>
<p id="p-0006" num="0005">A human applicant can reassemble the image and indicate to the security process that he or she recognizes the data. This may be done through actions such as inputting data contained within the reassembled image or by following directions contained within the data. That user interaction is then received and interpreted. A determination of whether the user is a human or not is made based on a comparison between what the user inputs and what data the original image contained.</p>
<p id="p-0007" num="0006">The additional step of requiring the image to be correctly assembled before identification of the data contained within it can be made adds another level of difficulty that image recognition software would have to overcome in order to trick the system into thinking that a human was attempting to make access. This process, however does not substantially increase the effort a human would encounter. Another aspect of preferred embodiments of the present invention is that a method comprising the recited steps of overlaying data and image, chopping up the image, shuffling the pieces and sending the resultant puzzle to a requestor for solving is a method of controlling access to a computer or service in order to inhibit unauthorized use.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007">The present invention is illustrated by way of example, and not limitation, in the following figures of the accompanying drawings:</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> shows a flowchart of a method for determining whether an applicant is a human or an algorithmic process or bot in accordance with one illustrative embodiment of the present invention.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> shows an exemplary method, in accordance with another aspect of the invention, of how a generated image containing human readable reference data might be presented to the user after being divided into upper and lower sections.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref> shows an exemplary method, in accordance with another aspect of the invention, of how a generated image containing reference data might be presented to an applicant after being divided in such a way that the middle section is separated from the remainder of the image.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 4</figref> shows an exemplary method, in accordance with another aspect of the invention, of how a generated image containing reference data might be presented to the user after being divided in such a way that the various sub images resemble, and fit together as, the irregular pieces of a jigsaw puzzle.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 5</figref> shows an exemplary method, in accordance with another aspect of the invention, of how a generated image containing reference data, with the reference data being in the form of instructions, might be presented to the user after being divided in such a way that the various sub-images are sliced into diagonal sections.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0014" num="0013">In studying this Detailed Description, the reader may be aided by noting definitions of certain words and phrases used throughout this patent document. Wherever those definitions are provided, those of ordinary skill in the art should understand that in many, if not most instances, such definitions apply to both preceding and following uses of such defined words and phrases. As noted above, &#x201c;bot&#x201d; stands for an algorithmic process that can, to some extent, mimic the behavior of a human seeking access to a service or process furnished by a computer. The words &#x201c;user&#x201d; and &#x201c;applicant&#x201d; are used more or less interchangeably to denote either a person or a bot seeking access to a computer. Moreover, the phrase &#x201c;access to a computer&#x201d; shall stand for any sort of such access including, but not limited to, access to the operating system of a single computer, access to a computer system, access to a process or service operating on one or more computers or to an information service supplied by a computer, regardless of whether it is supplied locally or remotely. Much of the following discussion is couched in terms befitting an internet-based scenario in which an applicant uses a computer to transmit a service request to a remote computer that can grant or deny that request. It will be understood, however, that the methods disclosed herein are not limited to that scenario and do not depend on the details of data transmission. For example, the claimed methods of distinguishing a human applicant from a bot are applicable to a single-computer environment in which the novel method is used to prevent access to a secured program by a viral bot running on the computer. Moreover, those skilled in the art will understand that in the interest of clarity of presentation much of this disclosure is presented in terms of what a human applicant would see on a graphical user interface&#x2014;i.e., an image or a collection of images&#x2014;and not in terms of data sets or computer files that a rival bot would process.</p>
<p id="p-0015" num="0014">Methods of distinguishing a human user from a bot are described. Numerous specific details are set forth in the following description for the purposes of explanation, to aid in a thorough understanding of the present invention. It will be evident, however, to one skilled in the art that the present invention may be practiced without these specific details. It will be appreciated that those skilled in the art will be able to devise various other arrangements, which, although not explicitly described or shown herein, embody the principles of the invention, and are included within its spirit and scope.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> shows a flowchart of a method for determining whether a given user is a human or a bot in accordance with one illustrative embodiment of the present invention. In particular, an access request is made by the applicant in step <b>10</b>. The system generates a data set representative of an image containing reference data in Step <b>12</b>. This image is divided equally or unequally, with or without rotation, resizing, or inversion into various sub-images (step <b>14</b>).</p>
<p id="p-0017" num="0016">The various sub-images are displayed to the user in step <b>16</b>, generally in a single interface that allows for their position, orientation or size to be individually or collectively manipulated through user input. The sub-images are separated and shuffled, as generally indicated in <figref idref="DRAWINGS">FIGS. 2-5</figref>. Other means of shuffling can include rotating or flipping of the various sub-images along either the x-axis or the y-axis, or resizing of the individual sub-images.</p>
<p id="p-0018" num="0017">Using available input devices, such as a mouse or other input device attached to a computer, the user arranges the various sub-images until the reference data is evident (step <b>18</b>). The applicant then inputs that data or responds in such a way indicating that the data contained within the reassembled image is recognized (step <b>20</b>). The input data or the interaction performed by the user is then compared against the data that was contained within the original image step <b>22</b>.</p>
<p id="p-0019" num="0018">The decision as to whether or not the data or interaction received from the user matches the data contained within the original image is made in step <b>24</b>. If the data does not match, then the user is rejected as being a machine or bot (step <b>26</b>). If the data does match, then the user is accepted as being human (step <b>28</b>).</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 2</figref> shows an exemplary illustration of an image containing data and that is divided into multiple sub images which are then presented to the user for reassembly. In particular, the original image contains the data for the user to recognize in step <b>30</b>. The image is then divided into upper and lower portions in step <b>32</b>.</p>
<p id="p-0021" num="0020">These separate sub-images are then presented to the user for reassembly by positioning through drag and drop, which is to say selecting with the mouse, dragging them to another location and releasing the mouse to leave the given sub image in the new location.</p>
<p id="p-0022" num="0021">In this example the upper sub image is aligned horizontally above the lower sub image by the user, after which the user inputs the data contained within the reassembled image. This inputted data is then compared by the system against the data contained within the original image for purposes of making the determination as to whether the user is human or bot.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 3</figref> shows an exemplary illustration of another method of dividing the original visual data-containing image into multiple sub-images, this time by virtue of using image transparencies. Again, the original image contains the data for the user to recognize in step <b>34</b>. The image is divided in such a way that the horizontal middle section is removed from the original image, and a copy of that middle section is placed on a new image containing a transparent background step in <b>36</b>.</p>
<p id="p-0024" num="0023">separate sub-images are presented to the user for reassembly by positioning the sub-image created from the horizontal middle portion of the original image directly over the sub-image that has the middle section removed. After reassembly the user inputs the data contained within the reassembled image, said inputted data is then compared by the system against the data contained in the original image in order to determine if the user is human or bot.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 4</figref> shows an exemplary illustration of another method of dividing the original visual data-containing image into multiple sub-images, this time through the use of splines or other patterns to create irregularly shaped pieces that fit together to form the whole. In particular, again the original image contains the data for the user to recognize in step <b>38</b>. The image is then divided in such a way that the upper left, upper right, lower left, and lower right sections are separated from one another, and through the use of transparencies an interlocking pattern is associated with each of the sections.</p>
<p id="p-0026" num="0025">separate sub-images are presented to the user in a DHTML web page after being shuffled in step <b>40</b>. Using the mouse to drag and drop the sections, the user positions the upper left (step <b>42</b>), lower left (step <b>44</b>), upper right <b>46</b>, and lower right <b>48</b> sub-images so that the data contained within the original image can be seen. After reassembly the user inputs the data contained within the reassembled image, said inputted data then being compared by the system against the data contained in the original image in order to determine if the user is a human or a bot.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 5</figref> shows an exemplary illustration of another method of dividing the original visual data-containing image into multiple sub-images by dividing the image into diagonal slices. In particular, the original image contains instructions for the user to recognize and follow (step <b>50</b>). The image is then divided in such a way that the left, middle, and right sections are separated from one another into diagonal shapes.</p>
<p id="p-0028" num="0027">separate sub-images are presented to the user in a DHTML web page after being shuffled, along with three HTML buttons step <b>52</b>. Using the mouse to drag and drop the sections, the user positions the left section step <b>54</b>, middle section step <b>56</b>, and right section <b>58</b> so that the data contained within the original image, in the form of instructions for the user to follow, can be seen.</p>
<p id="p-0029" num="0028">reassembly the user follows the instructions contained within the reassembled image <b>60</b>. The user's actions are then compared by the system against the data contained in the original image in order to determine if the user is human or bot.</p>
<p id="p-0030" num="0029">Thus, methods of distinguishing a human user from a machine, or bot, have been described. Although the present invention has been described with reference to specific exemplary embodiments, it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the invention. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>I claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of a computer determining that an applicant seeking access to said computer is a human applicant, the method comprising the steps of:
<claim-text>selecting by said computer an image containing human-readable data;</claim-text>
<claim-text>dividing by said computer said image into a plurality of separated sub-images;</claim-text>
<claim-text>presenting by said computer said plurality of separated sub-images to said applicant by a graphical user interface, said graphical user interface allowing said human applicant to manipulate at least one of a position, an orientation, or a size of at least one of said plurality of separated sub-images, whereby, said plurality of separated sub-images forms a reassembled image, said reassembled image containing human-readable data;</claim-text>
<claim-text>said human applicant following the steps comprising of:</claim-text>
<claim-text>recognizing by said human applicant a feature of said reassembled image, said feature comprising human-readable data, said human applicant responding to said human-readable data by performing the step of inputting said human-readable data to said computer to be authenticated;</claim-text>
<claim-text>said computer verifying that said applicant is said human applicant only if said applicant provides an input responsive to recognition of said human-readable data;</claim-text>
<claim-text>determining by said computer that said applicant is said human applicant, whereby, if said response is correct to allow access to said computer; and, determining by said computer that said applicant is said human applicant, whereby, if said response is incorrect to deny access to said computer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the graphical user interface comprises a portion of a second computer.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A method of a computer system determining that an applicant seeking access to said computer system is a human applicant, the method comprising the steps of:
<claim-text>generating by said computer system a computer file representative of a plurality of separated sub-images that can be combined by said human applicant to yield an image containing human-readable data;</claim-text>
<claim-text>displaying by said computer system said plurality of separated sub-images on a graphical user interface accessible to said applicant, whereby, said graphical user interface is operable by said human applicant to combine said plurality of separated sub-images, in accordance with said human applicant's manipulation thereof to yield said image containing human-readable data;</claim-text>
<claim-text>said human applicant following the steps comprising of:</claim-text>
<claim-text>recognizing by said human applicant said human-readable data contained within said image;</claim-text>
<claim-text>submitting by said human applicant a response based on a visual recognition of said human-readable data;</claim-text>
<claim-text>said computer verifying that said applicant is said human applicant only if said applicant supplies an input responsive to said human-readable data;</claim-text>
<claim-text>determining by said computer system that said applicant is said human applicant, whereby, if said response is correct to allow access to said computer; and, determining by said computer system that said applicant is said human applicant, whereby, if said response is incorrect to deny access to said computer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein the computer system comprises a single computer comprising the graphical user interface and wherein the file representative of a plurality of sub-images is generated by means of an algorithm running on the computer.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein the computer system comprises at least two computers wherein the computer file representative of a plurality of separated sub-images is generated by an algorithm running on a first of the computers and the input responsive to the human readable data is entered at a second of the at least two computers.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein the input responsive to the human-readable data comprises at least a portion of the human-readable data.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A method of a computer system determining that an applicant seeking access to said computer system is not human and thereupon denying the requested access, the method comprising the steps of:
<claim-text>generating by said computer system a first data set representative of an image containing human-readable data;</claim-text>
<claim-text>generating by said computer system a second data set representative of a plurality of separated sub-images of said image containing human-readable data, whereby, said plurality of separated sub-images are separated from each other by at least one of translation, rotation, overlay, or change of size;</claim-text>
<claim-text>supplying by said computer system said second data set to a graphical user interface operable by said human applicant to reassemble said image containing human-readable data by said human applicant manipulating at least one of said plurality of separated sub-images;</claim-text>
<claim-text>said human applicant following the steps comprising of:</claim-text>
<claim-text>recognizing by said human applicant a feature on said reassembled image, said feature comprising human-readable data, said human applicant responding to said human-readable data by performing the step of inputting said human-readable data on said computer to be authenticated;</claim-text>
<claim-text>said computer verifying that said applicant is said human applicant only if said applicant provides an input responsive to recognition of said human-readable data;</claim-text>
<claim-text>determining by said computer system if said applicant is not human, whereby, if said response is correct to allow access to said computer; and, determining by said computer system if said applicant is not human, whereby, if said response is incorrect to deny access to said computer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the first and second data sets are generated on a first computer and are transmitted to a second computer comprising the graphical user interface used by the applicant.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method of a computer determining that an applicant seeking access to said computer is a human applicant, the method comprising the steps of:
<claim-text>selecting by said computer an image containing human-readable data;</claim-text>
<claim-text>dividing by said computer said image into a plurality of separated sub-images;</claim-text>
<claim-text>presenting by said computer said plurality of separated sub-images to said applicant by a graphical user interface, said graphical user interface allowing said human applicant to manipulate at least one of a position, an orientation, or a size of at least one of said plurality of separated sub-images, whereby, said plurality of separated sub-images forms a reassembled image, said reassembled image containing human-readable data;</claim-text>
<claim-text>said human applicant following the steps comprising of:</claim-text>
<claim-text>recognizing by said human applicant instructions on said reassembled image, said human applicant responding to said instructions by following the steps of said instructions;</claim-text>
<claim-text>said computer verifying that an applicant is said human applicant only if said applicant follows said steps of said instructions;</claim-text>
<claim-text>determining by said computer that said applicant is said human applicant, whereby, if said response is correct to allow access to said computer; and, determining by said computer that said applicant is said human applicant, whereby, if said response is incorrect to deny access to said computer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref> wherein following said steps of said instructions comprises said human applicant performing an interaction on said computer.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref> wherein following said steps of said instructions comprises said human applicant performing said step of inputting said human-readable data to said computer.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein said human-readable data comprises instructions and wherein the input responsive to recognition comprises said human applicant following said instructions.</claim-text>
</claim>
</claims>
</us-patent-grant>
