<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624897-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624897</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12821600</doc-number>
<date>20100623</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2009-0078841</doc-number>
<date>20090825</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>722</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>10</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>20</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345427</main-classification>
<further-classification>345419</further-classification>
</classification-national>
<invention-title id="d2e71">Method and apparatus for automatic transformation of three-dimensional video</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2002/0009137</doc-number>
<kind>A1</kind>
<name>Nelson et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2004/0027267</doc-number>
<kind>A1</kind>
<name>Rousso</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>342  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2004/0044657</doc-number>
<kind>A1</kind>
<name>Lee</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2005/0117637</doc-number>
<kind>A1</kind>
<name>Routhier et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2006/0062490</doc-number>
<kind>A1</kind>
<name>Ha et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382298</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2006/0177124</doc-number>
<kind>A1</kind>
<name>Ha</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382154</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>EP</country>
<doc-number>1024672</doc-number>
<kind>A1</kind>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>EP</country>
<doc-number>1596609</doc-number>
<kind>A2</kind>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>8-331599</doc-number>
<kind>A</kind>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2006-332985</doc-number>
<kind>A</kind>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>International Search Report (PCT/ISA/220) dated Feb. 28, 2011, issued in International Application No. PCT/KR2010/004079.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Ianir Ideses et al., &#x201c;Real-time 2D to 3D Video Conversion&#x201d;, Journal of Real-Time Image Processing, vol. 2, No. 1, pp. 3-9, 2007.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Olivier Faugeras et al., &#x201c;Real time correlation-based stereo: algorithm, implementations and applications&#x201d;, Technical Report RR-2013, INRIA, 1993.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Luis Alvarez, &#x201c;Dense Disparity Map Estimation Respecting Image Discontinuities: A PDE and Scale-Space Based Approach&#x201d;, Technical Report RR-3874, INRIA, 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Communication dated Oct. 30, 2012 issued by the Mexican Patent Office in counterpart Mexican Patent Application No. MX/a/2011/012534.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Communication from the European Patent Office issued Mar. 12, 2013 in counterpart European Application No. 10792331.0.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>29</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>18</number-of-drawing-sheets>
<number-of-figures>29</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61219438</doc-number>
<date>20090623</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100321390</doc-number>
<kind>A1</kind>
<date>20101223</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Yong-tae</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Sang-hyoun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Dae-sik</first-name>
<address>
<city>Hwaseong-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Min</last-name>
<first-name>Jong-sul</first-name>
<address>
<city>Hwaseong-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Yong-tae</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Sang-hyoun</first-name>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Kim</last-name>
<first-name>Dae-sik</first-name>
<address>
<city>Hwaseong-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Min</last-name>
<first-name>Jong-sul</first-name>
<address>
<city>Hwaseong-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sughrue Mion, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Samsung Electronics Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Tung</last-name>
<first-name>Kee M</first-name>
<department>2677</department>
</primary-examiner>
<assistant-examiner>
<last-name>Chen</last-name>
<first-name>Frank</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method of transforming a 3D video format of a 3D video, the method including receiving a video sequence comprising 3D video that includes left-viewpoint video and right-viewpoint video; estimating at least one of disparity information between the left-viewpoint video and the right-viewpoint video and correlation information between neighboring pixel values of the left-viewpoint video and the right-viewpoint video, and determining a 3D video format of the 3D video based on a result of the estimating; transforming the left-viewpoint video and the right-viewpoint video into a format, based on the determined 3D video format; and displaying the transformed left-viewpoint video and the transformed right-viewpoint video three-dimensionally on a the display device.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="54.10mm" wi="131.66mm" file="US08624897-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="228.09mm" wi="153.16mm" file="US08624897-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="203.12mm" wi="152.48mm" orientation="landscape" file="US08624897-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="221.74mm" wi="171.11mm" file="US08624897-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="239.69mm" wi="173.65mm" orientation="landscape" file="US08624897-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="239.69mm" wi="162.73mm" file="US08624897-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="239.01mm" wi="149.94mm" file="US08624897-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="231.31mm" wi="150.62mm" file="US08624897-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="207.60mm" wi="115.32mm" file="US08624897-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="221.74mm" wi="178.82mm" file="US08624897-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="164.93mm" wi="112.69mm" file="US08624897-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="149.35mm" wi="119.21mm" file="US08624897-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="208.28mm" wi="120.48mm" file="US08624897-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="87.12mm" wi="131.40mm" file="US08624897-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="196.77mm" wi="125.56mm" file="US08624897-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="232.58mm" wi="119.80mm" orientation="landscape" file="US08624897-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="153.84mm" wi="132.00mm" file="US08624897-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="178.82mm" wi="179.41mm" file="US08624897-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="178.82mm" wi="182.63mm" file="US08624897-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED PATENT APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims priority from U.S. Provisional Application No. 61/219,438 filed Jun. 23, 2009, and priority from Korean Patent Application No. 10-2009-0078841 filed Aug. 25, 2009, the disclosures of which are incorporated herein in their entirety by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">1. Field</p>
<p id="p-0004" num="0003">Apparatuses and methods consistent with exemplary embodiments relate to video format transformation performed to reconstruct three-dimensional (3D) video that is a mixture of the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">A plurality of pieces of two-dimensional (2D) video captured from various viewpoints is used to display 3D video. Various formats may be used to record the pieces of 2D video. Existing 3D display apparatuses alternately display a plurality of pieces of 2D video captured from different viewpoints to display 3D video. Thus, in order to accurately display the 3D video, the pieces of 2D video needs to be accurately extracted from the 3D video. To this end, correct information regarding the format of the 3D video is needed.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0007" num="0006">Exemplary embodiments may address at least the above problems and/or disadvantages and other disadvantages not described above. Also, exemplary embodiments are not required to overcome the disadvantages described above, and an exemplary embodiment may not overcome any of the problems described above.</p>
<p id="p-0008" num="0007">Exemplary embodiments provide a method of displaying video three-dimensionally by analyzing 3D video and determining the format of the 3D video, which represents a manner in which left-viewpoint video and right-view point video are arranged.</p>
<p id="p-0009" num="0008">According to an aspect of an exemplary embodiment, there is provided a method of transforming a format of 3D video, the method including receiving a video sequence including 3D video that has left-viewpoint video and right-viewpoint video; estimating at least one of disparity information between the left-viewpoint video and the right-viewpoint video and correlation information between neighboring pixel values of the left-viewpoint video and the right-viewpoint video, and determining a 3D video format of the 3D video based on the result of estimation, where the 3D video format represents a manner in which the left-viewpoint video and the right-viewpoint video are arranged in the 3D video; transforming the left-viewpoint video and the right-viewpoint video into a format, based on the 3D video format, so that the left-viewpoint video and the right-viewpoint video are displayed three-dimensionally in a display device; and displaying the transformed left-viewpoint video and right-viewpoint video three-dimensionally in the display device.</p>
<p id="p-0010" num="0009">The determining of the 3D video format may include determining whether the 3D video format is a side by side format, a top and bottom format, a horizontal line interleaved format, or a vertical line interleaved format, based on the disparity information between the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0011" num="0010">The determining of the 3D video format may include determining whether the 3D video format is a horizontal line interleaved format, a vertical line interleaved format, or a checker board format, based on the correlation information between neighboring pixel values of the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0012" num="0011">The determining of the 3D video format may include determining whether the 3D video format is a horizontal line interleaved format, a vertical line interleaved format, or a checker board format, based on the correlation information between neighboring pixel values of the left-viewpoint video and the right-viewpoint video; and determining whether the 3D video format is a field sequential format or a frame sequential format, based on the disparity information.</p>
<p id="p-0013" num="0012">The determining of the 3D video format may include determining whether the 3D video format is the side by side format or the top and bottom format by detecting a boundary line between the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0014" num="0013">In order to determine the 3D video format of the 3D video in a region that has texture of the 3D video, the determining of the 3D video format may further include detecting the region having texture by calculating a smoothness of corresponding regions of the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0015" num="0014">The determining of the 3D video format may include estimating first disparity information by using an upper and lower differential image that represents an absolute value of a difference value between upper and lower regions of the 3D video (disparity estimated in consideration of the top and bottom format); and estimating second disparity information by using a left and right differential image that represents an absolute value of a difference value between left and right regions of the 3D video (disparity estimated in consideration of the side by side format).</p>
<p id="p-0016" num="0015">The determining of the 3D video format may include determining whether the 3D video format is the top and bottom format or the side by side format, based on the first disparity information and the second disparity information.</p>
<p id="p-0017" num="0016">The determining of the 3D video format may include dividing vertical lines in the 3D video into an odd-numbered vertical line and an even-numbered vertical line, and estimating third disparity information by using a vertical line differential image that represents an absolute value of a difference value between the odd-numbered vertical line and the even-numbered vertical line; and dividing horizontal lines in the 3D video into an odd-numbered line and an even-numbered horizontal line, and estimating fourth disparity information by using a horizontal line differential image that represents an absolute value of a difference value between the odd-numbered horizontal line and the even-numbered horizontal line.</p>
<p id="p-0018" num="0017">The determining of the 3D video format may further include determining whether the 3D video format is the vertical line interleaved format or the horizontal line interleaved format, based on the third disparity information and the fourth disparity information.</p>
<p id="p-0019" num="0018">The determining of the 3D video format may further include selecting the first section as a candidate section of the first disparity information when the length of a first section in which values of continuous pixels in the upper and lower differential image are greater than a first threshold is greater than a first longest disparity; and selecting the second section as a candidate section of the second disparity information when the length of a second section in which values of continuous pixels of the left and right differential image are greater than a second threshold is greater than a second longest disparity.</p>
<p id="p-0020" num="0019">The determining of the 3D video format may further include comparing the total number of candidate sections of the first disparity information with the total number of candidate sections of the second disparity information, determining that the 3D video format is the top and bottom format when the total number of candidate sections of the first disparity information is less than the total number of candidate sections of the second disparity information, and determining that the 3D video format is the side by side format when the total number of candidate sections of the first disparity information is greater than the total number of candidate sections of the second disparity information.</p>
<p id="p-0021" num="0020">The determining of the 3D video format may further include selecting the third section as a candidate section of the third disparity information when the length of a third section in which values of continuous pixels of the vertical line differential image are greater than a third threshold is greater than a third longest disparity; and selecting the fourth section as a candidate section of the fourth disparity information when the length of a fourth section in which values of continuous pixels of the horizontal line differential image are greater than a fourth threshold is greater than a fourth longest disparity.</p>
<p id="p-0022" num="0021">The determining of the 3D video format may further include comparing the total number of candidate sections of the third disparity information with the total number of candidate sections of the fourth disparity information, determining that the 3D video format is the vertical line interleaved format when the total number of candidate sections of the third disparity information is greater than the total number of candidate sections of the fourth disparity information, and determining that the 3D video format is the horizontal line interleaved format when the total number of candidate sections of the third disparity information is less than the total number of candidate sections of the fourth disparity information.</p>
<p id="p-0023" num="0022">The determining of the 3D video format may further include estimating correlation information between values of three pixels of the 3D video that are continuous in the vertical direction; and estimating correlation information between values of three pixels of the 3D video that are continuous in the horizontal direction.</p>
<p id="p-0024" num="0023">The determining of the 3D video format may include determining the 3D video format to be the vertical line interleaved format when the total number of pieces of correlation information between values of pixels in the horizontal direction, which are greater than a threshold of correlation between pixel values, is greater than a predetermined threshold and when the total number of pieces of correlation information between values of pixels in the vertical direction, which are greater than the threshold of correlation between pixel values, is less than the predetermined threshold; determining the 3D video format to be the horizontal line interleaved format when the total number of pieces of correlation information between the values of pixels in the horizontal direction, which are greater than the threshold of correlation between pixel values, is less than a predetermined threshold and when the total number of pieces of correlation information between the values of pixels in the vertical direction, which are greater than the threshold of correlation between pixel values, is greater than the predetermined threshold; and determining the 3D video format to be the checker board format when both the total number of pieces of correlation information between the values of pixels in the horizontal direction, which are greater than the threshold of correlation between pixel values, and the total number of pieces of correlation information between the values of pixels in the vertical direction, which are greater than the threshold of correlation between pixel values, are greater than the predetermined threshold;</p>
<p id="p-0025" num="0024">The correlation information between the values of three pixels that are continuous in the vertical direction may be a ratio of the sum of a second difference value and a third difference value to a first difference value, where the first difference value is an absolute value of a difference value between upper and lower pixels, the second difference value is an absolute value of a difference value between the upper pixel and a middle pixel, and the third difference value is an absolute value of a difference value between the middle and lower pixels from among the three pixels that are continuous in the vertical direction. The correlation information between the values of three pixels that are continuous in the horizontal direction may be a ratio of the sum of a fifth difference value and a sixth difference value to a fourth difference value, where the fourth difference value is an absolute value of a difference value between left and right pixels, the fifth difference value is an absolute value of a difference value between the left pixel and a center pixel, and the sixth difference value is an absolute value of a difference value between the center and right pixels from among the three pixels that are continuous in the horizontal direction.</p>
<p id="p-0026" num="0025">The determining of the 3D video format may further include estimating a change in a temporal disparity between three continuous frames of the 3D video on a time axis.</p>
<p id="p-0027" num="0026">The change in the temporal disparity between three continuous frames of the 3D video on the time axis may be a ratio of the sum of second differential frame data and third differential frame data to first differential frame data, where the first differential frame data is an absolute value of a difference value between first and third frames, the second differential frame data is an absolute value of a difference value between the first frame and a second frame, and the third differential frame data is an absolute value of a difference value between the second and third frames from among the three continuous frames on the time axis.</p>
<p id="p-0028" num="0027">The detecting of the boundary line between the left-viewpoint video and the right-viewpoint video may include dividing the 3D video into two equal upper and lower regions, and calculating a ratio of a horizontal boundary line difference value to the sum of an upper horizontal boundary line difference value and a lower horizontal boundary line difference value, where the upper horizontal boundary line difference value is an absolute value of a difference value between two adjacent pixels that are disposed above and perpendicular to a horizontal boundary line between the upper and lower regions, the lower horizontal boundary difference value is an absolute value of a difference value between two adjacent pixels that are disposed below and perpendicular to the horizontal boundary line, and the horizontal boundary line difference value is an absolute value of a difference value between a pixel above and a pixel below the horizontal boundary line; and may include determining the 3D video to be the top and bottom format when the sum of ratios of horizontal boundary line difference values to the sums of upper horizontal boundary line difference values and lower horizontal boundary line difference values, is greater than a horizontal boundary line threshold.</p>
<p id="p-0029" num="0028">The detecting of the boundary line between the left-viewpoint video and the right-viewpoint video may include dividing the 3D video into two equal left and right regions, and calculating a ratio of a vertical boundary line difference value to the sum of a left vertical boundary line difference value and a lower vertical boundary line difference value, where the left horizontal boundary line difference value is an absolute value of a difference value between two adjacent pixels that are disposed perpendicular to the left of a vertical boundary line between the left and right regions, the right horizontal boundary difference value is an absolute value of a difference value between two adjacent pixels that are disposed perpendicular to the right of the horizontal boundary line, and the horizontal boundary line difference value is an absolute value of a difference value between pixels that are disposed to the left and right of the vertical boundary line respectively; and may include determining the 3D video to be the side by side format when the sum of ratios of vertical boundary line difference values to the sums of left horizontal boundary line difference values and right horizontal boundary line difference values, is greater than a vertical boundary line threshold.</p>
<p id="p-0030" num="0029">The detecting of the boundary line may include determining the 3D video format of the 3D video except for the boundary region when the 3D video has a boundary region that includes at least a predetermined number of black lines with respect to the boundary line.</p>
<p id="p-0031" num="0030">If from among a plurality of frames of the 3D video, 3D video format of first frames is determined to be a first format, 3D video format of second frames is determined to be a second format, and 3D video formats of the remaining frames are determined to be the first format, then the determining of the 3D video format may include changing the 3D video format of the second frames from the second format to the first format, based on the total number of the predetermined number of frames, the 3D video formats of which are determined to be the second format.</p>
<p id="p-0032" num="0031">The changing of the 3D video formats of the predetermined number of frames may include checking whether a predetermined number of further frames are determined to have the second format after the second frames are determined to have the second format; and changing the 3D video formats of the second frames to be the first format, and finally determining the remaining frames to have the second format.</p>
<p id="p-0033" num="0032">The method may further include searching an Internet website for 3D video content by using the 3D video format as a keyword, where the receiving of the video sequence includes receiving 3D video content searched for in the web.</p>
<p id="p-0034" num="0033">The searching of the web for 3D video content may include searching for video content that is a mixture of 2D video and the 3D video. The receiving of the video sequence may include receiving video content searched for in the web. The transforming of the left-viewpoint video and the right-viewpoint video of the 3D video into a format may include transforming the left-viewpoint video and the right-viewpoint video into a format so that they are reproduced three-dimensionally, based on the 3D video format that is the keyword. The method may further include reproducing the 2D video of the video sequence two-dimensionally, and reproducing the 3D video three-dimensionally in the format into which the 3D video was transformed.</p>
<p id="p-0035" num="0034">Location information of the 3D video may be transmitted from a provider of the 3D video content to a web browser. The web browser may estimate at least one of disparity information and correlation information between neighboring pixel values, determine a 3D video format of the 3D video, transforms the 3D video in a format so that the 3D video is reproduced three-dimensionally, and then reproduce the 3D video three-dimensionally.</p>
<p id="p-0036" num="0035">The method may further include detecting location of the 3D video in the 3D video content, wherein the detecting is performed by a 3D display device. The 3D display device may reproduce the transformed 3D video three-dimensionally at the location of the 3D video.</p>
<p id="p-0037" num="0036">According to an aspect of another exemplary embodiment, there is provided an apparatus for transforming a format of 3D video, the apparatus including a video input unit receiving a video sequence including 3D video that has left-viewpoint video and right-viewpoint video; a format determination unit estimating at least one of disparity information between the left-viewpoint video and the right-viewpoint video and correlation information between neighboring pixel values of the left-viewpoint video and the right-viewpoint video, and determining a 3D video format of the 3D video based on the result of estimation, where the 3D video format represents a manner in which the left-viewpoint video and the right-viewpoint video are arranged in the 3D video; a format transform unit transforming the left-viewpoint video and the right-viewpoint video into a format, based on the 3D video format, so that the left-viewpoint video and the right-viewpoint video are displayed three-dimensionally in a display device; and a display unit displaying the transformed left-viewpoint video and right-viewpoint video three-dimensionally in the display device.</p>
<p id="p-0038" num="0037">According to an aspect of another exemplary embodiment, there is provided a non-transitory computer-readable recording medium having recorded thereon a computer program for executing the method of transforming a format of 3D video.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0039" num="0038">The above and other aspects will become more apparent by describing in certain exemplary embodiments thereof with reference to the accompanying drawings, in which:</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a 3D video format transforming apparatus, according to an exemplary embodiment;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a system that encodes/decodes 3D video, according to an exemplary embodiment;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a system that generates and encodes/decodes 3D video, according to an exemplary embodiment;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 4</figref> illustrates various 3D video formats of 3D video, according to an exemplary embodiment;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram illustrating in detail the construction of a format determination unit included in the 3D video format transforming apparatus of <figref idref="DRAWINGS">FIG. 1</figref>, according to an exemplary embodiment;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 6A</figref> is a diagram illustrating a method of estimating disparity information between left and right regions of 3D video, according to an exemplary embodiment;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 6B</figref> is a diagram illustrating a method of estimating disparity information between upper and lower regions of 3D video, according to an exemplary embodiment;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 6C</figref> is a diagram illustrating a method of estimating disparity information regarding horizontal lines of 3D video, according to an exemplary embodiment;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 6D</figref> is a diagram illustrating a method of estimating disparity information regarding vertical lines of 3D video, according to an exemplary embodiment;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 7A</figref> is a graph illustrating a method of estimating a disparity section in 3D video, according to an exemplary embodiment;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 7B</figref> is a flowchart illustrating a method of estimating disparity information, according to an exemplary embodiment;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 8A</figref> illustrates a method of estimating correlation information between horizontal pixel values, according to an exemplary embodiment;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 8B</figref> illustrates a method of estimating correlation information between vertical pixel values, according to an exemplary embodiment;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 9</figref> is a table showing results of determining a 3D video format based on correlation information between neighboring pixels, according to an exemplary embodiment;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 10A</figref> illustrates 3D video having a top and bottom format, according to an exemplary embodiment;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 10B</figref> illustrates a part of a boundary line between an upper region and a lower region of the 3D video of <figref idref="DRAWINGS">FIG. 10A</figref> in more detail, according to an exemplary embodiment;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 11A</figref> illustrates 3D video having a side by side format, according to an exemplary embodiment;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 11B</figref> illustrates a part of a boundary line between a left region and a right region of the 3D video of <figref idref="DRAWINGS">FIG. 11A</figref> in more detail, according to an exemplary embodiment;</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 12A</figref> illustrates 3D video that has a boundary region and the side by side format, according to an exemplary embodiment;</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 12B</figref> illustrates a part of the boundary region of the 3D video of <figref idref="DRAWINGS">FIG. 12A</figref> in more detail, according to an exemplary embodiment;</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 13A</figref> is a graph showing average values of the differences between pixel values of continuous frames of 2D video on the time axis, according to an exemplary embodiment;</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 13B</figref> is a graph showing average values of the differences between pixel values of continuous frames of 3D video having the frame sequential format on the time axis, according to an exemplary embodiment;</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 14</figref> illustrates a method of determining whether a 3D video format is a frame sequential format by using three continuous frames on the time axis, according to an exemplary embodiment;</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. 15</figref> illustrates a case where an error occurs when a 3D video format is determined;</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 16</figref> illustrates a method of correcting an error occurring when a 3D video format is determined, according to an exemplary embodiment;</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 17</figref> is a block diagram illustrating post-processing involving format transformation and 3D displaying, according to an exemplary embodiment;</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. 18</figref> is a flowchart illustrating a method of transforming a 3D video format, according to an exemplary embodiment;</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 19A</figref> illustrates a method of searching an Internet website for 3D video content having a 3D video format, according to an exemplary embodiment; and</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 19B</figref> illustrates a method of reproducing 3D video content having a 3D video format in a web, according to an exemplary embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0069" num="0068">Certain exemplary embodiments are described in greater detail below with reference to the accompanying drawings.</p>
<p id="p-0070" num="0069">In the following description, like drawing reference numerals are used for the like elements, even in different drawings. The matters defined in the description, such as detailed construction and elements, are provided to assist in a comprehensive understanding of exemplary embodiments. However, exemplary embodiments can be practiced without those specifically defined matters.</p>
<p id="p-0071" num="0070">Hereinafter, various exemplary embodiments for transforming the format of 3D video will be described in detail with reference to <figref idref="DRAWINGS">FIGS. 1 through 19</figref>.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a 3D video format transforming apparatus <b>100</b>, according to an exemplary embodiment. Referring to <figref idref="DRAWINGS">FIG. 1</figref>, the 3D video format transforming apparatus <b>100</b> includes a video input unit <b>110</b>, a format determination unit <b>120</b>, a format transform unit <b>130</b>, and a display unit <b>140</b>.</p>
<p id="p-0073" num="0072">A sequence of video input via the video input unit <b>110</b> includes 3D video containing left-viewpoint video and right-viewpoint video. The input video may be 2D video, 3D video, or mixed video of 2D video and 3D video. In the mixed video, 2D video sections and 3D video sections may be mixed according to time or space.</p>
<p id="p-0074" num="0073">For example, the left-viewpoint video and the right-viewpoint video may be arranged in one frame of 3D video so that the 3D video frame can include information regarding the left-viewpoint video and the right-viewpoint video. Alternatively, a 3D video sequence may be generated by alternately repeating a left-viewpoint video frame and a right-viewpoint video frame or by alternately repeating a left-viewpoint video field and a right-viewpoint video field. Hereinafter, a manner in which the left-viewpoint video and the right-viewpoint video are arranged in the 3D video will be referred to as a &#x201c;3D video format&#x201d;.</p>
<p id="p-0075" num="0074">The format determination unit <b>120</b> analyzes the 3D video contained in the input video and determines the 3D video format. The format determination unit <b>120</b> analyzes the 3D video, and estimates at least one of disparity information regarding the 3D video or correlation information between the values of neighboring pixels of the 3D video. The format determination unit <b>120</b> determines the 3D video format based on the estimated disparity information and/or the estimated correlation information. If the input video is 2D video, the 3D video format is not determined.</p>
<p id="p-0076" num="0075">According to an exemplary embodiment, the format determination unit <b>120</b> may determine whether the 3D video format is a side by side format, a top and bottom format, a horizontal line interleaved format, a vertical line interleaved format, or a checker board format, based on either the disparity information between the left-viewpoint video and the right-viewpoint video contained in the 3D video or the correlation information. Alternatively, the format determination unit <b>120</b> may determine whether the 3D video format is a field sequential format or a frame sequential format, based on the disparity information regarding each field or frame of the 3D video. The format determination unit <b>120</b> may estimate the disparity information and the correlation information in a parallel manner to determine the 3D video format. Alternatively, the format determination unit <b>120</b> may estimate only the disparity information or the correlation information to determine the 3D video format.</p>
<p id="p-0077" num="0076">For example, the format determination unit <b>120</b> may determine whether the 3D video format is the side by side format, the top and bottom format, the horizontal line interleaved format, or the vertical line interleaved format, based on the disparity information regarding the left-viewpoint video and the right-viewpoint video. Also, the format determination unit <b>120</b> may determine whether the 3D video format is the horizontal line interleaved format, the vertical line interleaved format, or the checker board format by using the correlation information between the values of the neighboring pixels of the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0078" num="0077">The format determination unit <b>120</b> may detect and use a boundary line between the left-viewpoint video and the right-viewpoint video to improve the performance for determining whether the 3D video format is the side by side format or the top and bottom format.</p>
<p id="p-0079" num="0078">The disparity information or the correlation information may not be correctly estimated in a flat and spacious image region having no texture. Thus, the format determination unit <b>120</b> may calculate the smoothness of corresponding regions of the left-viewpoint video and the right-viewpoint video and detect a region of the 3D video having texture, the 3D video format of which is to be determined.</p>
<p id="p-0080" num="0079">The format determination unit <b>120</b> may estimate the disparity information by estimating information related to a disparity between upper and lower regions of the 3D video from a difference value between the upper and lower regions and by estimating information related to a disparity between left and right regions of the 3D video based on an absolute value of the difference between the left and right regions.</p>
<p id="p-0081" num="0080">The format determination unit <b>120</b> may determine whether the 3D video format is the top and bottom format or the side by side format, based on the estimated information related to the disparity between the upper and lower regions or between the left and right regions.</p>
<p id="p-0082" num="0081">Alternatively, the format determination unit <b>120</b> may estimate the disparity information by estimating information related to a disparity between vertical lines of the 3D video from a vertical line differential image that represents an absolute value of the difference between an odd-numbered vertical line and an even-numbered vertical line of the 3D video and by estimating information related to a disparity between horizontal lines of the 3D video from a horizontal line differential image that represents an absolute value of the difference between an odd-numbered horizontal line and an even-numbered horizontal line of the 3D video.</p>
<p id="p-0083" num="0082">The format determination unit <b>120</b> may determine whether the 3D video format is the horizontal line interleaved format or the vertical line interleaved format, based on the estimated information regarding a disparity between the horizontal lines, and the information related to a disparity between the vertical lines.</p>
<p id="p-0084" num="0083">The information related to a disparity between the upper and lower regions, the information related to a disparity between the left and right regions, the information related to a disparity between vertical lines and the information related to a disparity between horizontal lines, may include an estimated disparity, a maximum threshold of a disparity section, the total number of candidate disparity sections, etc.</p>
<p id="p-0085" num="0084">The format determination unit <b>120</b> may estimate the correlation information by estimating the correlation information between the vertical pixel values of first, second, and third pixels of the 3D video, which are consecutive in the vertical direction, and by estimating correlation information between horizontal pixel values of three (first, second, and third) pixels of the 3D video, which are consecutive in the horizontal direction. The format determination unit <b>120</b> may determine whether the 3D video format is the vertical line interleaved format, the horizontal line interleaved format, or the checker board format by comparing the correlation information between the vertical pixel values with a correlation threshold between the vertical pixel values and comparing the correlation information between the horizontal pixel values with a correlation threshold between the horizontal pixel values.</p>
<p id="p-0086" num="0085">If an absolute value of the difference between the first and third pixels of three consecutive pixels is a first difference value, an absolute value of the difference between the first and second pixel values is a second difference value, and an absolute value of the difference between the second and third pixel values is a third difference value, then the correlation information between the vertical pixel values or the horizontal pixel values may be a ratio of the sum of the second and third difference values and the first difference value.</p>
<p id="p-0087" num="0086">The format determination unit <b>120</b> may estimate a variation of a temporal disparity by using a first differential frame that represents an absolute value of the difference between first and third frames of three frames that are consecutive on the time axis, a second differential frame that represents an absolute value of the difference between the first and second frames, and a third differential frame that represents an absolute value of the difference between the second and third frames. In this case, the disparity information between the first, second, and third frames is a ratio of the sum of data of the second and third differential frames and data of the first differential frame.</p>
<p id="p-0088" num="0087">The format determination unit <b>120</b> may determine whether 3D video format is the frame sequential format according to the estimated variation of the temporal disparity. Similarly, it is possible to determine whether the 3D video format is the field sequential format.</p>
<p id="p-0089" num="0088">The format determination unit <b>120</b> may determine whether the 3D video format is the top and bottom format by using a ratio of difference values between adjacent pixels perpendicular to a horizontal boundary line between the upper and lower regions of the 3D video.</p>
<p id="p-0090" num="0089">Also, the format determination unit <b>120</b> may determine whether the 3D video format is the side by side format by using a ratio of difference values between adjacent pixels perpendicular to a vertical boundary line between the left and right regions of the 3D video. In this case, the correlation between the values of adjacent pixels of a region that is estimated in an image region other than the region around the vertical boundary line may be used.</p>
<p id="p-0091" num="0090">If the format determination unit <b>120</b> determines that a first group of consecutive frames has a first format, a second group pf predetermined number of subsequent frames has a second format, and a third group of other remaining subsequent frames after the second group have the first format, then the format determination unit <b>120</b> may finally determine all of the frames to have the first format, thereby preventing a sudden change in the 3D video format from causing an error or from degrading a stereoscopic effect.</p>
<p id="p-0092" num="0091">If the format determination unit <b>120</b> determines that a first group of frames has a first format, a number of frames of the second group greater than a predetermined number has a second format, and the frames of the third group also have the second format, the format determination unit <b>120</b> may finally determine the frames of the first and second groups to have the first format and the frames of the third group to have the second format.</p>
<p id="p-0093" num="0092">That is, if determination results of the first and second groups are switched from the first format to the second format and then at least a predetermined number of frames of the third group keeps having the second format, the format determination unit <b>120</b> may finally determine the frames of the third group to have the second format based on observation of 3D video format of the second group.</p>
<p id="p-0094" num="0093">The format transform unit <b>130</b> separates the left-viewpoint video and the right-viewpoint video which are 2D video from the 3D video, and transforms the formats of the left-viewpoint video and the right-viewpoint video so that they can be reconstructed three-dimensionally by the display unit <b>140</b>.</p>
<p id="p-0095" num="0094">For example, if the 3D video has the frame sequential format or the field sequential format, the format transform unit <b>130</b> transmits the left-viewpoint video and the right-viewpoint video to the display unit <b>140</b> without restoring the resolutions thereof so that the left-viewpoint video and the right-viewpoint video can be synchronized with each other.</p>
<p id="p-0096" num="0095">If the 3D video has the side by side format, the top and bottom format, the vertical line interleaved format, the horizontal line interleaved format, or the checker board format, then the left-viewpoint video and the right-viewpoint video are recorded in one frame in a resolution that is a half full resolution. When the left-viewpoint video and the right-viewpoint video contained in the 3D video are not recorded in a full resolution, the format transform unit <b>130</b> may separate the left-viewpoint video and the right-viewpoint video from the 3D video and interpolate them so that they can be restored to the full resolution.</p>
<p id="p-0097" num="0096">If the input video is the 2D video, the format transform unit <b>130</b> does not need to perform such a resolution restoration process.</p>
<p id="p-0098" num="0097">The display unit <b>140</b> reconstructs a 3D video from the left-viewpoint video and the right-viewpoint video, the formats of which have been transformed.</p>
<p id="p-0099" num="0098">According to an exemplary embodiment, the 3D video format transforming apparatus <b>100</b> may obtain 3D video content from an Internet website. When a 3D video format is searched for by using a web browser, it is possible to detect 3D video content in the 3D video format, which is shared through a website. According to an exemplary embodiment, the 3D video format transforming apparatus <b>100</b> may be connected to the web, and may thus receive the 3D video content detected on the web and transform the 3D format of the 3D video content by using the format transform unit <b>130</b> so that the 3D video content may be displayed three dimensionally. If the 3D video format of the 3D video content is not known, the 3D video format may be determined using the format determination unit <b>120</b>.</p>
<p id="p-0100" num="0099">According to an exemplary embodiment, the 3D video format transforming apparatus <b>100</b> may display the 3D video content, which is obtained from an Internet website, on a web browser. When the 2D video content and 3D video content are displayed in a web page window on the web browser, the 3D video format transforming apparatus <b>100</b> may display the 2D video content two dimensionally and display the 3D video content three dimensionally.</p>
<p id="p-0101" num="0100">The 3D video format transforming apparatus <b>100</b> may detect the location of 3D video content directly on a web page or may receive information regarding the location of the 3D video content from a web page provider.</p>
<p id="p-0102" num="0101">The 3D video format transforming apparatus <b>100</b> may provide a web browser with the information regarding 3D video format determined with respect to the 3D video content so that the 3D video content can be displayed three dimensionally in a window of the web browser.</p>
<p id="p-0103" num="0102">In an exemplary embodiment, the 3D video format transforming apparatus <b>100</b> may analyze 3D video and estimate the 3D video format thereof without having to obtain any additional information regarding the 3D video format. Accordingly, no additional storage space or transport channel is needed to transmit information regarding the 3D video format.</p>
<p id="p-0104" num="0103"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a system <b>200</b> that encodes/decodes 3D video according to an exemplary embodiment. The system <b>200</b> includes a transmitting terminal <b>228</b> having a Moving Picture Expert Group (MPEG) encoding unit <b>230</b> and a transmitting/recording unit <b>240</b>, and a receiving terminal <b>248</b> having a receiving/restoring unit <b>250</b> and an MPEG decoding unit <b>260</b>.</p>
<p id="p-0105" num="0104">In a vertical line interleaved format <b>201</b>, pixels in odd-numbered vertical lines <b>202</b> are data of the left-viewpoint video and pixels in even-numbered vertical lines <b>203</b> are data of the right-viewpoint video. In a horizontal line interleaved format <b>211</b>, the left-viewpoint video data and the right-viewpoint video data are alternately and repeatedly arranged in odd-numbered horizontal lines <b>212</b> and even-numbered horizontal lines <b>213</b>, respectively. In a field sequential format <b>221</b>, an odd-numbered field <b>222</b> and an even-numbered field <b>223</b> are stored as a left-viewpoint video field and a right-viewpoint video field, respectively.</p>
<p id="p-0106" num="0105">When the 3D video of the various 3D video formats <b>201</b>, <b>211</b>, and <b>221</b> is input to the MPEG encoding unit <b>230</b>, the 3D video is compressed and encoded according to an MPEG encoding/decoding method, and is either transmitted from the transmitting terminal <b>228</b> to the receiving terminal <b>248</b> via a network or is recorded on a recording medium (not shown) by the transmitting/recording unit <b>240</b>. In the receiving terminal <b>248</b>, the receiving/restoring unit <b>250</b> receives the encoded 3D video and the MPEG decoding unit <b>260</b> decodes it to produce the 3D video <b>270</b> according to the MPEG encoding/decoding method.</p>
<p id="p-0107" num="0106">A 3D video format of the 3D video <b>270</b> corresponds to the 3D video formats <b>201</b>, <b>211</b>, and <b>221</b> of the input 3D video received from the transmitting terminal <b>228</b>.</p>
<p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a system <b>300</b> that generates and encodes/decodes the 3D video, according to an exemplary embodiment. The system <b>300</b> includes a transmitting terminal having a stereoscopic video preprocessor <b>320</b>, an MPEG encoding unit <b>230</b>, a transmitting/recording unit <b>240</b>, and a receiving terminal having a receiving/restoring unit <b>250</b>, an MPEG decoding unit <b>260</b>, and a stereoscopic video post-processor <b>370</b>. The stereoscopic video preprocessor <b>320</b> includes a first pixel structure transform unit <b>322</b> and a frame-to-field transform unit <b>324</b>, and the stereoscopic video post-processor <b>370</b> includes a field-to-frame transform unit <b>374</b> and a second pixel structure transform unit <b>372</b>.</p>
<p id="p-0109" num="0108">The 3D video is a mixture of the left-viewpoint video and right-viewpoint video. Thus, when a left-viewpoint video signal <b>311</b> and a right-viewpoint video signal <b>312</b> are individually input to the stereoscopic video preprocessor <b>320</b>, the stereoscopic video preprocessor <b>320</b> generates a 3D video format by using the first pixel structure transform unit <b>322</b> and the frame-to-field transform unit <b>324</b> such that the left-viewpoint video and the right-viewpoint video are mixed in units of pixels within one frame or are mixed in units of frames or fields.</p>
<p id="p-0110" num="0109">The 3D video in the 3D video format generated by the stereoscopic video preprocessor <b>320</b> is compressed and encoded by the MPEG encoding unit <b>230</b> and is transmitted from the transmitting terminal to the receiving terminal or is recorded on a recording medium (not shown) by the transmitting/recording unit <b>240</b>.</p>
<p id="p-0111" num="0110">In the receiving terminal, the receiving/restoring unit <b>250</b> receives the encoded 3D video and the MPEG decoding unit <b>260</b> decodes it according to an MPEG encoding/decoding method to reconstruct the 3D video. The stereoscopic video post-processor <b>370</b> separates the left-viewpoint video and the right-viewpoint video from the 3D video by using the field-to-frame transform unit <b>374</b> and the second pixel structure transform unit <b>372</b>. Then, the left-viewpoint video and the right-viewpoint video are transformed into a left-viewpoint video signal <b>381</b> and a right-viewpoint video signal <b>382</b> to be displayed three dimensionally on a display device (not shown).</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 4</figref> illustrates various 3D video formats of 3D video, according to an exemplary embodiment. The 3D video can be displayed three dimensionally if a 3D video encoding/decoding system <b>200</b>, <b>300</b> appropriately separates the left-viewpoint video and right-viewpoint video from the 3D video. A 3D video format of the 3D video represents a manner in which the left-viewpoint video and right-viewpoint video are arranged in the 3D video.</p>
<p id="p-0113" num="0112">Examples of the 3D video formats include the side by side format, the top and bottom format, the horizontal line interleaved format, the vertical line interleaved format, a frame/field sequential format, and the checker board format.</p>
<p id="p-0114" num="0113">In the side by side format, the left-viewpoint video and the right-viewpoint video, which correspond to a left region <b>412</b> and a right region <b>414</b> of a 3D video frame <b>410</b>, respectively, are arranged in parallel horizontally. The order in which the left-viewpoint video and the right-viewpoint video are arranged may vary according to an initial setting to correspond to the left and right regions <b>412</b> and <b>414</b> or the right and left regions <b>414</b> and <b>412</b>, respectively. Thus, the correlation between the left and right regions <b>412</b> and <b>414</b> is high, and a high-frequency discontinuous line is present at a vertical boundary line <b>413</b> between the left and right regions <b>412</b> and <b>414</b>.</p>
<p id="p-0115" num="0114">In the side by side format, the capacity of memory needed to drive a system is small and existing recording media may be reused as a memory.</p>
<p id="p-0116" num="0115">In the top and bottom format, the left-viewpoint video and the right-viewpoint video, which correspond to an upper region <b>422</b> and a lower region <b>424</b> of a 3D video frame <b>420</b>, respectively, are arranged in parallel vertically. The order in which the left-viewpoint video and the right-viewpoint video are arranged may vary according to an initial setting to correspond to the upper and lower regions <b>422</b> and <b>424</b> or the lower and upper regions <b>424</b> and <b>422</b>, respectively. Thus, the correlation between the upper and lower regions <b>422</b> and <b>424</b> is high, and a high-frequency discontinuous line is present at a horizontal boundary line <b>423</b> between the upper and lower regions <b>422</b> and <b>424</b>.</p>
<p id="p-0117" num="0116">The top and bottom format allows existing recording media to be reused.</p>
<p id="p-0118" num="0117">In the horizontal line interleaved format, the left-viewpoint video and the right-viewpoint video, which correspond to odd-numbered horizontal lines <b>432</b> and even-numbered horizontal lines <b>434</b> of a 3D video frame <b>430</b>, respectively, are arranged in parallel horizontally. The order in which the left-viewpoint video and the right-viewpoint video are arranged may vary according to an initial setting to correspond to the odd-numbered horizontal lines <b>432</b> and the even-numbered horizontal lines <b>434</b> or the even-numbered horizontal lines <b>434</b> and the odd-numbered horizontal lines <b>432</b>, respectively. Thus, a high-frequency component is generated between adjacent horizontal lines in a region <b>433</b> where a disparity between the left-viewpoint video and the right-viewpoint video is large.</p>
<p id="p-0119" num="0118">The horizontal line interleaved format is a 3D video format optimized for interlaced scanning type stereoscopic display.</p>
<p id="p-0120" num="0119">In the vertical line interleaved format, the left-viewpoint video and the right-viewpoint video, which correspond to odd-numbered vertical lines <b>442</b> and even-numbered vertical lines <b>444</b> of a 3D video frame <b>440</b>, respectively, are arranged in parallel vertically. The order in which the left-viewpoint video and the right-viewpoint video are arranged may vary according to an initial setting to correspond to the odd-numbered vertical lines <b>442</b> and the even-numbered vertical lines <b>444</b> or the even-numbered vertical lines <b>444</b> and the even-numbered vertical lines <b>442</b>, respectively. Thus, a high-frequency component is generated between adjacent vertical lines in a region <b>443</b> in which a disparity between the left-viewpoint video and the right-viewpoint video is large.</p>
<p id="p-0121" num="0120">The vertical line interleaved format is a 3D video format optimized for a parallel barrier type stereoscopic display.</p>
<p id="p-0122" num="0121">In the frame/field sequential format, the left-viewpoint video and the right-viewpoint video, which correspond to odd-numbered frames/fields <b>452</b> and even-numbered frames/fields <b>454</b> of a 3D video frame/field sequence <b>450</b>, respectively, are arranged in parallel. The order in which the left-viewpoint video and the right-viewpoint video are arranged may vary according to an initial setting to correspond to the odd-numbered frames/fields <b>452</b> and the even-numbered frames/fields <b>454</b> or the even-numbered frames/fields <b>454</b> and the odd-numbered frames/fields <b>452</b>, respectively. Accordingly, in the frame/field sequential format, pixel values and a motion vector vary repeatedly in units of the frames or fields.</p>
<p id="p-0123" num="0122">In the frame sequential format, the resolution of 3D video can be maintained to be the same as that of a 2D video sequence.</p>
<p id="p-0124" num="0123">In the checker board format, the left-viewpoint video and the right-viewpoint video, which correspond to horizontal pixels <b>462</b> and <b>464</b> and vertical pixels <b>462</b> and <b>466</b>, respectively, are alternately arranged in units of pixels of a 3D video frame <b>460</b>. The order in which the left-viewpoint video and right-viewpoint video are arranged may vary according to an initial setting to correspond to horizontal/vertical first and second pixels or horizontal/vertical second and first pixels, respectively. Thus, in the checker board format, a high-frequency component is generated in an omni-direction.</p>
<p id="p-0125" num="0124">When interpolation is performed on the checker board format, the result of interpolation may be excellent.</p>
<p id="p-0126" num="0125"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram illustrating in detail the construction of the format determination unit <b>120</b> of the 3D video format transforming apparatus <b>100</b> of <figref idref="DRAWINGS">FIG. 1</figref>, according to an exemplary embodiment. According to an exemplary embodiment, the format determination unit <b>120</b> may perform a multi-step process to determine a 3D video format of an input video <b>510</b>. The block diagram <b>500</b> illustrates a case where both disparity information and correlation information between the values of adjacent pixels are used to determine whether the 3D video format is the side by side format, the top and bottom format, the vertical line interleaved format, the horizontal line interleaved format, the checker board format, or the frame sequential format.</p>
<p id="p-0127" num="0126">In the block diagram of <figref idref="DRAWINGS">FIG. 5</figref>, a disparity information estimation module <b>530</b> includes a side by side format check module <b>532</b> that estimates and uses information regarding a disparity between the left and right regions of the 3D video; a top and bottom format check module <b>534</b> that estimates and uses information regarding a disparity between the upper and lower regions of the 3D video; a vertical line interleaved format check module <b>536</b> that estimates and uses disparity information regarding a vertical line; and a horizontal line interleaved format check module <b>538</b> that estimates and uses disparity information regarding a horizontal line.</p>
<p id="p-0128" num="0127">A correlation information estimation module <b>540</b> includes a horizontal pixel value correlation check module <b>542</b> that estimates and uses correlation information between neighboring pixels in the horizontal direction, and a vertical pixel value correlation check module <b>544</b> that estimates and uses correlation information between neighboring pixels in the vertical direction.</p>
<p id="p-0129" num="0128">A boundary line detection module <b>550</b> detects a boundary line and includes a horizontal boundary line detecting module <b>552</b> and a vertical boundary line detecting module <b>554</b>.</p>
<p id="p-0130" num="0129">A frame sequence check module <b>570</b> includes a frame sequential format check module <b>572</b> that estimates and uses a variation in a temporal disparity between the frames. For an arithmetic operation of the frame sequence check module <b>570</b>, three or more consecutive frames are used, and thus, frames are input via two or more delayers <b>556</b> and <b>558</b> and two or more memories <b>560</b> and <b>565</b>.</p>
<p id="p-0131" num="0130">The disparity information and the correlation information may be used more effectively when the pixel values of the left-viewpoint video are different from the corresponding pixel values of the right-viewpoint video. For this reason, the performance of determining a 3D video format by using the disparity information or the correlation information may be reduced in a flat and spacious region. Thus, an effective line determination module <b>520</b> determines an effective line, the disparity information or the correlation information of which is to be calculated, based on the smoothness between the left-viewpoint video and the right-viewpoint video. A smoothness of a region may be calculated by using an amount of dispersion of the values of pixels of the region or by using various types of filters, such as a sobel operator.</p>
<p id="p-0132" num="0131">The effective line determination module <b>520</b> may provide information regarding the effective line to the disparity information estimation module <b>530</b>, the correlation information estimation module <b>540</b>, the boundary line detection module <b>550</b> and the frame sequence check module <b>570</b>, so that a 3D video format of the effective line can be determined.</p>
<p id="p-0133" num="0132">A plurality of comparators <b>535</b>, <b>539</b>, <b>545</b> and <b>555</b> compares results of checking the 3D video format with one another, and the result of checking, which shows the highest probability, is supplied to a final format determination module <b>580</b>. That is, the results of checking the 3D video format by estimating disparity information by the side by side format check module <b>532</b> and the top and bottom format check module <b>534</b> of the disparity information estimation module <b>530</b> are compared with each other by a comparator <b>535</b>, and the result of checking, which shows the highest probability, is supplied to the final format determination module <b>580</b>. The results of checking the 3D video format by estimating disparity information by the vertical line interleaved format check module <b>536</b> and the horizontal line interleaved format check module <b>538</b> of the disparity information estimation module <b>530</b> are compared with each other by a comparator <b>539</b>, and the result of checking, which shows the highest probability, is supplied to the final format determination module <b>580</b>.</p>
<p id="p-0134" num="0133">Also, the results of checking the 3D video format by estimating correlation information between neighboring pixels by the horizontal pixel value correlation check module <b>542</b> and the vertical pixel value correlation check module <b>544</b> of the correlation information estimation module <b>540</b> are compared with each other by a comparator <b>545</b>, and the result of checking, which shows the highest probability, is supplied to the final format determination module <b>580</b>. The results of checking the 3D video format by detecting a boundary line by the horizontal boundary line detection module <b>552</b> and the vertical boundary line detection module <b>554</b> of the boundary line detection module <b>550</b> are compared with each other by a comparator <b>555</b>, and the result of checking, which shows the highest probability, is supplied to the final format determination module <b>580</b>.</p>
<p id="p-0135" num="0134">Also, the result of checking the 3D video format by the frame sequential format check module <b>572</b> of the frame sequence check module <b>570</b> is supplied to the final format determination module <b>580</b>.</p>
<p id="p-0136" num="0135">The final format determination module <b>580</b> collects the result of checking whether the 3D video format is the side by side format or the top and bottom format, the result of checking whether the 3D video format is the vertical line interleaved format or the horizontal line interleaved format, the result of checking the correlation between horizontal pixel values and the correlation between vertical pixel values, the result of detecting a horizontal boundary line and a vertical boundary line, and the result of checking whether the 3D video format is the frame sequential format; compares the results with one another; and then finally determines the 3D video format. Information regarding the determined 3D video format is supplied to a 3D video format transform module <b>590</b>, and the 3D video is transformed into the formats such that the 3D video is displayed three-dimensionally on a display device (not shown).</p>
<p id="p-0137" num="0136">Also, when an error in information regarding the 3D video format, which was determined with respect to previous frames and is stored in a memory <b>585</b> via a delayer <b>592</b>, is observed, the information regarding the 3D video format may be more accurately determined by correcting this error.</p>
<p id="p-0138" num="0137">In the block diagram of <figref idref="DRAWINGS">FIG. 5</figref>, a 3D video format is determined in consideration of the disparity information, correlation information between neighboring pixel values, boundary lines, and the result of checking a frame sequence. However, in the 3D video format transforming apparatus <b>100</b> according to an exemplary embodiment, a 3D video format may be determined by using at least one piece of information selected from the group consisting of disparity information, correlation information between neighboring pixel values, boundary lines, and the result of checking a frame sequence based on a system design or a user setting.</p>
<p id="p-0139" num="0138">A method of determining a 3D video format based on the disparity information or the correlation information between neighboring pixel values will now be described in detail with reference to <figref idref="DRAWINGS">FIGS. 6A to 14</figref>. In detail, a method of estimating the disparity information, a method of checking whether a 3D video format is the side by side format or the top and bottom format, based on the disparity information, and a method of checking whether a 3D video format is the vertical line interleaved format or the horizontal line interleaved format based on the disparity information will be described in detail with reference to <figref idref="DRAWINGS">FIGS. 6A</figref>, <b>6</b>B, <b>6</b>C, <b>6</b>D, <b>7</b>A and <b>7</b>B. A method of estimating correlation information between neighboring pixels, a method of comparing the correlation between horizontal pixel values with the correlation between vertical pixel values, and a method of checking whether a 3D video format is the vertical line interleaved format, the horizontal line interleaved format, or the checker board format will be described in detail with reference to <figref idref="DRAWINGS">FIGS. 8A</figref>, <b>8</b>B, and <b>9</b>.</p>
<p id="p-0140" num="0139">Also, a method of detecting a boundary line, and a method of checking whether a 3D video format is the side by side format or the top and bottom format, based on the boundary line will be described in detail with reference to <figref idref="DRAWINGS">FIGS. 10A</figref>, <b>10</b>B, <b>11</b>A, <b>11</b>B, <b>12</b>A, and <b>12</b>B. A method of checking whether a 3D video format is the frame sequential format will be described in detail with reference to <figref idref="DRAWINGS">FIGS. 13A</figref>, <b>13</b>B, and <b>14</b>.</p>
<p id="p-0141" num="0140"><figref idref="DRAWINGS">FIG. 6A</figref> is a diagram illustrating a method of estimating the disparity information between the left and right regions of the 3D video, according to an exemplary embodiment.</p>
<p id="p-0142" num="0141">The format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> divides the 3D video frame into a left region and a right region, calculates the difference between the values of pixels of the left and right regions, and checks whether the difference corresponds to a disparity generated in the 3D video in the side by side format to determine whether a 3D video format of input video is the side by side format.</p>
<p id="p-0143" num="0142">Referring to <figref idref="DRAWINGS">FIG. 6A</figref>, if a 3D video frame <b>600</b> has the side by side format, a left region <b>602</b> and a right region <b>604</b> corresponds to the left-viewpoint video and right-viewpoint video, respectively. The left-viewpoint video and the right-viewpoint video contain video information of the same subject but they are slightly different from each other at the same location according to a viewpoint. Thus, a disparity of at least a predetermined amount may occur between pixels that correspond to the left-viewpoint video and the right-viewpoint video, respectively.</p>
<p id="p-0144" num="0143">A plurality of combinations <b>611</b>, <b>612</b>, <b>613</b>, <b>614</b> and <b>615</b>, between the left-viewpoint video pixels and the right-viewpoint video pixels that correspond to one another on a predetermined horizontal line <b>610</b> is present in the 3D video frame <b>600</b>. A disparity of at least a predetermined amount may occur in each of the combinations <b>611</b>, <b>612</b>, <b>613</b>, <b>614</b>, and <b>615</b>.</p>
<p id="p-0145" num="0144">A difference value between the left region <b>602</b> and the right region <b>604</b> of the 3D video frame <b>600</b> is calculated as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>I</i><sub>diff</sub>(<i>i,j</i>)=|<i>I</i>(<i>i,j</i>)&#x2212;<i>I</i>(<i>i,j+w/</i>2)|&#x2003;&#x2003;(1),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where (i,j) denotes the index of pixel location, I(i,j) denotes a pixel value of the 3D video frame <b>600</b>, w denotes the entire width of the 3D video frame <b>600</b>, and I<sub>diff</sub>(i,j) denotes a pixel value of an absolute differential image of the left and right regions <b>602</b> and <b>604</b> of the 3D video frame <b>600</b>. A disparity between the corresponding left-viewpoint video pixel and right-viewpoint video pixel may be estimated from the absolute differential image of the left and right regions <b>602</b> and <b>604</b>.
</p>
<p id="p-0146" num="0145">The format determination unit <b>120</b> calculates an absolute value of the difference between the values of pairs of the corresponding pixels of a left region and a right region at the same horizontal line of the input video. If the total number of pairs of the corresponding consecutive pixels having at least a predetermined absolute value is equal to or greater than a predetermined number, then a section in which the pairs of the corresponding consecutive pixels are present may be estimated to be a disparity section in which a disparity occurs.</p>
<p id="p-0147" num="0146">When a disparity section in 3D video, the format of which is not the side by side format, is estimated as described above, information of a left region of the 3D video is substantially different from that of a right region thereof, and thus, a disparity between the left and right regions is great. If information of a disparity section is less than a threshold, the 3D video format may be determined to be the side by side format, and if this information is equal to or greater than the threshold, the 3D video format may be determined not to be the side by side format.</p>
<p id="p-0148" num="0147"><figref idref="DRAWINGS">FIG. 6B</figref> is a diagram illustrating a method of estimating the disparity information between the upper and lower regions of 3D video, according to an exemplary embodiment.</p>
<p id="p-0149" num="0148">The format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> divides the 3D video frame into the upper and lower regions, calculates the difference between the values of pixels of the upper and lower regions, and determines whether a disparity between the upper and lower regions corresponds to a disparity occurring in the 3D video having the top and bottom format to determine whether the 3D video is the top and bottom format.</p>
<p id="p-0150" num="0149">In the 3D video having the top and bottom format, the upper and lower regions correspond to the left-viewpoint video and the right-viewpoint video. A disparity occurs in a pair of the corresponding left-viewpoint video pixel and right-viewpoint video pixel that are captured from the same location.</p>
<p id="p-0151" num="0150">Referring to <figref idref="DRAWINGS">FIG. 6B</figref>, in a 3D video frame <b>620</b> having the top and bottom format, an upper region <b>622</b> and a lower region <b>624</b> correspond to the left-viewpoint video and the right-viewpoint video, respectively. In the 3D video frame <b>620</b>, a plurality of combinations <b>631</b>, <b>633</b>, <b>635</b>, <b>637</b>, and <b>639</b> of the corresponding left-viewpoint video pixels and right-viewpoint video pixels at a predetermined vertical line <b>630</b> is present. A disparity of at least a predetermined amount may occur in each of the combinations <b>631</b>, <b>633</b>, <b>635</b>, <b>637</b>, and <b>639</b> of the corresponding left-viewpoint video pixels and right-viewpoint video pixels.</p>
<p id="p-0152" num="0151">A difference value between the upper and lower regions <b>622</b> and <b>624</b> of the 3D video frame <b>620</b> may be calculated as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>I</i><sub>diff</sub>(<i>i,j</i>)=|<i>I</i>(<i>i,j</i>)&#x2212;<i>I</i>(<i>i+h/</i>2<i>,j</i>)|&#x2003;&#x2003;(2),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where h denotes the entire height of the 3D video frame <b>620</b>, and I<sub>diff</sub>(i,j) denotes a pixel value of an absolute differential image between the upper and lower regions <b>622</b> and <b>624</b>. A disparity between pairs of the corresponding left-viewpoint video pixels and right-viewpoint video pixels may be estimated from the absolute differential image between the upper and lower regions <b>622</b> and <b>624</b>.
</p>
<p id="p-0153" num="0152">That is, the format determination unit <b>120</b> calculates an absolute value of the difference between pairs of the corresponding pixels of the upper and lower regions <b>622</b> and <b>624</b> at the same vertical line of the input video. If the total number of pairs of the corresponding consecutive pixels having at least a predetermined absolute value is equal to or greater than a predetermined number, a section in which the pairs of the corresponding consecutive pixels are present may be estimated to be a disparity section in which a disparity occurs.</p>
<p id="p-0154" num="0153">When a disparity section in the 3D video, the format of which is not the top and bottom format is determined as described above, information of an upper region of the 3D video is substantially different from that of a lower region thereof, and thus, a disparity between the upper and lower regions is great. If the information of the disparity section is less than a threshold, the 3D video format may be determined to be the top and bottom format, and if this information is equal to or greater than the threshold, the 3D video format may be determined not to be the top and bottom format.</p>
<p id="p-0155" num="0154"><figref idref="DRAWINGS">FIG. 6C</figref> is a diagram illustrating a method of estimating the disparity information regarding horizontal lines of 3D video, according to an exemplary embodiment.</p>
<p id="p-0156" num="0155">The format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> divides the input 3D video frame into portions in units of horizontal lines, estimates a disparity in the input 3D video on a basis of the horizontal lines, and checks whether the disparity corresponds to a disparity occurring in the 3D video having the horizontal line interleaved format to determine whether a 3D video format of the 3D video is the horizontal line interleaved format.</p>
<p id="p-0157" num="0156">In the 3D video having the horizontal line interleaved format, odd-numbered horizontal lines and even-numbered horizontal lines correspond to the left-viewpoint video data and the right-viewpoint video data, respectively.</p>
<p id="p-0158" num="0157">Referring to <figref idref="DRAWINGS">FIG. 6C</figref>, in an enlarged region <b>650</b> of consecutive horizontal lines of the 3D video frame <b>640</b> having the horizontal line interleaved format, an odd-numbered horizontal line <b>652</b> and an even-numbered horizontal line <b>654</b> correspond to the left-viewpoint video data and the right-viewpoint video data, respectively. In the 3D video frame <b>640</b>, a disparity of at least a predetermined amount may occur between the corresponding odd-numbered horizontal line <b>652</b> and even-numbered horizontal line <b>654</b>.</p>
<p id="p-0159" num="0158">A difference value between the odd-numbered horizontal line <b>652</b> and the even-numbered horizontal line <b>654</b> may be calculated as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>I</i><sub>diff</sub>(<i>i,j</i>)=|<i>I</i>(<i>i&#xd7;</i>2<i>,j</i>)&#x2212;<i>I</i>(<i>i&#xd7;</i>2+1<i>,j</i>)|&#x2003;&#x2003;(3),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where I<sub>diff</sub>(i,j) denotes a pixel value of an absolute differential image between the horizontal lines <b>652</b>, <b>654</b> of the 3D video frame <b>640</b>. A disparity between a pair of the corresponding left-viewpoint video horizontal line and the right-viewpoint video horizontal line may be estimated from the pixel value of the absolute differential image.
</p>
<p id="p-0160" num="0159">If an absolute value of the difference between an odd-numbered horizontal line and an even-numbered horizontal line of the input 3D video is equal to or greater than a predetermined value in a section having a plurality of consecutive horizontal lines, the format determination unit <b>120</b> may estimate this section to be a disparity section in which a disparity occurs in the horizontal line interleaved format.</p>
<p id="p-0161" num="0160">When a disparity section in the 3D video, the format of which is not the horizontal line interleaved format, is determined as described above, information of an odd-numbered horizontal line is substantially similar to that of an even-numbered horizontal line, and thus, a disparity between the odd-numbered horizontal line and the even-numbered horizontal line is small. If information regarding the disparity section is equal to or greater than a threshold, the 3D video format may be determined to be the horizontal line interleaved format, and if this information is less than the threshold, the 3D video format may be determined not to be the horizontal line interleaved format.</p>
<p id="p-0162" num="0161"><figref idref="DRAWINGS">FIG. 6D</figref> is a diagram illustrating a method of estimating the disparity information regarding vertical lines of the 3D video, according to an exemplary embodiment.</p>
<p id="p-0163" num="0162">The format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> divides the input 3D video frame into portions in units of vertical lines, estimates a disparity in the input 3D video on a basis of the vertical lines, and checks whether the disparity corresponds to a disparity occurring in the 3D video having the vertical line interleaved format to determine whether a 3D video format of the input 3D video is the vertical line interleaved format.</p>
<p id="p-0164" num="0163">In the 3D video having the vertical line interleaved format, odd-numbered vertical lines and even-numbered vertical lines correspond to the left-viewpoint video data and the right-viewpoint video data, respectively.</p>
<p id="p-0165" num="0164">Referring to <figref idref="DRAWINGS">FIG. 6D</figref>, in an enlarged region <b>670</b> of consecutive vertical lines of the 3D video frame <b>660</b> having the vertical line interleaved format, an odd-numbered vertical line <b>672</b> and an even-numbered vertical line <b>674</b> correspond to the left-viewpoint video data and the right-viewpoint video data, respectively. In the 3D video frame <b>660</b>, a disparity of at least a predetermined amount may occur between the corresponding odd-numbered vertical line <b>672</b> and the even-numbered vertical line <b>674</b>.</p>
<p id="p-0166" num="0165">A difference value between the odd-numbered vertical line <b>672</b> and the even-numbered vertical line <b>674</b> may be calculated as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>I</i><sub>diff</sub>(<i>i,j</i>)=|<i>I</i>(<i>i,j&#xd7;</i>2)&#x2212;<i>I</i>(<i>i,j&#xd7;</i>2+1)|&#x2003;&#x2003;(4),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where I<sub>diff</sub>(i,j) denotes a pixel value of an absolute differential image between the vertical lines <b>672</b>, <b>674</b> of the 3D video frame <b>660</b>. A disparity between the corresponding left-viewpoint video vertical line and right-viewpoint video vertical line may be estimated from the pixel value of the absolute differential image.
</p>
<p id="p-0167" num="0166">If an absolute value of the difference between an odd-numbered vertical line and an even-numbered vertical line of the input 3D video is equal to or greater than a predetermined value in a section having a plurality of consecutive vertical lines, the format determination unit <b>120</b> may estimate this section to be a disparity section in which a disparity occurs in the vertical line interleaved format.</p>
<p id="p-0168" num="0167">When a disparity section in the 3D video, the format of which is not the vertical line interleaved format is determined as described above, information of an odd-numbered vertical line is substantially similar to that of an even-numbered vertical line, and thus, a disparity between the odd-numbered vertical line and the even-numbered vertical line is small. If the information regarding the disparity section is equal to or greater than a threshold, the 3D video format may be determined to be the vertical line interleaved format, and if this information is less than the threshold, the 3D video format may be determined not to be the vertical line interleaved format.</p>
<p id="p-0169" num="0168"><figref idref="DRAWINGS">FIG. 7A</figref> is a graph <b>700</b> illustrating a method of estimating a disparity section in the 3D video, according to an exemplary embodiment.</p>
<p id="p-0170" num="0169">Here, the disparity section is a section of an absolute differential image between two regions being respectively estimated to be the left-viewpoint video and the right-viewpoint video, in which the differences between consecutive pixels are equal to or greater than a predetermined value. The width of the disparity section is related to the correlation between the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0171" num="0170">The graph <b>700</b> shows the difference values between the pairs of the corresponding pixels or lines of the left-viewpoint video and the right-viewpoint video. The horizontal axis of the graph <b>700</b> denotes the indexes of the pairs of the corresponding pixels or lines of the left-viewpoint video and the right-viewpoint video, and the vertical axis of the graph <b>700</b> denotes the difference values between positive and negative values with respect to 0.</p>
<p id="p-0172" num="0171">The difference values between the pairs of the corresponding pixels or lines of the left-viewpoint video and the right-viewpoint video may include sections <b>710</b>, <b>712</b>, <b>714</b>, and <b>716</b> in which a disparity occurs continuously. A part of each of the sections <b>712</b> and <b>716</b> in which a positive disparity occurs continuously, may be selected as a disparity section when the graph has values greater than an upper limit threshold H<sub>limit </sub><b>720</b> and has a width less than or equal to a maximum width <b>730</b>. For example, a part <b>722</b> of the section <b>712</b> in which a positive disparity occurs continuously, may be selected as a disparity section, since the part <b>722</b> has graph values greater than the upper limit threshold H<sub>limit </sub><b>720</b> and has a width less than or equal to the maximum width <b>730</b>. Likewise, a part of each of the sections <b>710</b> and <b>714</b> in which a negative disparity occurs continuously, may be selected as a disparity section when the part has graph values less than a lower limit threshold L<sub>limit </sub><b>725</b> and has a width less than or equal to the maximum width <b>730</b>.</p>
<p id="p-0173" num="0172">That is, a disparity between the left-viewpoint video and the right-viewpoint video is not calculated directly using a disparity estimation process but is estimated indirectly, based on the information regarding consecutive pixels or lines in which an absolute value of the difference value between the left-viewpoint video and the right-viewpoint video is large.</p>
<p id="p-0174" num="0173">A region corresponding to the left-viewpoint video may not be the same as a region corresponding to the right-viewpoint video because of inconsistencies in positions and the distances between the left-viewpoint and right-viewpoint cameras, etc. Thus, a disparity may be considered to occur between the left-viewpoint video and the right-viewpoint video only when the difference value between the left-viewpoint video and the right-viewpoint video is either greater than an upper limit threshold H<sub>limit </sub>or is less than a lower limit threshold L<sub>limit</sub>. Also, when a section in which a disparity occurs continuously has a width equal to or greater than a predetermined value, the section may be selected as a candidate disparity section. The total number of candidate disparity sections detected in the 3D video is counted.</p>
<p id="p-0175" num="0174">The total number of candidate disparity sections between the left and right regions of the 3D video may be compared with that of the candidate disparity sections between the upper and lower regions of the 3D video, and a 3D video format of the 3D video may be determined to be the side by side format or the top and bottom format according to the result of comparison.</p>
<p id="p-0176" num="0175">Also, the total number of the candidate disparity sections between an odd-numbered horizontal lines and the even-numbered horizontal lines of the 3D video may be compared with that of the candidate disparity sections between the odd-numbered vertical lines and the even-numbered vertical lines of the 3D video, and the 3D video format of the 3D video may be determined to be the horizontal line interleaved format or the vertical line interleaved format according to the result of the comparison.</p>
<p id="p-0177" num="0176"><figref idref="DRAWINGS">FIG. 7B</figref> is a flowchart illustrating a method of estimating the disparity information, according to an exemplary embodiment.</p>
<p id="p-0178" num="0177">In the method of <figref idref="DRAWINGS">FIG. 7B</figref>, the format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 2</figref> may count the total number of candidate disparity sections in the 3D video, and determine a 3D video format of the 3D video according to the total number.</p>
<p id="p-0179" num="0178">Specifically, referring to <figref idref="DRAWINGS">FIG. 7B</figref>, in operation <b>750</b>, the total number of continuous disparity sections in which a disparity occurs is counted with respect to a pixel value I<sub>diff</sub>(i, j) of the differential image between the left-viewpoint video and the right-viewpoint video of the 3D video.</p>
<p id="p-0180" num="0179">In operation <b>755</b>, an absolute value of the pixel value of the differential image between the left-viewpoint video and the right-viewpoint video is compared with a threshold TH<sub>valid</sub><sub><sub2>&#x2014;</sub2></sub><sub>diff </sub>(|I<sub>diff</sub>(i,j)|&#x3e;TH<sub>valid</sub><sub><sub2>&#x2014;</sub2></sub><sub>diff</sub>?). In operation <b>755</b>, the critical value TH<sub>valid</sub><sub><sub2>&#x2014;</sub2></sub><sub>diff </sub>corresponds to an absolute value of the upper limit threshold H<sub>limit </sub><b>720</b> or the lower limit threshold L<sub>limit </sub><b>725</b> illustrated in <figref idref="DRAWINGS">FIG. 7A</figref>. If the absolute value |I<sub>diff</sub>(i,j)| of the pixel value I<sub>diff</sub>(i, j) of the differential image is less than or equal to the critical value TH<sub>valid</sub><sub><sub2>&#x2014;</sub2></sub><sub>diff</sub>, then the width of the continuous disparity section is initialized in operation <b>775</b>, and the total number of disparity sections is counted with respect to a next pixel of the differential image in operation <b>750</b>.</p>
<p id="p-0181" num="0180">If it is determined in operation <b>755</b> that the absolute value |I<sub>diff</sub>(i, j)| is greater than the critical value TH<sub>valid</sub><sub><sub2>&#x2014;</sub2></sub><sub>diff</sub>, the width of the disparity section is increased in operation <b>760</b>.</p>
<p id="p-0182" num="0181">In operation <b>765</b>, the total number of disparities, i.e., the width of the disparity section, is compared with a maximum width of disparity section SR (a search range). If it is determined in operation <b>765</b> that the width of the disparity section is not greater than the maximum width of disparity section SR, then the disparity section is not selected as a candidate disparity section and the total number of disparity sections is counted with respect to a next pixel of the differential image in operation <b>750</b>.</p>
<p id="p-0183" num="0182">If it is determined in operation <b>765</b> that the width of continuous disparity section is greater than the maximum width of disparity section SR, the number of candidate disparity sections DRcount is increased in operation <b>770</b>. Then, the method returns back to operation <b>750</b>, and the total number of disparity sections is counted with respect to a next pixel of the differential image.</p>
<p id="p-0184" num="0183">When a 3D video format of the left and right regions or the upper and lower regions of the 3D video is determined, if the total number of candidate disparity sections DRcount of the left and right regions of the 3D video is less than a threshold TH<sub>SBS</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount</sub>, then the format determination unit <b>120</b> may determine the 3D video format to be the side by side format. Here, the threshold TH<sub>SBS</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount </sub>denotes a threshold of the total number of disparity sections, which is used to determine whether the 3D video format is the side by side format.</p>
<p id="p-0185" num="0184">Also, if the total number of candidate disparity sections DRcount of the upper and lower regions of the 3D video is less than a threshold TH<sub>TNB</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount</sub>, the format determination unit <b>120</b> may determine the 3D video format to be the top and bottom format. The threshold TH<sub>TNB</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount </sub>denotes a threshold of the total number of disparity sections, which is used to determine whether the 3D video format is the top and bottom format.</p>
<p id="p-0186" num="0185">When a 3D video format of consecutive lines of the 3D video is determined, if the total number of candidate disparity sections DRcount of the horizontal lines of the 3D video is greater than a threshold TH<sub>HOR</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount</sub>, the format determination unit <b>120</b> may determine the 3D video format to be the horizontal line interleaved format. The threshold TH<sub>HOR</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount </sub>denotes a threshold of the total number of candidate disparity sections, which is used to determine whether the 3D video format is the horizontal line interleaved format.</p>
<p id="p-0187" num="0186">If the total number of candidate disparity sections DRcount of the vertical lines of the 3D video is greater than a threshold TH<sub>VER</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount</sub>, the format determination unit <b>120</b> may determine the 3D video format to be the vertical line interleaved format. The threshold TH<sub>VER</sub><sub><sub2>&#x2014;</sub2></sub><sub>DRcount </sub>denotes a threshold of the total number of candidate disparity sections, which is used to determine whether the 3D video format is the vertical line interleaved format.</p>
<p id="p-0188" num="0187">When a 3D video format of the left and right regions or the upper and lower regions of the 3D video is determined, a large disparity section may be estimated to be a disparity between a plurality of pieces of video that are less correlated to each other. Thus, when the total number of candidate disparity sections is less than a threshold TH<sub>DRcount </sub>of the total number of disparity sections, it is highly probable that the 3D video format is the side by side format or the top and bottom format.</p>
<p id="p-0189" num="0188">However, since consecutive horizontal or vertical lines of the interleaved formats are mixed artificially in the left-viewpoint video and the right-viewpoint video, horizontal lines are greatly different from vertical lines. Thus, if the total number of candidate disparity sections is greater than the threshold TH<sub>DRcount </sub>of the total number of disparity sections when a 3D video format of a horizontal or vertical line of 3D video is determined, the 3D video format is highly probably the horizontal line interleaved format or the vertical line interleaved format.</p>
<p id="p-0190" num="0189"><figref idref="DRAWINGS">FIG. 8A</figref> illustrates a method of estimating the correlation information between the horizontal pixel values, according to an exemplary embodiment. <figref idref="DRAWINGS">FIG. 8B</figref> illustrates a method of estimating correlation information between the vertical pixel values, according to an exemplary embodiment.</p>
<p id="p-0191" num="0190">The format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> may determine a 3D video format of 3D video in which the left-viewpoint video and the right-viewpoint video are mixed together in units of pixels, based on the correlation between the values of the horizontal pixels and the correlation between the values of the vertical pixels.</p>
<p id="p-0192" num="0191">According to an exemplary embodiment, the format determination unit <b>120</b> may use the ratio of the differences between neighboring pixel values as the correlation information between neighboring pixel values. Thus, the ratio of the differences between the values of consecutive pixels arranged in the vertical direction may be used as the correlation information between the vertical pixel values, and the ratio of the differences between the values of consecutive pixels arranged in the horizontal direction may be used as the correlation information between the horizontal pixel values. Hereinafter, the ratio of the differences between the values of consecutive pixels arranged in the vertical direction will be referred to as &#x2018;a ratio of the differences between vertical pixel values&#x2019;, and the ratio of the differences between the values of consecutive pixels arranged in the horizontal direction will be referred to as &#x2018;a ratio of the differences between horizontal pixel values&#x2019;.</p>
<p id="p-0193" num="0192">Referring to <figref idref="DRAWINGS">FIG. 8A</figref>, the ratio of the differences between the horizontal pixels may be calculated from the ratio of the differences between the values of first, second, and third horizontal pixels selected from 3&#xd7;3 pixels <b>801</b>, <b>802</b>, <b>803</b>, <b>804</b>, <b>805</b>, <b>806</b>, <b>807</b>, <b>808</b>, and <b>809</b> of the 3D video frame. The ratio of the differences between the horizontal pixel values may be calculated as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Val</i><sub>hor</sub>(<i>i,j</i>)=(|<i>I</i>(<i>i&#x2212;</i>1<i>,j</i>)&#x2212;<i>I</i>(<i>i,j</i>)|+|<i>I</i>(<i>i,j</i>)&#x2212;<i>I</i>(<i>i+</i>1<i>,j</i>)|)/(|<i>I</i>(<i>i&#x2212;</i>1<i>,j</i>)&#x2212;<i>I</i>(<i>i+</i>1<i>,j</i>)|+<i>c</i>)&#x2003;&#x2003;(5),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where Val<sub>hor</sub>(i,j) denotes the ratio of the differences between the horizontal pixel values, and c denotes a constant value that prevents a denominator from being zero. Regarding the first, second, and third pixels <b>804</b>, <b>805</b>, and <b>806</b> that are arranged sequentially in parallel in the horizontal direction, an absolute value <b>810</b> of the difference between the left (first) pixel <b>804</b> and the right (third) pixel <b>806</b> corresponds to the first term of the denominator of Equation (5), an absolute value <b>820</b> of the difference between the left (first) pixel <b>804</b> and the center (second) pixel <b>805</b> corresponds to the first term of the numerator of Equation (5), and an absolute value <b>830</b> of the difference between the center (second) pixel <b>805</b> and the right (third) pixel <b>806</b> corresponds to the second term of the numerator of Equation (5).
</p>
<p id="p-0194" num="0193">That is, the ratio of the differences between the horizontal pixel values Val<sub>hor</sub>(i,j) is the ratio of the sum of the absolute value <b>820</b> of the difference between the first pixel <b>804</b> and the second pixel <b>805</b> and the absolute value <b>830</b> of the difference between the second pixel <b>805</b> and the third pixel <b>806</b> and the absolute value <b>810</b> of the difference between the first pixel <b>804</b> and the third pixel <b>806</b>.</p>
<p id="p-0195" num="0194">Referring to <figref idref="DRAWINGS">FIG. 8B</figref>, similarly, the ratio of the differences between the vertical pixel values may be calculated from the ratio of the differences between the values of three pixels that are arranged in parallel in the vertical direction. The ratio of the differences between the vertical pixel values may be calculated as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Val</i><sub>ver</sub>(<i>i,j</i>)=(|<i>I</i>(<i>i,j&#x2212;</i>1)&#x2212;<i>I</i>(<i>i,j</i>)|+|<i>I</i>(<i>i,j</i>)&#x2212;<i>I</i>(<i>i,j+</i>1)|)/(|<i>I</i>(<i>i,j&#x2212;</i>1)&#x2212;<i>I</i>(<i>i,j+</i>1)|+<i>c</i>)&#x2003;&#x2003;(6),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where Val<sub>ver</sub>(i,j) denotes the ratio of the differences between the vertical pixel values, and c denotes a constant value that prevents a denominator from being zero. Regarding fourth, fifth, and sixth pixels <b>802</b>, <b>805</b>, and <b>808</b> that are arranged sequentially in parallel in the vertical direction, an absolute value <b>840</b> of the difference between the upper (fourth) pixel <b>802</b> and the lower (sixth) pixel <b>808</b> corresponds to the first term of the denominator of Equation (6), an absolute value <b>850</b> of the difference between the upper (fourth) pixel <b>802</b> and the middle (fifth) pixel <b>805</b> corresponds to the first term of the numerator of Equation (6), and an absolute value <b>860</b> of the difference between the middle (fifth) pixel <b>805</b> and the lower (sixth) pixel <b>808</b> corresponds to the second term of the numerator of Equation (6).
</p>
<p id="p-0196" num="0195">That is, the ratio Val<sub>ver</sub>(i,j) of the differences between the vertical pixel values is the ratio of the sum of the absolute value <b>850</b> of the difference between the fourth pixel <b>802</b> and the fifth pixel <b>805</b> and the absolute value <b>860</b> of the difference between the fifth pixel <b>805</b> and the sixth pixel <b>808</b> and the absolute value <b>840</b> of the difference between the fourth pixel <b>802</b> and the sixth pixel <b>808</b>.</p>
<p id="p-0197" num="0196">If Equations (5) and (6) are used, the format determination unit <b>120</b> may calculate the ratio Val<sub>hor </sub>of the differences between the horizontal pixel values and the ratio Val<sub>ver </sub>of the differences between the vertical pixel values with respect to the 2D video, thereby preventing the 2D video from being erroneously determined to be the 3D video at a boundary line of the 2D video when a 3D video format is determined. When Equations (5) and (6) are applied to a boundary line of the video, a numerator has a large value but a denominator also has a large value. Accordingly, the ratio Val<sub>hor </sub>of the differences between the horizontal pixel values and the ratio Val<sub>ver </sub>of the differences between the vertical pixel values at a boundary line of the 2D video are no more greater than those of the other parts of the 2D video.</p>
<p id="p-0198" num="0197">Since the 3D video includes pixels each corresponding to the left-viewpoint video or the right-viewpoint video, the denominator terms of Equations (5) and (6) correspond to an absolute difference value between the pixels of the video captured from the same viewpoint and thus have a small value. However, the numerator terms thereof correspond to absolute difference values between the pixels of a plurality of pieces of the video captured from different viewpoints and have values greater than the value of the denominator terms. Thus, the ratio of the differences between the horizontal pixel values given in Equation (5) and the ratio of the differences between the vertical pixel values given in Equation (6) have a large value when the 3D video has a 3D video format in which the left-viewpoint video data and the right-viewpoint video data are alternately repeated in units of pixels.</p>
<p id="p-0199" num="0198"><figref idref="DRAWINGS">FIG. 9</figref> is a table showing results of determining a 3D video format based on correlation information between the neighboring pixels, according to an exemplary embodiment.</p>
<p id="p-0200" num="0199">The format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> may calculate, as the correlation information between the neighboring pixel values, the ratios of the differences between the horizontal pixel values and the ratios of the differences between the vertical pixel values with respect to the entire or a part of input video, and may count the ratios of the differences between the horizontal pixel values and the ratios of the differences between the vertical pixel values that are greater than a threshold of the ratio of the differences between the pixel values. The format determination unit <b>120</b> may compare the count results and may determine a 3D video format of the input video to be the horizontal line interleaved format, the vertical line interleaved format, or the checker board format.</p>
<p id="p-0201" num="0200">Specifically, if the total number of the ratios of the differences between the horizontal pixel values that are greater than the threshold of the differences between pixel values is Num<sub>hor</sub>(i, j), the total number of the ratios of the differences between the vertical pixel values that are greater than the threshold of the differences between the pixel values is Num<sub>ver</sub>(i, j), and a predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count </sub>is given, then the count results show Cases 1, 2, and 3 as follows:</p>
<p id="p-0202" num="0201">Case 1: The total number Num<sub>hor</sub>(i, j) of the ratios of the differences between the horizontal pixel values that are greater than the threshold of the differences between the pixel values is greater than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count </sub>(Num<sub>hor</sub>(i, j)&#x3e;TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>), and the total number Num<sub>ver</sub>(i, j) of the ratios of the differences between the vertical pixel values that are greater than the threshold of the differences between the pixel values is less than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count </sub>(Num<sub>ver</sub>(i, j)&#x3c;TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>).</p>
<p id="p-0203" num="0202">Case 2: The total number Num<sub>hor</sub>(i, j) of the ratios of the differences between the horizontal pixel values that are greater than the threshold of the differences between the pixel values is less than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count </sub>(Num<sub>hor</sub>(i, j)&#x3c;TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>), and the total number Num<sub>ver</sub>(i, j) of the ratios of the differences between the vertical pixel values that are greater than the threshold of the differences between the pixel values is greater than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count </sub>(Num<sub>ver</sub>(i, j)&#x3e;TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>).</p>
<p id="p-0204" num="0203">Case 3: The total number Num<sub>hor</sub>(i,j) of the ratios of the differences between the horizontal pixel values and the total number Num<sub>ver</sub>(i, j) of the ratios of the differences between the vertical pixel values, which are greater than the threshold of the differences between the pixel values, are greater than the predetermined threshold (Num<sub>hor</sub>(i, j)&#x3e;TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>, Num<sub>ver</sub>(i,j)&#x3e;TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>).</p>
<p id="p-0205" num="0204">If the total number Num<sub>hor</sub>(i, j) of the ratios of the differences between the horizontal pixel values that are greater than the threshold of the differences between the pixel values is less than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>, then the correlation between the pixels on the horizontal lines may be determined to be high. If the total number Num<sub>ver</sub>(i, j) of the ratios of the differences between the vertical pixel values that are greater than the threshold of the differences between the pixel values is less than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>, then the correlation between the pixels on the vertical lines may be determined to be high. It is possible to estimate whether the horizontal or vertical lines correspond to the left-viewpoint video and the right-viewpoint video of the 3D video, respectively, according to the correlations between the pixels on the horizontal lines and between the pixels on the vertical lines.</p>
<p id="p-0206" num="0205">Accordingly, the format determination unit <b>120</b> may calculate the ratios of the differences between the horizontal pixel values and the ratios of the differences between the vertical pixel values of the input video, and may determine whether the input video is the 3D video and determine a 3D video format of the input video according to the calculated ratios.</p>
<p id="p-0207" num="0206">When the total number Num<sub>hor</sub>(i, j) of the ratios of the differences between the horizontal pixel values that are greater than the threshold of the differences between the pixel values is greater than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count </sub>(Case 1), the format determination unit <b>120</b> may determine that the correlation between the pixels on the horizontal lines is low and the correlation between the pixels on the vertical lines is high. It is possible to estimate whether the vertical lines correspond to the left-viewpoint video and the right-viewpoint video of the 3D video according to the high correlation between pixels thereon. Accordingly, the format determination unit <b>120</b> determines the 3D video format of the input video to be the vertical line interleaved format.</p>
<p id="p-0208" num="0207">When the total number Num<sub>ver</sub>(i,j) of the ratios of the differences between the vertical pixel values that are greater than the threshold of the differences between the pixel values is greater than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count </sub>(Case 2), the format determination unit <b>120</b> may determine that the correlation between the pixels on the horizontal lines is high and the correlation between the pixels on the vertical lines is low. It is possible to estimate whether the horizontal lines correspond to the left-viewpoint video and right-viewpoint video of the 3D video according to the high correlation between the pixels thereon. Accordingly, the format determination unit <b>120</b> determines the 3D video format of the input video to be the horizontal line interleaved format.</p>
<p id="p-0209" num="0208">When both the total number Num<sub>hor</sub>(i, j) of the ratios of the differences between the horizontal pixel values and the total number Num<sub>ver</sub>(i, j) of the ratios of the differences between the vertical pixel values that are greater than the threshold of the differences between the pixel values are greater than the predetermined threshold TH<sub>pel</sub><sub><sub2>&#x2014;</sub2></sub><sub>count</sub>(Case 3), the format determination unit <b>120</b> may determine that the correlations between the pixels on the horizontal lines and between the pixels on the vertical lines are low. Accordingly, the format determination unit <b>120</b> determines the 3D video format of the input video to be the checker board format.</p>
<p id="p-0210" num="0209">In the current exemplary embodiment, the format determination unit <b>120</b> uses the ratios of the differences between the neighboring pixel values as an example of the correlation information between the neighboring pixels but a method of determining the correlation between neighboring pixels of a target pixel of input video according to the inventive concept is not limited thereto. Various factors, such as the ratio of, a variation in, a dispersion of, or a standard deviation of pixel values, may be used to determine the correlation between the neighboring pixels.</p>
<p id="p-0211" num="0210"><figref idref="DRAWINGS">FIG. 10A</figref> illustrates a 3D video frame <b>1000</b> having the top and bottom format, according to an exemplary embodiment. <figref idref="DRAWINGS">FIG. 10B</figref> illustrates a portion <b>1040</b> surrounding a boundary line <b>1030</b> between an upper region <b>1010</b> and a lower region <b>1020</b> of the 3D video frame <b>1000</b> in more detail, according to an exemplary embodiment.</p>
<p id="p-0212" num="0211">In the 3D video frame <b>1000</b> having the top and bottom format, the upper region <b>1010</b> and the lower region <b>1020</b> may include the left-viewpoint video and the right-viewpoint video, respectively. In this case, a line of discontinuity occurs at the horizontal boundary line <b>1030</b> between the upper region <b>1010</b> and the lower region <b>1020</b>.</p>
<p id="p-0213" num="0212">Referring to <figref idref="DRAWINGS">FIG. 10B</figref>, in the portion <b>1040</b> around the boundary line <b>1030</b>, horizontal lines <b>1012</b> and <b>1014</b> are disposed in the upper region <b>1010</b> and horizontal lines <b>1022</b> and <b>1024</b> are disposed in the lower region <b>1020</b>. In the 3D video frame <b>1000</b>, the horizontal lines <b>1012</b> and <b>1014</b> include video data obtained from the same viewpoint, and the horizontal lines <b>1022</b> and <b>1024</b> include video data obtained from the same viewpoint. However, the horizontal lines <b>1012</b> and <b>1022</b> adjacent to the boundary line <b>1030</b> have video data obtained from different viewpoints. Two adjacent pixels <b>1052</b> and <b>1054</b> are disposed perpendicular to an upper part of the horizontal boundary line <b>1030</b>, and two adjacent pixels <b>1072</b> and <b>1074</b> are disposed perpendicular to a lower part of the horizontal boundary line <b>1030</b>.</p>
<p id="p-0214" num="0213">Thus, the difference value diff<sub>bound </sub><b>1060</b> between a pixel <b>1052</b> on the horizontal line <b>1012</b> and a pixel <b>1072</b> on the horizontal line <b>1022</b> is relatively large, while the difference value diff<sub>upper </sub><b>1050</b> between the pixel <b>1052</b> on the horizontal line <b>1012</b> and a pixel <b>1054</b> on the horizontal line <b>1014</b> and the difference value diff<sub>lower </sub><b>1070</b> between the pixel <b>1072</b> on the horizontal line <b>1022</b> and a pixel <b>1074</b> on the horizontal line <b>1024</b> are relatively small.</p>
<p id="p-0215" num="0214">Accordingly, the difference values between the upper lines and between the lower lines with respect to a boundary line between the upper and lower regions of the input video are calculated. Whether the input video is a 3D video is determined based on the difference values, and a 3D video format of the input video is also determined.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Bound<sub>hor</sub>=&#x3a3;|diff<sub>bound</sub>|/(|diff<sub>upper</sub>|+|diff<sub>lower</sub><i>|+c</i>)&#x2003;&#x2003;(7),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where Bound<sub>hor </sub>denotes the amount of discontinuity between the horizontal lines around the boundary line between the upper and lower regions. The amount of discontinuity Bound<sub>hor </sub>is calculated with respect to the entire or a part of the boundary line and the results of calculating are added in units of pixels. That is, the amount of discontinuity Bound<sub>hor </sub>is obtained by calculating the ratios of an absolute difference value |diff<sub>bound</sub>| between two adjacent pixels <b>1052</b>, <b>1072</b> disposed below and above, perpendicularly to the boundary line <b>1030</b> and a sum |diff<sub>upper</sub>|+|diff<sub>lower</sub>| of absolute values of the difference values diff<sub>upper </sub>between two adjacent pixels <b>1052</b>, <b>1054</b> of the upper region <b>1010</b> and absolute values of the difference values diff<sub>lower </sub>between two adjacent pixels <b>1072</b>, <b>1074</b> of the lower region <b>1020</b> disposed perpendicularly to the boundary line <b>1030</b>, and then summing the ratios.
</p>
<p id="p-0216" num="0215">The format determination unit <b>120</b> may calculate the amount of discontinuity Bound<sub>hor </sub>at the boundary line between the upper and lower regions of the input video, and compare it with a threshold TH<sub>horBound </sub>of discontinuity. If the amount of discontinuity Bound<sub>hor </sub>is greater than the threshold TH<sub>horBound </sub>of discontinuity, the format determination unit <b>120</b> may determine a 3D video format of the input video to be the top and bottom format.</p>
<p id="p-0217" num="0216"><figref idref="DRAWINGS">FIG. 11A</figref> illustrates 3D video frame <b>1100</b> having the side by side format, according to an exemplary embodiment. <figref idref="DRAWINGS">FIG. 11B</figref> illustrates a portion <b>1140</b> surrounding a boundary line between a left region <b>1110</b> and a right region <b>1120</b> of the 3D video frame <b>1100</b> in more detail, according to an exemplary embodiment.</p>
<p id="p-0218" num="0217">In the 3D video frame <b>1100</b> having the side by side format, the left region <b>1110</b> and the right region <b>1120</b> may have the left-viewpoint video and the right-viewpoint video, respectively. In this case, a line of discontinuity occurs at the vertical boundary line <b>1130</b> between the left region <b>1110</b> and the right region <b>1120</b>.</p>
<p id="p-0219" num="0218">Referring to <figref idref="DRAWINGS">FIG. 11B</figref>, in the portion <b>1140</b> surrounding the boundary line <b>1130</b>, vertical lines <b>1112</b> and <b>1114</b> are disposed in the left region <b>1110</b> and vertical lines <b>1122</b> and <b>1124</b> are disposed in the right region <b>1120</b>. Two adjacent pixels <b>1152</b> and <b>1154</b> are disposed perpendicular to the left edge of the vertical boundary line <b>1130</b>, and two adjacent pixels <b>1172</b> and <b>1174</b> are disposed perpendicular to the right edge of the vertical boundary line <b>1130</b>.</p>
<p id="p-0220" num="0219">The difference value diff<sub>bound </sub><b>1160</b> between a pixel <b>1152</b> on the vertical line <b>1112</b> and a pixel <b>1172</b> on the vertical line <b>1122</b> is relatively large, while the difference value diff<sub>left </sub><b>1150</b> between the pixel <b>1152</b> on the vertical line <b>1112</b> and a pixel <b>1154</b> on the vertical line <b>1114</b> and the difference value diff<sub>right </sub><b>1170</b> between the pixel <b>1172</b> on the vertical line <b>1122</b> and a pixel <b>1174</b> on the vertical line <b>1124</b> are relatively small.</p>
<p id="p-0221" num="0220">Accordingly, the difference values between the left regions and between the right regions with respect to a boundary line between the left and right region of the input video are calculated. Whether the input video is the 3D video is determined based on the difference values, and a 3D video format of the input video is also determined.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Bound<sub>ver</sub>=&#x3a3;|diff<sub>bound</sub>|/(|diff<sub>left</sub>|+|diff<sub>right</sub><i>|+c</i>)&#x2003;&#x2003;(8),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where Bound<sub>ver </sub>denotes the amount of discontinuity between the vertical lines around the boundary line between the upper and lower region. The amount of discontinuity Bound<sub>ver </sub>is calculated with respect to the entire or a part of the boundary line and the results of calculating are added in units of pixels. That is, the amount of discontinuity Bound<sub>ver </sub>is obtained by calculating the ratios of an absolute difference value |diff<sub>bound</sub>| between two adjacent pixels <b>1152</b>, <b>1172</b> disposed to the left and to the right of and perpendicularly to the boundary line <b>1130</b> and the sums |diff<sub>left</sub>|+|diff<sub>right</sub>| of absolute values of the difference values diff<sub>left </sub>between two adjacent pixels <b>1152</b>, <b>1154</b> of the left region <b>1110</b> and absolute values of the difference values diff<sub>right </sub>between two adjacent pixels <b>1122</b>, <b>1124</b> of the right region <b>1120</b> disposed perpendicularly to the boundary line <b>1130</b>, and then summing the ratios.
</p>
<p id="p-0222" num="0221">The format determination unit <b>120</b> may calculate the amount of discontinuity Bound<sub>ver </sub>at the boundary line between the left and right regions of the input video and compare it with a threshold TH<sub>verBound </sub>of discontinuity. If the amount of discontinuity Bound<sub>ver </sub>is greater than the threshold TH<sub>verBound </sub>of discontinuity, the format determination unit <b>120</b> may determine a 3D video format of the input video to be the side by side format.</p>
<p id="p-0223" num="0222"><figref idref="DRAWINGS">FIG. 12A</figref> illustrates 3D video frame <b>1200</b> that has a boundary region <b>1230</b> and the side by side format, according to an exemplary embodiment. <figref idref="DRAWINGS">FIG. 12B</figref> illustrates a portion <b>1240</b> of the boundary region <b>1230</b> of the 3D video frame <b>1200</b> in more detail, according to an exemplary embodiment.</p>
<p id="p-0224" num="0223">A plurality of lines of discontinuity having meaningless data may exist at the boundary line between the left and right regions or between the upper and lower regions of 3D video. For example, in the 3D video <b>1200</b> having the side by side format, boundary lines between a left region <b>1210</b> and a right region <b>1220</b> may form the boundary region <b>1230</b> having a predetermined width and, for example, black lines.</p>
<p id="p-0225" num="0224">In the portion <b>1240</b> of the boundary region <b>1230</b>, the vertical lines are illustrated in the left region <b>1210</b> and the right region <b>1220</b>. If the boundary region <b>1230</b> has meaningless data, it may be disregarded when calculating the amount of discontinuity Bound<sub>ver</sub>. Thus, the boundary region <b>1230</b> is disregarded, and the amount of discontinuity Bound<sub>ver </sub>is calculated from the difference value diff<sub>left </sub><b>1250</b> between pixels <b>1231</b>, <b>1232</b> on vertical lines <b>1212</b> and <b>1214</b> in the left region <b>1210</b>, the difference value diff<sub>right </sub><b>1270</b> between pixels <b>1272</b>, <b>1274</b> on vertical lines <b>1222</b> and <b>1224</b> in the right region <b>1220</b>, and the difference value diff<sub>bound </sub><b>1260</b> between pixels <b>1231</b>, <b>1272</b> on the vertical lines <b>1212</b> and <b>1222</b> located adjacent the boundary region <b>1230</b>.</p>
<p id="p-0226" num="0225">As described above with reference to <figref idref="DRAWINGS">FIGS. 10A to 12B</figref>, when the amounts of discontinuity Bound<sub>hor </sub>and Bound<sub>ver </sub>of a boundary line in the 3D video are calculated, not only the difference value diff<sub>bound </sub>between pixels on two lines adjacent to the boundary line is used but also the difference values diff<sub>upper </sub>between pixels on the lines in an upper region, the difference value diff<sub>lower </sub>between pixels on the lines in a lower region, the difference value diff<sub>left </sub>between pixels on the lines in a left region, and the difference value diff<sub>right </sub>between pixels on the lines in a right region are used. Accordingly, it is possible to prevent a 3D video format from being determined at a boundary region of the 2D video.</p>
<p id="p-0227" num="0226"><figref idref="DRAWINGS">FIG. 13A</figref> is a graph showing average values of the differences between the pixel values of the consecutive frames of the 2D video on the time axis, according to an exemplary embodiment. <figref idref="DRAWINGS">FIG. 13B</figref> is a graph showing average values of the differences between the pixel values of the consecutive frames of the 3D video having the frame sequential format on the time axis, according to an exemplary embodiment.</p>
<p id="p-0228" num="0227">Here, the horizontal axes denote the order of frames and the vertical axes denote the average values of the pixel values of each of the frames.</p>
<p id="p-0229" num="0228">Referring to <figref idref="DRAWINGS">FIG. 13A</figref>, in a 2D video sequence, video captured from the same viewpoint is displayed in units of frames, and thus, the pixel values of the respective frames change relatively continuously according to the order of the frames. However, referring to <figref idref="DRAWINGS">FIG. 13B</figref>, in the 3D video having the frame sequential format, the left-viewpoint video and the right-viewpoint video are alternately arranged in units of frames, and thus, the pixel values of the respective frames change discontinuously. This is because the distribution of pixels is different between the left-viewpoint video and the right-viewpoint video.</p>
<p id="p-0230" num="0229">Accordingly, the format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> may determine whether a 3D video format of the input video is the frame sequential format, based on a change in the pixel values of the respective frames of an input video sequence.</p>
<p id="p-0231" num="0230"><figref idref="DRAWINGS">FIG. 14</figref> illustrates a method of determining whether a 3D video format is the frame sequential format by using three consecutive frames on the time axis, according to an exemplary embodiment.</p>
<p id="p-0232" num="0231">The format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> compares disparities between three consecutive frames on the time axis, e.g., a first frame <b>1410</b> at a time t&#x2212;1, a second frame <b>1420</b> at a time t, and a third frame <b>1430</b> at a time t+1, to determine whether these frames belong to a group consisting of the left-viewpoint video frames and the right-viewpoint video frames. Disparities among the frames <b>1410</b>, <b>1420</b>, and <b>1430</b> may be compared by using the following equations:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>D</i><sub>FSQ</sub>=[diff(<i>t&#x2212;</i>1<i>,t</i>)+diff(<i>t,t+</i>1)]/[diff(<i>t&#x2212;</i>1<i>,t+</i>1)+<i>c]</i>&#x2003;&#x2003;(9),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where D<sub>FSQ </sub>denotes a variation in the frames <b>1410</b>, <b>1420</b>, and <b>1430</b>, and diff(t, t+1) denotes an absolute value of the difference between the pixel values of the second frame <b>1420</b> at the time t and the third frame <b>1430</b> at the time t+1.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>diff(<i>t&#x2212;</i>1<i>,t</i>)=|<i>I</i><sub>t&#x2212;1</sub>(<i>i,j</i>)&#x2212;<i>I</i><sub>t</sub>(<i>i,j</i>)|<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>diff(<i>t,t+</i>1)=|<i>I</i><sub>t</sub>(<i>i,j</i>)&#x2212;<i>I</i><sub>t+1</sub>(<i>i,j</i>)|<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>diff(<i>t&#x2212;</i>1<i>,t+</i>1)=|<i>I</i><sub>t&#x2212;1</sub>(<i>i,j</i>)&#x2212;<i>I</i><sub>t+1</sub>(<i>i,j</i>)|&#x2003;&#x2003;(10), <?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where I<sub>t</sub>(i,j) denotes a pixel value of the second frame <b>1420</b> at the time t.
</p>
<p id="p-0233" num="0232">That is, the variation D<sub>FSQ </sub>in the frames <b>1410</b>, <b>1420</b>, and <b>1430</b> is equal to the ratio of the sum of an absolute value diff(t&#x2212;1, t) of the difference between a pixel <b>1415</b> at the time t&#x2212;1 and a pixel <b>1425</b> at the time t and an absolute value diff(t, t+1) of the difference between the pixel <b>1425</b> at the time t and a pixel <b>1435</b> at the time t+1 to an absolute value diff(t&#x2212;1, t+1) and the difference between the pixel <b>1415</b> at the time t&#x2212;1 and the pixel <b>1435</b> at the time t+1.</p>
<p id="p-0234" num="0233">If an input video sequence is a 2D video sequence, the difference values between the pixel values of each two adjacent frames do not change greatly from the first frame <b>1410</b> at the time t&#x2212;1 to the second frame <b>1420</b> at the time t, and from the second frame <b>1420</b> at time t to the third frame <b>1430</b> at the time t+1. Thus, the variation D<sub>FSQ </sub>in the frames <b>1410</b>, <b>1420</b>, and <b>1430</b> has a value that is not large.</p>
<p id="p-0235" num="0234">However, if the input video sequence is a 3D video frame having the frame sequential format, the first frame <b>1410</b> at the time t&#x2212;1 and the third frame <b>1430</b> at the time t+1 are obtained from the same viewpoint but the second frame <b>1420</b> at the time t is obtained from a different viewpoint. Thus, an absolute value of the difference between the pixels of the first frame <b>1410</b> at the time t&#x2212;1 and the third frame <b>1430</b> at the time t+1 is relatively small but absolute values of the difference values between the pixels of the first frame <b>1410</b> at the time t&#x2212;1 and the second frame <b>1420</b> at the time t and between the second frame <b>1420</b> at the time t and the third frame <b>1430</b> at the time t+1 are relatively large. Accordingly, the variation D<sub>FSQ </sub>in the frames <b>1410</b>, <b>1420</b>, and <b>1430</b> is large.</p>
<p id="p-0236" num="0235">Accordingly, the format determination unit <b>120</b> may calculate a variation value D<sub>FSQ </sub>of the frames of an input video sequence and determine a 3D video format of the input video sequence using the calculated variation value D<sub>FSQ</sub>.</p>
<p id="p-0237" num="0236">A method of determining whether a 3D video format is the frame sequential format is described above with reference to <figref idref="DRAWINGS">FIGS. 13A</figref>, <b>13</b>B, and <b>14</b>, but the 3D video having the field sequential format has similar characteristics to the 3D video having the frame sequential format and the format determination unit <b>120</b> may thus determine whether 3D video has the field sequential format by applying Equation (9) in units of fields of the 3D video.</p>
<p id="p-0238" num="0237">The format determination unit <b>120</b> may check whether an error occurs in the results of determining a 3D video format of an input video sequence in units of frames, correct the error, and then finally determine the 3D video format, thereby increasing the precision of the result of determining the 3D video format. Methods of checking whether an error occurs in the results of determining a 3D video format of an input video sequence will now be described with reference to <figref idref="DRAWINGS">FIGS. 15 and 16</figref>.</p>
<p id="p-0239" num="0238"><figref idref="DRAWINGS">FIG. 15</figref> illustrates a case where an error occurs when a 3D video format is determined. When an input video sequence includes a first, second, . . . , fifteenth frame, the format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref> determines a 3D video format of each of these frames by using the disparity information or correlation information between the neighboring pixels. In results graph <b>1500</b> of determining the 3D video format of each of the first to fifteenth frames, the first to seventh frames are determined to have the side by side format in a first determination section <b>1510</b>, the eighth frame is determined to have the top and bottom format in a second section determination <b>1520</b>, and the ninth to fifteenth frames are determined to have the side by side format in a third determination section <b>1530</b>.</p>
<p id="p-0240" num="0239">If the input video sequence is transformed in formats according to the results <b>1500</b> such that the input video sequence can be displayed three-dimensionally, then a user may feel a sense of incongruity during 3D displaying of the eighth frame whose format is determined in the second determination section <b>1520</b> to be the top and bottom format when the first to fifteenth frames are displayed three-dimensionally. Accordingly, when the format of the 3D video is finally determined, the format of the eighth frame is changed from the top and bottom to the side by side format.</p>
<p id="p-0241" num="0240"><figref idref="DRAWINGS">FIG. 16</figref> illustrates a method of correcting an error occurring when a 3D video format is determined, according to an exemplary embodiment.</p>
<p id="p-0242" num="0241">In the results graph <b>1600</b> of determining a 3D video format of each of a first, second, . . . , fifteenth frame of an input video sequence by the format determination unit <b>120</b> of <figref idref="DRAWINGS">FIG. 1</figref>, based on the disparity information or correlation information regarding the neighboring pixels, the first to seventh frames are determined to have the side by side format in a fourth determination section <b>1620</b>, and the eighth to fifteenth frames are determined to have the top and bottom format in a fifth determination section <b>1628</b>.</p>
<p id="p-0243" num="0242">In this case, after the format determination unit <b>120</b> determines the first to seventh frames to have the side by side format in the fourth determination section <b>1620</b>, when the 3D video format of the input video sequence is switched from the side by side format to the top and bottom format when the 3D video format of the eighth frame is determined, the format determination unit <b>120</b> does not directly determine the eighth frame to have the top and bottom format and further checks the result of determining a 3D video format of a predetermined number of consecutive frames in a check section <b>1630</b>.</p>
<p id="p-0244" num="0243">For example, if in the check section <b>1630</b>, the result of determining a 3D video format of each of four consecutive frames, i.e., the eighth to eleventh frames, reveals that they have the top and bottom format, then the result of determining the 3D video format of the twelfth to fifteenth frames may be finally determined to be the 3D video format of the input video sequence. Alternatively, the 3D video format determined in the check section <b>1630</b> is definitely changed from the top and bottom format to the side by side format to keep the determination results determined previously in the fourth determination section <b>1620</b>.</p>
<p id="p-0245" num="0244">Accordingly, in the results graph <b>1610</b> of definitely determining the 3D video format of the input video sequence, the first to eleventh frames are finally determined to have the side by side format and the twelfth to fifteenth frames are finally determined to have the top and bottom format, unlike in the results <b>1600</b>.</p>
<p id="p-0246" num="0245">If determination results of the fourth determination section <b>1620</b> and the check section <b>1630</b> are switches, the check section <b>1630</b> maintains the determination result of the check section <b>1630</b> to be the determination result of the fourth determination section <b>1620</b> to prevent a sudden change in the 3D video format from causing an error or from degrading a stereoscopic effect. Length of the check section <b>1630</b> is determined to be quite shorter than that of the input video sequence. Although format transformation of a predetermined number of frames checked in the check section <b>1630</b> is delayed, format transformation and displaying may be more stably performed in a case when a format determination error occurs.</p>
<p id="p-0247" num="0246"><figref idref="DRAWINGS">FIG. 17</figref> is a block diagram illustrating post-processing involving format transformation and 3D displaying, according to an exemplary embodiment.</p>
<p id="p-0248" num="0247">If a 3D video format transforming apparatus <b>100</b> according to an exemplary embodiment is installed in a 3D television (TV) system <b>1700</b>, the 3D TV system <b>1700</b> is capable of automatically sensing and transforming a 3D video format of input video and displaying the input video three-dimensionally.</p>
<p id="p-0249" num="0248">In the 3D TV system <b>1700</b>, if 3D video is input from a source device, such as a digital versatile disc player (DVD)/Blu-ray Disc (BD) player <b>1702</b>, a personal computer (PC) or a set-top box <b>1704</b>, then the 3D video is sequentially supplied to a format determination unit <b>1710</b> and a format transform unit <b>1720</b> which are 3D integrated circuits (3DICs) and is then transformed into formats so that the 3D video may be displayed three-dimensionally.</p>
<p id="p-0250" num="0249">The format determination unit <b>1710</b> analyzes the 3D video and determines a 3D video format thereof, and supplies information regarding the 3D video format to the format transform unit <b>1720</b> so that the format transform unit <b>1720</b> may perform format transformation.</p>
<p id="p-0251" num="0250">The result of transforming the left-viewpoint video and the right-viewpoint video of the 3D video by the format transform unit <b>1720</b> is supplied to a 3D video enhancer <b>1730</b>, so that the post-processing is performed to improve the quality of the 3D video or to reduce a sense of fatigue that users may feel when they view the 3D video displayed. Then, the final left-viewpoint video and the final right-viewpoint video are supplied to a display device (not shown). In this case, a stereo synchronization signal generator <b>1740</b> generates and outputs a stereo synchronization signal by using the result of transforming the left-viewpoint video and the right-viewpoint video, which is received from the format transform unit <b>1720</b>, and by using a synchronization signal received from the source device, so that the left-viewpoint video and the right-viewpoint video can be displayed while being synchronized with each other.</p>
<p id="p-0252" num="0251">In an exemplary embodiment, as described above, the 3D video format transforming apparatus <b>100</b> may be embodied as hardware to be installed in a 3D display system, and methods of determining and transforming a 3D video format that are performed by the 3D video format transforming apparatus <b>100</b> may be embodied as software, such as a graphics device driver for use in a PC.</p>
<p id="p-0253" num="0252"><figref idref="DRAWINGS">FIG. 18</figref> is a flowchart illustrating a method of transforming a 3D video format, according to an exemplary embodiment. Referring to <figref idref="DRAWINGS">FIG. 18</figref>, in operation <b>1810</b>, a video sequence with 3D video having the left-viewpoint video and the right-viewpoint video is received.</p>
<p id="p-0254" num="0253">In operation <b>1820</b>, at least one of disparity information between the left-viewpoint video and the right-viewpoint video and correlation information between the neighboring pixel values is estimated, and a 3D video format of the 3D video is determined based on the result of estimation.</p>
<p id="p-0255" num="0254">In operation <b>1830</b>, the left-viewpoint video and the right-viewpoint video are transformed into a format, based on the 3D video format, so that they can be displayed three-dimensionally.</p>
<p id="p-0256" num="0255">In operation <b>1840</b>, the transformed left-viewpoint video and right-viewpoint video are reproduced three-dimensionally by using a display device.</p>
<p id="p-0257" num="0256">The method of transforming a 3D video format, which is illustrated in <figref idref="DRAWINGS">FIG. 18</figref>, may be embodied as hardware by using the 3D video format transforming apparatus <b>100</b> of <figref idref="DRAWINGS">FIG. 1</figref> as described above with reference to <figref idref="DRAWINGS">FIGS. 1 to 17</figref>.</p>
<p id="p-0258" num="0257"><figref idref="DRAWINGS">FIG. 19A</figref> illustrates a method of searching an Internet website for 3D video content having a 3D video format, according to an exemplary embodiment.</p>
<p id="p-0259" num="0258">In a method of transforming a 3D video format according to an exemplary embodiment, a 3D video web search service may be provided to search for a 3D video as the input video. Referring to <figref idref="DRAWINGS">FIG. 19A</figref>, a web browser window <b>1900</b> that supports a search for the 3D video includes a search function setting section <b>1910</b> and a search word input section <b>1920</b>.</p>
<p id="p-0260" num="0259">For example, when the 3D video having the side by side format is searched for, a &#x2018;3D search&#x2019; function is selected in the search function setting section <b>1910</b> and an expression, &#x2018;side by side&#x2019; is input as a 3D video format in the search word input section <b>1920</b>. Then, a list of the 3D videos having the side by side format is displayed in a search result window <b>1930</b>. If a piece of a 3D video <b>1940</b> is selected from the list of 3D videos, the 3D video <b>1940</b> is displayed in a main window of the web browser window <b>1900</b>.</p>
<p id="p-0261" num="0260">In a method of transforming a 3D video format according to an exemplary embodiment, a 3D video web search service may be performed to search an Internet website for the 3D video having a desired 3D video format and provide the 3D video to a user.</p>
<p id="p-0262" num="0261"><figref idref="DRAWINGS">FIG. 19B</figref> illustrates a method of reproducing the 3D video content having a 3D video format in a web, according to an exemplary embodiment.</p>
<p id="p-0263" num="0262">When a mixture of 2D video and 3D video is displayed in a web browser window <b>1950</b> by using a method of transforming a 3D video format according to an exemplary embodiment, the 2D video may be displayed two-dimensionally and the 3D video may be displayed three-dimensionally.</p>
<p id="p-0264" num="0263">A 3D video format of the 3D video may be determined using a 3D video format determination algorithm. In the web browser window <b>1950</b>, a list <b>1930</b> of detected 3D video and video <b>1940</b> selected from the list <b>1930</b> are all 3D video but the other parts displayed are all 2D video. In order to display only 3D video three-dimensionally, the following methods may be used.</p>
<p id="p-0265" num="0264">As an example, a 3D video format transform unit may provide location information regarding 3D video parts <b>1960</b> and <b>1970</b>, e.g., the coordinates thereof, to a display processing module of a web browser so that the web browser can display the 3D video parts <b>1960</b> and <b>1970</b> three-dimensionally in the web browser window <b>1950</b>.</p>
<p id="p-0266" num="0265">As an example, the 3D video format transform unit may analyze the web browser window <b>1950</b> to determine the location of the 3D video parts <b>1960</b> and <b>1970</b>, and display only the 3D video parts <b>1960</b> and <b>1970</b> three-dimensionally. According to the above examples of displaying the 3D video in a web browser window, even if a mixture of 2D video and 3D video is displayed in the web browser window, a user may view the 3D video three-dimensionally.</p>
<p id="p-0267" num="0266">The above described exemplary embodiments may be embodied as a computer program. The computer program may be stored in a non-transitory computer-readable recording medium, and executed using a general digital computer. Examples of the computer-readable medium include a magnetic recording medium (a ROM, a floppy disc, a hard disc, etc.), and an optical recording medium (a CD-ROM, a DVD, etc.). While exemplary embodiments have been particularly shown and described, it will be understood by those of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present invention as defined by the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of transforming a format of three-dimensional (3D) video, the method comprising:
<claim-text>receiving a video sequence comprising 3D video that includes left-viewpoint video and right-viewpoint video;</claim-text>
<claim-text>estimating at least one of disparity information between the left-viewpoint video and the right-viewpoint video, and correlation information between neighboring pixel values of the left-viewpoint video and the right-viewpoint video;</claim-text>
<claim-text>determining a 3D video format of the 3D video based on a result of the estimating;</claim-text>
<claim-text>transforming the left-viewpoint video and the right-viewpoint video into a format from the determined 3D video format;</claim-text>
<claim-text>displaying the transformed left-viewpoint video and the transformed right-viewpoint video three-dimensionally on a display device;</claim-text>
<claim-text>determining, from a plurality of the 3D video, first secutive frames to be a first format and second consecutive frames, a predetermined number of frames subsequent to the first frames, to be a second format;</claim-text>
<claim-text>determining 3D video formats of remaining third consecutive frames. subsequent to the second frames, to be the first format; and</claim-text>
<claim-text>changing the 3D video format of the second frames from the second format to the first format.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the 3D video format comprises determining whether the 3D video format is one of a side by side format, a top and bottom format, a horizontal line interleaved format, and a vertical line interleaved format based on the disparity information between the left-viewpoint video and the right-viewpoint video.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the 3D video format comprises determining whether the 3D video format is one of a horizontal line interleaved format, a vertical line interleaved format, and a checker board format, based on the correlation information between the neighboring pixel values of the left-viewpoint video and the right-viewpoint video.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>determining whether the 3D video format is one of a horizontal line interleaved format, a vertical line interleaved format, and a checker board format based on the correlation information between the neighboring pixel values of the left-viewpoint video and the right-viewpoint video; and</claim-text>
<claim-text>determining whether the 3D video format is one of a field sequential format and a frame sequential format, based on the disparity information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the 3D video format further comprises determining whether the 3D video format is one of a side by side format and a top and bottom format by detecting a boundary line between the left-viewpoint video and the right-viewpoint video.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the 3D video format comprises determining the 3D video format of the 3D video in a region that has texture of the 3D video by detecting the region having texture, and calculating a smoothness of corresponding regions of the left-viewpoint video and the right-viewpoint video.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>dividing a frame of the 3D video into equal upper and lower regions;</claim-text>
<claim-text>estimating first disparity information by using an upper and lower differential image that represents an absolute value of a difference value between the upper and lower regions;</claim-text>
<claim-text>dividing the frame of the 3D video into equal left and right regions; and</claim-text>
<claim-text>estimating second disparity information by using a left and right differential image that represents an absolute value of a difference value between the left and right regions.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the determining of the 3D video format comprises determining whether the 3D video format is the top and bottom format or the side by side format, based on the first disparity information and the second disparity information.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>dividing vertical lines of the frame of the 3D video into an odd-numbered vertical line and an even-numbered vertical line;</claim-text>
<claim-text>estimating third disparity information by using a vertical line differential image that represents an absolute value of a difference value between the odd-numbered vertical line and the even-numbered vertical line;</claim-text>
<claim-text>dividing horizontal lines of the frame of the 3D video into an odd-numbered line and an even-numbered horizontal line; and</claim-text>
<claim-text>estimating fourth disparity information by using a horizontal line differential image that represents an absolute value of a difference value between the odd-numbered horizontal line and the even-numbered horizontal line.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>determining whether the 3D video format is one of the top and bottom format and the side by side format based on the first and the second disparity information and providing a first determination result; and</claim-text>
<claim-text>determining whether the 3D video format is one of the vertical line interleaved format and the horizontal line interleaved format based on the third disparity information and the fourth disparity information and providing a second determination result.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>if a width of a first section, in which values of consecutive pixels in the upper and lower differential image are greater than a first threshold, is greater than a first section disparity value, selecting the first section as a first candidate section of the first disparity information; and</claim-text>
<claim-text>if the width of a second section, in which values of consecutive pixels of the left and right differential image are greater than a second threshold, is greater than a second section disparity value, selecting the second section as a second candidate section of the second disparity information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>comparing a total number of first candidate sections of the first disparity information with a total number of the second candidate sections of the second disparity information;</claim-text>
<claim-text>determining that the 3D video format is the top and bottom format if the total number of the first candidate sections of the first disparity information is less than the total number of the second candidate sections of the second disparity information; and</claim-text>
<claim-text>determining that the 3D video format is the side by side format if the total number of the first candidate sections of the first disparity information is greater than the total number of the second candidate sections of the second disparity information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the determining of the 3D video format further comprises:
<claim-text>if the width of a third section, in which values of consecutive pixels of the vertical line differential image are greater than a third threshold, is greater than a third section disparity value, selecting the third section as a third candidate section of the third disparity information; and</claim-text>
<claim-text>if the width of a fourth section, in which values of consecutive pixels of the horizontal line differential image are greater than a fourth threshold, is greater than a fourth section disparity value, selecting the fourth section as a fourth candidate section of the fourth disparity information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>comparing a total number of third candidate sections of the third disparity information with a total number of fourth candidate sections of the fourth disparity information;</claim-text>
<claim-text>determining that the 3D video format is the vertical line interleaved format if the total number of the third candidate sections of the third disparity information is greater than the total number of the fourth candidate sections of the fourth disparity information;</claim-text>
<claim-text>determining that the 3D video format is the horizontal line interleaved format if the total number of the third candidate sections of the third disparity information is less than the total number of the fourth candidate sections of the fourth disparity information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>estimating first correlation values between values of first, second, and third pixels of the 3D video that are consecutive in a horizontal direction; and</claim-text>
<claim-text>estimating second correlation values between values of fourth, fifth, and sixth pixels of the 3D video that are consecutive in a vertical direction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the determining the 3D video format further comprises:
<claim-text>determining the 3D video format to be the vertical line interleaved format if a total number of the first correlation values, which are greater than a correlation threshold, is greater than a predetermined format threshold and a total number of the second correlation values, which are greater than the correlation threshold, is less than the predetermined format threshold;</claim-text>
<claim-text>determining the 3D video format to be the horizontal line interleaved format if the total number of the first correlation values, which are greater than the correlation threshold, is less than the predetermined format threshold and the total number of the second correlation values, which are greater than the correlation threshold, is greater than the predetermined format threshold; and</claim-text>
<claim-text>determining the 3D video format to be the checker board format if the total number of the first correlation values, which are greater than the correlation threshold , and the total number of the second correlation values, which are greater than the correlation threshold, are greater than the predetermined format threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein each of the first correlation values is a ratio of a sum of a second difference value and a third difference value and a first difference value, where the first difference value is an absolute value of a difference value between the first and third pixels, the second difference value is an absolute value of a difference value between the first and second pixels, and the third difference value is an absolute value of a difference value between the second and third pixels, and
<claim-text>the second correlation values each is a ratio of a sum of a fifth difference value and a sixth difference value and a fourth difference value, where the fourth difference value is an absolute value of a difference value between the fourth and sixth pixels, the fifth difference value is an absolute value of a difference value between the fourth and fifth pixels, and the sixth difference value is an absolute value of a difference value between the fifth and sixth pixels.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the determining the 3D video format further comprises estimating a change in a temporal disparity between first, second, and third consecutive frames of the 3D video on a time axis.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the change in the temporal disparity between the first, second, and third consecutive frames is equal to a ratio of a sum of second differential frame data and third differential frame data and first differential frame data, wherein the first differential frame data is an absolute value of a difference value between the first and third frames, the second differential frame data is an absolute value of a difference value between the first and second frames, and the third differential frame data is an absolute value of a difference value between the second and third frames.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the detecting the boundary line between the left-viewpoint video and the right-viewpoint video comprises:
<claim-text>dividing the 3D video frames each into equal upper and lower regions;</claim-text>
<claim-text>calculating ratios of a horizontal boundary line difference value and a sum of an upper horizontal boundary line difference value and a lower horizontal boundary line difference value of pixel groups each including adjacent first, second, third and fourth pixels, where the upper horizontal boundary line difference value is an absolute value of a difference value between the first and second pixels disposed above and perpendicular to a horizontal boundary line between the upper and lower regions, the lower horizontal boundary difference value is an absolute value of a difference value between the third and fourth pixels disposed below and perpendicular to the horizontal boundary line, and the horizontal boundary line difference value is an absolute value of a difference value between the second pixel disposed above and the third pixel disposed below the horizontal boundary line; and</claim-text>
<claim-text>determining the 3D video to be the top and bottom format if a sum of the ratios is greater than a horizontal boundary line threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the detecting the boundary line between the left-viewpoint video and the right-viewpoint video comprises:
<claim-text>dividing the 3D video frames each into equal left and right regions;</claim-text>
<claim-text>calculating ratios of a vertical boundary line difference value and a sum of a left vertical boundary line difference value and a right vertical boundary line difference value of pixel groups each including adjacent first, second, third and fourth pixels, where the left vertical boundary line difference value is an absolute value of a difference value between the first and second pixels disposed perpendicular and to the left of a vertical boundary line between the left and right regions, the right vertical boundary difference value is an absolute value of a difference value between the third and fourth pixels disposed perpendicular and to the right of the vertical boundary line, and the vertical boundary line difference value is an absolute value of a difference value between the second and third pixels disposed to the left and to the right of the vertical boundary line, respectively; and</claim-text>
<claim-text>determining the 3D video to be the side by side format if a sum of the ratios is greater than a vertical boundary line threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the 3D video has a boundary region, which surrounds the boundary line and includes at least a number of black lines, and the determining the 3D video format further comprises determining the 3D video format of the 3D video while excluding the boundary region from the determining.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the 3D video format of remaining third consecutive frames comprises:
<claim-text>determining the remaining third consecutive frames, subsequent to the second frames, having the second format;</claim-text>
<claim-text>wherein the changing the 3D video format of the second frames comprises checking whether at least a predetermined number of the third frames has the second format; and</claim-text>
<claim-text>if at least the predetermined number of the third frames have the second format, changing the 3D video format of the second frames to the first format, and finally determining the third frames to have the second format.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising searching an Internet website for 3D video content by using a selected 3D video format as a keyword,
<claim-text>wherein the receiving the video sequence comprises receiving the 3D video content searched for in the web.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the searching the web for the 3D video content comprises searching for the video content that is a mixture of two-dimensional (2D) video and the 3D video,
<claim-text>the receiving the video sequence further comprises receiving the 2D and 3D video content searched for in the web,</claim-text>
<claim-text>the transforming the left-viewpoint video and the right-viewpoint video of the 3D video into the format further comprises transforming the left-viewpoint video and the right-viewpoint video into the format to be reproduced three-dimensionally based on the selected 3D video format used as the keyword, and</claim-text>
<claim-text>the method further comprises reproducing the 2D video of the video sequence two-dimensionally, and reproducing the 3D video of the video sequence three-dimensionally in the format into which the 3D video is transformed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method of <claim-ref idref="CLM-00025">claim 25</claim-ref>, further comprising:
<claim-text>receiving location information of the 3D video transmitted from a provider of the 3D video content to a web browser; and</claim-text>
<claim-text>estimating, by the web browser, at least one of the disparity information and the correlation information between the neighboring pixel values, determining the 3D video format of the 3D video, transforming the 3D video into the format, and reproducing the 3D video three-dimensionally.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The method of <claim-ref idref="CLM-00025">claim 25</claim-ref>, further comprising detecting location of the 3D video in the 3D video content, by a 3D display device,
<claim-text>wherein the 3D display device reproduces the transformed 3D video three-dimensionally at the location of the 3D video.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. An apparatus for transforming a format of three-dimensional (3D) video, the apparatus comprising:
<claim-text>a video input unit which receives a video sequence comprising 3D video that includes left-viewpoint video and right-viewpoint video;</claim-text>
<claim-text>a format determination unit which estimates at least one of disparity information between the left-viewpoint video and the right-viewpoint video and correlation information between neighboring pixel values of the left-viewpoint video and the right-viewpoint video, and determines the 3D video format of the 3D video based on a result of the estimation;</claim-text>
<claim-text>a format transform unit which transforms the left-viewpoint video and the right-viewpoint video into a format, from the determined 3D video format; and</claim-text>
<claim-text>a display unit which displays the transformed left-viewpoint video and the transformed right-viewpoint video three-dimensionally on a display device,</claim-text>
<claim-text>wherein the format determination unit;</claim-text>
<claim-text>determines, from a plurality of frames of the 3D video, first consecutive frames to be a first format and second consecutive frames, a predetermined number of frames subsequent to the first frames, to be a second format,</claim-text>
<claim-text>determines 3D video formats of remaining third consecutive frames subsequent to the second frames, to be the first format, and</claim-text>
<claim-text>changes the 3D video format of the second frames from the second format to the first format.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. A non-transitory computer-readable recording medium storing a computer program which, when executed by a computer, causes the computer to execute a method of transforming a format of three-dimensional (3D) video, the method comprising:
<claim-text>receiving a video sequence comprising 3D video that includes left-viewpoint video and right-viewpoint video;</claim-text>
<claim-text>estimating at least one of disparity info ation between the left-viewpoint video and the right-viewpoint video, and correlation infornnudnn between neighboring pixel values of the left-viewpoint video and the right-viewpoint video;</claim-text>
<claim-text>determining a 3D video format of the 3D video based on a result of the estimating;</claim-text>
<claim-text>transforming the left-viewpoint video and the right-viewpoint video into a format from the determined 3D video format;</claim-text>
<claim-text>displaying the transformed left-viewpoint video and the transformed right-viewpoint video three-dimensionally on a display device;</claim-text>
<claim-text>determining, from a plurality of frames of the 3D video, first consecutive frames to be a first format and second consecutive frames, a predetermined number of frames subsequent to the first frames, to be a second format;</claim-text>
<claim-text>determining 3D video formats of remaining third consecutive frames, subsequent to the second frames, to be the first format; and</claim-text>
<claim-text>changing the 3D video format of the second frames from the second format to the first format. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
