<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625675-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625675</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13759178</doc-number>
<date>20130205</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>2003-0022018</doc-number>
<date>20030408</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>12</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>11</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>37524024</main-classification>
<further-classification>37524027</further-classification>
</classification-national>
<invention-title id="d2e69">Block error compensating apparatus of image frame and method thereof</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5212549</doc-number>
<kind>A</kind>
<name>Ng</name>
<date>19930500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5400076</doc-number>
<kind>A</kind>
<name>Iwamura</name>
<date>19950300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5410553</doc-number>
<kind>A</kind>
<name>Choon</name>
<date>19950400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5442400</doc-number>
<kind>A</kind>
<name>Sun</name>
<date>19950800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5621467</doc-number>
<kind>A</kind>
<name>Chien</name>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5737022</doc-number>
<kind>A</kind>
<name>Yamaguchi</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5841477</doc-number>
<kind>A</kind>
<name>Kim</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5933542</doc-number>
<kind>A</kind>
<name>Chang</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6078616</doc-number>
<kind>A</kind>
<name>Ozcelik</name>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6134352</doc-number>
<kind>A</kind>
<name>Radha</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6137915</doc-number>
<kind>A</kind>
<name>Chai</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7003174</doc-number>
<kind>B2</kind>
<name>Kryukov</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2001/0005399</doc-number>
<kind>A1</kind>
<name>Kimoto</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2004/0088378</doc-number>
<kind>A1</kind>
<name>Moats</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2005/0157799</doc-number>
<kind>A1</kind>
<name>Raman et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>EP</country>
<doc-number>1081963</doc-number>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>EP</country>
<doc-number>1126725</doc-number>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>EP</country>
<doc-number>1126725</doc-number>
<kind>A1</kind>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>JP</country>
<doc-number>2001-078198</doc-number>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>2001-186521</doc-number>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>2002-027475</doc-number>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>JP</country>
<doc-number>2003-032686</doc-number>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>KR</country>
<doc-number>1998-015341</doc-number>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>WO</country>
<doc-number>WO03/007495</doc-number>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>Eduardo Asbun, et al., &#x201c;Real-Time Error Concealment in Digital Video streams using Digital Signal Processors&#x201d;, XP-001200521, IEEE Transactions on Consumer Electronics, vol. 47, No. 4 (Nov. 2001).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>European Search Report dated Oct. 7, 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Japanese Office Action dated Apr. 4, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Paul Salama, et al., &#x201c;Error Concealment in MPEG Video Streams Over ATM Networks&#x201d;, IEEE Journalon Selected Areas in Communications, vol. 19, No. 6, (Jun. 2000).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>4</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>37524024</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524027</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11682402</doc-number>
<date>20070306</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8428141</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13759178</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10815669</doc-number>
<date>20040402</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7221710</doc-number>
<date>20070522</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11682402</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130148744</doc-number>
<kind>A1</kind>
<date>20130613</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>LG Electronics Inc.</orgname>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Sung Kyu</first-name>
<address>
<city>Ansan</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Fish &#x26; Richardson P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>LG Electronics Inc.</orgname>
<role>03</role>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Perungavoor</last-name>
<first-name>Sath V</first-name>
<department>2488</department>
</primary-examiner>
<assistant-examiner>
<last-name>Xu</last-name>
<first-name>Xiaolan</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An apparatus and method are provided for compensating a block error in an image frame. This may include a video codec decoder for decoding an inputted image frame, and outputting a decoded image frame. An error concealment block may detect an error-generated block in the decoded image frame and compensate the detected error block through a median filter, and output the compensated image frame.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="95.17mm" wi="222.33mm" file="US08625675-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="222.67mm" wi="139.19mm" file="US08625675-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="222.33mm" wi="113.28mm" orientation="landscape" file="US08625675-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="182.63mm" wi="151.64mm" file="US08625675-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of (and claims the benefit of priority under 35 USC 120 to) U.S. application Ser. No. 11/682,402, filed Mar. 6, 2007, which is a continuation of U.S. application Ser. No. 10/815,669, filed Apr. 2, 2004, now U.S. Pat. No. 7,221,710, which claims the benefit of a foreign priority application filed in Korea as Serial No. 2003-0022018 on Apr. 8, 2003. The disclosures of the prior applications are considered part of (and are incorporated by reference in) the disclosure of this application.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD</heading>
<p id="p-0003" num="0002">Embodiments of the present invention may to multimedia communication, and more particularly) to an apparatus for compensating a block error generated from an image frame and a method thereof.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">Mobile communication includes communication systems primarily using a voice signal. However, as techniques for mobile communication are being developed and demands therefore are being increased, mobile communication is being developed as a multimedia communication including not only voice, but also data, as well as moving images. In multimedia communication, an amount of data to be processed may be large, and a bandwidth of an allocated channel or a data transmission speed may be limited. Techniques for transmitting/receiving a large amount of data with limited data transmission speed by compressing, for example, moving picture expert group (MPEG) techniques, have been developed.</p>
<p id="p-0005" num="0004">MPEG techniques for compressing multimedia signals may reduce a data amount of the MPEG frame consecutively changed as a function of time, and transmit the multimedia signal by using an intra-coded frame (I-Frame) decoded only by information of an image frame, a predictive-coded frame (P-Frame) including only motion vector values from the I-Frame, etc. Herein, even if the I-Frame and the P-Frame have few differences by the MPEG method or ocher application methods, they may have a transmission ratio of about 1:15 per second.</p>
<p id="p-0006" num="0005">When a block error is generated at the I-Frame, a receiving side may receive the I-Frame again, so as to compensate the block error. When a block error is generated at the P-Frame, the receiving side may perform a motion estimation process and a motion compensation process for the previous frame and the next frame of the P-Frame, so as to compensate the block error. An apparatus for compensating the block error of an image frame according to an exemplary arrangement will be explained with reference to <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing the block error compensating apparatus of an image frame according to an example arrangement.</p>
<p id="p-0008" num="0007">As shown, the block error compensating apparatus of an image frame may include a video codec decoder <b>10</b> for decoding an inputted image frame, compensating an error-generated image frame among the decoded image frame, and thereby outputting. The apparatus may include a memory <b>12</b> for storing an image frame processed in the video codec decoder <b>10</b>. The apparatus may include a window interface <b>14</b> for converting the image frame inputted from the video codec decoder <b>10</b> into a corresponding format for displaying and thereby outputting. The apparatus may include a display window <b>16</b> for displaying the image frame inputted from the window interface <b>14</b>.</p>
<p id="p-0009" num="0008">A block error compensating method of an image frame according to an example arrangement will be explained with reference to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart showing the block error compensating method of an image frame according to an example arrangement.</p>
<p id="p-0011" num="0010">As shown, a method for compensating a block error of an image frame may include detecting an error-generated block in a decoded image frame (S<b>20</b>). The method may include judging whether a frame including the detected block is a P-Frame (S<b>22</b>). The method may include compensating the generated block error based on the previous frame and the next frame when the frame including the detected block is the P-Frame. The method may include displaying the frame where the bock error has been compensated (S<b>26</b>), which may be repeated. In determining whether a frame including the detected block is a P-Frame (S<b>22</b>), when a frame including the detected block is an I-Frame, the I-Frame may be received again (S<b>23</b>) and the block error-generated image frame may be compensated by the re-received I-Frame.</p>
<p id="p-0012" num="0011">A method for compensating a block error of an image frame according to an exemplary arrangement will be explained in more detail.</p>
<p id="p-0013" num="0012">The video codec decoder <b>10</b> may receive an image frame from a transmitting side thus to decode, then store the decoded image frame in the memory, and then detect an error-generated block the decoded image frame (S<b>20</b>). Herein, the image frame may be composed of blocks having predetermined regions.</p>
<p id="p-0014" num="0013">When an error-generated block is not detected in the decoded image frame, the video codec decoder <b>10</b> may output the image frame to the window interface <b>14</b>. When an error-generated block is detected in the decoded image frame, the video codec decoder <b>10</b> may judge whether an image frame including the error-generated block is a P-Frame (S<b>22</b>).</p>
<p id="p-0015" num="0014">When the image frame including the error-generated block is not the P-Frame but an I-Frame, the video codec decoder <b>10</b> may receive the I-Frame again (S<b>23</b>) and the block error-generated image frame may be compensated by the re-received I-Frame thereby to be outputted to the window interface <b>14</b>.</p>
<p id="p-0016" num="0015">On the other hand, when the image frame including the error-generated block is the P-Frame, the video codec decoder <b>10</b> may perform a motion estimation process and a motion compensation process for the previous frame and the next frame thereby to output the image frame in which the block error has been compensated to the window interface <b>14</b> (S<b>24</b>).</p>
<p id="p-0017" num="0016">The window interface <b>14</b> may convert the inputted image frame into a corresponding format to be suitable for the display window <b>16</b>, and output the converted image frame. The display window <b>16</b> may display the inputted converted image frame (S<b>26</b>).</p>
<p id="p-0018" num="0017">As described above, in the block error compensating apparatus of an image frame, a block error-generated frame may be received again, or a motion estimation process and a motion compensation process for the previous frame and the next frame may be performed, thereby compensating the block error-generated frame.</p>
<p id="p-0019" num="0018">However, in the block error compensating apparatus of an image frame, since a block error-generated frame may have to be received again, or the motion estimation process and the motion compensation process for the previous frame and the next frame may have to be performed, an additional memory for operating a large amount of data may be necessary and data may not be processed in real-time.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0020" num="0019">Therefore, an embodiment(s) of the present invention may provide a block error compensating apparatus of an image frame capable of enhancing reliability by re-confirming an error generation for an error-generated block and a method thereof.</p>
<p id="p-0021" num="0020">Another embodiment(s) of the present invention may provide a block error compensating apparatus of an image frame capable of compensating an error without need for additional memory by compensating a block error-generated image frame through a median filter and a method thereof.</p>
<p id="p-0022" num="0021">Still another embodiment(s) of the present invention may provide a block error compensating apparatus of an image frame capable of compensating an error in real time by compensating a block error-generated image frame through a median filter and a method thereof.</p>
<p id="p-0023" num="0022">To achieve these and other advantages and in accordance with the purpose of embodiments of the present invention, as embodied and broadly described herein, there is provided a block error compensating apparatus of an image frame including a video codec decoder for decoding an inputted image frame and outputting a decoded image frame. The block error compensating apparatus may include an error concealment block for detecting an error-generated block in the decoded image frame, compensating the detected error block through a median filter, and outputting a compensated image frame.</p>
<p id="p-0024" num="0023">To achieve these and other advantages and in accordance with the purpose of embodiments of the present invention, as embodied and broadly described herein, there is provided a method for compensating a block error of an image frame including decoding an inputted image frame and thereby outputting a decoded image frame. The method for compensating a block error may include detecting a block error of the decoded image frame and compensating the detected block error through a median filter, and outputting a compensated image frame.</p>
<p id="p-0025" num="0024">The foregoing and other objects, features, aspects and advantages of the present invention will become more apparent from the following detailed description of the present invention when read in conjunction with the accompanying drawings, all forming a part of the disclosure of the present invention.</p>
<p id="p-0026" num="0025">Additional advantages, objects, and features of the invention may be set forth in part in the description which follows and in part will become apparent to those having ordinary skill in the art upon examination of the following or may be learned from practice of the invention.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0027" num="0026">The accompanying drawings, which are included to provide a further understanding of the invention, are incorporated in and constitute a part of this specification, illustrate embodiments of the invention and together with the description serve to explain the principles of the invention.</p>
<p id="p-0028" num="0027">Embodiments of the present invention will be described in detail with reference to the following drawings in which like reference numerals refer to like elements and wherein:</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing a block error compensating apparatus of an image frame according to an example arrangement;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart showing a block error compensating method of an image frame according to an example arrangement;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram showing a block error compensating apparatus of an image frame according to an example embodiment of the present invention; and</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart showing a block error compensating method of an image frame according to an example embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0033" num="0032">Reference will now be made in detail to exemplary embodiments of the present invention, examples of which are illustrated in the accompanying drawings.</p>
<p id="p-0034" num="0033">Hereinafter, a block error compensating apparatus of an image frame that may compensate an error in, real time and/or without an additional memory by compensating a block error-generated image frame through a median filter, and a method thereof will be explained with reference to the attached drawings.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram showing the block error compensating apparatus of an image frame according to an example embodiment of the present invention.</p>
<p id="p-0036" num="0035">As shown, the block error compensating apparatus of an image frame or video according to an embodiment of the present invention may include a video codec decoder <b>30</b> for decoding an inputted image frame and outputting a decoded image frame. The apparatus may include a memory <b>32</b> for storing an image frame processed in the video codec decoder <b>30</b>. The apparatus may include an error concealment block <b>33</b> for detecting a block error or video block error in the frame inputted from the video codec decoder <b>30</b>, compensating the detected block error through a median filter, and outputting a compensated frame. The apparatus may include a window interface <b>34</b> for converting the frame inputted from the error concealment block <b>33</b> into a format suitable for a display device and outputting a converted frame. The apparatus may include a display window <b>36</b> for displaying the frame inputted from the window interface <b>34</b>.</p>
<p id="p-0037" num="0036">The error concealment block <b>33</b> may include an error detection block <b>331</b> for detecting an error-generated block in the inputted image frame. The error concealment block <b>33</b> may include an error refinement block <b>332</b> for averaging pixel values of one or more blocks adjacent (preceding and/or subsequent) to the detected error block to obtain a first average value or a confirmation average value, obtaining an absolute value for a difference between the average value and a pixel value of the detected error block, and comparing the absolute value with a predetermined, value. The error concealment block <b>33</b> may include an error correction filter <b>333</b> for averaging pixel values of one or more blocks adjacent to the confirmed error block through a median filter to obtain a second average value or compensation average value, and outputting the compensation average value as a pixel value of the confirmed error block when the absolute value is greater than the predetermined value. The error concealment block <b>33</b> may include a frame generation block <b>334</b> for restoring a normal or error-free image frame based on the outputted pixel value, and outputting a restored image frame.</p>
<p id="p-0038" num="0037">The block error compensating method of an image frame according to an embodiment(s) of the present invention will be explained in more detail with reference to <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart showing the block error compensating method of an image frame according to an exemplary embodiment(s) of the present invention.</p>
<p id="p-0040" num="0039">As shown, the block error compensating method of an image frame may include detecting an error-generated block in the decoded image frame (S<b>40</b>). The method may include averaging pixel values of blocks adjacent to the detected error block to obtain a first average value or confirmation average value, obtaining an absolute value for a difference between the confirmation average value and a pixel value of the detected error block, and comparing the absolute value with a predetermined value (S<b>42</b>). The method may include compensating the detected error block through a median Eater when the absolute value is greater than the predetermined value (S<b>44</b>). The method may include restoring an image frame including the block based on the compensated block (S<b>46</b>).</p>
<p id="p-0041" num="0040">The block error compensating method of an image frame according to an embodiment(s) of the present invention will be explained in more detail.</p>
<p id="p-0042" num="0041">First, the video codec decoder <b>30</b> may receive an image frame from a transmitting side. The video coder decoder <b>30</b> may decode the received image frame. A decoded image frame may be stored in the memory <b>32</b>. The decoded image frame may be outputted to the error detection block <b>331</b>. Herein, one image frame or video frame may be composed of video blocks or pixel blocks having predetermined regions.</p>
<p id="p-0043" num="0042">The error detection block <b>331</b> may detect an error-generated block in the image frame inputted from the video codec decoder <b>30</b> (S<b>40</b>). The detected block may be outputted to the error refinement block <b>332</b>.</p>
<p id="p-0044" num="0043">The error refinement block <b>332</b> may average pixel values of one or more blocks adjacent (preceding and/or subsequent) to or contiguous with the detected error block to obtain a first average value or confirmation average value. An absolute value may be obtained for a difference between the confirmation average value and a pixel value of the detected error block. The absolute value may be compared with the predetermined value. According to the comparison result (S<b>42</b>), it may be determined whether or not an error is generated in the detected block.</p>
<p id="p-0045" num="0044">An average value for pixel values of one or more blocks adjacent to the error block may be obtained by the following formula.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>P</i><sub>S</sub>(<i>x,y</i>)=[<i>P</i>(<i>x&#x2212;</i>1<i>,y&#x2212;</i>1)+<i>P</i>(<i>x,y&#x2212;</i>1)+<i>P</i>(<i>x+</i>1<i>,y&#x2212;</i>1)]/3+[<i>P</i>(<i>x&#x2212;</i>1<i>,y</i>)+<i>P</i>(<i>x+</i>1<i>,y</i>)]/2+[<i>P</i>(<i>x&#x2212;</i>1<i>,y+</i>1)+<i>P</i>(<i>x,y+</i>1)+<i>P</i>(<i>x+</i>1<i>,y+</i>1)]/3&#x2003;&#x2003;(Formula 1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0046" num="0045">In Formula 1, P(x,y) may denote a pixel value of the detected error block, and P<sub>s</sub>(x,y) may denote an average value of pixel values of one or more blocks adjacent to the detected error block. Formula 1 may be modified to include one or more successive blocks.</p>
<p id="p-0047" num="0046">The error refinement block <b>332</b> may operate an average value of pixel values of one or more blocks adjacent to the detected error block. The error refinement block <b>332</b> may obtain an absolute value for a difference between P(x, y) and P<sub>s</sub>(x, y). The error refinement block <b>332</b> may compare the absolute value with the predetermined value.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>abs[<i>P</i>(<i>x,y</i>)&#x2212;<i>P</i><sub>s</sub>(<i>x,y</i>)]<img id="CUSTOM-CHARACTER-00001" he="3.13mm" wi="0.68mm" file="US08625675-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x3b1;&#x2003;&#x2003;(Formula 2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0048" num="0047">When the absolute value is less than or equal to the predetermined value, the error refinement block <b>332</b> may determine the detected error block to be a normal or error-free block. The error refinement block <b>332</b> may output a block having no error to the frame generation block <b>334</b>. When the absolute value is greater than or equal to the predetermined value, the error refinement block <b>332</b> may determine the detected error block to be a block in which a final or confirmed error is generated, i.e., a confirmed error block or error block. The error refinement block <b>332</b> may output an error block to the error correction Filter (e.g., median filter) <b>334</b>.</p>
<p id="p-0049" num="0048">The error correction filter <b>333</b> may average pixel values of one or more blocks adjacent (preceding or subsequent) to or contiguous with the error block through the median filter to obtain an average value or compensation average value, thereby compensating the pixel value of the error block by the compensation average value (S<b>44</b>). The averaging process through the median filter may be performed according to the following formula.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>P</i><sub>gen</sub>(<i>x,y</i>)=[<i>P</i>(<i>x,y&#x2212;</i>1)+<i>P</i>(<i>x,y&#x2212;</i>3)+<i>P</i>(<i>x+</i>1<i>,y&#x2212;</i>2)+<i>P</i>(<i>x&#x2212;</i>1<i>,y&#x2212;</i>2)+<i>P</i>(<i>x,y+</i>1)+<i>P</i>(<i>x,y+</i>3)+<i>P</i>(<i>x+</i>1<i>,y+</i>2)]/7&#x2003;&#x2003;(Formula 3)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0050" num="0049">In Formula 3, P<sub>gen</sub>(x, y) may denote an average value operated through the median filter, and P(x, y) may denote a pixel value of the error block. Formula 3 may be modified to include one or more successive blocks.</p>
<p id="p-0051" num="0050">Next, the frame generation block <b>334</b> may restore an image frame including the compensated block on the basis of the block compensated from the error correction filter <b>333</b>, thereby outputting the restored image frame to the window interface <b>34</b> (S<b>46</b>).</p>
<p id="p-0052" num="0051">The window interface <b>34</b> may convert the inputted image frame into a corresponding format suitable for the display window <b>36</b>, and thereby output the converted image frame. The display window <b>36</b> may display the inputted image frame. A liquid crystal display (LCD), for example, may be used as the display window <b>36</b>.</p>
<p id="p-0053" num="0052">As aforementioned, according to the block error compensating apparatus of an image frame and the method thereof according to embodiments of the present invention, whether an error generation exists or not for the error-generated block may be re-confirmed thereby to enhance reliability.</p>
<p id="p-0054" num="0053">Also, according to the block error compensating apparatus of an image frame and the method thereof according to embodiments of the present invention, the block error-generated image frame may be compensated through the median filter thereby to be able to compensate a block error without an additional memory.</p>
<p id="p-0055" num="0054">In addition, according to the block error compensating apparatus of an image frame and the method thereof according to embodiments of the present invention, the block error generated image frame may be compensated through the median filter thereby to be able to compensate a block error in real time.</p>
<p id="p-0056" num="0055">As the present invention may be embodied in several forms without departing from the spirit or essential characteristics thereof, it should also be understood that the above-described embodiments are not limited by any of the details of the foregoing description, unless otherwise specified, but rather should be construed broadly within its spirit and scope as defined in the appended claims, and therefore all changes and modifications that fall within the metes and bounds of the claims, or equivalence of such metes and bounds are therefore intended to be embraced by the appended claims.</p>
<p id="p-0057" num="0056">The foregoing embodiments and advantages are merely exemplary and are not to be construed as limiting the present invention. The present teaching can be readily applied to other types of apparatuses. The description of the present invention is intended to be illustrative, and not to Limit the scope of the claims. Many alternatives, modifications, and variations will be apparent to those skilled in the art. In the claims, means-plus-function clauses are intended to cover the structures described herein as performing the recited function and not only structural equivalents but also equivalent structures.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>receiving a video signal including a plurality of video frames, at least one video frame having at least one target pixel block to be filtered;</claim-text>
<claim-text>filtering said target pixel block by using at least one pixel value of said target pixel block and multiple pixel values of one other pixel block adjacent to said target pixel block, said filtering being performed upon consideration of a frame type, said frame type including an intra-coded frame and a predictive-coded frame; and</claim-text>
<claim-text>storing said filtered video frame in a decoded frame buffer,</claim-text>
<claim-text>wherein said filtering comprises:</claim-text>
<claim-text>obtaining an absolute value of a result from calculations using a difference between said at least one pixel value of said target pixel block and at least one of said multiple pixel values of said one other pixel block;</claim-text>
<claim-text>obtaining, based on a comparison of said absolute value with a particular value, a compensation value calculated by using said at least one pixel value of said target pixel block and said multiple pixel values of said one other pixel block; and</claim-text>
<claim-text>applying said compensation value to compensate for said target pixel block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said target pixel block and said one other pixel block are separated by a pixel block boundary.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said filtering step is additionally performed with respect to another pixel block, said another pixel block being different from said one other
<claim-text>pixel block and adjacent to said target pixel block.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>decoding said plurality of video frames before performing said filtering step. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
