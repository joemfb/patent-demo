<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625773-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625773</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12106753</doc-number>
<date>20080421</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>739</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>3</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>L</subclass>
<main-group>11</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>37926506</main-classification>
<further-classification>704270</further-classification>
</classification-national>
<invention-title id="d2e53">System and method for analyzing automatic speech recognition performance data</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6233570</doc-number>
<kind>B1</kind>
<name>Horvitz et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6247149</doc-number>
<kind>B1</kind>
<name>Falls et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 45</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6405170</doc-number>
<kind>B1</kind>
<name>Phillips et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704270</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6904143</doc-number>
<kind>B1</kind>
<name>Peterson et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37926501</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7263489</doc-number>
<kind>B2</kind>
<name>Cohen et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704270</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2003/0078782</doc-number>
<kind>A1</kind>
<name>Blair</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2003/0105630</doc-number>
<kind>A1</kind>
<name>MacGinitie et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>15</number-of-claims>
<us-exemplary-claim>2</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>37926501-26514</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704270</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10683648</doc-number>
<date>20031010</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7383170</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12106753</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080228489</doc-number>
<kind>A1</kind>
<date>20080918</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Mills</last-name>
<first-name>Scott H.</first-name>
<address>
<city>Arlington</city>
<state>VA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Martin</last-name>
<first-name>John M.</first-name>
<address>
<city>Austin</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Mills</last-name>
<first-name>Scott H.</first-name>
<address>
<city>Arlington</city>
<state>VA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Martin</last-name>
<first-name>John M.</first-name>
<address>
<city>Austin</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Jackson Walker L.L.P.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>AT&#x26;T Intellectual Property I, L.P.</orgname>
<role>02</role>
<address>
<city>Atlanta</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Neway</last-name>
<first-name>Samuel G</first-name>
<department>2657</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">In a disclosed method for interpreting automatic speech recognition (ASR) performance data, a data processing system may receive user input that selects a log file to be processed. The log file may contain log records produced by an ASR system as a result of verbal interaction between an individual and the ASR system. In response to receiving the user input, the data processing system may automatically interpret data in the log records and generate interpretation results. The interpretation results may include a duration for a system prompt communicated to the individual by the ASR system, a user response to the system prompt, and a duration for the user response. The user response may include a textual representation of a verbal response from the individual, obtained through ASR. The interpretation results may also include an overall duration for the telephone call.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="141.65mm" wi="79.42mm" file="US08625773-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="214.71mm" wi="160.10mm" orientation="landscape" file="US08625773-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="204.22mm" wi="161.63mm" file="US08625773-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="181.19mm" wi="161.04mm" file="US08625773-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="149.78mm" wi="114.05mm" orientation="landscape" file="US08625773-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="212.77mm" wi="92.63mm" orientation="landscape" file="US08625773-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The present invention relates in general to information handling systems and, in particular, to a system, a method, and a program product for analyzing automatic speech recognition performance data.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Automatic speech recognition (ASR) technology has improved greatly in recent years, and various companies are beginning to use it to provide customer service, such as in interactive voice response (IVR) systems. Multiple vendors offer different forms of ASR technology, and customers may desire to analyze and compare competing ASR products before selecting a particular ASR product for implementation.</p>
<p id="p-0004" num="0003">For example, a company may desire to evaluate and compare selected ASR products or systems by conducting usability studies in which individuals, such as customers of the company, interact with the selected ASR systems by telephone. Each ASR system may interpret the participant's utterances and produce a log file detailing each event that occurs during a call. The ASR log files would thus contain ASR performance data. As recognized by the present invention, logs files produced by ASR products are difficult to analyze because of their content and form. The present invention addresses that difficulty.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0005" num="0004">A more complete understanding of the present invention and advantages thereof may be acquired by referring to the appended claims, the following description of one or more example embodiments, and the accompanying drawings, in which:</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 1</figref> depicts a block diagram of an example embodiment of a system for analyzing automatic speech recognition (ASR) performance data, according to the present disclosure;</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 2</figref> depicts a table that portrays example dialog involving an example ASR system;</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 3</figref> depicts a table that portrays an example log file to be processed by the ASR performance data analysis engine of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 4</figref> depicts an example embodiment of a user interface produced by the ASR performance data analysis engine of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 5</figref> depicts a flowchart of an example embodiment of a process for analyzing ASR performance data, according to the present disclosure;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 6</figref> depicts a table of example events, indicator strings, and automated processes according to the present disclosure; and</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 7</figref> depicts an example embodiment of interpretation results generated by the ASR performance data analysis engine of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF EXAMPLE EMBODIMENT(S)</heading>
<p id="p-0013" num="0012">The logs files produced by ASR products are difficult to analyze. Consequently, even though usability studies may be performed in which customers interact with different ASR systems by telephone, it is difficult to evaluate the performance of an ASR system and to compare the performance of different ASR systems.</p>
<p id="p-0014" num="0013">This document describes example embodiments of a system, a method, and a program product for analyzing ASR performance data. Advantages of various embodiments of the present invention may include making it easier to evaluate the performance of an individual ASR system and easier to compare the performance of different systems.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> depicts a block diagram of an example embodiment of a system for analyzing ASR performance data, according to the present disclosure. As illustrated, a data processing system <b>10</b> may include one or more central processing units (CPUs) <b>20</b> that communicate with input/output (I/O) components, data storage components, and other components via one or more system buses <b>50</b>. The I/O components in data processing system <b>10</b> may include one or more communications adapters, such as network adapter <b>32</b>, for communicating with remote systems or components, such as external data storage <b>36</b>, via a network <b>34</b>. The I/O components may further include one or more I/O modules <b>30</b> in communication with I/O devices such as a display <b>58</b>, a keyboard <b>52</b>, and a mouse <b>54</b>. The data storage components may include various volatile and non-volatile data storage devices. For instance, data processing system <b>10</b> may include one or more volatile data storage devices, such as random access memory (RAM) <b>24</b>, and non-volatile internal data storage <b>22</b>, such as one or more hard disk drives. Thus, data processing system <b>10</b> may use internal data storage <b>22</b>, external data storage <b>36</b>, or a combination of internal and external data storage devices.</p>
<p id="p-0016" num="0015">According to the illustrated embodiment, data processing system <b>10</b> may be used to host an ASR product, and also to analyze the performance of that ASR product. However, in alternative embodiments, separate data processing systems may be used for those two functions.</p>
<p id="p-0017" num="0016">During a study or trial, a human participant may interact with the ASR product or system by telephone. Each call can be characterized as a series of one or more dialogs or exchanges between the ASR system and the participant. The participant's utterances may include responses to verbal prompts, such as questions or instructions, generated by the ASR system. In general, a system generated prompt and the corresponding response, if any, may be referred to collectively as an &#x201c;individual exchange.&#x201d; Verbal interactions between the ASR system and a participant may be referred to in general as &#x201c;dialog.&#x201d;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> depicts a table that portrays example dialog involving an example ASR system. For instance, in a dialog, the ASR system may play a recording to prompt the participant. The participant may then respond with an utterance. The ASR system may then attempt to interpret the response using ASR. Based on the interpretation, or the failure to interpret, the ASR system may repeat the prompt, play a new prompt, end the call, or take some other action. Referring again to <figref idref="DRAWINGS">FIG. 1</figref>, the ASR system may include an ASR engine <b>40</b> that interprets the participant's utterances and produces a log file <b>42</b> detailing each event that occurs during the trial.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3</figref> depicts a table that portrays an example log file <b>42</b> from ASR engine <b>40</b>. As illustrated, log file <b>42</b> may include many different kinds of information. Much of the information may not be necessary for the purposes of a particular study. Log file <b>42</b> may also be formatted in a way that makes it difficult for a person to locate the information necessary for a particular study. The formatting may also make it difficult to decipher or understand that information. In addition, the log file may not directly contain all of the data of interest to a reviewer. For instance, it may be necessary to compute certain types of data, such as the duration of certain events, based on information in log file <b>42</b> such as start times and end times.</p>
<p id="p-0020" num="0019">Furthermore, multiple trials may be run to generate performance data from multiple ASR systems, and multiple participants may interact with each of those ASR systems. Consequently, the reviewer may be faced with the task of analyzing and comparing a large number of log files <b>42</b>.</p>
<p id="p-0021" num="0020">As illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, data processing system <b>10</b> includes an analysis engine <b>44</b> for automatically processing ASR performance data, such as the data in log file <b>42</b>. Analysis engine <b>44</b> may also be referred to as an ASR log analysis engine <b>44</b>.</p>
<p id="p-0022" num="0021">Data processing system <b>10</b> may also include a call-type file <b>43</b> and a substitutions file <b>45</b>. As described in greater detail below, analysis engine <b>44</b> may use call-type file <b>43</b> and substitutions file <b>45</b> to process log file <b>42</b>. For instance, call-type file <b>43</b> may contain event definitions that help analysis engine <b>44</b> interpret log file data, and substitutions file <b>45</b> may contain predefined replacement definitions to be applied to log files.</p>
<p id="p-0023" num="0022">In the illustrated embodiment, programs or applications such as analysis engine <b>44</b> may be copied from internal data storage <b>22</b> into RAM <b>24</b> for execution. Likewise, data to be processed, such as call-type file <b>43</b>, substitutions file <b>45</b>, log file <b>42</b>, or parts thereof, may be copied to RAM <b>24</b> for processing. Programs or data may also be retrieved by data processing system <b>10</b> from external data storage <b>36</b>.</p>
<p id="p-0024" num="0023">In operation, analysis engine <b>44</b> may generate one or more user interface screens to allow the user to set various parameters and execute various functions. For instance, <figref idref="DRAWINGS">FIG. 4</figref> depicts an example embodiment of a user interface screen <b>60</b> produced by analysis engine <b>44</b>. Screen <b>60</b> may also be referred to as a control panel <b>60</b>.</p>
<p id="p-0025" num="0024">As illustrated, control panel <b>60</b> allows the user to select and open input files and output files. In addition, control panel <b>60</b> allows the user to select and open call-type files and substitutions files. By selecting a file, the user may specify the file to be processed or generated by analysis engine <b>44</b>. Opening a file may cause the file to be opened in a new window, possibly in a new application, such as a spreadsheet or word processing application.</p>
<p id="p-0026" num="0025">Multiple substitutions files may be predefined, with each including data that analysis engine <b>44</b> may use to replace specified strings with specified replacement strings, during the process of analyzing or interpreting a selected log file. The different substitutions files may be used for processing log files from different ASR systems. Similarly, multiple call-type files may be predefined, with each including data that analysis engine <b>44</b> may use to interpret a selected log file. The different call-type files may be used to interpret log files from different ASR systems. Different call type files may associate different event indicator strings with the same event or event identifier.</p>
<p id="p-0027" num="0026">Control panel <b>60</b> may also allow the user to save the current settings, to specify whether column headers should be sent to the output file, and to initiate processing of the specified log file. A progress indicator may also be provided.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 5</figref> depicts a flowchart of an example embodiment of a process for analyzing ASR performance data, according to the present disclosure. The illustrated process is described with reference to operations performed by data processing system <b>10</b>. The process starts with a user having utilized control panel <b>60</b> to select log file <b>42</b> as the input file, output file <b>46</b> as the output file, call-type file <b>43</b> as the call-type file, and substitutions file <b>45</b> as the substitutions file.</p>
<p id="p-0029" num="0028">At block <b>100</b>, analysis engine <b>44</b> receives a command to start processing, for instance in response to a user clicking on process button <b>62</b> in <figref idref="DRAWINGS">FIG. 4</figref>. In response, analysis engine <b>44</b> may copy log file <b>42</b> into RAM <b>24</b>, and analysis engine <b>44</b> may automatically scan through that copy of log file <b>42</b>, performing string substitutions, in accordance with the predefined replacement definitions in substitutions file <b>45</b>, as shown at block <b>102</b>. For example, analysis engine <b>44</b> may change &#x201c;prompt audio/70.vox&#x201d; to &#x201c;Greeting,&#x201d; and analysis engine <b>44</b> may change &#x201c;prompt audio/11.vox&#x201d; to &#x201c;Opening prompt.&#x201d;</p>
<p id="p-0030" num="0029">Analysis engine <b>44</b> may then begin an iterative process of automatically extracting and translating data from the modified log file <b>42</b> in RAM <b>24</b>, based on call-type file <b>43</b>. For instance, as depicted at block <b>104</b>, analysis engine <b>44</b> may load call-type file <b>43</b> into RAM <b>24</b>. As shown at block <b>106</b>, analysis engine <b>44</b> may begin stepping through each line in log file <b>42</b> to find a relevant event.</p>
<p id="p-0031" num="0030">For example, call-type file <b>43</b> may contain a number of event definitions. An event definition may include a string that is known to correspond to a certain type of event in log files such as log file <b>42</b>. Such strings may be called event indicator strings. Analysis engine <b>44</b> may search for those strings when processing each line in log file <b>42</b>. An event definition may also include a standard identifier for a particular type of event or data, linking that type of event or data to a specific event indicator string. Analysis engine <b>44</b> may disregard any event in log file <b>42</b> that is not specified in call-type file <b>43</b>.</p>
<p id="p-0032" num="0031">As shown at block <b>110</b>, analysis engine <b>44</b> may determine whether the end of log file <b>42</b> was reached. If the end of the log file was not reached, analysis engine <b>44</b> may process the event that was found, as shown at block <b>112</b>. For example, as events are found, analysis engine <b>44</b> may store various values pertaining to the performance of the ASR system that produced log file <b>42</b>, and may compute various relevant performance metrics. Consequently, as described in greater detail below, analysis engine <b>44</b> may find and interpret specific, predefined call events or characteristics in log file <b>42</b>, based on the event definitions. Analysis engine <b>44</b> may also extract relevant values from log file <b>42</b>, based on the event indicator strings defined in call-type file <b>43</b>. For example, analysis engine <b>44</b> may extract the start time and date for the call, as well as a participant or customer identifier (&#x201c;ID&#x201d;).</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 6</figref> depicts a table of some example events, indicator strings, and automated processes according to the present disclosure. When processing the first line of log file <b>42</b>, for example, analysis engine <b>44</b> may recognize the event indicator string &#x201c;call_start,&#x201d; and, in response, record the call start time from the timestamp in that line as a characteristic for a standardized &#x201c;call start&#x201d; event. Those operations are represented by row <b>1</b> in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0034" num="0033">As indicated in row <b>2</b>, analysis engine <b>44</b> may then recognize the event indicator string &#x201c;log: SubjectID=&#x201d; in the third line of log file <b>42</b>, and, in response, record &#x201c;Ginny&#x201d; as the pertinent characteristic. As depicted in row <b>3</b>, analysis engine <b>44</b> may then recognize the event indicator string &#x201c;prompt audio/70.vox&#x201d; in the fifth line of log file <b>42</b>, and, in response, extract the start time for that prompt from the timestamp in that line. Alternatively, the fifth line of log file <b>42</b> may include the event indicator string &#x201c;Greeting&#x201d; instead of &#x201c;prompt audio/70.vox,&#x201d; pursuant to the substitution process described above, and analysis engine <b>44</b> may recognize and process &#x201c;Greeting&#x201d; as the event indicator string.</p>
<p id="p-0035" num="0034">Although <figref idref="DRAWINGS">FIG. 6</figref> illustrates examples of various types of events that may be recognized and processed by analysis engine <b>44</b>, many additional events, such as &#x201c;prompt end&#x201d; events, &#x201c;input end&#x201d; events, and other events or values, may also be recognized and processed by analysis engine <b>44</b>, in accordance with the approach described herein. For instance, analysis engine <b>44</b> may recognize the event indicator string &#x201c;prompt_end done:&#x201d; in line six of log file <b>42</b>, and, in response, may extract the end time from the timestamp in that line. Analysis engine <b>44</b> may then compute and record the prompt duration for the greeting, based on the pertinent start time and end time.</p>
<p id="p-0036" num="0035">Further examples of the performance metrics or characteristics that may be extracted or computed by analysis engine <b>44</b> may include, without limitation, the following:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0036">the duration of each individual exchange;</li>
        <li id="ul0002-0002" num="0037">the duration of each prompt;</li>
        <li id="ul0002-0003" num="0038">the duration of the caller's utterance;</li>
        <li id="ul0002-0004" num="0039">the latency or time interval between the end of the prompt and the beginning of the caller's utterance;</li>
        <li id="ul0002-0005" num="0040">the results of the attempts by the ASR system to recognize the caller's utterance;</li>
        <li id="ul0002-0006" num="0041">the duration of the entire call.
<br/>
Additional event definitions may be predefined, with event indicator strings for events relevant to any particular project.
</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0037" num="0042">The data values and performance metrics that are recognized or generated during the process of finding and processing events may be referred to in general as interpretation results. According to the example embodiment, some or all of the interpretation results may ultimately be saved in output file <b>46</b>, in internal data storage <b>22</b> or in external data storage <b>36</b>, displayed on display device <b>58</b>, and/or printed.</p>
<p id="p-0038" num="0043"><figref idref="DRAWINGS">FIG. 7</figref> depicts example interpretation results that may be generated by analysis engine <b>44</b> and saved in output file <b>46</b>. The interpretation results may be categorized as general characteristics and exchange characteristics. The general characteristics and the exchange characteristics may also be referred to as general analysis results and exchange analysis results, respectively. The general characteristics may include values that pertain to an entire call, such as the ID of the participant, the duration of the call, etc. In <figref idref="DRAWINGS">FIG. 7</figref>, general characteristics and labels for those values are presented in the first two rows. According to the example embodiment, exchange characteristics may include values pertaining to individual exchanges within a call. The labels and values starting at row four in <figref idref="DRAWINGS">FIG. 7</figref> may represent exchange characteristics.</p>
<p id="p-0039" num="0044">For example, the duration of individual exchanges are depicted under the heading &#x201c;DLGDUR.&#x201d; The duration of prompts are depicted under the heading &#x201c;PRMTDUR.&#x201d; The results of attempts by the ASR system to recognize speech are depicted under the heading &#x201c;RECRSLT.&#x201d; Identifiers or names for the different messages played by the ASR system are listed under the heading &#x201c;PROMPTNAME.&#x201d; In addition, a dialog may include a group of prompts. Thus, there may be several prompt names within a given dialog name listed under the heading &#x201c;DLGNAME&#x201d;. Analysis engine <b>44</b> may extract the prompt names, the dialog names, and other data from log file <b>42</b> after some or all of those names have been provided pursuant to the substitution process described above. Data that indicates whether the prompt played to completion or whether, instead, the prompt ended early may be depicted under the heading &#x201c;PRMTENDTYPE.&#x201d; For instance, if a caller barges in with a response while a prompt is still playing, the ASR system may terminate the prompt as soon as it detects the speech.</p>
<p id="p-0040" num="0045">Referring again to <figref idref="DRAWINGS">FIG. 5</figref>, after analysis engine <b>44</b> processes an event, analysis engine <b>44</b> may search log file <b>42</b> for the next event, as indicated by the arrow returning to block <b>106</b> from block <b>112</b>. As indicated at block <b>120</b>, after all of the lines in log file <b>42</b> have been analyzed, analysis engine <b>44</b> may compute the general analysis results, such as the duration of the entire call listed under the heading &#x201c;CALLDUR,&#x201d; and the total amount of time spent playing prompts. Other general analysis results may include, without limitation, the following:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0046">an identifier for the participant or subject under &#x201c;SUBID,&#x201d;</li>
        <li id="ul0004-0002" num="0047">an identifier for a particular call to distinguish multiple calls from the same subject under &#x201c;CALLNUM,&#x201d;</li>
        <li id="ul0004-0003" num="0048">identifiers for different call designs being tested under &#x201c;PATH,&#x201d;</li>
        <li id="ul0004-0004" num="0049">the date and time the call started,</li>
        <li id="ul0004-0005" num="0050">the duration of time spent in dialog between the caller and the ASR system under &#x201c;ASRDUR,&#x201d;</li>
        <li id="ul0004-0006" num="0051">the elapsed time between termination of the ASR dialog and pick up by the operator under &#x201c;GETOPDUR,&#x201d;</li>
        <li id="ul0004-0007" num="0052">the time duration for &#x201c;storing and forwarding&#x201d; the information received from the subject to the operator under &#x201c;SAFDUR,&#x201d; and</li>
        <li id="ul0004-0008" num="0053">the time duration spent with the subject connected to the live operator under &#x201c;LIVEDUR.&#x201d;</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0041" num="0054">As illustrated at block <b>122</b>, analysis engine <b>44</b> may then save the interpretation results to output file <b>46</b>. The automated interpretation process may then end. A user may then open output file <b>46</b>, for instance by selecting the &#x201c;Open Output File&#x201d; button on control panel <b>60</b>.</p>
<p id="p-0042" num="0055">By using the approach described above, analysis engine <b>44</b> may generate output file <b>46</b> with format and content that may be understood by a person with relative ease, compared to log file <b>42</b>. Output file <b>46</b> may omit unnecessary information, and may include results that were computed by analysis engine <b>44</b>, possibly without including the data values used in such computations. In one embodiment, the interpretation results may reproduce less than half of the data from the log file. In alternative embodiments, the interpretation results may reproduce less than seventy-five percent of the data from the log file.</p>
<p id="p-0043" num="0056">Although the present invention has been described with reference to various example embodiments, those with ordinary skill in the art will understand that numerous variations of those embodiments could be practiced without departing from the scope and spirit of the present invention. For example, one of ordinary skill will appreciate that alternative embodiments could be deployed with many variations in the number and type of components in the system, the network protocols, the system or network topology, the distribution of various software and data components among the data processing systems in the network, and myriad other details (e.g., the length of various fields or columns, the number of columns, and other characteristics of the output.) without departing from the present invention.</p>
<p id="p-0044" num="0057">It should also be noted that the hardware and software components depicted in the example embodiment represent functional elements that are reasonably self-contained so that each can be designed, constructed, or updated substantially independently of the others. In alternative embodiments, however, it should be understood that the components may be implemented as hardware, software, or combinations of hardware and software for providing the functionality described and illustrated herein. In alternative embodiments, information handling systems incorporating the invention may include personal computers, mini computers, mainframe computers, distributed computing systems, and other suitable devices.</p>
<p id="p-0045" num="0058">In alternative embodiments, the trial of the ASR system may be performed by one data processing system, and the performance analysis may be performed by a different data processing system, with reference to the results from the trial. Similarly, one or more of the components illustrated as residing in internal data storage may instead reside in external data storage.</p>
<p id="p-0046" num="0059">Alternative embodiments of the invention also include computer-usable media encoding logic such as computer instructions for performing the operations of the invention. Such computer-usable media may include, without limitation, storage media such as floppy disks, hard disks, CD-ROMs, read-only memory, and random access memory; as well as communications media such as wires, optical fibers, microwaves, radio waves, and other electromagnetic or optical carriers. The control logic may also be referred to as a program product.</p>
<p id="p-0047" num="0060">Many other aspects of the example embodiment may also be changed in alternative embodiments without departing from the scope and spirit of the invention. The scope of the invention is therefore not limited to the particulars of the embodiments or implementations illustrated herein, but is defined by the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for interpreting automatic speech recognition performance data, the method comprising:
<claim-text>in response to receiving first user input indicative of a log file, selecting, by a data processing system, the log file for processing, wherein the log file contains log records produced by an automatic speech recognition system as a result of verbal interaction between an individual and the automatic speech recognition system during a telephone call;</claim-text>
<claim-text>receiving second user input indicative of a call-type file containing a list of event definition strings, wherein each event definition string listed includes a character string indicating a corresponding event type;</claim-text>
<claim-text>interpreting log records associated with event types listed in the call-type file and disregarding log records not associated with event types listed in the call-type file, wherein the name of the individual is an event type defined in the call-type file;</claim-text>
<claim-text>generating interpretation results including general analysis results and exchange analysis results; and</claim-text>
<claim-text>generating an output file including the interpretations results;</claim-text>
<claim-text>wherein the general analysis results in the output file include:
<claim-text>an identifier for the individual, a date for the telephone call, a start time for the telephone call, an end time for the telephone call, an overall duration for the telephone call, a total amount of time spent playing prompts, an identifier for a particular call to distinguish multiple calls from the same individual, an identifier to indicate one of multiple call designs being tested, a duration of time spent in dialog between the caller and the ASR system, the elapsed time between termination of the automatic speech recognition dialog and pick up by an operator, the time duration for storing and forwarding information received from the individual to the operator, and the time duration spent with the subject connected to the operator; and</claim-text>
</claim-text>
<claim-text>wherein the exchange analysis results in the output file include:
<claim-text>an identifier for a system prompt communicated to the individual by the automatic speech recognition system and a user response to the system prompt, wherein the user response includes a textual representation of a verbal response from the individual, and a duration for the user response; and</claim-text>
<claim-text>wherein the exchange analysis results group the identifier for the system prompt, the user response, and the duration for the user response.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A method for interpreting automatic speech recognition performance data, the method comprising:
<claim-text>in response to receiving, by a data processing system, first user input, selecting, by the data processing system, a log file containing log records indicative of an interaction between an individual and an automatic speech recognition system, wherein the name of the individual is indicated by the first user input;</claim-text>
<claim-text>in response to receiving a second user input, selecting a substitutions file including a set of original character strings and a corresponding set of replacement character strings, wherein the replacement character strings are human-readable text strings;</claim-text>
<claim-text>replacing a log record character string that matches one of the set of original character strings with a corresponding one of the set of replacement character strings; and</claim-text>
<claim-text>after replacing the log record character string, interpreting the log records and generating interpretation results including general analysis results and exchange analysis results;</claim-text>
<claim-text>generating an output file including the interpretations results;</claim-text>
<claim-text>wherein the general analysis results in the output file include:
<claim-text>an identifier for the individual, a date for the telephone call, a start time for the telephone call, an end time for the telephone call, an overall duration for the telephone call, a total amount of time spent playing prompts, an identifier for a particular call to distinguish multiple calls from the same individual, an identifier to indicate one of multiple call designs being tested, a duration of time spent in dialog between the caller and the ASR system, the elapsed time between termination of the automatic speech recognition dialog and pick up by the operator, the time duration for storing and forwarding information received from the individual to the operator, and the time duration spent with the subject connected to the operator;</claim-text>
<claim-text>wherein the interpretation results in the output file include a duration for a time interval between the end of a system prompt communicated to the individual by the automatic speech recognition system and a response from the individual to the system prompt.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the interaction occurred during a telephone call.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein interpreting the log records and generating the interpretation results includes:
<claim-text>identifying a start time for the system prompt within the log file;</claim-text>
<claim-text>identifying an end time for the system prompt within the log file; and</claim-text>
<claim-text>computing the duration for the system prompt based on the start time and the end time.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein interpreting the log records and generating the interpretation results includes:
<claim-text>identifying a start time for the response from the individual within the log file;</claim-text>
<claim-text>identifying an end time for the response from the individual within the log file; and</claim-text>
<claim-text>computing the duration for the response from the individual based on the start time and the end time.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein generating the interpretation results includes:
<claim-text>generating interpretation results that reproduce less than seventy-five percent of data from the log file.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein generating the interpretation results includes:
<claim-text>generating interpretation results that reproduce less than half of data from the log file.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A non-transitory computer readable medium including stored, processor executable instructions that, when executed by a processor, cause the processor to perform operations comprising:
<claim-text>selecting a log file to be processed in response to receiving a first user input during a telephone call, wherein selection of the log file is based on a name of an individual and further wherein the log file contains log records indicative of an interaction between the individual and an automatic speech recognition system;</claim-text>
<claim-text>selecting, in response to receiving a second user input, a substitutions file for use by the processor in the processing of the log file;</claim-text>
<claim-text>substituting replacement character strings for log record character strings that match original character strings, wherein the replacement character strings and the corresponding original character strings are listed in the substitutions file, and wherein the replacement character strings are human-readable text strings; and</claim-text>
<claim-text>interpreting data in the log records and generating interpretation results including general analysis results and exchange analysis results;</claim-text>
<claim-text>generating an output file including the interpretations results;</claim-text>
<claim-text>wherein the general analysis results in the output file include:
<claim-text>an identifier for the individual, a date for the telephone call, a start time for the telephone call, an end time for the telephone call, an overall duration for the telephone call, a total amount of time spent playing prompts, an identifier for a particular call to distinguish multiple calls from the same individual, an identifier to indicate one of multiple call designs being tested, a duration of time spent in dialog between the caller and the ASR system, the elapsed time between termination of the automatic speech recognition dialog and pick up by an operator, the time duration for storing and forwarding information received from the individual to the operator, and the time duration spent with the subject connected to the operator;</claim-text>
<claim-text>wherein the generated interpretation results include a duration for a time interval between the end of a system prompt communicated to the individual by the automatic speech recognition system and a user response to the system prompt.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The non-transitory computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein interpreting data in the log records and generating the interpretation results comprises:
<claim-text>identifying a start time for the system prompt within the log file;</claim-text>
<claim-text>identifying an end time for the system prompt within the log file; and</claim-text>
<claim-text>computing the duration for the system prompt, based on the start time and the end time.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The non-transitory computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein interpreting the data in the log records and generating the interpretation results comprises:
<claim-text>identifying a start time for the user response within the log file;</claim-text>
<claim-text>identifying an end time for the user response within the log file; and</claim-text>
<claim-text>computing the duration for the user response, based on the start time and the end time.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The non-transitory computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein generating the interpretation results includes:
<claim-text>generating interpretation results that reproduce less than seventy-five percent of data from the log file.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The non-transitory computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein generating the interpretation results includes:
<claim-text>generating interpretation results that reproduce less than half of data from the log file.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The non-transitory computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein:
<claim-text>the exchange analysis results include the duration for the system prompt, the user response to the system prompt, and the duration for the user response.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The non-transitory computer readable medium of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein generating the interpretation results includes grouping the general analysis results together and grouping the exchange analysis results together.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein selecting the substitutions file includes selecting the substitutions file corresponding to a type of the automatic speech recognition system. </claim-text>
</claim>
</claims>
</us-patent-grant>
