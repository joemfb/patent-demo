<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626443-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626443</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13496889</doc-number>
<date>20100920</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>DE</country>
<doc-number>10 2009 041 837</doc-number>
<date>20090918</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>C</subclass>
<main-group>21</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>08</class>
<subclass>G</subclass>
<main-group>1</main-group>
<subgroup>123</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>701532</main-classification>
</classification-national>
<invention-title id="d2e61">Method for creating a map relating to location-related data on the probability of future movement of a person</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5543802</doc-number>
<kind>A</kind>
<name>Villevieille et al.</name>
<date>19960800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34235751</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6323807</doc-number>
<kind>B1</kind>
<name>Golding et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>342419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2006/0247847</doc-number>
<kind>A1</kind>
<name>Carter et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701200</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2010/0125409</doc-number>
<kind>A1</kind>
<name>Prehofer</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701207</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2010/0305858</doc-number>
<kind>A1</kind>
<name>Richardson</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701301</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2011/0010033</doc-number>
<kind>A1</kind>
<name>Asahara et al.</name>
<date>20110100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701 26</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2011/0282571</doc-number>
<kind>A1</kind>
<name>Krumm et al.</name>
<date>20111100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701200</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2012/0035823</doc-number>
<kind>A1</kind>
<name>Carter et al.</name>
<date>20120200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701 70</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2012/0191505</doc-number>
<kind>A1</kind>
<name>Shang et al.</name>
<date>20120700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705  731</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2012/0215586</doc-number>
<kind>A1</kind>
<name>Shang et al.</name>
<date>20120800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705  731</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2012/0239291</doc-number>
<kind>A1</kind>
<name>Do</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701451</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>Krach B et al: &#x201c;Cascaded estimation architecture for integration of foot-mounted inertial sensors&#x201d;, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Krach B et al: &#x201c;Integration of foot-mounted inertial sensors into a Bayesian location estimation framework&#x201d;, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>International Search Report for corresponding patent application No. PCT/EP2010/063778 dated Dec. 8, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>701120</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701532</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120232795</doc-number>
<kind>A1</kind>
<date>20120913</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Robertson</last-name>
<first-name>Patrick</first-name>
<address>
<city>Ammerland</city>
<country>DE</country>
</address>
</addressbook>
<residence>
<country>DE</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Angermann</last-name>
<first-name>Michael</first-name>
<address>
<city>Graefelfing</city>
<country>DE</country>
</address>
</addressbook>
<residence>
<country>DE</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Krach</last-name>
<first-name>Bernhard</first-name>
<address>
<city>Hilpoltstein</city>
<country>DE</country>
</address>
</addressbook>
<residence>
<country>DE</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Robertson</last-name>
<first-name>Patrick</first-name>
<address>
<city>Ammerland</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Angermann</last-name>
<first-name>Michael</first-name>
<address>
<city>Graefelfing</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Krach</last-name>
<first-name>Bernhard</first-name>
<address>
<city>Hilpoltstein</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Renner, Otto, Boisselle &#x26; Sklar, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Deutsches Zentrum f&#xfc;r Luft&#x2014;und Raumfahrt e.V.</orgname>
<role>03</role>
<address>
<city>Cologne</city>
<country>DE</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Cheung</last-name>
<first-name>Mary</first-name>
<department>3667</department>
</primary-examiner>
<assistant-examiner>
<last-name>Brushaber</last-name>
<first-name>Frederick</first-name>
</assistant-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/EP2010/063778</doc-number>
<kind>00</kind>
<date>20100920</date>
</document-id>
<us-371c124-date>
<date>20120604</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2011/033100</doc-number>
<kind>A </kind>
<date>20110324</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The invention relates to a method for creating a map relating to location-related data on the likelihood of the future movement of a person in a spatial environment, such as a building, forest, tunnel system or public place, and in particular a shopping center, airport or train station. In the method according to the invention, at least one person is supplied with one or more sensors (e.g. inertial sensors, rotation rate sensors, optical sensors) for odometrical measurement (odometry) (e.g. attached to a shoe), wherein the odometry has errors due to inherent measurement inaccuracies of the sensor(s) (e.g. angle deviations, length deviations). The at least one person moves by foot through the spatial environment. Information regarding the pedestrian step lengths and/or pedestrian step direction and/or orientation of the sensor or the person (called odometry information Z<sup>u</sup>) is determined from the measurement signals of the sensor(s). Based on said odometry information, a map is created using a Bayesian estimator (e.g. particle filter, Rao-Blackwellized particle filter, Kalman filter, Mone-Cario hypothesis filter or combined forms of such filters), the state-variable space thereof (e.g. hypothetical space of the particle of a particle filter) comprising both the current pedestrian step (pedestrian step length and optionally movement direction change as well) of the person U, odometry errors E (e.g. drift parameters with respect to the determined pedestrian step lengths and/or pedestrian step direction and/or orientation of the sensor or the person) and also the location-related data on the probabilities of the future movement of the person.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="134.11mm" wi="195.33mm" file="US08626443-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="221.91mm" wi="159.34mm" orientation="landscape" file="US08626443-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="148.67mm" wi="158.41mm" orientation="landscape" file="US08626443-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="197.70mm" wi="140.80mm" orientation="landscape" file="US08626443-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="216.24mm" wi="158.07mm" orientation="landscape" file="US08626443-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="211.50mm" wi="170.69mm" orientation="landscape" file="US08626443-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="227.50mm" wi="173.14mm" orientation="landscape" file="US08626443-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="206.59mm" wi="145.20mm" orientation="landscape" file="US08626443-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="184.83mm" wi="148.34mm" orientation="landscape" file="US08626443-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="198.63mm" wi="152.40mm" orientation="landscape" file="US08626443-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="156.80mm" wi="150.20mm" orientation="landscape" file="US08626443-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="168.74mm" wi="178.48mm" orientation="landscape" file="US08626443-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="168.15mm" wi="167.81mm" orientation="landscape" file="US08626443-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="167.22mm" wi="177.55mm" orientation="landscape" file="US08626443-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="219.37mm" wi="133.86mm" orientation="landscape" file="US08626443-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">The invention relates to a method for creating a map relating to location-related data on the probability of the future movement of a person in a spatial environment. The invention particularly relates to a method for the creating of route maps and floor plans inside and outside of buildings by evaluation of sensors carried by persons.</p>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">The positioning of persons and goods is presently often carried out by use of satellite navigation (e.g. GPS), which, when performed outside of buildings, can yield acceptable accuracies also in case of pedestrians. Within buildings, as well as in areas where the visible range of the sky is considerably blocked from view (e.g. urban canyons, shopping malls, inner courts, railroad stations with partial roofing), there are often massive disturbances caused by shading of the direct signal path from the satellite, or multi-path errors may occur. As a remedy in such situations, use is made in principle of two options&#x2014;which can also be combined:</p>
<p id="p-0004" num="0003">1) the use of further radio systems for positioning which allow for reception also within buildings (e.g. Wireless LAN, mobile radio, Ultra Wide Band&#x2014;UWB),</p>
<p id="p-0005" num="0004">2) the use of sensor technology adapted to obtain information on the movement of the pedestrian or another body (e.g. inertial sensor technology, odometry in robots, barometric altimeters, passive and active sensors/systems).</p>
<p id="p-0006" num="0005">A combination of various systems, signals and sensors is referred to as a sensor fusion; it is a suitable method particularly for dynamic bodies (thus, e.g., pedestrians, robots) for connecting the systems to each other in an optimum manner. A further option for improving the accuracy is the use of information on the environment, such as e.g. building floor plans. In &#x201c;Integration of Foot-Mounted Inertial Sensors into a Bayesian Location Estimation Framework&#x201d;, Krach, Bernhard and Robertson, Patrick (2008), in WPNC 2008, 2008 Mar. 27, Hannover, and &#x201c;Cascaded Estimation Architecture for Integration of Foot-Mounted Inertial Sensors&#x201d;, Krach, Bernhard and Robertson, Patrick (2008), in PLANS 2008, 2008 May 5-2008 May 8, Monterey, Calif., USA, it is demonstrated that prior knowledge of building floor plans and the mere use of an inertial sensor worn on the shoe (Inertial Measurement Unit for all three spatial axes&#x2014;IMU) is suited for an unambiguous positioning of a pedestrian in the building. This known method is an important basis for the present application and will be explained in greater detail hereunder:</p>
<p id="p-0007" num="0006">The pedestrian wears, on his/her shoe, an IMU whose acceleration and rotation-rate signals will be processed in an Extended Kalman Filter (EKF) so as to estimate the position of the shoe&#x2014;and thus of the person. In order to reduce the problem of the continuously increasing error (&#x201c;drift&#x201d;), use is made of so-called Zero Velocity Updates (ZUPTs) so that, in the phases when the foot is resting on the ground, the EKF can be set to zero velocity (so-called pseudo measurement). The resting phases of the foot can be determined in a quite reliable and simple manner by evaluating the acceleration and rotation rates of the IMU since each pedestrian step made by a human involves the occurrence of a characteristic pattern. The use of the EKF and of the ZUPT in this manner was introduced by Foxlin (see Pedestrian Tracking with Shoe-Mounted Inertial Sensors, Eric Foxlin, November/December 2005, published by the IEEE Computer Society 0272-1716/05 2005 IEEE). This method, however, has the disadvantage that the errors&#x2014;increased by the drift&#x2014;of the orientation about the vertical axis (&#x201c;heading&#x201d;) are only poorly observable by the ZUPT, thus causing an increasing inaccuracy primarily of the person's direction. This is also the case&#x2014;even through to a lesser extent&#x2014;for the length of path that has been covered. Further, this system, if used alone, will generally only allow for a relative positioning (i.e. in relation to a known starting point). As described above, according to the publications by Krach and Robertson, there could be used an additional hypothesis filter (hereunder also referred to as a particle filter) so as to determine, together with known maps, the position in space in that the &#x201c;particles&#x201d; (also referred to as &#x201c;hypotheses&#x201d; but hereunder being called &#x201c;particle&#x201d;) are moved according to the measured pedestrian step estimation of the EFK (which mathematically corresponds to the derivation of a new state of the particle from the proposal function of the particle filter), however, with a respectively different assumed deviation of pedestrian step direction and pedestrian step length. Thus, the hypotheses will &#x201c;fathom&#x201d; all possible deviations of the EKF pedestrian step length determination from the real sequence of the person's pedestrian steps. Such hypotheses, normally ranging within the known walls and obstacles, will&#x2014;as one possibility&#x2014;be &#x201c;rewarded&#x201d;, by a high likelihood, in the &#x201c;update&#x201d; or &#x201c;prediction&#x201d; part of the &#x201c;particle filter&#x201d; (PF) algorithm, and will be allowed to be continued in the next time-instant step of the PF algorithm. Those hypotheses which represent &#x201c;pedestrian steps through walls&#x201d; will either be directly eliminated or be penalized more less strongly. A disadvantage of this method resides in the requirement for existing knowledge on the walls (building floor plan).</p>
<p id="p-0008" num="0007">Plans (building floor plans) of existing buildings (or maps of existing paths) are normally established by use of means from the field of surveying technology which are expensive and complex. Often, building floor plans from the construction or planning phase of a building exist as hardcopies; these would either have to be manually scanned (with subsequent post-editing) or be automatically scanned (digitized) and processed to make it possible to detect e.g. walls. This process is expensive and prone to errors. Further, it will not detect various local conditions within/on a building, although these could be useful in the positioning according to the above method because they restrict the possible movement of the hypotheses&#x2014;e.g. obstacles such as larger pieces of furniture, exhibition objects, large plant arrangements, barriers, temporary or permanent stands, bars, seating arrangements, partition walls etc.</p>
<p id="p-0009" num="0008">Building floor plans and route networks are of value also outside the application for the mere positioning: in the simulating, adapting and checking of escape routes, in the optimizing and planning of buildings, structures and resources (e.g. optimization of an airport or hospital by use of the knowledge about spatial movement of persons and goods), in interventions by public authorities (e.g. in the fight against terrorism, in the freeing of hostages or in covert investigations), in cases of emergency such as large fires, in mass events (e.g. for analyzing the flows of large masses of people), in routing systems, in logistics (e.g. storage, process optimization), and in electronic assistants such as e.g. electronic navigation systems or museum guides. For a large number of the enumerated applications, such plans are valuable especially if not only the walls are known but also the routes actually used by persons&#x2014;while such routes can be determined also by pieces of furniture and by other obstacles.</p>
<heading id="h-0002" level="1">PROBLEMS</heading>
<p id="p-0010" num="0009">There exists a need for a system and a method for detecting building floor plans and/or route networks particularly pertaining to pedestrians. One application of such a system and method is&#x2014;based on said detection&#x2014;the positioning and navigation of pedestrians within buildings and outside buildings. The system and method shall not be dependent on measurement instruments and shall be capable to quickly adapt to new situations and to changes in the environment. Further, the system and method shall be capable of imaging particularly such characteristics of the environment which have a strong influence on the real movement of pedestrians.</p>
<heading id="h-0003" level="1">THE IDEA OF THE INVENTION</heading>
<p id="p-0011" num="0010">The invention proposes a method for creating a map relating to location-related data on the likelihood of the future movement of a person in a spatial environment, wherein, in said method,
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0011">at least one person carries one or more sensors (e.g. inertial sensors, rotation-rate sensors, optical sensors) for odometrical measurement (odometry) (e.g. attached to a shoe), wherein the odometry is error-prone due to inherent measurement inaccuracies of the sensor(s) (e.g. angle deviations, length deviations),</li>
        <li id="ul0002-0002" num="0012">the at least one person moves by foot through the spatial environment,</li>
        <li id="ul0002-0003" num="0013">information regarding the pedestrian step lengths and/or pedestrian step direction and/or orientation of the sensor or the person (called odometry information Z) is determined from the measurement signals of the sensor(s),</li>
        <li id="ul0002-0004" num="0014">based on said odometry information, a map is created using a Bayesian estimator (e.g. particle filter, Rao-Blackwellized particle filter, Kalman filter, Monte-Carlo hypothesis filter or combined forms of such filters), the state-variant space thereof (e.g. hypothetical space of the hypotheses of a particle filter) comprising both the current pedestrian step (pedestrian step length and optionally movement direction change as well) of the person U, odometry errors E (e.g. drift parameters with respect to the determined pedestrian step lengths and/or pedestrian step direction and/or orientation of the sensor or the person) and also the location-related data on the probabilities of the future movement of the person.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0012" num="0015">A &#x201c;particle filter&#x201d; in the sense of the invention is to be understood as a hypothesis filter which is a numerical method by which a plurality of &#x201c;hypotheses&#x201d; are dealt with in order to solve a dynamic estimation problem in an approximative manner. In this regard, each hypothesis and respectively each &#x201c;particle&#x201d; represents a point in the mostly three-dimensional state-variant space. According to the so-called &#x201c;importance sampling&#x201d; principle, a new value is assigned to each hypothesis or each &#x201c;particle&#x201d; in the state-variant space in each time-instant step of the numerical method. Subsequently, each hypothesis (particle) will be weighted by a weighting factor and thus be evaluated.</p>
<p id="p-0013" num="0016">&#x201c;Importance sampling&#x201d; in the sense of the invention is to be understood as a numerical representation of the likelihood density function P of a mostly multi-dimensional state variable. A concrete realization of this state variable corresponds to a point in the state-variant space. In &#x201c;importance sampling&#x201d;, there is extracted, from a likelihood density function P (also referred to as &#x201c;proposal density&#x201d;), a quantity of concrete realizations of a proposal random variable. This &#x201c;proposal density&#x201d; should have the largest possible similarities to the desired likelihood density function P. The quantity of the thus &#x201c;drawn&#x201d; concrete realizations of the proposal random variable represents the approximation to the likelihood density function P. To each concrete realization of the random variable, there is assigned a weighting factor which considers the difference between the &#x201c;proposal density&#x201d; and the desired likelihood density function P. If a favorable &#x201c;proposal density&#x201d; has been selected, there will be a lesser number of those concrete realizations of the proposal random variable which have relatively low weightings and thus, even though they require expenditure for storage and computation, will offer a lesser contribution to a more precise representation of the likelihood density function P.</p>
<p id="p-0014" num="0017">Further, it can be provided that said map is created with a delay during the movement of the person through the environment or after storage of the sensor measurement signals or the detected odometry information.</p>
<p id="p-0015" num="0018">The computations for creating the map can be performed either on an end device which is carried along (e.g. a mobile phone, PDA, portable computer), or on a server.</p>
<p id="p-0016" num="0019">Advantageously, the created map is used either for positioning or routing of the person or for improved positioning or routing of other persons.</p>
<p id="p-0017" num="0020">For improvement of the odometry information, use can be made of measurement signals/data of further sensors, e.g. satellite navigation, magnetic compass, WLAN, measurements for positioning, mobile phone position measurements, UWB measurements for positioning, and/or use can made of partial regions of a map of the environment for restricting the state space of the Bayesian estimator which is used according to the invention.</p>
<p id="p-0018" num="0021">A modification of the method is characterized in that use is made of real or virtual reference marks which can be perceived by the person and whose presence and optionally position are included as further parameters into the state space of the Bayesian estimator, e.g. by a man/machine interface arranged close to the person, such as e.g. a button, a key, voice input.</p>
<p id="p-0019" num="0022">Further, the method can be combined with optical SLAM methods known from robotics by including, into the determining of the state space of the Bayesian estimator, the visual features measured by optical sensors, e.g. by entering them as contributing factors into the weight computation and/or as the &#x201c;importance sampling&#x201d; step of the particle&#x2014;e.g. as a multiplicative term in the weight, wherein each particle now also carries the state of each observed visual feature and adapts the location and spatial position and the accuracy thereof to the current observation of the features and of the other conditions of the particle, and wherein, further, in the same manner, also features of ultrasonic or infrared or microwave sensor systems can be used which thus can be considered and used as parts of the created map and/or can improve the creating of the map on the basis of odometry.</p>
<p id="p-0020" num="0023">Further, use can be made of magnetic sensors (e.g. electronic magnetic field sensors), by including the respective strength and direction of the local magnetic field as a feature and entering them corresponding to a visual feature into the computations.</p>
<p id="p-0021" num="0024">It can be provided that the person is provided with a plurality of sensors for reducing odometry errors (e.g. the drift), wherein an improved odometry can be achieved by combining the measurement signals of the plurality of sensors (e.g. averaging of the odometry information or averaging the raw data of the sensors).</p>
<p id="p-0022" num="0025">Further, it can be provided that sensors for odometry are placed on parts of the body other than the feet/shoes, and that methods known from Pedestrian Dead Reckoning are used for computation and respectively improvement of the odometry.</p>
<p id="p-0023" num="0026">As a proposal density of the Bayesian estimator (e.g. particle filter), use can be made of the following mathematical product: the conditioned likelihood density of the current odometry errors E, conditioned to the odometry errors in the last time-instant step, multiplied by the conditioned likelihood density of the current pedestrian step vector U, conditioned to the current odometry information Z<sup>u </sup>and the current drift parameter E.</p>
<p id="p-0024" num="0027">A map in the sense of the invention is to be understood as comprising location-related data on the likelihood of the future movement of a person in a spatial environment (P-map). When creating such maps, use can be made of data on transition probabilities over edges of spatially arranged polygons (e.g. hexagons, rectangles, triangles, other polygons), wherein, in case of realization by means of a particle filter, the edge transitions of the particle at each polygon transition for this particle are counted and included into a weight computation.</p>
<p id="p-0025" num="0028">If polygons are used, the counters are preferably updated and stored only for one edge between two adjacent polygons and not individually for all edges of all polygons, whereby the required storage capacity can be distinctly reduced.</p>
<p id="p-0026" num="0029">Suitably, use is made of visual odometry methods known from robotics (e.g. the &#x201c;Lucas Kanade&#x201d; or &#x201c;Focus of Expansion&#x201d; methods), wherein, with the aid of optical sensors (e.g. camera), use is made e.g. of the change of the appearance of the environment for estimating the change of location and position of the person.</p>
<p id="p-0027" num="0030">When using polygon representations (e.g. hexagon) of the map, it is preferred that the polygon grid is adapted to the environment so as to be configured with varying density, wherein the polygons can overlap and/or a plurality of polygon planes can be used hierarchically and the transition counters are computed separately for each plane, and wherein, in the weight computation of the particle (of a particle filter), all planes are included (e.g. multiplicatively in the weight), and then, as a map, there will be output e.g. all planes created in this manner.</p>
<p id="p-0028" num="0031">When using polygons for the map, the polygons are configured with overlap or without overlap and/or are regular or irregular and/or are configured in a plurality of planes.</p>
<p id="p-0029" num="0032">If polygons are used for the map, use is made, instead of using a polygon grid, of a regular or irregular arrangement of circles or ovals or other geometric shapes, wherein, instead of counting an edge transition, there is detected the angle via which the shape is left during a pedestrian step or part of a pedestrian step, and for this angle (in suitable random quantization, i.e. range-of-values division), an angle range transition counter is evaluated and updated (in analogy the edge counters for the hexagons in the embodiment), wherein, in case of an overlapping pattern of shapes, there is always selected that shape whose center is closest to the particle, and, in analogy with the realization by hexagons, the angle range transitions are counted and included in the weight computation.</p>
<p id="p-0030" num="0033">Suitably, there are evaluated not only the counters for edge transitions and respectively angle range transitions per hexagon or other structure but also those for each combination of any number of previous transitions.</p>
<p id="p-0031" num="0034">When creating the map, use can be made of already created maps of other users or other walks of a person (for example, the &#x201c;a-priori&#x201d; counters for edge transitions of polygon maps can be placed onto already measured transition counters and/or an iterative processing can be performed wherein the map creation for an odometry data set is continuously repeated using mutually created maps).</p>
<p id="p-0032" num="0035">Suitably, the created map represents three spatial dimensions (for example, for an application in three dimensions, use can be made of columnar geometric surfaces with polygon-like footprints and a flat or oblique bottom or roof (the height being e.g. from 0.5 m to 5 m), wherein, e.g., in analogy with the two-dimensional version of the polygon map, the transitions are counted and evaluated by the therein defined walls or bottom and roof surfaces (in a two-dimensional map, transitions are observed via lines and, in a three-dimensional map, transitions are observed by surfaces).</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<p id="p-0033" num="0036">The method will be explained in greater detail hereunder by way of an embodiment and with reference to the drawing.</p>
<p id="p-0034" num="0037"><figref idref="DRAWINGS">FIG. 1</figref></p>
<p id="p-0035" num="0038">Schematically shown in this Figure is the dynamic model for a Bayesian estimator, with DBN designating a dynamic Bayesian network, Z<sup>u </sup>designating the pedestrian step estimation (odometry information), E designating the odometry error conditions, U designating the real pedestrian step and P designating the &#x201c;pose&#x201d;, and M being time-invariant for the duration of the computation (map determination period), i.e. being identical for all time-instant steps k. M designates the location-related data on the likelihood of the future movement of a person in a spatial environment.</p>
<p id="p-0036" num="0039"><figref idref="DRAWINGS">FIG. 2</figref></p>
<p id="p-0037" num="0040">This Figure shows the definitions of the &#x201c;pose&#x201d; (position in space) and of the pedestrian step vector for the subsequent Figures and examples. Designated by P<sub>k&#x2212;1 </sub>is the (old) position in space at the time k&#x2212;1, and P<sub>k </sub>designates the (new) position in space at the time k. Designated by U<sub>k </sub>is the pedestrian step vector, i.e. the translation of the new position in relation to the old position. The value k is an integral number. It will be increased by one with each cycle. This can occur e.g. at regular points of time (e.g. each second) or if the odometry computed a new pedestrian step, or if the pedestrian step length computed by the odometry exceeds a minimum length (in relation to k&#x2212;1).</p>
<p id="p-0038" num="0041"><figref idref="DRAWINGS">FIG. 3</figref></p>
<p id="p-0039" num="0042">In this Figure, two examples of odometry computations are graphically illustrated, wherein, in each case, pedestrians were walking in an office environment for about 10 minutes. Each point represents the estimated position of the foot at the time that the foot came to a standstill (i.e. when the pedestrian step was estimated). The odometry errors lead to a deviation of these positions from the real positions.</p>
<p id="p-0040" num="0043"><figref idref="DRAWINGS">FIG. 4</figref></p>
<p id="p-0041" num="0044">This Figure schematically shows a system survey. The user can optionally carry with him/her further sensors such as e.g. GPS or WLAN receivers, an electric compass, further pedestrian step counters, a camera or the like. Optionally, an IMU mounted on the foot or shoe can be provided if the odometry is made possible by other sensors. The components of block <b>2</b><i>b </i>can be distributed in the system as desired, i.e. for example in the user device and/or on the shoe and/or as a computing unit in the data network.</p>
<p id="p-0042" num="0045"><figref idref="DRAWINGS">FIG. 5</figref></p>
<p id="p-0043" num="0046">This Figure schematically shows a system survey. The user can optionally carry along further sensors such as e.g. GPS or WLAN receivers, an electric compass, further pedestrian step counters, a camera or the like. Optionally, an IMU mounted on the foot or shoe can be provided if the odometry is made possible by other sensors. The components of block <b>2</b><i>a </i>can be distributed in the system as desired, i.e. for example in the user device and/or on the shoe and/or as a computing unit in the data network.</p>
<p id="p-0044" num="0047"><figref idref="DRAWINGS">FIG. 6</figref></p>
<p id="p-0045" num="0048">This Figure shows a schematic representation of the functional relationships between the blocks <b>3</b>, <b>4</b> and <b>14</b> in <figref idref="DRAWINGS">FIGS. 4 and 5</figref>, respectively. Blocks <b>5</b>, <b>6</b> and <b>8</b> will, at each time-instant step k, store their results as a hypothesis (particle) state in the memory. The RBPF control will be performed in the order of blocks <b>5</b>, <b>6</b>, <b>7</b>, <b>8</b> and <b>9</b>. Then, the new computation of the weight from blocks <b>7</b> and <b>8</b> and, in the given case, resampling will be performed.</p>
<p id="p-0046" num="0049"><figref idref="DRAWINGS">FIG. 7</figref></p>
<p id="p-0047" num="0050">This Figure shows an exemplary definition of the coordinate systems and the angle and pedestrian step vectors, as can be used in one embodiment of the invention.</p>
<p id="p-0048" num="0051"><figref idref="DRAWINGS">FIGS. 8 and 9</figref></p>
<p id="p-0049" num="0052">These Figures show the entire processing, starting from the raw data up to the determination of the odometry information, and further to the extraction of E<sup>i</sup><sub>k </sub>and U<sub>k</sub>.</p>
<p id="p-0050" num="0053"><figref idref="DRAWINGS">FIG. 10</figref></p>
<p id="p-0051" num="0054">This Figure shows, by way of example, two adjacent hexagons which can be used for the creation of the P-map.</p>
<p id="p-0052" num="0055"><figref idref="DRAWINGS">FIG. 11</figref></p>
<p id="p-0053" num="0056">This Figure shows an example of a hexagon P-map with hexagon grid and hexagon edges, wherein, here, one pedestrian step leads to one of the neighboring hexagons.</p>
<p id="p-0054" num="0057"><figref idref="DRAWINGS">FIG. 12</figref></p>
<p id="p-0055" num="0058">This Figure shows an example of a hexagon P-map with hexagon grid and hexagon edges, wherein, in this example, one pedestrian step leads to one of the hexagons beyond the next ones.</p>
<p id="p-0056" num="0059"><figref idref="DRAWINGS">FIG. 13</figref></p>
<p id="p-0057" num="0060">This Figure shows the representation of a person (partly behind the hexagon) in a spatial environment.</p>
<p id="p-0058" num="0061"><figref idref="DRAWINGS">FIG. 14</figref></p>
<p id="p-0059" num="0062">This Figure shows two examples of route maps for a building, as created according to the method of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0060" num="0063">The idea of the invention is the acquisition of a suitable map of the environment (i.e. a sort of building floor plan or route network or mixed forms of them) by evaluating data of inertial sensors which are worn by individual or a plurality of pedestrians. According to the invention, this is performed by use of a Bayesian estimator such as e.g. a Rao-Blackwellized particle filter (RBPF). Such methods are generally known from robotics (cf. Literature on SLAM&#x2014;Simultaneous Localization and Mapping) but, as of yet, only in connection with the use of visual sensors or radar/sonar/laser-ranging sensors which will scan the physical environment or detect it by image processing and will process it in a Bayesian filter (e.g. BBPF or EKF) as a sensor signal). According to the invention, the creation of the map is based solely on pedestrian step estimation&#x2014;while it can be improved by further sensors and information.</p>
<p id="p-0061" num="0064">An example of the underlying dynamic model for a Bayesian filter is illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. There is shown a dynamic Bayesian network (DBN) representing the causal relationships between the participating random variables. In accordance with the known understanding of DBNs as causal networks, the directions of the arrows indicate the directions of the effect of the causality (Uk has a causal effect on Pk, not vice versa). The meaning of the variables will be explained in the text hereunder. In the application, this DBN is illustrated because, in scientific circles dealing with Bayesian estimation algorithms, it is commonly used for clarification and for avoidance of unclarities and is widely understood.</p>
<p id="p-0062" num="0065">Pedestrian step estimation is hereunder referred to as odometry: For odometry, use can be made of the method described by Foxlin in the above publication, but also other methods which do not necessarily require sensor devices for attachment to the shoe (e.g. measurement on other parts of the body&#x2014;e.g. hip, trousers pockets&#x2014;also in combination with a magnetic compass; these are often referred to as Pedestrian Dead Reckoning). In this regard, it is assumed that odometry will always yield more or less good estimations of the pedestrian step vector (This pedestrian step estimation is designated as Z<sup>u </sup>and in this application is partially also referred to as odometry information, and is the estimation of the real pedestrian step vector U) of the pedestrian (pedestrian step estimation: spatial vector in 2D or 3D related to the most recent pedestrian step or equivalent thereto, generally related to another point of time than the starting point. Cf. also <figref idref="DRAWINGS">FIG. 2</figref>). Two examples of the distribution of the estimated position according to odometry computation are presented in <figref idref="DRAWINGS">FIG. 3</figref>. It is to be noted that the definition of a pedestrian step can comprise not only a translation of the location of the foot or the person but also a change of the spatial arrangement (orientation) of the foot or the person. Thus, when a person makes a pedestrian step, the person's foot and respectively the sensor attached to it will change both its position in space and its orientation (direction); at the same time, the person's body will change its position (with regard to a site on the body) as well as the spatial orientation of an axis of the body (e.g. shoulder line or pelvis orientation). However, the translation and respectively directional change of foot and person are in a close relation to each other. In the two-dimensional world, consisting of coordinates x and y, the direction is always related to a direction in the x-y plane.</p>
<p id="p-0063" num="0066">According to <figref idref="DRAWINGS">FIGS. 4 and 5</figref>, &#x201c;System survey of map determination&#x201d;, the user carries an IMU (<b>1</b>) attached e.g. to the foot/shoe, and/or further sensors (<b>3</b>). A position determination computer (<b>2</b><i>a</i>) performs the computation of the position, as will be described hereunder.</p>
<p id="p-0064" num="0067">According to the invention, in case of an exemplary use of a particle filter, there are assigned, to each particle of the particle filter (comprising the components (<b>11</b>), (<b>12</b>) and (<b>10</b>), the following state variables:</p>
<p id="p-0065" num="0068">1) various suitable time-variant or time-fixed odometry error states E for imaging the possible errors, such as e.g. fixed deviations and/or drifts, of the underlying odometry (e.g. angular deviation of the pedestrian step vector Z<sup>u </sup>per second, change rate of the angular deviation, length deviation factor, fixed angular deviations) for the current as well as for the most recent time-instant step of the particle filter.</p>
<p id="p-0066" num="0069">2) location coordinates and, in the given case, orientation in space, in a suitable relative or absolute location coordinate system (e.g. WGS-84, or relative to a corner of the building or relative to a starting point) for the current as well as for the most recent time-instant step of the particle filter. The current pedestrian step vector U is obtained as the change of the position and of the orientation from the most recent to the present time-instant step. This state variable is called the pose P and is shown in <figref idref="DRAWINGS">FIG. 2</figref> together with the pedestrian step vector.</p>
<p id="p-0067" num="0070">3) a suitable representation of location-related data on the likelihood of the future movement of a person in a spatial environment&#x2014;herein referred to as a P-map. Embodiments will be explained hereunder.</p>
<p id="p-0068" num="0071">In each time-instant step, there is supplied to the particle filter the odometry information, i.e. the pedestrian step vector resulting from the unit (block) <b>4</b> of <figref idref="DRAWINGS">FIGS. 4 and 6</figref>, optionally with information on its reliability (i.e. in the form of a likelihood distribution or variance). The particles are now treated in two ways according to the known particle filter algorithm:</p>
<p id="p-0069" num="0072">a) The state variables will be newly determined&#x2014;optionally with the aid of a random generator. This is the known &#x201c;importance sampling&#x201d; or &#x201c;proposal density drawing&#x201d; step of the particle filter. The process is carried out in the components (<b>5</b>), (<b>6</b>) and (<b>8</b>) of <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0070" num="0073">b) Each particle will be newly weighted. This is the &#x201c;weight update&#x201d; step of the particle filter. The process is carried out in the components (<b>7</b>), (<b>11</b>) and optionally (<b>9</b>) of <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0071" num="0074">The exact manner in which these two steps are performed is in part freely selectable and is a function of the nature of the uncertainty of the odometry and of the P-map representation selected according to item <b>3</b>) above. After the selection of the so-called &#x201c;proposal function&#x201d; has been made, the&#x2014;according to Bayesian&#x2014;optimum &#x201c;weight update&#x201d; computation will have been determined. Known approaches are referred to, among experts, as a &#x201c;likelihood particle filter&#x201d; or a &#x201c;transition likelihood proposal function&#x201d;.</p>
<p id="p-0072" num="0075">The P-map can be freely selected. However, for it to be useful, it should comply with some mathematical and practical criteria which will be enumerated hereunder. The P-map is understood as the likelihood density of a suitable random variable, M, of the map, as described further below. It should be selected such that the component (<b>8</b>) (<figref idref="DRAWINGS">FIGS. 4 and 6</figref>) can at least approximately determine the conditional likelihood density p(M|P<sub>&#x2014;</sub>{0:k}). Here, P<sub>&#x2014;</sub>{0:k} is the entire sequence of the pose from the start of the measurements (time-instant step <b>0</b>) to the current time-instant step k. Particularly, M should be selected to the effect that, over time, i.e. with increasing k, p(M|P<sub>&#x2014;</sub>{0:k}) substantially has an ever lower entropy in the sense of the known Shannon entropy. Also the conditional likelihood p(U_k|P<sub>&#x2014;</sub>{0:k&#x2212;1},M) should be determinable at least approximately (component (<b>7</b>) in <figref idref="DRAWINGS">FIGS. 4 and 6</figref>). This term represents the influence of the P-map M on the next pedestrian step at the time k, as given with a specific pose history up to the point of time k&#x2212;1. Preferably, however, one can approximate p(U_k|P<sub>&#x2014;</sub>{0:k&#x2212;1},M)=p(U_k|P_{k&#x2212;1},M), i.e. neglect the influence of older poses, the way this is the case in the hexagon P-maps explained hereunder.</p>
<p id="p-0073" num="0076">An example of M and this distribution is an hexagon P-map. M represents edge transition probabilities in a hexagon grid. The likelihood density p(M<sup>i</sup>|P<sup>i</sup><sub>0:k</sub>) f&#xfc;r Particle i is, in mathematical formulation, a suitable representation of an environment influencing the movement (P map). M accordingly is a random variable. p(M| . . . ) follows a known beta distribution. When newly computing p(M| . . . ), use is made of the transition of the pose from time k&#x2212;1 to k, and the corresponding counters of the beta distribution are increased by one (cf. also <figref idref="DRAWINGS">FIGS. 10</figref>, <b>11</b> and <b>12</b>). M is selected such that
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>(<i>U</i><sub>k</sub><sup>i</sup><i>|P</i><sub>0:k&#x2212;1</sub><sup>i</sup><i>,M</i><sup>i</sup>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
can be computed, i.e. the influence of M on the next pedestrian step at the time k, namely at a given pose development from 0 to the time-instant step k&#x2212;1. In the above example for hexagon P-maps, there applies:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i>(<i>U</i><sub>k</sub><sup>i</sup><i>|P</i><sub>0:k&#x2212;1</sub><sup>i</sup><i>,M</i><sup>i</sup>)=<i>p</i>(<i>U</i><sub>k</sub><sup>i</sup><i>|P</i><sub>k&#x2212;1</sub><sup>i</sup><i>,M</i><sup>i</sup>)=<i>konst&#xb7;{M</i><sub>h(P</sub><sub><sub2>k&#x2212;1</sub2></sub><sub>)</sub><sup>e(U</sup><sup><sub2>k</sub2></sup><sup>)</sup>}<sup>i </sup><?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0074" num="0077">Further, the integral</p>
<p id="p-0075" num="0078">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
  <msubsup>
    <mi>w</mi>
    <mi>k</mi>
    <mi>i</mi>
  </msubsup>
  <mo>=</mo>
  <mrow>
    <msub>
      <mi>k</mi>
      <mi>k</mi>
    </msub>
    <mo>&#xb7;</mo>
    <msubsup>
      <mi>w</mi>
      <mrow>
        <mi>k</mi>
        <mo>-</mo>
        <mn>1</mn>
      </mrow>
      <mi>i</mi>
    </msubsup>
    <mo>&#xb7;</mo>
    <mrow>
      <msub>
        <mo>&#x222b;</mo>
        <msub>
          <mi>M</mi>
          <mi>i</mi>
        </msub>
      </msub>
      <mo>&#x2062;</mo>
      <mrow>
        <mrow>
          <mrow>
            <mi>p</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <msubsup>
                    <mi>U</mi>
                    <mi>k</mi>
                    <mi>i</mi>
                  </msubsup>
                  <mo>|</mo>
                  <msubsup>
                    <mi>P</mi>
                    <mrow>
                      <mn>0</mn>
                      <mo>:</mo>
                      <mrow>
                        <mi>k</mi>
                        <mo>-</mo>
                        <mn>1</mn>
                      </mrow>
                    </mrow>
                    <mi>i</mi>
                  </msubsup>
                </mrow>
                <mo>,</mo>
                <msup>
                  <mi>M</mi>
                  <mi>i</mi>
                </msup>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>&#xb7;</mo>
          <mrow>
            <mi>p</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <msup>
                  <mi>M</mi>
                  <mi>i</mi>
                </msup>
                <mo>|</mo>
                <msubsup>
                  <mi>P</mi>
                  <mrow>
                    <mn>0</mn>
                    <mo>:</mo>
                    <mrow>
                      <mi>k</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </mrow>
                  <mi>i</mi>
                </msubsup>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
        <mo>&#x2062;</mo>
        <mstyle>
          <mspace width="0.2em" height="0.2ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mo>&#x2146;</mo>
          <msup>
            <mi>M</mi>
            <mi>i</mi>
          </msup>
        </mrow>
      </mrow>
    </mrow>
  </mrow>
</mrow>
</math>
</maths>
<br/>
must be determinable at least approximately (e.g. in component (<b>7</b>) of <figref idref="DRAWINGS">FIGS. 4 and 6</figref>). For particle i at the time k, one will newly compute w_k. The likelihood density is the influence of the random variable M on the movement (pedestrian step U) at the time k. The most recent term of the integral is the result of the component (<b>8</b>) from the most recent time-instant step; thus, it is the old P-map. The component (<b>7</b>) will compute or approximate this integral either implicitly (i.e. the integral can be expressed analytically) or by numerical or analytic integration during the real-time operation of the system. The normalization constant k_k will be computed in such a manner that the sum of the w_k over all particles will add up to one. In hexagon P-maps, p(M| . . . ) is completely specified by the edge counters and a-priori counters. The integral is then generally solvable analytically. The integral does not have to be evaluated during the running time, which also applies to the terms in the integral (cf. <figref idref="DRAWINGS">FIG. 10</figref>).
</p>
<p id="p-0076" num="0079">Advantageously, M and p(M|P<sub>&#x2014;</sub>{0:k}) should be selected in such a manner that the integral can be determined analytically, as is the case in the hexagon P-maps to be explained later on.</p>
<p id="p-0077" num="0080">Advantageously, after computation of the weight of all particles, the weights will be standardized to the sum <b>1</b>, and there is performed an optional &#x201c;re-sampling&#x201d; step (known in the field). (This can be performed e.g. again in the component (<b>11</b>) of <figref idref="DRAWINGS">FIGS. 4 and 6</figref>.).</p>
<p id="p-0078" num="0081">As an exemplary realization of the above, let it be mentioned that, as a &#x201c;proposal density&#x201d; for the drawing of each particle at each time-instant step, the following mathematical product can be selected with advantage:</p>
<p id="p-0079" num="0082">The conditional likelihood density of the current odometry errors E, conditioned to the odometry errors in the last time-instant step (e.g in the component (<b>5</b>) of <figref idref="DRAWINGS">FIGS. 4 and 6</figref>), multiplied by the conditioned likelihood density of the current pedestrian step vector U, conditioned to the current odometry information Z<sup>u </sup>and the current drift parameter E (e.g in the component (<b>6</b>) of <figref idref="DRAWINGS">FIGS. 4 and 6</figref>).</p>
<p id="p-0080" num="0083">In the components (<b>5</b>) and (<b>6</b>), the following is performed:</p>
<p id="p-0081" num="0084">(5): draw a new E<sub>k</sub><sup>i </sup>from the distribution p(E<sub>k</sub>|E<sub>k&#x2212;</sub><sup>i</sup>)</p>
<p id="p-0082" num="0085">Example of E and this distribution:</p>
<p id="p-0083" num="0086">E represents a time-variant pedestrian step angle deviation (&#x201c;bias&#x201d;) and a temporal change rate (&#x201c;drift&#x201d;) from Z<sup>u</sup>. Both state variables are independent and follow a &#x201c;random walk&#x201d; process of chance and thus each represent one of two multiplicative factors of p(E| . . . ).</p>
<p id="p-0084" num="0087">(6) draw a new pedestrian step vector U<sub>k</sub><sup>i </sup>from the distribution:</p>
<p id="p-0085" num="0088">New odometry error state for particle i</p>
<p id="p-0086" num="0089"><chemistry id="CHEM-US-00001" num="00001">
<img id="EMI-C00001" he="18.20mm" wi="14.65mm" file="US08626443-20140107-C00001.TIF" alt="embedded image" img-content="chem" img-format="tif"/>
</chemistry>
</p>
<p id="p-0087" num="0090">Pedestrian step estimation at the time k (2D-vector)</p>
<p id="p-0088" num="0091">In practice, this means that, for each particle, there has to be first drawn, in a random or pseudo-random manner, a new odometry-error parameter set&#x2014;conditioned to the old ones, and that there is then drawn, in regard to this new odometry-error parameter set and the current odometry data, a new pedestrian step vector in a random or pseudo-random manner (&#x201c;proposal density drawing&#x201d;). Using the selected new pedestrian step vector, the new position and orientation is computed, and the system state of the particle is stored. In practice, the distribution from which the drawing is performed can be the normal distribution; the variants therein will result from the real quality characteristics of the odometry sensors and can be determined e.g. experimentally.</p>
<p id="p-0089" num="0092"><figref idref="DRAWINGS">FIG. 7</figref> shows the coordinate system used in the present example, with angles and pedestrian step vectors. For the symbolics used, there applies:</p>
<p id="p-0090" num="0093">Odometry information: Z<sup>U</sup><sub>k</sub>={Z<sup>r</sup><sub>k</sub>+n<sup>r</sup><sub>k</sub>; Z<sup>&#x3c8;</sup><sub>k</sub>+<sup>&#x3c8;</sup><sub>k</sub>}={(Z<sup>rx</sup><sub>k</sub>+n<sup>x</sup><sub>k</sub>,Z<sup>ry</sup><sub>k</sub>+n<sup>y</sup><sub>k</sub>); Z<sup>V</sup><sub>k</sub>+n<sup>&#x3c8;</sup><sub>k}</sub></p>
<p id="p-0091" num="0094">pedestrian step vector U: U<sub>k</sub>={r<sub>k</sub>;&#x3c8;<sub>k</sub>} {(r<sup>x</sup><sub>k</sub>,r=<sup>v</sup><sub>k</sub>); &#x3c8;k}; mit &#x2225;r<sub>k</sub>*&#x2225;=&#x2225;Z<sup>r</sup><sub>k</sub>&#x2225;</p>
<p id="p-0092" num="0095">For the Odometry measurement Z<sup>U </sup>we can state: Z<sup>U</sup>=Z<sup>r</sup><sub>k</sub>+noise vector n<sup>r</sup><sub>k</sub>; and direction change Z<sup>&#x3c8;</sup><sub>k</sub>+noise n<sup>&#x3c8;</sup><sub>k </sub></p>
<p id="p-0093" num="0096">U represents the true moving x,y&#x2014;step vector in the form of r<sub>k </sub>(red) as well as the true orientation change of the person &#x3c8;.</p>
<p id="p-0094" num="0097">&#x3c8;: Angular difference between the orientation of the person and the sensor orientation</p>
<p id="p-0095" num="0098">&#x3b3;: Odometry heading drift &#x3b3;<sub>k</sub>=Z<sup>&#x3c8;</sup><sub>k </sub>&#x3c8;<sub>k </sub></p>
<p id="p-0096" num="0099">The whole processing sequence is shown in <figref idref="DRAWINGS">FIGS. 8 and 9</figref>. In these Figures, there applies:</p>
<p id="p-0097" num="0100">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mrow>
  <msup>
    <mi>E</mi>
    <mi>i</mi>
  </msup>
  <mo>&#x2062;</mo>
  <mrow>
    <mo>{</mo>
    <mtable>
      <mtr>
        <mtd>
          <mrow>
            <mstyle>
              <mspace width="0.6em" height="0.6ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mtable>
              <mtr>
                <mtd>
                  <mrow>
                    <mi>Noise</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>terms</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>are</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>drawn</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>randomly</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>from</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>a</mi>
                  </mrow>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mrow>
                    <mi>zero</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>mean</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>normal</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>distribution</mi>
                  </mrow>
                </mtd>
              </mtr>
            </mtable>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
          </mrow>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>Calculation</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>of</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <msub>
                      <mi>&#x3c8;</mi>
                      <msup>
                        <mi>k</mi>
                        <mrow>
                          <mi>&#x25b;</mi>
                          <mo>&#x2062;</mo>
                          <mstyle>
                            <mspace width="0.3em" height="0.3ex"/>
                          </mstyle>
                          <mo>&#x2062;</mo>
                          <mi>li</mi>
                        </mrow>
                      </msup>
                    </msub>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>follows</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>a</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>random</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>walk</mi>
                    <mo>&#x2062;</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>&#x2062;</mo>
                    <mi>process</mi>
                  </mrow>
                  <mo>;</mo>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mi>optionally</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.8em" height="0.8ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <mi>clipped</mi>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mrow>
            <mi>Calculation</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>of</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <msubsup>
              <mi>&#x3b3;</mi>
              <mi>k</mi>
              <mi>li</mi>
            </msubsup>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>follows</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>a</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>random</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>walk</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>process</mi>
          </mrow>
        </mtd>
      </mtr>
    </mtable>
  </mrow>
</mrow>
</math>
</maths>
</p>
<p id="p-0098" num="0101">(Notice: U<sup>i </sup>is in the &#x201c;person zero heading&#x201d; coordinate system, i.e. with respect to the most recent orientation of the person at the time k.)</p>
<p id="p-0099" num="0102">Now, according to the exemplary realization by hexagon P-maps as shown in <figref idref="DRAWINGS">FIGS. 10</figref>, <b>11</b> and <b>12</b>, the computation of the weight of the particle is carried out as follows (&#x201c;weight update&#x201d;, see components (<b>7</b>,<b>9</b>,<b>11</b>) in <figref idref="DRAWINGS">FIGS. 4 and 6</figref>):
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0103">New weight=old weight multiplied by product_{j=0 to Ns&#x2212;1} (N(h(j), e(j))+a(h(j), e(j)))/(N(h(j))+a(h(j))); if the new pedestrian step leads the particle out from a hexagon</li>
        <li id="ul0004-0002" num="0104">or:</li>
        <li id="ul0004-0003" num="0105">New weight=old weight multiplied by 0,25; if the new pedestrian step does not lead the particle out from a hexagon.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0100" num="0106">For <figref idref="DRAWINGS">FIG. 10</figref>, it holds true that Ns=2 since the pedestrian step K pertains to merely two hexagons. Further, there applies:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sub>h(P</sub><sub><sub2>k&#x2212;1</sub2></sub><sub>)</sub><sup>e</sup>(<i>U</i><sup><sub2>k</sub2></sup><sup>)</sup><img id="CUSTOM-CHARACTER-00001" he="2.46mm" wi="1.78mm" file="US08626443-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>M<sub>{tilde over (h)}</sub><sup>{tilde over (e)}</sup><img id="CUSTOM-CHARACTER-00002" he="2.46mm" wi="1.78mm" file="US08626443-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>P(<i>P</i><sub>k</sub><i>&#x3b5;H</i><sub>j</sub><i>|P</i><sub>k&#x2212;1</sub><i>&#x3b5;H</i><sub>h </sub><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
so that H<sub>j </sub>is reached from H<sub>h </sub>via U<sub>k </sub>and j&#x2260;.
</p>
<p id="p-0101" num="0107">For Ns=2, there further applies:</p>
<p id="p-0102" num="0108">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mrow>
  <msup>
    <mi>w</mi>
    <mi>i</mi>
  </msup>
  <mo>=</mo>
  <mrow>
    <msub>
      <mi>k</mi>
      <mi>k</mi>
    </msub>
    <mo>&#xb7;</mo>
    <msubsup>
      <mi>w</mi>
      <mrow>
        <mi>k</mi>
        <mo>-</mo>
        <mn>1</mn>
      </mrow>
      <mi>i</mi>
    </msubsup>
    <mo>&#xb7;</mo>
    <msup>
      <mrow>
        <mo>{</mo>
        <mfrac>
          <mrow>
            <msubsup>
              <mi>N</mi>
              <mover>
                <mi>h</mi>
                <mo>~</mo>
              </mover>
              <mover>
                <mi>e</mi>
                <mo>~</mo>
              </mover>
            </msubsup>
            <mo>+</mo>
            <msubsup>
              <mi>a</mi>
              <mover>
                <mi>h</mi>
                <mo>~</mo>
              </mover>
              <mover>
                <mi>e</mi>
                <mo>~</mo>
              </mover>
            </msubsup>
          </mrow>
          <mrow>
            <msub>
              <mi>N</mi>
              <mover>
                <mi>h</mi>
                <mo>~</mo>
              </mover>
            </msub>
            <mo>+</mo>
            <msub>
              <mi>a</mi>
              <mover>
                <mi>h</mi>
                <mo>~</mo>
              </mover>
            </msub>
          </mrow>
        </mfrac>
        <mo>}</mo>
      </mrow>
      <mi>i</mi>
    </msup>
  </mrow>
</mrow>
</math>
</maths>
<br/>
N are edge counters and respectively the sum for all edges of a hexagon. In analogy thereto, alpha denotes the a-priori counters.
</p>
<p id="p-0103" num="0109">In <figref idref="DRAWINGS">FIGS. 11 and 12</figref>, the digits <b>0</b>, <b>1</b>, <b>2</b>, <b>3</b>, <b>4</b>, <b>5</b> designate the edge numbers of respectively one hexagon. According to <figref idref="DRAWINGS">FIG. 11</figref>, in the transition of a particle position from P<sub>k&#x2212;1 </sub>to P<sub>k </sub>of the weight computation in component (<b>7</b>), the counter of edge <b>1</b> of hexagon H<b>1</b> is incremented, and optionally the counter of edge <b>4</b> of hexagon H<b>2</b> is incremented. In the weight computation in component (<b>7</b>) of the particle, the counter of edge <b>1</b> of hexagon H<b>1</b> (with respect to the sum counter of hexagon H<b>1</b>) is used. According to <figref idref="DRAWINGS">FIG. 12</figref>, in the transition of a particle position from P<sub>k&#x2212;1 </sub>to P<sub>k </sub>after the weight computation in component (<b>7</b>), the counter of edge <b>1</b> of hexagon H<b>1</b> is incremented and the counter of edge <b>2</b> of hexagon H<b>2</b> and optionally the counter of edge <b>4</b> of hexagon H<b>2</b> and the counter of edge <b>5</b> of hexagon H<b>3</b> are incremented. In the weight computation of the particle, use is made of the counter of edge <b>1</b> of hexagon H<b>1</b> (with respect to the sum counter of hexagon H<b>1</b>) and the counter of edge <b>2</b> of hexagon H<b>2</b> (with respect to the sum counter of hexagon H<b>2</b>).</p>
<p id="p-0104" num="0110">For ease of understanding, reference is made to <figref idref="DRAWINGS">FIG. 13</figref>, showing an individual hexagon of a hexagon P-map representing the probabilities of the possible movements of the person at this location. In this example, the arrow length is proportionate to the likelihood of a transition over the respective hexagon edge&#x2014;it is unlikely that the person, when viewed from the rear, will walk to the left or to the rear. Typically, the hexagon radius is selected to be 0.25-1 meter.</p>
<p id="p-0105" num="0111">In this embodiment&#x2014;for an application in two spatial dimensions&#x2014;the above mentioned terms N(h(j), e(j)), a(h(j), e(j)), N(h(j)), a(h(j)), and Ns are determined and respectively used in the following manner:
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0000">
    <ul id="ul0006" list-style="none">
        <li id="ul0006-0001" num="0112">The 2D local area will be subdivided into a regular hexagon grid (hexagon radius e.g. 0.5 m).</li>
        <li id="ul0006-0002" num="0113">The index h(<b>0</b>) precisely defines the x- and y-position of the center of that hexagon which the particle left in the most recent pedestrian step.</li>
        <li id="ul0006-0003" num="0114">The index h(Ns) precisely defines the x- and y-position of the center of that hexagon which the particle reached as a result of the most recent pedestrian step.</li>
        <li id="ul0006-0004" num="0115">All hexagons which are still passed through (if any) will be indexed, in the ascending order of leaving, by h(j), wherein 0&#x3c;j&#x3c;Ns. In <figref idref="DRAWINGS">FIG. 12</figref>, for instance, Ns=3, and in this Figure, h(<b>0</b>) is equal to H<b>1</b>, h(<b>1</b>) is H<b>2</b>, and h(<b>2</b>) is H<b>3</b>. For Ns=2, <figref idref="DRAWINGS">FIG. 10</figref> holds true as an example.</li>
        <li id="ul0006-0005" num="0116">In a similar manner, 0&#x3c;=e(j)&#x3c;6 defines the edge of the hexagon h(j) via which it was left.</li>
        <li id="ul0006-0006" num="0117">The number N(h(j), e(j)) is the number of all past events (for this particle) where the hexagon with the index h(j) was left via the edge e(j), i.e. indicating how often the path of this particle crossed the respective edge. This term is referred to as an edge counter. In this case of the hexagon P-maps, N(h(j), e(j)) is also the representation of an environment influencing the movement, as initially described. This representation is computed into the map, as explained later on.</li>
        <li id="ul0006-0007" num="0118">The number N(h(j)) is the sum counter of the hexagon and represents the sum of N(h(j), e) for e=0 to 5.</li>
        <li id="ul0006-0008" num="0119">The number a(h(j), e(j)) is a positive number, in principle selectable at random, which can be interpreted as an &#x201c;a-priori&#x201d; counter (the English term, known from Bayesianian estimation theory, being &#x201c;virtual counts&#x201d;) and which includes previous knowledge on the ability of this hexagon to pass across this edge.</li>
        <li id="ul0006-0009" num="0120">Thus, further, a(h(j)) is the sum of a(h(j), e) for e=0 to 5. It is also possible, for instance, to generally use a value of about 1 for each a(h(j), e(j)).</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0106" num="0121">Advantageously, one will increment N(h(j), e(j)) for a particle not only for the polygon (e.g. hexagon) which has been left but one will act as if the human step had also performed the transition in the reverse order and will also increment the corresponding edge of the polygon which has been reached (as in the examples from <figref idref="DRAWINGS">FIGS. 11 and 12</figref>). Advantageously, the fraction in the term for the weight computation will be corrected for geometric non-uniformities of the polygon grid since, depending on the passage direction of the respective particle, e.g. through a hexagon grid, slightly different numbers of edges will be crossed for a fixed and linear length of path, which otherwise would cause a wrong preference given to some directions and thus of some particles because the fraction in the formula for weight computation is always smaller than 1. Advantageously, the fraction in the term for weight computation will be corrected by different length of the current pedestrian step vector of a particle since, otherwise, particles which accidentally represent rather shorter pedestrian steps would erroneously be favored because the fraction in the formula for weight computation is always smaller than 1. This can be performed e.g. in that the fraction is raised to the power of a number z, wherein z comprises the length and/or direction correction (e.g. linear standardization to the number of hexagon transitions with respect to a length of path of one meter and to a uniform direction in the hexagon grid.</p>
<p id="p-0107" num="0122">The determination of the map itself is performed in the component <b>13</b><i>b </i>in <figref idref="DRAWINGS">FIGS. 4 and 6</figref> after termination of a walk by evaluation of the representation, stored in the state variable, of each particle's environment influencing the movement (P-map or map M, hereunder simply referred to as map), in the above example e.g. the number N(h, e) or also the fraction (N(h, e)+a(h, e))/(N(h)+a(h)) for all hexagons h and all edges e. There will be taken either the map of the particle having the largest weight, or the map averaged in a weighted manner across all particles, or other methods known in the literature on particles. In the weighted averaging, it is e.g. the transition counters that can be averaged in a weighted manner. In such a form, the map can be used directly in the positioning of a pedestrian at a later time&#x2014;in the above example, it will, permanently or as a &#x201c;a-priori&#x201d; counter, replace the corresponding values during the later positioning with or without recomputation of the map. However, the map can also be further processed (by application of random further functions), e.g. by application of local-area filters or edge detection algorithms so as to obtain a graphic representation of the map and respectively the environment. In the above exemplary embodiment, use can be made of the (weighted-with-averaging) edge transition counters computed from the particles, for detecting walls and obstacles (edges without or with only few transitions). In the process, non-linear functions such as e.g. a hard limitation, Sigmoid functions or thresholds can be used so that different values of the map transition counters can be reflected in the map in a differentiated and non-linear manner.</p>
<heading id="h-0004" level="1">ADVANTAGES OF THE INVENTION</heading>
<p id="p-0108" num="0123">The above described method has the advantage that such particles will be rewarded which due to their odometry-error and pedestrian step hypotheses will often appear at the same edge transitions of the hexagons again. This is what also a person will do when moving about within an environment delimited by walls: at doors, in corridors, at crossings and at similar obstacles and junctures, the pedestrian will select one of the physically possible transitions&#x2014;he/she will not walk through walls. Thus, if a pedestrian repeatedly enters the same areas (i.e. for example the above hexagons), preference is given to such particles (hypotheses) which represent the same patterns of movement. After some time, there will &#x201c;survive&#x201d; only such particles by which the real movement history of the pedestrian is more or less correctly imaged&#x2014;and, thus, the map. This, accordingly, makes it possible for a person e.g. to walk into a building&#x2014;using the most recent known position obtained by satellite navigation (e.g. GPS)&#x2014;and then, in the building, to compile a map, under the precondition that an area is re-entered with sufficient frequency. (In practice, one further visit will often suffice.) The drift of recent sensors nowadays is so good that the positioning can often be performed for several minutes with a precision in the range of a few meters even though the pedestrian has not re-entered any areas. In this time period, it is highly likely that e.g. a stretch of a route has been walked on in the opposite direction, or that a corner in a corridor has been passed several times in the same manner.</p>
<p id="p-0109" num="0124">Further, the method is capable of detecting&#x2014;and acquiring knowledge of&#x2014;not only walls but also influences such as furniture, partition walls and other obstacles. As a result, there is obtained a closer linkage of person's movement to the environment, which will increase the positioning accuracy. Further, the method can also detect changes in the environment such as e.g. changes of inner and outer walls, shifting of larger pieces of furniture, new partition walls, etc.</p>
<p id="p-0110" num="0125">Illustrated in <figref idref="DRAWINGS">FIG. 14</figref> are two examples of created hexagon P-maps for respective independent walks of a person in a building during about 10 minutes each time. During this period, the person has passed several times through the inner looped corridor and has entered some of the rooms. Method: In this example, there was used a Rao-Blackwellized particle filter with about 30,000 particles.</p>
<p id="p-0111" num="0126">Background outline: Real floor plan&#x2014;here, only for comparison</p>
<p id="p-0112" num="0127">Black hexagons: the P-map which by the method was computed to be the most probable one. This P-map is also the P-map in the state of the particle which on the whole receive the best cumulative weight.</p>
<p id="p-0113" num="0128">Medium black (grey) hexagons: hexagons which belong to somewhat less probable but still not improbable P-maps.</p>
<p id="p-0114" num="0129">The larger the holes in the hexagons are, the more frequently this hexagon has been &#x201c;visited&#x201d; by the best particle.</p>
<p id="p-0115" num="0130">White areas: these were not visited by the best particle.</p>
<p id="p-0116" num="0131">Extensions</p>
<p id="p-0117" num="0132">In practice, one will include also data of further sensors into this method, which will further improve its reliability: e.g. satellite navigation, magnetic compass, WLAN measurements for positioning, mobile phone position measurements, UWB measurements for positioning (e.g. in component (<b>3</b>) of <figref idref="DRAWINGS">FIGS. 4 and 6</figref>). Further, one will use known portions of a building floor map in order to restrict the particle movement&#x2014;e.g. the outer walls.</p>
<p id="p-0118" num="0133">A further possibility for improving this method is the use of real or virtual reference marks. In the context of the invention, a reference mark is a feature of the environment which a person will be able to recognize again (e.g. a specific door, a corner of a specific room, etc.) In a virtual reference mark, the site (in the coordinate system of the system) of this reference mark does not have to be known.</p>
<p id="p-0119" num="0134">The system uses these virtual reference marks in the following manner: When a person encounters a new suitable reference mark for the first time, the person will give a signal to the system in a suitable manner. This can be performed e.g. in that the person will input a special number into a portable end device (e.g. mobile phone) or will push a dedicated key on the device. Or the person will move his/her foot on which the sensors are applied, in a specific manner (e.g. by softly tapping onto the floor two times, which can be easily detected by the system from the sensor data). The person himself/herself can freely select the reference mark and respectively decide on which sites he/she wants to place the reference mark. Or, however, a reference mark has already been physically marked as such or has been described to the pedestrian in such a manner that it will be detectable.</p>
<p id="p-0120" num="0135">The particle filter will now assign, to each particle, a further state variable for this new reference mark, said state variable comprising the following information: the current location of the particle (copied from the state variable thereof) and, appertaining thereto, optionally a representation of the spatial accuracy (e.g. variances, likelihood density function) and an identification number. If only a virtual reference mark is allowed or if the explicit identification of the reference mark is evident e.g. from the name allocation in a software realization, no identification number has to be stored. Now, if the pedestrian in the further development again encounters this virtual reference mark, he/she will again give the new signal (e.g. producing the same movement pattern with the feet or push the same button/numerical key). Then, in the above example, in the &#x201c;weight update&#x201d; step, the weights will be evaluated with a further multiplicative factor. This factor is a function (called F<b>1</b>) of the current local coordinate of the particle and the stored position of the reference mark and the spatial accuracy of the particle as determined as of yet. This function can be selected as desired but preferably is selected in such a manner that the factor is the larger the closer the two coordinates are to each other and the higher the current spatial accuracy is. Further, the position of the reference mark stored for each particle and the as yet determined spatial accuracy of the particle will be newly computed in that e.g. the position will be taken from the average value of all observed positions, and the spatial accuracy will represent the variation of all observed positions (e.g. the variance; for this purpose, also a Kalman filter can be used).</p>
<p id="p-0121" num="0136">If the pedestrian does not give a signal, all particles will nonetheless be weighted in the &#x201c;weight update&#x201d; step with NIv further multiplicative factors. NIv herein is the number of the as yet determined virtual reference marks. These factors are respectively computed as follows: They are also a function (referred to as F<b>2</b>) of the current local coordinate of the particle and the stored position and its as yet determined spatial accuracy. This function F<b>2</b> can be selected as desired but preferably is selected in such a manner that the factor becomes smaller the closer the coordinates are to each other and the higher the current spatial accuracy of the reference mark is. When a reference mark is observed, the &#x201c;weight update&#x201d; step optionally does not only comprise a multiplicative factor related to this reference mark, but comprises this factor multiplied by (NIv&#x2212;1) further factors related to all (NIv&#x2212;1) now unobserved reference marks, as has been described. In the form of the above mentioned functions, consideration has also been given to the fact that pedestrians particularly may forget to report a reference mark, and that it may also (more rarely) happen that a pedestrian reports a reference mark although he/she is not near it. The adapting of these two functions F<b>1</b> and F<b>2</b> to these error sources is suitably achieved in that their values will not become too small when the respective included positions are more remote (in the function F<b>1</b>) and respectively are nearer (in F<b>2</b>). In a similar manner, F<b>1</b> and F<b>2</b> can be adapted in such a manner that reference marks will be reported by the pedestrian also in a larger environment by being, in the mathematical sense, less discriminating (&#x201c;sharp&#x201d;) with respect to the positional differences.</p>
<p id="p-0122" num="0137">In contrast to the also described virtual reference marks, real reference marks are observed and are processed in the system in a similar manner. The difference is that the positions of these real reference marks have to be known to the system. Thus, the step of newly computing the position of the reference mark is eliminated. Further, the system will right from the start work with NIr real reference marks, and there is no need to wait until this number has been reached by marking the reference marks. In this method, real and virtual reference marks can of course be combined: in the selected example described above, all corresponding factors will be multiplicatively included into the weight computation.</p>
<p id="p-0123" num="0138">Further, the method can be suitably combined with optical SLAM methods known from robotics in that also the visual &#x201c;features&#x201d; measured by the optical sensors (see component (<b>3</b>) in <figref idref="DRAWINGS">FIGS. 4 and 6</figref>) will be included as contributing factors into the weight computation and/or as &#x201c;importance sampling&#x201d; step of the particle&#x2014;e.g. as a multiplicative term in the weight. Further, each particle now also conveys the state of each observed visual feature and will adapt the location and spatial position as well as the precision thereof to the current observation and to the other states of the particle. Also, in the same manner, use can be made of features of ultrasonic or infrared or microwave sensor systems. These features can thus be understood and used as a part of the created map, and/or the extension described herein improves the creation of the map on the basis of the odometry.</p>
<p id="p-0124" num="0139">The method can also be suitably combined with magnetic sensors in that the respective strength and direction of the local magnetic field are included as a feature and are incorporated in the system in correspondence to the above described visual features. In this case, the magnetic field will be measured with the aid of suitable electronic magnetic field sensors.</p>
<p id="p-0125" num="0140">The method can also be advantageously improved by attaching odometric sensors on both feet (so that there exist two units of component (<b>1</b>)). Further, the use of several sensors on a foot can be provided in order to reduce the drift. By suitable combination of the sensor data (e.g. averaging of the odometry results or averaging the raw data of the sensors), an improved odometry can be achieved.</p>
<p id="p-0126" num="0141">Further, the method can also be advantageously improved and/or simplified by arranging sensors for odometry (component (<b>3</b>) in <figref idref="DRAWINGS">FIGS. 4 and 6</figref>) on other parts of the body and using methods known from Pedestrian Dead Reckoning for computing and respectively improving the odometry (in component (<b>4</b>) in <figref idref="DRAWINGS">FIGS. 4 and 6</figref>). Further, it is possible to perform the method only with the aid of odometry by pedestrian step detection and estimation of the pedestrian step length/angle&#x2014;without sensors attached to the shoe. (Thus, component (<b>1</b>) in <figref idref="DRAWINGS">FIGS. 4 and 6</figref> is optional in this case.)</p>
<p id="p-0127" num="0142">Further, the method can also be advantageously simplified in that, when using polygon or hexagon P-maps, the counters will be updated and stored only for an edge between two polygons or hexagons, and not individually for all edges of all hexagons. As a result, the required storage capacity can be noticeably reduced.</p>
<p id="p-0128" num="0143">Further, the method can also be advantageously improved and/or simplified by application of the visual odometry known from robotics (&#x201c;Lucas-Kanade&#x201d; or &#x201c;Focus of Expansion&#x201d; methods). In such a case, with the aid of optical sensors (e.g. camera (component (<b>1</b>) in FIGS. <b>4</b> and <b>6</b>)), the change of the appearance of the environment is used for estimating the change of the person's position and orientation.</p>
<p id="p-0129" num="0144">Further, the method can also be advantageously improved, using the polygon representation (polygon P-maps), in that the polygon grid is adapted to the environment so as to be configured with varying density. The polygons can also overlap. Further, a plurality polygon levels can be used hierarchically and the transition counters for each level can be computed separately. Also in the weight computation of the particles, all levels will be included (e.g. multiplicatively in the weight).</p>
<p id="p-0130" num="0145">As a card, there are then output all levels established in this manner.</p>
<p id="p-0131" num="0146">Further, the method can also be advantageously realized in that, when using hexagon P-maps instead of a hexagon grid, other grid elements are used (e.g. rectangles, triangles, other polygons). These can be arranged with overlap or without overlap and/or be regular or irregular and/or be configured in a plurality of planes. In analogy with the realization by hexagons, the angle range transitions are counted and included in the weight computation.</p>
<p id="p-0132" num="0147">Further, the method can also be advantageously realized in that, if using hexagon P-maps, use is made, instead of a hexagon grid or another polygon grid, of a regular or irregular arrangement of circles or ovals. In this case, no edge transitions are counted but there is detected the angle via which the circle is left during a pedestrian step or part of a pedestrian step. For this angle (in suitable random quantization, i.e. subdivision of ranges of values), the angle range transition counter is evaluated and updated (in analogy with the hexagons in the embodiment). In case of an overlapping pattern of circles, one would always select the circle whose center is closest to the particle. In analogy with the realization by hexagons, the edge transitions are counted and included in the weight computation.</p>
<p id="p-0133" num="0148">Further, the method can also be advantageously realized in that there are evaluated not only the counters for edge transitions and respectively angle range transitions per hexagon or other structure but also those for each combination of any number of previous transitions. If Nm such previous transitions are considered, this is referred to as a Markov process of the Nm-th order, and one can use the methods for computation of the Markov process that are known in the field, such as e.g. the representation of the Markov chain as a so-called directional Bayesian network (which, for simplification, has to comprise only node transitions from each state node of the Markov chain, i.e. for example the edge transitions of the respective earlier hexagon in hexagon P-maps, to the node of the edge transitions of the current hexagon), and the learning acquisition of the Bayesian Network's likelihood tables in accordance with the known Baysian learning of data in a situation with a known network structure. Also in this case, the computation of the integral from <figref idref="DRAWINGS">FIG. 8</figref> can be analytically solved beforehand and corresponds to the solving of a Bayesian network with a target node and Nm independent parent nodes.</p>
<p id="p-0134" num="0149">Further, the method can also be advantageously improved in that, when creating the map, use is made of already created maps of other users. Thus, for instance, the &#x201c;a-priori&#x201d; counters can be set to already measured transition counters.</p>
<p id="p-0135" num="0150">Further, the method can also be advantageously extended in that, when creating the map, the measured sensor values (inclusive of data of other sensors which possibly are to be used further on, such as e.g. satellite navigation, compass, etc.) of a plurality of walks in the same environment or in overlapping environments will be linked. These data sets can be picked up from the same walker or from different persons. Thus, it would be possible that knowledgeable persons&#x2014;e.g. employees working in a building&#x2014;will, for a time, pick up measurement data during a given normal working day or during special measurement walks. In the process or later on, these data can be transmitted to a computing unit (e.g. server), and this computing unit can generate a map from them. As an extension of the above, newly obtained maps and respectively measurements of certain areas can be linked with maps/measurements of (partially) overlapping areas which already exist or which have been included parallel thereto. This linking can be realized e.g. in the following different manners:</p>
<p id="p-0136" num="0151">1. by connection of the individual maps, after each map for each walk has been created. In case of overlapping areas, the connection can be performed by detection of common geometric features in the maps, e.g. by means of cross correlation of the transition probabilities in the search space of different rotation, translation and scaling transformations of one of the maps. Herein, the maps will be combined under consideration of the transformation with the largest correlation (e.g. addition of the map counters). In this combination, it has to be considered that, when a rotation occurs, the edges of the hexagon (or other polygons) of the maps will have been rotated relative to each other. The angle does not have to be a multiple of the polygon base angle (e.g. 60&#xb0; for the hexagon). In this case, when performing the compensation, an interpolation can be carried out between the adjacent contributing edge values. In scaling or translation, the process can be similar if, after these transformations, the hexagon grids do not fit onto each other&#x2014;also here, the contributing edges can be combined with weighted averaging.</p>
<p id="p-0137" num="0152">2. As described above&#x2014;but after combining new maps with existing maps, the resultant map will be used as an &#x201c;a-priori&#x201d; counter for a renewed application of the SLAM algorithm to the individual sets of data. The individual edges resulting therefrom will then be combined again. This process can be iteratively repeated for all or individual ones of the contributing sets of data. In the use of the &#x201c;a-priori&#x201d; counters in the renewed computation of a map from a data set X, the method can be improved in that the counters from the map which had been flown from the data set X into the common map, will be withdrawn from this map, but only for the renewed processing of the data set X. This last-mentioned principle corresponds to the known consideration of &#x201c;extrinsic&#x201d; and &#x201c;intrinsic&#x201d; information in the iterative decoding of turbo codes which are used for error correction in news technology.</p>
<p id="p-0138" num="0153">3. As described above, but with the extension feature that, when combining the counter values, there is not realized a simple addition of the values from the new and the existing map, but a random linear or non-linear function of the contributing values (e.g. weighted addition, compression of the contributing values, compression of the result of an addition, application of thresholds to the contributing values or to the result).</p>
<p id="p-0139" num="0154">As described in the context of the combining of maps, the computed map can be subjected to a desired linear or non-linear function (e.g. compression of the counter values or probabilities, application of thresholds).</p>
<p id="p-0140" num="0155">A further, still more detailed description of the invention is found in the articles listed hereunder, their subject matters being herewith included by reference in the present application:</p>
<p id="p-0141" num="0156">Conference GNSS-ION: &#x201c;Inertial Systems Based Joint Mapping and Positioning for Pedestrian Navigation&#x201d;, Patrick Robertson, Michael Angermann, Bernhard Krach, Mohammed Khider; Sep. 22-25 2009, Savannah, Ga., USA.</p>
<p id="p-0142" num="0157">Conference UbiComp 2009: &#x201c;Simultaneous Localization and Mapping for Pedestrians using only Foot-Mounted Inertial Sensors&#x201d;, Patrick Robertson, Michael Angermann, Bernhard Krach, Sep. 30-Oct. 3, 2009, Orlando, Fla., USA.</p>
<p id="p-0143" num="0158">Robertson, Patrick; Angermann, Michael; Krach, Bernhard and Khider, Mohammed: SLAM Dance: Inertial-Based Joint Mapping and Positioning for Pedestrian Navigation, InsideGNSS, May 201 (www.insidegnss.com).</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-chemistry idref="CHEM-US-00001" cdx-file="US08626443-20140107-C00001.CDX" mol-file="US08626443-20140107-C00001.MOL"/>
<us-math idrefs="MATH-US-00001" nb-file="US08626443-20140107-M00001.NB">
<img id="EMI-M00001" he="7.03mm" wi="76.20mm" file="US08626443-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08626443-20140107-M00002.NB">
<img id="EMI-M00002" he="20.15mm" wi="76.20mm" file="US08626443-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08626443-20140107-M00003.NB">
<img id="EMI-M00003" he="8.81mm" wi="76.20mm" file="US08626443-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for creating a map relating to location-related data on the likelihood of the future movement of a person in a spatial environment, said method comprising
<claim-text>causing at least one person to carry one or more sensors for odometrical measurement (odometry), wherein the odometry is error-prone due to inherent measurement inaccuracies of the one or more sensors,</claim-text>
<claim-text>causing the at least one person to move by foot through the spatial environment,</claim-text>
<claim-text>determining from measurement signals of the one or more sensors information regarding the pedestrian step lengths and/or pedestrian step direction and/or orientation of the sensor or the person (called odometry information Z<sup>u</sup>),</claim-text>
<claim-text>creating a map based on said odometry information using a Bayesian estimator, wherein a state-variable space thereof comprises both the current pedestrian step (pedestrian step length and optionally movement direction change as well) of the person, odometry errors E and also the location-related data on the probabilities of the future movement of the person.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said map is created with a delay during the movement of the person through the environment or after storage of the sensor measurement signals or the detected odometry information.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the computations for creating the map are performed either on an end device carried by the person, or on a server.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising the step of using the created map either for positioning or routing of the person or for improved positioning or routing of other persons.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, for improvement of the odometry information, use is made of measurement signals/data of one or more further sensors including one or more of satellite navigation, magnetic compass, WLAN, measurements for positioning, mobile phone position measurements, UWB measurements for positioning, and/or that use is made of partial regions of a map of the environment for restricting the state space of the Bayesian estimator.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein use is made of real or virtual reference marks which can be perceived by the person and whose presence and optionally position are included as further parameters into the state space of the Bayesian estimator.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method is combined with optical SLAM methods known from robotics by including, into the determining of the state space of the Bayesian estimator, the visual features measured by optical sensors.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein use is made of magnetic sensors by including the respective strength and direction of the local magnetic field as a feature and entering them corresponding to a visual feature into the computations.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the person is provided with a plurality of sensors for reducing odometry errors, wherein an improved odometry can be achieved by combining the measurement signals of the plurality of sensors.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein sensors for odometry can be placed on parts of the body other than the feet/shoes, and that methods known from Pedestrian Dead Reckoning are used for computation and respectively improvement of the odometry.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, as a representation of the likelihood density function of the Bayesian estimator, use is made of the following mathematical product: the conditioned likelihood density of the current odometry errors E, conditioned to the odometry errors in the last time-instant step, multiplied by the conditioned likelihood density of the current pedestrian step vector U, conditioned to the current odometry information Z<sup>u </sup>and the current drift parameter E.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, for a map relating to location-related data on the likelihood of the future movement of a person in a spatial environment, use is made of data on transition probabilities over edges of spatially arranged polygons, wherein, in case of realization by means of a particle filter, the edge transitions of the particle at each polygon transition for this particle are counted and included into a weight computation.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the counters are updated and stored only for one edge between two adjacent polygons and not individually for all edges of all polygons, whereby the required storage capacity can be distinctly reduced.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein use is made of visual odometry methods known from robotics, wherein, with the aid of optical sensors, use is made of the change of the appearance of the environment for estimating the change of location and position of the person.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, with use of polygon representations, e.g. hexagon of the map, the polygon grid is adapted to the environment so as to be configured with varying density, wherein the polygons can overlap and/or a plurality of polygon planes can be used hierarchically and the transition counters are computed separately for each plane, and wherein, in the weight computation of the hypotheses of a particle filter, all planes are included.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, if polygons are used for the map, the polygons are configured with overlap or without overlap and/or are regular or irregular and/or are configured in a plurality of planes.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, if polygons are used for the map, use is made, instead of using a polygon grid, of a regular or irregular arrangement of circles or ovals or other geometric shapes, wherein, instead of counting an edge transition, there is detected the angle via which the shape is left during a pedestrian step or part of a pedestrian step, and an angle range transition counter is evaluated and updated for this angle, wherein, in case of an over-lapping pattern of shapes, there is always selected that shape whose center is closest to the particle, and, in analogy with the realization by hexagons, the angle range transitions are counted and included in the weight computation.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein there are evaluated not only the counters for edge transitions and respectively angle range transitions per hexagon or other structure but also those for each combination of any number of previous transitions.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, when creating the map, use is made of already created maps of other users or other walks of a person, e.g. by placing the &#x201c;a-priori&#x201d; counters for edge transitions of polygon maps onto already measured transition counters and/or performing an iterative processing wherein the map creation for an odometry data set is continuously repeated with use of mutually created maps.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the created map represents three spatial dimensions.</claim-text>
</claim>
</claims>
</us-patent-grant>
