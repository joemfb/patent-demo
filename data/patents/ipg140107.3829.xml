<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624896-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624896</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12129816</doc-number>
<date>20080530</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>P2007-145976</doc-number>
<date>20070531</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1218</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>50</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>60</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345426</main-classification>
<further-classification>345419</further-classification>
<further-classification>345530</further-classification>
</classification-national>
<invention-title id="d2e71">Information processing apparatus, information processing method and computer program</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2002/0129186</doc-number>
<kind>A1</kind>
<name>Emerson et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710302</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2006/0100953</doc-number>
<kind>A1</kind>
<name>Downs</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 37</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>JP</country>
<doc-number>5-266201</doc-number>
<date>19931000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>JP</country>
<doc-number>2004-118713</doc-number>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>WO</country>
<doc-number>WO 2007/049610</doc-number>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>23</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>19</number-of-drawing-sheets>
<number-of-figures>19</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080301681</doc-number>
<kind>A1</kind>
<date>20081204</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Sakamoto</last-name>
<first-name>Junichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yoshimori</last-name>
<first-name>Masaharu</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Nagasaki</last-name>
<first-name>Tanio</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Koyama</last-name>
<first-name>Shinsuke</first-name>
<address>
<city>Chiba</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ito</last-name>
<first-name>Kazumasa</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Takahata</last-name>
<first-name>Minoru</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="007" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Hatakenaka</last-name>
<first-name>Mikako</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="008" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Satoh</last-name>
<first-name>Jin</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="009" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yamada</last-name>
<first-name>Hideshi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="010" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yokota</last-name>
<first-name>Kenichiro</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="011" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Takeuchi</last-name>
<first-name>Hideki</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="012" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ishikawa</last-name>
<first-name>Hitoshi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Sakamoto</last-name>
<first-name>Junichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Yoshimori</last-name>
<first-name>Masaharu</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Nagasaki</last-name>
<first-name>Tanio</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Koyama</last-name>
<first-name>Shinsuke</first-name>
<address>
<city>Chiba</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Ito</last-name>
<first-name>Kazumasa</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Takahata</last-name>
<first-name>Minoru</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="007" designation="us-only">
<addressbook>
<last-name>Hatakenaka</last-name>
<first-name>Mikako</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="008" designation="us-only">
<addressbook>
<last-name>Satoh</last-name>
<first-name>Jin</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="009" designation="us-only">
<addressbook>
<last-name>Yamada</last-name>
<first-name>Hideshi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="010" designation="us-only">
<addressbook>
<last-name>Yokota</last-name>
<first-name>Kenichiro</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="011" designation="us-only">
<addressbook>
<last-name>Takeuchi</last-name>
<first-name>Hideki</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="012" designation="us-only">
<addressbook>
<last-name>Ishikawa</last-name>
<first-name>Hitoshi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Frommer Lawrence &#x26; Haug LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Frommer</last-name>
<first-name>William S.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Broome</last-name>
<first-name>Said</first-name>
<department>2679</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An information processing apparatus including: a plurality of data processing functional blocks each used for carrying out individual data processing; a flow control section configured to execute control of data flows among the data processing functional blocks; and a control section configured to carry out a setting process to set the data processing functional blocks and the flow control section. The control section acquires configuration information in accordance with a task list for data processing to be carried out; carries out the setting process to set the data processing functional blocks and the flow control section on the basis of the acquired configuration information; and constructs a data processing configuration adapted to various kinds of data processing to be carried out.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="151.72mm" wi="230.72mm" file="US08624896-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="230.04mm" wi="160.95mm" orientation="landscape" file="US08624896-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="233.76mm" wi="157.31mm" orientation="landscape" file="US08624896-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="192.70mm" wi="150.79mm" orientation="landscape" file="US08624896-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="229.79mm" wi="162.56mm" orientation="landscape" file="US08624896-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="208.96mm" wi="160.87mm" orientation="landscape" file="US08624896-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="201.17mm" wi="155.79mm" orientation="landscape" file="US08624896-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="238.51mm" wi="164.00mm" orientation="landscape" file="US08624896-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="198.29mm" wi="138.43mm" file="US08624896-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="243.08mm" wi="166.54mm" orientation="landscape" file="US08624896-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="226.14mm" wi="157.48mm" orientation="landscape" file="US08624896-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="226.74mm" wi="151.89mm" orientation="landscape" file="US08624896-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="228.68mm" wi="154.43mm" orientation="landscape" file="US08624896-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="224.45mm" wi="151.64mm" orientation="landscape" file="US08624896-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="237.15mm" wi="162.90mm" orientation="landscape" file="US08624896-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="217.17mm" wi="151.64mm" orientation="landscape" file="US08624896-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="213.78mm" wi="128.35mm" orientation="landscape" file="US08624896-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="191.85mm" wi="156.13mm" orientation="landscape" file="US08624896-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="237.41mm" wi="160.61mm" orientation="landscape" file="US08624896-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="232.07mm" wi="159.51mm" orientation="landscape" file="US08624896-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCES TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present invention contains subject matter related to Japanese Patent Application JP 2007-145976, filed in the Japan Patent Office on May 31, 2007, the entire contents of which being incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to an information processing apparatus, an information processing method and a computer program. To put it in detail, the present invention relates to an information processing apparatus for carrying out 3-dimensional graphic processing accompanying typically a 3DCG process and/or a CODEC process, relates to an information processing method to be adopted by the information processing apparatus and relates to a computer program implementing the information processing method.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">A 3DCG (3-Dimensional Computer Graphics) technology plays a role in displaying 3-dimensional data stored in a computer as a display easy to visually understand by carrying out a coordinate transformation process and a shading process on the data. Thus, the 3DCG technology can be used in a wide range of applications such as a video game and a user interface. In addition, the image CODEC processing includes a decompression process to decompress a compressed image stored in a computer and display an image obtained as a result of the decompression process as well as a compression process carried out inversely to the compression process to compress an image. The image CODEC processing is carried out in an apparatus such as a digital video camera, a digital still camera or a hand phone in order to display an image after decompressing the image or store an image in a memory after compressing the image.</p>
<p id="p-0007" num="0006">In digital apparatus such as a video game, a digital still camera, a digital camera and a hand phone, the 3DCG processing and image CODEC processing are carried out frequently. <figref idref="DRAWINGS">FIG. 17</figref> is a block diagram showing an example of hardware for carrying out the general 3DCG processing and the general image CODEC processing.</p>
<p id="p-0008" num="0007">The typical hardware shown in <figref idref="DRAWINGS">FIG. 17</figref> includes a CPU <b>11</b>, a DSP <b>12</b>, a RAM <b>13</b>, a ROM <b>14</b>, an external IF <b>15</b> and a media processing functional block <b>20</b> typically employing a JPEG processing functional block <b>21</b>, a MPEG processing functional block <b>22</b> and a 3DCG processing functional block <b>23</b> in the case of the example shown in the figure. The JPEG processing functional block <b>21</b> is a section configured to carry out image CODEC processing according to JPEG whereas the MPEG processing functional block <b>22</b> is a section configured to carry out image CODEC processing according to MPEG. The 3DCG processing functional block <b>23</b> is a section configured to carry out a 3DCG function.</p>
<p id="p-0009" num="0008">The JPEG processing functional block <b>21</b>, the MPEG processing functional block <b>22</b> and the 3DCG processing functional block <b>23</b> each have a processing circuit dedicated to processing unique to the functional block. It is to be noted that the dedicated data processing functional blocks are each also referred to as a functional IP (Intellectual Property).</p>
<p id="p-0010" num="0009">Instead of making use of such functional IPs (or dedicated data processing functional blocks), there is a technique referred to as a software processing technique by which software is executed by a general-purpose computer having a high processing speed. Since image drawing processing must be generally carried out in a real-time manner, however, the performance of a CPU employed in an ordinary digital apparatus is not high enough for executing the image drawing processing in a real-time manner. For this reason, a dedicated processing circuit is normally used for executing the image drawing processing in a real-time manner. In this case, however, all functional IPs (dedicated data processing functional blocks) must be employed in the dedicated processing circuit, raising a problem of an increased area of an LSI for implementing the functional IPs.</p>
<p id="p-0011" num="0010">A demand made in past recent years as a demand for a high performance of each IP function is lower than the same demand made presently. Thus, even if a logic circuit was employed for each function in the dedicated processing module, there was no problem. However, there is now a demand for data processing to make the 3DCG technology abundant in image expressions. For example, by carrying out a shading process making use of a program referred to as a shader, it is possible to make the 3DCG technology abundant in image expressions. In a typical shading process adopting a shading technique based on the 3DCG technology, the brightness of each corner point of a plane is computed and the brightness of each point on the plane is then found by linear interpolation based on the computed brightness of each corner point. In addition, the 3DCG technology has been becoming advanced along with the rising demand for performance and functions. As for the image CODEC technology, its algorithm has been becoming complicated and diversified as indicated by the following progression:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>MPEG-2&#x2192;MPEG-4&#x2192;MPEG-4AVC/H.264<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0012" num="0011">The configurations of the general processes based on the 3DCG and the CODEC technologies are explained by referring to <figref idref="DRAWINGS">FIGS. 18 and 19</figref> respectively. 3DCG processing is explained by taking an OpenGl process, which is a typical API, as an example. The configuration shown in <figref idref="DRAWINGS">FIG. 18</figref> as the configuration of the 3DCG processing is introduced in the following document: OpenGL, 2.0 Overview 2003 3Dlabs, Inc.</p>
<p id="p-0013" num="0012">Vertex information stored in advance in a memory <b>31</b> as information on vertices of an object coordinate system is transferred to a vertex processor <b>32</b>. The vertex processor <b>32</b> executes a program prepared in advance in order to carry out vertex processing on the vertex information. As a result of the vertex processing, the vertex processor <b>32</b> supplies output vertex information set in a clip coordinate system to a vertex-information processing execution unit <b>35</b>. The vertex-information processing execution unit <b>35</b> outputs its result to a clip/project view cull process <b>36</b>. The clip/project view cull process <b>36</b> is carried out on the result received from the vertex-information processing execution unit <b>35</b>. The clip/project view cull process <b>36</b> outputs its result to a rasterize process <b>37</b>.</p>
<p id="p-0014" num="0013">Fragments output by the rasterize process <b>37</b> are supplied to a fragment processor <b>38</b> for carrying out a fragment process. Besides the fragment process, the fragment processor <b>38</b> may also carry out a variety of blend processes by using a texture read out from a texture memory <b>40</b>. The fragment processor <b>38</b> outputs a result of the fragment process to a per fragment operation <b>39</b>. The result of the per fragment operation <b>39</b> is supplied to a frame buffer <b>41</b>. The result stored in the frame buffer <b>41</b> is then is subjected to a 1-frame process, a result of which is finally read out from the frame buffer <b>41</b> and displayed. It is to be noted that details of the 3DCG processing are described in a document describing the OpenGL 2.0 standard with a title of &#x201c;The OpenGL Graphic System: A Specification.&#x201d;</p>
<p id="p-0015" num="0014">An image CODEC compression process is carried out in accordance with typically an image CODEC processing configuration shown in <figref idref="DRAWINGS">FIG. 19</figref>. An input image is subjected to an intra-frame prediction process. As an alternative, a result of a movement compensation process carried out on different frames is subtracted from the input image to give a difference which is then sequentially subjected to an orthogonal transform process, a quantization process and an entropy encoding process. The output of the quantization process is supplied to an inverse quantization process whereas the output of the inverse quantization process is supplied to an inverse orthogonal transform process. The output of the inverse orthogonal transform process is added to the result of the movement compensation process and the sum is filtered in a loop filtering process. An image frame of the loop filtering process is then stored in a frame memory. The movement compensation process is a movement prediction process carried out on an image stored in the frame memory. In addition, a vector output by the movement prediction process and the output of the intra-frame prediction process are also subjected to the entropy encoding process in the same way as the output of the quantization process. The result of the entropy encoding process is a stream.</p>
<p id="p-0016" num="0015">CODEC decoding processing is basically process carried out in a sequence inverse to that of the CODEC encoding processing described above. However, the CODEC decoding processing does not include the movement prediction process and the inverse processes (that is, the inverse quantization process and the inverse orthogonal transform process).</p>
<p id="p-0017" num="0016">As described above, <figref idref="DRAWINGS">FIG. 18</figref> shows the configuration of the 3DCG processing whereas <figref idref="DRAWINGS">FIG. 19</figref> shows the configuration of the image CODEC processing. In an ordinary configuration, each of the 3DCG and the image CODEC processing is carried out by an independent functional IP or a data processing functional block. To put it concretely, as described earlier by referring to <figref idref="DRAWINGS">FIG. 17</figref>, the JPEG processing functional block <b>21</b> is a section configured to carry out image CODEC processing according to JPEG whereas the MPEG processing functional block <b>22</b> is a section configured to carry out image CODEC processing according to MPEG. The 3DCG processing functional block <b>23</b> is a section configured to carry out the 3DCG processing.</p>
<p id="p-0018" num="0017">In the case of the image CODEC processing supporting a plurality of standards, some circuits such as a movement detection circuit and a movement compensation circuit may be shared by the standards as circuits common to the standards. For every one of the standards, however, there are also a number of peculiar circuits. In addition, logic circuits of any other function such as the 3DCG circuit are not circuits that can be shared by the standards. Examples of functional IP (or each dedicated data processing functional block) of the image CODEC processing are the JPEG processing functional block <b>21</b> for carrying out image CODEC processing according to JPEG and the MPEG processing functional block <b>22</b> for carrying out image CODEC processing according to MPEG as shown in <figref idref="DRAWINGS">FIG. 17</figref>.</p>
<p id="p-0019" num="0018">If each functional IP (or each dedicated data processing functional block) is employed in accordance with such a technique, the size of the circuit becomes large. In order to meet a demand for a high speed in every process and keep up with an increase of the amount of processed data, a gate is used for every implementing functional IP (or every dedicated data processing functional block) as a logic circuit. In this case, the size of the gate also increases. Thus, the area of an LSI mounted on the digital apparatus increases and, as a result, the manufacturing cost also rises faster. In addition, if the area of an LSI mounted on the digital apparatus put to practical use increases, there is raised a problem that the power consumptions of the LSI and the digital apparatus rise due to leak currents that flow even if a variety of functions are not being carried out.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0020" num="0019">In order to solve the problems including those described above, inventors of the invention have proposed an information processing apparatus, an information processing method to be adopted by the apparatus and a computer program implementing the method. The proposed information processing apparatus has a small size as well as a low power consumption and is applicable to various kinds of data processing by implementing:</p>
<p id="p-0021" num="0020">an extracted portion common to all the kinds of data processing such as the 3DCG processing as the CODE process as fixed logic circuits each having a low power consumption; and</p>
<p id="p-0022" num="0021">portions each peculiar to a kind of data processing as a programmable circuit which is usable as a circuit common to all the kinds of data processing.</p>
<p id="p-0023" num="0022">According to an embodiment of the present invention, there is provided an information processing apparatus including:</p>
<p id="p-0024" num="0023">a plurality of data processing functional blocks each used for carrying out an individual data processing;</p>
<p id="p-0025" num="0024">a flow control section configured to execute control of data flows among the data processing functional blocks; and</p>
<p id="p-0026" num="0025">a control section configured to carry out a setting process to set the data processing functional blocks and the flow control section,</p>
<p id="h-0004" num="0000">wherein the control section:</p>
<p id="p-0027" num="0026">acquires configuration information in accordance with a task list for data processing to be carried out;</p>
<p id="p-0028" num="0027">carries out the setting process to set the data processing functional blocks and the flow control section on the basis of the acquired configuration information; and</p>
<p id="p-0029" num="0028">constructs a data processing configuration adapted to various kinds of data processing to be carried out.</p>
<p id="p-0030" num="0029">According to another embodiment of the present invention, there is provided an information processing apparatus according to claim <b>1</b> wherein at least some of the data processing functional blocks are configured to function as data processing functional blocks for carrying out a variety of processes according to a received instruction and configured into a configuration capable of performing different kinds of data processing in conformity with the setting process carried out by the control section.</p>
<p id="p-0031" num="0030">According to yet another embodiment of the present invention, there is provided an information processing method to be adopted in an information processing apparatus including:</p>
<p id="p-0032" num="0031">a plurality of data processing functional blocks each used for carrying out an individual data process;</p>
<p id="p-0033" num="0032">a flow control section configured to execute control of data flows among the data processing functional blocks; and</p>
<p id="p-0034" num="0033">a control section configured to carry out a setting process to set the data processing functional blocks and the flow control section, wherein the control section executes the steps of:</p>
<p id="p-0035" num="0034">acquiring configuration information in accordance with a task list for data processing to be carried out;</p>
<p id="p-0036" num="0035">carrying out a setting process to set the data processing functional blocks and the flow control section on the basis of the acquired configuration information; and</p>
<p id="p-0037" num="0036">constructing a data processing configuration adapted to the data processing to be carried out.</p>
<p id="p-0038" num="0037">According to yet another embodiment of the present invention, there is provided a computer program to be executed to drive an information processing apparatus including:</p>
<p id="p-0039" num="0038">a plurality of data processing functional blocks each used for carrying out an individual block process;</p>
<p id="p-0040" num="0039">a flow control section configured to execute control of data flows among the data processing functional blocks; and</p>
<p id="p-0041" num="0040">a control section configured to carry out a process to set the data processing functional blocks and the flow control section,</p>
<p id="h-0005" num="0000">wherein the control section executes the steps of:</p>
<p id="p-0042" num="0041">acquiring configuration information in accordance with a task list for data processing to be carried out;</p>
<p id="p-0043" num="0042">carrying out a setting process to set the data processing functional blocks and the flow control section on the basis of the acquired configuration information; and</p>
<p id="p-0044" num="0043">constructing a data processing configuration adapted to the data processing to be carried out.</p>
<p id="p-0045" num="0044">In accordance with a configuration of an information processing apparatus, the apparatus employs:</p>
<p id="p-0046" num="0045">a plurality of data processing functional blocks each used for carrying out an individual block process;</p>
<p id="p-0047" num="0046">a flow control section configured to execute control of data flows among the data processing functional blocks; and</p>
<p id="p-0048" num="0047">a control section configured to carry out a process to set the data processing functional blocks and the flow control section,</p>
<p id="p-0049" num="0048">wherein the control section:</p>
<p id="p-0050" num="0049">acquires configuration information in accordance with a task list for data processing to be carried out;</p>
<p id="p-0051" num="0050">carries out a setting process to set the data processing functional blocks and the flow control section on the basis of the acquired configuration information; and</p>
<p id="p-0052" num="0051">constructs a data processing configuration adapted to the data processing to be carried out.</p>
<p id="p-0053" num="0052">Thus, processing such as the 3DCG processing and the image CODEC processing can be carried out by data processing functional blocks common to different kinds of data processing so that it is possible to provide an information processing apparatus allowing an implementation area of the information processing apparatus to be reduced. In addition, it is possible to decrease the cost of manufacturing the information processing apparatus as well as the power consumption of the apparatus.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing a data processing section employed in an information processing apparatus according to the embodiment of the present invention;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 2</figref> is a plurality of diagrams showing a typical task list used in the information processing apparatus according to the embodiment of the present invention;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 2A</figref> is a diagram showing a list of tasks;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 2B</figref> is a diagram showing information blocks each related to one of the tasks;</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 2C</figref> is a diagram showing different active maps included in each information block;</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 3</figref> is an explanatory diagram to be referred to in description of a process to set configuration information in the information processing apparatus according to the embodiment of the present invention;</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 4</figref> is an explanatory diagram to be referred to in description of a sequence of operations carried out by the data processing section in a process to draw an image without a texture;</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 5</figref> is an explanatory diagram to be referred to in description of a sequence of operations carried out by the data processing section in a typical 3DCG process to draw an image by adoption of a texture mapping technique;</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 6</figref> is an explanatory diagram to be referred to in description of a sequence of operations carried out by the data processing section in a typical 3DCG process to draw an image by adoption of a texture mapping technique;</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. 7</figref> is an explanatory diagram to be referred to in description of a sequence of operations carried out in an image CODEC decoding process performed by the data processing section;</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 8</figref> is an explanatory diagram to be referred to in description of a process carried out by a TU (texture unit);</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 9</figref> is an explanatory diagram to be referred to in description of a typical configuration of an SE (the shader element);</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. 10</figref> is an explanatory diagram to be referred to in description of a typical configuration of the data processing section in which 1 of 4 SEs (the shader elements) is set as a VS (vertex shader) element and the 3 remaining SEs are each set as an FS (fragment shader) element;</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 11</figref> is an explanatory diagram to be referred to in description of a typical configuration of the data processing section in which 4 SEs (the shader elements) are each set as a VS (vertex shader) element;</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 12</figref> is an explanatory diagram to be referred to in description of a typical configuration of the data processing section in which 4 SEs (the shader elements) are each set as an FS (fragment shader) element;</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 13</figref> is an explanatory diagram to be referred to in description of a sequence of operations carried out by the data processing section in a process to generate a contracted image;</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 14</figref> is an explanatory diagram to be referred to in description of processing carried out by an ADU (Arbitration Distribution Unit) to control flows of data;</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 15</figref> is a block diagram showing a detailed configuration of a second sub-ADU (Arbitration Distribution Unit);</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 16</figref> is an explanatory diagram to be referred to in description of processing carried out by the second sub-ADU (Arbitration Distribution Unit) to control flows of data;</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. 17</figref> is a block diagram showing an example of hardware for carrying out general 3DCG processing and general image CODEC processing.</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 18</figref> is a block diagram showing an example of hardware for carrying out the general 3DCG processing; and</p>
<p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. 19</figref> is a block diagram showing an example of hardware for carrying out the general CODEC processing.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0076" num="0075">By referring to diagrams, the following description explains details of an information processing apparatus, details of an information processing method to be adopted by the information processing apparatus and details of a computer program implementing the information processing method.</p>
<p id="p-0077" num="0076">First of all, an outline of the present invention is explained. The information processing apparatus provided by the present invention employs hardware common to at least some of processes in the 3DCG processing and the image CODEC processing such as processes conforming to standards such as MPEG and JPEG.</p>
<p id="p-0078" num="0077">The image CODEC processing includes, among other processes, the quantization process, the orthogonal transform process (or the DCT (Discrete Cosine Transformation) process), a movement search process and a movement compensation process. The orthogonal transform process is a process to compress or decompress macro-blocks. For the quantization process and the orthogonal transform process, processing varying from standard to standard is carried out. For the movement search process and the movement compensation process, however, almost the same intra-image search processing and almost the same filtering processing are carried out for different standards which include MPEG and JPEG. In addition, it is desirable to implement the intra-image search processing and the filtering processing by making use of a temporary local image memory area and a filtering processor which are means also usable in 3DCG texture processing. Thus, one data processing functional block can be used to carry out the movement search process, the movement compensation process and the texture process.</p>
<p id="p-0079" num="0078">In addition, for example, a pixel process of the image CODEC macro-block processing can be best carried out as parallel processing. In this case, typically, a processor capable of carrying out 4 parallel processes on 4 inputs respectively is used to perform the parallel processing. In this way, an increased processing speed due to a 4<sup>th </sup>or 8<sup>th </sup>order of parallelism can be anticipated. In addition, the coordinate transformation of the vertex shader process in the 3DCG processing and the fragment sub-process of the fragment shader process of the 3DCG processing can each be carried out as parallel processing as well. Thus, an increased processing speed due to the 4<sup>th </sup>order of parallelism can be realized.</p>
<p id="p-0080" num="0079">In the case of the 3DCG processing for example, as explained earlier by referring to <figref idref="DRAWINGS">FIG. 18</figref>, processes such as the vertex process and the fragment process are carried out. In the vertex shader process carried out as the vertex process, the coordinates of (x, y, z, w) of a vertex are taken as data being processed and data processing is carried out in accordance with the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>x&#x2032;,y&#x2032;,z&#x2032;,w</i>)=ModelView &#x26; Projection matrix*(<i>x,y,z,w</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0081" num="0080">In the fragment shader process, on the other hand, values (r, g, b, a) are taken as data being processed and data processing is carried out in accordance with the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>r,g,b,a</i>)=(<i>r</i>1<i>,g</i>1<i>,b</i>1<i>,a</i>1)+(<i>r</i>2<i>,g</i>2<i>,b</i>2<i>,a</i>2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where (r, g, b, a) is red, green and blue color values of a pixel and an alpha value thereof.
</p>
<p id="p-0082" num="0081">In the case of the image CODEC processing, on the other hand, a 1-dimensional integer DCT process conforming to the MPEG-4AVC/H.264 standard is typically carried out. In this DCT process, DCT transformation is applied to an input (a<b>0</b>, a<b>1</b>, a<b>2</b>, a<b>3</b>) serving as the subject of transformation in accordance with the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>A</i>0<i>,A</i>1<i>,A</i>2<i>,A</i>3)=Transformation matrix*(<i>a</i>0<i>,a</i>1<i>,a</i>2<i>,a</i>3).<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0083" num="0082">As described above, all the pieces of data processing are carried out on the basis of similar computations.</p>
<p id="p-0084" num="0083">It is to be noted that processes of the image CODEC processing are carried out in a way varying among a variety of CODEC standards such as JPEG, MPEG-2, MPEG-4 and MPEG-4AVC/H.264. The processes of the image CODEC processing are the macro-block orthogonal transform process and the quantization process (or the inverse macro-block orthogonal transform process and the inverse quantization process) as well as the intra-block filtering process. In addition, processes of the 3DGC processing are required to be processes that can be programmed freely by the user which is a programmer or a designer. The processes of the 3DGC processing are the vertex shader program and the fragment shader program. It is thus desirable to have these processes as processor processing executable by making use of a variety of programs. In the configuration of the present invention, these processes are implemented as a data processing functional block provided with a processing execution section configured to carry out parallel processing.</p>
<p id="p-0085" num="0084">It is to be noted that, even if the data processing functional block usable as a block common to the 3DCG processing and the image CODEC processing has been set, it is still necessary to implement a variety of processes along data processing sequences. For example, in the case of the 3DGC processing, processes are carried out along the following data processing sequence:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Memory&#x2192;Vertex shader process&#x2192;Rasterize process&#x2192;Fragment shader process&#x2192;Per fragment operation&#x2192;Memory<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0086" num="0085">As described above, the vertex shader process and the fragment shader process in the above data processing sequence are each required to be a process carried out by execution of a program. Since the vertex shader process and the fragment shader process are set before and after the rasterize process, a data transfer is required as follows. A data processing section executing a program of the vertex shader process carries out the vertex shader process and outputs the result of the execution of the vertex shader process to the rasterize process. Then, the result of the rasterize process is supplied back to the same data processing section executing a program of the fragment shader process. This time, the data processing section carries out the fragment shader process.</p>
<p id="p-0087" num="0086">In the case of the image CODEC processing, on the other hand, processes are carried out along the following data processing sequence:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Memory&#x2192;Entropy decoding process&#x2192;Inverse quantization process&#x2192;Inverse orthogonal transform process&#x2192;Block integration process&#x2192;Memory<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0088" num="0087">The inverse quantization process and the inverse orthogonal transform process in the above data processing sequence can each be properly carried out by execution of a program. Since the inverse quantization process and the inverse orthogonal transform process are carried out successively in the above data processing sequence, however, a data processing section configured to execute the program is capable of carrying out these processes as a sequence of processes without the need to supply data to an external recipient and receive data from an external source.</p>
<p id="p-0089" num="0088">Thus, it is possible to provide a configuration employing a data processing section (IP: functional bloc) configured to carry out the vertex shader process and fragment shader process of the 3DCG processing as well as the inverse quantization process and inverse orthogonal transform process of the image CODEC processing. If the hardware of the configuration is designed as hardware oriented for a specific process only, however, the configuration will have a problem that the hardware cannot be used to carry out processes other than the specific one.</p>
<p id="p-0090" num="0089">The information processing apparatus according to the embodiment of the present invention is provided with hardware capable of carrying out various kinds of data processing like the ones described above. That is to say, the information processing apparatus has hardware common to all the kinds of data processing. In addition, the information processing apparatus has a data processing section capable of carrying out a variety of data processing sequences by execution of programs each provided for a process.</p>
<p id="p-0091" num="0090">A concrete embodiment implementing the information processing apparatus according to the present invention is explained as follows. The embodiment explained in the following description implements an information processing apparatus having a data processing section capable of carrying out an image drawing process of the 3DCG processing and the image CODEC process.</p>
<p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing a data processing section <b>100</b> employed in an information processing apparatus according to the embodiment of the present invention. The data processing section <b>100</b> is typically designed as an LSI having a plurality of data processing functional blocks each used for carrying out individual data processing. In the case of the embodiment shown in the figure, the data processing functional blocks are enumerated as follows: SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), a rasterizer <b>131</b>, a PPU (pixel processing unit) <b>141</b> and a TU (texture unit) <b>121</b>. In addition, the data processing section <b>100</b> also employs an ADU (arbitration distribution unit) <b>150</b> and a TC (Task Controller) <b>101</b>. The ADU (arbitration distribution unit) <b>150</b> is a flow control section configured to execute control of data flows among the data processing functional blocks. The TC (task controller) <b>101</b> is a control section configured to carry out a setting process to set the data processing functional blocks and the ADU (arbitration distribution unit) <b>150</b>. The TC (task controller) <b>101</b> functioning as a control section in the data processing section <b>100</b> acquires configuration information in accordance with a task list for data processing to be carried out, carries out a setting process to set the data processing functional blocks as well as the ADU (arbitration distribution unit) <b>150</b> serving as the flow control section on the basis of the acquired configuration information and constructs a data processing configuration adapted to the data processing to be carried out.</p>
<p id="p-0093" num="0092">It is to be noted that, even though the flow control section (that is, the ADU (arbitration distribution unit) <b>150</b>) is not shown as a block in <figref idref="DRAWINGS">FIG. 1</figref>, the ADU (arbitration distribution unit) <b>150</b> is a unit for executing control of data flows among the data processing functional blocks. The data flow control executed by the ADU (arbitration distribution unit) <b>150</b> will be explained later.</p>
<p id="p-0094" num="0093">As described above, the data processing section <b>100</b> employs the TC (task controller) <b>101</b>. The TC (task controller) <b>101</b> has the function of a host interface. To put it concretely, the TC (task controller) <b>101</b> receives a command as a task list from an upper-level host CPU executing software of applications and libraries. The task list is interpreted as the substance of processing including requests each made for an access to a register. The TC (task controller) <b>101</b> then activates the entire data processing section <b>100</b> and carries out a process to synchronize the internal elements of the data processing section <b>100</b>. In addition, the TC (task controller) <b>101</b> also carries out the entropy encoding and decoding processes of the image CODEC processing.</p>
<p id="p-0095" num="0094">The shader elements <b>110</b> to <b>113</b> each referred to hereafter simply as an SE each carry out the following processes and operations:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0095">(a): a vertex element operation of the vertex shader process in the 3DCG processing;</li>
    <li id="ul0001-0002" num="0096">(b): a fragment element operation of the fragment shader process in the 3DCG processing; and</li>
    <li id="ul0001-0003" num="0097">(c): the macro-block quantization and inverse quantization processes, the orthogonal transform and inverse orthogonal transform processes, an intra prediction compensation process, a block integration process and an in-loop filtering process in the image CODEC processing.</li>
</ul>
</p>
<p id="p-0096" num="0098">In the case of this embodiment, the operations (a) and (b) as well as the processes (c) are carried out as SIMD parallel processing by execution of programs.</p>
<p id="p-0097" num="0099">The embodiment shown in the figure employs four SEs (shader elements). It is to be noted, however, that the shader-element count of four is typical. That is to say, the number of shader elements can be set at any value according to a desired number of parallel processes. For example, the number of shader elements can be set at any value up to 256.</p>
<p id="p-0098" num="0100">The TU (Texture Unit) <b>121</b> carries out the following processes:
<ul id="ul0002" list-style="none">
    <li id="ul0002-0001" num="0101">(a): Processes of the 3DCG processing. These processes include sampling of a texture mapping process, texture point sampling which is a filtering function, a bilinear filtering process, a tri-linear filtering process, anisotropic filtering process, a cubemap process and a MIPMAP image generation process.</li>
    <li id="ul0002-0002" num="0102">(b): Processes of the image CODEC processing. These processes include a movement compensation process and a movement detection process.</li>
</ul>
</p>
<p id="p-0099" num="0103">In the 3DCG processing, the rasterizer <b>131</b> carries out a view port transformation process, a perspective division process, a clipping process, a triangle setup process, a point sprite extension process, a pixel interpolation process, a multi-sampling process, a scissoring process, a polygon offset process, a depth range process and a face culling process. These processes are referred to as a rasterize process.</p>
<p id="p-0100" num="0104">The PPU (Pixel Processing Unit) <b>141</b> has a function to carry out a per fragment operation in the 3DCG processing and a pixel read/write function.</p>
<p id="p-0101" num="0105">The data processing section <b>100</b> also employs a DMAC (direct memory access controller) <b>142</b> having a function for interfacing with an external memory provided externally to the data processing section <b>100</b>. To be more specific, the DMAC (direct memory access controller) <b>142</b> is a section configured to control a DMA (direct memory access) transfer of receiving data from the external memory and storing the transferred data into a local memory <b>143</b>.</p>
<p id="p-0102" num="0106">The local memory <b>143</b> is a memory for storing data transferred from the external memory and temporarily storing data being processed internally in the data processing section <b>100</b>.</p>
<p id="p-0103" num="0107">It is to be noted that the data processing section <b>100</b> carries out the vertex shader process and the fragment shader process in the 3DCG processing as well as the quantization process (or the inverse quantization process) and the orthogonal transform process (or the inverse orthogonal transform process) in the CODEC processing. It is thus necessary to carry out operations to transfer data output by these processes among configuration elements employed in the data processing section <b>100</b> and operations to supply data to the processes in different ways.</p>
<p id="p-0104" num="0108">In order to change the data transferring or supplying way in accordance with the type of the process, it needs to provide the data processing section <b>100</b> with the ADU (arbitration distribution unit) <b>150</b> which is shown as a direct link or a bus in the figure. In actuality, the ADU (arbitration distribution unit) <b>150</b> employs a data buffer and/or a cross switch.</p>
<p id="p-0105" num="0109">An outline of processing carried out by the data processing section <b>100</b> shown in the figure is explained as follows.</p>
<p id="p-0106" num="0110">First of all, typical operations in typical 3DCG processing are explained. A task list transmitted by an upper-level host CPU outside the data processing section <b>100</b> to the data processing section <b>100</b> by way of a host IF is stored in the TC (task controller) <b>101</b>. A task in the task list is then activated by execution of a register write process. The TC (task controller) <b>101</b> gives a DMA transfer command to the DMAC (direct memory access controller) <b>142</b> in accordance with the task list.</p>
<p id="p-0107" num="0111"><figref idref="DRAWINGS">FIG. 2</figref> is a plurality of diagrams showing a typical task list used in the embodiment. As shown in <figref idref="DRAWINGS">FIG. 2A</figref>, the task list includes a plurality of tasks each used as a processing unit. As shown in <figref idref="DRAWINGS">FIG. 2B</figref>, a task has a plurality of passes each used as a DMA transfer unit. Each of the passes prescribes the base address of data to be transferred from the external memory, the size of the data, a synchronization mode and an active map. The tasks each including such passes are arranged on the task list in a task-execution order. In the case of the typical task list shown in the figure, the tasks are carried out as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>task 0&#x2192;task 1&#x2192;task 2 . . . task n<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0108" num="0112">In each of the tasks, passes of the task are executed in the following order:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>initialization pass&#x2192;pass 1&#x2192;pass 2<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0109" num="0113">The base address of data to be transferred from the external memory and the size of the data are information used for carrying out a DMA transfer. That is to say, in accordance with control executed by the DMAC (direct memory access controller) <b>142</b> on the basis of the information, the DMA transfer is carried out. The synchronization mode prescribes a timing to start a DMA transfer between passes. The active map prescribes data processing functional blocks to be activated as blocks each required in the pass to be executed.</p>
<p id="p-0110" num="0114">As shown in <figref idref="DRAWINGS">FIG. 2C</figref>, the active map is a plurality of flags each indicating whether or not a data processing functional block represented by the flag is to be activated for executing data processing. The data processing functional blocks each represented by a flag are those shown in <figref idref="DRAWINGS">FIG. 1</figref>. That is to say, the data processing functional block represented by the flags are the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), the rasterizer <b>131</b>, the PPU (pixel processing unit) <b>141</b> and the TU (texture unit) <b>121</b>. Typically, a flag set at 1 indicates an active data processing functional block. That is to say, a flag set at 1 indicates that the data processing functional block represented by the flag is used in the processing. On the other hand, a flag set at 0 indicates an inactive data processing functional block. That is to say, a flag set at 0 indicates that the data processing functional block represented by the flag is not used in the processing.</p>
<p id="p-0111" num="0115">The typical active map shown in <figref idref="DRAWINGS">FIG. 2C</figref> indicates that, the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) and the TU (texture unit) <b>121</b> are used as a processing configuration in the image CODEC processing, the PPU (pixel processing unit) <b>141</b> and the TU (texture unit) <b>121</b> are used as a processing configuration in contracted-image generation processing whereas the shader element (SE <b>3</b>) <b>113</b>, the rasterizer <b>131</b>, the PPU (pixel processing unit) <b>141</b> and the TU (texture unit) <b>121</b> are used as a processing configuration in the 3DCG processing with a small load.</p>
<p id="p-0112" num="0116">It is to be noted that a process carried out by a shader element varies in accordance with the processing to which the process pertains. For example, in the 3DCG processing, the control section sets the shader elements to carry out the vertex shader process and the fragment shader process. In the image CODEC processing, on the other hand, the control section sets the shader elements to carry out the macro-block process.</p>
<p id="p-0113" num="0117">The TC (task controller) <b>101</b> functioning as the control section carries out a setting process according to data processing to be performed in the initialization pass of a task on the task list shown in <figref idref="DRAWINGS">FIG. 2</figref>. That is to say, the TC (task controller) <b>101</b> carries out an initial setting process required as a process common to the passes in the task. A plurality of the data processing functional blocks employed in the data processing section <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> each have a setting register referred to hereafter as a configuration register. For example, the rasterizer <b>131</b> has a configuration register called RA_PRIM. The RA_PRIM configuration register is a register for prescribing the type of a primitive used in a drawing process in the 3DCG processing. Such configuration registers are set as follows. As shown in <figref idref="DRAWINGS">FIG. 3</figref>, the DMAC (direct memory access controller) <b>142</b> transfers setting data also referred to as configuration information from the external memory to the inside of the data processing section <b>100</b>. The setting data is then distributed to configuration registers each included in a data processing functional block indicated by a register address through the ADU (arbitration distribution unit) <b>150</b>. Dashed-line arrows shown in <figref idref="DRAWINGS">FIG. 3</figref> each represent a path of the setting data transferred to a configuration register.</p>
<p id="p-0114" num="0118">By referring to <figref idref="DRAWINGS">FIG. 4</figref>, the following description explains a processing sequence of a drawing process carried out by the data processing section <b>100</b> without a texture. Also in the case of the execution of a drawing process in the data processing section <b>100</b> without a texture, the process is carried out on the basis of a task list like one shown in <figref idref="DRAWINGS">FIG. 2</figref> too. As described above, an initial setting process in an initialization pass is required as a process common to the passes in a task. After the initialization pass has been carried out, the drawing process is actually carried out in pass <b>1</b>. In this case, by the same token, the TC (task controller) <b>101</b> drives the DMAC (direct memory access controller) <b>142</b> to start a DMA transfer to transfer vertex-array data to be processed from the external memory to the inside of the data processing section <b>100</b>.</p>
<p id="p-0115" num="0119">As shown in <figref idref="DRAWINGS">FIG. 4</figref>, when carrying out a drawing process without a texture, the SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>) are used in a VS (vertex shader) process whereas the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) are used in a FS (fragment shader) process.</p>
<p id="p-0116" num="0120">The vertex-array data is distributed to the SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>) set as elements to be used in the VS (vertex shader) process through the ADU (arbitration distribution unit) <b>150</b> in the following order: SE <b>0</b>&#x2192;SE <b>1</b>&#x2192;SE <b>0</b>&#x2192;SE <b>1</b>. Arrows shown in <figref idref="DRAWINGS">FIG. 4</figref> as arrows pointing to data processing functional blocks and arrows leaving data processing functional blocks form data flows set by the ADU (arbitration distribution unit) <b>150</b> in this processing. In the typical processing shown in <figref idref="DRAWINGS">FIG. 4</figref>, the number of shading elements (SEs) used in the VS (vertex shader) is two. It is to be noted, however, that the shading-element count of two is merely a typical value. The number of shading elements (SEs) used in the VS (vertex shader) process can be set at any integer in the range zero to four.</p>
<p id="p-0117" num="0121">The SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>) used in a VS (vertex shader) process each take the vertex-array data supplied thereto as data to be processed and carry out the VS (vertex shader) process in accordance with information set in the configuration register by execution of an internal program. Results of the VS (vertex shader) process are supplied to the rasterizer <b>131</b>. At that time, the results of the VS (vertex shader) process are supplied to the rasterizer <b>131</b> through the ADU (arbitration distribution unit) <b>150</b> in the same order in which the vertex-array data is distributed to the SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>) through the ADU (arbitration distribution unit) <b>150</b>. The rasterizer <b>131</b> carries out a rasterize process and outputs the results of the process to the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) used in an FS (fragment shader) process.</p>
<p id="p-0118" num="0122">The number of SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) used in an FS (fragment shader) process is also two. Also in this case, the rasterize-process results output by the rasterizer <b>131</b> are sequentially distributed to the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) set as elements to be used in the FS (fragment shader) process through the ADU (arbitration distribution unit) <b>150</b> in the following order: SE <b>2</b>&#x2192;SE <b>3</b>&#x2192;SE <b>2</b>&#x2192;SE <b>3</b>.</p>
<p id="p-0119" num="0123">The SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) used in an FS (fragment shader) process carry out a process on fragment elements and output the result of the process to the PPU (pixel processing unit) <b>141</b>. The SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) also output the result of the process to the PPU (pixel processing unit) <b>141</b> through the ADU (arbitration distribution unit) <b>150</b> in the same order in which the rasterize-process results are distributed to the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>).</p>
<p id="p-0120" num="0124">The PPU (pixel processing unit) <b>141</b> carries out a per fragment operation. Then, the DMAC (direct memory access controller) <b>142</b> transfers the result of the per fragment operation from the local memory <b>143</b> to the external memory.</p>
<p id="p-0121" num="0125">By referring to <figref idref="DRAWINGS">FIGS. 5 and 6</figref>, the following description explains a processing sequence of a drawing process carried out by the data processing section <b>100</b> adopting a texture mapping technique in the 3DCG processing.</p>
<p id="p-0122" num="0126">Also in the case of the execution of a drawing process in the data processing section <b>100</b> with a texture, the process is carried out on the basis of a task list like one shown in <figref idref="DRAWINGS">FIG. 2</figref> too. As described above, an initial setting process in an initialization pass is required as a process common to the passes in a task. After the initialization pass has been carried out, the drawing process is actually carried out in passes <b>1</b> and <b>2</b>. In this case, by the same token, the TC (task controller) <b>101</b> drives the DMAC (direct memory access controller) <b>142</b> to start a DMA transfer to transfer vertex-array data to be processed from the external memory to the inside of the data processing section <b>100</b>. The process of pass <b>1</b> is explained by referring to <figref idref="DRAWINGS">FIG. 5</figref> whereas the process of pass <b>2</b> is explained by referring to <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0123" num="0127">First of all, the process of pass <b>1</b> is explained by referring to <figref idref="DRAWINGS">FIG. 5</figref>. When a drawing process with a texture is carried out, the ADU (arbitration distribution unit) <b>150</b> sets data paths according to arrows pointing to and leaving the data processing functional blocks shown in <figref idref="DRAWINGS">FIG. 5</figref>. In the case of this processing, the SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>) are used in a VS (vertex shader) process whereas the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) are used in a FS (fragment shader) process.</p>
<p id="p-0124" num="0128">The vertex-array data is distributed to the SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>) set as elements to be used in the VS (vertex shader) process through the ADU (arbitration distribution unit) <b>150</b> in the following order: SE <b>0</b>&#x2192;SE <b>1</b>&#x2192;SE <b>0</b>&#x2192;SE <b>1</b>. The SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>) used in a VS (vertex shader) process each take the vertex-array data supplied thereto as data to be processed and carry out the VS (vertex shader) process in accordance with information set in the configuration register by execution of an internal program. Results of the VS (vertex shader) process are supplied to the rasterizer <b>131</b>. At that time, the results of the VS (vertex shader) process are supplied to the rasterizer <b>131</b> in the same order in which the vertex-array data is distributed to the SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>). The rasterizer <b>131</b> carries out a rasterize process and outputs the results of the process to the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) used in an FS (fragment shader) process.</p>
<p id="p-0125" num="0129">The process explained above is the same as the process explained by referring to <figref idref="DRAWINGS">FIG. 4</figref> as a drawing process without a texture. In the case of the drawing process with a texture, however, the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) used in a FS (fragment shader) process compute a texture address from a fragment element and sends a request for a texture located at the computed texture address to the TU (texture unit) <b>121</b> by way of the local memory <b>143</b>.</p>
<p id="p-0126" num="0130">The TU (texture unit) <b>121</b> converts the texture address into a real address in the external memory and issues a DMA transfer request specifying the real address to the DMAC (direct memory access controller) <b>142</b> in order to acquire a pixel value of the texture. Then, the TU (texture unit) <b>121</b> carries out a filtering process on the pixel value and stores the result of the filtering process into a buffer in the local memory <b>143</b>. Subsequently, as the process of pass <b>1</b> is completed, a data transfer in pass <b>2</b> is started.</p>
<p id="p-0127" num="0131">The process of pass <b>2</b> is explained by referring to <figref idref="DRAWINGS">FIG. 6</figref> as follows. The process carried out in pass <b>2</b> as a process ending at an operation to output a result from the rasterizer <b>131</b> has the same processing sequence as the process of pass <b>1</b>. Then, the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) used in a FS (fragment shader) process blend a color value output by the rasterizer <b>131</b> with a color value output by the TU (texture unit) <b>121</b> and output the result of the blending process to the PPU (pixel processing unit) <b>141</b>.</p>
<p id="p-0128" num="0132">The PPU (pixel processing unit) <b>141</b> carries out a per fragment operation. Then, the DMAC (direct memory access controller) <b>142</b> transfers the result of the per fragment operation from the local memory <b>143</b> to an area included in the external memory as an area used for storing color and Z results.</p>
<p id="p-0129" num="0133">By referring to <figref idref="DRAWINGS">FIG. 7</figref>, the following description explains the processing sequence of a decoding process carried out by the data processing section <b>100</b> as a process of the image CODEC processing. Also in the image CODEC processing, the TC (task controller) <b>101</b> interprets a request explained earlier by referring to <figref idref="DRAWINGS">FIG. 2</figref> in order to start an operation in the same way as the 3DCG processing described before by referring to <figref idref="DRAWINGS">FIGS. 4 to 6</figref>. First of all, a DMA transfer is started in order to transfer information to be loaded into a configuration register from the external memory to the inside of the data processing section <b>100</b>. Then, the TC (task controller) <b>101</b> acquires entropy-encoded bit-stream data from the external memory through the DMAC (direct memory access controller) <b>142</b> and carries out an entropy-decoding process to decode the data. The TC (task controller) <b>101</b> stores the result of the entropy-decoding process in the local memory <b>143</b>. In the following description, the result of the entropy-decoding process is referred to as a raw MB (a raw macro-block).</p>
<p id="p-0130" num="0134">The activation of the TC (task controller) <b>101</b> causes the raw MBs obtained as a result of the entropy-decoding process to be supplied to the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>). In this case, unlike the 3DCG processing, all the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) each operate as a CODEC shader for carrying out the same decoding process.</p>
<p id="p-0131" num="0135">The SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) set to operate as a CODEC shader each compute the movement vector (MV) of the macro-block (MB) processed thereby and pass on the movement vector (MV) to the TU (texture unit) <b>121</b>, requesting the TU (texture unit) <b>121</b> to carry out a movement compensation (MC) process making use of the movement vector (MV). The TU (texture unit) <b>121</b> finds a real address from the movement vector (MV) and issues a DMA transfer request specifying the real address to the DMAC (direct memory access controller) <b>142</b> in order to acquire the value of a pixel at the specified real address in an already decoded reference image. If the value of the movement vector (MV) is 0.5 or 0.25 pixels, the TU (texture unit) <b>121</b> carries out a filtering process and outputs a predicted movement compensation (MC) value obtained as a result of the movement compensation (MC) process to the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>). During a period starting with the request issued to the TU (texture unit) <b>121</b> as a request for a movement compensation (MC) process and ending with the arrival of the result of the movement compensation (MC) process from the TU (texture unit) <b>121</b>, the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) carry out an inverse quantization process and an inverse orthogonal transform process. The result of the inverse quantization process and the inverse orthogonal transform process is added to the predicted movement compensation (MC) value before ending the decoding process. Finally, the decompressed macro-block (MB) is stored in the external memory through the DMAC (direct memory access controller) <b>142</b>.</p>
<p id="p-0132" num="0136">As described above, the data processing section <b>100</b> carries out different kinds of processing such as the 3DCG processing and the image CODEC processing. In each processing, the following data processing functional blocks are used: the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), the rasterizer <b>131</b>, the PPU (pixel processing unit) <b>141</b> and the TU (texture unit) <b>121</b>. The SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), the rasterizer <b>131</b>, the PPU (pixel processing unit) <b>141</b> and the TU (texture unit) <b>121</b> are each properly set so to carry out the desired processing. The process to set the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), the rasterizer <b>131</b>, the PPU (pixel processing unit) <b>141</b> and the TU (texture unit) <b>121</b> prior to the execution of the processing is prescribed by configuration information. Concrete processes of the processing are prescribed by a task list.</p>
<p id="p-0133" num="0137">For example, the TU (texture unit) <b>121</b> carries out a texture process common to other processes. The process carried out by the TU (texture unit) <b>121</b> is explained by referring to <figref idref="DRAWINGS">FIG. 8</figref>. <figref idref="DRAWINGS">FIG. 8</figref> is a diagram showing the configuration of the TU (texture unit) <b>121</b>. As shown in the figure, an input section <b>201</b> receives a request from a shader element (SE) and passes on the request to an address generation section <b>202</b>. The address generation section <b>202</b> generates a real address in the external memory and supplies this real address to a tag check section <b>203</b>. If desired data at the real address does not exist in a cache section <b>204</b> provided at a stage following the tag check section <b>203</b>, a cache request section <b>211</b> issues a request for a DMA transfer to the DMAC (direct memory access controller) <b>142</b>. As a result of the requested DMA transfer, memory data in an area in the neighborhood of the real address is transferred from the external memory to the cache section <b>204</b> by way of the DMAC (direct memory access controller) <b>142</b> and a cache input section <b>212</b>. The cache section <b>204</b> is a RAM for holding memory data. A filtering processing section <b>205</b> then reads out the desired data at the real address from the cache section <b>204</b>. The filtering processing section <b>205</b> carries out a filtering process on the data and outputs the result of the filtering process to the requesting shader element (SE) by way of an output section <b>206</b>.</p>
<p id="p-0134" num="0138">It is to be noted that, in the TU (texture unit) <b>121</b> shown in <figref idref="DRAWINGS">FIG. 8</figref>, the tag check section <b>203</b>, the cache request section <b>211</b>, the cache input section <b>212</b> and the cache section <b>204</b> carry out their respective processes which are each independent of an algorithm. Thus, the tag check section <b>203</b>, the cache request section <b>211</b>, the cache input section <b>212</b> and the cache section <b>204</b> are each implemented entirely as a logic circuit. In addition, the filtering processing section <b>205</b> carries out a filtering process by performing additions, subtractions, multiplications and divisions on eight-bit luminance values and eight-bit color values in both the 3DCG processing and the image CODEC processing. Thus, the filtering processing section <b>205</b> is implemented by logic circuits almost entirely.</p>
<p id="p-0135" num="0139">Next, a typical configuration of the shader element (SE) is explained by referring to <figref idref="DRAWINGS">FIG. 9</figref>. As described earlier, the shader element (SE) carries out the following operations and processes:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0140">(a): a vertex element operation of the vertex shader process in the 3DCG processing;</li>
    <li id="ul0003-0002" num="0141">(b): a fragment element operation of the fragment shader process in the 3DCG processing; and</li>
    <li id="ul0003-0003" num="0142">(c): the macro-block quantization and inverse quantization processes, the orthogonal transformation and inverse orthogonal transform processes, an intra prediction compensation process, a block integration process and an in-loop filtering process in the image CODEC processing. In the case of this embodiment, the operations (a) and (b) as well as the processes (c) are carried out as SIMD parallel processing by execution of programs. That is to say, the shader element (SE) is configured to operate as a data processing functional block for carrying out a variety of processes in accordance with an instruction acquired by performing an instruction fetch operation. The shader element (SE) has a configuration capable of carrying out various kinds of data processing in accordance with a setting process performed by the control section.</li>
</ul>
</p>
<p id="p-0136" num="0143">In particular, <figref idref="DRAWINGS">FIG. 9</figref> is a block diagram showing the configuration of the SE <b>0</b> (the shader element <b>110</b>). However, the configurations of the other SE <b>1</b> to the SE <b>3</b> (the shader elements <b>111</b> to <b>113</b>) are same with the configuration shown in the figure. The SE <b>0</b> (the shader element <b>110</b>) is a processor for carrying out four SIMD operations concurrently by execution of a program. The shader element <b>110</b> employs an input register <b>303</b> for inputting an operand and an arithmetic logic unit <b>302</b> for carrying out an operation suitable for the operand on the operand. The shader element <b>110</b> also includes a sequencer <b>301</b> and an output register <b>304</b>. The sequencer <b>301</b> functions as a control section for executing data processing control on the basis of configuration information of the data processing and a data processing program.</p>
<p id="p-0137" num="0144">That is to say, the sequencer <b>301</b> functions as a control section for controlling the data processing carried out by the SE <b>0</b> (the shader element <b>110</b>). Thus, the sequencer <b>301</b> is a block functioning as a control section for prescribing operations to be carried out by the information processing apparatus on the basis of an instruction and a register set by an external element. The register set by an external element is referred to as a configuration register. The control section (sequencer <b>301</b>) employs the following configuration elements:</p>
<p id="h-0008" num="0000">(a): IFU (Instruction Fetching Unit)</p>
<p id="p-0138" num="0145">An instruction fetching unit (IFU) is a block for carrying out an operation to fetch an instruction and stores the instruction in an instruction cache referred to as ICACHE.</p>
<p id="h-0009" num="0000">(b): ICACHE</p>
<p id="p-0139" num="0146">The instruction cache (ICACHE) is a cache for storing instructions fetched by the IFU.</p>
<p id="p-0140" num="0147">The instruction fetching unit (IFU) fetches an instruction and stores the instruction in the instruction cache (ICACHE). Then, in accordance with control executed by the sequencer <b>301</b>, which serves as a control section, on the basis of the instruction, the SE <b>0</b> (the shader element <b>110</b>) carries out a process on data received by the input register <b>303</b> and outputs the result of the process to the output register <b>304</b>. In <figref idref="DRAWINGS">FIG. 9</figref>, ALU (Arithmetic Logic Unit) <b>0</b> to ALU <b>3</b> form the arithmetic logic unit <b>302</b>, which functions as an arithmetic logic circuit for carrying out four operations concurrently. Notations GPR, CR, SPR and FR each denote a buffer used for storing a constant and a processing intermediate result. A load/store register <b>305</b> is a register used for saving data received from the external memory. A TU (texture unit) request section <b>306</b> is a register used for storing an issued request.</p>
<p id="p-0141" num="0148">In a vertex shader process carried out as a vertex process of the 3DCG processing, the coordinates (x, y, z, w) of a vertex are taken as data being processed in accordance with the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>x&#x2032;,y&#x2032;,z&#x2032;,w&#x2032;</i>)=ModelView &#x26; Projection matrix*(<i>x,y,z,w</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0142" num="0149">In a fragment shader process of the 3DCG processing, on the other hand, values (r, g, b, a) are taken as data being processed and data processing is carried out in accordance with the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>r,g,b,a</i>)=(<i>r</i>1<i>,g</i>1<i>,b</i>1<i>,a</i>1)+(<i>r</i>2<i>,g</i>2<i>,b</i>2<i>,a</i>2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where (r, g, b, a) is red, green and blue color values of a pixel and an alpha value thereof.
</p>
<p id="p-0143" num="0150">In the case of the image CODEC processing, on the other hand, a one-dimensional integer DCT process conforming to the MPEG-4AVC/H.264 standard is typically carried out. In this DCT process, DCT transformation is applied to an input (a<b>0</b>, a<b>1</b>, a<b>2</b>, a<b>3</b>) serving as the subject of transformation in accordance with the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>A</i>0<i>,A</i>1<i>,A</i>2<i>,A</i>3)=Transformation matrix*(<i>a</i>0<i>,a</i>1<i>,a</i>2<i>,a</i>3).<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0144" num="0151">As described above, all the pieces of data processing are carried out on the basis of similar computations.</p>
<p id="p-0145" num="0152">As described above, the 3DCG vertex shader (VS) process, the 3DCG fragment shader (FS) process and the CODEC macro-block process each entail a large number of vector computations. Thus, if data processing is carried out by making use of an SIMD processor like the shader element (SE) having the configuration explained earlier by referring to <figref idref="DRAWINGS">FIG. 9</figref> for example, the data processing can be performed with a high degree of efficiency.</p>
<p id="p-0146" num="0153">In addition, the 3DCG shader processes demand that the processes be carried out in an environment allowing the designer (or the creator) to do various kinds of programming and it is necessary to get rid of the programming works. However, this demand also means a need for processor processing. In addition, the macro-block process of the image CODEC processing is carried out in a way varying among a variety of CODEC standards such as JPEG, MPEG-4 and MPEG-4AVC/H.264. Thus, rather than performing the macro-block process of the image CODEC processing by making use of a fixed logic circuit, it is desirable to let the SE (shader element) shown in <figref idref="DRAWINGS">FIG. 9</figref>, that is, an SIMD-type processor, carry out the macro-block process of the image CODEC processing as processor processing that can be changed with ease in accordance with the adopted standard.</p>
<p id="p-0147" num="0154">In the information processing apparatus according to the present embodiment, processes carried out as 3DCG and CODEC processes are properly allocated to two data processing functional blocks, i.e., the shader element (SE) and the TU (texture unit) <b>121</b>. To put it concretely, as described earlier by referring to <figref idref="DRAWINGS">FIGS. 4 to 6</figref>, the vertex shader (VS) and fragment shader (FS) processes of the 3DCG processing are carried out by making use of the shader element (SE) as vertex shader (VS) and fragment shader (FS) elements. On the other hand, the image CODEC processing is carried out by making use of the shader element (SE) as CODEC shader elements as shown in <figref idref="DRAWINGS">FIG. 7</figref>. It is to be noted that the TU (texture unit) <b>121</b> serves as a unit common to the 3DCG processing and the image CODEC processing, being used for carrying out a texture process in both the 3DCG processing and the image CODEC processing.</p>
<p id="p-0148" num="0155">As described above, the vertex shader (VS) and fragment shader (FS) processes of the 3DCG processing are carried out by making use of the shader element (SE) as vertex shader (VS) and fragment shader (FS) elements. In this case, configuration information for the process to be carried out is set and the process is carried out by applying the task list shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0149" num="0156">As described above, in the information processing apparatus according to the embodiment, there is provided a configuration in which the same data processing functional block can be used for carrying out a variety of processes. Thus, the area of the hardware circuit can be decreased. In addition, the DMAC (direct memory access controller) <b>142</b>, the local memory <b>143</b> and the ADU (arbitration distribution unit) <b>150</b> do not carry out logic processing. Instead, the DMAC (direct memory access controller) <b>142</b> carries out an operation to exchange data with the external memory, the local memory <b>143</b> serves as an internal buffer whereas the ADU (arbitration distribution unit) <b>150</b> functions as a data flow controller. Thus, the DMAC (direct memory access controller) <b>142</b>, the local memory <b>143</b> and the ADU (arbitration distribution unit) <b>150</b> can each be used as a component common to both the 3DCG processing and the image CODEC processing. That is to say, in the configuration of the data processing section <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>, only the rasterizer <b>131</b> and the PPU (pixel processing unit) <b>141</b> are dedicated to the 3DCG processing.</p>
<p id="p-0150" num="0157">Next, other embodiments implementing the information processing apparatus provided by the present invention are explained. A variation of the 3DCG drawing process described earlier is explained. That is to say, the following description explains a typical case of changing a ratio of the number of SEs (shader elements) each selected among a plurality of shader elements as a shader element used in the vertex shader (VS) process to the number of SEs (shader elements) each selected among the same shader elements as a shader element used in the fragment shader (FS) process.</p>
<p id="p-0151" num="0158">In the configuration explained earlier by referring to <figref idref="DRAWINGS">FIG. 4</figref> as the configuration of the data processing section <b>100</b>, the 3DCG processing is carried out by selecting 2 shader elements, i.e., the SE <b>0</b> and the SE <b>1</b> (the shader elements <b>110</b> and <b>111</b>), among the four shader elements employed in the data processing section <b>100</b>. That is, the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), as shader elements each used in the vertex shader (VS) process and selecting the two other shader elements, i.e., the SE <b>2</b> and the SE <b>3</b> (the shader elements <b>112</b> and <b>113</b>) among the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) as shader elements each used in the fragment shader (FS) process.</p>
<p id="p-0152" num="0159">In a configuration shown in <figref idref="DRAWINGS">FIG. 10</figref> as a typical configuration of the data processing section <b>100</b>, the 3DCG processing is carried out by selecting 1 shader element <b>110</b> (SE <b>0</b>) among the four shader elements, that is, the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), as a shader element used in the vertex shader (VS) process and selecting the three other shader elements, i.e., the SE <b>1</b> to the SE <b>3</b> (the shader elements <b>111</b> to <b>113</b>) among the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) as shader elements each used in the fragment shader (FS) process. That is to say, in the configuration shown in <figref idref="DRAWINGS">FIG. 10</figref> as a typical configuration of the data processing section <b>100</b>, the shader element <b>110</b> (SE <b>0</b>) is selected among the four shader elements, that is, the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), and set as a shader element used in the vertex shader (VS) process. On the other hand, the three other shader elements, i.e., the SE <b>1</b> to the SE <b>3</b> (the shader elements <b>111</b> to <b>113</b>), are selected among the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) and each set as a shader element used in the fragment shader (FS) process.</p>
<p id="p-0153" num="0160">In the 3DCG processing, the state of balance between the loads of the vertex shader (VS) process and the fragment shader (FS) process changes in accordance with the application and/or the scene being processed or the object of processing. Thus, by making the number of shader elements each set as a vertex shader (VS) element and the number of shader elements each set as a fragment shader (FS) element variable, the balance between the loads can be established. In a process to draw an object for which the polygon is big, the load of the vertex shader (VS) process is small but the load of the fragment shader (FS) process is large for example, the number of shader elements each set as a vertex shader (VS) element is decreased but the number of shader elements each set as a fragment shader (FS) element is increased. In a process to draw an object for which the polygon is small and the load of the vertex shader (VS) process is large, on the other hand, the number of shader elements each set as a vertex shader (VS) element is increased in order to raised the processing speed.</p>
<p id="p-0154" num="0161">If the balance between the loads of the vertex shader (VS) process and the fragment shader (FS) process or the ratio of the former to the latter needs to be set at 1:100 representing a big difference between the former and the latter, such a balance can be established through allocation of time to the former and the latter.</p>
<p id="p-0155" num="0162"><figref idref="DRAWINGS">FIG. 11</figref> is a block diagram showing a typical configuration in which all the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) are each set to function as a vertex shader (VS) element. In this case, all the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each carry out a vertex shader (VS) process. The results of the vertex shader (VS) processes are supplied to the local memory <b>143</b> to be stored temporarily therein. <figref idref="DRAWINGS">FIG. 12</figref> is a block diagram showing another typical configuration in which all the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) are each set to function as a fragment shader (FS) element later on. In this case, the results of the vertex shader (VS) processes are transferred from the local memory <b>143</b> to the rasterizer <b>131</b>. A rasterize result output by the rasterizer <b>131</b> is distributed to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each already set to function as a fragment shader (FS) element. The SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each already set to function as a fragment shader (FS) element each carry out a fragment shader (FS) process on the rasterize result. The results of the fragment shader (FS) processes are supplied to the PPU (pixel processing unit) <b>141</b>. The PPU (pixel processing unit) <b>141</b> carries out a per fragment operation on the results of the fragment shader (FS) processes and supplies the result of the per fragment operation to the external memory by way of the local memory <b>143</b> and the DMAC (direct memory access controller) <b>142</b>.</p>
<p id="p-0156" num="0163">The configurations shown in <figref idref="DRAWINGS">FIGS. 11 and 12</figref> are typical configurations for carrying out the image drawing process explained before by referring to <figref idref="DRAWINGS">FIG. 4</figref> as a process to draw an image without a texture. To be more specific, a time period is allocated to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each set to function as a vertex shader (VS) element and another time period is allocated the SE<b>0</b> to the SE<b>3</b> each set to function as a fragment shader (FS) element in order for the SE<b>0</b> to the SE<b>3</b> to carry out the process to draw an image without a texture on a time-division basis.</p>
<p id="p-0157" num="0164">In the time period allocated to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each set to function as a vertex shader (VS) element as shown in <figref idref="DRAWINGS">FIG. 11</figref>, the ADU (arbitration distribution unit) <b>150</b> distributes vertex-array data to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) in the following order: SE <b>0</b>&#x2192;SE <b>1</b>&#x2192;SE <b>2</b>&#x2192;SE <b>3</b>. Arrows pointing to and leaving data processing functional blocks shown in <figref idref="DRAWINGS">FIG. 11</figref> represent data flows set by the ADU (arbitration distribution unit) <b>150</b> in this embodiment.</p>
<p id="p-0158" num="0165">The SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each set to function as a vertex shader (VS) element each carry out data processing on vertex-array data received thereby in accordance with the setting of a configuration register and an internal program. In the configuration explained before by referring to <figref idref="DRAWINGS">FIG. 4</figref>, the data processing section <b>100</b> is set to supply the results of the data processing to the rasterizer <b>131</b>. In this embodiment, however, the results of the data vertex element (VS) processes are stored in the local memory <b>143</b>. In this case, the results of the data vertex element (VS) processes are stored temporarily in the local memory <b>143</b> in the same order as that adopted by the ADU (arbitration distribution unit) <b>150</b> to supply vertex information to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>).</p>
<p id="p-0159" num="0166">Later on, during and after the time period allocated to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each set to function as a fragment shader (FS) element as shown in <figref idref="DRAWINGS">FIG. 12</figref>, the results of the data vertex element (VS) processes are transferred from the local memory <b>143</b> to the rasterizer <b>131</b>. Rasterize results output by the rasterizer <b>131</b> are distributed to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each already set to function as a fragment shader (FS) element.</p>
<p id="p-0160" num="0167">The rasterize results output by the rasterizer <b>131</b> are distributed to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each already set to function as a fragment shader (FS) element in the following order: SE <b>0</b>&#x2192;SE <b>1</b>&#x2192;SE <b>2</b>&#x2192;SE <b>3</b>. The SE<b>2</b> and the SE<b>3</b> (the shader elements <b>112</b> and <b>113</b>) each already set to function as a fragment shader (FS) element each carry out a fragment shader (FS) process on the rasterize results and output the results of the fragment shader (FS) processes to the PPU (pixel processing unit) <b>141</b>. The operations to output the results of the fragment shader (FS) processes to the PPU (pixel processing unit) <b>141</b> are controlled by the ADU (arbitration distribution unit) <b>150</b> so that the results are output in the same order in which the fragment shader (FS) processes are carried out by the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>). The PPU (pixel processing unit) <b>141</b> carries out a per fragment operation on the results of the fragment shader (FS) processes and supplies the result of the per fragment operation to the external memory by way of the local memory <b>143</b> and the DMAC (direct memory access controller) <b>142</b>.</p>
<p id="p-0161" num="0168">By setting the ratio of a time period allocated to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each configured to function as a vertex shader (VS) element to a time period allocated to the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) each configured to function as a fragment shader (FS) element at a typical rate of 1:100 for example, the data processing can also be carried out as processing adapted to a case in which the balance between the loads of the vertex shader (VS) process and the fragment shader (FS) process is 1:100. This time period allocation can appropriately change based on the setting information in the configuration information and the task list.</p>
<p id="p-0162" num="0169">As described above, the TC (task controller) <b>101</b> functioning as a control section executes control to set a proper number of shader elements each selected among a plurality of shader elements to serve as a vertex shader (VS) element for carrying out a vertex shader (VS) process and the remaining shader elements as fragment shader (FS) elements for carrying out fragment shader (FS) processes in parallel to the vertex shader (VS) processes. In addition, the TC (task controller) <b>101</b> also sets the ratio of a time period allocated to the element shaders each configured to function as a vertex shader (VS) element to a time period allocated to the element shaders each configured to function as a fragment shader (FS) element.</p>
<p id="p-0163" num="0170">In the configuration shown in <figref idref="DRAWINGS">FIG. 12</figref>, all the SE<b>0</b> to the SE<b>3</b> (the shader elements <b>110</b> to <b>113</b>) are each configured to function as a fragment shader (FS) element. It is to be noted, however, that this configuration can also be applied to an application in which, typically, an upper-level host CPU outside the data processing section <b>100</b> takes charge of a coordinate transformation process as a vertex shader (VS) process whereas the data processing section <b>100</b> itself processes vertex-array data of a clip coordinate system.</p>
<p id="p-0164" num="0171">By referring to <figref idref="DRAWINGS">FIG. 13</figref>, the following description explains the data processing sequence of a contracted-image generation process carried out by the data processing section <b>100</b>. There are standards for prescribing CG (computer graphics) programming interfaces. An example of the standards is OpenGL 2.0 which prescribes a MIPMAP image generation function. The MIPMAP image generation function is a contracted-image generation function for generating a small texture from a large one. In addition, a movement detection process of the image CODEC processing normally adopts a technique of carrying out a coarse search operation on a contracted image and a fine search operation on the original image. Also in the case of the movement detection process, the contracted-image generation function is used.</p>
<p id="p-0165" num="0172"><figref idref="DRAWINGS">FIG. 13</figref> is an explanatory diagram referred to in description of the data processing sequence of a contracted-image generation process carried out by the data processing section <b>100</b>. Also in the case of the contracted-image generation process, a task list shown in <figref idref="DRAWINGS">FIG. 2</figref> is set, data processing functional blocks are configured to carry out the contracted-image generation process on the basis of the task list and the contracted-image generation process itself is then performed. The TC (task controller) <b>101</b> sets configuration information to be used as setting information on the basis of information included in the task list. A DMA transfer is carried out to transfer an original image from the external memory to the TU (texture unit) <b>121</b> by way of the DMAC (direct memory access controller) <b>142</b> and the local memory <b>143</b>.</p>
<p id="p-0166" num="0173">The TU (texture unit) <b>121</b> carries out a bilinear filtering process on the original image and outputs the result of the process to the PPU (pixel processing unit) <b>141</b>. The PPU (pixel processing unit) <b>141</b> carries out a color format conversion process on the image received from the TU (texture unit) <b>121</b> as a result of the bilinear filtering process and stores the result of the color format conversion process in the local memory <b>143</b>. The color format conversion process carried out by the PPU (pixel processing unit) <b>141</b> is a process to convert the eight-bit format of data representing RGBA into a format of five and/or six bits. The RGBA data is the color and alpha values of each pixel. For example, in order to reduce the number of circuits employed in the data processing section <b>100</b>, it is also possible to provide a configuration in which all processes in the TU (texture unit) <b>121</b> are carried out in eight-bit units but the format of an image supplied to the data processing section <b>100</b> is changed by the TU (texture unit) <b>121</b> in the color format conversion process. Originally, it is the PPU (pixel processing unit) <b>141</b> that is provided with the color format conversion function for carrying out the color format conversion process on output data.</p>
<p id="p-0167" num="0174">In a MIPMAP image generation process carried out as a contracted-image generation process for generating a small texture from a large one, the size of an image is reduced to half the size by carrying out a size halving operation repeatedly. For example, an original image having a size of 512 pixels&#xd7;512 pixels is subjected to the size halving operation carried out repeatedly in order successively reduce the size to &#xbd;, &#xbc;&#x215b; and so on so as to decrease the number of pixels to 256&#xd7;256, 128&#xd7;128 and so on to the final pixel count of 1&#xd7;1 of the desired contracted image.</p>
<p id="p-0168" num="0175">To put it in detail, a current image having a size equal to half the size of a preceding image is temporarily stored in the local memory <b>143</b> before being output to the external memory by way of the DMAC (direct memory access controller) <b>142</b>. Then, the current image having a size equal to half the size of a preceding image is subjected to the next size halving operation and the result of the next size halving operation is temporarily stored in the local memory <b>143</b> as a new current image before again being output to the external memory by way of the DMAC (direct memory access controller) <b>142</b>. In this way, a current image temporarily stored in the local memory <b>143</b> is used for generating a new current image. Thus, during the repeated execution of to the size halving operation, it is no longer necessary to acquire the image, which has been once output to the external memory, from time to time. As a result, the bandwidth of an external bus and the power consumption can be decreased. In this process, the ADU (arbitration distribution unit) <b>150</b> sets the setting of flows of data.</p>
<p id="p-0169" num="0176">As described above, the TU (texture unit) <b>121</b> has a configuration for carrying out a process to generate a contracted image. The contracted image generated by the TU (texture unit) <b>121</b> is output to the external memory by way of the local memory <b>143</b> and a contracted image temporarily stored in the local memory <b>143</b> is again acquired to be subjected to a size halving operation carried out repeatedly in order to generate a contracted image having the desired size.</p>
<p id="p-0170" num="0177">By referring to <figref idref="DRAWINGS">FIG. 14</figref>, the following description explains a process carried out by the ADU (arbitration distribution unit) <b>150</b> to control flows of data. The ADU (arbitration distribution unit) <b>150</b> controls data transfers among configuration elements employed in the data processing section <b>100</b>. As shown in the figure, the configuration elements employed in the data processing section <b>100</b> include the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), the TU (texture unit) <b>121</b>, the rasterizer <b>131</b>, the PPU (pixel processing unit) <b>141</b>, the DMAC (direct memory access controller) <b>142</b> and the local memory <b>143</b>.</p>
<p id="p-0171" num="0178">As shown in <figref idref="DRAWINGS">FIG. 14</figref>, the ADU (arbitration distribution unit) <b>150</b> employs four sub-ADUs (ADU<b>1</b> to ADU<b>4</b>) denoted by reference numerals <b>151</b> to <b>154</b> respectively. The ADU<b>1</b> <b>151</b> controls data transfers between the DMAC (direct memory access controller) <b>142</b> and other data processing functional blocks as well as data transfers between the local memory <b>143</b> and other data processing functional blocks. The ADU<b>1</b> <b>151</b> employs two selectors, i.e., a SEL <b>0</b> and a SEL <b>1</b>.</p>
<p id="p-0172" num="0179">The selector SEL <b>0</b> in the ADU<b>1</b> <b>151</b> has a function for selecting an input to be supplied to the PPU (pixel processing unit) <b>141</b>. In the normal 3DCG processing, the selector SEL <b>0</b> selects data output by the ADU<b>2</b> <b>152</b> to the ADU<b>2</b> <b>151</b> and outputs the selected data to the PPU (pixel processing unit) <b>141</b>. The data output by the ADU<b>2</b> <b>152</b> to the ADU<b>1</b> <b>151</b> is one of the pieces of data output by the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>). In the contracted-image generation process, on the other hand, the selector SEL <b>0</b> selects the output of the TU (texture unit) <b>121</b> and supplies the selected output to the PPU (pixel processing unit) <b>141</b>. Set as setting information in the configuration information, the select function of the selector SEL <b>0</b> is a function to carry out a predetermined process which varies from task to task.</p>
<p id="p-0173" num="0180">The selector SEL <b>1</b> employed in the ADU<b>1</b> <b>151</b> selects vertex data received from the DMAC (direct memory access controller) <b>142</b> or data stored temporarily in the local memory <b>143</b> and outputs the selected data to one of the SE to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) or the rasterizer <b>131</b> by way of the ADU<b>2</b> <b>152</b>. The data stored temporarily in the local memory <b>143</b> is typically the result of a filtering process carried out by the TU (texture unit) <b>121</b> performing a texture mapping process. This function is demanded when a texture is processed by making use of a fragment shader (FS) element while a vertex is being processed by making use of a vertex shader (VS) element at the same time. The ADU<b>2</b> <b>152</b> outputs the selected data to one of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) or the rasterizer <b>131</b> on the basis of a request made by any one of the SE <b>0</b> to the SE <b>3</b>, dynamically changing the amount of data stored in a buffer employed in the ADU<b>2</b> <b>152</b>.</p>
<p id="p-0174" num="0181">The ADU<b>2</b> <b>152</b> controls the operation to receive data from the ADU<b>1</b> <b>151</b> as data to be output to one of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) or the rasterizer <b>131</b>. The ADU<b>2</b> <b>152</b> employs three selectors, i.e., selectors SEL <b>2</b>, SEL <b>3</b> and the SEL <b>4</b>. The selector SEL <b>2</b> selects one of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) or the rasterizer <b>131</b> as a recipient of data output by the ADU<b>2</b> <b>152</b>. The select function of the selector SEL <b>2</b> selects the rasterizer <b>131</b> in accordance with the set configuration information which varies from task to task. On the other hand, the selector SEL <b>3</b> selects the SE <b>0</b>, the SE <b>1</b>, the SE <b>2</b> or the SE <b>3</b> (the shader element <b>110</b>, <b>111</b>, <b>112</b> or <b>113</b>). As described above, the data output by the ADU<b>2</b> <b>152</b> to the ADU<b>1</b> <b>151</b> is one of the pieces of data output by the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) and it is the selector SEL <b>4</b> that selects one of the pieces of data as the data to be output to the ADU<b>1</b> <b>151</b>.</p>
<p id="p-0175" num="0182"><figref idref="DRAWINGS">FIG. 15</figref> is a block diagram showing a detailed configuration of the ADU<b>2</b> <b>152</b>. As shown in <figref idref="DRAWINGS">FIG. 15</figref>, the ADU<b>2</b> <b>152</b> has a plurality of data buffers <b>401</b> used for storing vertex data received from the DMAC (direct memory access controller) <b>142</b> and data read out from the local memory <b>143</b>. In addition, the ADU<b>2</b> <b>152</b> employs a cross-bus switch <b>402</b> for selectively designating one of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) as a shader element to receive data output by the ADU<b>2</b> <b>152</b>. That is to say, the cross-bus switch <b>402</b> having a function for selectively designating one of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) as a shader element to receive data output by the ADU<b>2</b> <b>152</b> distributes the data to a plurality of SEs (shader elements), i.e., the SE <b>0</b> to the SE <b>3</b>. The cross-bus switch <b>402</b> corresponds to the selectors SEL <b>2</b> and SE L <b>3</b> which are shown in <figref idref="DRAWINGS">FIG. 14</figref>. The data output by the ADU<b>2</b> <b>152</b> is data stored in a vertex memory or any one of the data buffers <b>401</b>. The cross-bus switch <b>402</b> distributes the data to the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) in accordance with configuration information set for the ADU<b>2</b> <b>152</b>.</p>
<p id="p-0176" num="0183">For example, the SE <b>0</b> (the shader element <b>110</b>) and the SE <b>1</b> (the shader element <b>111</b>) have been set as a vertex shader (VS) element and three pieces of data (i.e. vertex data, the data of texture <b>0</b> and the data of texture <b>1</b>) are each used as a processing unit of the SEs (shader elements) as shown in <figref idref="DRAWINGS">FIG. 16</figref>. In this case, three data buffers (i.e., data buffers <b>0</b>, <b>1</b> and <b>2</b>) employed in the ADU<b>2</b> <b>152</b> are used for storing the vertex data, the data of texture <b>0</b> and the data of texture <b>1</b> respectively. Units of the vertex data are 00, 01, 02 and 03 whereas units of the data of texture <b>0</b> are 10, 11, 12 and 13. Units of the data of texture <b>1</b> are 20, 21, 22 and 23. The cross-bus switch <b>402</b> employed in the ADU<b>2</b> <b>152</b> sequentially distributes the three pieces of data (i.e. the vertex data, the data of texture <b>0</b> and the data of texture <b>1</b>) to the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) as a data set in accordance with configuration information set for the ADU<b>2</b> <b>152</b>.</p>
<p id="p-0177" num="0184">The cross-bus switch <b>402</b> employed in the ADU<b>2</b> <b>152</b> shown in <figref idref="DRAWINGS">FIG. 16</figref> sequentially distributes the three pieces of data (i.e. the vertex data, the data of texture <b>0</b> and the data of texture <b>1</b>) to the SE <b>0</b> (the shader element <b>110</b>) and the SE <b>1</b> (the shader element <b>111</b>) by typically adopting a round robin method, that is, by typically selecting the recipient shader elements in the following order: SE <b>0</b>&#x2192;SE <b>1</b>&#x2192;SE <b>0</b>&#x2192; and so on. If four shader elements are used, the cross-bus switch <b>402</b> sequentially distributes the three pieces of data (i.e. the vertex data, the data of texture <b>0</b> and the data of texture <b>1</b>) to the SE <b>0</b> (the shader element <b>110</b>), the SE <b>1</b> (the shader element <b>111</b>), the SE <b>2</b> (the shader element <b>112</b>) and the SE <b>3</b> (the shader element <b>113</b>) by typically selecting the recipient shader elements in the following order: SE <b>0</b>&#x2192;SE <b>1</b>&#x2192;SE <b>2</b>&#x2192;SE <b>3</b>&#x2192;SE <b>0</b>&#x2192;SE <b>1</b> and so on.</p>
<p id="p-0178" num="0185">As described above, data is supplied to the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) in data processing units demanded by the SE <b>0</b> to the SE <b>3</b>. In the reversed data flow through the selectors SEL <b>3</b> and the SE L <b>4</b> which are employed in the ADU<b>2</b> <b>152</b> as shown in <figref idref="DRAWINGS">FIG. 14</figref>, the selectors SEL <b>3</b> and the SE L <b>4</b> select one of the outputs of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) by adopting the round robin technique and supply the selected output to a data buffer.</p>
<p id="p-0179" num="0186">The ADU<b>3</b> <b>153</b> shown in <figref idref="DRAWINGS">FIG. 14</figref> controls an operation to select one of the outputs of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) or the output of the selector SEL <b>2</b> and supply the selected output to the rasterizer <b>131</b>. The local memory <b>143</b> employs two selectors, i.e., selectors SEL <b>5</b> and the SE L <b>6</b>. The selector SEL <b>5</b> selects the output of the selector SEL <b>6</b> or the output of the selector SEL <b>2</b> and supply the selected output to the rasterizer <b>131</b> in accordance with set configuration information which varies from task to task as is the case with the selector SEL <b>2</b>. The selector SEL <b>6</b> selects one of the outputs of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>). The outputs of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) and the output of the selector SEL <b>2</b> are the outputs of the ADU<b>2</b> <b>152</b> which receives data supplied by the local memory <b>143</b> or the DMAC (direct memory access controller) <b>142</b> by way of the ADU<b>1</b> <b>151</b>.</p>
<p id="p-0180" num="0187">Provided with a selector SEL <b>7</b>, the ADU<b>4</b> <b>154</b> controls an operation to supply the fragment output of the rasterizer <b>131</b> to the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>). The selector SEL <b>7</b> selects one of the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>) each already set as a fragment shader (FS) as a recipient of the fragment output of the rasterizer <b>131</b> by adoption of the round robin method.</p>
<p id="p-0181" num="0188">As described above, the ADU (arbitration distribution unit) <b>150</b> controls data transfers among configuration elements employed in the data processing section <b>100</b>. The configuration elements employed in the data processing section <b>100</b> include the SE <b>0</b> to the SE <b>3</b> (the shader elements <b>110</b> to <b>113</b>), the TU (texture unit) <b>121</b>, the rasterizer <b>131</b>, the PPU (pixel processing unit) <b>141</b>, the DMAC (direct memory access controller) <b>142</b> and the local memory <b>143</b>.</p>
<p id="p-0182" num="0189">That is to say, the ADU (arbitration distribution unit) <b>150</b> dynamically executes control to change data transfer routes in the data processing section <b>100</b> in accordance with processing carried out by the data processing section <b>100</b>. By executing the control, the data processing section <b>100</b> is capable of carrying out 3DCG processing and image CODEC processing conforming to a variety of standards such as JPEG, MPEG-2, MPEG-4 and MPEG-4AVC/H.264.</p>
<p id="p-0183" num="0190">In particular, in the case of the information processing apparatus according to the present invention, by setting an active map included in the task list explained earlier by referring to <figref idref="DRAWINGS">FIG. 2</figref>, it is possible to specify data processing functional blocks used for carrying out a process and data processing functional blocks not used for carrying out the process.</p>
<p id="p-0184" num="0191">In execution of image CODEC processing for example, neither the rasterizer <b>131</b> nor the PPU (pixel processing unit) <b>141</b> is used. In particular, in execution of a process to generate a contracted image, the SEs (shader elements) and the rasterizer <b>131</b> are not used. In addition, in a 3DCG process to draw an image, it is possible to provide a configuration in which the number of active SEs (shader elements) can be decreased if the load of the process is small.</p>
<p id="p-0185" num="0192">The TC (task controller) <b>101</b> serving as a control section interprets an active map included in the task list and issues an instruction to an external clock supply controller to supply no clock signal to inactive data processing functional blocks or issues an instruction to a power-supply controller to supply no power to inactive data processing functional blocks. It is thus possible to execute power supplying control to provide neither clock signal nor power to data processing functional blocks each put in an inactive state because of function and/or load reasons. As a result, it is possible to stop an operation to wastefully supply power to deliberately selected inactive data processing functional blocks and, hence, reduce the power consumption.</p>
<p id="p-0186" num="0193">The data processing section <b>100</b> according to the embodiment described above carries out a process as 3DCG or image CODEC processing. It is to be noted, however, that processes carried out by the data processing section <b>100</b> are by no means limited to the 3DCG processing and the image CODEC processing. For example, the data processing section <b>100</b> is also capable of carrying out processes such as a de-mosaic process for an input received from a CCD or CMOS image sensor and a camera signal process such as a noise filtering process. In addition, the data processing section <b>100</b> is also applicable to other kinds of data processing.</p>
<p id="p-0187" num="0194">An embodiment of the present invention has been described so far by referring to diagrams. It is obvious, however, that a person skilled in the art is capable of thinking of any modifications of the embodiment or any substitutes for the embodiment as long as the modifications and the substitutes are within a range not deviating from essentials of the present invention. That is to say, the embodiment is merely a typical implementation of the present invention and, hence, should not be interpreted in a limited narrow manner. In order to determine the gist of the present invention, the reader is suggested to refer to claims included in this patent specification. It is to be noted that the data processing section <b>100</b> provided by the present invention is by no means limited to apparatus for carrying out the 3DCG processing and the image CODEC processing only. That is to say, the data processing section <b>100</b> provided by the present invention can also be applied to other kinds of data processing.</p>
<p id="p-0188" num="0195">In addition, the series of processes explained in the patent specification can be carried out by using hardware, execution of software or adoption of a compound configuration making use of both. If the series of processes described above is carried out by execution of software, programs composing the software can be installed into a memory employed in a computer embedded in dedicated hardware, a general-purpose computer or the like from typically a network or a recording medium. In this case, the embedded computer or the general-purpose computer serves as the information processing apparatus described above. A general-purpose computer is a computer, which can be made capable of carrying out a variety of functions by installing a variety of programs into the memory of the computer. For example, the programs are recorded in advance in the recording medium which is then mounted on the computer in an operation to install the programs into the memory of the computer. Typically, the memory of the computer is a hard disk embedded in the computer. Instead of installing the program into the computer from a recording medium, the computer receives the programs from a network such as a LAN (Local Area Network) or the Internet and, then, the programs are installed into the hard disk employed in the computer.</p>
<p id="p-0189" num="0196">It is also worth noting that, in this patent specification, the various processes described in this specification can each be carried out not only in a pre-prescribed order along the time axis, but also concurrently or individually depending on the processing power of the information processing apparatus or depending on necessity. It is also to be noted that the technical term &#x2018;system&#x2019; used in this patent specification implies the configuration of a confluence including a plurality of apparatus.</p>
<p id="p-0190" num="0197">As described above, there is provided an information processing apparatus characterized in that the apparatus employs: a plurality of data processing functional blocks each used for carrying out individual data processing; a flow control section for executing control of data flows among the data processing functional blocks; and a control section for carrying out a setting process to set the data processing functional blocks and the flow control section. The control section acquires configuration information in accordance with a task list for data processing to be carried out, carries out a setting process to set the data processing functional blocks and the flow control section on the basis of the acquired configuration information, and constructs a data processing configuration adapted to various kinds of data processing to be carried out. Thus, data processing functional blocks common to various kinds of data processing such as 3DCG processing and image CODEC processing can be used for carrying out the data processing. As a result, it is possible to implement an information processing apparatus allowing the area of an LSI implementing the data processing functional blocks, the manufacturing cost and the power consumption to be reduced.</p>
<p id="p-0191" num="0198">In addition, it should be understood by those skilled in the art that a variety of modifications, combinations, sub-combinations and alterations may occur, depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An information processing apparatus for executing a 3-dimensional graphic process or an image CODEC process, the information processing apparatus comprising:
<claim-text>a plurality of data processing functional blocks each used for executing an individual data processing included in a 3-dimensional graphic process or an image CODEC process, each of the plurality of data processing functional blocks being a hardware circuit;</claim-text>
<claim-text>a flow control section configured to execute control of data flows among said data processing functional blocks; and</claim-text>
<claim-text>a control section configured to execute a setting process to set said data processing functional blocks and said flow control section,</claim-text>
<claim-text>wherein said control section:
<claim-text>acquires configuration information in accordance with a task list for data processing to be executed;</claim-text>
<claim-text>executes said setting process to set said data processing functional blocks and said flow control section on the basis of said acquired configuration information; and</claim-text>
<claim-text>constructs a data processing configuration adapted to various kinds of data processing to be executed,</claim-text>
</claim-text>
<claim-text>wherein said task list includes an active map for holding data distinguishing data processing functional blocks used in data processing to be executed from data processing functional blocks not used in said data processing; and said control section executes control to stop an operation to supply power to said data processing functional blocks not used in data processing on the basis of said active map, and</claim-text>
<claim-text>wherein the task list includes a plurality of tasks, and each task includes a plurality of passes prescribing a base address of data to be transferred from an external memory, a size of the data, and a synchronization mode.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The information processing apparatus according to claim l wherein said control section executes a process of setting at least some of said data processing functional blocks to be capable of performing different kinds or data processing to be executed in accordance with said data processing.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein at least some of said data processing functional blocks are configured to function as data processing functional blocks for executing a variety of processes according to a received instruction and configured into a configuration capable of performing different kinds of data processing in conformity with said setting process executed by said control section.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein at least some of said data processing functional blocks each have a configuration capable of selectively executing a vertex shader process or a fragment shader process.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein:
<claim-text>at least some of said data processing functional blocks are each configured as one of a plurality of shader elements each capable of selectively executing a vertex shader process or a fragment shader process; and</claim-text>
<claim-text>said control section sets some of said shader elements to execute said vertex shader process and some of said shader elements to execute said fragment shader process.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein:
<claim-text>at least some of said data processing functional blocks are each configured as one of a plurality of shader elements each capable of selectively executing a vertex shader process or a fragment shader process in; and</claim-text>
<claim-text>said control section executes control to set a time period for executing said vertex shader process and a time period for executing said fragment shader process, allocating said set time periods to some of said shader elements on a time division basis.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein at least some of said data processing functional blocks each have a configuration capable of selectively executing a vertex shader process or a fragment shader process or a macro-block process.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein:
<claim-text>at least some of said data processing functional blocks are each a texture unit for executing a texture process; and</claim-text>
<claim-text>said texture unit has a configuration for executing a process to generate a contracted image and, in order to generate a final contracted image having a desired size, repeatedly executing the following steps of:</claim-text>
<claim-text>outputting a contracted image obtained as a result of said process to an external destination by way of a local memory;</claim-text>
<claim-text>reacquiring said contracted image from said local memory; and</claim-text>
<claim-text>shrinking said reacquired contracted image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said flow control section comprises:
<claim-text>a data buffer for temporarily storing data; and</claim-text>
<claim-text>a cross-bus switch for selectively outputting data stored in said data buffer to the plurality of data processing functional blocks.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said flow control section has a configuration for executing a process to sequentially changing an output destination of data from one to another in accordance with said data to be output.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said flow control section has a configuration for executing a process to sequentially changing an output destination of data from one to another by adoption of a round-robin technique in accordance with said data to be output data.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An information processing method of an information processing apparatus for executing a 3-dimensional graphic process or an image CODEC process, the information processing method comprising:
<claim-text>a plurality of data processing functional steps each used for executing an individual data process included in a 3-dimensional graphic process or an image CODEC process, the plurality of data processing functional steps being executed by a hardware circuit;</claim-text>
<claim-text>a flow control step configured to execute control of data flows among said data processing functional steps; and</claim-text>
<claim-text>a control section configured to execute a setting process to set said data processing functional blocks and said flow control section, wherein</claim-text>
<claim-text>said control step further including:
<claim-text>acquiring configuration information in accordance with a task list for data processing to be executed;</claim-text>
<claim-text>executing a setting process to set said data processing functional steps and said flow control step on the basis of said acquired configuration information; and</claim-text>
<claim-text>constructing a data processing configuration adapted to said data processing to be executed,</claim-text>
</claim-text>
<claim-text>wherein said task list includes an active map for holding data distinguishing data processing functional steps used in data processing to be executed from data processing functional steps not used in said data processing; and said control step executes control to stop an operation to supply power to said data processing functional steps not used in data processing on the basis of said active map, and</claim-text>
<claim-text>wherein the task list includes a plurality of tasks, and each task includes a plurality of passes prescribing a base address of data to be transferred from an external memory, a size of the data, and a synchronization mode.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> whereby said control step executes a process of setting at least some of said data processing functional steps to be capable of performing different kinds of data processing to be executed in accordance with said data processing.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein:
<claim-text>at least some of said data processing functional steps are configured to function as data processing functional steps for executing a variety of processes according to a received instruction; and</claim-text>
<claim-text>said control step controls an operation to configure at least some of said data processing functional steps to execute specific data processing in accordance with setting based on said task list.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein at least some of said data processing functional steps each have a configuration capable of selectively executing a vertex shader process or a fragment shader process.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein:
<claim-text>at least some of said data processing functional steps are each configured as one of a plurality of shader elements each capable of selectively executing a vertex shader process or a fragment shader process; and</claim-text>
<claim-text>said control step sets some of said shader elements to execute said vertex shader process and some of said shader elements to execute said fragment shader process.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein:
<claim-text>at least some of said data processing functional steps are each configured as one of a plurality of shader elements each capable of selectively executing a vertex shader process or a fragment shader process; and</claim-text>
<claim-text>said control step executes control to set a time period for executing said vertex shader process and a time period for executing said fragment shader process, allocating said set time periods to some of said shader elements on a time division basis.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein at least some of said data processing functional steps each have a configuration capable of selectively executing a vertex shader process or a fragment shader process or a macro-block process.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein:
<claim-text>at least some of said data processing functional steps are each a texture step for executing a texture process; and</claim-text>
<claim-text>said texture step executes a process to generate a contracted image and, in order to generate a final contracted image having a desired size, repeatedly executes the following steps of:</claim-text>
<claim-text>outputting a contracted image obtained as a result of said process to an external destination by way of a local memory;</claim-text>
<claim-text>reacquiring said contracted image from said local memory; and</claim-text>
<claim-text>shrinking said reacquired contracted image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein said flow control step comprises:
<claim-text>a data buffer step for temporarily storing data; and</claim-text>
<claim-text>a cross-bus switching step for selectively outputting data stored in said data buffer step to the plurality of data processing functional steps.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein said flow control step executes a process to sequentially changing an output destination of data from one to another in accordance with said data to be output.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The information processing method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein said flow control step executes a process to sequentially changing an output destination of data from one to another by adoption of a round-robin technique in accordance with said data to be output data.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. A non-transitory storage medium storing a computer program to be executed to drive an information processing apparatus for executing a 3-dimensional graphic process or an image CODEC process, the computer program comprising:
<claim-text>a plurality of data processing functional steps each used for executing an individual block process included in a 3-dimensional graphic process or an image CODEC process, the plurality of data processing functional steps being executed by a hardware circuit;</claim-text>
<claim-text>a flow control step configured to execute control of data flows among said data processing functional steps; and</claim-text>
<claim-text>a control step configured to execute a process to set said data processing functional steps and said flow control step,</claim-text>
<claim-text>wherein said control step further includes:</claim-text>
<claim-text>acquiring configuration information in accordance with a task list for data processing to be executed;</claim-text>
<claim-text>executing a setting process to set said data processing functional steps and said flow control step on the basis of said acquired configuration information; and</claim-text>
<claim-text>constructing a data processing configuration adapted to said data processing to be executed,</claim-text>
<claim-text>wherein said task list includes an active map for holding data distinguishing data processing functional steps used in data processing to be executed from data processing functional steps not used in said data processing; and said control step executes control to stop an operation to supply power to said data processing functional steps not used in data processing on the basis of said active map, and</claim-text>
<claim-text>wherein the task list includes a plurality of tasks, and each task includes a plurality of passes prescribing a base address of data to be transferred from an external memory, a size of the data, and a synchronization mode. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
