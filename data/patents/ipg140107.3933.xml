<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625001-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625001</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13219103</doc-number>
<date>20110826</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>76</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>222</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>3482312</main-classification>
<further-classification>34833305</further-classification>
</classification-national>
<invention-title id="d2e51">Pre- and post-shutter signal image capture and sort for digital camera</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7594177</doc-number>
<kind>B2</kind>
<name>Jojic et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715720</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>8098297</doc-number>
<kind>B2</kind>
<name>Crisan et al.</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482312</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2003/0147640</doc-number>
<kind>A1</kind>
<name>Voss et al.</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396310</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2003/0189647</doc-number>
<kind>A1</kind>
<name>Kang</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34820799</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2005/0264678</doc-number>
<kind>A1</kind>
<name>Butterworth</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0222884</doc-number>
<kind>A1</kind>
<name>Mori et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34833305</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2007/0263128</doc-number>
<kind>A1</kind>
<name>Zhang</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348700</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2007/0270182</doc-number>
<kind>A1</kind>
<name>Gulliksson</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2008/0192129</doc-number>
<kind>A1</kind>
<name>Walker et al.</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482312</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2009/0207279</doc-number>
<kind>A1</kind>
<name>Ochi et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2010/0135395</doc-number>
<kind>A1</kind>
<name>Servais et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>H11-136557</doc-number>
<kind>A</kind>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>JP</country>
<doc-number>2004-242093</doc-number>
<kind>A</kind>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>JP</country>
<doc-number>2007-049408</doc-number>
<kind>A</kind>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>13</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>1</number-of-drawing-sheets>
<number-of-figures>2</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12365322</doc-number>
<date>20090204</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8098297</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13219103</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61190991</doc-number>
<date>20080903</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110310261</doc-number>
<kind>A1</kind>
<date>20111222</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Crisan</last-name>
<first-name>Adrian</first-name>
<address>
<city>San Diego</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Georgis</last-name>
<first-name>Nikolaos</first-name>
<address>
<city>San Diego</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Crisan</last-name>
<first-name>Adrian</first-name>
<address>
<city>San Diego</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Georgis</last-name>
<first-name>Nikolaos</first-name>
<address>
<city>San Diego</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sony Corporation</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
<assignee>
<addressbook>
<orgname>Sony Electronics Inc.</orgname>
<role>02</role>
<address>
<city>Parkridge</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Cutler</last-name>
<first-name>Albert</first-name>
<department>2661</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A camera system includes an image sensor and a processing apparatus receiving image frames from the sensor before and after receipt of a user picture signal. The processing apparatus discards frames that do not meet a quality criterion such as under-exposed frames. Also, the processing apparatus compresses only a subset of remaining frames, specifically, those that meet a compression amount threshold. The remaining frames are presented to a user, who can select a representative frame as the &#x201c;picture&#x201d; that was taken.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="141.99mm" wi="148.76mm" file="US08625001-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="239.69mm" wi="178.39mm" file="US08625001-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<p id="p-0002" num="0001">This is a continuation of and claims priority to U.S. patent application Ser. No. 12/365,322 filed Feb. 4, 2009 now U.S Pat. No. 8,098,297 and to U.S. Provisional Ser. No. 61/190,991 filed Sep. 3, 2008.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to capturing images in a digital camera both prior to and after the user generates a shutter open signal, and then sorting the images for the user to select one or more images.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Digital camera users often miss the opportunity to capture an image at the right time. This is sometimes due to the slow camera response of point-and-shoot digital cameras. Another potential reason is that the subject has moved, wrongly posed, framing is not correct or lighting has changed, resulting in a not correctly exposed image. As a consequence, users are often disappointed to realize that the end result is not the desired one when they review their captured images either on the device or on their personal computer.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0005" num="0004">A method includes, prior to receiving a take picture signal from a camera user input element, capturing plural digital image frames. The method also includes, after receiving the take picture signal, capturing plural image frames. The captured frames can be considered as establishing an initial set of frames. Frames not satisfying a quality criterion are discarded from the initial set of frames to render a filtered image set. The filtered image set is presented to a user for selection of one or more images therefrom, and responsive to a user frame selection, one or more frames from the filtered image set are stored.</p>
<p id="p-0006" num="0005">In some implementations the method may include compressing only frames yielding a minimum compressed size to establish a compressed set of frames. Only frames in the filtered image set may be compressed. Frames in the filtered image set may not be compressed if the frame results in a compressed file larger than a threshold. Only frames in the compressed set of frames may be presented to the user.</p>
<p id="p-0007" num="0006">The method may be executed in a digital camera device and/or in a computer receiving frame information from a digital camera device.</p>
<p id="p-0008" num="0007">In another aspect, a camera system has an image sensor and processing apparatus that receives image frames from the sensor before and after receipt of a user picture signal. The processing apparatus discards frames that do not meet a quality criterion and compresses only a subset of remaining frames for presentation thereof to a user.</p>
<p id="p-0009" num="0008">In another aspect, a system includes means for producing image frames prior to and after generation of a picture signal to render an initial set of frames. Means are provided for filtering frames from the initial set of frames based on at least one quality metric to render a filtered set of frames. Also, means are provided for presenting frames from the filtered set of frames to a user for selection of at least one frame.</p>
<p id="p-0010" num="0009">The details of the present invention, both as to its structure and operation, can best be understood in reference to the accompanying drawings, in which like reference numerals refer to like parts, and in which:</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic block diagram of an example camera; and</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart of example logic in accordance with present principles.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
<p id="p-0013" num="0012">Referring initially to <figref idref="DRAWINGS">FIG. 1</figref>, a digital camera <b>10</b> includes a portable lightweight hand-held housing <b>12</b> holding a camera sensor <b>14</b> such as but not limited to a charge-coupled device (CCD). The sensor <b>14</b> produces images sensed through a lens <b>16</b>, and in the example non-limiting embodiment shown the images are sent to a processing circuit <b>18</b> which executes compression/frame selection logic in accordance with disclosure below, it being understood that the logic of <figref idref="DRAWINGS">FIG. 2</figref> alternatively may be entirely embodied by software on, e.g., the below-described PC or storage medium.</p>
<p id="p-0014" num="0013">In turn, the processing circuit <b>18</b> may communicate with a camera processor <b>20</b> in the housing <b>12</b>, which can access and store data on a computer-readable medium <b>22</b>. The medium <b>22</b> may be, without limitation, disk-based storage and/or solid state storage and in one implementation is implemented by random access memory (RAM).</p>
<p id="p-0015" num="0014">To activate the camera <b>10</b>, a power button <b>24</b> may be provided on the housing <b>12</b>. A user can manipulate the power button <b>24</b> to cause one or more camera batteries <b>26</b> to energize the components of the camera <b>10</b>, including the processor <b>20</b> and a visual display <b>28</b> such as but not limited to a liquid crystal display (LCD). Also, a picture button <b>30</b> typically is provided on the housing <b>12</b> that can be manipulated by a user to signal the user's desire to capture a frame as a picture. If desired, a communications interface <b>32</b> such as but not limited to a universal serial bus (USB) interface may be provided to enable the camera processor <b>20</b> to communicate with, e.g., a user's personal computer <b>34</b>.</p>
<p id="p-0016" num="0015">It is to be understood that the camera <b>10</b> may be implemented as an electronic device with an imaging sensor and storage such as digital cameras per se, camera-equipped mobile phones, personal digital assistants (PDAs), and notebook computers with built in cameras.</p>
<p id="p-0017" num="0016">Now referring to <figref idref="DRAWINGS">FIG. 2</figref>, at block <b>35</b> the camera <b>10</b> is activated by, e.g., the user manipulating the power button <b>24</b>. In the case of a mobile computing device equipped with a camera block <b>35</b> may be implemented by the launch of a camera application.</p>
<p id="p-0018" num="0017">At block <b>36</b> images are captured and filtered-compressed as set forth further below, and at block <b>38</b> image capture continues after receipt of a user-generated &#x201c;take picture&#x201d; signal as might be generated by the user manipulating the picture button <b>26</b>. In one embodiment, &#x201c;N&#x201d; frames are captured after receipt of the &#x201c;take picture&#x201d; signal, wherein &#x201c;N&#x201d; is an integer; also, if desired only &#x201c;M&#x201d; frames (wherein &#x201c;M&#x201d; is an integer) prior to the &#x201c;take picture&#x201d; signal may be retained.</p>
<p id="p-0019" num="0018">In any case, proceeding to block <b>40</b> the frames that preceded the take picture signal and that were retained in, e.g., a temporary location in RAM along with the frame taken in response to the take picture signal plus the post-signal frames that were retained are analyzed for quality, with frames not satisfying one or more quality metrics being discarded. For example, if a frame is found to be under-exposed, i.e., exposed below a threshold, such a frame may be discarded at block <b>40</b>, thus saving storage space and bandwidth.</p>
<p id="p-0020" num="0019">As understood herein, the image sequence captured as described above can be compressed at block <b>42</b> using preferably lossless video coding technology to minimize storage requirements, and additionally only certain frames may undergo compression. Specifically, at block <b>42</b> only frames that result in a minimal compressed file may be compressed, i.e., only frames that satisfy a compression amount threshold of, e.g., at least 20% compressed are compressed. For example, a frame that might have passed the exposure test at block <b>40</b> but nonetheless due to exposure anomalies would result in a significant increase in the size of the compressed file because motion compensation techniques that are used in lossless video coding might fail to find a frame similar to the frame under test and, thus, result in a relatively large file even after compression, would not be compressed at block <b>42</b>. Thus, only a subset of frames surviving the screening test of block <b>40</b> might be compressed at block <b>42</b>.</p>
<p id="p-0021" num="0020">The final compressed set of frames from block <b>42</b> is stored at block <b>44</b> and presented (after decompression) to the user at block <b>46</b> on, e.g., the display <b>28</b>. The frames may be presented automatically or in response to user signals, which may allow the user to scroll through the frames and then select one or more, with non-selected frames being discarded from memory if desired.</p>
<p id="p-0022" num="0021">In alternate embodiments instead of executing the above-described processing entirely on the camera <b>10</b>, frames may be sent to a PC or server through the communication interface <b>32</b> for processing as described. Also, users not only have the opportunity to analyze captured image sequence on the camera <b>10</b> itself, but alternatively may download the frames output by block <b>42</b> to the PC <b>34</b> and use a software application that allows them to browse the image sequence and re-capture the desired frame.</p>
<p id="p-0023" num="0022">In the example non-limiting implementation shown, the lossless video coding algorithm is implemented in a hardware processing circuit <b>18</b> that directly captures images from the sensor <b>14</b>, with the camera <b>10</b> processing and storing the compressed image sequence to the storage medium <b>22</b> using direct memory access (DMA) to minimize processing overhead. However, present principles can be implemented in software in either the camera <b>10</b> or the personal computer <b>34</b>.</p>
<p id="p-0024" num="0023">If desired, image enhancements in accordance with image enhancing principles known in the art can be applied to the image sequence before being presented to the user. Such enhancement can include but are not limited to applying super-resolution algorithms to the captured frames.</p>
<p id="p-0025" num="0024">It may now be appreciated that using present principles, users of digital cameras or camera equipped mobile devices have the opportunity to correct problems in captured images by being given the chance to review not only their captured image but also the previous and following frames too. Users can select the frame of their choice either on their device or on their personal computer and finally save it to their album. They also have the opportunity to create mosaics or enhance the quality of the captured image by using super-resolution imaging on the captured image sequence.</p>
<p id="p-0026" num="0025">In addition to the above, various sensors may be used determine when to start automatic frame capturing. Usage of various sensors such as orientation sensors, heat sensors, camera CCD/CMOS images, proximity sensors, or accelerometers can be used to determine when to capture a picture. For example, the above-described automatic capturing can begin as soon as a proximity sensor detects that the user's face is near the viewfinder eyepiece.</p>
<p id="p-0027" num="0026">Additionally, metrics such as image contrast or proper exposure may be used to determine if a frame that has been captured automatically is worth keeping or not. Other metrics that may be used are determinations of whether points of interest are located/distributed properly, whether the color/light is properly balanced, etc.</p>
<p id="p-0028" num="0027">Furthermore two or more frames may be combined using, e.g., super-resolution techniques to create a new picture that is a combination of a few sub-optimal frames and that is much better than any of the original frames, in effect a frame that the user might never have been able to capture otherwise. Super-resolution imaging may thus be used to improve dynamic range and also eliminate camera sensor noise during shooting a night scene.</p>
<p id="p-0029" num="0028">While the particular PRE- AND POST-SHUTTER SIGNAL IMAGE CAPTURE AND SORT FOR DIGITAL CAMERA is herein shown and described in detail, it is to be understood that the subject matter which is encompassed by the present invention is limited only by the claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system comprising:
<claim-text>a processing apparatus operatively coupled to an image sensor, the processing apparatus being operable to:
<claim-text>receive image frames from the image sensor in response to receipt of a user picture signal, wherein the received image frames comprise a set of image frames captured by the image sensor prior to reception of the user picture signal, during the reception of the user picture signal, and after the reception of the user picture signal, wherein the image frames captured by the image sensor prior to the reception of the user picture signal are based on receipt of a sensor input from one or more of: an orientation sensor, a proximity sensor, or an accelerometer, prior to the user picture signal;</claim-text>
<claim-text>discard a first set of one or more image frames from the received image frames based on a determination that the first set of one or more image frames do not satisfy at least one quality criterion;</claim-text>
<claim-text>discard a second set of one or more image frames from the remaining image frames based on a determination that the second set of one or more image frames do not compress to a size small enough to satisfy a compression threshold;</claim-text>
<claim-text>compress one or more third image frames other than the first set of one or more image frames and the second set of one or more image frames for presentation thereof to a user.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing apparatus comprises processing circuitry within a camera housing.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing apparatus is operable to consider a maximum of &#x201c;N&#x201d; frames imaged after the user picture signal and a maximum of &#x201c;M&#x201d; frames imaged prior to the user picture signal for compression.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the quality criterion is sufficient exposure.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing apparatus is external to a camera housing holding the image sensor.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing apparatus is further operable to decompress the compressed third image frames prior to the presentation to the user.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing apparatus is further operable to compose a fourth image by combining the one or more third image frames using super-resolution technique.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An imaging system comprising:
<claim-text>an image sensor operable to generate image frames in response to receipt of a user picture signal, wherein the generated image frames comprise an initial set of image frames captured by the image sensor prior to reception of the user picture signal, during the reception of the user picture signal, and after the reception of the user picture signal, wherein the image frames captured by the image sensor prior to the reception of the user picture signal are based on receipt of a sensor input from one or more of: an orientation sensor, a proximity sensor, or an accelerometer, prior to the user picture signal;</claim-text>
<claim-text>a processing apparatus comprising one or more processors operable to:
<claim-text>filter a first set of one or more image frames from the initial set of image frames based on a determination that the first set of one or more image frames fail to satisfy at least one quality metric;</claim-text>
<claim-text>discard a second set of one or more image frames from the initial set of image frames based on a determination that the second set of one or more image frames, if compressed, would be larger than a compression threshold; and</claim-text>
<claim-text>present one or more remaining image frames that are not filtered and not discarded to a user for selection of at least one of the remaining image frames.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The imaging system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more processors are further operable to compress the remaining frames.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The imaging system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the processing apparatus is embodied in a camera housing holding the image sensor.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The imaging system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the processing apparatus is embodied in a computer separate from a camera housing holding the image sensor.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The imaging system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the quality metric comprises exposure.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The imaging system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more processors operable to filter the first set of one or more image frames and compress the remaining image frames using one of: hardware or a combination of hardware and software.</claim-text>
</claim>
</claims>
</us-patent-grant>
