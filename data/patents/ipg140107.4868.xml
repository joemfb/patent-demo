<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625961-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625961</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11750621</doc-number>
<date>20070518</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2006-161084</doc-number>
<date>20060609</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>1213</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>80</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>765</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>93</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>386241</main-classification>
<further-classification>386200</further-classification>
<further-classification>386239</further-classification>
<further-classification>386248</further-classification>
<further-classification>386353</further-classification>
</classification-national>
<invention-title id="d2e71">Information processing system, recording/playback apparatus, playback terminal, information processing method, and program</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7578429</doc-number>
<kind>B2</kind>
<name>Nagatsuka et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235375</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>8112718</doc-number>
<kind>B2</kind>
<name>Nezu et al.</name>
<date>20120200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715810</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2003/0086691</doc-number>
<kind>A1</kind>
<name>Yu</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386 69</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2004/0008970</doc-number>
<kind>A1</kind>
<name>Junkersfeld et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386 69</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2004/0221308</doc-number>
<kind>A1</kind>
<name>Cuttner et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 46</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2005/0044489</doc-number>
<kind>A1</kind>
<name>Yamagami et al.</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2005/0114214</doc-number>
<kind>A1</kind>
<name>Itoh</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 14</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2005/0169610</doc-number>
<kind>A1</kind>
<name>Ono</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2005/0207727</doc-number>
<kind>A1</kind>
<name>Hirose et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386 46</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2005/0229223</doc-number>
<kind>A1</kind>
<name>Katagishi et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0245233</doc-number>
<kind>A1</kind>
<name>Anderson</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455411</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2005/0281540</doc-number>
<kind>A1</kind>
<name>Inokuchi et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386 94</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2006/0085367</doc-number>
<kind>A1</kind>
<name>Genovese</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 44</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2006/0159429</doc-number>
<kind>A1</kind>
<name>Sugahara et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386 95</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>JP</country>
<doc-number>2002-262220</doc-number>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>JP</country>
<doc-number>2004-72132</doc-number>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>JP</country>
<doc-number>2004-229035</doc-number>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>JP</country>
<doc-number>2004-350092</doc-number>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>JP</country>
<doc-number>2005-151445</doc-number>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>2005-175715</doc-number>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>2005-184180</doc-number>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>JP</country>
<doc-number>2005-251374</doc-number>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>JP</country>
<doc-number>2005-286855</doc-number>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>JP</country>
<doc-number>2006-199996</doc-number>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>WO</country>
<doc-number>WO 2004/112036</doc-number>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-cpc-text>G11B 27/10</classification-cpc-text>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>WO</country>
<doc-number>WO 2004/112036</doc-number>
<kind>A1</kind>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Japanese Office Action issued Dec. 2, 2010, in Patent Application No. 2006-161084.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Office Action issued Aug. 23, 2011, in Japanese Patent Application No. 2006-161084, filed Jun. 9, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>Office Action issued Jun. 19, 2012, in Japanese Patent Application No. 2006-161084, filed Jun. 9, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>386200</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386201</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386216</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386219</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386230</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386232</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386239</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386241</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386353</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386328</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070286584</doc-number>
<kind>A1</kind>
<date>20071213</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yukimatsu</last-name>
<first-name>Yosuke</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Yukimatsu</last-name>
<first-name>Yosuke</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oblon, Spivak, McClelland, Maier &#x26; Neustadt, L.L.P.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Dang</last-name>
<first-name>Hung</first-name>
<department>2484</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An information processing system is disclosed. The information processing system includes: a recording/playback apparatus; and a playback terminal. The recording/playback apparatus includes an output unit, a management unit, and a playback unit. The playback terminal includes a playback unit, a generating unit, and an output unit.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="129.37mm" wi="155.36mm" file="US08625961-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="225.64mm" wi="174.16mm" orientation="landscape" file="US08625961-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="137.41mm" wi="157.56mm" file="US08625961-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="180.17mm" wi="141.05mm" orientation="landscape" file="US08625961-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="215.48mm" wi="131.66mm" orientation="landscape" file="US08625961-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="207.43mm" wi="94.06mm" orientation="landscape" file="US08625961-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="183.13mm" wi="111.42mm" file="US08625961-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="216.15mm" wi="121.16mm" file="US08625961-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="172.30mm" wi="124.80mm" orientation="landscape" file="US08625961-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present invention contains subject matter related to Japanese Patent Application JP 2006-161084 filed in the Japanese Patent Office on Jun. 9, 2006, the entire contents of which being incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The invention relates to an information processing system, a recording/playback apparatus, a playback terminal, an information processing method and a program, particularly, relates to the information processing system, the recording/playback apparatus, the playback terminal, the information processing method and the program, in which a position of a content from which playback is started by the recording/playback device can be selected by a user by referring positions designated by the playback terminal.</p>
<p id="p-0005" num="0004">2. Background Art</p>
<p id="p-0006" num="0005">In recent years, concerning a recorder which records video contents such as broadcast programs, the ones using nonvolatile memories having high capacity such as an HDD (Hard Disc Drive) and a DVD (Digital Versatile Disc) prevail, which enables recording of many video contents. It is anticipated that the number of video contents which can be recorded in the recorder continues to increase by the increase of capacity of the HDD and commercialization of optical discs having high capacity.</p>
<p id="p-0007" num="0006">Additionally, as multi-channel broadcasting is introduced in recent years, multi-content delivery is proceeding. In addition to previous terrestrial analog broadcasting, Cs (Communications Satellite) digital broadcasting, BS (Broadcasting Satellite) digital broadcasting, and terrestrial digital broadcasting are started, which increases the number of video contents which can be seen by viewers.</p>
<p id="p-0008" num="0007">Accordingly, it is presumable that, as the recorder in the future, the recorder complying with the multi-channel broadcasting will prevail. In view of that, it is presumable that many viewers perform recording for the moment and select video contents to be actually viewed among the recorded contents.</p>
<p id="p-0009" num="0008">Viewing style in which video contents recorded in the recorder are viewed by a portable terminal is prevailing, based on technical background such as improvement of processing power of the CPU (Central Processing Unit) in the potable terminals represented by a cellular phone, high capacity in a memory card removable from the portable terminal, and high capacity in a nonvolatile memory mounted on the portable terminal, as well as environmental changes such as increase of prerecorded video contents.</p>
<p id="p-0010" num="0009">In JP-A-2002-262220 (Patent Document 1), a technique is disclosed, in which a video content is transmitted to a portable information apparatus after the content is converted into a file for the portable playback device in a recording/playback apparatus connected to the portable playback device.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0011" num="0010">However, the viewing style of video contents using the portable terminal is not always excellent in the following points.</p>
<p id="h-0004" num="0000">1. Since it is necessary to compress data of video contents, picture quality is low.</p>
<p id="h-0005" num="0000">2. On the nature of the portable terminal as a device, the size of a display used for viewing is small.</p>
<p id="h-0006" num="0000">3. Viewing in trains or at the outdoor is anticipated, therefore there is a case that a noise problem exist.</p>
<p id="p-0012" num="0011">Consequently, it is conceivable that there a request that at least main scenes of the video content viewed by using the portable terminal are viewed by using a device at home having good viewing environment, however, in the technique at present, it is necessary that playback is started from the head of the video content and desired positions to be viewed are searched by performing fast-forwarding operation or rewinding operation despite it is the same video content as the one viewed by using the portable terminal.</p>
<p id="p-0013" num="0012">It is desirable to allow the user to select positions of the content from which playback is started by the recording/playback apparatus by referring positions designated by the playback terminal.</p>
<p id="p-0014" num="0013">An information processing system according to an embodiment of the invention includes a recording/playback apparatus and a playback terminal. The recording/playback apparatus as one of them has an output unit outputting a content to the playback terminal, a management unit managing a list in which plural information including position information indicating positions designated by a user of the playback terminal during playback of the content and identification information of the user of the playback terminal, which are outputted from the playback terminal, and a playback unit presenting specific information at respective positions indicated by the position information included in information including the same identification information as identification information designated by the user among information registered in the list, and playing back the content from a selected position, and the playback terminal has a playback unit playing back a content outputted from the recording/playback apparatus, a generating unit generating information including position information indicating positions in the content designated by the user during playback of the content and identification information of the user, and registering the information in the list, and an output unit outputting the list in which plural information generated by the generating unit is registered to the recording/playback apparatus.</p>
<p id="p-0015" num="0014">A recording/playback apparatus according to an embodiment of the invention includes an output unit outputting a content to the playback terminal, a management unit managing a list in which plural information including position information indicating positions designated by a user of the playback terminal during playback of the content and identification information of the user of the playback terminal, which are outputted from the playback terminal, and a playback unit presenting specific information of the content at respective positions indicated by the position information included in information including the same identification information as identification information designated by the user among information registered in the list, and playing back the content from a selected position.</p>
<p id="p-0016" num="0015">The playback unit can present at least images of the content and time information at respective positions as the specific information.</p>
<p id="p-0017" num="0016">In the case that comments inputted by the user of the playback terminal when designating positions of the content are included in information registered in the list, the playback unit can further represent the comments as the specific information in addition to images of the content and time information at respective positions.</p>
<p id="p-0018" num="0017">An information processing method or a program according to an embodiment of the invention includes the steps of outputting a content to a playback terminal, managing a list in which plural information including position information indicating positions designated by a user of the playback terminal during playback of the content and identification information of the user of the playback terminal, which are outputted from the playback terminal, and presenting specific information of the content at respective positions indicated by the position information included in information including the same identification information as identification information designated by the user among information registered in the list, and playing back the content from a selected position.</p>
<p id="p-0019" num="0018">A playback terminal according to an embodiment of the invention includes a playback unit playing back a content outputted from a recording/playback apparatus, a generating unit generating information including position information indicating positions in the content designated by the user during playback of the content and identification information of the user, and registering the information in a list, and an output unit outputting the list in which plural information generated by the generating unit is registered to the recording/playback apparatus.</p>
<p id="p-0020" num="0019">The generating unit, when position registration is instructed during the playback of the content, can present plural positions which are prior to a playback position at the time by predetermined periods of time as positions to be able to be registered, and can generate information including the position information indicating a selected position from the presented positions.</p>
<p id="p-0021" num="0020">The generating unit can generate information including comments inputted by the user when designating positions of the content.</p>
<p id="p-0022" num="0021">An information processing method or a program according to an embodiment of the invention includes the steps of playing back a content outputted from a recording/playback apparatus, generating information including position information indicating positions of the content designated by the user during the playback of the content and identification information of the user, and registering the information in a list, and outputting the list in which the generated plural information is registered to the recording/playback apparatus.</p>
<p id="p-0023" num="0022">In the recording/playback apparatus in the information processing system of the embodiment of the invention, the content is outputted to the playback terminal, and the list is managed, in which plural information including position information indicating positions designated by the user of the playback terminal during playback of the content and the identification information of the user of the playback terminal, which are outputted from the playback terminal. In addition, specific information of the content at respective positions indicated by the position information included in information including the same identification information as identification information designated by the user among information registered in the list is presented, and the content is played back from a selected position.</p>
<p id="p-0024" num="0023">On the other hand, in the playback terminal, a content outputted from the recording/playback apparatus is played back, information including position information indicating positions in the content designated by the user during playback of the content and identification information of the user is generated and registered in the list. In addition, the list in which the generated plural information is registered is outputted to the recording/playback apparatus.</p>
<p id="p-0025" num="0024">According to the embodiment of the invention, a content is outputted to a playback terminal, a list in which plural information including position information indicating positions designated by a user of the playback terminal during playback of the content and identification information of the user of the playback terminal, which are outputted from the playback terminal is managed. In addition, specific information of the content at respective positions indicated by the position information included in information including the same identification information as identification information designated by the user among information registered in the list is presented, and the content is played back from a selected position.</p>
<p id="p-0026" num="0025">According to the embodiment of the invention, a content outputted from a recording/playback apparatus is played back, information including position information indicating positions of the content designated by the user during the playback of the content and identification information of the user is generated and registered in a list. In addition, the list in which the generated plural information is registered is outputted to the recording/playback apparatus.</p>
<p id="p-0027" num="0026">According to the embodiment of the invention, the user selects a position of the content from which playback is started by the recording/playback apparatus, referring positions designated by using the playback terminal.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0007" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 1</figref> is a view showing a configuration example of an information processing system according to an embodiment of the invention;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 2</figref> is a view showing a display example of a registration window for a playback start position;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 3</figref> is a view showing a display example of a selection window for a playback start position;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram showing a function configuration of a recording/playback device;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram showing a function configuration of a portable playback device;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart explaining processing of the recording/playback device;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart explaining processing of the portable playback device; and</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram showing a configuration example of a personal computer.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0008" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0036" num="0035">Embodiments of the invention will be described below, and the correspondence between constituent features of the invention and embodiments described in the specification and the drawings is exemplified as follows. The description is made for confirming that embodiments which support the invention are written in the specification and the drawings. Therefore, if there is an embodiment which is written in the specification and the drawings but not written here as the embodiment corresponding to a constituent feature of the invention, that does not mean that the embodiment does not correspond to the constituent feature. Conversely, if an embodiment is written here as the embodiment corresponding to the invention, that does not mean that the embodiment does not correspond to a feature other than the constituent feature.</p>
<p id="p-0037" num="0036">An information processing system according to an embodiment of the invention (for example, an information processing system of <figref idref="DRAWINGS">FIG. 1</figref>) basically includes a configuration of a recording/playback apparatus of the embodiment of the invention (for example, a recording/playback device <b>1</b> of <figref idref="DRAWINGS">FIG. 1</figref>) and a configuration of a playback terminal of the embodiment of the invention (for example, a portable playback device <b>2</b> of <figref idref="DRAWINGS">FIG. 1</figref>). The correspondence between respective configurations and embodiments will be described as follows.</p>
<p id="p-0038" num="0037">A recording/playback apparatus according to an embodiment of the invention includes an output unit (for example, a transfer unit <b>52</b> of <figref idref="DRAWINGS">FIG. 4</figref>) outputting a content to the playback terminal, a management unit (for example, a playback position information list management unit <b>53</b> of <figref idref="DRAWINGS">FIG. 4</figref>) managing a list in which plural information including position information indicating positions designated by a user of the playback terminal during playback of the content and identification information of the user of the playback terminal, which are outputted from the playback terminal, and a playback unit (for example, a display control unit <b>54</b> of <figref idref="DRAWINGS">FIG. 4</figref>) presenting specific information of the content at respective positions indicated by the position information included in information including the same identification information as identification information designated by the user among information registered in the list, and playing back the content from a selected position.</p>
<p id="p-0039" num="0038">An information processing method or a program according to an embodiment of the invention includes the steps of outputting a content to a playback terminal, managing a list in which plural information including position information indicating positions designated by a user of the playback terminal during playback of the content and identification information of the user of the playback terminal, which are outputted from the playback terminal, and presenting specific information of the content at respective positions indicated by the position information included in information including the same identification information as identification information designated by the user among information registered in the list, and playing back the content from a selected position (for example, Step S<b>7</b> of <figref idref="DRAWINGS">FIG. 6</figref>).</p>
<p id="p-0040" num="0039">A playback terminal according to an embodiment of the invention includes a playback unit (for example, a display control unit <b>62</b> of <figref idref="DRAWINGS">FIG. 5</figref>) playing back a content outputted from a recording/playback apparatus, a generating unit (for example, a playback position information generating unit <b>63</b> of <figref idref="DRAWINGS">FIG. 5</figref>) generating information including position information indicating positions in the content designated by the user during playback of the content and identification information of the user, and registering the information in the list, and an output unit (for example, a transfer unit <b>61</b> of <figref idref="DRAWINGS">FIG. 5</figref>) outputting the list in which plural information generated by the generating unit is registered to the recording/playback apparatus.</p>
<p id="p-0041" num="0040">An information processing method or a program according to an embodiment of the invention includes the steps of playing back a content outputted from a recording/playback apparatus, generating information including position information indicating positions of the content designated by the user during the playback of the content and identification information of the user, and registering the information in a list, and outputting the list in which the generated plural information is registered to the recording/playback apparatus (for example, Step S<b>19</b> of <figref idref="DRAWINGS">FIG. 7</figref>).</p>
<p id="p-0042" num="0041">Hereinafter, embodiments of the invention will be explained with reference to the drawings.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 1</figref> is a view showing a configuration example of an information processing system according to an embodiment of the invention.</p>
<p id="p-0044" num="0043">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the information processing system includes a recording/playback device <b>1</b> and a portable playback device <b>2</b>.</p>
<p id="p-0045" num="0044">The recording/playback device <b>1</b> is a hybrid recorder including, for example, an HDD drive and a DVD drive, which is placed at home. On the other hand, the portable playback device <b>2</b> is a terminal such as a cellular phone, which is held by the user.</p>
<p id="p-0046" num="0045">The recording/playback device <b>1</b> and the portable playback device <b>2</b> can communicate with each other through wires or air. The communication between the recording/playback device <b>1</b> and the portable playback device <b>2</b> is also performed through a memory card respectively removable with respect to the recording/playback device <b>1</b> and the portable playback device <b>2</b>.</p>
<p id="p-0047" num="0046">In the information processing system including these devices, the user transfers a prerecorded content recorded in the recording/playback device <b>1</b> to the portable playback device <b>2</b> and can view the content by using the portable playback device <b>2</b>. When the user is viewing the content by using the portable playback device <b>2</b>, the user can also register positions such as favorite scenes in the portable playback device <b>2</b>.</p>
<p id="p-0048" num="0047">Information concerning positions registered in the portable playback device <b>2</b> is outputted from the portable playback device <b>2</b> to the recording/playback device <b>1</b> at a predetermined timing such as when the communication becomes available again, and respective positions are presented to the user by the recording/playback device <b>1</b>. The user allows the recording/playback device <b>1</b> to start playing back of the same content as the content viewed by using the portable playback device <b>2</b> from the selected position by selecting a designated position from the positions to be presented. A television receiver including an LCD (Liquid Crystal Display) and the like is connected to the recording/playback device <b>1</b>, and content video played back by the recording/playback device <b>1</b> is displayed on a screen of the television receiver.</p>
<p id="p-0049" num="0048">The above function is used, for example, on an occasion when positions of favorite scenes at the time of viewing the content by using the portable playback device <b>2</b> are registered, and the same scenes are reviewed leisurely by using the recording/playback device <b>1</b> after coming home, or on an occasion when one scene of a program such as an English conversation program is viewed repeatedly by using the recording/playback device <b>1</b> or the portable playback device.</p>
<p id="p-0050" num="0049">A sequence of processing flow performed between the recording/playback device <b>1</b> and the portable playback device <b>2</b> will be explained.</p>
<p id="p-0051" num="0050">A plurality of prerecorded contents are recorded in the recording/playback device <b>1</b>, and a content selected, for example, from a list of the prerecorded contents by the user is converted into a content having a format for the portable playback device <b>2</b> by lowering resolution or reducing the transfer rate as shown by an arrow A<b>1</b>.</p>
<p id="p-0052" num="0051">The content whose format has been converted is copied to the portable playback device <b>2</b> by communication performed between the recording/playback device <b>1</b> and the portable playback device <b>2</b> by wires or air, or by a memory card in which the content is recorded by the recording/playback device <b>1</b> mounted on the portable playback device <b>2</b> and read out from the portable playback device <b>2</b>, as shown by an arrow A<b>2</b>. The original content remains in the recording/playback device <b>1</b> and the content having lower quality than the original content, though the contents are the same as the original, is outputted to the portable playback device <b>2</b>.</p>
<p id="p-0053" num="0052">In the portable playback device <b>2</b>, the content copied from the recording/playback device <b>1</b> is played back according to an instruction by the user as shown by an arrow A<b>3</b>, and video of the content is displayed at a display unit <b>21</b> provided in the portable playback device <b>2</b>. The user can view the content which has been recorded in the recording/playback device <b>1</b> by using the portable playback device <b>2</b>.</p>
<p id="p-0054" num="0053">During viewing of the content, as described above, the user can register positions of the content by operating, for example, a button provided at the portable playback device <b>2</b>. The operation by the user is received by an input unit <b>22</b> and playback position information is generated according to the input by the user.</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 2</figref> is a view showing a display example of a registration window for a playback start position.</p>
<p id="p-0056" num="0055">The window shown in <figref idref="DRAWINGS">FIG. 2</figref> is displayed when the user instructs the position registration during viewing of the content.</p>
<p id="p-0057" num="0056">When the user instructs the position registration, the playback of the content becomes a pause state, and a menu <b>31</b> is displayed as a UI (User Interface) used for the position registration, being superimposed on the content video as shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0058" num="0057">In the menu <b>31</b>, an &#x201c;YES&#x201d; button <b>32</b> selected when registering a position, a &#x201c;NO&#x201d; button <b>33</b> selected when position registration is stopped, and a selection menu <b>34</b> used for selecting a position to be registered as a position played back how many seconds prior to a current playback position when the user instructs the position registration are displayed.</p>
<p id="p-0059" num="0058">In the example of <figref idref="DRAWINGS">FIG. 2</figref>, three items of &#x201c;0 second before&#x201d;, &#x201c;10 seconds before&#x201d; and &#x201c;20 seconds before&#x201d; are displayed in the selection menu <b>34</b>, and the user can register the position which is prior to the current playback position by the selected seconds from the selection menu <b>34</b> by selecting one item by pressing an up-and-down button provided at a surface of a casing of the portable playback device <b>2</b>, and next, selecting the &#x201c;YES&#x201d; button <b>32</b>.</p>
<p id="p-0060" num="0059">When registering the position, the user can input designated character strings as a comment concerning the position which has been registered by the user. It is preferable that the input of character strings is performed by using the UI for inputting character strings such as a software keyboard, or also preferable to be performed by using alphabet keys physically provided at the portable playback device <b>2</b>.</p>
<p id="p-0061" num="0060">The position registration is performed by the user, using the UI described above.</p>
<p id="p-0062" num="0061">Returning to the explanation for <figref idref="DRAWINGS">FIG. 1</figref>, when the input concerning the position by the user is received by the input unit <b>22</b>, as shown by an arrow A<b>4</b>, playback position information concerning the position designated by the user is generated, and registered in a playback position information list stored in an internal nonvolatile memory. The communication of information between the recording/playback device <b>1</b> and the portable playback device <b>2</b> is performed through the memory card, the playback position information generated in accordance with the input by the user will be registered in the playback position information list stored in the memory card.</p>
<p id="p-0063" num="0062">For example, an identification ID of the content during playback, an identification ID of the user and optional character strings inputted by the user are included in the playback position information, in addition to position information represented by time from the head of the content. That is, one position in the content is indicated by one playback position information. In the playback position information list can register plural playback position information. It is also preferable that playback position information of plural contents is allowed to be registered in one playback position information list. In the case that the identification ID is set in the portable playback device <b>2</b>, for example, an identification ID of the portable playback device <b>2</b> is used as the identification ID of the user.</p>
<p id="p-0064" num="0063">The registration of the playback position information is repeated every time position registration is instructed by the user and playback position information is generated, and the playback position information list obtained by the processing is copied to the recording/playback device <b>1</b> at a predetermined timing as shown by an arrow A<b>5</b>. The copy of the playback position information list is performed by, for example, the communication between the recording/playback device <b>1</b> and the portable playback device <b>2</b> by wires or air or by the recording/playback device <b>1</b> reading out the playback position information list recorded in the memory card by the portable playback device <b>2</b>.</p>
<p id="p-0065" num="0064">When the playback position information list is copied to the internal nonvolatile memory, only playback position information concerning the content selected as a playback target by the user from all playback position information registered in the playback position information list is selected in the recording/playback device <b>1</b>. The selection of the playback position information is performed based on a result of matching between the identification ID of the content selected as the play back target and the identification ID of the content included in the playback position information.</p>
<p id="p-0066" num="0065">Additionally, a thumbnail image is generated, which shows the contents at a position of the content indicated by the playback position information selected based on the identification ID of the content, and displayed at a display unit <b>11</b> by the recording/playback device <b>1</b> as shown by an arrow A<b>6</b>. In the case that the user registered plural positions in one content, thumbnail images showing the contents at respective positions are generated and displayed in a list. The display unit <b>11</b> is, for example, a component of the television receiver connected to the recording/playback device <b>1</b>.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 3</figref> is a view showing a display example of a selection window for a playback start position.</p>
<p id="p-0068" num="0067">The window shown in <figref idref="DRAWINGS">FIG. 3</figref> is displayed when the content of the playback target is selected and the display of the list of the playback start positions is instructed by the user, using, for example, a remote controller of the recording/playback device <b>1</b>.</p>
<p id="p-0069" num="0068">In the example of <figref idref="DRAWINGS">FIG. 3</figref>, information of four playback start positions is displayed at columns <b>41</b> to <b>44</b> in time series, respectively. The figure shows the example in which the user registered four positions when the user viewed a content of &#x201c;W-Cup Soccer Japan&#xd7;Brazil&#x201d; a title of which is shown at an upper part of <figref idref="DRAWINGS">FIG. 3</figref> by using the portable playback device <b>2</b>.</p>
<p id="p-0070" num="0069">Information displayed in the column <b>41</b> in <figref idref="DRAWINGS">FIG. 3</figref> is information concerning a position specified by &#x201c;0:00:00&#x201d; in the content of &#x201c;W-Cup Soccer Japan&#xd7;Brazil&#x201d;.</p>
<p id="p-0071" num="0070">An image displayed at the left end of the column <b>41</b> is a thumbnail image generated by the recording/playback device <b>1</b> based on the content video at the position specified by &#x201c;0:00:00&#x201d;, and character strings &#x201c;PROGRAM START&#x201d; displayed at the right side of the display of &#x201c;0:00:00&#x201d; are a comment inputted when the user registered the position of &#x201c;0:00:00&#x201d; in the portable playback device <b>2</b>.</p>
<p id="p-0072" num="0071">Information displayed at the column <b>42</b> of <figref idref="DRAWINGS">FIG. 3</figref> is information concerning a position specified by &#x201c;0:15:12&#x201d; in the content of &#x201c;W-Cup Soccer Japan&#xd7;Brazil&#x201d;.</p>
<p id="p-0073" num="0072">An image displayed at the left end of the column <b>42</b> is a thumbnail image generated by the recording/playback device <b>1</b> based on the content video at the position specified by &#x201c;0:15:12&#x201d;, and character strings &#x201c;GAME START&#x201d; displayed at the right side of the display of &#x201c;0:15:12&#x201d; are a comment inputted when the user registered the position of &#x201c;0:15:12&#x201d; in the portable playback device <b>2</b>.</p>
<p id="p-0074" num="0073">In the same manner, information displayed at the column <b>43</b> of <figref idref="DRAWINGS">FIG. 3</figref> is information concerning a position specified by &#x201c;0:53:33&#x201d; in the content of &#x201c;W-Cup Soccer Japan&#xd7;Brazil&#x201d;, and information displayed at the column <b>44</b> is information concerning a position specified by &#x201c;1:27:20&#x201d; in the content of &#x201c;W-Cup Soccer Japan&#xd7;Brazil&#x201d;.</p>
<p id="p-0075" num="0074">The user can select a playback start position at a certain column from the above window displayed by the recording/playback device <b>1</b> by operating the remote controller and the like and allows the playback of the content to start from the selected position.</p>
<p id="p-0076" num="0075">For example, when the user selects the playback start position of the column <b>42</b> of <figref idref="DRAWINGS">FIG. 3</figref>, playback of the content &#x201c;W-Cup Soccer JapanxBrazil&#x201d; is started from the position specified by &#x201c;0:15:12&#x201d; in the recording/playback device <b>1</b>.</p>
<p id="p-0077" num="0076">The display of the window shown in <figref idref="DRAWINGS">FIG. 3</figref> is performed based on playback position information including the same identification ID as the user's identification ID inputted by the user. In the case that plural users use the recording/playback device <b>1</b>, respective users can display the list of playback start positions registered by them by instructing the display of the list of the playback start positions after respective users input their identification IDs.</p>
<p id="p-0078" num="0077">Returning to the explanation of <figref idref="DRAWINGS">FIG. 1</figref>, the operation performed by the user with respect to the window shown in <figref idref="DRAWINGS">FIG. 3</figref> are received by an input unit <b>12</b>. When the operation of selecting the playback start position by the user is received by the input unit <b>12</b>, the playback is started from a position selected by the user as shown by an arrow A<b>7</b>.</p>
<p id="p-0079" num="0078">As described above, the user can select the position from which the playback is started by the recording/playback device <b>1</b> by referring the positions which have been registered when viewed by using the portable playback device <b>2</b>. The user can easily search scenes and the like registered by the user because he/she wanted to view the scenes again when coming home.</p>
<p id="p-0080" num="0079">Additionally, since comments inputted when positions have been registered are displayed at the list of playback start positions, the user can search the target scene more easily, as compared with the case in which thumbnail images and positions are merely displayed as information of respective positions.</p>
<p id="p-0081" num="0080">The details of respective processing of the recording/playback device <b>1</b> and the portable playback device <b>2</b> performed according to the above flow will be described later with reference to flowcharts.</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram showing a function configuration example of the recording/playback device <b>1</b>. At least part of function units shown in <figref idref="DRAWINGS">FIG. 4</figref> is realized by a prescribed program executed by a CPU included in the recording/playback device <b>1</b>.</p>
<p id="p-0083" num="0082">As shown in <figref idref="DRAWINGS">FIG. 4</figref>, in the recording/playback device <b>1</b>, a contents storage unit <b>51</b>, a transfer unit <b>52</b>, a playback position information list management unit <b>53</b>, and a display control unit <b>54</b> are realized.</p>
<p id="p-0084" num="0083">The contents storage unit <b>51</b> stores prerecorded contents. The contents recorded in the contents storage unit <b>51</b> are read out by the transfer unit <b>52</b> when transferred to the portable playback device <b>2</b>, and read out by the display control unit <b>54</b> when played back on the recording/playback device <b>1</b>.</p>
<p id="p-0085" num="0084">For example, when a content is selected from the list of prerecorded contents by the user, the transfer unit <b>52</b> reads out the selected content from the contents storage unit <b>51</b> and converts the read-out content into a content having a format for the portable playback device <b>2</b> to be transferred to the portable playback device <b>2</b>.</p>
<p id="p-0086" num="0085">The transfer unit <b>52</b> also acquires the playback position information list managed by the portable playback device <b>2</b> when the list is transferred from the portable playback device <b>2</b>, and outputs the playback position information list to the playback position information list management unit <b>53</b>.</p>
<p id="p-0087" num="0086">The playback position information list management unit <b>53</b> manages the playback position information list transferred from the portable playback device <b>2</b> by storing the list in a nonvolatile memory and the like. The playback position information list management unit <b>53</b> is, for example, when a content of a playback target is selected by the user, performs matching between the identification ID of the selected content and identification IDs of contents included in respective playback position information registered in the managed playback position information list, and outputs only the playback position information having the matched identification ID to the display control unit <b>54</b>.</p>
<p id="p-0088" num="0087">There is a case in which, after a prerecorded content is transferred to the portable playback device <b>2</b>, the original content is deleted from the contents storage unit <b>52</b>, and playback position information of contents not stored in the contents storage unit <b>51</b> in the playback position information registered in the playback position information list may be abandoned by the playback position information list management unit <b>53</b>.</p>
<p id="p-0089" num="0088">When the content of the playback target is selected by the user, and the display of the position list registered with respect to the content by using the portable playback device <b>2</b> is instructed by the user, the display control unit <b>54</b> reads out data of the content at the position indicated by the playback position information supplied from the playback position information list management unit <b>53</b>, generating a thumbnail image based on the read-out data. In the case that plural playback position information is supplied from the playback position information list management unit <b>53</b>, thumbnail images showing the contents at positions indicated by respective playback position information are generated.</p>
<p id="p-0090" num="0089">The display control unit <b>54</b> displays a window as shown in <figref idref="DRAWINGS">FIG. 3</figref> at the display unit <b>11</b>, in which thumbnail images, times indicating positions when registered are displayed with comments included in the playback position information, allowing the user to select a playback start position of the content.</p>
<p id="p-0091" num="0090">When a certain position is selected from the displayed playback start positions by the user, the display control unit <b>54</b> reads out data of the content starting from the selected position from the contents storage unit <b>51</b>, and plays back the read-out data, thereby displaying content video at the display unit <b>11</b> from the position selected by the user. Audio of the content is also outputted from a speaker and the like of the television receiver connected to the recording/playback device <b>1</b>, which corresponds to the video display.</p>
<p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram showing a function configuration example of the portable playback device <b>2</b>. At least part of function units shown in <figref idref="DRAWINGS">FIG. 5</figref> is realized by a prescribed program executed by a CPU included in the portable playback device <b>2</b>.</p>
<p id="p-0093" num="0092">As shown in <figref idref="DRAWINGS">FIG. 5</figref>, in the portable playback device <b>2</b>, a transfer unit <b>61</b>, a display control unit <b>62</b>, a playback position information generating unit <b>63</b> and a playback position information list management unit <b>64</b> are realized.</p>
<p id="p-0094" num="0093">When the content having a prescribed format selected at the recording/playback device <b>1</b> is transferred from the recording/playback device <b>1</b>, the transfer unit <b>61</b> acquires the content, and outputs the acquired content to the display control unit <b>62</b>.</p>
<p id="p-0095" num="0094">The transfer unit <b>61</b>, when the transfer of the playback position information list to the recording/playback device <b>1</b> is instructed by the user, acquires the playback position information list managed by the playback position information list management unit <b>64</b>, and outputs the playback position information list to the recording/playback device <b>1</b>.</p>
<p id="p-0096" num="0095">The display control unit <b>62</b> plays back the content supplied from the transfer unit <b>61</b> in accordance with instruction by the user, and displays content video at the display unit <b>21</b>. The display control unit <b>62</b> also outputs audio of the content from a speaker, or earphones fitted to the portable playback device <b>2</b>.</p>
<p id="p-0097" num="0096">The display control unit <b>62</b> allows the playback of the content to be a pause state when registration of a position is instructed by the user during playback of the content, displaying the window shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0098" num="0097">When the input by the user performed with respect to the window shown in <figref idref="DRAWINGS">FIG. 2</figref> is received by the input unit <b>22</b>, and information indicating the contents of the input by the user is supplied from the input unit <b>22</b>, the playback position information generating unit <b>63</b> generates playback position information including information of a position indicated by a time from the head of the content, an indication ID of the content, an indication ID of the user and character strings inputted by the user, and outputs the generated playback position information to the playback position information list management unit <b>64</b>. The playback position information generating unit <b>63</b> generates playback position information and outputs the generated playback position information to the playback position information list management unit <b>64</b> every time position registration is instructed by the user.</p>
<p id="p-0099" num="0098">The playback position information management unit <b>64</b> registers the playback position information supplied from the playback position information generating unit <b>63</b> in the playback position information list. The playback position information list managed by the playback position information list management unit <b>64</b> is read out at a predetermined timing by the transfer unit <b>61</b> and transferred to the recording/playback device <b>1</b>.</p>
<p id="p-0100" num="0099">Subsequently, respective processing of the recording/layback device <b>1</b> and the portable playback device <b>2</b> having the above configurations will be explained.</p>
<p id="p-0101" num="0100">First, processing of the recording/playback device <b>1</b> will be explained with reference to a flowchart in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0102" num="0101">The processing is started when, for example, one content is selected from the list of prerecorded contents by the user.</p>
<p id="p-0103" num="0102">In Step S<b>1</b>, the transfer unit <b>52</b> of the recording/playback device <b>1</b> reads out the content selected by the user from the contents storage unit <b>51</b>, and converts the read-out content into a content having a format for the portable playback device <b>2</b> to be transferred to the portable playback device <b>2</b>. In the portable playback device <b>2</b>, the content is played back in accordance with an instruction by the user, and position registration is performed suitably.</p>
<p id="p-0104" num="0103">In Step S<b>2</b>, the transfer unit <b>52</b> judges whether the playback position information list has been transferred from the portable playback device <b>2</b> or not, and waits until the transfer unit <b>52</b> judges that the list has been transferred.</p>
<p id="p-0105" num="0104">When it is judged that the playback position information list has been transferred in Step S<b>2</b>, the transfer unit <b>52</b> proceeds to Step S<b>3</b>, acquiring the transferred playback position information list. The transfer unit <b>52</b> outputs the acquired playback position information list to the playback position information management unit <b>53</b> to allow the list to be managed.</p>
<p id="p-0106" num="0105">In Step S<b>4</b>, the display control unit <b>54</b> judges whether presentation of positions has been instructed by the user or not, which have been registered when the content of the playback target was selected by the user and the same content was viewed by the user by using the portable playback device <b>2</b>, and waits until the display control unit <b>54</b> judges the presentation has been instructed.</p>
<p id="p-0107" num="0106">When the display control unit <b>54</b> judges that the presentation of positions registered when the user viewed the content by using the portable playback device <b>2</b> has been instructed in Step S<b>4</b>, the display control unit <b>54</b> proceeds to Step <b>5</b> and displays the registered playback start positions by a list as shown in <figref idref="DRAWINGS">FIG. 3</figref> based on the playback position information supplied from the playback position information list management unit <b>53</b>. When the content of the playback target was selected by the user, in the playback position information list management unit <b>53</b>, playback position information concerning positions for the content of the playback target registered by the user is selected among playback position information registered in the playback position information list to be outputted to the display control unit <b>54</b>.</p>
<p id="p-0108" num="0107">In Step S<b>6</b>, the display control unit <b>54</b> judges whether a certain position has been selected from the presented playback start positions by the user or not, and waits until the display control unit <b>54</b> judges that the position has been selected.</p>
<p id="p-0109" num="0108">When the display control unit <b>54</b> judges that the certain position has been selected in the Step S<b>6</b>, the display control unit <b>54</b> proceeds to Step S<b>7</b>, reads out data of the content starting from the selected position from the contents storage unit <b>51</b>, and plays back the read-out data. Video of the played content is displayed at the display unit <b>11</b> and audio is outputted from the speaker.</p>
<p id="p-0110" num="0109">Next, processing of the portable playback device <b>2</b> will be explained with reference to a flowchart of <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0111" num="0110">The processing is started when, for example, a content having a prescribed format is transferred from the recording/playback device <b>1</b>.</p>
<p id="p-0112" num="0111">In Step S<b>11</b>, the transfer unit <b>61</b> of the portable playback device <b>2</b> acquires the content transferred from the recording/playback device <b>1</b>, and outputs the acquired content to the display control unit <b>62</b>.</p>
<p id="p-0113" num="0112">In Step S<b>12</b>, the display control unit <b>62</b> judges whether start of playback of the content has been instructed or not, and waits until the display control unit <b>62</b> judges that the start of playback has been instructed by the user.</p>
<p id="p-0114" num="0113">When the display control unit <b>62</b> judges that the start of playback has been instructed by the user in Step S<b>12</b>, the display control unit <b>62</b> proceeds to Step S<b>13</b>, starting playback of the content, for example, from the head thereof. Video of the played content is displayed at the display unit <b>21</b> and audio is outputted from the speaker and the like.</p>
<p id="p-0115" num="0114">In Step S<b>14</b>, the display control unit <b>62</b> judges whether registration of a playback start position has been instructed or not, and waits until the display control unit <b>62</b> judges that the registration has been instructed. The playback of the content is continued until the registration of the playback start position is instructed.</p>
<p id="p-0116" num="0115">When the display control unit <b>62</b> judges that the registration of the playback start position has been instructed by the user in Step S<b>14</b>, the display control unit <b>62</b> proceeds to Step S<b>15</b>, allows the playback of the content to be a pause state and displays a window used for the position registration as shown in <figref idref="DRAWINGS">FIG. 2</figref> at the display unit <b>21</b>.</p>
<p id="p-0117" num="0116">In Step S<b>16</b>, the playback position information generating unit <b>63</b> generates playback position information including information indicating a position designated by the user, an identification ID of the content, an identification ID set in the portable playback device <b>2</b> (user ID) and character strings inputted by the user, and outputs the generated playback position information to the playback position information list management unit <b>64</b> to be registered in the playback position information list.</p>
<p id="p-0118" num="0117">In Step S<b>17</b>, the display control unit <b>62</b> judges whether the playback of the content is finished or not, and repeats the processing from Step S<b>14</b> until the display control unit <b>62</b> judges the finish. When the display control unit <b>62</b> judges that the playback of the content is finished in Step S<b>17</b>, the process proceeds to Step S<b>18</b>.</p>
<p id="p-0119" num="0118">In Step S<b>18</b>, the transfer unit <b>61</b> judges whether transfer of the playback position information list to the recording/playback device <b>1</b> has been instructed by the user or not, and waits until the transfer unit <b>61</b> judges that the transfer has been instructed.</p>
<p id="p-0120" num="0119">When the transfer unit <b>61</b> judges that the transfer of the playback position information list to the recording/playback device <b>1</b> has been instructed by the user, the transfer unit <b>61</b> proceeds to Step S<b>19</b>, transfers the playback position information list managed by the playback position information list management unit <b>64</b> to the recording/playback device <b>1</b> and ends the processing.</p>
<p id="p-0121" num="0120">According to the above processing, the user can select a position from which the playback is started in the recording/playback device <b>1</b> by referring to positions registered when viewed the content using the portable playback device <b>2</b>.</p>
<p id="p-0122" num="0121">In the above description, the case that the content which can be viewed by the user using the portable playback device <b>2</b> and in which playback start positions can be registered is the content copied from the recording/playback device <b>1</b> has been explained, however, it is also preferable that the user registers playback start positions with respect to contents played back on the portable playback device <b>2</b> by streaming.</p>
<p id="p-0123" num="0122">In the above description, in the playback start position list displayed in the recording/playback device <b>1</b>, only thumbnail images, positions (for example, time or chapter information) and character strings are displayed as information for respective playback start positions, however, it is also preferable that various scene metadata other than the above are displayed. For example, in the case that the priority of the playback start position can be set at the time of registration of the playback start position, the set priority is displayed at the list as the scene metadata.</p>
<p id="p-0124" num="0123">It is also preferable that the identification ID of the user is displayed as scene metadata, and that, when the user registers his/her name in the portable playback device <b>2</b> and it is included in the playback position information, the name of the user is displayed as scene metadata.</p>
<p id="p-0125" num="0124">The playback start positions registered by the user are not only used for selecting a start position of the playback in the recording/playback device <b>1</b> but also used for the skip (index) after the playback is started. In this case, playback is performed from respective playback start positions registered by the user every time the user instructs the skip by operating the remote controller and the like.</p>
<p id="p-0126" num="0125">In the above description, playback position information registered in the playback position information list will be deleted in the recording/playback device <b>1</b> when the concerned content is deleted, however, it is preferable that the content is deleted when instructed by the user. Also in the portable playback device <b>2</b>, the content may be deleted in accordance with the instruction of the user or the deletion of the content.</p>
<p id="p-0127" num="0126">In the above description, the identification ID of the user included in the playback position information is the identification ID set in the portable playback device<b>2</b>, however, it is also preferable that other identification IDs are used. For example, in the case that it is necessary that information of the portable playback device <b>2</b> is registered in the recording/playback device <b>1</b> as information of a device for viewing the content before transferring the content, an identification ID generated by the recording/playback device <b>1</b> at the time of the initial registration is used as the identification ID of the user. In this case, the same identification ID generated by the recording/playback device <b>1</b> is managed both in the recording/playback device <b>1</b> and the portable playback device <b>2</b>, and the user using the portable playback device <b>2</b> is identified by the recording/playback device <b>1</b> based on the identification ID.</p>
<p id="p-0128" num="0127">It is also preferable that an identification ID is added to the content when the content is copied to the portable playback device <b>2</b>, and the added identification ID is used not only as the ID for identifying the content but also used as the ID for identifying the user.</p>
<p id="p-0129" num="0128">The above series of processing can be executed by hardware as well as executed by software. In the case that the series of the processing is executed by the software, programs included in the software are installed from a program storage medium to a computer incorporated in a dedicated hardware or, for example, a general-purpose computer which can execute various functions by installing various programs.</p>
<p id="p-0130" num="0129"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram showing an example of a configuration of a personal computer which executes the above series of processing by programs.</p>
<p id="p-0131" num="0130">A CPU (Central Processing Unit) <b>101</b> executes various processing in accordance with programs stored in a ROM (Read Only Memory) <b>102</b>, or a storage unit <b>108</b>. In a RAM (Random Access Memory) <b>103</b>, programs executed by the CPU <b>101</b> and data and the like are suitably stored. The CPU <b>101</b>, the ROM <b>102</b> and the RAM <b>103</b> are connected to one another by a bus <b>104</b>.</p>
<p id="p-0132" num="0131">An input/output interface <b>105</b> is connected to the CPU <b>101</b> through the bus <b>104</b>. To the input/output interface <b>105</b>, an input unit <b>106</b> including a keyboard, a mouse, a microphone and the like and an output unit <b>107</b> including a display, a speaker and the like are connected. The CPU <b>101</b> executes various processing in accordance with instructions inputted from the input unit <b>106</b>. Then, the CPU <b>101</b> outputs results of processing to the output unit <b>107</b>.</p>
<p id="p-0133" num="0132">The storage unit <b>108</b> connected to the input/output interface <b>105</b> includes, for example, a hard disc, which stores programs executed by the CPU <b>101</b> or various data. The communication unit <b>109</b> communicates with external apparatuses through networks such as Internet or local area networks.</p>
<p id="p-0134" num="0133">A drive <b>110</b> connected to the input/output interface <b>105</b>, when removal media <b>111</b> such as a magnetic disc, an optical disc, an optical magnetic disc or a semiconductor memory are mounted, drives them and acquires programs or data stored therein. The acquired programs or data are transferred to the storage unit <b>108</b> if necessary to be stored therein.</p>
<p id="p-0135" num="0134">The program storage media installed in the computer and storing programs which are activated by the computer includes the removal media <b>111</b> as package media such as the magnetic disc (including a flexible disc), the optical disc (including a CD-ROM (Compact Disc-Read Only Memory), a DVD (Digital Versatile Disc), the optical magnetic disc, or the semiconductor memory and the like, the ROM <b>102</b> in which programs are stored temporally or permanently, and the hard disc included in the storage unit <b>108</b>. The storage of programs to the program storage media is performed by utilizing wired or wireless communication media such as local area networks, Internet or digital satellite broadcasting through the communication unit <b>109</b> which is an interface such as a router or a modem, according to need.</p>
<p id="p-0136" num="0135">In the specification, steps describing programs includes not only processes performed in time series along the described order but also includes processes not always processed in time series but executed in parallel or individually.</p>
<p id="p-0137" num="0136">In the specification, the system means the whole apparatus including plural devices.</p>
<p id="p-0138" num="0137">It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An information processing system comprising:
<claim-text>a recording/playback apparatus; and</claim-text>
<claim-text>a playback terminal,</claim-text>
<claim-text>wherein the recording/playback apparatus includes</claim-text>
<claim-text>an output unit to output a content to the playback terminal,</claim-text>
<claim-text>a management unit to manage a list received from the playback terminal, the list including position information designated at the playback terminal during playback of the content to identify content positions and identification information identifying a user of the playback terminal, the information identifying the user being set in the playback terminal by the user, and</claim-text>
<claim-text>a playback unit to present specific information of the content at respective positions indicated by the position information and the identification information registered in the list, the playback unit playing back the content from a selected position, and</claim-text>
<claim-text>wherein the playback terminal includes</claim-text>
<claim-text>a playback unit to play back the content outputted from the recording/playback apparatus,</claim-text>
<claim-text>a generating unit to generate the position information based on a current content position and a predetermined time offset and to register, in the list, the position information in association with the identification information of the user, and</claim-text>
<claim-text>an output unit to output the list, in which a plurality of position information generated by the generating unit is registered, to the recording/playback apparatus,</claim-text>
<claim-text>wherein the playback unit overlays a menu on the content being played back, the menu including the predetermined time offset in a drop-down menu, and</claim-text>
<claim-text>the generating unit generates the position information in response to selection of the predetermined time offset from the drop-down menu in the menu overlaid on the content being played back.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The information processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the identification information of the playback terminal identifies the user.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The information processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the identification information of the playback terminal is generated by the recording/playback apparatus and transmitted to the playback terminal.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The information processing system according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the playback terminal is registered in the recording/playback apparatus prior to output of the content to the playback terminal, the identification information being transmitted to the playback terminal after registration.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The information processing system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the recording/playback apparatus inserts the identification information of the playback terminal prior to outputting the content to the playback terminal.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A recording/playback apparatus, comprising:
<claim-text>an output unit to output a content to a playback terminal;</claim-text>
<claim-text>a management unit to manage a list received from the playback terminal and including position information indicating content positions designated at the playback terminal during playback of the content, based on a predetermined time offset selected from a drop-down menu included in a menu overlaid on the content being played back at the terminal, and identification information of a user of the playback terminal, the information identifying the user being set in the playback terminal by the user; and</claim-text>
<claim-text>a playback unit to present specific information of the content at respective positions indicated by the position information and the identification information registered in the list, the playback unit playing back the content from a selected position.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The recording/playback apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the playback unit presents at least images of the content and time information at respective positions as the specific information.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The recording/playback apparatus according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein, when user comments inputted in the playback terminal when designating positions of the content are included in the list, the playback unit further represents the comments as the specific information in addition to images of the content and time information at respective positions.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. An information processing method, comprising:
<claim-text>outputting a content to a playback terminal;</claim-text>
<claim-text>managing a list received from the playback terminal, the list including position information indicating content positions designated at the playback terminal during playback of the content, based on a predetermined time offset selected from a drop-down menu included in a menu overlaid on the content being played back at the terminal, and identification information of a user of the playback terminal, the identification information of the user being set in the playback terminal by the user;</claim-text>
<claim-text>presenting specific information of the content at respective positions indicated by the position information and the identification information registered in the list; and</claim-text>
<claim-text>playing back the content from a selected position.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The information processing method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein, in the playback step, at least images of the content and time information at respective positions are presented as the specific information.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The information processing method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:
<claim-text>when user comments inputted in the playback terminal when designating positions of the content are included in the list, representing the comments as the specific information in addition to images of the content and time information at respective positions.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A non-transitory computer-readable medium storing computer-readable instructions thereon, the computer-readable instructions when executed by a processor cause the processor to perform a method comprising:
<claim-text>outputting a content to a playback terminal,</claim-text>
<claim-text>managing a list received from the playback terminal, the list including position information indicating content positions designated from a drop-down menu included in a menu overlaid on the content being played back at the playback terminal during playback of the content, based on a predetermined time offset selected at the terminal, and identification information of a user of the playback terminal, the identification information of the user being set in the playback terminal by the user;</claim-text>
<claim-text>presenting specific information of the content at respective positions indicated by the position information and the identification information registered in the list; and</claim-text>
<claim-text>playing back the content from a selected position.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A playback terminal, comprising:
<claim-text>a playback unit to play back a content outputted from a recording/playback apparatus;</claim-text>
<claim-text>a generating unit to generate position information indicating positions in the content designated at the playback terminal during playback of the content, based on a predetermined time offset, and to register, in a list, the position information in association with identification information of a user of the playback terminal, the identification information of the user being set in the playback terminal by the user; and</claim-text>
<claim-text>an output unit to output the list, in which a plurality of position information generated by the generating unit is registered, to the recording/playback apparatus,</claim-text>
<claim-text>wherein the playback unit overlays a menu on the content being played back, the menu including the predetermined time offset in a drop-down menu, and</claim-text>
<claim-text>the generating unit generates the position information in response to selection of the predetermined time offset from the drop-down menu in the menu overlaid on the content being played back.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The playback terminal according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the generating unit, when position registration is instructed during the playback of the content, presents a user interface including the predetermined time offsets for selection by the user, and generates the position information from a current position in the content and a selected predetermined time offset.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The playback terminal according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the generating unit generates user comments inputted when designating positions of the content.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The playback terminal according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the predetermined time offset includes one of 10 second before the current position of the content and 20 second before the current position of the content.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. An information processing method comprising:
<claim-text>playing back a content outputted from a recording/playback apparatus;</claim-text>
<claim-text>generating position information indicating positions of the content designated at a playback terminal during the playback of the content, based on a predetermined time offset, and identification information of a user of the playback terminal, the identification information of the user being set in the playback terminal by the user;</claim-text>
<claim-text>registering the position information and the identification information in a list; and</claim-text>
<claim-text>outputting the list, in which a plurality of position information is registered, to the recording/playback apparatus,</claim-text>
<claim-text>wherein a menu is overlaid on the content being played back, the menu including the predetermined time offset in a drop-down menu, and</claim-text>
<claim-text>the position information is generated in response to selection of the predetermined time offset from the drop-down menu in the menu overlaid on the content being played back.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The information processing method according to <claim-ref idref="CLM-00017">claim 17</claim-ref> further comprising:
<claim-text>when position registration is instructed during the playback of the content, presenting a user interface including the predetermined time offsets for selection by the user; and</claim-text>
<claim-text>generating the position information based on a current position in the content and a selected predetermined time offset.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The information processing method according to <claim-ref idref="CLM-00017">claim 17</claim-ref> further comprising:
<claim-text>generating information including comments inputted by the user when designating positions of the content.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A non-transitory computer-readable medium storing computer-readable instructions thereon, the computer readable instructions, when executed by a processor cause the processor to perform a method comprising:
<claim-text>playing back a content outputted from a recording/playback apparatus;</claim-text>
<claim-text>generating position information indicating positions of the content designated at a playback terminal during the playback of the content, based on a predetermined time offset, and identification information of a user of the playback terminal, the identification information of the user being set in the playback terminal by the user;</claim-text>
<claim-text>registering the position information and the identification information in a list; and</claim-text>
<claim-text>outputting the list, in which a plurality of position information is registered, to the recording/playback apparatus,</claim-text>
<claim-text>wherein a menu is overlaid on the content being played back, the menu including the predetermined time offset in a drop-down menu, and</claim-text>
<claim-text>the position information is generated in response to selection of the predetermined time offset from the drop-down menu in the menu overlaid on the content being played back. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
