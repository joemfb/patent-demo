<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625845-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625845</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12706206</doc-number>
<date>20100216</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>736</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382103</main-classification>
</classification-national>
<invention-title id="d2e53">Overlaying virtual content onto video stream of people within venue based on analysis of the people within the video stream</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5959717</doc-number>
<kind>A</kind>
<name>Chaum</name>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>352 40</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6400374</doc-number>
<kind>B2</kind>
<name>Lanier</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345630</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6508553</doc-number>
<kind>B2</kind>
<name>Gao et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>351227</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6634754</doc-number>
<kind>B2</kind>
<name>Fukuma et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>351227</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7027101</doc-number>
<kind>B1</kind>
<name>Sloo et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348564</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7259747</doc-number>
<kind>B2</kind>
<name>Bell</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7348963</doc-number>
<kind>B2</kind>
<name>Bell</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7528890</doc-number>
<kind>B2</kind>
<name>Staker et al.</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7536032</doc-number>
<kind>B2</kind>
<name>Bell</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7646434</doc-number>
<kind>B2</kind>
<name>Staker et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7649571</doc-number>
<kind>B2</kind>
<name>Staker et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7710391</doc-number>
<kind>B2</kind>
<name>Bell et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>7809167</doc-number>
<kind>B2</kind>
<name>Bell</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>7834846</doc-number>
<kind>B1</kind>
<name>Bell</name>
<date>20101100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>RE42205</doc-number>
<kind>E</kind>
<name>Jung et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382103</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>8035612</doc-number>
<kind>B2</kind>
<name>Bell et al.</name>
<date>20111000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>8035614</doc-number>
<kind>B2</kind>
<name>Bell et al.</name>
<date>20111000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>8035624</doc-number>
<kind>B2</kind>
<name>Bell et al.</name>
<date>20111000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>8081822</doc-number>
<kind>B1</kind>
<name>Bell</name>
<date>20111200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>8098277</doc-number>
<kind>B1</kind>
<name>Bell</name>
<date>20120100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>8135724</doc-number>
<kind>B2</kind>
<name>Smyers</name>
<date>20120300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>8159682</doc-number>
<kind>B2</kind>
<name>Bell</name>
<date>20120400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>8199108</doc-number>
<kind>B2</kind>
<name>Bell</name>
<date>20120600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>8230367</doc-number>
<kind>B2</kind>
<name>Bell et al.</name>
<date>20120700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>8259163</doc-number>
<kind>B2</kind>
<name>Bell</name>
<date>20120900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2002/0073417</doc-number>
<kind>A1</kind>
<name>Kondo et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 10</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2002/0186221</doc-number>
<kind>A1</kind>
<name>Bell</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2004/0194128</doc-number>
<kind>A1</kind>
<name>McIntyre et al.</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 32</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2004/0218100</doc-number>
<kind>A1</kind>
<name>Staker et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2005/0011964</doc-number>
<kind>A1</kind>
<name>Greenlee</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2006/0136979</doc-number>
<kind>A1</kind>
<name>Staker et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2009/0040385</doc-number>
<kind>A1</kind>
<name>Staker et al.</name>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2009/0041422</doc-number>
<kind>A1</kind>
<name>Staker et al.</name>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2009/0237565</doc-number>
<kind>A1</kind>
<name>Staker et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>2009/0237566</doc-number>
<kind>A1</kind>
<name>Staker et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>2010/0027961</doc-number>
<kind>A1</kind>
<name>Gentile et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>2010/0031149</doc-number>
<kind>A1</kind>
<name>Gentile et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>2010/0035682</doc-number>
<kind>A1</kind>
<name>Gentile et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>2010/0039500</doc-number>
<kind>A1</kind>
<name>Bell et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>2010/0060722</doc-number>
<kind>A1</kind>
<name>Bell</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>2010/0121866</doc-number>
<kind>A1</kind>
<name>Bell et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>28</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382103</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11460981</doc-number>
<date>20060729</date>
</document-id>
<parent-status>ABANDONED</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12706206</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60705746</doc-number>
<date>20050806</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100142928</doc-number>
<kind>A1</kind>
<date>20100610</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Rohde</last-name>
<first-name>Mitchell M.</first-name>
<address>
<city>Saline</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Rohde</last-name>
<first-name>Mitchell M.</first-name>
<address>
<city>Saline</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Dryja</last-name>
<first-name>Michael</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Quantum Signal, LLC</orgname>
<role>02</role>
<address>
<city>Ann Arbor</city>
<state>MI</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lu</last-name>
<first-name>Tom Y</first-name>
<department>2667</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A video stream of people within a venue like a movie theater is received. The people within the video stream are analyzed. Based on analysis of the people within the video stream, virtual content is overlaid onto the video stream. The video stream, with the virtual content overlaid thereon, is then displayed onto a screen within the venue. As such, the virtual content and one or more of the people within the venue can appear to be interacting with one another as if the virtual content were real and present within the venue.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="139.11mm" wi="138.43mm" file="US08625845-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="226.99mm" wi="178.39mm" orientation="landscape" file="US08625845-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="243.59mm" wi="177.46mm" orientation="landscape" file="US08625845-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="253.41mm" wi="197.02mm" orientation="landscape" file="US08625845-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="251.97mm" wi="186.77mm" orientation="landscape" file="US08625845-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="250.95mm" wi="182.37mm" orientation="landscape" file="US08625845-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="239.18mm" wi="173.48mm" orientation="landscape" file="US08625845-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="173.99mm" wi="180.85mm" file="US08625845-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="170.60mm" wi="178.39mm" file="US08625845-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="246.04mm" wi="171.11mm" file="US08625845-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present patent application is a continuation-in-part of the previously filed patent application entitled &#x201c;Interactive, video-based content for theaters,&#x201d; filed on Jul. 29, 2006, and assigned Ser. No. 11/460,981, and which claims the benefit of the previously filed provisional patent application having the same title, filed on Aug. 6, 2005, and assigned Ser. No. 60/705,746. The content of these two patent applications is hereby incorporated into the present patent application by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Patrons of a movie theater typically arrive some time before the show time of a movie to which they bought tickets. During this time, they may buy concessions, and then settle into their seats in the movie theater, waiting for the movie to start. Movie theaters have tried to engage their customers during this time, by showing advertisements on the screen, and so on. However, many customers tune out these advertisements, reducing their effectiveness. Furthermore, younger patrons in particular can become bored, and start doing things that the movie theatres would prefer they not, such as causing problems with other patrons, raising their voices too much, and so on.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0004" num="0003">The present invention overlays virtual content onto a video stream of the people within a movie theater, based on an analysis of the people within the video stream. In one embodiment, a video stream of the people within a movie theater is received. A processor of a computing device analyzes the people within the video stream, and overlays virtual content onto the video stream based on this analysis. The video stream, with the virtual content overlaid thereon, is displayed on a screen within the movie theater. For instance, the virtual content and one or more of the people may appear to be interacting with one another, as if the virtual content were real and present within the movie theater.</p>
<p id="p-0005" num="0004">The virtual content may include advertisements, such as logos of businesses. Because of the interactive nature of the virtual content, the patrons within the movie theater are less likely to tune out the virtual content, increasing the effectiveness of the advertisements. The virtual content may also engage patrons that would otherwise become bored, reducing the likelihood that the patrons start partaking in conduct that the movie theatres would prefer they not do. Still other advantages, aspects, and embodiments of the invention will become apparent by reading the detailed description that follows, and by referring to the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0006" num="0005">The drawings referenced herein form a part of the specification. Features shown in the drawing are meant as illustrative of only some embodiments of the invention, and not of all embodiments of the invention, unless explicitly indicated, and implications to the contrary are otherwise not to be made.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of a movie theater, according to an embodiment of the invention.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIGS. 2-6</figref> are diagrams of examples of virtual content that may be overlaid onto a video stream of people within a movie theater, according to an embodiment of the invention.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram of a system, according to an embodiment of the invention.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart of a method, according to an embodiment of the invention.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of a method, according to another embodiment of the invention.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 10</figref> is a diagram of an example of a first video stream integrated within a second video stream, according to an embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0013" num="0012">In the following detailed description of exemplary embodiments of the invention, reference is made to the accompanying drawings that form a part hereof, and in which is shown by way of illustration specific exemplary embodiments in which the invention may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice the invention. Other embodiments may be utilized, and logical, mechanical, and other changes may be made without departing from the spirit or scope of the present invention. The following detailed description is, therefore, not to be taken in a limiting sense, and the scope of the present invention is defined only by the appended claims.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1</figref> shows a representative movie theater <b>100</b>, according to an embodiment of the invention. The movie theater <b>100</b> is more generally a venue. A number of people <b>102</b> are seated within the movie theater <b>100</b> towards a screen <b>106</b>. A projector <b>104</b> projects a video stream onto the screen <b>106</b>, for viewing by the people <b>102</b>. A video camera <b>108</b> records or generates a video stream of the people <b>102</b>.</p>
<p id="p-0015" num="0014">In general, the video stream of the people <b>102</b> recorded or generated by the video camera <b>108</b> is analyzed, and virtual content is overlaid onto the video stream based on this analysis. The projector <b>104</b> then displays the video stream of the people <b>102</b>, within which the virtual content has been overlaid, onto the screen <b>106</b>. This process occurs in real time or in near-real time.</p>
<p id="p-0016" num="0015">There may be more than one video camera <b>108</b>. For instance, more than one video camera <b>108</b> may be used to provide for better coverage of the people <b>102</b> within the theater <b>100</b>, as well as different types of coverage of the people <b>102</b> within the theater <b>100</b>. As examples of the latter, stereo and time-of-flight video cameras may be employed.</p>
<p id="p-0017" num="0016">Different examples of such virtual content, according to different embodiments of the invention, are now described. The present invention, however, is not limited to these examples. Other embodiments of the invention may employ other types of virtual content, in addition to and/or in lieu of those described herein. In some embodiments, the virtual content is overlaid so that it appears one or more of the people within the movie theater are interacting with the virtual content as if the virtual content were real and present within the theater.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> shows an example of virtual content overlaid onto a video stream <b>200</b> of the people <b>102</b> in a movie theater, according to an embodiment of the invention. The video stream <b>200</b> is displayed on the screen <b>106</b>. The video stream <b>200</b> is of the people <b>102</b> seated in the movie theater.</p>
<p id="p-0019" num="0018">A virtual object <b>202</b> has been overlaid onto the video stream <b>200</b>. That is, the virtual object <b>202</b> does not actually exist in the movie theater, but rather is overlaid onto the video stream <b>200</b> in <figref idref="DRAWINGS">FIG. 2</figref>. The virtual object <b>202</b> is a moving object, and has motion to approximate or mirror that of a real physical object, like an inflated beach ball.</p>
<p id="p-0020" num="0019">When the virtual object <b>202</b> is first overlaid onto the video stream <b>200</b>, it may movie as if it had dropped from the ceiling of the movie theater. The video stream <b>200</b> is analyzed to detect which person is close to the virtual object <b>202</b>, and to detect motion of this person. The motion of the virtual object <b>202</b> as overlaid onto the video stream <b>200</b> is then changed as if the virtual object <b>202</b> were real, and this person were interacting with the virtual object <b>202</b>.</p>
<p id="p-0021" num="0020">For example, as specifically depicted in <figref idref="DRAWINGS">FIG. 2</figref>, the person <b>204</b> is raising his or her hands to hit the virtual object <b>202</b>. As such, the motion of the virtual object <b>202</b> as overlaid onto the video stream <b>200</b> will change so that it appears the object <b>202</b> has bounced off or has been hit by the person <b>204</b>. In this respect, the virtual object <b>202</b> and the person <b>204</b> appear to be interacting with one another, as if the virtual object <b>202</b> were real and present within the movie theater.</p>
<p id="p-0022" num="0021">The virtual object <b>202</b> may have a logo of a business, or an advertisement, on it. Therefore, while the people <b>102</b> are having fun playing with a virtual beach ball, for instance (i.e., interacting with the virtual content), they are more likely to continue watching the video stream <b>200</b> displayed on the screen <b>106</b>, and thus more likely to view the logo or the advertisement, instead of not concentrating on the screen <b>106</b>. The invention thus advantageously entertains the people <b>102</b> while they are waiting for a movie to start, while potentially providing increased advertising revenue to the movie theater.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 3</figref> shows an example of virtual content overlaid onto a video stream <b>300</b> of the people <b>102</b> in a movie theater, according to a second embodiment of the invention. The video stream <b>300</b> is displayed on the screen <b>106</b>. The video stream <b>300</b> is of the people <b>102</b> seated in the movie theater.</p>
<p id="p-0024" num="0023">A virtual object <b>302</b> has been overlaid onto the video stream <b>300</b>. That is, the virtual object <b>302</b> does not actually exist in the movie theater, but rather is overlaid onto the video stream <b>300</b> in <figref idref="DRAWINGS">FIG. 3</figref>. The virtual object <b>302</b> is a ribbon or a rainbow, that starts from the top of the video stream <b>300</b> and lengthens and extends downward. The video stream <b>300</b> is analyzed to detect which person is close to the virtual object <b>302</b>, and to detect motion of this person to see if he or she is trying to catch the object <b>302</b>. If this person does not appear to be trying to catch the virtual object <b>302</b>, then the object <b>302</b> continues to length and extend downwards towards the bottom of the video stream <b>300</b>.</p>
<p id="p-0025" num="0024">For example, as specifically depicted in <figref idref="DRAWINGS">FIG. 3</figref>, the person <b>304</b> is raising his or her hands so that it appears the person <b>304</b> has caught the virtual object <b>302</b>. Once the person <b>304</b> has caught the virtual object <b>302</b>, the virtual object <b>302</b> may disappear, and words like &#x201c;good job&#x201d; or &#x201c;nice catch&#x201d; virtually displayed on the video stream <b>300</b> near the person <b>304</b>. In this respect, the virtual object <b>302</b> and the person <b>304</b> appear to be interacting with one another, as if the virtual object <b>302</b> were real and present within the movie theater.</p>
<p id="p-0026" num="0025">The virtual object <b>302</b> may also have a logo of a business, or an advertisement, on it. Therefore, while the people <b>102</b> are having fun catching virtual ribbons or rainbows, for instance (i.e., interacting with the virtual content), they are more likely to continue watching the video stream <b>300</b> displayed on the screen <b>106</b>, and thus more likely to view the logo or the advertisement, instead of not concentrating on the screen. The invention thus advantageously entertains the people <b>102</b> while they are waiting for a movie to start, while potentially providing increased advertising revenue to the movie theater.</p>
<p id="p-0027" num="0026">The embodiments of <figref idref="DRAWINGS">FIGS. 2 and 3</figref>, among other embodiments of the invention, are examples of games. In these games, the people within the video stream are analyzed, and virtual content overlaid onto the video stream, to result in one or more of the people playing games in relation to the virtual content. In <figref idref="DRAWINGS">FIG. 2</figref>, the game is to hit a virtual beach ball, whereas in <figref idref="DRAWINGS">FIG. 3</figref>, the game is to catch a virtual ribbon or rainbow.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 4</figref> shows an example of virtual content overlaid onto a video stream <b>400</b> of the people <b>102</b> in a movie theater, according to a third embodiment of the invention. The video stream <b>400</b> is displayed on the screen <b>106</b>. The video stream <b>400</b> is of the people <b>102</b> seated in the movie theater.</p>
<p id="p-0029" num="0028">A virtual object <b>402</b> has been overlaid onto the video stream <b>400</b>. That is, the virtual object <b>402</b> does not actually exist in the movie theater, but rather is overlaid onto the video stream <b>400</b> in <figref idref="DRAWINGS">FIG. 4</figref>. The virtual object <b>402</b> is a divider, which logically divides the people <b>102</b> into two groups, a left group and a right group.</p>
<p id="p-0030" num="0029">Virtual text <b>404</b> also is overlaid onto the video stream <b>400</b>. The text <b>404</b> is a trivia question or a poll question. The people <b>102</b> are requested to wave their hands when the choice they want to select is virtually displayed on the video stream <b>400</b> projected onto the screen <b>106</b>. After each choice is virtually displayed, the motion of the people within the video stream <b>400</b> is detected. In the example specifically depicted in <figref idref="DRAWINGS">FIG. 4</figref>, the people <b>102</b> have been logically divided into groups on either side of the virtual object <b>402</b>, and are asked via the virtual text <b>404</b> to wave their hands when the correct answer to a movie trivia question is shown.</p>
<p id="p-0031" num="0030">Once all the choices have been virtually displayed, in the case of a trivia question, it is determined which choice each group of the people <b>102</b> selected by virtue of their detected motion. The correct choice may then be virtually displayed, along with which group or groups of the people <b>102</b>, if any, selected the correct choice. There may be a number of such trivia questions. As such, the groups of the people <b>102</b> are playing a trivia game against each other.</p>
<p id="p-0032" num="0031">In the case of a poll, once all the choices have been virtually displayed, the top choice selected by each group of the people <b>102</b> by virtue of their detected motion is determined. The top choice for each group may then be virtually displayed. For instance, virtual text may be overlaid onto the video stream <b>400</b> that says &#x201c;you guys prefer soft drink A, while you guys prefer soft drink B,&#x201d; and so on. There may be a number of such poll questions.</p>
<p id="p-0033" num="0032">In the embodiment represented by <figref idref="DRAWINGS">FIG. 4</figref>, then, the people <b>102</b> within the video stream <b>400</b> are analyzed, and the virtual content <b>402</b> and <b>404</b> overlaid onto the video stream <b>400</b>, to result in one or more of the people <b>102</b> answering a question. Analyzing the people <b>102</b> within the video stream <b>400</b> in this embodiment encompasses logically dividing the people <b>102</b> into a number of groups and detecting motion of the people <b>102</b> within each group. The virtual content is ultimately overlaid onto the video stream <b>400</b> based on the motions of the people <b>102</b> within the groups&#x2014;such as which group answered which trivia questions correctly, and so on.</p>
<p id="p-0034" num="0033">The embodiment of <figref idref="DRAWINGS">FIG. 4</figref> may also be a game that is played by the people <b>102</b> before the movie starts. The virtual object <b>402</b>, the virtual text <b>404</b>, and/or other virtual objects may include logos of businesses, or advertisements. Therefore, while the people <b>102</b> are having fun answering poll or trivia questions, for instance (i.e., interacting with the virtual content), they are more likely to continue watching the video stream <b>400</b> displayed on the screen <b>106</b>, and thus more likely to view the logos or the advertisements. The invention thus advantageously entertains the people <b>102</b> while they are waiting for a movie to start, while potentially providing increased advertising revenue to the theater.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 5</figref> shows an example of virtual content overlaid onto a video stream <b>500</b> of the people <b>102</b> in a movie theater, according to a fourth embodiment of the invention. The video stream <b>500</b> is displayed on the screen <b>106</b>. The video stream <b>500</b> is of the people <b>102</b> seated in the movie theater.</p>
<p id="p-0036" num="0035">A virtual character <b>504</b> has been overlaid onto an empty seat <b>502</b> in the video stream <b>500</b>. The virtual character <b>504</b> does not actually exist and is not present in the movie theater, but rather is overlaid onto the video stream <b>500</b> in <figref idref="DRAWINGS">FIG. 5</figref>. In the example of <figref idref="DRAWINGS">FIG. 5</figref>, for instance, the virtual character <b>504</b> is a one-eye alien, such as a Cyclops. Thus, the virtual character <b>504</b> appears to be sitting in the empty seat <b>502</b> as if the character <b>504</b> were real and present within the movie theater. Analyzing the video stream <b>500</b> therefore includes locating an empty seat within the movie theater onto which to overlay the virtual character <b>504</b>.</p>
<p id="p-0037" num="0036">The virtual character <b>504</b> may be overlaid in conjunction with an advertisement. For example, the virtual text <b>506</b> may be a teaser advertisement associated with a movie to be released in the future. As a way to increase interest in the movie, the virtual character <b>504</b> is overlaid onto the video stream <b>500</b>. The invention thus advantageously entertains the people <b>102</b> while they are waiting for a movie to start, and increasing interest in the advertisement with which the virtual text <b>506</b> is associated, by overlaying the virtual character <b>504</b> onto the video stream <b>500</b>.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 6</figref> shows an example of virtual content overlaid onto a video stream <b>600</b> of the people <b>102</b> in a movie theater, according to a fifth embodiment of the invention. The video stream <b>600</b> is displayed on the screen <b>106</b>. The video stream <b>600</b> is of the people <b>102</b> seated in the movie theater.</p>
<p id="p-0039" num="0038">A virtual object <b>604</b> has been overlaid onto the video stream <b>600</b>. The virtual object <b>604</b> is a large arrow, which draws or calls attention to an actual and real given person <b>602</b> seated in the movie theater. Analyzing the video stream <b>600</b> therefore includes locating and selecting a person, such as randomly, within the movie theater. Virtual text <b>606</b> may also be overlaid onto the video stream <b>600</b>, to describe the person selected, such as &#x201c;smart guy!&#x201d; in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0040" num="0039">The invention thus advantageously entertains the people <b>102</b> while they are waiting for a movie to start. If there is additional text overlaid onto the video stream <b>600</b> associated with an advertisement or a logo of a business, the virtual object <b>604</b> and the virtual text <b>606</b> increases the likelihood that the people <b>102</b> will view and see the advertisement or logo. That is, the virtual object <b>604</b> is attending to draw interested of the people <b>102</b> to watch the screen <b>106</b> even before the movie starts.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 7</figref> shows a system <b>700</b>, according to an embodiment of the invention. The system <b>700</b> includes the video camera <b>108</b> and a computing device <b>704</b>. The system <b>700</b> can also include one or more lights <b>712</b> to illuminate the people within the movie theater or other venue, and the projector <b>104</b>. The video camera <b>108</b> generates a video stream <b>702</b> of the people within the movie theater or other venue.</p>
<p id="p-0042" num="0041">The computing device <b>704</b> receives the video stream <b>702</b>. The computing device <b>704</b> includes at least a processor <b>706</b> and a computer-readable storage medium <b>708</b>, such as semiconductor memory and/or a hard disk drive. The computing device <b>704</b> can and typically does include other components. The computer-readable storage medium <b>708</b> stores a computer program <b>710</b> that is executed by the processor <b>706</b>.</p>
<p id="p-0043" num="0042">The computer program <b>710</b>, when executed by the processor <b>706</b>, analyzes the people within the video stream <b>702</b>, and based on this analysis, overlays virtual content onto the video stream <b>702</b>, to result in a video stream <b>702</b>&#x2032; that has virtual content overlaid thereon. Examples of such virtual content have been described above. The computer program <b>710</b> transmits the video stream <b>702</b>&#x2032; to the projector <b>104</b>, which displays the video stream <b>702</b>&#x2032; on a screen within the movie theater or other venue.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 8</figref> shows a method <b>800</b>, according to an embodiment of the invention. The method <b>800</b> can be performed as a result of execution of the computer program <b>710</b> stored on the computer-readable storage medium <b>708</b>, by the processor <b>706</b>. The video stream <b>702</b> of the people within a movie theater or other venue is received (<b>802</b>), as generated or recorded by the video camera <b>108</b>.</p>
<p id="p-0045" num="0044">The people within the video stream <b>702</b> are analyzed (<b>804</b>). Such analysis is performed by performing appropriate image processing and/or computer vision techniques, as can be appreciated by those of ordinary skill within the art. For instance, the locations of the people within the video stream <b>702</b> may be determined, the motion of the people within the stream <b>702</b> may be detected, the outlines or contours of the people within the stream <b>702</b> may be detected, and so on. As another example, the various body parts of the people, such as their faces, hands, and other parts, may be detected and tracked within the video stream <b>702</b>.</p>
<p id="p-0046" num="0045">Virtual content is then overlaid onto the video stream <b>702</b>, based on the analysis of the people that has been performed (<b>806</b>). Static or animated virtual content, such as borders, graphics, and so on, may be synthesized based on the location, motion, and/or action of the people within the video stream <b>702</b>, as can be appreciated by those of ordinary skill within the art. The video stream <b>702</b> may be used in whole or in part with the overlaid content. The resulting video stream <b>702</b>&#x2032;, with the virtual content overlaid thereon, is then displayed, or caused to be displayed, on a screen within the movie theater or other venue (<b>808</b>).</p>
<p id="p-0047" num="0046">It is noted that, although specific embodiments have been illustrated and described herein, it will be appreciated by those of ordinary skill in the art that any arrangement that is calculated to achieve the same purpose may be substituted for the specific embodiments shown. Other applications and uses of embodiments of the invention, besides those described herein, are amenable to at least some embodiments. This application is intended to cover any adaptations or variations of the present invention. Therefore, it is manifestly intended that this invention be limited only by the claims and equivalents thereof.</p>
<p id="p-0048" num="0047">For example, <figref idref="DRAWINGS">FIG. 9</figref> shows a method <b>900</b>, according to another embodiment of the invention. Like the method <b>800</b> of <figref idref="DRAWINGS">FIG. 8</figref>, the method <b>900</b> can be performed as a result of execution of the computer program <b>710</b> stored on the computer-readable storage medium <b>708</b>, by the processor <b>706</b>. The (first) video stream <b>702</b> of the people within a movie theater or other venue is received (<b>902</b>), as generated or recorded by the video camera <b>108</b>.</p>
<p id="p-0049" num="0048">The people within the (first) video stream <b>702</b> are analyzed (<b>904</b>). Such analysis is performed by performing appropriate image processing and/or computer vision techniques, as can be appreciated by those of ordinary skill within the art. For instance, the locations of the people within the video stream <b>702</b> may be determined, the motion of the people within the stream <b>702</b> may be detected, the outlines or contours of the people within the stream <b>702</b> may be detected, and so on. As another example, the various body parts of the people, such as their faces, hands, and other parts, may be detected and tracked within the video stream <b>702</b>.</p>
<p id="p-0050" num="0049">A portion of the (first) video stream <b>702</b> is integrated within another (second) video stream, based on the analysis of the people that has been performed (<b>906</b>). For example, at least a part of one person within the (first) video stream <b>702</b> may be integrated within the second video stream. The second video stream, with the portion of the (first) video stream <b>702</b> integrated therein, is then displayed, or caused to be displayed, on a screen within the movie theater or other venue (<b>908</b>).</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 10</figref> shows an example of a (second) video stream <b>1000</b> with a portion of a (first) video stream <b>1002</b> integrated therein, according to an embodiment of the invention. The video stream <b>1000</b> with the portion of the video stream <b>1002</b> integrated therein is displayed on the screen <b>106</b>. The portion of the video stream <b>1002</b> is the head of a person seated in the movie theater in which the screen <b>106</b> is located. By comparison, the video stream <b>1000</b> is a promotional trailer for a movie.</p>
<p id="p-0052" num="0051">Therefore, the head of a person seated in the movie theater is transposed onto the body <b>1004</b> within the promotional trailer for a movie. The purpose is to increase the audience's attention of the promotional trailer, by substituting the head of the actor within the promotional trailer for the head of a person seated in the movie theater. This may be done to comedic effect, as well. In the example of <figref idref="DRAWINGS">FIG. 10</figref>, for instance, the body <b>1004</b> is that of a bodybuilder, whereas the audience member within the video stream <b>1002</b> having the head that is transposed onto the body <b>1004</b> may not be a bodybuilder at all.</p>
<p id="p-0053" num="0052">In general, then, this example shows how in one embodiment, a portion of the video stream of the people within a venue may be integrated with another video stream, such as that of a promotional trailer for a movie. The portion of the video stream of the people within a venue may be a static image in one embodiment. As depicted in the example of <figref idref="DRAWINGS">FIG. 10</figref>, the head of a member of the audience in a movie theater is transposed onto the body of an actor within a promotional trailer for a movie.</p>
<p id="p-0054" num="0053">This embodiment of course encompasses other examples as well. As just one example, the promotional trailer for a movie may involve the primary actors sitting in a room with a number of secondary actors, known as &#x201c;extras,&#x201d; sitting in the background. Some members of the audience within the (first) video stream may be displayed within the (second) video stream of the promotional trailer on the screen within the movie theater, in addition to and/or in lieu of the extras originally present within the promotional trailer. Embodiments of the invention thus include this, and other exemplary scenarios, as well, as encompassed by the claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>I claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>receiving a video stream of a plurality of people within a venue;</claim-text>
<claim-text>analyzing, by a processor of a computing device, the people within the video stream;</claim-text>
<claim-text>overlaying, by the processor of the computing device, virtual content onto the video stream based on analysis of the people within the video stream; and,</claim-text>
<claim-text>displaying the video stream, with the virtual content overlaid thereon, onto a screen within the venue.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the virtual content is overlaid onto the video stream such that upon display of the video stream, the virtual content and one or more of the people within the venue appear to be interacting with one another as if the virtual content were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the virtual content comprises a moving object, wherein analyzing the people within the video stream comprises detecting a given person to which the moving object is close and detecting motion of the given person, and wherein overlaying the virtual content onto the video stream comprises overlaying the moving object onto the video stream such that the moving object appears to bounce off or be hit by the given person as if the moving object were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the virtual content comprises an object, wherein analyzing the people within the video stream comprises detecting a given person to which the object is close and detecting motion of the given person, and wherein overlaying the virtual content onto the video stream comprises overlaying the object onto the video stream such that the object appears to be caught by the given person as if the object were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the people within the video stream and wherein overlaying the virtual content onto the video stream result in one or more of the people playing a game in relation to the virtual content.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the people within the video stream and wherein overlaying the virtual content onto the video stream result in one or more of the people answering a question in relation to the virtual content.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the people within the video stream comprises logically dividing the people into a plurality of groups and detecting motion of the people within each group, and wherein overlaying the virtual content onto the video stream comprises overlaying the virtual content based on the motions of the people within the groups.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the virtual content comprises a character, wherein analyzing the people within the video stream comprises locating an empty seat within the venue, and wherein overlaying the virtual content onto the video stream comprises overlaying the character onto the empty seat such that the character appears to be sitting in the empty seat as if the character were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the people within the video stream comprises selecting a given person within the venue, and wherein overlaying the virtual content onto the video stream comprises overlaying the virtual content to call attention to the given person.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A system comprising:
<claim-text>a video camera to generate a video stream of a plurality of people within a venue;</claim-text>
<claim-text>a processor; and,</claim-text>
<claim-text>a computer-readable storage medium to store a computer program that is executed by the processor to analyze the people within the video stream, to overlay virtual content onto the video stream based on analysis of the people within the video stream, and to transmit the video stream with the virtual content overlaid thereon for display onto a screen within the venue.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising one or more of:
<claim-text>one or more light sources to illuminate the people within the venue; and,</claim-text>
<claim-text>a projector to display the video stream, with the virtual content overlaid thereon, on a screen.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the virtual content is overlaid onto the video stream such that upon display of the video stream, the virtual content and one or more of the people within the venue appear to be interacting with one another as if the virtual content were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the virtual content comprises a moving object, wherein the computer program is to analyze the people within the video stream by detecting a given person to which the moving object is close and by detecting motion of the given person, and wherein the computer program is to overlay the virtual content onto the video stream by overlaying the moving object onto the video stream such that the moving object appears to bounce off or be hit by the given person as if the moving object were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the virtual content comprises an object, wherein the computer program is to analyze the people within the video stream by detecting a given person to which the object is close and by detecting motion of the given person, and wherein the computer program is to overlay the virtual content onto the video stream by overlaying the object onto the video stream such that the object appears to be caught by the given person as if the object were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the computer program is to analyze the people within the video stream and is to overlay the virtual content onto the video stream to result in one or more of the people playing a game in relation to the virtual content.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the computer program is to analyze the people within the video stream and is to overlay the virtual content onto the video stream to result in one or more of the people answering a question in relation to the virtual content.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the computer program is to analyze the people within the video stream by logically dividing the people into a plurality of groups and by detecting motion of the people within each group, and wherein the computer program is to overlay the virtual content onto the video stream by overlaying the virtual content based on the motions of the people within the groups.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the virtual content comprises a character, wherein the computer program is to analyze the people within the video stream by locating an empty seat within the venue, and wherein the computer program is to overlay the virtual content onto the video stream by overlaying the character onto the empty seat such that the character appears to be sitting in the empty seat as if the character were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the computer program is to analyze the people within the video stream by selecting a given person within the venue, and wherein the computer program is to overlay the virtual content onto the video stream by overlaying the virtual content to call attention to the given person.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A non-transitory computer-readable storage medium having a computer program stored thereon, wherein execution of the computer program by a processor of a computing device causes a method to be performed, the method comprising:
<claim-text>receiving a video stream of a plurality of people within a venue;</claim-text>
<claim-text>analyzing the people within the video stream;</claim-text>
<claim-text>overlaying virtual content onto the video stream based on analysis of the people within the video stream; and,</claim-text>
<claim-text>causing the video stream, with the virtual content overlaid thereon, to be displayed onto a screen within the venue.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the virtual content is overlaid onto the video stream such that upon display of the video stream, the virtual content and one or more of the people within the venue appear to be interacting with one another as if the virtual content were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the virtual content comprises a moving object, wherein analyzing the people within the video stream comprises detecting a given person to which the moving object is close and detecting motion of the given person, and wherein overlaying the virtual content onto the video stream comprises overlaying the moving object onto the video stream such that the moving object appears to bounce off or be hit by the given person as if the moving object were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the virtual content comprises an object, wherein analyzing the people within the video stream comprises detecting a given person to which the object is close and detecting motion of the given person, and wherein overlaying the virtual content onto the video stream comprises overlaying the object onto the video stream such that the object appears to be caught by the given person as if the object were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein analyzing the people within the video stream and wherein overlaying the virtual content onto the video stream result in one or more of the people playing a game in relation to the virtual content.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein analyzing the people within the video stream and wherein overlaying the virtual content onto the video stream result in one or more of the people answering a question in relation to the virtual content.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein analyzing the people within the video stream comprises logically dividing the people into a plurality of groups and detecting motion of the people within each group, and wherein overlaying the virtual content onto the video stream comprises overlaying the virtual content based on the motions of the people within the groups.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the virtual content comprises a character, wherein analyzing the people within the video stream comprises locating an empty seat within the venue, and wherein overlaying the virtual content onto the video stream comprises overlaying the character onto the empty seat such that the character appears to be sitting in the empty seat as if the character were real and present within the venue.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein analyzing the people within the video stream comprises selecting a given person within the venue, and wherein overlaying the virtual content onto the video stream comprises overlaying the virtual content to call attention to the given person. </claim-text>
</claim>
</claims>
</us-patent-grant>
