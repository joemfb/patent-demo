<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625069-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625069</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12141216</doc-number>
<date>20080618</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2007-165312</doc-number>
<date>20070622</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>272</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>03</class>
<subclass>B</subclass>
<main-group>27</main-group>
<subgroup>68</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>03</class>
<subclass>B</subclass>
<main-group>27</main-group>
<subgroup>52</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>355 52</main-classification>
<further-classification>355 55</further-classification>
</classification-national>
<invention-title id="d2e71">Exposure apparatus and method of manufacturing device</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4668077</doc-number>
<kind>A</kind>
<name>Tanaka</name>
<date>19870500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 30</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5105075</doc-number>
<kind>A</kind>
<name>Ohta et al.</name>
<date>19920400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>2502012</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5710620</doc-number>
<kind>A</kind>
<name>Taniguchi</name>
<date>19980100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 53</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5721608</doc-number>
<kind>A</kind>
<name>Taniguchi</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5917581</doc-number>
<kind>A</kind>
<name>Suzuki</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 55</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6235438</doc-number>
<kind>B1</kind>
<name>Suzuki et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>430 30</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2003/0035090</doc-number>
<kind>A1</kind>
<name>Imai et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 53</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2003/0128344</doc-number>
<kind>A1</kind>
<name>Nishi</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 52</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2009/0213351</doc-number>
<kind>A1</kind>
<name>Kok</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 67</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2010/0092881</doc-number>
<kind>A1</kind>
<name>Mos et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>430 30</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2010/0225889</doc-number>
<kind>A1</kind>
<name>Sumiyoshi</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 55</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>63-16725</doc-number>
<kind>B2</kind>
<date>19880400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>JP</country>
<doc-number>02-297918</doc-number>
<kind>A</kind>
<date>19901200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>JP</country>
<doc-number>09-148228</doc-number>
<kind>A</kind>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>JP</country>
<doc-number>2828226</doc-number>
<kind>B2</kind>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>JP</country>
<doc-number>2001-102291</doc-number>
<kind>A</kind>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>JP</country>
<doc-number>2001-297961</doc-number>
<kind>A</kind>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>JP</country>
<doc-number>2005-012201</doc-number>
<kind>A</kind>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>JP</country>
<doc-number>2005-183747</doc-number>
<kind>A</kind>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>2007-206643</doc-number>
<kind>A</kind>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>English Translation of JP 2001-102291 (dated Apr. 13, 2001).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>English Translation of JP 09-148228 (dated Jun. 6, 1997).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00023">
<othercit>English Translation of JP 2007-206643 (dated Aug. 16, 2007).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00024">
<othercit>English Translation of JP 08-234136 (dated Sep. 13, 1996).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
</us-references-cited>
<number-of-claims>9</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>355 53</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>355 67</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>355 68</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>355 75</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>355 77</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>355 55</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>355 52</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>430 30</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>13</number-of-drawing-sheets>
<number-of-figures>18</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080316447</doc-number>
<kind>A1</kind>
<date>20081225</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yabu</last-name>
<first-name>Nobuhiko</first-name>
<address>
<city>Utsunomiya</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Nakamura</last-name>
<first-name>Tadao</first-name>
<address>
<city>Utsunomiya</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Yabu</last-name>
<first-name>Nobuhiko</first-name>
<address>
<city>Utsunomiya</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Nakamura</last-name>
<first-name>Tadao</first-name>
<address>
<city>Utsunomiya</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Canon U.S.A., Inc. IP Division</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Canon Kabushiki Kaisha</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kim</last-name>
<first-name>Peter B</first-name>
<department>2882</department>
</primary-examiner>
<assistant-examiner>
<last-name>Persaud</last-name>
<first-name>Deoram</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An exposure apparatus the present invention comprises: an illumination optical system configured to illuminate an illumination area on an original with light from a light source; a projection optical system configured to project a pattern of the original onto a substrate; a first stage configured to hold the original; a second stage configured to hold the substrate; and a controller configured to control driving of at least one of the first stage, the second stage, and an optical element which forms the projection optical system so as to reduce variations in imaging characteristics of the projection optical system, based on a dependence of a transmittance of the pattern on a position in the illumination area.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="189.48mm" wi="126.92mm" file="US08625069-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="204.98mm" wi="168.15mm" file="US08625069-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="205.06mm" wi="146.56mm" file="US08625069-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="205.74mm" wi="145.03mm" orientation="landscape" file="US08625069-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="206.93mm" wi="138.18mm" file="US08625069-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="195.50mm" wi="149.18mm" orientation="landscape" file="US08625069-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="213.78mm" wi="156.38mm" file="US08625069-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="216.07mm" wi="160.19mm" file="US08625069-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="210.40mm" wi="137.50mm" orientation="landscape" file="US08625069-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="193.97mm" wi="147.66mm" file="US08625069-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="173.48mm" wi="134.37mm" file="US08625069-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="213.02mm" wi="174.24mm" file="US08625069-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="231.22mm" wi="152.57mm" file="US08625069-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="184.57mm" wi="141.22mm" orientation="landscape" file="US08625069-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates to an exposure apparatus in which variations in imaging characteristics are reduced.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">A process of manufacturing a semiconductor device such as an LSI or VLSI formed from an extra fine pattern has conventionally adopted a reduction projection exposure apparatus which reduces and prints by exposing a circuit pattern drawn on a mask on a substrate (also called a &#x201c;wafer&#x201d;) coated with a photosensitive agent, thereby forming a desired pattern on the substrate. Along with an improvement in the packaging density of semiconductor devices, further micropatterning is becoming necessary. A demand for micropatterning on the exposure apparatus is increasing along with the development of the resist process.</p>
<p id="p-0006" num="0005">To improve the resolving power of an exposure apparatus, there are a method of shortening the exposure light wavelength and a method of increasing the numerical aperture (NA) of a reduction projection lens. As the resolving power increases, the depth of focus of the reduction projection lens decreases. It is therefore important to improve the focus accuracy of focusing the wafer surface on the imaging plane (focal plane) of the reduction projection lens. One important optical characteristic of the projection exposure apparatus is the alignment accuracy of precisely aligning various patterns obtained by a plurality of processes. An important factor which influences the alignment accuracy is a magnification error of the reduction projection lens. Along with a stronger trend toward further micropatterning of a VLSI every year, a need for improving the alignment accuracy is becoming stronger. It is therefore very important to maintain the magnification of the reduction projection lens at a predetermined value.</p>
<p id="p-0007" num="0006">A reduction projection lens is known to partially absorb exposure energy so that the temperature of the reduction projection lens changes due to heat generated by the absorption, leading to a change in the optical characteristics of the reduction projection lens, such as the refractive index. When the reduction projection lens is continuously irradiated with exposure light for a long period of time, the imaging characteristics (including at least one of the focus, magnification, and wavefront aberrations such as astigmatism aberration and distortion aberration) of the reduction projection lens vary. This may result in non-negligible amounts of focus errors or alignment errors. Under the circumstance, there is proposed a method of correcting variations in imaging characteristics, which occur when exposure energy is applied to the reduction projection lens.</p>
<p id="p-0008" num="0007">For example, the applicant of Japanese Patent Publication No. 63-16725 proposes calculating the amounts of variations in imaging characteristics, which occur when exposure energy is applied to the reduction projection lens by model equations using, e.g., the exposure amount, exposure time, and non-exposure time as variables. Based on the calculation result, the variations in imaging characteristics of the projection optical system are corrected. The model equations have imaging characteristic-specific coefficients unique to the reduction projection lens. Measuring the coefficients makes it possible to correct the variations in the imaging characteristics of the reduction projection lens.</p>
<p id="p-0009" num="0008">There is also proposed an exposure apparatus which can obtain a more excellent projection resolving power for a specific pattern by changing the illumination shape. In such an apparatus, a light source distribution generated on the pupil surface of the reduction projection lens changes depending on the exposure conditions (e.g., the numerical aperture of a projection system, the numerical aperture of an illumination system, the exposure area, the exposure center position, and the exposure mask). Therefore, the variation amounts of imaging characteristics change for the respective exposure conditions.</p>
<p id="p-0010" num="0009">Under the circumstance, there is proposed an exposure method of satisfactorily adjusting the variations in imaging characteristics even when the distribution of energy applied to the reduction projection lens changes. For example, Japanese Patent No. 2828226 proposes a method of storing imaging characteristic correction coefficients corresponding to various states of the illumination light source distribution, and reading out corresponding correction information when the state of the light source distribution is changed, performing correction based on the readout information. To precisely correct variations in imaging characteristics corresponding to various states of the illumination light source distribution, it is necessary to calculate a correction coefficient best suited to a set of exposure conditions of interest from pieces of information on, e.g., the state of the illumination light source distribution on the pupil plane, the reticle transmittance, the dimensions of the exposure area in the scanning direction and in a direction perpendicular to the scanning direction, the scanning speed, the exposure amount, and the irradiation time.</p>
<p id="p-0011" num="0010">It is necessary to calculate a correction coefficient best suited to a set of exposure conditions of interest. For this purpose, the transmittance of a mask needs to be calculated from mask transmittance information (e.g., mask transmittance map information/mask design information) and information on the exposure area on the mask. However, the prior arts do not take account of the difference in transmittance (the difference in pattern density) attributed to the image height in the illumination area. Still worse, even when the pattern density in the illumination area is calculated from the mask transmittance information and illumination area information, correction systems in the prior arts have poor correction capabilities.</p>
<p id="p-0012" num="0011">Nowadays, however, the correction systems are being upgraded to meet a demand for an improvement in the accuracy of the exposure apparatus. This has made it possible to correct variations in imaging characteristics which depend on the image height in the illumination area.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0013" num="0012">It is an object of the present invention to provide an exposure apparatus in which variations in imaging characteristics attributed to the dependence of the transmittance of a pattern formed on a mask on the position in the illumination area are reduced.</p>
<p id="p-0014" num="0013">According to the present invention, there is provided an exposure apparatus comprising an illumination optical system configured to illuminate an illumination area on an original with light from a light source; a projection optical system configured to project a pattern of the original onto a substrate; a first stage configured to hold the original; a second stage configured to hold the substrate; and a controller configured to control driving of at least one of the first stage, the second stage, and an optical element which forms the projection optical system so as to reduce variations in imaging characteristics of the projection optical system, based on a dependence of a transmittance of the pattern on a position in the illumination area.</p>
<p id="p-0015" num="0014">Further features of the present invention will become apparent from the following description of exemplary embodiments with reference to the attached drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic view showing an exposure apparatus according to an embodiment of the present invention;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> is a graph showing the irradiation variation characteristic of the aberration of a reduction projection lens;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> is a view showing an example of the mask pattern layout;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> is a view showing the relationship between the exposure area on a mask and the irradiation area of a projection optical system;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating how to calculate a correction coefficient;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> is a view showing the light intensity distribution on the pupil plane;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 7</figref> is a table showing a mask transmittance map;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 8</figref> is a view showing divided illumination areas;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 9</figref> is a table showing an approach to calculating the mask transmittances in the divided illumination areas;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 10</figref> is a table showing normalized mask transmittances in the divided illumination areas;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 11</figref> is a table showing an approach to calculating a weighting coefficient from the divided illumination areas;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 12</figref> is a table showing an exposure time weighting method;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 13</figref> is a graph showing the relationship between the image height and the amount of aberration variation;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart illustrating exposure processing;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 15</figref> is a graph showing an example of a correction position calculation method;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 16</figref> is a graph showing another example of the correction position calculation method;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 17</figref> is a plan view and a sectional view showing driving mechanisms of a projection system; and</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 18</figref> is a view showing the transmittance map image height and aberration correction equation.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DESCRIPTION OF THE EMBODIMENTS</heading>
<p id="p-0034" num="0033">Variations in imaging characteristics in an exposure apparatus according to embodiments of the present invention include a variation in at least one of the focus, magnification aberration, distortion aberration, astigmatism aberration, spherical aberration, coma aberration, and other wavefront aberrations. As is well known in the technical field of the present invention, the wavefront aberrations are expressed as the respective terms of an expression obtained by expanding the wavefront shape using the Zernike polynomial. These wavefront aberrations are also collectively called &#x201c;aberration&#x201d;.</p>
<heading id="h-0005" level="1">First Embodiment</heading>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 1</figref> shows the schematic arrangement of a scanning exposure apparatus according to an embodiment of the present invention. A pulse laser source <b>101</b> contains, e.g., ArF gas and emits a laser beam with a far-ultraviolet wavelength of 193 nm. The pulse laser source <b>101</b> includes, e.g., a front mirror which constitutes a resonator, a wavelength range narrowing module which includes, e.g., a diffraction grating and prism and narrows the exposure wavelength range, a monitor module which includes, e.g., a spectroscope and detector and monitors the wavelength stability and spectral width, and a shutter.</p>
<p id="p-0036" num="0035">A laser controller <b>102</b> performs, e.g., the control of gas exchange, wavelength stabilization, and a discharge voltage in the pulse laser source <b>101</b>. In this embodiment, the control is not performed by the laser controller <b>102</b> alone and can be performed in accordance with an instruction from a main controller <b>103</b> for the overall exposure apparatus, which is connected to the laser controller <b>102</b> via an interface cable.</p>
<p id="p-0037" num="0036">The beam emitted by the pulse laser source <b>101</b> is shaped into a desired beam shape via a beam shaping optical system of an illumination optical system <b>104</b>, enters an optical integrator, and forms a large number of secondary sources to illuminate a mask <b>109</b> with a uniform illuminance distribution.</p>
<p id="p-0038" num="0037">An aperture stop <b>105</b> of an illumination system has a nearly circular aperture so that an illumination system controller <b>108</b> can set the aperture diameter of the aperture stop <b>105</b> and, eventually, the numerical aperture of the illumination optical system <b>104</b> to desired values. Since the ratio of the numerical aperture of the illumination optical system <b>104</b> to that of a projection optical system <b>110</b> is the coherence factor (&#x3c3; value), the illumination system controller <b>108</b> can set the &#x3c3; value by controlling the aperture stop <b>105</b> of the illumination system.</p>
<p id="p-0039" num="0038">A half mirror <b>106</b> is inserted into the optical path of the illumination optical system <b>104</b>. A certain component of exposure light, which illuminates the mask <b>109</b>, is reflected and extracted by the half mirror <b>106</b>. An ultraviolet photosensor <b>107</b> is inserted in the optical path of the light component reflected by the half mirror <b>106</b>, and generates an output corresponding to the intensity (exposure energy) of the exposure light.</p>
<p id="p-0040" num="0039">The output from the photosensor <b>107</b> is converted into exposure energy per pulse by an integration circuit (not shown) which performs integration for each pulse emission of the pulse laser source <b>101</b>. The converted exposure energy is input to the main controller <b>103</b> which controls the overall exposure apparatus via the illumination system controller <b>108</b>.</p>
<p id="p-0041" num="0040">The circuit pattern of a semiconductor device to be printed is formed on the mask (reticle) <b>109</b> serving as an original. The illumination optical system <b>104</b> irradiates the illumination area (exposure slit) on the mask <b>109</b> with a laser beam. The mask <b>109</b> is held by a mask stage (not shown). The mask stage moves the mask <b>109</b> to scan the mask <b>109</b> with a laser beam (illumination area), thereby exposing the exposure area on the mask <b>109</b>. The projection optical system <b>110</b> is set so as to reduce the circuit pattern image of the mask <b>109</b> at a reduction magnification &#x3b2; (&#x3b2; is, e.g., &#xbc;) and image and project the reduced image onto a wafer <b>115</b> serving as a photosensitive substrate coated with a photoresist. The pattern formed on the mask <b>109</b> is transferred onto the wafer <b>115</b> serving as a substrate via the projection optical system <b>110</b>. An aperture stop <b>111</b> of the projection optical system <b>110</b> has a nearly circular aperture and is inserted on the pupil plane (the Fourier transformation plane with respect to the reticle) of the projection optical system <b>110</b>. By controlling the aperture diameter of the aperture stop <b>111</b> using a driver <b>112</b> such as a motor, the numerical aperture of the aperture stop <b>111</b> can be set to a desired value.</p>
<p id="p-0042" num="0041">A field lens driver <b>113</b> moves a field as a constituent element of a lens system in the projection optical system <b>110</b> onto the optical axis of a reduction projection lens using, e.g., the air pressure or a piezoelectric element, so that deterioration in various aberrations of the reduction projection lens is prevented and a satisfactory projection magnitude is ensured, thus reducing distortion errors. A projection lens controller <b>114</b> controls optical elements of the projection optical system <b>110</b>.</p>
<p id="p-0043" num="0042">A wafer stage <b>116</b> serving as a second stage which holds a substrate can three-dimensionally move along the optical axis direction (Z direction) of the projection optical system <b>110</b> and on a plane (X-Y plane) perpendicular to this direction. A laser interferometer <b>118</b> measures the distance between the wafer stage <b>116</b> and a movable mirror <b>117</b> fixed to it, thereby detecting the position of the wafer stage <b>116</b> on the X-Y plane. A stage controller <b>120</b> under the control of the main controller <b>103</b> of the exposure apparatus detects the position of the wafer stage <b>116</b> by the laser interferometer <b>118</b> and controls a driver <b>119</b> such as a motor to move the wafer stage <b>116</b> to a predetermined position on the X-Y plane. A mask stage controller, the stage controller <b>120</b>, the projection lens controller <b>114</b>, and the main controller <b>103</b> constitute a controller which controls the driving of the optical elements of the projection optical system, the first stage which holds the mask, and the second stage which holds the substrate.</p>
<p id="p-0044" num="0043">A light-projecting optical system <b>121</b> and detection optical system <b>122</b> constitute a focal plane detector. The light-projecting optical system <b>121</b> projects a plurality of light beams formed from non-exposure light which does not expose the photoresist on the wafer <b>115</b>. The light beams are converged on the wafer <b>115</b> and reflected by it. The light beams reflected by the wafer <b>115</b> enter the detection optical system <b>122</b>. Although not shown, a plurality of position detection light-receiving elements are inserted in the detection optical system <b>122</b> in correspondence with the respective reflected light beams. The light-receiving surface of each position detection light-receiving element is set nearly conjugate to a corresponding light beam reflection point on the wafer <b>115</b> by an imaging optical system. A positional shift of the surface of the wafer <b>115</b> in the optical axis direction of the projection optical system <b>110</b> is measured as a positional shift of the incident light beam on the position detection light-receiving element in the detection optical system <b>122</b>.</p>
<p id="p-0045" num="0044">Model equations of a variation in the aberration of the projection optical system <b>110</b> upon exposure energy irradiation, and a correction coefficient used to quantize the model equations according to this embodiment will be explained.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 2</figref> shows an example of a temporal change in the aberration of the projection optical system by exposure. The abscissa indicates a time t, and the ordinate indicates an aberration variation amount &#x394;F at a certain image height of the projection optical system <b>110</b>. The aberration herein means, e.g., the focus, magnification, distortion, astigmatism aberration, spherical aberration, and coma aberration. The aberration variation amount &#x394;F generally takes an image height-specific value. The initial amount of aberration of the projection optical system <b>110</b> is indicated by F<b>0</b>. As the projection optical system <b>110</b> starts exposure upon receiving exposure light from the pulse laser source <b>101</b> at time t<b>0</b>, the amount of aberration varies with time and becomes stable upon reaching a predetermined amount of aberration F<b>1</b> at time t<b>1</b>. After that, even when the exposure light is continuously applied to the projection optical system <b>110</b>, the amount of aberration does not change from F<b>1</b> because energy which transforms into heat upon being absorbed by the projection optical system <b>110</b> equilibrates with thermal energy discharged by the projection optical system <b>110</b>. As the exposure is stopped at time t<b>2</b>, the amount of aberration returns to the original state with time and reaches the initial amount of aberration F<b>0</b> at time t<b>3</b>.</p>
<p id="p-0047" num="0046">Time constants TS<b>1</b> and TS<b>2</b> in <figref idref="DRAWINGS">FIG. 2</figref> are equivalent to those of the heat transfer characteristic of the projection optical system <b>110</b>. Since these time constants are aberration-specific values unique to the projection optical system <b>110</b>, they are acquired for each apparatus and aberration in inspecting the projection optical system <b>110</b>.</p>
<p id="p-0048" num="0047">A method of calculating the maximum amount of aberration variation F<b>1</b> in <figref idref="DRAWINGS">FIG. 2</figref> will be explained. The maximum amount of aberration variation F<b>1</b> can be expressed by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>F</i>1=<i>K&#xd7;Q</i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where K is the amount of aberration variation per unit amount of light (unit exposure energy) as a correction coefficient, and Q is a value calculated from the parameters of conditions (e.g., information on the exposure amount, scanning speed, and exposure area) which determine actual exposure energy.
</p>
<p id="p-0049" num="0048">Let &#x394;F<sub>k </sub>be the amount of aberration at a certain time. Then, using the maximum amount of variation F<b>1</b> and the time constants TS<b>1</b> and TS<b>2</b> stored for each aberration, an amount of aberration&#x394;F<sub>k+1 </sub>after exposure for only a time period &#x394;t from the certain time &#x394;F<sub>k </sub>is approximated by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>F</i><sub>k+1</sub><i>=&#x394;F</i><sub>k</sub><i>+F</i>1&#xd7;(1&#x2212;exp(&#x2212;&#x394;<i>t/TS</i>1))&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0050" num="0049">Likewise, an amount of aberration&#x394;F<sub>k+1 </sub>when exposure is not performed for the time period &#x394;t from the certain time &#x394;F<sub>k </sub>is approximated by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>F</i><sub>k+1</sub><i>=&#x394;F</i><sub>k</sub>&#xd7;exp(&#x2212;&#x394;<i>t/TS</i>2)&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0051" num="0050">A curve indicating the irradiation variation characteristic of the aberration of the projection optical system <b>110</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> is modeled by the functions in equations (2) and (3) to predict a variation in the aberration of the projection optical system due to the generation of exposure heat. Note that the modeling functions in equations (1), (2), and (3) are merely an example, and the curve may be modeled using other equations.</p>
<p id="p-0052" num="0051">A correction coefficient K necessary for correcting a variation in imaging characteristic, which occurs upon exposure in accordance with the illumination area and the dependence of the pattern transmittance on the position in it, needs to be calculated for each exposure condition. This is because when the exposure conditions change, the energy density distribution of light which enters the projection optical system <b>110</b> changes, resulting in changes in the amount of aberration variation of the projection optical system and in its dependence on the image height. The exposure conditions herein mean the effective light source shape, the mask pattern, and the exposure area on the mask.</p>
<p id="p-0053" num="0052">In order to calculate a correction coefficient corresponding to the energy distribution of light which enters the projection optical system, a first process of calculating and storing a correction coefficient for predicting a variation in the aberration of the projection optical system by taking account of the illumination area on the mask and the dependence of the pattern transmittance on the position in it will be explained.</p>
<p id="p-0054" num="0053">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, an exposure pattern is laid out on the mask. The pattern layout is generally nonuniform in the entire mask area, and the pattern density, i.e., pattern transmittance has a deviation. For this reason, even if the energy distribution of irradiation light is uniform over the entire mask surface, the energy distribution of a light component transmitted through the pattern is nonuniform. This deviation in the energy distribution is averaged by scanning in the scanning direction (in this case, the Y direction), but it remains in a direction (in this case, the X direction) perpendicular to the scanning direction as a difference in image height of the energy distribution.</p>
<p id="p-0055" num="0054">As shown in <figref idref="DRAWINGS">FIG. 4</figref>, there is a case in which the mask is partially shielded by a light-shielding member so that exposure is performed by limiting the mask exposure area. In this case, a difference in image height of the energy distribution is influenced by a mask range determined as the exposure area.</p>
<p id="p-0056" num="0055">In this embodiment, a method of calculating a correction coefficient by taking account of the pattern transmittance distribution and illumination area will be explained. <figref idref="DRAWINGS">FIG. 5</figref> illustrates a correction coefficient calculation sequence. A first calculator of the main controller <b>103</b> performs the correction coefficient calculation.</p>
<p id="p-0057" num="0056">In step <b>1</b>, the first calculator writes information of the exposure conditions to a memory. The pieces of the information are the type of an exposure mask, the illumination area, and the effective light source shape. The effective light source shape information is obtained in advance based on the measurement result and/or the simulation result obtained by a computer. For example, as shown in <figref idref="DRAWINGS">FIG. 6</figref>, the pupil plane is divided into 101&#xd7;101 areas so that a pupil plane light intensity map generated by normalizing the light intensity in each area by a maximum light intensity is used as the effective light source shape information.</p>
<p id="p-0058" num="0057">In step <b>2</b>, the first calculator reads out exposure mask transmittance information (to be referred to as a mask transmittance map hereinafter) as shown in <figref idref="DRAWINGS">FIG. 7</figref>. This information is light amount data in a matrix, which is obtained by measuring the amounts of light of a projected image on the entire mask surface under appropriate measurement conditions. The apparatus measures and stores the mask transmittance map for each mask. Although the mask transmittance map uses matrix data defined by 8 data points in the X direction and 10 data points in the Y direction in this embodiment, the amounts of light may be acquired at an arbitrary number of data points in an arbitrary area. Also, although a mask transmittance map generated by the exposure apparatus is used in this embodiment, the mask transmittance may be calculated based on, e.g., mask design information (e.g., CAD information). When the mask transmittance map information or mask design information is used by a plurality of exposure apparatuses, the information may be stored in a server which allows a plurality of exposure apparatuses to commonly use it.</p>
<p id="p-0059" num="0058">In step <b>3</b>, as the first calculation processing procedure, the first calculator divides the illumination area into a plurality of areas in the X direction, and individually calculates the mask transmittances in the respective divided areas. In this embodiment, the dimension of the illumination area in the X direction is 26 mm (a value when converting the dimension of the illumination area in the X direction on the mask into that on the wafer). Although this embodiment will exemplify a case in which the illumination area is divided into 8 areas with equal areas as shown in <figref idref="DRAWINGS">FIG. 8</figref>, the number of divided areas may be an arbitrary one of 2 or more. The divided areas are obtained by dividing the range within which the exposure light enters the projection optical system into a plurality of areas. As shown in <figref idref="DRAWINGS">FIG. 9</figref>, the mask transmittance in the divided area (to be referred to as divided area n; n is the area number that is one of 1 to 8 in this embodiment) is calculated as the average of transmittance data in a mask area scanned along division area n by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(the mask transmittance in divided area <i>n</i>)=(&#x3a3; transmittance data)/(the number of data points)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
(Note that the &#x3a3; range is defined as only a mask area scanned along divided area n)
</p>
<p id="p-0060" num="0059">In step <b>4</b>, the first calculator normalizes the mask transmittance in divided area n, and calculates a mask transmittance r<sub>n </sub>in each divided area, as shown in <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0061" num="0060">In steps <b>5</b> and <b>6</b>, the first calculator calculates an exposure area ratio g<sub>n </sub>of divided area n based on exposure area information. The exposure area information herein includes a dimension w of the exposure area in the X direction, and an X-image height x<sub>0 </sub>at the center of the exposure area. These pieces of information can be substituted by X-coordinates xr and x<b>1</b> at the two ends of the exposure area. The dimension of the exposure area in the Y direction is taken into consideration as the scanning distance not herein but in a calculation process to be described later.</p>
<p id="p-0062" num="0061">The g<sub>n </sub>value is given as the area ratio between divided area n and a portion in divided area n, which is included in the illumination area under a certain set of exposure conditions. That is, the g<sub>n </sub>value can be calculated on a case-by-case basis as follows:</p>
<p id="p-0063" num="0062">A case in which divided area n is included in the illumination area: g<sub>n</sub>=1</p>
<p id="p-0064" num="0063">A case in which divided area n is not included in the illumination area: g<sub>n</sub>=0</p>
<p id="p-0065" num="0064">A case in which divided area n is partially included in the illumination area: g<sub>n</sub>=((the ratio of a portion in divided area n, which is included in the illumination area)/(the area of divided area n)) <figref idref="DRAWINGS">FIG. 11</figref> shows a detailed example of the calculation result.</p>
<p id="p-0066" num="0065">In step <b>7</b>, the first calculator calculates the weighting coefficient from the mask transmittance information and exposure area information. Let &#x3bb;<sub>n </sub>be the weighting coefficient calculated by multiplying the r<sub>n </sub>value calculated from the mask transmittance by the g<sub>n </sub>value calculated from the exposure area information. Then, the coefficient &#x3bb;<sub>n </sub>corresponds to a value obtained by normalizing the amount of light energy which propagates through divided area n.</p>
<p id="p-0067" num="0066">Steps <b>3</b> to <b>7</b> are repeated for each divided area n (eight times in this embodiment), and the weighting coefficient &#x3bb;<sub>n </sub>in each divided area n is calculated and stored.</p>
<p id="p-0068" num="0067">Using the calculated weighting coefficient &#x3bb;<sub>n </sub>for each divided area, an aberration function:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>f</i><sub>n</sub><sup>I,C</sup>(<i>x</i>)&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
is weighted, where n is the divided area number, I is the effective light source shape on the pupil plane, C is the type of aberration, and x is an arbitrary X-image height. Expression (1) represents the degree of influence of the mask transmittance and exposure area on the aberration C as an imaging characteristic, which is generated by the projection optical system when divided area n is exposed with the effective light source shape I by the unit exposure amount, as a function of the image height x. That is, the aberration function means the degree of influence, on the imaging characteristic, of the mask transmittance and exposure area determined for each of the plurality of areas obtained by dividing the range within which the exposure light enters the projection optical system. The image height x is not particularly limited to image heights inside the divided area n. This means that the light which enters the divided area n can change the aberration not only at image heights inside the divided area n but also at image heights outside the divided area n. The aberration function and its coefficients generally differ for each aberration C, e.g., a function for focus is not necessarily equal to one for image shift. In general, the coefficients also differ for each effective light source shape I. In this embodiment, an appropriate function is selected based on the effective light source information read out in step <b>1</b>. The dependence of the aberration on the image height only in the X direction is expressed as a function in this embodiment. However, when the dependence of the aberration on the image height in the Y direction needs to be taken into consideration in aberration correction to be described hereinafter, the aberration function may be expanded into:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>f</i><sub>n</sub><sup>I,C</sup>(<i>x,y</i>)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where y is an arbitrary Y-image height.
</p>
<p id="p-0069" num="0068">The aberration function given by expression (1) is calculated in advance based on the aberration measurement result and/or simulation result. However, since it is difficult to calculate the value of expression (1) for an arbitrary divided area n, arbitrary effective light source shape I, and arbitrary image height x, expression (1) may be determined by appropriately interpolating using the values calculated for several values each of n, I, and x.</p>
<p id="p-0070" num="0069">Letting x<sub>0n </sub>be the image height at the center of divided area n, the aberration function in expression (1) may be substituted by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>f</i><sub>n</sub><sup>I,C</sup>(<i>x</i>)&#x2192;<i>F</i><sup>I,C</sup>(<i>x,x</i><sub>0n</sub>)&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
so that the aberration function F<sup>I,C</sup>(x,x<sub>0n</sub>) is used for all divided areas 1 to 8.
</p>
<p id="p-0071" num="0070">The amount of variation in the aberration C due to the influence of each divided area under specific exposure conditions can be calculated by multiplying the function in expression (1) by the weighting coefficient &#x3bb;<sub>n</sub>. This calculation is valid because the weighting coefficient &#x3bb;<sub>n </sub>corresponds to the amount of light which enters divided area n under the exposure conditions, and the amount of aberration variation is proportional to the amount of incident light as is commonly known. Assume, for example, that the image height coordinate position to predict a variation in focus is (0.0), the effective light source shape under the exposure conditions is I, the number of divided areas is 8, and the weighting coefficient in each divided area is &#x3bb;<sub>n</sub>. Then, the amount of variation in aberration due to the influence of each divided area can be expressed by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x3bb;<sub>1</sub><i>&#xd7;f</i><sub>1</sub><sup>I,Focus</sup>(0.0),&#x3bb;<sub>2</sub><i>&#xd7;f</i><sub>2</sub><sup>I,Focus</sup>(0.0)), . . . ,&#x3bb;<sub>8</sub>&#xd7;f<sub>8</sub><sup>I,Focus</sup>(0.0)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0072" num="0071">A variation in aberration under the exposure conditions is calculated as the sum of variations in aberrations due to the influence of the divided areas. In the above-described example, the correction coefficient of a variation in focus at the image height coordinate position (0.0) under the exposure conditions is given by:</p>
<p id="p-0073" num="0072">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <msup>
            <mi>K</mi>
            <mi>Focus</mi>
          </msup>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mn>0.0</mn>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <munderover>
            <mo>&#x2211;</mo>
            <mrow>
              <mi>n</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mn>8</mn>
          </munderover>
          <mo>&#x2062;</mo>
          <mrow>
            <msub>
              <mi>&#x3bb;</mi>
              <mi>n</mi>
            </msub>
            <mo>&#x2062;</mo>
            <mrow>
              <msubsup>
                <mi>f</mi>
                <mi>n</mi>
                <mrow>
                  <mi>I</mi>
                  <mo>,</mo>
                  <mi>Focus</mi>
                </mrow>
              </msubsup>
              <mo>&#x2061;</mo>
              <mrow>
                <mo>(</mo>
                <mn>0.0</mn>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
which corresponds to K in equation (1).
</p>
<p id="p-0074" num="0073">The correction coefficient K can be calculated based on information on at least one of the light intensity distribution on the pupil plane of the projection optical system, the scanning speed, and the exposure time, in addition to the pattern transmittance distribution information and exposure area information.</p>
<p id="p-0075" num="0074">These processing operations are performed for a combination of the number of image height coordinate positions to be corrected and that of aberrations to be corrected, thereby calculating the correction coefficient for each image height and aberration.</p>
<p id="p-0076" num="0075">A correction coefficient commonly used in a plurality of exposure conditions can be calculated by weighting correction coefficients under the respective exposure conditions by the irradiation time (or the dimension of the exposure area in the Y direction/scanning speed), as shown in <figref idref="DRAWINGS">FIG. 12</figref>. In this case, the correction coefficient K used in two sets of exposure conditions is the weighted average of the correction coefficients K<b>1</b> and K<b>2</b>, which are calculated under the respective sets of exposure conditions, by the irradiation time.</p>
<p id="p-0077" num="0076">A second process of, when the current exposure conditions are changed, reading out a correction coefficient according to this change and calculating and predicting the amount of aberration variation under the exposure conditions at an arbitrary image height will be explained. A second calculator of the main controller <b>103</b> calculates the amount of variation in aberration as an imaging characteristic of the projection optical system based on the calculated correction coefficient and exposure conditions.</p>
<p id="p-0078" num="0077">The calculation for predicting a variation in the aberration of the projection optical system is done at one or more image heights. The calculation of a variation in the aberration of the projection optical system includes the calculation of the exposure time (Heating) and non-exposure time (Cooling). The former is calculated by equation (2), while the latter is calculated by equation (3).</p>
<p id="p-0079" num="0078">The F<b>1</b> value used in equation (2) is calculated using the correction coefficient K calculated in the first process. The correction coefficient K is calculated for each image height and aberration in the first process.</p>
<p id="p-0080" num="0079">The parameter Q in equation (1) includes one of, e.g., the exposure time, amount of exposure, and scanning speed. The F<b>1</b> value can be calculated by combining the parameter Q with the correction coefficient. In this embodiment, a value common to a plurality of image heights is used as the parameter Q.</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. 13</figref> shows the state in which the F<b>1</b> value changes for each image height because, even for the same aberration (e.g., the focus), the exposure area or mask pattern density changes and so the correction coefficient K changes. In this embodiment, variations in aberration are calculated at nine image heights.</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. 14</figref> illustrates an exposure sequence. The second calculator reads out a correction coefficient matching the current exposure conditions in step <b>1</b>, and performs exposure processing in step <b>2</b>. If the exposure conditions (e.g., the exposure amount and exposure area) for which the correction coefficient is calculated are different from those under which exposure is actually performed, a prediction error is generated in the aberration equation. In step <b>3</b>, the second calculator corrects the error. Then, a correction coefficient best suited to the actual exposure conditions is set. In step <b>4</b>, the second calculator calculates the aberration using the correction coefficient.</p>
<p id="p-0083" num="0082">The second calculator calculates the maximum amount of variation (F<b>1</b>) for each image height from the correction coefficient calculated for each exposure condition and the actual exposure conditions (Q). After calculating the F<b>1</b> value, the second calculator can predict the time characteristic of the amount of aberration variation &#x394;F by the Heating calculation and Cooling calculation in equations (2) and (3).</p>
<p id="p-0084" num="0083">A method of correcting the amount of aberration variation calculated by aberration calculation at each image height will be explained. In the second process, the second calculator predicts the amount of aberration variation at each image height from the actual exposure conditions and the correction coefficient calculated in the first process, and calculates the position of a correction system so as to correct the amount of aberration variation. The projection optical system and a driving system which drives a stage such as the substrate stage constitute the correction system. The controller controls the correction system so as to reduce the amount of aberration variation calculated by the second calculator.</p>
<p id="p-0085" num="0084">To calculate the position of the correction system so as to image an optimal pattern under the exposure conditions (e.g., the exposure area and exposure center), a method of averagely calculating aberration generated in the exposure area as shown in <figref idref="DRAWINGS">FIG. 15</figref> is available. It is also possible to calculate the position of the correction system by predicting the amount of variation of an arbitrary aberration at an arbitrary image height based on aberration variation model simulation at a plurality of image heights, and weighting the variation in the arbitrary aberration at the arbitrary image height, as shown in <figref idref="DRAWINGS">FIG. 16</figref>. Although not shown, it is also possible to calculate the position of the correction system by predicting the amount of variation of an arbitrary aberration at an arbitrary image height based on aberration variation model simulation at a plurality of image heights, and weighting the variation in the arbitrary aberration.</p>
<p id="p-0086" num="0085">The position of the correction system immediately before exposure is calculated by taking account of the influence of the pressure of an ambient gas surrounding the projection optical system on the imaging projection system from the output from a pressure sensor, and the offset amount set to an exposure parameter or apparatus parameter.</p>
<p id="p-0087" num="0086">A method of driving the correction system to the calculated position by the controller will be explained. The projection optical system according to this embodiment mounts optical element drivers which accurately drive optical elements such as a lens and mirror in desired directions, in order to more precisely image a mask pattern.</p>
<p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. 17</figref> shows an optical system driver inserted in the projection optical system according to this embodiment. These driving systems adopt the driving scheme disclosed in Japanese Patent Laid-Open No. 2007-206643. This driving scheme can drive the optical elements in desired directions. For example, <b>17</b><i>a </i>in <figref idref="DRAWINGS">FIG. 17</figref> is a plan view of the optical system driver in which a lens and lens frame are detached. <b>17</b><i>b </i>in <figref idref="DRAWINGS">FIG. 17</figref> is a plan view of the optical system driver in which the lens and lens frame are attached. <b>17</b><i>c </i>in <figref idref="DRAWINGS">FIG. 17</figref> is a sectional view of the optical system driver. Referring to <figref idref="DRAWINGS">FIG. 17</figref>, a stationary lens barrel <b>201</b> comprises a bottom surface flat portion <b>201</b><i>a </i>for fixing optical element drivers <b>210</b> and lens position detectors <b>202</b>, and a side wall cylindrical portion <b>201</b><i>b </i>to connect to other vertically adjacent lens units.</p>
<p id="p-0089" num="0088">The optical element drivers <b>210</b> are formed from three identical driving mechanisms and are arranged on the bottom surface flat portion <b>201</b><i>a </i>of the stationary lens barrel <b>201</b>. The lens position detector <b>202</b> detects displacements of the lens frame in its optical axis direction and its radial direction perpendicular to the optical axis. In accordance with the required detection accuracy, the lens position detector <b>202</b> is appropriately selected from, e.g., an interferometric measuring unit using a semiconductor laser, a capacitance displacement gauge, a linear encoder, and a differential transformer displacement gauge.</p>
<p id="p-0090" num="0089"><b>17</b><i>b </i>in <figref idref="DRAWINGS">FIG. 17</figref> shows the state in which the lens and lens frame are mounted. A lens frame <b>204</b> which accommodates a lens <b>203</b> has projecting flange portions at six portions on its upper surface. Three of these flange portions are connected to displacement output portions of the optical element drivers <b>210</b> using lens frame attaching screws <b>205</b>.</p>
<p id="p-0091" num="0090">A laser interferometric displacement sensor is used as the lens position detector <b>202</b>, as will be explained with reference to <b>17</b><i>c </i>in <figref idref="DRAWINGS">FIG. 17</figref>. For example, detection laser beams are projected onto the lens <b>203</b> in its optical axis direction and radial direction. Based on information on interference between the reflected light beams, displacements of the lens frame <b>204</b> in its optical axis direction (Z direction) and radial direction are detected at the three points (the vicinities of the flange portions). With the above-described arrangement, the lens <b>203</b> can be translated in the optical axis direction, i.e., the Z-axis direction shown in <b>17</b><i>c </i>in <figref idref="DRAWINGS">FIG. 17</figref> as the three optical element drivers <b>210</b> are driven by equal amounts.</p>
<p id="p-0092" num="0091">Differentiating the driving amounts of the three optical element drivers <b>210</b> by a predetermined amount allows the tilt driving in the &#x3b8;a and &#x3b8;b directions shown in <b>17</b><i>b </i>in <figref idref="DRAWINGS">FIG. 17</figref>. The translational and tilt driving amounts of the lens <b>203</b> can be precisely controlled by feeding back the output in the optical axis direction from the lens position detector <b>202</b> to these driving amounts. The amount of shift in an image on a plane perpendicular to the optical axis of the lens <b>203</b> upon parallel decentering is calculated by monitoring the output in the radial direction from the lens position detector <b>202</b>.</p>
<p id="p-0093" num="0092">The driving amount of, e.g., the wafer stage is determined by taking account of this calculation result so that any alignment error of a mask image upon lens decentering is eliminated. The above-described drivers of the projection optical system can tilt-drive the optical elements and can correct any aberrations by driving the optical elements in the Z direction. This makes it possible to correct, e.g., variations in aberration which are asymmetrical about the optical axis. To correct, e.g., the focus, a correction method by driving, in the Z direction, not only the projection optical system but also the driving unit (mask stage) which mounts the mask or the driving unit (wafer stage) which mounts the wafer or by tilt-driving them is also available.</p>
<heading id="h-0006" level="1">Second Embodiment</heading>
<p id="p-0094" num="0093">An embodiment when the above-described aberration correction method is applied to a step &#x26; repeat exposure apparatus will be explained next with reference to <figref idref="DRAWINGS">FIG. 5</figref>. Since the step &#x26; repeat exposure apparatus does not scan a mask with a laser beam (illumination area), the illumination area on the mask is identical to the exposure area. Steps <b>1</b> and <b>2</b> in <figref idref="DRAWINGS">FIG. 5</figref> are the same as those in the first embodiment.</p>
<p id="p-0095" num="0094">Step <b>3</b> will be explained. As the first calculation processing procedure, the illumination area is divided into a plurality of areas in the X direction and/or Y direction, and the mask transmittances in the respective divided areas are individually calculated. In this embodiment, the dimension of the illumination area in the X direction is 26 mm (a value when converting the dimension of the illumination area in the X direction on the mask into that on the wafer), and the dimension of the illumination area in the Y direction is 33 mm (a value when converting the dimension of the illumination area in the Y direction on the mask into that on the wafer). Although this embodiment will exemplify a case in which the illumination area is divided into 4 rectangular areas in the X direction and 4 rectangular areas in the Y direction, i.e., a total of 16 rectangular areas, it may be divided by another method and the shape of each divided area is not particularly limited to a rectangle.</p>
<p id="p-0096" num="0095">The mask transmittance in the divided area (to be referred to as divided area n; n is the area number that is one of 1 to 16 in this embodiment) is calculated as the average of transmittance data in a mask area included in division area n by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(the mask transmittance in divided area <i>n</i>)=(&#x3a3; transmittance data)/(the number of data points)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
(Note that the &#x3a3; range is defined as only a mask area included in divided area n)
</p>
<p id="p-0097" num="0096">In step <b>4</b>, the mask transmittance in divided area n is normalized, and a mask transmittance r<sub>n </sub>in each divided area is calculated.</p>
<p id="p-0098" num="0097">In steps <b>5</b> and <b>6</b>, an exposure area ratio g<sub>n </sub>of divided area n is calculated based on exposure area information. The exposure area information herein includes dimensions wx and wy of the exposure area in the X and Y directions, respectively, and an X-image height x<sub>0 </sub>and Y-image height y<sub>0 </sub>at the center of the exposure area. These pieces of information can be substituted by X-coordinates xr and x<b>1</b> at the two ends of the exposure area in the X direction, and Y-coordinates yu and yd at the two ends of the exposure area in the Y direction.</p>
<p id="p-0099" num="0098">The g<sub>n </sub>value is given as the area ratio between divided area n and a portion in divided area n, which is included in the illumination area under a certain set of exposure conditions. That is, the g<sub>n </sub>value can be calculated on a case-by-case basis as follows:</p>
<p id="p-0100" num="0099">A case in which divided area n is included in the illumination area: g<sub>n</sub>=1</p>
<p id="p-0101" num="0100">A case in which divided area n is not included in the illumination area: g<sub>n</sub>=0</p>
<p id="p-0102" num="0101">A case in which divided area n is partially included in the illumination area: g<sub>n</sub>=((the ratio of a portion in divided area n, which is included in the illumination area)/(the area of divided area n))</p>
<p id="p-0103" num="0102">In step <b>7</b>, the weighting coefficient is calculated for each divided area. Let &#x3bb;<sub>n </sub>be the weighting coefficient calculated by multiplying the r<sub>n </sub>value calculated from the mask transmittance by the g<sub>n </sub>value calculated from the exposure area information. Then, the coefficient &#x3bb;<sub>n </sub>corresponds to a value obtained by normalizing the amount of light energy which propagates through divided area n. Steps <b>3</b> to <b>7</b> are repeated for each divided area n, and the weighting coefficient &#x3bb;<sub>n </sub>in each divided area n is calculated and stored.</p>
<p id="p-0104" num="0103">Using the calculated weighting coefficient &#x3bb;<sub>n </sub>for each divided area, an aberration function given by expression (2) is weighted, where n is the divided area number, I is the effective light source shape on the pupil plane, C is the type of aberration, and x and y are arbitrary X- and Y-image heights. Expression (2) represents the degree of influence of the mask transmittance and exposure area on the aberration C as an imaging characteristic, which is generated by the projection optical system when divided area n is exposed with the effective light source shape I by the unit exposure amount, as a function of the image height (x,y). The image height (x,y) is not particularly limited to image heights inside divided area n. This means that the light which enters divided area n can change the aberration not only at image heights inside divided area n but also at image heights outside divided area n. The aberration expression and its coefficients generally differ for each aberration C and can be, e.g., a focus expression or image shift expression. In general, the coefficients also differ for each effective light source shape I. In this embodiment, an appropriate function is selected based on the effective light source information read out in step <b>1</b>.</p>
<p id="p-0105" num="0104">The aberration function given by expression (2) is calculated in advance based on the aberration measurement result and/or simulation result. However, since it is difficult to calculate the value of expression (2) for an arbitrary divided area n, arbitrary effective light source shape I, and arbitrary image height (x,y), expression (2) may be determined by appropriately interpolating using the values calculated for several values each of n, I, and x.</p>
<p id="p-0106" num="0105">Letting (x<sub>0n</sub>,y<sub>0n</sub>) be the image height at the center of divided area n, the aberration function in expression (2) may be substituted by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>f</i><sub>n</sub><sup>I,C</sup>(<i>x,y</i>)&#x2192;<i>F</i><sup>I,C</sup>(<i>x,x</i><sub>0n</sub><i>,y,y</i><sub>0n</sub>)&#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
so that the aberration function F<sup>I,C</sup>(x,x<sub>0n</sub>,y,y<sub>0n</sub>) is used for all divided areas 1 to 16.
</p>
<p id="p-0107" num="0106">The amount of aberration generation due to the influence of each divided area under specific exposure conditions can be calculated by multiplying the function in expression (2) by the weighting coefficient &#x3bb;<sub>n</sub>. This calculation is valid because the weighting coefficient &#x3bb;<sub>n </sub>corresponds to the amount of light which enters divided area n under the exposure conditions, and the amount of aberration generation is proportional to the amount of incident light as is commonly known.</p>
<p id="p-0108" num="0107">The sum of the amounts of aberration generation due to the influence of the divided areas is the amount of aberration generation under the exposure conditions. In the above-described example, the correction coefficient of a variation in focus at the image height coordinate position (0.0,0.0) under the exposure conditions is given by:</p>
<p id="p-0109" num="0108">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <msup>
            <mi>K</mi>
            <mi>Focus</mi>
          </msup>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mn>0.0</mn>
              <mo>,</mo>
              <mn>0.0</mn>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <munderover>
            <mo>&#x2211;</mo>
            <mrow>
              <mi>n</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mn>16</mn>
          </munderover>
          <mo>&#x2062;</mo>
          <mrow>
            <msub>
              <mi>&#x3bb;</mi>
              <mi>n</mi>
            </msub>
            <mo>&#x2062;</mo>
            <mrow>
              <msubsup>
                <mi>f</mi>
                <mi>n</mi>
                <mrow>
                  <mi>I</mi>
                  <mo>,</mo>
                  <mi>Focus</mi>
                </mrow>
              </msubsup>
              <mo>&#x2061;</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mn>0.0</mn>
                  <mo>,</mo>
                  <mn>0.0</mn>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>6</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
which corresponds to K in equation (1).
</p>
<p id="p-0110" num="0109">These processing operations are performed for a combination of the number of image height coordinate positions to be corrected and that of aberrations to be corrected, thereby calculating the correction coefficient for each image height and aberration.</p>
<heading id="h-0007" level="1">Third Embodiment</heading>
<p id="p-0111" num="0110">In this embodiment, the mask transmittances at a plurality of image heights are combined to be used as a mask transmittance at an arbitrary image height, as shown in <figref idref="DRAWINGS">FIG. 18</figref>. In this case, the average of a plurality of image heights can be used or the weighted average of a plurality of image heights by the exposure area can be calculated.</p>
<p id="p-0112" num="0111">Assume that the aberration variation expression calculated at an arbitrary image height in equation (1) is substituted by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>F=K&#xd7;T/T</i>0&#xd7;<i>Q</i>&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where T is the mask transmittance, and T<b>0</b> is a normalized mask transmittance.
</p>
<p id="p-0113" num="0112">Even in this case, it is possible to predict a variation in aberration due to a difference in mask pattern density at an arbitrary image height.</p>
<p id="p-0114" num="0113">The mask transmittance at an arbitrary image height is calculated from mask transmittance information. Substituting the calculated value in equation (4) yields &#x394;F. When a variation in arbitrary aberration at an arbitrary image height is calculated from the actual exposure energy conditions, exposure time, and non-exposure time, it is possible to predict the variation in arbitrary aberration at the arbitrary image height.</p>
<p id="p-0115" num="0114">As has been described in the first embodiment, there are a method of correcting a predicted variation in arbitrary aberration at an arbitrary image height by driving an optical element in, e.g., a projection optical system in the Z direction or tilt direction, and a method of correcting it by driving a mask stage or wafer stage.</p>
<p id="p-0116" num="0115">Devices (e.g., a semiconductor device and liquid crystal display device) are manufactured by a step of exposing a substrate coated with a photosensitive agent to radiant energy using the above-described exposure apparatus, a step of developing the photosensitive agent on the substrate exposed in the exposing step, and other known steps.</p>
<p id="p-0117" num="0116">While the present invention has been described with reference to exemplary embodiments, it is to be understood that the invention is not limited to the disclosed exemplary embodiments. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures and functions.</p>
<p id="p-0118" num="0117">This application claims the benefit of Japanese Patent Application No. 2007-165312, filed Jun. 22, 2007, which is hereby incorporated by reference herein in its entirety.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08625069-20140107-M00001.NB">
<img id="EMI-M00001" he="8.81mm" wi="76.20mm" file="US08625069-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08625069-20140107-M00002.NB">
<img id="EMI-M00002" he="8.81mm" wi="76.20mm" file="US08625069-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An exposure apparatus for performing an exposure of a substrate to radiant energy via a pattern formed on a mask, the apparatus comprising:
<claim-text>a projection optical system configured to project radiant energy from the mask onto the substrate;</claim-text>
<claim-text>a first stage configured to hold the mask;</claim-text>
<claim-text>a second stage configured to hold the substrate; and</claim-text>
<claim-text>a controller configured to obtain, with respect to each of image heights, a coefficient of a term, including a time constant, in an equation for obtaining an aberration of the projection optical system that varies with time via the exposure, based on a distribution of a transmittance of the pattern over the image heights, and to control a drive of at least one of an optical element included in the projection optical system, the first stage and the second stage so as to reduce the aberration obtained with respect to each of the image heights,</claim-text>
<claim-text>wherein the controller is configured to obtain the transmittance with respect to each of a plurality of regions obtained by dividing an exposure region of the pattern, to perform multiplication of a previously-obtained aberration of the projection optical system generated with respect to each of the image heights via the exposure with a unit exposure energy through each of the plurality of regions, by a weighting coefficient that is based on the transmittance of corresponding one of the plurality of regions, and to obtain the coefficient of the term, with respect to each of the image heights, by a sum of values obtained by the multiplication with respect to the plurality of regions.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the aberration of the projection optical system generated with respect to each of the image heights via the exposure with the unit exposure energy is obtained in advance based on at least one of measurement and simulation.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the distribution of the transmittance of the pattern over the image heights is measured by the exposure apparatus or calculated from design information of the mask.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to obtain the coefficient, with respect to each of the image heights, further based on information about at least one of an effective light source, a scanning speed of the mask and an exposure time.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to obtain the coefficient, with respect to each of the image heights, further based on a condition of the exposure.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to control, as the drive, at least one of a drive in a direction parallel to an optical axis of the projection optical system and a tilt drive, with respect to at least one of the optical element, the first stage and the second stage.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to weight the aberration obtained with respect to one of the image heights, and to control the drive of at least one of the optical element, the first stage and the second stage so as to reduce the weighted aberration.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the aberration includes at least one of focus, magnification, distortion, astigmatism, spherical aberration, and coma aberration.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method of manufacturing a device, the method comprising:
<claim-text>exposing a substrate to radiant energy using an exposure apparatus;</claim-text>
<claim-text>developing the exposed substrate; and</claim-text>
<claim-text>processing the developed substrate to manufacture the device,</claim-text>
<claim-text>wherein the exposure apparatus performs an exposure of a substrate to radiant energy via a pattern formed on a mask, the apparatus including:</claim-text>
<claim-text>a projection optical system configured to project radiant energy from the mask onto the substrate;</claim-text>
<claim-text>a first stage configured to hold the mask;</claim-text>
<claim-text>a second stage configured to hold the substrate; and</claim-text>
<claim-text>a controller configured to obtain, with respect to each of image heights, a coefficient of a term, including a time constant, in an equation for obtaining an aberration of the projection optical system that varies with time via the exposure, based on a distribution of a transmittance of the pattern over the image heights, and to control a drive of at least one of an optical element included in the projection optical system, the first stage and the second stage so as to reduce the aberration obtained with respect to each of the image heights,</claim-text>
<claim-text>wherein the controller is configured to obtain the transmittance with respect to each of a plurality of regions obtained by dividing an exposure region of the pattern, to perform multiplication of a previously-obtained aberration of the projection optical system generated with respect to each of the image heights via the exposure with a unit exposure energy through each of the plurality of regions, by a weighting coefficient that is based on the transmittance of corresponding one of the plurality of regions, and to obtain the coefficient of the term, with respect to each of the image heights, by a sum of values obtained by the multiplication with respect to the plurality of regions.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
