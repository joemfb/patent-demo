<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626611-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626611</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12008433</doc-number>
<date>20080111</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1155</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>C</subclass>
<main-group>21</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>705 269</main-classification>
<further-classification>705 261</further-classification>
<further-classification>705 2642</further-classification>
<further-classification>705 2643</further-classification>
<further-classification>705 268</further-classification>
<further-classification>705 272</further-classification>
<further-classification>345419</further-classification>
<further-classification>345420</further-classification>
<further-classification>345621</further-classification>
<further-classification>345633</further-classification>
<further-classification>345335</further-classification>
<further-classification>345632</further-classification>
<further-classification>235380</further-classification>
<further-classification>235383</further-classification>
<further-classification>235375</further-classification>
</classification-national>
<invention-title id="d2e53">Method and apparatus for augmented reality shopping assistant</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6094625</doc-number>
<kind>A</kind>
<name>Ralston</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6512838</doc-number>
<kind>B1</kind>
<name>Rafii et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382106</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6675091</doc-number>
<kind>B2</kind>
<name>Navab</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2003/0080978</doc-number>
<kind>A1</kind>
<name>Navab et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2004/0131232</doc-number>
<kind>A1</kind>
<name>Meisner et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2004/0164926</doc-number>
<kind>A1</kind>
<name>Schonlau</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2007/0210155</doc-number>
<kind>A1</kind>
<name>Swartz et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2008/0043013</doc-number>
<kind>A1</kind>
<name>Gruttadauria et al.</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2008/0071559</doc-number>
<kind>A1</kind>
<name>Arrasvuori</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705  1</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00010">
<othercit>Volume holographic storage and retrieval of digital data, Science 265.5173 (Aug 5, 1994): 749.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
</us-references-cited>
<number-of-claims>15</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>701207</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20090182499</doc-number>
<kind>A1</kind>
<date>20090716</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Bravo</last-name>
<first-name>Luis Eduardo</first-name>
<address>
<city>Norcross</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Bravo</last-name>
<first-name>Luis Eduardo</first-name>
<address>
<city>Norcross</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Maginot</last-name>
<first-name>Paul</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Stevens, III</last-name>
<first-name>Harden E.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>NCR Corporation</orgname>
<role>02</role>
<address>
<city>Duluth</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Zeender</last-name>
<first-name>Ryan</first-name>
<department>3627</department>
</primary-examiner>
<assistant-examiner>
<last-name>Haider</last-name>
<first-name>Fawaad</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An augmented reality shopping system in one embodiment includes a store communication network, a memory including program instructions for receiving a product location request, associating the received request with product information stored in a product database, determining the location of the product within the store, receiving shopper location information, determining a route between the determined location of the product and the shopper location based upon the shopper location information, generating route rendering data based upon the determined route, and transmitting the route rendering data through the store communication network. The system further includes a processor operably connected to the store communication network and to the memory for executing the program instructions and a mobile display device operably connected to the processor through the store communication network for rendering an overlay image using the transmitted route rendering data.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="179.41mm" wi="248.67mm" file="US08626611-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="250.61mm" wi="182.54mm" orientation="landscape" file="US08626611-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="244.86mm" wi="174.75mm" file="US08626611-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="252.98mm" wi="188.98mm" orientation="landscape" file="US08626611-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="255.69mm" wi="192.02mm" orientation="landscape" file="US08626611-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="256.37mm" wi="186.61mm" orientation="landscape" file="US08626611-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="264.16mm" wi="180.85mm" file="US08626611-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="250.61mm" wi="173.06mm" orientation="landscape" file="US08626611-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The present invention relates generally to retail shopping systems, and more particularly, to methods and apparatus for assisting a shopper to locate products.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Some shoppers enjoy hunting through a store in an effort to find a particular product. Shoppers who have only a vague idea of the desired product or who are looking for anything that inspires them may benefit from searching through the various products of a store.</p>
<p id="p-0004" num="0003">Other shoppers, however, prefer to proceed directly to the product location. For example, the shopper may be on a tight schedule or the shopper may simply desire to minimize the shopping experience. In some instances, this type of shopper may be not overly familiar with the various products that a store offers. Moreover, the actual location of the products within the store may not be known. This leads to undesired extension of the shopping experience, particularly when the store offers a large number of products.</p>
<p id="p-0005" num="0004">Additionally, many retail stores are continuously receiving and stocking new products. Accordingly, the particular location of an item within the store may change. A shopper looking for the product in a location of the store that was previously occupied by the product may thus be unable to find the product, even if the product is still available albeit at a different location within the store. While it is possible to ask a store employee for assistance in locating a product, some shoppers are averse to such interactions. Furthermore, the particular store employee may not be aware that the product has been moved.</p>
<p id="p-0006" num="0005">What is needed is a system which automatically guides a shopper to the location of a desired product. What is further needed is a system that can accompany the shopper through the store to provide updated guidance. A further need exists for a system which can inform the shopper when a desired product is not available and suggest an alternative product which is available.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">The present invention in one embodiment provides an augmented reality shopping system including a store communication network, a memory including program instructions for receiving a product location request, associating the received request with product information stored in a product database, determining the location of the product within the store, receiving shopper location information, determining a route between the determined location of the product and the shopper location based upon the shopper location information, generating route rendering data based upon the determined route, and transmitting the route rendering data through the store communication network. The system further includes a processor operably connected to the store communication network and to the memory for executing the program instructions and a mobile display device operably connected to the processor through the store communication network for rendering an overlay image using the transmitted route rendering data.</p>
<p id="p-0008" num="0007">In a further embodiment, a method of rendering an overlay image includes receiving a product location request through a store communications network, associating the received request with product information stored in a product database, determining the location of the product within the store, receiving shopper location information, determining a route to the determined product location from a determined shopper location based upon the shopper location information, transmitting route rendering data through the store communication network and rendering an overlay image using the transmitted route rendering data on a mobile display device.</p>
<p id="p-0009" num="0008">The above described features and advantages, as well as others, will become more readily apparent to those of ordinary skill in the art by reference to the following detailed description and accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 1</figref> is a block representation of a store with an exemplary embodiment of a control system in which the subject invention may be used;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 2</figref> is a block representation of an exemplary communication subsystem in the form of a piconet which is formed by the transmitters of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of the components of the transmitter of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 4</figref> depicts an elevational perspective view of a mobile display device that may be integrated into the communication subsystem of <figref idref="DRAWINGS">FIG. 2</figref> to overlay information onto the portion of a store viewed by an individual wearing the mobile display device in accordance with aspects of the invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 5</figref> is a plan view of the rear of the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> with the arms removed and depicting a projector, a communication module and a battery;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 6</figref> is a plan view of the side of the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> with the arms removed;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram of the sensor module of the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> that may be used to provide data to the control system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram of the communications module of the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> that may be used to provide data to and wireless connectivity with the control system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of an exemplary overview of a manner of operation of one aspect of the subject invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 10</figref> is a schematic of various data paths between transmitters, mobile display devices and the control system of <figref idref="DRAWINGS">FIG. 1</figref> in accordance with aspects of the invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart of an exemplary environment determination process which generates data indicative of the portion of the store viewed by a user through the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> in accordance with principles of the invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart of an exemplary manner of using the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> which is integrated into the communication subsystem of <figref idref="DRAWINGS">FIG. 2</figref> to provide a user with an augmented reality view of the store of <figref idref="DRAWINGS">FIG. 1</figref> in accordance with principles of the invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 13</figref> depicts a user view of a portion of the store of <figref idref="DRAWINGS">FIG. 1</figref> through the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> when no indicia is rendered on the mobile display device; and</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 14</figref> depicts the user view of the portion of the store of <figref idref="DRAWINGS">FIG. 12</figref> through the mobile display device of <figref idref="DRAWINGS">FIG. 4</figref> when indicia are rendered on the mobile display device to augment the view of the user in accordance with principles of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0024" num="0023">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, there is depicted a representation of a store or premises generally designated <b>100</b>. Without being limiting, the store <b>100</b> may be any type of store that sells, rents, and/or leases merchandise. Typically the store <b>100</b> is of the type that sells merchandise such as a grocery store. Without being limiting, the subject invention will be described herein in the context of a grocery store selling merchandise of any and all types.</p>
<p id="p-0025" num="0024">The store <b>100</b> has a control system <b>102</b> that includes I/O devices <b>104</b>, a processing circuit <b>106</b> and a memory <b>108</b>. The I/O devices <b>104</b> may include a user interface, graphical user interface, keyboards, pointing devices, remote and/or local communication links, displays, and other devices that allow externally generated information to be provided to the processing circuit <b>106</b>, and that allow internal information of the control system <b>102</b> to be communicated externally.</p>
<p id="p-0026" num="0025">The processing circuit <b>106</b> may suitably be a general purpose computer processing circuit such as a microprocessor and its associated circuitry. The processing circuit <b>106</b> is operable to carry out the operations attributed to it herein.</p>
<p id="p-0027" num="0026">Within the memory <b>108</b> is a digital model <b>110</b> of the store <b>100</b>. The model <b>110</b> is a collection of interrelated data objects representative of, or that correspond to, elements of the store <b>100</b>. Elements of the store <b>100</b> may include floor plans, shelving units, displays, storage areas, etc. Databases <b>112</b> are also located within the memory <b>108</b>.</p>
<p id="p-0028" num="0027">The databases <b>112</b> include a price database <b>114</b>, an inventory database <b>116</b>, a location database <b>118</b>, an equivalent database <b>120</b> and a classification database <b>122</b>. In one embodiment, the databases are populated using object oriented modeling. The use of object oriented modeling allows for a rich description of the relationship between various objects. While shown within the store <b>100</b>, the control system <b>104</b> and/or any one or more of the databases <b>112</b> may be remote from the store <b>100</b>.</p>
<p id="p-0029" num="0028">Program instructions <b>124</b> are also included in the memory <b>108</b>. The program instructions <b>124</b>, which are described more fully below, are executable by the processing circuit <b>106</b> and/or any other components as appropriate.</p>
<p id="p-0030" num="0029">A communications network <b>126</b> provides communications between the control system <b>102</b> a plurality of assisted/self check-out terminals (ASCOTs) <b>128</b>, and a number of transmitters <b>130</b> positioned throughout the store <b>100</b>. In the embodiment described herein, the communications network <b>126</b> is a wireless communication scheme implemented as a wireless area network. A wireless communication scheme identifies the specific protocols and RF frequency plan employed in wireless communications between sets of wireless devices. To this end, the processing circuit <b>106</b> employs a packet-hopping wireless protocol to effect communication by and among the processing circuit <b>106</b>, the ASCOTs <b>128</b> and the transmitters <b>130</b>.</p>
<p id="p-0031" num="0030">The transmitters <b>130</b> may be self-configuring and self-commissioning. Accordingly, when the transmitters <b>130</b> are placed within communication range of each other, they will form a piconet as is known in the relevant art. In the case that a transmitter <b>130</b> is placed within range of an existent piconet, the transmitters <b>130</b> will join the existent piconet. Accordingly, the transmitters <b>130</b> are formed into one or more communication subsystems <b>140</b> as shown in <figref idref="DRAWINGS">FIG. 2</figref>. The transmitters <b>130</b> within the communication subsystem <b>140</b> include a hub transmitter <b>142</b>, and slave transmitters <b>144</b>, <b>146</b> and <b>148</b>. Additionally, a slave transmitter <b>150</b> is within the communication subsystem <b>140</b> as a slave to the slave transmitter <b>144</b>. It will be appreciated that a particular communication subsystem <b>140</b> may contain more or fewer transmitters <b>130</b> than the transmitters <b>130</b> shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0032" num="0031">In the exemplary embodiment described herein, the communication subsystem <b>140</b> is operable to assist in transmitting and receiving information between a user and the control system <b>102</b>. To accomplish these and other functions, the hub transmitter <b>142</b>, shown in <figref idref="DRAWINGS">FIG. 3</figref>, includes a network interface <b>152</b>, a hub processor <b>154</b>, a non-volatile memory <b>156</b>, a signal processing circuit <b>158</b>, and a micro-electrical mechanical system (MEMS) local RF communication circuit <b>160</b>.</p>
<p id="p-0033" num="0032">The network interface <b>152</b> is a communication circuit that effectuates communication to one or more components of the communications network <b>126</b>. To allow for wireless communication with the other components of the communications network <b>126</b>, the network interface <b>152</b> is preferably a radio frequency (RF) modem configured to communicate using the wireless area network communication scheme. Thus, each of the transmitters <b>130</b> may communicate with components such as other communication subsystems, the ASCOTs <b>128</b> and the processing circuit <b>106</b>. In the communication subsystem <b>140</b>, the hub transmitter <b>142</b> uses the network interface <b>152</b> to link with the communications network <b>126</b> as well as to establish piconet links <b>162</b><sub>(1-3) </sub>(see <figref idref="DRAWINGS">FIG. 2</figref>) with the network interfaces <b>152</b> of the slave transmitters <b>144</b>, <b>146</b> and <b>148</b>. The network interfaces <b>152</b> of the slave transmitters <b>144</b> and <b>150</b> also establish a piconet link <b>162</b><sub>(4)</sub>.</p>
<p id="p-0034" num="0033">The network interface <b>152</b> is further operable to, either alone or in conjunction with the hub processor <b>154</b>, interpret messages in wireless communications received from external devices and determine whether the messages should be retransmitted to another external device, or processed by the hub transmitter <b>142</b>. Preferably, the network interface <b>152</b> employs a packet-hopping protocol to reduce the overall transmission power required. In packet-hopping, each message may be transmitted through multiple intermediate communication subsystem interfaces before it reaches its destination as is known in the relevant art.</p>
<p id="p-0035" num="0034">The MEMS local RF communication circuit <b>160</b> may suitably include a Bluetooth RF modem, or some other type of short range (about 30-100 feet) RF communication modem. The use of a MEMS-based RF communication circuit allows for reduced power consumption, thereby enabling the hub transmitter <b>142</b> to be battery operated, if desired. The life of the hub transmitter <b>142</b> may be extended using power management approaches. Additionally, the battery may be augmented or even replaced by incorporating structure within the MEMS module to use or convert energy in the form of vibrations or ambient light.</p>
<p id="p-0036" num="0035">The hub processor <b>154</b> is a processing circuit operable to control the general operation of the hub transmitter <b>142</b>. In addition, the hub processor <b>154</b> may implement control functions and information gathering functions used to maintain the databases <b>112</b>. For example, the hub processor <b>154</b> may obtain data from RFID tags located within the range of the communication subsystem <b>140</b> and forward RFID tag information to the processing circuit <b>106</b>.</p>
<p id="p-0037" num="0036">Returning to <figref idref="DRAWINGS">FIG. 1</figref>, a number of mobile display devices (MDDs) <b>170</b> are also provided within the store <b>100</b>. One MDD <b>170</b> is depicted in <figref idref="DRAWINGS">FIG. 4</figref>. The MDD <b>170</b> in this embodiment is a hands-free display unit. The MDD <b>170</b> includes two arms <b>172</b> and <b>174</b> joined by a support rim <b>176</b>. A dual projector <b>178</b> (shown in <figref idref="DRAWINGS">FIGS. 5 and 6</figref>) is positioned to project an image onto lenses <b>180</b> and <b>182</b>. The lenses <b>180</b> and <b>182</b> are substantially clear. The projector <b>178</b> and lenses <b>180</b> and <b>182</b> are configured to render an image that appears as an overlay of objects seen by a user through the lenses <b>180</b> and <b>182</b>. One such system is described in U.S. Patent Application Publication 2004/0164926 A1 dated Aug. 26, 2004, the contents of which are herein incorporated by reference. A microphone <b>184</b> is imbedded within the arm <b>172</b> to capture audio commands from the user. A sensor module <b>186</b> is embedded within the arm <b>174</b>.</p>
<p id="p-0038" num="0037">The sensor module <b>186</b> includes a microcontroller <b>188</b>, a programmable non-volatile memory <b>190</b>, a communication circuit <b>192</b>, a signal processing circuit <b>194</b> and a MEMS sensor suite <b>196</b> as shown in <figref idref="DRAWINGS">FIG. 7</figref>. The signal processing circuit <b>194</b> includes the circuitry that interfaces with the sensor suite <b>196</b>, converts analog sensor signals to digital signals, and provides the digital signals to the microcontroller <b>188</b>.</p>
<p id="p-0039" num="0038">The programmable non-volatile memory <b>190</b>, which may be embodied as a flash programmable EEPROM, stores configuration information for the sensor suite <b>196</b>. The programmable non-volatile memory <b>190</b> includes an &#x201c;address&#x201d; or &#x201c;ID&#x201d; of the sensor module <b>186</b> that is appended to any communications generated by the sensor module <b>186</b>. The memory <b>190</b> further includes set-up configuration information related to the system communication parameters employed by the microcontroller <b>188</b> and/or communication circuit <b>192</b> to transmit information to other devices.</p>
<p id="p-0040" num="0039">The microcontroller <b>188</b> is a processing circuit operable to control the general operation of the sensor module <b>186</b>. The sensor suite <b>196</b> in this embodiment is configured as a <b>3</b>-axis gyroscope to provide information as to the orientation of the MDD <b>170</b>. In general, the microcontroller <b>188</b> receives digital sensor information from the signal processing circuit <b>194</b> and provides the information to the local communication circuit <b>192</b> for transmission. The microcontroller <b>188</b> is further operable to receive configuration information via the communication circuit <b>192</b>, store configuration information in the memory <b>190</b>, and perform operations in accordance with such configuration information.</p>
<p id="p-0041" num="0040">The communication circuit <b>192</b> is operably connected to a communications module <b>198</b> located in the support rim <b>176</b> along with a battery <b>200</b> that provides power for the MDD <b>170</b>. The communications module <b>198</b>, as shown in <figref idref="DRAWINGS">FIG. 8</figref>, includes a MEMS local RF communication circuit <b>202</b>, a microcontroller <b>204</b>, a programmable non-volatile memory <b>206</b>, a MEMS sensor suite <b>208</b> and a signal processing circuit <b>210</b>, all of which function generally in a manner similar to the similarly named components discussed above with respect to <figref idref="DRAWINGS">FIGS. 3 and 7</figref>. The MEMS sensor suite <b>208</b> in this embodiment is configured as a camera to track the eye movement of the individual wearing the mobile device. Accordingly, the individual may interface with the device using both voice commands and eye movement. A system for eye tracking and speech recognition that may be used in such an embodiment is disclosed in U.S. Pat. No. 6,853,972 B2, issued on Feb. 8, 2005 to Friedrich et al., which is herein incorporated by reference.</p>
<p id="p-0042" num="0041">Referring to <figref idref="DRAWINGS">FIG. 9</figref>, there is depicted a flowchart, generally designated <b>220</b>, setting forth an exemplary manner of operation of the system according to the present principles. Initially, a digital model <b>110</b> of the store <b>100</b> may be stored within the memory <b>108</b> at the step <b>222</b>. The digital model <b>110</b> preferably identifies the floor plan of the store <b>100</b> along with the location of shelves and mobile displays. In one embodiment, the digital model <b>110</b> is a three dimensional model. Maintenance of the digital model <b>110</b> may be automated. For example, store fixtures may be equipped with identification devices, active or passive, which can be used to track the location of the fixture within the store <b>100</b> using the communications network <b>126</b>.</p>
<p id="p-0043" num="0042">Next, in step <b>224</b>, the databases <b>112</b> are populated. By way of example the inventory database <b>116</b> may be populated with product identification data along with data identifying the current number of each product available within the store. The inventory database <b>116</b> may be updated with information from a store receiving station for incoming product as well as information as to product sold which is obtained from the ASCOT <b>128</b>. The executable commands for maintenance of the inventory database <b>116</b> are stored as program instructions <b>124</b>.</p>
<p id="p-0044" num="0043">The location database <b>118</b> may likewise be populated and maintained using any desired data input process. In one embodiment, a product includes a radio frequency identification tag (RFID tag) which identifies the particular product. When the location of the product is changed, an RFID tag reader is used to read the RFID tag at the new location. Product information, including location information, is then transmitted through the communications network <b>126</b> to the processing circuit <b>106</b>. The RFID tag reader may be located in the shelving of the store or a portable reader may be used. The executable commands for maintenance of the location database <b>118</b> are stored as program instructions <b>124</b>.</p>
<p id="p-0045" num="0044">The equivalent database <b>120</b> may also be populated and maintained using any desired data input process. For each predetermined product, one or more alternative products are identified. The alternative product may be a product for which the merchant has a more favorable margin or a generic equivalent of a brand name. Alternative products may be identified for products which are normally stocked or for products which are not carried in inventory. The executable commands for maintenance of the equivalent database <b>120</b> are stored as program instructions <b>124</b>.</p>
<p id="p-0046" num="0045">The classification database <b>122</b> may be populated and maintained using any desired data input process. The classification database <b>122</b> may be used to associate different products with common characteristics. For example, products with low sugar content or low carbohydrate content may be associated. Similarly, products which do not include certain ingredients or which are provided by the same manufacturer may be associated. The executable commands for maintenance of the classification database <b>122</b> are stored as program instructions <b>124</b>.</p>
<p id="p-0047" num="0046">Returning to <figref idref="DRAWINGS">FIG. 9</figref>, at step <b>226</b> a user obtains a MDD <b>170</b>. The MDDs <b>170</b> may be available for use at the entrance of the store. In one embodiment, a credit card may be used to check-out an MDD from an automated display device. The automated display device (not shown) may be used to recharge the battery <b>200</b>. The MDD <b>170</b> may be configured to automatically energize when removed from the display. Alternatively, an energization switch may be provided. Upon energization of the MDD <b>170</b> at step <b>228</b>, the microcontroller <b>204</b> causes the MEMS local RF communication circuit <b>202</b> to emit a signal which is detected by one or more transmitters <b>130</b>. At the step <b>230</b>, the MDD <b>170</b> is then integrated into a communication subsystem <b>140</b> through a temporary piconet link <b>212</b> (see <figref idref="DRAWINGS">FIG. 1</figref>) as a slave device through a transmitter <b>130</b>. The transmitter <b>130</b> may be a slave transmitter or a hub transmitter.</p>
<p id="p-0048" num="0047">Once the MDD <b>170</b> is integrated into a communication subsystem <b>140</b>, information may be passed between the MDD <b>170</b> and the control system <b>102</b> through the communication network <b>126</b>. By way of example, <figref idref="DRAWINGS">FIG. 10</figref> depicts communication subsystems <b>140</b><sub>(1-3) </sub>which are connected to the control system <b>102</b> through communication network <b>126</b>. In the configuration of <figref idref="DRAWINGS">FIG. 10</figref>, transmitter <b>130</b><sub>(2)</sub>, transmitter <b>130</b><sub>(4) </sub>and transmitter <b>130</b><sub>(7) </sub>are configured as hub transmitters with the communication subsystem <b>140</b><sub>(2) </sub>connected to the control system <b>102</b> through the communication subsystem <b>140</b><sub>(1)</sub>.</p>
<p id="p-0049" num="0048">Each of the communication subsystems <b>140</b><sub>(1-3) </sub>in the embodiment of <figref idref="DRAWINGS">FIG. 10</figref> include multiple transmitters <b>130</b> linked with piconet links <b>162</b>. Additionally, MDDs <b>170</b><sub>(1-3) </sub>are each linked to communication subsystems <b>140</b><sub>(1-3)</sub>, respectively, through a respect temporary piconet link <b>212</b><sub>(1-3)</sub>. Thus, data may be passed back and forth between an MDD <b>170</b> and the processing circuit <b>106</b>.</p>
<p id="p-0050" num="0049">Continuing with the process <b>220</b>, as the user moves within the store, the MDD <b>170</b> may move in and out of range of various transmitters <b>130</b>. In response, communications control over the MDD <b>170</b> is automatically removed from a given transmitter <b>130</b> and transferred to another transmitter <b>130</b> at step <b>232</b>. The various transmitters may be within a common communication subsystem or they may be integrated into separate communication subsystems. By way of example, as the MDD <b>170</b><sub>(1) </sub>moves closer to the communication subsystem <b>140</b><sub>(2) </sub>of <figref idref="DRAWINGS">FIG. 10</figref>, the temporary piconet link <b>212</b><sub>(4) </sub>is established between the MDD <b>170</b><sub>(1) </sub>and the communication subsystem <b>140</b><sub>(2)</sub>. This allows the temporary piconet link <b>212</b><sub>(1) </sub>to be terminated.</p>
<p id="p-0051" num="0050">Returning to the process <b>220</b>, when the user is done using the MDD <b>170</b>, the MDD <b>170</b> is returned to the display (not shown) or other location at step <b>234</b> and made ready for the next user. Updates to the databases <b>112</b> and/or the model <b>110</b> may occur at any time as established by the program instructions <b>124</b>.</p>
<p id="p-0052" num="0051">When the MDD <b>170</b> is being worn by a user, the location and orientation of the MDD <b>170</b> may be determined. In <figref idref="DRAWINGS">FIG. 11</figref>, an environment determination process <b>240</b> commences with the integration of a MDD <b>170</b> into a communications subsystem <b>140</b> at step <b>242</b> in the manner set forth above. The process <b>240</b> may be executed on an &#x201c;as needed&#x201d; basis. Alternatively, the process <b>240</b> may be executed at a constant periodicity. Next, the hub transmitter <b>142</b> of the communication subsystem <b>140</b> into which the MDD <b>170</b> has been integrated automatically performs a geolocation process at step <b>244</b>. To this end, the newly integrated MDD <b>170</b> may be commanded to transmit a signal. The transmitted signal is received by the slave transmitters <b>144</b>, <b>146</b>, <b>148</b>, <b>150</b> and the hub transmitter <b>142</b> in the piconet and time-stamped. Because the location of the transmitters <b>130</b> is known, the position of the newly integrated MDD <b>170</b> may be determined by triangulation by comparing the time at which the transmitted signal was received by various transmitters <b>130</b>.</p>
<p id="p-0053" num="0052">Alternatively, the slave transmitters <b>144</b>, <b>146</b>, <b>148</b> and <b>150</b> may transmit signals at predetermined times. By comparing the time at which the newly integrated MDD <b>170</b> receives the transmitted signals, the position of the newly integrated MDD <b>170</b> may be determined by triangulation. In a further embodiment, a portable geographic position determining device may be incorporated into the MDD <b>170</b>. The geographic position determining device may then be temporarily integrated into the piconet to transmit the geolocation data to the hub transmitter <b>142</b>.</p>
<p id="p-0054" num="0053">In any event, once the location data is available, the location data of the MDD <b>170</b> is forwarded to the processing circuit <b>106</b>. Additionally, the orientation of the MDD <b>170</b> may be obtained by polling the sensor module <b>186</b> at step <b>246</b> and transmitting the orientation data from the sensor module <b>186</b> to the processing circuit <b>106</b>. Likewise, the sensor suite <b>208</b> may be polled for data indicative of the positioning of the eyes of the user at the step <b>248</b> and the eye position data transmitted to the processing circuit <b>106</b>. If the MDD <b>170</b> is still energized at step <b>250</b>, then the process returns to performance of a geolocation of the MDD <b>170</b> at the step <b>244</b>. If the MDD <b>170</b> is no longer energized, the process ends at step <b>252</b>.</p>
<p id="p-0055" num="0054">The system described above allows for a variety of data to be provided to a user to assist the user when the user is wearing a MDD <b>170</b>. An example of the operation of the system in response to a user request is described with reference to the process <b>260</b> of <figref idref="DRAWINGS">FIG. 12</figref>. After the process of <figref idref="DRAWINGS">FIG. 9</figref> has been executed through step <b>230</b> and the MDD <b>170</b> is integrated into a communication subsystem <b>140</b>, the user wearing the MDD <b>170</b> may issue a voice command requesting product data at the step <b>262</b>. For example, the user may say &#x201c;show me dog biscuits.&#x201d; The voice command is detected by the microphone <b>184</b> in the MDD <b>170</b> and analyzed using voice recognition software stored in the memory <b>206</b> of the communications module <b>198</b>. An alternative user interface, such as a keypad, may be used in addition to or in place of the microphone <b>184</b>.</p>
<p id="p-0056" num="0055">At step <b>264</b>, the microcontroller <b>204</b> controls the local RF communication circuit <b>202</b> of the communications module <b>198</b> to transmit the product data request to the hub transmitter <b>142</b> of the communication subsystem <b>140</b> which forwards the request to the processing circuit <b>106</b> through the communications network <b>126</b>. The processing circuit <b>106</b> executes program instructions <b>124</b> at step <b>266</b> which cause the inventory database <b>114</b> to be searched to ascertain the availability of the product identified by the user. At step <b>268</b>, the processing circuit determines whether or not the requested product is available. If the product is available, then at step <b>270</b> the processing circuit <b>106</b> executes program instructions <b>124</b> which cause the location database <b>118</b> to be searched to ascertain the location of the product identified by the user. The location data may be provided in two dimensional coordinates or in three dimensional coordinates.</p>
<p id="p-0057" num="0056">Next, the processing circuit <b>106</b> obtains user data at step <b>272</b>. The user data includes the location and orientation of the MDD <b>170</b> obtained in the process <b>240</b>. The user data may further include the eye orientation data obtained in process <b>240</b>. If the system is limited to two dimensional coordinates, then eye orientation data is not necessary. Additionally, when using two dimensional coordinates, MDD orientation data need only be provided to the extent necessary to ascertain the direction the user is looking.</p>
<p id="p-0058" num="0057">At step <b>274</b>, the processing circuit <b>106</b> obtains model data from the stored model <b>110</b>. The entire model <b>110</b> need not be obtained. Rather, only the portion of the model between and including the product location and the location of the user is needed. Using the data obtained in steps <b>270</b>, <b>272</b> and <b>274</b>, the processing circuit <b>106</b> at step <b>276</b> determines the best route from the user location to the product location. Additionally, the perspective of the user is determined based upon the user data from step <b>272</b>. Based upon the determined route and perspective data, the processing circuit <b>106</b> generates indicia rendering data which may be used to render the indicia onto the lenses <b>180</b> and <b>182</b> and transmits the rendering data for the indicia to the MDD <b>170</b> through the communications network <b>126</b> at step <b>278</b>.</p>
<p id="p-0059" num="0058">When the communication module <b>198</b> of the MDD <b>170</b> receives the indicia rendering data, the microcontroller <b>204</b> controls the dual projectors <b>178</b> at step <b>280</b> to render the indicia on the lenses <b>180</b> and <b>182</b>. The indicia are viewable to the user as an overlay of the view of the store through the lenses <b>180</b> and <b>182</b>. By way of example, <figref idref="DRAWINGS">FIG. 13</figref> depicts a portion of the store <b>100</b> as viewed through the lenses <b>180</b> and <b>182</b>. The user can see, for example, fixtures <b>290</b> and <b>292</b> and various products <b>292</b>, <b>296</b> and <b>298</b> on the fixtures <b>290</b> and <b>292</b>.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 14</figref> shows the view through the lenses <b>180</b> and <b>182</b> in response to the voice command &#x201c;show dog biscuits.&#x201d; While the fixtures <b>290</b> and <b>292</b> and the various products <b>294</b>, <b>296</b> and <b>298</b> on the fixtures <b>290</b> and <b>292</b> are still viewable, indicia <b>300</b> and <b>302</b> are also viewable. The indicia <b>300</b> show the user the route to the dog biscuits within the store <b>100</b>. If desired, the indicia <b>300</b> may be used with a two dimensional model <b>110</b>. The indicia <b>302</b>, however, inform the user of the height above the floor at which the product is located. This information may be particularly desired for small products and/or multiple products located in tall fixtures.</p>
<p id="p-0061" num="0060">Additionally, an informational message <b>304</b> is projected onto the lenses <b>180</b> and <b>182</b>. The message can be used to specifically identify the product located. This information is useful when, instead of a single product, a list of products is presented to the processing circuit <b>106</b>. Accordingly, the processing circuit <b>106</b> can determine the best route through the store <b>100</b> which allows the user to obtain all of the products in the list. The program instructions used to identify the best route may be based upon minimizing the time required to obtain all of the products on the provided list, maximizing the user's exposure to special product displays, or other criteria.</p>
<p id="p-0062" num="0061">Returning to <figref idref="DRAWINGS">FIG. 12</figref>, at the step <b>282</b> the processing circuit <b>106</b> determines if the user is at the same location within the store <b>100</b> as the product. The user location for this step is the most recent location available from the process <b>240</b>. If the user is at the location of the product, the process ends at step <b>284</b>. If the user is not at the product location, then the process returns to the step <b>272</b> and updates the indicia rendered onto the lenses <b>180</b> and <b>182</b>.</p>
<p id="p-0063" num="0062">Returning to step <b>268</b>, if the processing circuit <b>106</b> determines that the requested product is not available, then the process proceeds to step <b>310</b> and determines if an alternative product is available by interrogating the equivalent database <b>120</b> and the inventory database <b>116</b>. By way of example, if a user requested the location of a particular brand of dog biscuits which is not in inventory, an alternative brand may be associated with either the particular brand requested or with key words within the request. Of course, this step may also be performed when the requested product is in inventory so as to offer the user a choice of products.</p>
<p id="p-0064" num="0063">If an alternative product is available, the process proceeds to step <b>312</b> and the processing circuit <b>106</b> executes program instructions <b>124</b> which cause the location database <b>118</b> to be searched to ascertain the location of the alternative product identified in the equivalent database <b>120</b>. The location data may be provided in two dimensional coordinates or in three dimensional coordinates.</p>
<p id="p-0065" num="0064">Next, the processing circuit <b>106</b> obtains user data at step <b>314</b>. The user data includes the location and orientation of the MDD <b>170</b> obtained in process <b>240</b>. The user data may further include the eye orientation data obtained in process <b>240</b>. If the system is limited to two dimensional coordinates, then eye orientation data is not necessary. Additionally, when using two dimensional coordinates, MDD orientation data need only be provided to the extent necessary to ascertain the direction the user is looking.</p>
<p id="p-0066" num="0065">At step <b>316</b>, the processing circuit <b>106</b> obtains model data from the stored model <b>110</b>. Using the data obtained in steps <b>312</b>, <b>314</b> and <b>316</b>, the processing circuit <b>106</b> at step <b>318</b> determines the best route from the user location to the alternative product location. Additionally, the perspective of the user is determined based upon the user data from step <b>314</b>. Based upon the route and perspective data, the processing circuit <b>106</b> generates indicia rendering data which may be used to render indicia onto the lenses <b>180</b> and <b>182</b> and transmits the rendering data for the indicia to the MDD <b>170</b> through the communications network <b>126</b> at step <b>320</b>.</p>
<p id="p-0067" num="0066">When the communication module <b>198</b> of the MDD <b>170</b> receives the indicia rendering data, the microcontroller <b>204</b> at step <b>322</b> controls the dual projectors <b>178</b> to render the indicia on the lenses <b>180</b> and <b>182</b>. Additionally, an indicia <b>304</b>, which may be a word or a symbol, may be used to inform the user why an alternative product has been presented. At the step <b>324</b> the processing circuit <b>106</b> determines if the user is at the same location within the store <b>100</b> as the alternative product. The user location for this step is the most recent location available from the process <b>240</b>. If the user is at the location of the alternative product, the process ends at step <b>284</b>. If the user is not at the product location, then the process returns to the step <b>314</b> and updates the indicia rendered onto the lenses <b>180</b> and <b>182</b>.</p>
<p id="p-0068" num="0067">In the event there is no alternative product identified in the equivalent database <b>120</b> or if the alternative product(s) is out of inventory, then at step <b>310</b> the process proceeds to step <b>326</b> and the processing circuit <b>106</b> generates rendering data in the form of words or symbols explaining to the user why no location data is available. For example, a message may be &#x201c;not in stock,&#x201d; or &#x201c;sold out,&#x201d; or &#x201c;on order for delivery tomorrow,&#x201d; etc. The desired informational rendering data is then transmitted to the MDD <b>170</b> through the communications network <b>126</b> at step <b>328</b>. When the communication module <b>198</b> of the MDD <b>170</b> receives the informational rendering data, the microcontroller <b>204</b> at step <b>328</b> controls the dual projectors <b>178</b> to render the information on the lenses <b>180</b> and <b>182</b> and the process ends at step <b>284</b>.</p>
<p id="p-0069" num="0068">The foregoing processes may be modified in a number of ways within the scope of the invention. By way of example, many of the steps may be performed in different sequences. Additionally, different types of information may be used in determining the route information or other information to be rendered. For example, the classification database <b>120</b> may be used to identify all products which have a low caloric value, products which do not incorporate certain allergens, or products offered particular manufacturers or producers. Accordingly, a shopper may issue a product request for a low calorie soup, a sugar free drink, a candy bar with no peanuts or an organic loaf of bread, and be provided with guidance to the desired product.</p>
<p id="p-0070" num="0069">While this invention has been described as having a preferred design, the subject invention can be further modified within the spirit and scope of this disclosure. This application is therefore intended to cover any variations, uses, or adaptations of the subject invention using its general principles. Further, this application is intended to cover such departures from the present disclosure as come within known or customary practice in the art to which this invention pertains and that fall within the limits of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>I claim: </us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An augmented reality shopping system comprising:
<claim-text>a store communication network;</claim-text>
<claim-text>a control system comprising:
<claim-text>I/O devices;</claim-text>
<claim-text>a memory including program instructions for:
<claim-text>receiving a product location request;</claim-text>
<claim-text>associating the received request with product information stored in a product database where the product database is located within the memory and includes product availability information;</claim-text>
<claim-text>determining the location of the product within the store,</claim-text>
<claim-text>receiving shopper location information;</claim-text>
<claim-text>determining a route between the determined location of the product and the shopper location based upon the shopper location information;</claim-text>
<claim-text>generating route rendering data based upon the determined route;</claim-text>
<claim-text>transmitting product availability information through the store communication network; and</claim-text>
<claim-text>transmitting the route rendering data through the store communication network; and</claim-text>
</claim-text>
<claim-text>a processor operably connected to the I/O devices, the store communication network and to the memory for executing the program instructions; and</claim-text>
</claim-text>
<claim-text>a hands-free mobile display device operably connected to the processor through the store communication network including a lens and a projector for rendering an overlay image on the lens using the transmitted route rendering data and the transmitted product availability information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the memory further comprises a stored model of at least a portion of the store; and</claim-text>
<claim-text>the mobile device is further operable to render an overlay image based upon the stored model.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the network is a wireless network and the mobile display device is wirelessly integrated into the network.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mobile display device operates based upon voice commands.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mobile display device operates based upon eye tracking.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the I/O devices include a keyboard and a pointing device.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An augmented reality shopping system comprising:
<claim-text>a store communication network;</claim-text>
<claim-text>a control system comprising:
<claim-text>I/O devices;</claim-text>
<claim-text>a memory including program instructions for:
<claim-text>receiving a product location request;</claim-text>
<claim-text>associating the received request with product information stored in a product database where the product database is located within the memory and includes alternative product availability information;</claim-text>
<claim-text>determining the location of the product within the store;</claim-text>
<claim-text>receiving shopper location information;</claim-text>
<claim-text>determining a route between the determined location of the product and the shopper location based upon the shopper location information;</claim-text>
<claim-text>generating route rendering data based upon the determined route;</claim-text>
<claim-text>transmitting alternative product availability information through the store communication network; and</claim-text>
<claim-text>transmitting the route rendering data through the store communication network; and</claim-text>
</claim-text>
<claim-text>a processor operably connected to the I/O devices, the store communication network and to the memory for executing the program instructions; and</claim-text>
</claim-text>
<claim-text>a hands-free mobile display device operably connected to the processor through the store communication network including a lens and a projector for rendering an overlay image on the lens using the transmitted route rendering data and the transmitted alternative product availability information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A method of rendering an overlay image on a hands-free mobile display device, the method comprising:
<claim-text>transmitting the product location request through the hands-free mobile display device based upon voice commands to the control system;</claim-text>
<claim-text>receiving by a control system a product location request through a store communications network from the hands-free mobile display device;</claim-text>
<claim-text>associating by the control system the received request with product information stored in a product database located within the control system;</claim-text>
<claim-text>determining the location of the product within the store;</claim-text>
<claim-text>receiving by the control system shopper location information from the hands-free mobile display device;</claim-text>
<claim-text>determining by the control system a route to the determined product location from a determined shopper location based upon the shopper location information;</claim-text>
<claim-text>transmitting by the control system route rendering data through the store communication network including a wireless network to the hands-free mobile display device; and</claim-text>
<claim-text>rendering an overlay image on a lens of the hands-free mobile display device by a projector of the hands-free mobile display device using the transmitted route rendering data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:
<claim-text>storing a model of at least a portion of the store within the control system; and wherein rendering comprises:</claim-text>
<claim-text>rendering an overlay image based upon the stored model.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:
<claim-text>transmitting by the control system product availability information through the store communication network to the hands-free mobile display device; and</claim-text>
<claim-text>rendering by the control system an overlay image using the product availability information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:
<claim-text>transmitting by the control system alternative product availability information through the store communication network to the hands-free mobile display device; and</claim-text>
<claim-text>rendering by the control system an overlay image using the alternative product availability information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A method of rendering an overlay image on a hands-free mobile display device, the method comprising:
<claim-text>transmitting the product location request through the hands-free mobile display device to the control system;</claim-text>
<claim-text>receiving eye tracking data from the hands-free mobile display device wherein a micro-electrical mechanical system sensor is used to track eye movement;</claim-text>
<claim-text>receiving by a control system a product location request through a store communications network from the hands-free mobile display device;</claim-text>
<claim-text>associating by the control system the received request with product information stored in a product database located within the control system;</claim-text>
<claim-text>determining the location of the product within the store;</claim-text>
<claim-text>receiving by the control system shopper location information from the hands-free mobile display device;</claim-text>
<claim-text>determining by the control system a route to the determined product location from a determined shopper location based upon the shopper location information;</claim-text>
<claim-text>transmitting by the control system route rendering data through the store communication network including a wireless network to the hands-free mobile display device; and</claim-text>
<claim-text>rendering an overlay image on a lens of the hands-free mobile display device by a projector of the hands-free mobile display device using the transmitted route rendering data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the hands-free mobile display device further comprises a 3-axis gyroscope operable to provide information identifying the orientation of the hands-free mobile display device.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the hands-free mobile display device further comprises a micro-electrical mechanical system sensor operable to track the eye movement of a person wearing the hand-free mobile display device and to provide information identifying the person eye position.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein receiving shopper location information further comprises:
<claim-text>receiving orientation data identifying the orientation of the hands-free mobile display device wherein the orientation data is generated by a 3-axis gyroscope.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
