<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626801-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626801</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13197906</doc-number>
<date>20110804</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>30</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>707803</main-classification>
</classification-national>
<invention-title id="d2e51">Extraction of attributes and values from natural language documents</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5146406</doc-number>
<kind>A</kind>
<name>Jensen</name>
<date>19920900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5418717</doc-number>
<kind>A</kind>
<name>Su et al.</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5943670</doc-number>
<kind>A</kind>
<name>Prager</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6278987</doc-number>
<kind>B1</kind>
<name>Reed et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6405175</doc-number>
<kind>B1</kind>
<name>Ng</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6668254</doc-number>
<kind>B2</kind>
<name>Matson</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6714939</doc-number>
<kind>B2</kind>
<name>Saldanha</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6785671</doc-number>
<kind>B1</kind>
<name>Bailey</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6804659</doc-number>
<kind>B1</kind>
<name>Graham et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6986104</doc-number>
<kind>B2</kind>
<name>Green et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7020662</doc-number>
<kind>B2</kind>
<name>Boreham et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7043420</doc-number>
<kind>B2</kind>
<name>Ratnaparkhi</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>7043492</doc-number>
<kind>B1</kind>
<name>Neal et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>7567976</doc-number>
<kind>B1</kind>
<name>Betz et al.</name>
<date>20090700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>7970767</doc-number>
<kind>B2</kind>
<name>Probst et al.</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>7996440</doc-number>
<kind>B2</kind>
<name>Probst et al.</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2002/0107861</doc-number>
<kind>A1</kind>
<name>Clendinning et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707101</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2002/0111863</doc-number>
<kind>A1</kind>
<name>Landesmann</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2002/0133479</doc-number>
<kind>A1</kind>
<name>Dippold</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2002/0142277</doc-number>
<kind>A1</kind>
<name>Burstein et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2003/0233230</doc-number>
<kind>A1</kind>
<name>Ammicht et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2004/0220782</doc-number>
<kind>A1</kind>
<name>Cook</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2011/0246467</doc-number>
<kind>A1</kind>
<name>Probst et al.</name>
<date>20111000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00024">
<othercit>Ghani, mining the web to add semantics to retail data mining, Springer, 2004, pp. 43-56.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>Collins, unsupervised models for named entity classification, 1999, pp. 100-110.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Guha, (A Clustering Algorithm for Categorical Attributes, Elsevier, 2000, pp. 1-24.</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>Naumann (Declarative Data Mining with Conflict Resolution, IBM, 2002, pp. 1-13).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>Ester, (A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise, AAI, 1996, pp. 226-231).</othercit>
</nplcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>Songfeng, et al. &#x201c;Unsupervised Clustering Based Reduced Support Vector Machines&#x201d;, IEEE 2003, pp. 821-824.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>Guha, Rastogi &#x26; Shim, &#x201c;A Clustering Algorithm for Categorical Attributes&#x201d;, Elsevier, 2000, pp. 1-24.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00031">
<othercit>Nauman &#x26; Haussler, &#x201c;Declarative Data Mining with Conflict Resolution&#x201d;, IBM, 2002, pp. 1-13.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00032">
<othercit>Ghani, &#x201c;Mining the Web to Add Semantics to Retail Data Mining&#x201d;, Springer, 2004, pp. 43-56.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00033">
<othercit>Ester, et al. &#x201c;A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise&#x201d;, AAI, 1996, pp. 226-231.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Dempster, A.P., et al., &#x201c;Maximum Likelihood from Incomplete Data via the EM Algorithm&#x201d;, Journal of Royal Statistical Society, Series B, 39 (1):1-38, 1977.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>Agrawal, R, et al., &#x201c;Fast Discovery of Association Rules&#x201d;, in U. Fayyad, et al., editors, Advances in Knowledge Discovery and Data Mining, AAI Press/The MIT Press, pp. 307-328, 1996.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>Jaakholda, T., et al., &#x201c;Exploiting Generative Models in Discriminative Classifiers&#x201d;, in Advances in NIPS, 1999.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00037">
<othercit>Lewis, D.D., &#x201c;Naive (Bayes) at Forty: The Independence Assumption in Information Retrieval&#x201d;, in Machine Learning ECML-98, Tenth European Conference on Machine Learning, pp. 4-15, 1998.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>Nahm, U.Y., et al., &#x201c;Text Mining with Information Extraction&#x201d;, in AAAI 2002 Spring Symposium on Mining Answers from Texts and Knowledge Bases, 2002.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>McCallum &#x26; Nigam, &#x201c;A comparison of Event Models for Naive Bayes Text Classification&#x201d;, in Learning for Text Categorization: Papers from the AAAI Workshop, pp. 41-48, 1998. Tech. Rep., WS 98-05, AAAI Press.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>Ghani, R., et al., &#x201c;Data Mining on Symbolic Knowledge Extraction from the Web&#x201d;, in Workshop of Text Mining at the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>Joachim, T., &#x201c;Transductive Inference for Text Classification Using Support Vector Machines&#x201d;, in Machine Learning: Proceedings of the Sixteenth International Conference, 1999.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00042">
<othercit>Craven, M., et al, &#x201c;Learning to Construct Knowledge Bases from the World Wide Web&#x201d;, Artificiation Intelligence, 188 (1-2) 69-114, 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>Schafer, J. Ben, et al., &#x201c;E-Commerce Recommendation Applications&#x201d;, GroupLens Research Project, Department of Computer Science and Engineering, University of Minnesota, 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00044">
<othercit>Ghani, R., and A. Fano., &#x201c;Building Recommender Systems using a Knowledge Base of Product Semantics&#x201d;, Accenture Technology Labs, Chicago, IL 2002.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00045">
<othercit>Lin, D, &#x201c;Dependency-Based Evaluation of Minipar&#x201d;, Department of Computer Science, University of Alberta, Edmonton, Alberta, Canada 1998.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00046">
<othercit>Porter, M.F., &#x201c;An Algorithm for Suffix Stripping&#x201d;, PROGRAM, 14, No. 3, pp. 130-137, Jul. 1980.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>Nigam, et al., &#x201c;Text Classification from Labeled and Unlabeled Documents using EM&#x201d;, Machine Learning, 1-34, Kluwer Academic Publishers, Boston, Manufactured in the Netherlands, vol. 39, Issue 2-3, May-Jun. 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>Agrawal, et al., &#x201c;On Integrating Catalogs&#x201d;, ACM, May 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>Joachims, &#x201c;A Probablistics Analysis of the Rocchio Algorithm with TFIDF for Text Categorization&#x201d;, Carnegie Mellon University, Mar. 1996.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00050">
<othercit>Hoiem, et al, &#x201c;Object-Based Image Retrieval Using the Statistical Structure of Images&#x201d;, IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00051">
<othercit>DeCoste, et al., &#x201c;Distortion-Invariant Recognition via Jittered Queries&#x201d;, IEEE, pp. 1-6, 2000.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00052">
<othercit>Zhou, Y., &#x201c;Democratic Co-Learning&#x201d;, 16th IEEE Conference on Tools with Artificial Intelligence, pp. 1-9, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00053">
<othercit>Zufiria, et al., &#x201c;Extended Backpropagation for Invariant Pattern Recognition Neural Networks&#x201d;, International Joint Conference on Neural Networks, pp. 2097-2100, 1993.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00054">
<othercit>Licsar, et al., &#x201c;User-Adaptive Hand Gesture Recognition Sytem with Interactive Training&#x201d;, Image and Vision Computing 23m, pp. 1102-1114, 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00055">
<othercit>Becker, D., &#x201c;Sensei: A Real-Time Recognition, Feedback and Training System for T'ai Chi Gestures&#x201d;, MIT Media Lab Perceptual Computing Group Technical Report No. 426, pp. 1-50, 1997.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00056">
<othercit>Probst, K. and Ghani: &#x201c;Towards &#x2018;Interactive&#x2019; Active Learning in Multi-view Feature Sets for Information Extraction&#x201d;, Lecture Notes in Computer Science, vol. 4701, Sep. 8, 2007, pp. 683-890, XP019071429.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00057">
<othercit>Probst, Ghani, Krema, Fano &#x26; Liu: &#x201c;Semi-Supervised Learning of Attribute-Value Pairs from Product Descriptions&#x201d;, Proceedings of hte 20th International Joint Conferences on Artifical Intelligence (UCAI '07), Jan. 6, 2007-Jan. 12, 2007, pp. 2838-2843, XP007906331.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00058">
<othercit>Probst, Ghani, Krema, Fano &#x26; Liu: &#x201c;Semi-Supervised Learning to Extract Attribute Value Pairs from Product Descriptions on the Web&#x201d;, Proceedings of the 2006 Workshop on Web Mining (Webmine '06), 17th European Conference on Machine Learning (ECML '06) &#x26; 10th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD '06) Sep. 18, 2006, pp. 38-49, XP002504179.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00059">
<othercit>Nigam &#x26; Ghani, &#x201c;Analyzing the Effectiveness and Applicability of Co-Training&#x201d;, Proceedings of the 9th International Conference on Information Knowledge Management (CIKM '00), Nov. 6, 2000-Nov. 11, 2000, pp. 86-93, XP00790319.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00060">
<othercit>International Search Report and Written Opinion for PCT/GB2008/003118 dated Sep. 12, 2008, Form PCT/ISA/210.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00061">
<othercit>International Preliminary Report on Patentability under Chapter I for PCT/GB2008/003118 dated Mar. 25, 2010.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00062">
<othercit>Blum, Avrim &#x26; Mitchell, Tom, &#x201c;Combining Labeled and Unlabeled Data with Co-Training&#x201d;, Proceedings of the 1998 Conference on Computational Learning Theory, 1998.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00063">
<othercit>Brill, Eric, &#x201c;Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part of Speak Tagging&#x201d;, Computational Linguistics, 1995.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00064">
<othercit>Collins, Michael &#x26; Singer, Yoram, &#x201c;Unsupervised Models for Named Entity Classification&#x201d;, EMNLP/VLC, 1999, pp. 100-110, AT&#x26;T Labs&#x2014;Research.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00065">
<othercit>Finn, Aidan and Kushmerick, Nicholas, &#x201c;Active Learning Selection Strategies for Information Extraction&#x201d;, ECML-03, Workshop on Adaptive Text Extraction and Mining, 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00066">
<othercit>Ghani, Rayid and Jones, Rosie, &#x201c;A Comparison of Efficacy and Assumptions of Bootstrapping Algorithms for Training Information Extraction Systems&#x201d;, LREC 2002 Workshop on Linguistic Knowledge Acquisition, 2002.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00067">
<othercit>Jones, Rosie, &#x201c;Learning to Extract Entities from Labeled and Unlabeled Text&#x201d;, Ph.D. Dissertation, School of Computer Science, Carnegie Mellon University, Pittsburgh PA 15213, May 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00068">
<othercit>Jones, Rosie, et al., &#x201c;Active Learning for Information Extraction with Multiple View Feature Sets&#x201d;, ECML 2003 Workshop on Adaptive Text Extraction and Mining, 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00069">
<othercit>Lewis &#x26; Gale, &#x201c;A Sequential Algorithm for Training Text Classifiers&#x201d;, ICML, 1994, Proceedings of Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, Springer-Verlag, London, pp. 3-12.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00070">
<othercit>Liu, et al., &#x201c;Opinion Observer: Analyzing and Comparing Opinions on the Web&#x201d;, International World Wide Web Conference Committee (W3C2) WWW 2005, May 10-14, 2005, Ohiba, Japan.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00071">
<othercit>McCallum and Nigam, &#x201c;Employing EM and Pool-Based Active Learning for Text Classification&#x201d;, Proceedings of ICML, 1998.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00072">
<othercit>Muslean, et al., Active+ Semi-Supervised Learning = Robust Multi-View Learning, Proceedings of the ICML, 2002.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00073">
<othercit>Seymore, et al., &#x201c;Learning Hidden Markoff Model Structure for information Extraction&#x201d;, AAAI 99 Workshop on Machine Learning for Information Extraction, 1999.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00074">
<othercit>Peng &#x26; McCallum, &#x201c;Accurate Information Extraction from Research Papers Using Conditional Random Fields&#x201d;, Department of Computer Science, University of Massachusetts, HLT, 2004.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00075">
<othercit>Popesscu &#x26; Etzioni, &#x201c;Extracting Product Features and Opinions from Reviews&#x201d;, Department of Computer Science and Engineering, University of Washington, Seattle, WA, EMNLP, 2006.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00076">
<othercit>Thompson, Cynthia, et al., &#x201c;Active Learning for Natural Language Parsing and Information Extraction&#x201d;, ICML, 1999.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00077">
<othercit>Tong &#x26; Koller, &#x201c;Support Vector Machine Active Learning with Applications to Text Classification&#x201d;, Journal of Machine Learning Research, 2001.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00078">
<othercit>Potamianos et al., &#x201c;Dialogue Management in the Bell Labs Communicator System&#x201d; Oct. 2000, 4 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>30</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>707803</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>19</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11742215</doc-number>
<date>20070430</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7996440</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13197906</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60803940</doc-number>
<date>20060605</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120036100</doc-number>
<kind>A1</kind>
<date>20120209</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Probst</last-name>
<first-name>Katharina</first-name>
<address>
<city>Dyer</city>
<state>IN</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Ghani</last-name>
<first-name>Rayid</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Fano</last-name>
<first-name>Andrew E.</first-name>
<address>
<city>Lincolnshire</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Krema</last-name>
<first-name>Marko</first-name>
<address>
<city>Evanston</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Liu</last-name>
<first-name>Yan</first-name>
<address>
<city>Elmsford</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Probst</last-name>
<first-name>Katharina</first-name>
<address>
<city>Dyer</city>
<state>IN</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Ghani</last-name>
<first-name>Rayid</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Fano</last-name>
<first-name>Andrew E.</first-name>
<address>
<city>Lincolnshire</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Krema</last-name>
<first-name>Marko</first-name>
<address>
<city>Evanston</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Liu</last-name>
<first-name>Yan</first-name>
<address>
<city>Elmsford</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Harrity &#x26; Harrity, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Accenture Global Services Limited</orgname>
<role>03</role>
<address>
<city>Dublin</city>
<country>IE</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Beausoliel, Jr.</last-name>
<first-name>Robert</first-name>
<department>2167</department>
</primary-examiner>
<assistant-examiner>
<last-name>Arjomandi</last-name>
<first-name>Noosha</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">One or more classification algorithms are applied to at least one natural language document in order to extract both attributes and values of a given product. Supervised classification algorithms, semi-supervised classification algorithms, unsupervised classification algorithms or combinations of such classification algorithms may be employed for this purpose. The at least one natural language document may be obtained via a public communication network. Two or more attributes (or two or more values) thus identified may be merged to form one or more attribute phrases or value phrases. Once attributes and values have been extracted in this manner, association or linking operations may be performed to establish attribute-value pairs that are descriptive of the product. In a presently preferred embodiment, an (unsupervised) algorithm is used to generate seed attributes and values which can then support a supervised or semi-supervised classification algorithm.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="113.71mm" wi="121.58mm" file="US08626801-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="228.09mm" wi="180.85mm" file="US08626801-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="210.99mm" wi="192.28mm" file="US08626801-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="237.83mm" wi="188.98mm" file="US08626801-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="224.79mm" wi="177.55mm" file="US08626801-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="242.74mm" wi="182.46mm" file="US08626801-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="239.52mm" wi="187.37mm" file="US08626801-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="149.86mm" wi="142.58mm" file="US08626801-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The instant application is a continuation of U.S. patent application Ser. No. 11/742,215 entitled &#x201c;Extraction Of Attributes And Values From Natural Language Documents&#x201d; and filed Apr. 30, 2007, which prior application claims the benefit of Provisional U.S. Patent Application Ser. No. 60/803,940 entitled &#x201c;Text Mining For Product Attribute Extraction&#x201d; and filed Jun. 5, 2006, the entirety of which is incorporated herein by this reference. The instant application is also related to U.S. patent application Ser. No. 11/742,244 filed Apr. 30, 2007, now U.S. Pat. No. 7,970,767.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to determination of product attributes and values and, in particular, to techniques for extracting such attributes and values from natural language documents.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Retailers have been collecting a growing amount of data from various sources in hopes of improving business performance based on analysis of such data. For example, most retailers have terabytes of transaction data containing customer information and related transactions. These data warehouses also contain product information, but that information is often very sparse and limited. For example, most retailers treat products as &#x201c;atomic&#x201d; entities with very few related attributes (typically brand, size, or color). Nevertheless, retailers currently try to use transactional data for various applications, such as demand forecasting, assortment optimization, product recommendations, assortment comparison across retailers/manufacturers or product supplier selection. However, treating products as atomic entities hinders the effectiveness of these applications. Representations of products in terms of attributes and attribute values would significantly improve, both in terms of efficiency and efficacy, the above-mentioned applications. As used hereinafter, attributes describe a generalized quality, property, or characteristic of a product, whereas values assign a specific quantity, quality, configuration, etc. to an otherwise generic attribute.</p>
<p id="p-0005" num="0004">For example, assume a grocery store wants to forecast sales of &#x201c;Tropicana Low Pulp Vitamin-D Fortified Orange Juice 1-liter plastic bottle&#x201d;. Typically, they would look at sales of the same product from the same time last year and adjust that number based on some new information. If this particular product is new, however, data from previous years will obviously not be available. In contrast, representing the product as a set of attribute-value pairs (e.g., Brand: Tropicana; Pulp: Low; Fortified with: Vitamin-D; Size: 1 liter; Bottle Type: Plastic) would enable use of data from other products having identical or similar attributes, thereby enabling a more accurate forecast. Even if the product is not new, representing it in terms of attribute-value pairs allows comparison with other related products and improved forecasts.</p>
<p id="p-0006" num="0005">Many retailers have realized this recently and are trying to enrich their product databases with attributes and corresponding values for each product. However, this is typically done using a manual process in which product descriptions (often obtained from an internal database, the World Wide Web or actual product packaging) are individually inspected, making the process relatively inefficient and expensive. Automation of this type of processing would greatly improve efficiency and overall expense.</p>
<p id="p-0007" num="0006">To this end, techniques for extracting information from text documents are well known. However, such techniques have not been applied to the problem of extracting product attributes and values. For example, recently proposed techniques extract product features and their polarity (i.e., &#x201c;good&#x201d;, &#x201c;bad&#x201d;, &#x201c;useful&#x201d;, etc.) from online user reviews. While these techniques attempt to describe a product as a vector of attributes, they do not address the extraction of values or associating the extracted attributes and values together. Other techniques encompass information extraction with the goal of filling templates whereby certain parts of a text document are extracted as relevant facts. However, these techniques start with a definitive list of template slots, akin to attributes, rather than deriving such attributes directly from the documents themselves. Additional work has been performed in the area of extracting named entities from documents using so-called semi-supervised learning, discussed in further detail below. However, while these techniques essentially perform classification of words/phrases as attributes or values, such classifications are performed independently of each other, and attribute-value pairs are not determined. Further still, such classification techniques have not been applied to the determination of product attributes and values. Recently, Silver Creek Systems, Inc. has offered its &#x201c;DATALENS&#x201d; system as means for developing &#x201c;understanding&#x201d; of, for example, a company's products through analysis of product descriptions. Relying on user intervention to identify attributes and values manually, at least in part, the &#x201c;DATALENS&#x201d; system uses non-classification-based techniques (i.e., the development of schemas in which core terms are further described by their attributes and values) to transform such product descriptions from one or more (often idiosyncratic) language domains into other, more useful language domains.</p>
<p id="p-0008" num="0007">Thus, it would be advantageous to provide techniques that allow for the establishment of product attribute-value pairs through the automatic extraction of product attributes and values while overcoming the limitations of prior art techniques.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">The present invention provides techniques for extracting product attributes and corresponding values in an automated fashion. In particular, the present invention teaches the application of classification algorithms to natural language documents in order to extract both attributes of a given product as well as corresponding values of the attributes. Supervised classification algorithms, semi-supervised classification algorithms, unsupervised classification algorithms or combinations of such classification algorithms may be employed for this purpose. In one embodiment of the present invention, the one or more natural language documents operated upon by the classification algorithm are obtained via a public communication network, such as the World Wide Web. Two or more attributes (or two or more values) thus identified may be merged to form one or more attribute phrases or value phrases. Furthermore, once attributes and values have been extracted in this manner, association or linking operations may be performed to establish attribute-value pairs that are descriptive of the product.</p>
<p id="p-0010" num="0009">In a presently preferred embodiment, a seed algorithm (unsupervised) is used to generate seed attributes and corresponding seed values based on at least one natural language document. Thereafter, a classification algorithm employs the seed attributes and seed values to further identify (i.e., &#x201c;extract&#x201d;) additional attributes and values from the at least one natural language document. The classification algorithm used for this purpose comprises a combination of a supervised classification algorithm operating in conjunction with a semi-supervised algorithm, thereby obtaining the benefits of each type of classification algorithm. In this manner, the present invention provides techniques that are readily implemented in an automated fashion, thereby greatly improving the determination of product attributes and values and, consequently, product attribute-value pairs.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0011" num="0010">The features of the present invention are set forth with particularity in the appended claims. The invention itself, together with further features and attended advantages, will become apparent from consideration of the following detailed description, taken in conjunction with the accompanying drawings. One or more embodiments of the present invention are now described, by way of example only, with reference to the accompanied drawings wherein like reference numerals represent like elements and in which:</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram schematically illustrating high-level processing in accordance with an embodiment of the present invention;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating a system that may be used in conjunction with an embodiment of the present invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating an alternative system that may be used in conjunction with another embodiment of the present invention;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating processing in accordance with one embodiment of the present invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating processing in accordance with another embodiment of the present invention;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram of an implementation of an apparatus in accordance with the present invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram of a preferred implementation of an unsupervised seed generation module in accordance with one embodiment of the present invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram of a preferred implementation of a classification module in accordance with the present invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 9</figref> is a block diagram of a preferred implementation of a linking module in accordance with the present invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. 10-16</figref> illustrate operation of a semi-supervised algorithm in accordance with an embodiment of the present invention; and</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. 17-19</figref> illustrate association of attributes and values in accordance with an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE PRESENT EMBODIMENTS</heading>
<p id="p-0023" num="0022">Referring now to <figref idref="DRAWINGS">FIG. 1</figref>, high-level processing in accordance with an embodiment of the present invention is illustrated in block diagram form. In particular, one or more natural language documents <b>104</b>, descriptive of one or more products, are provided as input to an attribute and value extraction process <b>102</b>. Using techniques describe in further detail below, the attribute and value extraction process <b>102</b> provides at least one attribute <b>106</b> and at least one value <b>108</b> to a linking process <b>110</b>, which operates to identify attribute-value pairs. In a presently preferred embodiment, the processing of the various embodiments of the present invention, as exemplified in <figref idref="DRAWINGS">FIG. 1</figref>, is carried out using one or more suitably programmed computers or equivalents thereof.</p>
<p id="p-0024" num="0023">The at least one natural language document <b>104</b> preferably describes one or more products. As used herein, a natural language document comprises any document that at least textually describes a product using virtually any language syntax normally used by, and intended for consumption by, humans, either orally or in written form, when describing something. As such, a natural language document may be expressed in any language. In a most general sense, a product may comprise anything that may be described using a natural language document and, in a presently preferred embodiment, comprises any object or service that is made available by a supplying entity (e.g., retailers, manufacturers, etc.) for use by interested consumers. For instance, it is anticipated that the present invention may be beneficially applied to retailers or other commercial enterprises that offer an array of merchandise and/or services for sale. However, the present invention need not be limited to commercial contexts and may be beneficially applied to any domain where it would be beneficial to gain insight into things described in natural language documents.</p>
<p id="p-0025" num="0024">As an example, products falling within the general category of sporting goods is an interesting and relatively challenging domain because unlike electronics, the attributes are not easy and straightforward to detect. For example, a camera has a relatively well-defined list of attributes (resolution, zoom, memory-type, etc.). In contrast, a baseball bat would have some typical attributes such as brand, length, material as well as others that might be harder to identify as attributes and values (aerodynamic construction, curved hitting surface, etc.).</p>
<p id="p-0026" num="0025">The attribute and value extraction process <b>102</b> treats the problem of extracting (identifying) attributes and values as a classification problem and, therefore, employs one or more classification algorithms for this purpose. As known in the art, classification algorithms are applied to documents in an attempt to classify individual words within a document into one of several predefined classes. In the case of the present invention, these classes are defined as &#x201c;attribute&#x201d;, &#x201c;value&#x201d; or &#x201c;neither&#x201d; (in addition to a default class of &#x201c;unassigned&#x201d;). Words that have been classified in this manner can be thought of as &#x201c;labeled&#x201d; data. It should be noted that labeled data may come in the form of individually labeled words or phrases that exist outside the confines of a document structure, e.g., seed attributes and corresponding seed values, as described in greater detail below. In contrast, a document comprises unlabeled data if not all of its constituent words have previously been classified. As described in greater detail below, classification algorithms may be characterized into three different categories: unsupervised, supervised and semi-supervised. The present invention may employ any of these different categories of classification algorithms individually or, as in a presently preferred embodiment, in combination. As known in the art, unsupervised classification algorithms do not require any labeled data as input in order to work, whereas supervised classification algorithms require labeled data in order to train the classifier. Semi-supervised classification algorithms can incorporate both labeled training data and unlabeled data.</p>
<p id="p-0027" num="0026">Regardless of the particular classification algorithm employed, the attribute and value extraction process <b>102</b> provides at least one attribute <b>106</b> and at least one value <b>108</b> as output, which are subsequently provided to an association or linking process <b>110</b>. The linking process <b>110</b> formulates one or more attribute-value pairs <b>112</b> based on the at least one attribute <b>106</b> and at least one value <b>108</b>. In practice, the classification algorithm employed by the attribute and value extraction process <b>102</b> attempts to assign (in a probabilistic sense) a label to all unlabeled words in the natural language documents provided to it. However, it remains to use these labels to tag attributes and values in the actual product descriptions, i.e., in the at least one natural language document originally provided, and to find correspondences between words or phrases tagged as attributes and values. Stated another way, the classification phase assigns a probability distribution over all the labels to each word (or phrase). This is not enough, because some words that are tagged with the same label should be merged to form an attribute or a value. Additionally, the system must establish links between attributes (or attribute phrases) and their corresponding values (or value phrases), so as to form attribute-value pairs. Some unlabeled data items contain more than one attribute-value pair, so that it is important to find the correct associations between them. As described in greater detail below, the task of associating attributes and values may employ various techniques to establish attribute-value pairs.</p>
<p id="p-0028" num="0027">Referring now to <figref idref="DRAWINGS">FIG. 2</figref>, a system that may be used to implement one or more of the various embodiments of the present invention is further illustrated. In particular, a back end system <b>202</b> is coupled to a database <b>208</b>. As shown, the back end system <b>202</b> comprises at least one processor (such as a microprocessor, microcontroller, digital signal processor, etc. or combinations thereof) coupled to a storage device <b>212</b> (such as random-access memory, read-only memory, optical and/or magnetic storage devices, etc.) having stored thereon executable instructions that may be executed by the at least one processor. Generally, the back end system <b>206</b> comprises one or more general purpose computers suitably programmed to perform the techniques described herein. As known by those having ordinary skill in the art, however, such processing devices may incorporate, or be replaced by, specialized processing circuits such as programmable logic arrays, application-specific integrated circuits, etc. as a matter of design choice. Although not show, the back end system <b>202</b> may comprise a display and other user input/output devices, as known in the art, that allow a user of the back end system <b>202</b> to interact with and otherwise control processing in accordance with the present invention.</p>
<p id="p-0029" num="0028">In a presently preferred embodiment, the natural language documents describing products are available via a public communications network such as the World Wide Web in the form of textual content in web pages. Such content typically resides on one or more web servers <b>204</b> coupled to the back end <b>202</b> using conventional techniques. Web servers are well known to those having skill in the art. When gathering the documents, a so-called web crawler <b>206</b> (i.e., a computer-executed program that visits remote sites and automatically downloads their contents) programmed to visit websites of relevant entities (e.g., retailers, manufacturers, etc.) and extract names, Uniform Resource Locators, descriptions, prices and categories of all products available, may be used. Such a web crawler is preferably implemented using computer-programming techniques and may be programmed to automatically extract information or, in a simpler implementation, manually configured to extract specific information. As the web crawler collects suitable information (descriptions), they are stored in the database <b>208</b>, which may comprise a suitably configured server computer. Of course, sources of documents other than web sites, such as internal databases or other non-publicly accessible sources may be equally employed. Further, it is not a requirement of the present invention that natural language documents be collected in this manner. For example, pre-compiled databases of such documents may be equally employed.</p>
<p id="p-0030" num="0029">Referring now to <figref idref="DRAWINGS">FIG. 3</figref>, another system is shown in which the back end system <b>202</b> and database <b>208</b> are used to analyze selected/offered products. In particular, the back end system is coupled, preferably via a public communications network such as the World Wide Web, to a web client <b>302</b> and/or one or more web servers <b>304</b>. Once again, web clients are well known to those having ordinary skill in the art. In general, the descriptions of the products to be analyzed (e.g., as shown in <figref idref="DRAWINGS">FIG. 1</figref> and as described in detail below) may be identified from either or both of two sources: products that are selected by an entity or products that are offered by an entity. For purposes of the present invention, the act of &#x201c;selecting&#x201d; a product includes any manifestation of interest by the entity in the product, e.g., on-line browsing, selecting a product for inclusion in a shopping cart, asking for info, etc. In a currently preferred embodiment, the web client allows an entity (such as an individual, organization or any uniquely identifiable party) to request and obtain information from, or submit information to, the one or more web servers <b>304</b>. To the extent that such requested/submitted information manifests an entity's interest in one or more products, they may be regarded as selected products. The back end system <b>202</b> may directly monitor the activity of the web client <b>302</b> or may be provided with the relevant information through the web server(s) <b>304</b> or other sources.</p>
<p id="p-0031" num="0030">As in <figref idref="DRAWINGS">FIG. 2</figref>, the product descriptions are preferably provided through web sites and web pages maintained by retailers, etc. In this case, the back end system <b>202</b> may directly access the relevant web sites to obtain the new descriptions. As noted above, although web-based sources of descriptions are presently preferred, the instant invention is not necessarily limited in this regard. Once again, suitable product descriptions may come from virtually any source provided that the descriptions may be reduced to a format whereby the back end system <b>202</b> is able to analyze them, e.g., manually entered into a computer, scanned and automatically recognized, etc.</p>
<p id="p-0032" num="0031">Regardless of the source of the descriptions, the back end system <b>202</b> may perform the processing described herein to extract attributes and values of products as well as establish attribute-value pairs that serve as a basis for meaningfully describing products. The resulting attributes, values and/or attribute-value pairs may then be stored in the database <b>208</b> as part of a larger knowledge base, or may be provided to the web client <b>302</b>, the web server(s) <b>304</b> or to a third party <b>310</b>. For example, an individual browsing a retailer's web site may wish to see how his or her selections are perceived in terms of the defined attributes. Conversely, a retailer implementing a web site on the web server(s) <b>304</b> may wish to understand how its product offerings are perceived. Further still, one retailer (e.g., a third party <b>310</b>) may want to know the attributes of a competitor's product line.</p>
<p id="p-0033" num="0032">Referring now to <figref idref="DRAWINGS">FIG. 4</figref>, a process in accordance with an embodiment of the present invention is illustrated in flowchart form. In particular, the processing illustrated in <figref idref="DRAWINGS">FIG. 4</figref> illustrates a technique for identifying attributes and values in natural language documents using a classification algorithm and, thereafter, identifying attribute-value pairs from the extracted attributes and values. In a presently preferred embodiment, the processing of <figref idref="DRAWINGS">FIG. 4</figref> is carried out using executable instructions stored on a suitable computer-readable medium that are executed by a computer. However, as known to those having skill in the art, other techniques may be used to implement the processing of <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0034" num="0033">At block <b>402</b>, at least one natural language document that is descriptive of a product is obtained using, for example, the web crawler embodiment described above. Thereafter, at block <b>404</b>, seed attributes and corresponding seed values may be optionally generated based on the at least one natural language document. Depending on the type of classification algorithm employed, seed attributes and seed values may or may not be needed. In particular, if a supervised or semi-supervised classification algorithm is employed, such seed attributes and seed values are necessary. Conversely, if an unsupervised classification algorithm is used by itself, such seeds are not necessary.</p>
<p id="p-0035" num="0034">Regardless, processing continues at block <b>406</b> where attributes and values of the product are extracted using a classification algorithm as applied to the at least one natural language document. (Note that the terms &#x201c;extracting&#x201d; and &#x201c;identifying&#x201d; as applied to attributes and values are used synonymously throughout this disclosure.) The present invention may equally employ unsupervised, supervised or semi-supervised classification algorithms alone, or in combinations thereof, for this purpose. As described in greater detail below, a preferred embodiment of the present invention uses an unsupervised classification algorithm for seed generation (i.e., identification of seed attributes and values) and a combination of a supervised classification algorithm and a semi-supervised classification algorithm for the identification of attributes and values. Having identified at least one attribute and at least one value, processing continues at block <b>408</b> where attribute-value pairs are identified within the at least one attribute and the at least one value. The processing of block <b>408</b> is described in further detail with reference to <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a presently preferred technique for establishing attribute-value pairs based on previously-identified, but otherwise unlinked, attributes and values. Once again, the processing of <figref idref="DRAWINGS">FIG. 5</figref> is preferably carried out using executable instructions stored on a suitable computer-readable medium that are executed by a computer, although it is further understood that other implementation techniques may be equally employed. In the process of establishing attribute-value pairs, words of certain parts of speech, namely most closed-class items, are excluded. For example, prepositions, conjunctions, etc., are not good candidates for attributes or values, and thus are not extracted. With this understanding, an initial operation (not shown in <figref idref="DRAWINGS">FIG. 5</figref>) is to assign labels based on already known pairs, namely the pairs extracted as seed attributes and corresponding seed values by the unsupervised classification algorithm. Whenever instances of such extracted pairs are encountered, they are appropriately labeled as attributes or values and a link is establish between them so that they form a pair. As known in the art, a variety of techniques may be employed to establish such links, such as establishing a pointer from an attribute that points to its corresponding value, or vice versa.</p>
<p id="p-0037" num="0036">At block <b>502</b>, one or more correlation metrics (as described below) are determined between attributes within a given document. Thereafter, at block <b>504</b>, one or more attribute phrases, i.e., two or more words each labeled as attributes that should be merged together, are identified based on the correlation metrics determined at block <b>502</b>. In a similar vein, at block <b>506</b>, the same type of correlations are calculated between words identified as values within the document and, at block <b>508</b>, one or more value phrases are identified based on the value correlation metrics. Although illustrated as separate blocks, the determinations of correlations at blocks <b>502</b> and <b>506</b> are essentially identical regardless whether the words are attributes or values and may be implemented as a single process, i.e., computed once for all the data and subsequently accessed as needed. Regardless, thereafter, at blocks <b>510</b>-<b>514</b>, one or more techniques may be employed to link (or, equivalently, associate) attributes (or attribute phrases) with corresponding values (or value phrases) to thereby establish attribute-value pairs. Generally, the techniques implemented by each of blocks <b>510</b>-<b>514</b> establishes respective selection criteria and calculates metrics between attributes and values for comparison with the corresponding selection criteria. Thus, at block <b>510</b>, syntactic dependencies, as described below, are determined between attributes and, where the existence of syntactic dependencies are identified, used to establish links between attributes and values. At block <b>512</b>, correlations metrics, like those employed in blocks <b>502</b> and <b>506</b>, are calculated between attributes and values. Where the correlations surpass one or more thresholds, links are again established between attributes and values. Finally, at block <b>514</b>, a straightforward proximity test is used to link attributes and values; that is, immediately adjacent attributes and values are linked. <figref idref="DRAWINGS">FIGS. 4 and 5</figref> provide high level overviews of processing in accordance with the present invention. However, a more detailed understanding of the processing of <figref idref="DRAWINGS">FIGS. 4 and 5</figref> may be obtained with reference to the remaining Figures.</p>
<p id="p-0038" num="0037">Referring now to <figref idref="DRAWINGS">FIG. 6</figref>, a more detailed illustration of an implementation of the present invention is shown. In particular, an apparatus or device <b>600</b> comprises a classification module <b>602</b> in communication with a storage device <b>604</b>. The storage device <b>604</b> is further in communication with a linking module <b>606</b> and a seed generation module <b>610</b> and, optionally, a network interface <b>608</b>. In this manner, the storage device <b>604</b> essentially acts as a means for passing data between modules. However, as known to those having skill in the art, this is not a requirement and the separate modules could, in practice, communicate directly with one another. In a presently preferred embodiment, the modules illustrated in <figref idref="DRAWINGS">FIG. 6</figref> are preferably implemented using one or more suitably programmed computers or similar devices, with the illustrated storage device <b>604</b> and network interface <b>608</b> being provided as part of the hardware/firmware of the computer(s). However, it is understood that some or all of the components illustrated in <figref idref="DRAWINGS">FIG. 6</figref> could be implemented using other techniques, such as programmable logic arrays, application-specific integrated circuits, state machines, etc. or even manual processing.</p>
<p id="p-0039" num="0038">The classification module <b>602</b> implements a classification algorithm that operates upon at least one natural language document stored in the storage device <b>604</b>. When provided, the network interface <b>608</b> (which may comprise, for example, a physical network connection and a corresponding software driver suitable for terminating the network protocol) may be used to receive the at least one natural language document using any of the previously described techniques, e.g., a web crawler. However, the present invention is not limited in this regard and other techniques may be equally employed to obtain natural language documents. Regardless of the manner in which they are obtained, the natural language documents are operated upon by the classification module <b>602</b> in order to extract one or more attributes and values, which attributes and values are subsequently stored in the storage device <b>604</b>. The classification module <b>602</b> implements any one of an unsupervised classification algorithm, a supervised classification algorithm, a semi-supervised classification algorithm or combinations thereof, specific examples of which are described in greater detail below.</p>
<p id="p-0040" num="0039">A preprocessing module <b>612</b> is provided to operate upon the at least one natural language document in order to bring such documents into suitable condition for analysis by the classification module <b>602</b>. First, the data is preferably tagged with parts of speech, i.e., the part of speech for each word in a given document is identified, using a so-called Brill tagger as described in &#x201c;Transformation-based error driven learning and natural language processing: A case study in part of speech tagging&#x201d;, E. Brill, <i>Computational Linguistics, </i>1995, 21(4): 552-565. Second, the data is preferably stemmed, i.e., any suffixes are stripped from words to provide only the stem portion of each word, using, for example, a so-called Porter stemmer as described in &#x201c;An algorithm for suffix stripping&#x201d;, M. F. Porter, <i>Program, </i>1980, 14(3): 130-137. This stemming procedure ensures that the data (i.e., the words in each document) are normalized by mapping morphological variations of words to the same token.</p>
<p id="p-0041" num="0040">In order to more fully generalize the data, all numbers in a document are preferably replaced with a unique token, e.g., #number#. Numerical tokens of substantially all forms are recognized, e.g., fractions, scientific notation, floating point numbers, and spelled out numbers (e.g., two). As many values for attributes are numerical values, normalizing the data in this way allows the collection of many more unlabeled data items for a given pattern or context, as described in greater detail below. For the same reason, all units of measure (e.g., liter, kg) are also replaced by a unique token, e.g., #measure#.</p>
<p id="p-0042" num="0041">Additionally, the preprocessing module <b>612</b> uses several well-known techniques for calculating correlation scores between all pairs of words. For example, Yule's Q statistic, mutual information, as well as the &#x3c7;<sup>2 </sup>scores are calculated. Using all three of these methods allows for high precision recognition of phrases. For example, a pair of words may be recognized as a phrase if all three of its correlation scores exceed thresholds. Furthermore, sequences of words may be recognized as phrases if two or more words in a row exceed these thresholds.</p>
<p id="p-0043" num="0042">The linking module <b>606</b> operates upon the attributes and values stored in the storage device <b>604</b> by the classification module <b>602</b> to establish attribute-value pairs within one or more of the at least one natural language documents. As described in greater detail below, the process of establishing such pairs is preferably based on a variety of techniques including correlation values, syntactic dependencies and proximity. Regardless, once determined, the attribute-value pairs are preferably stored in the storage device <b>604</b>.</p>
<p id="p-0044" num="0043">Finally, the device <b>600</b> may include a seed generation module <b>610</b> that operates upon the at least one natural language document to provide seed attributes and corresponding seed values as input to the classification module <b>602</b>. In a presently preferred embodiment, the seed generation module <b>610</b> implements an unsupervised classification algorithm that extracts relatively few, but accurately identified, attribute-value pairs from training data. The approach uses correlation scores to find candidates, and makes use of parts of speech tags by excluding certain words from being candidates for extraction. As such, the presently preferred unsupervised seed extraction is performed after the pre-processing operations described above. However, it is understood that other seed generation approaches, up to and including manual seed determinations, may be equally employed.</p>
<p id="p-0045" num="0044">Generally, extracting attribute-value pairs is related to the problem of phrase recognition (i.e., which consecutive words constitute a phrase) in that both methods aim at extracting pairs of highly correlated words. There are however differences between the two problems. Consider the following two sets of phrases:</p>
<p id="p-0046" num="0045">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="56pt" align="left"/>
<colspec colname="1" colwidth="77pt" align="left"/>
<colspec colname="2" colwidth="84pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>back</entry>
<entry>pockets</entry>
</row>
<row>
<entry/>
<entry>front</entry>
<entry>pockets</entry>
</row>
<row>
<entry/>
<entry>zip</entry>
<entry>pockets</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0047" num="0046">Versus:</p>
<p id="p-0048" num="0047">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="91pt" align="left"/>
<colspec colname="2" colwidth="77pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>Pittsburgh</entry>
<entry>Steelers</entry>
</row>
<row>
<entry/>
<entry>Chicago</entry>
<entry>Bears</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0049" num="0048">The first list contains an example of an attribute with several possible values. The second list contains phrases that are not attribute-value pairs. The biggest difference between the two lists is that attributes generally have more than one possible value, as in the above example. This observation is exploited to automatically extract high-quality seeds in an unsupervised fashion by defining a modified mutual information metric as follows.</p>
<p id="p-0050" num="0049">All bigrams w<sub>i</sub>w<sub>i+1 </sub>are considered as candidate attribute-value pairs, where w<sub>i </sub>is a potential value, and w<sub>i+1 </sub>is a candidate attribute. Although it is not always the case that the modifying value occurs (directly) before its attribute, this heuristic allows the extraction of seeds with high precision. Of course, other such heuristics could be employed, e.g., adjectives followed by nouns that often correspond to value/attribute (in that order) pairs, as a matter of design choice. Suppose word w (in position i+1) occurs with n unique words w<sub>1 . . . n </sub>in position i. The words w<sub>1 . . . n </sub>are ranked by their associated conditional probabilities p(w<sub>j</sub>|w), w<sub>j</sub>&#x3b5;w<sub>1 . . . n</sub>, where the word w<sub>j </sub>with the highest conditional probability is ranked highest.</p>
<p id="p-0051" num="0050">The words w<sub>j </sub>that have the highest conditional probability are candidates values for the candidate attribute w. Clearly, however, not all words are good candidate attributes. However, it is noted that attributes generally have more than one value and typically do not occur with a wide range of words. For example, frequent words such as the occur with many different words. This is indicated by their conditional probability mass being distributed over a large number of words. The desired situation occurs where few words account for a high proportion of the probability mass. For example, both Steelers and on will not be good candidates for being attributes. Steelers typically only occurs after Pittsburgh so all of the conditional probability mass will be distributed on one value whereas on occurs with many words with the mass distributed over too many values. Identification of suitable cases is preferably accomplished in two phases: in the first phase, enough words w<sub>i </sub>retained to account for a part z, 0&#x3c;z&#x3c;1 of the conditional probability mass &#x3a3;<sub>j=1</sub><sup>k</sup>p(w<sub>j</sub>|w). In a presently preferred embodiment, z is set to 0.5 although other values may be equally employed as a matter of design choice.</p>
<p id="p-0052" num="0051">In the second phase, a cumulative modified mutual information is computed for all candidate attribute-value pairs. Once again, consider the perspective of the candidate attribute. If there are a few words that together have a high mutual information with the candidate attribute, then that word is likely to be an attribute, along with (some of) its values. The cumulative modified mutual information is defined as follows:</p>
<p id="p-0053" num="0052">Let p(w, w<sub>1 . . . k</sub>)=&#x3a3;<sub>j=1</sub><sup>k</sup>p(w, w<sub>j</sub>). Then:</p>
<p id="p-0054" num="0053">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>cmi</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <mrow>
        <msub>
          <mi>w</mi>
          <mrow>
            <mn>1</mn>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>&#x2026;</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <mi>k</mi>
          </mrow>
        </msub>
        <mo>;</mo>
        <mi>w</mi>
      </mrow>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mi>log</mi>
    <mo>&#x2062;</mo>
    <mfrac>
      <mrow>
        <mi>p</mi>
        <mo>&#x2061;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mi>w</mi>
            <mo>,</mo>
            <msub>
              <mi>ww</mi>
              <mrow>
                <mn>1</mn>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.8em" height="0.8ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <mi>&#x2026;</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.8em" height="0.8ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <mi>k</mi>
              </mrow>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>&#x3bb;</mi>
          <mo>*</mo>
          <mrow>
            <munderover>
              <mo>&#x2211;</mo>
              <mrow>
                <mi>j</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mi>k</mi>
            </munderover>
            <mo>&#x2062;</mo>
            <mrow>
              <mrow>
                <mi>p</mi>
                <mo>&#x2061;</mo>
                <mrow>
                  <mo>(</mo>
                  <msub>
                    <mi>w</mi>
                    <mi>j</mi>
                  </msub>
                  <mo>)</mo>
                </mrow>
              </mrow>
              <mo>*</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>&#x3bb;</mi>
                  <mo>-</mo>
                  <mn>1</mn>
                </mrow>
                <mo>)</mo>
              </mrow>
              <mo>*</mo>
              <mrow>
                <mi>p</mi>
                <mo>&#x2061;</mo>
                <mrow>
                  <mo>(</mo>
                  <mi>w</mi>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mfrac>
  </mrow>
</mrow>
</math>
</maths>
</p>
<p id="p-0055" num="0054">&#x3bb; is a user-specified parameter, where 0&#x2266;&#x3bb;&#x3c;1. Experiments have found that setting &#x3bb; close to 1 yields robust (relatively accurate) results. Setting &#x3bb; close to 0 implies that a candidate pair is not penalized for the word w being frequent, as long as few words cover most of its conditional probability mass. In essence, each cumulative modified mutual information measures how much a word predicts several other words that commonly occur with it. Thus, higher cumulative modified mutual information values are increasingly favorable in the sense that they have a higher probability of corresponding to a valid attribute-value pair or pairs.</p>
<p id="p-0056" num="0055">Table 1 below lists several examples of extracted attribute-value pairs using the above-described technique taken from documents describing sporting goods related to tennis and football.</p>
<p id="p-0057" num="0056">
<tables id="TABLE-US-00003" num="00003">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Automatically (unsupervised) extracted seed attribute-value pairs</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="42pt" align="left"/>
<colspec colname="1" colwidth="84pt" align="left"/>
<colspec colname="2" colwidth="91pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>values</entry>
<entry>attribute</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>carrying</entry>
<entry>case</entry>
</row>
<row>
<entry/>
<entry>storage</entry>
</row>
<row>
<entry/>
<entry>main</entry>
<entry>compartment</entry>
</row>
<row>
<entry/>
<entry>racquet</entry>
</row>
<row>
<entry/>
<entry>ball</entry>
<entry>pocket</entry>
</row>
<row>
<entry/>
<entry>welt</entry>
</row>
<row>
<entry/>
<entry>side-seam</entry>
</row>
<row>
<entry/>
<entry>key</entry>
</row>
<row>
<entry/>
<entry>coat</entry>
<entry>steel</entry>
</row>
<row>
<entry/>
<entry>durable</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0058" num="0057">It should be noted that not all extracted pairs are actual attribute-value pairs. One typical example of an extracted incorrect pair are first name-last name pairs, e.g., Smith is extracted as an attribute as it occurs as part of many phrases and fulfills the criteria (Joe Smith, Mike Smith, etc.) after many first names. Other examples of incorrectly extracted attribute-value pairs include more (attribute)&#x2212;much (value) and more (attribute)&#x2212;achieve (value). However, experimentation has shown that some of the incorrectly extracted examples are rare enough that they do not have much impact on subsequent processing.</p>
<p id="p-0059" num="0058">An implementation of the unsupervised classification algorithm <b>610</b> described above is further illustrated with reference to <figref idref="DRAWINGS">FIG. 7</figref>. As with previous embodiments, the implementation of <figref idref="DRAWINGS">FIG. 7</figref> is preferably carried out using software programming techniques, although it is understood that other implementations are possible. As shown, the unsupervised classification algorithm <b>610</b> comprises an identification module <b>702</b> that operates upon the at least one natural language document to identify a plurality of candidate attribute-value pairs. Thus, the identification module <b>702</b> preferably computes the associated conditional probabilities, described above, and selects as candidate values those potential values corresponding to the highest valued associated conditional probabilities. The resulting candidate attribute-value pairs are provided to the metric calculation module <b>704</b> that determines the cumulative modified mutual information metrics for each candidate attribute-value pair. The cumulative modified mutual information metrics, in turn, are employed by the selection module <b>706</b> to identify as attribute-value pairs, those candidate attribute-value pairs that have the most favorable metrics, i.e., higher values of cumulative modified mutual information metrics.</p>
<p id="p-0060" num="0059">Referring now to <figref idref="DRAWINGS">FIG. 8</figref>, a presently preferred implementation of the classification module <b>602</b> is further illustrated. In particular, the classification module <b>602</b> is shown comprising a supervised classification algorithm <b>804</b> operating in conjunction with a semi-supervised classification algorithm <b>806</b>. Both the supervised algorithm <b>804</b> and the semi-supervised algorithm <b>806</b> operate to provide both attributes and values <b>805</b>, <b>807</b> to the linking module <b>606</b>. As shown, the unsupervised seed generation module <b>802</b> also provides the seed attributes and corresponding seed values <b>803</b> to both the linking module <b>606</b> and the supervised algorithm <b>804</b>. In a presently preferred embodiment, the seed attributes and corresponding seed values <b>803</b> are also provided to the semi-supervised algorithm <b>806</b>, as illustrated by the dashed arrow. Further still, as shown, attributes and values extracted by the supervised algorithm <b>804</b> are provided to, and are indeed necessary for the operation of, the semi-supervised algorithm <b>806</b> for further identification of additional attributes and values.</p>
<p id="p-0061" num="0060">As noted above, the approach adopted by the present invention to extract attributes and values is to treat the extraction as a classification problem where each word (or phrase) can be classified in one of a number of predefined classes. As an initial approach, the supervised algorithm <b>804</b> is employed using the generated seeds <b>803</b>. In particular, a so-called Nave Bayes classifier is preferably used as the supervised algorithm <b>804</b>. The initial attribute and value seeds are used to label training data (not shown in <figref idref="DRAWINGS">FIG. 8</figref>) that Na&#xef;ve Bayes uses to &#x201c;train&#x201d; a classifier. Thereafter, the semi-supervised algorithm <b>806</b> is used to improve the performance of the Nave Bayes algorithm by exploiting large amounts of unlabeled data that may be gathered relatively cheaply. That is, gathering product descriptions, for example, from retail websites is a relatively cheap process using simple web crawlers. The expensive part is labeling the words in the descriptions as attributes or values. Using the semi-supervised algorithm <b>806</b>, the initial seeds (in this case, the labeled data output by the supervised algorithm <b>804</b>, in addition to the seed attributes and values <b>803</b>) are augmented with unlabeled product descriptions (not shown) collected as described above. As described in greater detail below, a presently preferred semi-supervised algorithm is the so-called co-EM algorithm.</p>
<p id="p-0062" num="0061">In practice, the process of &#x201c;extracting&#x201d; attributes and values is essentially an exercise in labeling words. The initial labeling of words or phrases (sometimes collectively referred to herein simply as &#x201c;words&#x201d;) is based on whether they match previously labeled data, e.g., the seed attributes and values <b>803</b>, and is performed, in one embodiment, by the supervised algorithm <b>804</b> although such processing could be performed as an entirely separate operation. Regardless, four classes are preferably used to probabilistically label individual words: unassigned, attribute, value, or neither. The probability distribution for each word defaults to unassigned. If an unlabeled word does not match the labeled data, this default remains as input for the classification algorithm. If the unlabeled word does match the labeled data, then it is simply assigned the corresponding label. To facilitate this process, a stoplist, i.e., a list of words that are known in all cases to be neither an attribute or value, may be employed. Stoplist words are usually words that are extremely common, such as &#x201c;the&#x201d;, &#x201c;and&#x201d;, etc. and therefore aren't useful as attributes or values. Thus, if a word appears on the stoplist, it is tagged as neither. In some cases, it can happen that a word or phrase appears with more than one label. This is because the same word or phrase can have different labels in different contexts. For example, a numerical value (indicated by the #number# token) can appear as both an attribute and as a value. In such a case, partial probabilities can be assigned to each label by the supervised algorithm <b>804</b> with the assumption that the semi-supervised algorithm <b>806</b> will assign the appropriate label for the given context.</p>
<p id="p-0063" num="0062">Words labeled as described above are then used as training data by the supervised classification algorithm <b>804</b>, e.g., the Na&#xef;ve Bayes algorithm, that classifies each word or phrase in the unlabeled data as an attribute, value, or neither. Techniques for implementing the Na&#xef;ve Bayes algorithm are well known to those having ordinary skill in the art as described, for example, in Machine Learning by Thomas M. Mitchell (McGraw-Hill Higher Education 1997). In a presently preferred embodiment, the features used for classification are the words of each unlabeled data item, plus the surrounding eight words and their corresponding parts of speech.</p>
<p id="p-0064" num="0063">As noted above, the labeling of attributes and values is an expensive process and it would be particularly advantageous to reduce the amount of labeled data required to train accurate classifiers. To this end, relatively easily obtained unlabeled product descriptions may be used with the semi-supervised algorithm <b>806</b> effectively combining small amounts of labeled data with large amounts of unlabeled data. In a presently preferred embodiment, a multi-view implementation (similar to co-training) is employed where each word can be described using multiple views (e.g., the word itself and the context in which it occurs). In particular, a co-EM semi-supervised algorithm is preferred. As described in &#x201c;Analyzing the effectiveness and applicability of co-training&#x201d;, K. Nigam &#x26; R. Ghani, 2000<i>, Proceedings of the Ninth International Conference on Information and Knowledge Management </i>(CIKM-2000), co-EM is a multi-view, semi-supervised learning algorithm that combines features from both co-training and Expectation-Maximization (EM). Like EM, co-EM is iterative but uses the multiple views present in the data as in co-training. The presently preferred separate feature sets or views used herein are the word to be classified and the context in which it occurs.</p>
<p id="p-0065" num="0064">Co-EM is a multi-view algorithm, and requires two views for each learning example. Each word or phrase (sometimes referred to herein as data items) is expressed in view<b>1</b> by the stemmed word or phrase itself, plus the parts of speech as assigned by the Brill tagger. The view<b>2</b> for this data item is a context of window size eight, i.e., four words (plus parts of speech) before and four words (plus parts of speech) after the word or phrase in view<b>1</b>. If the context around a view<b>1</b> data item is less than 8 words long, whatever context that is available is employed.</p>
<p id="p-0066" num="0065">By default, all words are processed into view<b>1</b> as single words. There are two exceptions: one is a phrase that matches the labeled data. In this case, the longest phrase possible is labeled and the entire phrase is treated as one view<b>1</b> data item. In addition, correlation scores are used to detect phrases as described previously. When two or more words are recognized as a phrase, they are treated the same as a single word.</p>
<p id="p-0067" num="0066">Co-EM proceeds by initializing a view<b>1</b> classifier using the labeled data only. Then this classifier is used to probabilistically label all the unlabeled data. The context (view<b>2</b>) classifier is then trained using the original labeled data plus the unlabeled data with the labels provided by the view<b>1</b> classifier. Similarly, the view<b>2</b> classifier then re-labels the data for use by the view<b>1</b> classifier, and this process iterates for a number of iterations or until the classifiers converge, i.e., when each classifier fails to label or re-label any data.</p>
<p id="p-0068" num="0067">Each iteration consists of collecting evidence for each data item from all the data items in the other view that it occurs with. For example, if a view<b>2</b> data item view<b>2</b><sub>k </sub>occurs with view<b>1</b> data items view<b>1</b><sub>i1 </sub>and view<b>1</b><sub>i2</sub>, then the probability distribution for view<b>2</b><sub>k </sub>is the averaged distribution of the probabilities currently assigned to view<b>1</b><sub>i1 </sub>and view<b>1</b><sub>i2</sub>, weighted by the number of times view<b>2</b><sub>k </sub>appears together with view<b>1</b><sub>i1 </sub>and view<b>1</b><sub>i2</sub>, respectively, as well as by the class probabilities, described below.</p>
<p id="p-0069" num="0068">More formally, the co-EM algorithm can be expressed as follows: Let the unlabeled training examples be view<b>1</b><sub>i</sub>, 0&#x3c;i&#x3c;n<sub>1 </sub>and view<b>2</b><sub>j</sub>, 0&#x3c;j&#x3c;n<sub>2</sub>. Each pair of unlabeled training examples (view<b>1</b><sub>i</sub>, view<b>2</b><sub>j</sub>) co-occurs with frequency cooc(view<b>1</b><sub>i</sub>,view<b>2</b><sub>j</sub>). Each training example also has a complete frequency cnt(view<b>1</b><sub>i</sub>) and cnt(view<b>2</b><sub>j</sub>), respectively, where cnt(view<b>1</b><sub>i</sub>)=&#x3a3;<sub>j=0</sub><sup>n</sup><sup><sub2>2 </sub2></sup>cooc(view<b>1</b><sub>i</sub>,view<b>2</b><sub>j</sub>) and equivalently for view<b>2</b>. Let the classes be denoted as c<sub>k</sub>, 0&#x3c;k&#x3c;4. The classes are labeled as unassigned, attribute, value, and neither, respectively. The goal is to label unlabeled training examples that are attributes or values, and leave the others unlabeled. Co-EM can be summarized by the following steps:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0069">1. Initialize based on labeled data (see above).</li>
    <li id="ul0001-0002" num="0070">2. Use view<b>1</b> to label view<b>2</b></li>
    <li id="ul0001-0003" num="0071">3. Use view<b>2</b> to label view<b>1</b></li>
    <li id="ul0001-0004" num="0072">4. Repeat steps 2 and 3 for n iterations or until convergence is reached.</li>
    <li id="ul0001-0005" num="0073">5. Assign final labels to words:</li>
</ul>
</p>
<p id="p-0070" num="0074">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>P</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <mrow>
        <msub>
          <mi>c</mi>
          <mi>k</mi>
        </msub>
        <mo>|</mo>
        <mrow>
          <mo>&#x2329;</mo>
          <mrow>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>1</mn>
                <mi>i</mi>
              </msub>
            </mrow>
            <mo>,</mo>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>2</mn>
                <mi>j</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>&#x232a;</mo>
        </mrow>
      </mrow>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mrow>
        <mi>P</mi>
        <mo>&#x2061;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mi>c</mi>
              <mi>k</mi>
            </msub>
            <mo>|</mo>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>1</mn>
                <mi>i</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
      <mo>+</mo>
      <mrow>
        <mi>P</mi>
        <mo>&#x2061;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mi>c</mi>
              <mi>k</mi>
            </msub>
            <mo>|</mo>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>2</mn>
                <mi>j</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
    </mrow>
    <mn>2</mn>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0071" num="0075">When estimating class probabilities for labeling a view, each is estimated from the respective other view's probability distributions. When labeling view<b>2</b> from view<b>1</b>, the class probabilities for the Na&#xef;ve Bayes classifier are computed only on view<b>1</b>, without reference to the view<b>2</b> data items. The resulting probability distributions from these two approaches are the same. The class probabilities are thus estimated as follows:</p>
<p id="p-0072" num="0076">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>P</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <msub>
        <mi>c</mi>
        <mi>j</mi>
      </msub>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <mrow>
        <munderover>
          <mo>&#x2211;</mo>
          <mi>i</mi>
          <msub>
            <mi>n</mi>
            <mn>1</mn>
          </msub>
        </munderover>
        <mo>&#x2062;</mo>
        <mrow>
          <msub>
            <mi>cnt</mi>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>1</mn>
                <mi>i</mi>
              </msub>
            </mrow>
          </msub>
          <mo>*</mo>
          <mrow>
            <mi>P</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <msub>
                  <mi>c</mi>
                  <mi>j</mi>
                </msub>
                <mo>|</mo>
                <mrow>
                  <mi>view</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mn>1</mn>
                    <mi>i</mi>
                  </msub>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mrow>
    <mrow>
      <mi>numclasses</mi>
      <mo>+</mo>
      <mrow>
        <munderover>
          <mo>&#x2211;</mo>
          <mi>i</mi>
          <mi>N</mi>
        </munderover>
        <mo>&#x2062;</mo>
        <msub>
          <mi>cnt</mi>
          <mrow>
            <mi>view</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <msub>
              <mn>1</mn>
              <mi>i</mi>
            </msub>
          </mrow>
        </msub>
      </mrow>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0073" num="0077">numclasses in the preferred embodiment is 4, for unassigned, attribute, value, and neither. The above formula is for those iterations where view<b>2</b> is labeled from view<b>1</b>. The other iterations are defined analogously.</p>
<p id="p-0074" num="0078">As with class probabilities, word probabilities from view<b>1</b> are used as training data for view<b>2</b>. For example, if a view<b>1</b> element has a probability distribution of p(value)=0.5 and p(attribute)=0.5, then the data element is counted as a value example with weight 0.5, but also as an attribute example with weight 0.5.</p>
<p id="p-0075" num="0079">For all words view<b>2</b><sub>j</sub>, estimate the new probability for each class c<sub>k</sub>, 0&#x3c;k&#x3c;4, from all words view<b>1</b><sub>i</sub>, 0&#x3c;i&#x3c;n<sub>1</sub>. In practice, the algorithm considers only those view<b>2</b> items whose co-occurrence count with view<b>1</b>, is greater than zero.</p>
<p id="p-0076" num="0080">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>P</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <mrow>
        <mrow>
          <mi>view</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <msub>
            <mn>2</mn>
            <mi>j</mi>
          </msub>
        </mrow>
        <mo>|</mo>
        <msub>
          <mi>c</mi>
          <mi>k</mi>
        </msub>
      </mrow>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <mrow>
        <munderover>
          <mo>&#x2211;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <msub>
            <mi>n</mi>
            <mn>1</mn>
          </msub>
        </munderover>
        <mo>&#x2062;</mo>
        <mrow>
          <mrow>
            <mi>cooc</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <mi>view</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mn>1</mn>
                    <mi>i</mi>
                  </msub>
                </mrow>
                <mo>,</mo>
                <mrow>
                  <mi>view</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mn>2</mn>
                    <mi>j</mi>
                  </msub>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>*</mo>
          <mrow>
            <mi>P</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <msub>
                  <mi>c</mi>
                  <mi>k</mi>
                </msub>
                <mo>|</mo>
                <mrow>
                  <mi>view</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mn>1</mn>
                    <mi>i</mi>
                  </msub>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mrow>
    <mrow>
      <mi>numclasses</mi>
      <mo>+</mo>
      <mrow>
        <munderover>
          <mo>&#x2211;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <msub>
            <mi>n</mi>
            <mn>1</mn>
          </msub>
        </munderover>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>cooc</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <mi>view</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msub>
                  <mn>1</mn>
                  <mi>i</mi>
                </msub>
              </mrow>
              <mo>,</mo>
              <mrow>
                <mi>view</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msub>
                  <mn>2</mn>
                  <mi>j</mi>
                </msub>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0077" num="0081">Similarly,</p>
<p id="p-0078" num="0082">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>P</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <mrow>
        <mrow>
          <mi>view</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <msub>
            <mn>1</mn>
            <mi>i</mi>
          </msub>
        </mrow>
        <mo>|</mo>
        <msub>
          <mi>c</mi>
          <mi>k</mi>
        </msub>
      </mrow>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <mrow>
        <munderover>
          <mo>&#x2211;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <msub>
            <mi>n</mi>
            <mn>2</mn>
          </msub>
        </munderover>
        <mo>&#x2062;</mo>
        <mrow>
          <mrow>
            <mi>cooc</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <mi>view</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mn>1</mn>
                    <mi>i</mi>
                  </msub>
                </mrow>
                <mo>,</mo>
                <mrow>
                  <mi>view</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mn>2</mn>
                    <mi>j</mi>
                  </msub>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>*</mo>
          <mrow>
            <mi>P</mi>
            <mo>&#x2061;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <msub>
                  <mi>c</mi>
                  <mi>k</mi>
                </msub>
                <mo>|</mo>
                <mrow>
                  <mi>view</mi>
                  <mo>&#x2062;</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                  <mo>&#x2062;</mo>
                  <msub>
                    <mn>2</mn>
                    <mi>j</mi>
                  </msub>
                </mrow>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mrow>
    <mrow>
      <mi>numclasses</mi>
      <mo>+</mo>
      <mrow>
        <munderover>
          <mo>&#x2211;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <msub>
            <mi>n</mi>
            <mn>2</mn>
          </msub>
        </munderover>
        <mo>&#x2062;</mo>
        <mrow>
          <mi>cooc</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <mi>view</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msub>
                  <mn>1</mn>
                  <mi>i</mi>
                </msub>
              </mrow>
              <mo>,</mo>
              <mrow>
                <mi>view</mi>
                <mo>&#x2062;</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>&#x2062;</mo>
                <msub>
                  <mn>2</mn>
                  <mi>j</mi>
                </msub>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0079" num="0083">In accordance with standard statistical techniques (see, e.g., Foundations of Statistical Natural Language Processing by Chris Manning and Hinrich Sch&#xfc;tze (MIT Press May 1999)), the &#x201c;1&#x201d; in the numerator and the numclasses in the denominator of the above equations are added to provide smoothing, i.e., to deal with zero probabilities.</p>
<p id="p-0080" num="0084">In each iteration, the computed class and word probabilities are used to label unlabeled data items in the respective other view. This is done as follows:</p>
<p id="p-0081" num="0085">P(c<sub>k</sub>|view<b>2</b><sub>j</sub>)&#x221d;P(c<sub>k</sub>)*P(view<b>2</b><sub>j</sub>|c<sub>k</sub>) if view<b>2</b><sub>j </sub>does not match the labeled training data.</p>
<p id="p-0082" num="0086">After computing the probabilities for all classes, renormalization occurs according to:</p>
<p id="p-0083" num="0087">
<maths id="MATH-US-00006" num="00006">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>P</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <mrow>
        <msub>
          <mi>c</mi>
          <mi>k</mi>
        </msub>
        <mo>|</mo>
        <mrow>
          <mi>view</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <msub>
            <mn>2</mn>
            <mi>j</mi>
          </msub>
        </mrow>
      </mrow>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>P</mi>
      <mo>&#x2061;</mo>
      <mrow>
        <mo>(</mo>
        <mrow>
          <msub>
            <mi>c</mi>
            <mi>k</mi>
          </msub>
          <mo>|</mo>
          <mrow>
            <mi>view</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <msub>
              <mn>2</mn>
              <mi>j</mi>
            </msub>
          </mrow>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mrow>
    <mrow>
      <munderover>
        <mo>&#x2211;</mo>
        <mrow>
          <mi>k</mi>
          <mo>=</mo>
          <mn>1</mn>
        </mrow>
        <mn>4</mn>
      </munderover>
      <mo>&#x2062;</mo>
      <mrow>
        <mi>P</mi>
        <mo>&#x2061;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mi>c</mi>
              <mi>k</mi>
            </msub>
            <mo>|</mo>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>2</mn>
                <mi>j</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0084" num="0088">Similarly,</p>
<p id="p-0085" num="0089">P(c<sub>k</sub>|view<b>1</b><sub>i</sub>)&#x221d;P(c<sub>k</sub>)*P(view<b>1</b><sub>i</sub>|c<sub>k</sub>) if view<b>1</b><sub>i </sub>does not match the labeled training data.</p>
<p id="p-0086" num="0090">Again, renormalization is necessary after computing the probabilities for each class:</p>
<p id="p-0087" num="0091">
<maths id="MATH-US-00007" num="00007">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>P</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <mrow>
        <msub>
          <mi>c</mi>
          <mi>k</mi>
        </msub>
        <mo>|</mo>
        <mrow>
          <mi>view</mi>
          <mo>&#x2062;</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>&#x2062;</mo>
          <msub>
            <mn>1</mn>
            <mi>i</mi>
          </msub>
        </mrow>
      </mrow>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>P</mi>
      <mo>&#x2061;</mo>
      <mrow>
        <mo>(</mo>
        <mrow>
          <msub>
            <mi>c</mi>
            <mi>k</mi>
          </msub>
          <mo>|</mo>
          <mrow>
            <mi>view</mi>
            <mo>&#x2062;</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>&#x2062;</mo>
            <msub>
              <mn>1</mn>
              <mi>i</mi>
            </msub>
          </mrow>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mrow>
    <mrow>
      <munderover>
        <mo>&#x2211;</mo>
        <mrow>
          <mi>k</mi>
          <mo>=</mo>
          <mn>1</mn>
        </mrow>
        <mn>4</mn>
      </munderover>
      <mo>&#x2062;</mo>
      <mrow>
        <mi>P</mi>
        <mo>&#x2061;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mi>c</mi>
              <mi>k</mi>
            </msub>
            <mo>|</mo>
            <msub>
              <mrow>
                <mi>view</mi>
                <mo>&#x2062;</mo>
                <mn>1</mn>
              </mrow>
              <mi>i</mi>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0088" num="0092">However, if view<b>1</b><sub>i </sub>matches the labeled training data, P(c<sub>k</sub>|view<b>1</b><sub>i</sub>)=InitialLabeling.</p>
<p id="p-0089" num="0093">Analogously for the other direction.</p>
<p id="p-0090" num="0094">After co-EM is run for a pre-specified number of iterations, final co-EM probability distributions are assigned to all (view<b>1</b><sub>i</sub>,view<b>2</b><sub>j</sub>) pairs as follows:</p>
<p id="p-0091" num="0095">
<maths id="MATH-US-00008" num="00008">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>P</mi>
    <mo>&#x2061;</mo>
    <mrow>
      <mo>(</mo>
      <mrow>
        <msub>
          <mi>c</mi>
          <mi>k</mi>
        </msub>
        <mo>|</mo>
        <mrow>
          <mo>&#x2329;</mo>
          <mrow>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>1</mn>
                <mi>i</mi>
              </msub>
            </mrow>
            <mo>,</mo>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>2</mn>
                <mi>j</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>&#x232a;</mo>
        </mrow>
      </mrow>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mrow>
        <mi>P</mi>
        <mo>&#x2061;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mi>c</mi>
              <mi>k</mi>
            </msub>
            <mo>|</mo>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>1</mn>
                <mi>i</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
      <mo>+</mo>
      <mrow>
        <mi>P</mi>
        <mo>&#x2061;</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mi>c</mi>
              <mi>k</mi>
            </msub>
            <mo>|</mo>
            <mrow>
              <mi>view</mi>
              <mo>&#x2062;</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>&#x2062;</mo>
              <msub>
                <mn>2</mn>
                <mi>j</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
    </mrow>
    <mn>2</mn>
  </mfrac>
</mrow>
</math>
</maths>
</p>
<p id="p-0092" num="0096">It should be noted that words that are tagged as attributes or values are not necessarily extracted as part of an attribute-value pair in the linking phase. As described in greater detail below, they will only be extracted if they form part of a pair, or if they occur frequently enough by themselves or as part of a longer phrase.</p>
<p id="p-0093" num="0097">Various examples illustrating operation of the co-EM, semi-supervised algorithm are further illustrated with reference to <figref idref="DRAWINGS">FIGS. 10-16</figref>. Starting with <figref idref="DRAWINGS">FIG. 10</figref>, a word <b>1004</b> under consideration (i.e., within the view<b>1</b> classifier described above) is provided with its surrounding context <b>1002</b>, <b>1006</b> (i.e., the view<b>2</b> classifier described above). Based on previously labeled data, the word <b>1004</b> is labeled <b>1008</b> as a value. As a result, the context <b>1002</b>, <b>1006</b> is likewise identified <b>1102</b>, <b>1104</b> as a value context, as shown in <figref idref="DRAWINGS">FIG. 11</figref>. Thereafter, as illustrated in <figref idref="DRAWINGS">FIG. 12</figref>, re-occurrence of the same context <b>1202</b>, <b>1206</b> results in a similar identification <b>1208</b>, <b>1210</b> as a value context. As a result, the intermediate word <b>1204</b> is labeled <b>1212</b> as a value given the probability of the value context <b>1208</b>, <b>1210</b>. As shown in <figref idref="DRAWINGS">FIG. 13</figref>, this same process of recognizing contexts <b>1302</b>, <b>1306</b>, similarly identifying them <b>1308</b>, <b>1310</b> and inferring a label <b>1312</b> of an intermediate word <b>1304</b> may be repeated as often as possible. In essence, <figref idref="DRAWINGS">FIGS. 10-13</figref> illustrate an example of using labeled data to probabilistically identify, in this case, a value context and subsequently using the labeled context (as well as the contexts, e.g., view<b>2</b>'s) to further label (identify) additional values. That is, whether &#x201c;trail-running&#x201d; <b>1304</b> will be tagged as a value depends also on the probabilities dictated by all the other contexts in which it appears.</p>
<p id="p-0094" num="0098">Use of this acquired knowledge to leverage further labeling, particularly of attributes, is illustrated in <figref idref="DRAWINGS">FIGS. 14-16</figref>. As shown in <figref idref="DRAWINGS">FIG. 14</figref>, the process described above with reference to <figref idref="DRAWINGS">FIGS. 10-13</figref> can once again be used to identify a context <b>1402</b>, <b>1406</b> as a value context <b>1410</b>, <b>1412</b> based on a previously-labeled value <b>1404</b>, and thereafter using reoccurrence of the identified context <b>1414</b>, <b>1418</b> to further label another word <b>1416</b> as a value <b>1408</b>. Because the value <b>1408</b> occurs within the context <b>1414</b>, <b>1418</b>, it therefore possible to inferentially identify both portions of the context <b>1414</b>, <b>1418</b> as likely attributes <b>1502</b>, <b>1504</b>, i.e., to assign a probability that both halves of the context <b>1414</b>, <b>1418</b> are more likely than not to fall within the attribute classification since attributes tend to occur around values and vice versa. Thereafter, as shown in <figref idref="DRAWINGS">FIG. 16</figref>, reoccurrence of the second half of the context <b>1604</b> along with a previously labeled value <b>1602</b> increases the probability that the second half of the context <b>1604</b> is properly labeled as an attribute <b>1606</b>. Conversely, that the first half of the context <b>1414</b> did not occur in conjunction with the subsequent example decreases the probability that the first half of the context <b>1414</b> is an attribute resulting in a label as a possible attribute, i.e., reassigning a lower probability that the first half of the context <b>1414</b> will fall within the attribute classification. In effect, the examples illustrated in <figref idref="DRAWINGS">FIGS. 10-16</figref> illustrate how the co-EM algorithm carries an iterative process of using different views to label previously unlabeled words and &#x201c;bootstrapping&#x201d; the newly labeled words to perform further labeling.</p>
<p id="p-0095" num="0099">After the classification algorithm has assigned a (probabilistic) label to all (or as many as possible) unlabeled words, additional processing remains: using these labels to tag attributes and values in the actual product descriptions, i.e., in the original data, and finding correspondences between words or phrases tagged as attributes and values sufficient to confidently identify attribute-value pairs. As part of this process, it may be necessary to identify words, tagged with the same label, that should be merged to form attribute phrases or value phrases. Thereafter, links or association between attributes (or attribute phrases) and their corresponding values (or value phrases), are established to form attribute-value pairs. Thus, attribute-value pair identification can be divided into two high-level tasks: merging words having the same label into phrases, and associating values with the attributes that they describe. In a presently preferred embodiment, this is accomplished according to the following process implemented by the linking module <b>606</b>:</p>
<p id="p-0096" num="0100">1. Link based on seed pairs.</p>
<p id="p-0097" num="0101">2. Merge words of the same label into phrases if their correlation scores exceed a threshold</p>
<p id="p-0098" num="0102">3. Link attribute and value phrases based on directed or syntactic dependencies.</p>
<p id="p-0099" num="0103">4. Link attribute and value phrases if they exceed a correlation score threshold.</p>
<p id="p-0100" num="0104">5. Link attribute and value phrases based on proximity.</p>
<p id="p-0101" num="0105">6. Adding known, but not overt, attributes: material, country, and/or color.</p>
<p id="p-0102" num="0106">7. Extract binary attributes, i.e., attributes without values, if they appear frequently or if the unlabeled data item consists of only one word.</p>
<p id="p-0103" num="0107">A more detailed view of the linking module <b>606</b> is further illustrated with reference to <figref idref="DRAWINGS">FIG. 9</figref>. As shown, the linking module <b>606</b> comprises a correlation module <b>902</b>, a phrase determination module <b>904</b>, a syntactic dependency module <b>906</b>, a storage component <b>908</b>, an association module <b>910</b> and a proximity module <b>912</b> in communication with each other as shown. The correlation module <b>902</b> takes the attributes and values, determined in accordance with the previously described techniques, and calculates correlations between the attributes (i.e., the words that have been labeled as attributes) and correlations between the values (i.e., the words that have been labeled as values). In a presently preferred embodiment, the correlation metric used by the correlation module <b>902</b> is the standard Yule's Q statistic, although other correlation metrics could be equally employed in place of, or in addition to, the Yule's Q statistic.</p>
<p id="p-0104" num="0108">The resulting correlations <b>920</b> are passed to the phrase determination module <b>904</b>. Generally, the phrase determination module <b>904</b> ascertains if two adjacent words (or words that are separated only by a closed-class item, which is not be labeled) are tagged with the same label, and if these two words have a sufficiently high correlation score. If these conditions are met, the two words are merged by the phrase determination module <b>904</b> into a phrase (including the closed-class items, if any). The threshold used by the phrase determination module <b>904</b> is generally lower than that employed in the phrase extraction phase described above relative to the preprocessing module <b>612</b>: two words can form an attribute (or value) phrase if they appear together sometimes, even if their correlation score is not high enough for them to be recognized as a phrase. For example, the phrase polycotton blend tape should together be considered a phrase if each of the words has the same label, even though polycotton blend tape is not recognized as a phrase in the preprocessing step, because tape occurs in many other contexts as well. The process of determining phrases is further illustrated with reference to <figref idref="DRAWINGS">FIGS. 17 and 18</figref>. As shown in <figref idref="DRAWINGS">FIG. 17</figref>, a sentence, for example, may comprise two adjacent words that are similarly labeled, in this case the values synthetic and leather. When the correlation metric between these adjacent words exceeds the necessary threshold, which may be selected as a matter of design choice, they are merged into a single phrase having the same label as before, as illustrated in <figref idref="DRAWINGS">FIG. 18</figref>.</p>
<p id="p-0105" num="0109">After creating sets of attribute words and sets of value words where possible, the next task is to establish links between them so as to obtain attribute-value pairs. It is not uncommon that an unlabeled data item contains more than one attribute-value pair, and in this case establishing the link between attributes and values is complicated by the fact that there are multiple attributes and multiple values. The establishment of links between attributes and values also serves as a means to filter out attributes and values that were extracted, but for which there is no word or phrase of the opposite label to form a pair with. In such cases, the extracted attribute or value is likely statistically &#x201c;noisy&#x201d;, and should not be output.</p>
<p id="p-0106" num="0110">In a presently preferred embodiment, as described above relative to <figref idref="DRAWINGS">FIG. 5</figref>, links are established using three mechanisms, preferably executed in a specific order, meaning that less preference is given to links that are established by the successively later mechanisms. However, this ordered determination using the different mechanisms is not a requirement; different orders may be used, or any single mechanism or combination of mechanisms may be equally employed as a matter of design choice.</p>
<p id="p-0107" num="0111">As illustration of the preferred embodiment, the first mechanism used to establish pairs is syntactic dependencies. To this end, the output of the phrase determination module <b>904</b>, i.e., that at least one attribute phrase and/or at least one value phrase <b>922</b> as identified by the newly labeled phrases, is provided to the syntactic dependency module <b>906</b> along with the other attributes and values. In a presently preferred embodiment, the so-called Minipar dependency parser, described by D. Lin, &#x201c;Dependency-based evaluation of MINIPAR&#x201d;, 1998<i>, Workshop on the Evaluation of Parsing Systems</i>, is used to identify links between words labeled as attributes and values. For each sentence, the Minipar parser lists all dependency pairs. For example, in Top quality leather cover, Minipar parses leather as a dependent of cover. Most of the unlabeled data items are not complete sentences; Minipar is generally able to assign dependencies even for incomplete sentences, but in some cases it does not do so correctly. Despite this, Minipar can be leveraged to successfully establish links. This is done as follows: for every attribute/attribute phrase and value/value phrase, if there is at least one word in the attribute phrase that is linked (via a dependency) to a word in the value phrase, a link is established between the two. It is currently preferred to only consider directed links, meaning a link is established only if the attribute word is the governor and the value is the dependent, e.g., cover being the governor and attribute of the dependent value leather. The resulting attribute-value pairs <b>924</b> are thereafter stored in storage component <b>908</b>, which may comprise any manner of machine-readable storage device, such as magnetic storage media, etc. In a presently preferred embodiment, the entire sentence in which the attribute-value pair occurs, plus the actual words of the extracted pair, is stored. The use of syntactic dependencies is further illustrated in <figref idref="DRAWINGS">FIG. 19</figref> where a dependency <b>1902</b> is identified between the previously-determined value phrase synthetic leather and the attribute upper. In this manner, an attribute-value pair <b>1904</b> is identified.</p>
<p id="p-0108" num="0112">After syntactic dependency, links between attributes and values may be established based on the correlation scores of the candidate words. Thus, in addition to the correlations between similarly labeled words used by the phrase determination module <b>904</b>, the correlation module also computes correlations between words having different labels, i.e., attributes and values. To this end, the correlation module <b>902</b> preferably uses Yule's Q statistic and provides the resulting correlations <b>930</b> to the association module <b>910</b>. The association module <b>910</b> operates to identify pairs of dissimilarly labeled words with high correlation values, i.e., surpassing a threshold value. If such pairs are identified, a link is established and the resulting attribute-value pairs <b>932</b> are stored in the storage component <b>908</b>.</p>
<p id="p-0109" num="0113">Finally, the proximity module <b>912</b> links any remaining attributes and values or attribute phrases or value phrases <b>922</b> (i.e., any remaining attributes/attribute phrases and values/value phrases that have not been linked according to any of the previous methods) based simply on proximity. Thus, in a preferred embodiment, any unaffiliated attributes and values that are adjacent are linked together. Once again, the attribute-value pairs <b>940</b> identified in this manner are stored in the storage component <b>908</b>. In this manner, a plurality of attribute-value pairs may be stored for later recall when it is desired to describe the product using attribute-value pairs. Of course, the process of generating attribute-value pairs can be repeated for multiple products, thereby creating a database of attribute-value pair &#x201c;vectors&#x201d;, each being descriptive of a corresponding product.</p>
<p id="p-0110" num="0114">Although not shown in <figref idref="DRAWINGS">FIG. 9</figref>, other methods may be employed to assess any remaining unaffiliated (i.e., unlinked) attributes and values. Attributes with binary values, e.g., true or false, may be present in the data. For example, the data item Imported is a valid attribute with two possible values: true or false, where the value is simply assigned by the absence or presence of the attribute. In a presently preferred embodiment, only those attributes that are single word data items and those attributes that occur frequently in the data as a phrase are extracted in this manner. Further still, attributes that are not present in the data may be added. That is, if an extracted value appears on the list of countries, colors, and materials, it may be desirable to automatically assign the appropriate attribute. This attribute (country, color, or material) is added to any existing attribute words for this value. For example, the data item leather upper would result in the attribute-value pair #material# upper&#x2212;leather, i.e., the material of the upper part of the product is leather.</p>
<p id="p-0111" num="0115">As described above, the present invention provides a technique for automatically extracting product attributes and values from one or more natural language documents. This is achieved by treating the task as a classification problem and using one or more classification algorithms to classify words and/or phrases in natural language documents as attributes, values or neither. Based on the attributes and values identified in this manner, further processing is performed to identify (extract) attribute-value pairs that are descriptive of the product. For at least these reasons, the present invention represents an advancement over prior art techniques.</p>
<p id="p-0112" num="0116">While the particular preferred embodiments of the present invention have been shown and described, it will be obvious to those skilled in the art that changes and modifications may be made without departing from the teachings of the invention. It is therefore contemplated that the present invention cover any and all modifications, variations or equivalents that fall within the scope of the basic underlying principles disclosed above and claimed herein.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08626801-20140107-M00001.NB">
<img id="EMI-M00001" he="10.58mm" wi="76.20mm" file="US08626801-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US08626801-20140107-M00002.NB">
<img id="EMI-M00002" he="6.35mm" wi="76.20mm" file="US08626801-20140107-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US08626801-20140107-M00003.NB">
<img id="EMI-M00003" he="15.49mm" wi="76.20mm" file="US08626801-20140107-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US08626801-20140107-M00004.NB">
<img id="EMI-M00004" he="15.49mm" wi="76.20mm" file="US08626801-20140107-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US08626801-20140107-M00005.NB">
<img id="EMI-M00005" he="15.49mm" wi="76.20mm" file="US08626801-20140107-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00006" nb-file="US08626801-20140107-M00006.NB">
<img id="EMI-M00006" he="10.58mm" wi="76.20mm" file="US08626801-20140107-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00007" nb-file="US08626801-20140107-M00007.NB">
<img id="EMI-M00007" he="10.24mm" wi="76.20mm" file="US08626801-20140107-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00008" nb-file="US08626801-20140107-M00008.NB">
<img id="EMI-M00008" he="6.35mm" wi="76.20mm" file="US08626801-20140107-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>labeling, by a device, a first portion of a first string of words as at least two attributes for a product associated with at least one document;</claim-text>
<claim-text>labeling, by the device, a second portion of the first string of words as at least two values for the product,
<claim-text>the first portion of the first string of words being different than the second portion of the first string of words;</claim-text>
</claim-text>
<claim-text>associating, by the device, the at least two attributes and the at least two values,
<claim-text>the associating including:
<claim-text>associating an attribute, of the at least two attributes, with a value, of the at least two values, to provide an attribute-value pair by:</claim-text>
</claim-text>
</claim-text>
<claim-text>merging attributes, of the at least two attributes, having one or more first correlation values that satisfy a correlation threshold; and merging values, of the at least two values, having one or more second correlation values that satisfy the correlation threshold;</claim-text>
<claim-text>identifying, by the device, a second string of words,
<claim-text>the second string of words being different than the first string of words, and</claim-text>
<claim-text>the second string of words including a plurality of words that are included in the first string of words;</claim-text>
</claim-text>
<claim-text>determining, by the device, that a context associated with the first string of words is similar to a context associated with the second string of words; and</claim-text>
<claim-text>labeling, by the device and based on determining that the context associated with the first string of words is similar to the context associated with the second string of words, a first portion of the second string of words as a value using the association of the at least two attributes and the at least two values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>obtaining the at least one document via a public communication network.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>storing the attribute-value pair.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where, when associating the attribute with the value to provide the attribute-value pair, the method further comprises:
<claim-text>calculating the one or more first correlation values between each of the at least two attributes; and</claim-text>
<claim-text>calculating the one or more second correlation values between each of the at least two values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>associating the attribute with the value based on selection criteria to provide the attribute-value pair.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>generating seed attributes; and</claim-text>
<claim-text>generating seed values,</claim-text>
<claim-text>where, when generating the seed attributes and generating the seed values, the method further comprises:
<claim-text>identifying the seed attributes and the seed values using a first algorithm applied to the at least one document, and</claim-text>
</claim-text>
<claim-text>where, when labeling the first portion of the first string of words as the at least two attributes and labeling the second portion of the first string of words as the least two values, the method further comprises:
<claim-text>labeling the first portion of the first string of words as the at least two attributes and labeling the second portion of the first string of words as the at least two values using at least one second algorithm operating upon the at least one document and based on the generated seed attributes and the generated seed values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where
<claim-text>when labeling the first portion of the first string of words as the at least two attributes, the method includes:
<claim-text>labeling a first sub-portion of the first portion with a first attribute of the at least two attributes; and</claim-text>
<claim-text>labeling a second sub-portion of the first portion with a second attribute of the at least two attributes, and</claim-text>
</claim-text>
<claim-text>when labeling the second portion of the first string of words as the at least two values, the method includes:
<claim-text>labeling a first sub-portion of the second portion with a first value of the at least two values; and</claim-text>
<claim-text>labeling a second sub-portion of the second portion with a second value of the at least two values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A device comprising:
<claim-text>a memory to store instructions; and</claim-text>
<claim-text>a processor to execute the instructions to:
<claim-text>label a first a portion of a first string of words as at least two attributes for a product associated with at least one document;</claim-text>
<claim-text>label a second portion of the first string of words as at least two values for the product,
<claim-text>the first portion of the first string of words being different than the second portion of the first string of words;</claim-text>
</claim-text>
<claim-text>associate the at least two attributes with the at least two values,
<claim-text>the processor, when associating the at least two attributes with the at least two values, being to:
<claim-text>associate an attribute, of the at least two attributes, with a value, of the at least two values, to provide an attribute-value pair by:</claim-text>
</claim-text>
</claim-text>
</claim-text>
<claim-text>merging attributes, of the at least two attributes, having one or more first correlation values that satisfy a correlation threshold; and merging values, of the at least two values, having one or more second correlation values that satisfy the correlation threshold;
<claim-text>identify a second string of words,
<claim-text>the second string of words being different than the first string of words, and</claim-text>
<claim-text>the second string of words including a plurality of words that are included in the first string of words;</claim-text>
</claim-text>
<claim-text>determine that a context associated with the first string of words is similar to a context associated with the second string of words; and</claim-text>
<claim-text>label, based on determining that the context associated with the first string of words is similar to the context associated with the second string of words, a first portion of the second string of words as a value using the association of the at least two attributes and the at least two values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, where the processor is further to:
<claim-text>obtain the at least one document via a public communication network.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, where the processor is further to:
<claim-text>store the attribute-value pair.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, where the processor is further to:
<claim-text>calculate the one or more first correlation values between each of the at least two attributes; and</claim-text>
<claim-text>calculate the or more second correlation values between each of the at least two values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, where the processor is further to:
<claim-text>associate the attribute with the value based on selection criteria to provide the attribute-value pair.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, where the processor is further to:
<claim-text>generate seed attributes; and</claim-text>
<claim-text>generate seed values,</claim-text>
<claim-text>where, when generating the seed attributes and generating the seed values, the processor is further to:
<claim-text>identify the seed attributes and the seed values using a first algorithm applied to the at least one document, and</claim-text>
</claim-text>
<claim-text>where, when labeling the first portion of the first string of words as the at least two attributes and labeling the second portion of the first string of words as the least two values, the processor is further to:
<claim-text>label the first portion of the first string of words as the at least two attributes and label the second portion of the first string of words as the at least two values using at least one second algorithm operating upon the at least one document and based on the generated seed attributes and the generated seed values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, where
<claim-text>the processor, when labeling the first portion of the first string of words as the at least two attributes, is further to:
<claim-text>label a first sub-portion of the first portion with a first attribute of the at least two attributes; and</claim-text>
<claim-text>label a second sub-portion of the first portion with a second attribute of the at least two attributes, and</claim-text>
</claim-text>
<claim-text>the processor, when labeling the second portion of the first string of words as the at least two values, is further to:
<claim-text>label a first sub-portion of the second portion with a first value of the at least two values; and</claim-text>
<claim-text>label a second sub-portion of the second portion with a second value of the at least two values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A non-transitory computer-readable medium storing instructions, the instructions comprising:
<claim-text>one or more instructions which, when executed by at least one processor, cause the at least one processor to:
<claim-text>label a first portion of a first string of words in at least one document as at least two attributes for a product;</claim-text>
<claim-text>label a second portion of the first string of words as at least two values for the product,
<claim-text>the first portion of the first string of words being different than the second portion of the first string of words;</claim-text>
</claim-text>
<claim-text>associate the at least two attributes and the at least two values,
<claim-text>the one or more instructions to associate the at least two attributes and the at two values including:
<claim-text>one or more instructions to associate an attribute, of the at least two attributes, with a value, of the at least two values, to provide an attribute-value pair by:</claim-text>
</claim-text>
</claim-text>
</claim-text>
<claim-text>merging attributes, of the at least two attributes, having one or more first correlation values that satisfy a correlation threshold; and merging values, of the at least two values, having one or more second correlation values that satisfy the correlation threshold;
<claim-text>identify a second string of words,
<claim-text>the second string of words being different than the first string of words, and</claim-text>
<claim-text>the second string of words including a plurality of words that are included in the first string of words;</claim-text>
</claim-text>
<claim-text>determine that a context associated with the first string of words is similar to a context associated with the second string of words; and</claim-text>
<claim-text>label, based on determining that the context associated with the first string of words is similar to the context associated with the second string of words, a first portion of the second string of words as a value using the association of the at least two attributes and the at least two values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, where the instructions further comprise:
<claim-text>one or more instructions to obtain the at least one document via a public communication network.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, where the instructions further comprise:
<claim-text>one or more instructions to store the attribute-value pair.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The non-transitory computer-readable medium <claim-ref idref="CLM-00015">claim 15</claim-ref>, where the one or more instructions to associate the attribute with the value to provide the attribute-value pair further comprise:
<claim-text>one or more instructions to calculate the one or more first correlation values between each of the at least two attributes; and</claim-text>
<claim-text>one or more instructions to calculate the one or more second correlation values between each of the at least two values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The non-transitory computer-readable medium <claim-ref idref="CLM-00015">claim 15</claim-ref>, where the instructions further comprise:
<claim-text>one or more instructions to associate the attribute with the value based on selection criteria to provide the attribute-value pair.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, where the instructions further comprise:
<claim-text>one or more instructions to generate seed attributes; and</claim-text>
<claim-text>one or more instructions to generate seed values,</claim-text>
<claim-text>where the one or more instructions to generate the seed attributes and the one or more instructions to generate the seed values further comprise:
<claim-text>one or more instructions to identify the seed attributes and the seed values using a first algorithm applied to the at least one document, and</claim-text>
</claim-text>
<claim-text>where the one or more instructions to label the first portion of the first string of words as the at least two attributes and the one or more instructions to label the second portion of the first string of words as the least two values further comprise:
<claim-text>one or more instructions to label the first portion of the first string of words as the at least two attributes and label the second portion of the first string of words as the least two values using a second algorithm operating upon the at least one document and based on the generated seed attributes and the generated seed values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, where
<claim-text>the one or more instructions to label the first portion of the first string of words as the at least two attributes include:
<claim-text>one or more instructions to label a first sub-portion of the first portion with a first attribute of the at least two attributes; and</claim-text>
<claim-text>one or more instructions to label a second sub-portion of the first portion with a second attribute of the at least two attributes, and</claim-text>
</claim-text>
<claim-text>the one or more instructions to label the second portion of the first string of words as the at least two values include:
<claim-text>one or more instructions to label a first sub-portion of the second portion with a first value of the at least two values; and</claim-text>
<claim-text>one or more instructions to label a second sub-portion of the second portion with a second value of the at least two values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. A method comprising:
<claim-text>labeling, by a device, a first set of attributes and a first set of values of a first string of words associated with a product using a first algorithm applied to the at least one document;</claim-text>
<claim-text>identifying, by the device, a second set of attributes and a second set of values of the product via a second algorithm applied to the at least one document and based on the first set of attributes and the first set of values,
<claim-text>the first algorithm being different than the second algorithm;</claim-text>
</claim-text>
<claim-text>associating, by the device, the first set of attributes and the second set of attributes with the first set of values and the second set of values,
<claim-text>the associating including:
<claim-text>associating the first set of attributes with the first set of values to provide one or more attribute-value pairs by:
<claim-text>merging attributes, of the first set of attributes, having one or more first correlation values that satisfy a correlation threshold; and</claim-text>
<claim-text>merging values, of the first set of values, having one or more second correlation values that satisfy the correlation threshold; and</claim-text>
</claim-text>
<claim-text>associating the second set of attributes with the second set of values to provide one or more attribute-value pairs by:
<claim-text>merging attributes, of the second set of attributes, having one or more first correlation values that satisfy the correlation threshold; and</claim-text>
<claim-text>merging values, of the second set of values, having one or more second correlation values that satisfy the correlation threshold;</claim-text>
</claim-text>
</claim-text>
</claim-text>
<claim-text>identifying, by the device, a second string of words,
<claim-text>the second string of words being different than the first string of words, and</claim-text>
<claim-text>the second string of words including a plurality of words that are included in the first string of words;</claim-text>
</claim-text>
<claim-text>determining, by the device, that a context associated with the first string of words is similar to a context associated with the second string of words; and</claim-text>
<claim-text>labeling, by the device and based on determining that the context associated with the first string of words is similar to the context associated with the second string of words, a first portion of the second string of words as a value or an attribute using the association of the first set of attributes and the second set of attributes with the first set of values and the second set of values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising:
<claim-text>accessing one or more seed attributes and one or more seed values identified by a third algorithm applied to the at least one document,
<claim-text>the third algorithm being different than the first algorithm and being different than the second algorithm; and</claim-text>
</claim-text>
<claim-text>identifying the first set of attributes and the first set of values based on the one or more accessed seed attributes and the one or more accessed seed values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising:
<claim-text>obtaining the at least one document via a public communication network.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. A device comprising:
<claim-text>a memory to store instructions; and</claim-text>
<claim-text>a processor to execute the instructions to:
<claim-text>identify a first set of attributes and a first set of values of a first string of words for a product associated with at least one document;</claim-text>
<claim-text>identify a second set of attributes and a second set of values of the product based on the first set of attributes and the first set of values;</claim-text>
<claim-text>associate the first set of attributes and the second set of attributes with the first set of values and the second set of values,
<claim-text>the processor, when associating the first set of attributes and the second set of attributes with the first set of values and the second set of values, being to:
<claim-text>associate the first set of attributes with the first set of values to provide one or more attribute-value pairs by:</claim-text>
</claim-text>
</claim-text>
</claim-text>
<claim-text>merging attributes, of the first set of attributes, having one or more first correlation values that satisfy a correlation threshold; and</claim-text>
<claim-text>merging values, of the first set of values, having one or more second correlation values that satisfy the correlation threshold; and associate the second set of attributes with the second set of values to provide one or more attribute-value pairs by:</claim-text>
<claim-text>merging attributes, of the second set of attributes, having one or more first correlation values that satisfy the correlation threshold; and merging values, of the second set of values, having one or more second correlation values that satisfy the correlation threshold;
<claim-text>identify a second string of words,
<claim-text>the second string of words being different than the first string of words, and</claim-text>
<claim-text>the second string of words including a plurality of words that are included in the first string of words;</claim-text>
</claim-text>
<claim-text>determine that a context associated with the first string of words is similar to a context associated with the second string of words; and</claim-text>
<claim-text>label, based on determining that the context associated with the first string of words is similar to the context associated with the second string of words, a first portion of the second string of words as a value or an attribute using the association of the first set of attributes and the second set of attributes with the first set of values and the second set of values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The device of <claim-ref idref="CLM-00025">claim 25</claim-ref>, where the processor is further to:
<claim-text>identify one or more seed attributes and one or more seed values based on the at least one document; and</claim-text>
<claim-text>identify the first set of attributes and the first set of values based on the one or more identified seed attributes and the one or more identified seed values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The device of <claim-ref idref="CLM-00025">claim 25</claim-ref>, where the processor is further to:
<claim-text>obtain the at least one document via a public communication network.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. A non-transitory computer-readable medium storing instructions, the instructions comprising:
<claim-text>one or more instructions which, when executed by at least one processor, cause the at least one processor to:
<claim-text>identify a first set of attributes and a first set of values of a first string of words for a product using a first algorithm applied to at least one document;</claim-text>
<claim-text>identify a second set of attributes and a second set of values of the product using a second algorithm applied to the at least one document and based on the first set of attributes and the first set of values,
<claim-text>the first algorithm being different than the second algorithm;</claim-text>
</claim-text>
<claim-text>associate the first set of attributes and the second set of attributes with the first set of values and the second set of values,
<claim-text>the one or more instructions to associate the first set of attributes and the second set of attributes with the first set of values and the second set of values including:
<claim-text>one or more instructions to associate the first set of attributes with the first set of values to provide one or more attribute-value pairs by:</claim-text>
</claim-text>
</claim-text>
</claim-text>
<claim-text>merging attributes, of the first set of attributes, having one or more first correlation values that satisfy a correlation threshold; and merging values, of the first set of values, having one or more second correlation values that satisfy the correlation threshold; and</claim-text>
<claim-text>one or more instructions to associate the second set of attributes with the second set of values to provide one or more attribute-value pairs by:</claim-text>
<claim-text>merging attributes, of the second set of attributes, having one or more first correlation values that satisfy the correlation threshold; and merging values, of the second set of values, having one or more second correlation values that satisfy the correlation threshold;
<claim-text>identify a second string of words,
<claim-text>the second string of words being different than the first string of words, and</claim-text>
<claim-text>the second string of words including a plurality of words that are included in the first string of words;</claim-text>
</claim-text>
<claim-text>determine that a context associated with the first string of words is similar to a context associated with the second string of words; and</claim-text>
<claim-text>label, based on determining that the context associated with the first string of words is similar to the context associated with the second string of words, a first portion of the second string of words as a value or an attribute using the association of the first set of attributes and the second set of attributes with the first set of values and the second set of values.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The non-transitory computer-readable medium of <claim-ref idref="CLM-00028">claim 28</claim-ref>, where the instructions further comprise:
<claim-text>one or more instructions to access one or more seed attributes and one or more seed values identified by a third algorithm applied to the at least one document,
<claim-text>the third algorithm being different than the first algorithm and being different than the second algorithm; and</claim-text>
</claim-text>
<claim-text>one or more instructions to identify the first set of attributes and the first set of values based on the one or more accessed seed attributes and the one or more accessed seed values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The non-transitory computer-readable medium of <claim-ref idref="CLM-00028">claim 28</claim-ref>, where the instructions further comprise:
<claim-text>one or more instructions to obtain the at least one document via a public communication network.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
