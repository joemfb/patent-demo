<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626897-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626897</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12463497</doc-number>
<date>20090511</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>334</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>173</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709224</main-classification>
<further-classification>709223</further-classification>
<further-classification>709226</further-classification>
</classification-national>
<invention-title id="d2e53">Server farm management</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6148335</doc-number>
<kind>A</kind>
<name>Haggard et al.</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6963828</doc-number>
<kind>B1</kind>
<name>McDonald et al.</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703 22</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7146353</doc-number>
<kind>B2</kind>
<name>Garg et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>  1  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7171668</doc-number>
<kind>B2</kind>
<name>Molloy et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7500001</doc-number>
<kind>B2</kind>
<name>Tameshige et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7613797</doc-number>
<kind>B2</kind>
<name>Stefaniak et al.</name>
<date>20091100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709221</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7647405</doc-number>
<kind>B2</kind>
<name>Bivens et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>7757214</doc-number>
<kind>B1</kind>
<name>Palczak et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>717121</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7769843</doc-number>
<kind>B2</kind>
<name>Neuse et al.</name>
<date>20100800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709223</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7986843</doc-number>
<kind>B2</kind>
<name>Chaudhury et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382229</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>8060599</doc-number>
<kind>B2</kind>
<name>Cherkasova et al.</name>
<date>20111100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>8145731</doc-number>
<kind>B2</kind>
<name>Cherkasova et al.</name>
<date>20120300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709220</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2003/0154282</doc-number>
<kind>A1</kind>
<name>Horvitz</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2003/0177160</doc-number>
<kind>A1</kind>
<name>Chiu et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2004/0103194</doc-number>
<kind>A1</kind>
<name>Islam et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2004/0153481</doc-number>
<kind>A1</kind>
<name>Talluri</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2004/0220947</doc-number>
<kind>A1</kind>
<name>Aman et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707100</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2004/0249939</doc-number>
<kind>A1</kind>
<name>Amini et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2004/0267897</doc-number>
<kind>A1</kind>
<name>Hill et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709217</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2005/0060389</doc-number>
<kind>A1</kind>
<name>Cherkasova et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709220</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2005/0138170</doc-number>
<kind>A1</kind>
<name>Cherkasova et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2005/0144280</doc-number>
<kind>A1</kind>
<name>Kawai et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709225</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2005/0149940</doc-number>
<kind>A1</kind>
<name>Calinescu et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718104</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2005/0228879</doc-number>
<kind>A1</kind>
<name>Cherkasova et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2005/0278439</doc-number>
<kind>A1</kind>
<name>Cherkasova</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2005/0278453</doc-number>
<kind>A1</kind>
<name>Cherkasova</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2006/0089982</doc-number>
<kind>A1</kind>
<name>Abbott et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709223</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2007/0233866</doc-number>
<kind>A1</kind>
<name>Appleby et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709226</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2008/0077366</doc-number>
<kind>A1</kind>
<name>Neuse et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703  2</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2009/0089419</doc-number>
<kind>A1</kind>
<name>Saha et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2009/0089699</doc-number>
<kind>A1</kind>
<name>Saha et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715771</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00032">
<othercit>&#x201c;Transforming Capacity Planning in Enterprise Data Centers&#x201d;, 2008 Hewlett-Packard Development Company, http://docs.hp.com/en/15052/CapPlan4AA1-9758ENW.pdf.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00033">
<othercit>&#x201c;ITIL and CMDB: The Challenge in the Data Center&#x201d;, 2009, Aperture Technologies, Inc., http://www.aperture.com/solutions/vista<sub>&#x2014;</sub>itil.php.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00034">
<othercit>Barchi, Alfred J., &#x201c;Throughput Capacity Planning and Application Saturation&#x201d;, 2007, Alfred J. Barchi, Inc., pp. 1-10, http://www.ajbinc.net/Assets/Throughput%Capacity%20Planning%20and%20Application%20Saturation.pdf.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00035">
<othercit>&#x201c;Neptuny Presents Capacity Planning for Heterogeneous Virtualized Environments at VMWorld Europe&#x201d;, 1999-2008, http://www.dabcc.com/article.aspx?id=9920.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00036">
<othercit>&#x201c;eG Citrix Monitor&#x201d;, 2003-2008 Portage Software Inc., pp. 1-4, http://www.portagesoftware.com/egcitrix.htm.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100287019</doc-number>
<kind>A1</kind>
<date>20101111</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Guo</last-name>
<first-name>Wei-Qiang Michael</first-name>
<address>
<city>Bellevue</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Wadhawan</last-name>
<first-name>Ajay</first-name>
<address>
<city>Yarrow Point</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Huang</last-name>
<first-name>Lin</first-name>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Dudziak</last-name>
<first-name>Jacek T.</first-name>
<address>
<city>Bellevue</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Guo</last-name>
<first-name>Wei-Qiang Michael</first-name>
<address>
<city>Bellevue</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Wadhawan</last-name>
<first-name>Ajay</first-name>
<address>
<city>Yarrow Point</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Huang</last-name>
<first-name>Lin</first-name>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Dudziak</last-name>
<first-name>Jacek T.</first-name>
<address>
<city>Bellevue</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Microsoft Corporation</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Microsoft Corporation</orgname>
<role>02</role>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Nguyen</last-name>
<first-name>Thu</first-name>
<department>2452</department>
</primary-examiner>
<assistant-examiner>
<last-name>Widhalm</last-name>
<first-name>Angela</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Techniques and systems are disclosed that can measure capacity of a server farm, and project capacity needs based on traffic and resources. Server farm system information is collected for managing the server farm by identifying a list of servers in the server farm. Performance metrics are collected from identified servers and stored in a collection database. The stored performance metrics are analyzed in accordance with a server farm management request.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="247.40mm" wi="187.28mm" file="US08626897-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="264.84mm" wi="193.46mm" file="US08626897-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="263.82mm" wi="192.36mm" file="US08626897-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="258.57mm" wi="186.18mm" file="US08626897-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="257.89mm" wi="182.37mm" file="US08626897-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="253.66mm" wi="189.31mm" file="US08626897-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="246.30mm" wi="167.30mm" file="US08626897-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="255.35mm" wi="192.70mm" file="US08626897-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">In a computing environment, servers are often used to store and manage data. A server may be a typical computing device used by a consumer, for example, or a specialized computing device designed merely for specific data storage and management operations. Often servers can be used individually or linked together to provide services to users, such as a home computer network, an office data storage network, or an online gaming environment.</p>
<p id="p-0003" num="0002">Servers may also be combined into a very large server farm that manages and stores very large amounts of data. Typical use of very large server farms may include online services systems, such as sites that provide Internet-based search engines, online mapping, document upload and retrieval services, and more. Other uses may include large enterprises, such as multi-national corporations and governmental operations, or large communication services, such as phone companies, Internet-service providers, and Internet-content provider or aggregators. These very-large server farms often comprise many hundreds or thousands of servers linked to appear as a single system to an end-user.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0004" num="0003">This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.</p>
<p id="p-0005" num="0004">Often, servers in a server farm are accumulated over time to increase capacity as usage grows. Because the computer-based hardware development cycle is progressing rapidly, accumulated hardware for a server farm is typically heterogeneous (e.g., more recently added hardware is of differing types or configurations than previously added hardware). Therefore, a server farm can have hardware of different row power, such as computer processing unit (CPU) and input/output (I/O) bandwidth.</p>
<p id="p-0006" num="0005">Having heterogeneous hardware configurations in a server farm can make it difficult and expensive to benchmark individual server performance, as each server may need to be tested instead of testing one and apply the results to the rest. Further, an aggregated performance of the heterogeneous servers may be quite different from an additive summation of individual performances, which can make it difficult for desired load-balancing, among other things, of the system. Additionally, aggregated performance of a heterogeneous hardware configuration is very complicated and difficult to replicate in a laboratory environment, due to large volumes of traffic in real-life. Combined, these problems provide a complicated task for system administrators to effectively manage a server farm, such as capacity resource management and planning.</p>
<p id="p-0007" num="0006">Prior solutions focus on benchmarking an application against a few varieties of hardware row power, and derive mathematical models of projected software capacity in non-test hardware configurations. These methods are expensive and typically require extensive testing. Further, prior methods do not produce aggregated performances for heterogeneous hardware configurations in a sever farm, nor can they project resource planning needs.</p>
<p id="p-0008" num="0007">Techniques and systems are disclosed herein that directly measure capacity of a server farm, and can heuristically project capacity expansion needs based on traffic growth trends. Further, the techniques and systems allow a server farm that comprises heterogeneous hardware configurations to be managed more effectively.</p>
<p id="p-0009" num="0008">In one embodiment, collecting and analyzing server farm system information for effectively managing a server farm comprises identifying a list of servers that are running in the server farm, for example, by accessing a server farm database that comprises active servers and respective application services running on the servers. Once servers are identified, performance metrics can be collected from the servers, such as hardware metrics (e.g., CPU speed, I/O bandwidth, storage, memory) and server usage metrics (e.g., applications, traffic counts, response times), and stored in a collection database. The stored performance metrics can then be analyzed in accordance with a server farm management request, such as from an administrator or an automated system request.</p>
<p id="p-0010" num="0009">To the accomplishment of the foregoing and related ends, the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects, advantages, and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating an exemplary environment where a server farm may be utilized.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart diagram of an exemplary method for collecting and analyzing server farm system information for effectively managing a server farm.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref> is an embodiment of a portion of an exemplary method where configuration metrics and server usage metrics that can be collected.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4</figref> is a chart diagram illustrating one embodiment of how data stored in a collection database may be analyzed.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart diagram illustrating one embodiment of an application for collecting and analyzing server farm system information for effectively managing a server farm.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 6</figref> is a component block illustrating an exemplary system for collecting and analyzing server farm system information for effectively managing a server farm.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 7</figref> is an illustration of one embodiment of a component for a system for collecting and analyzing server farm system information for effectively managing a server farm.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 8</figref> is an illustration of an exemplary environment where one embodiment of one or more of the systems described herein may be utilized.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 9</figref> is an illustration of an exemplary computer-readable medium comprising processor-executable instructions configured to embody one or more of the provisions set forth herein.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 10</figref> illustrates an exemplary computing environment wherein one or more of the provisions set forth herein may be implemented.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0021" num="0020">The claimed subject matter is now described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident, however, that the claimed subject matter may be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram illustrating an exemplary environment <b>100</b> where a server farm may be utilized. A server farm <b>102</b> can comprise a plurality of servers <b>104</b>, such as special purpose computers that are designed to store and manage data (e.g., store custom applications used to serve user requests such as user login authentication, store user data for custom application needs, and/or perform customized processing, not directly taking traffic from end users, but performing (constant) offline processing). It will be appreciated that a server in a data storage and management network, such as a server farm, can be a device attached to the network as a connection point, redistribution point or communication endpoint. A server may be capable of storing, sending, receiving, and/or forwarding information for a network, and could comprise any device that meets any or all of these criteria.</p>
<p id="p-0023" num="0022">In one embodiment, a plurality of users <b>106</b> may be connected to the server farm <b>102</b> over a connection network, such as the Internet. As an example, a server farm may be part of an Internet-based services network (e.g., search engine, map service, virtual storage) that allows users <b>106</b> to retrieve information that may be stored on or accessed by the server farm <b>106</b>. The server farms can be further connected to other networks <b>108</b>, such as the Internet, for updating and retrieving information stored on the servers <b>104</b> in the server farm <b>102</b>.</p>
<p id="p-0024" num="0023">Typically, one or more administrators <b>110</b> are tasked with managing the server farm's operations, which can include ongoing software and hardware maintenance, as well as planning for capacity increases based on user traffic. For example, as more users <b>106</b> access the server farm, and/or more services are added to the server farm, a corresponding increase in user traffic is likely. Therefore, in this example, an administrator <b>110</b> may wish to plan for adding hardware and/or software resources to the server farm based on the increase in traffic.</p>
<p id="p-0025" num="0024">A method may be devised that provides for collecting computing resource consumption information for a server farm, and analyzing that information in association with the server farm's resources to develop capacity planning information, for example. <figref idref="DRAWINGS">FIG. 2</figref> is a flow chart diagram of an exemplary method <b>200</b> for collecting and analyzing server farm system information for effectively managing a server farm.</p>
<p id="p-0026" num="0025">The exemplary method <b>200</b> begins at <b>202</b> and involves identifying a list of servers running in the server farm, at <b>204</b>. In one embodiment, the list of servers may be retrieved from a database that is used to store hardware and software configurations for the server farm. Some large server farms that are used to provide online services can comprise hundreds or thousands of servers, for example, so an administrator may utilize a database to facilitate management of the multitude of servers and services.</p>
<p id="p-0027" num="0026">Further, in one embodiment, the hardware configurations for servers in the server farm may be heterogeneous. For example, when a new server is added to the server farm, or a hardware upgrade is undertaken, the newly installed hardware may be different than the existing servers or hardware. Therefore, in this embodiment, when identifying the servers in the server farm, two or more servers may be heterogeneous, comprising different hardware configurations.</p>
<p id="p-0028" num="0027">At <b>206</b>, performance metrics are collected from respective identified servers and stored in a collection database. Respective servers that are identified in the list of servers for the server farm can be probed to determine performance metrics. In one embodiment, collecting performance metrics can comprise collecting hardware configuration metrics for a server, and collecting server usage metrics for the server. For example, in order to develop a resource capacity plan for the server farm, an administrator may wish to identify specific hardware and software configurations for respective servers, along with traffic patterns and resource usage over time.</p>
<p id="p-0029" num="0028">One embodiment <b>300</b> of hardware configuration metrics and server usage metrics that can be collected is illustrated in <figref idref="DRAWINGS">FIG. 3</figref>. In this embodiment <b>300</b>, collecting hardware configuration metrics <b>310</b> can comprise collecting central processing unit (CPU) configuration information for the server <b>314</b>, such as CPU type and processing speed. Further, collecting hardware configuration metrics <b>310</b> can comprise collecting memory configuration information for the server <b>318</b>, such as size and speed. Additionally, collecting hardware configuration metrics <b>310</b> can comprise collecting storage configuration information for the server <b>318</b>, such as disk size and speed. Collecting hardware configuration metrics <b>310</b> can also comprise collecting data traffic routing information for the server <b>320</b>, such as bus speed, and amounts and types of connections (e.g., network and database connections).</p>
<p id="p-0030" num="0029">In this embodiment <b>300</b>, collecting server usage metrics <b>312</b> can comprise collecting information for application services installed on the server <b>322</b>, such as the types and number of applications running on the server that are utilized by server farm users (e.g., <b>106</b> from <figref idref="DRAWINGS">FIG. 1</figref>). Further, collecting server usage metrics <b>312</b> can comprise collecting incoming traffic counts over time to the server <b>324</b>, such as a number of requests for data from the server farms (e.g., as sent by users of an online service). Collecting server usage metrics <b>312</b> can comprise collecting server hardware usage data <b>326</b> for the respective hardware units associated with a server, such as CPU, memory, I/O elements, bandwidth, and/or database connections, for example. Additionally, collecting server usage metrics <b>312</b> can comprise collecting response counts over time from the server <b>328</b>, such as responses to requests sent by the servers in the server farm. Collecting server usage metrics <b>312</b> can also comprise collecting transaction types for the server <b>330</b>, such as a type of request and/or type of response.</p>
<p id="p-0031" num="0030">In one aspect, collecting hardware configuration metrics and server usage metrics can be based on a type and location of the server in the server farm, and services that it may provide, for example. For example, a server farm may comprise front end web-based services that can be accessed by users to provide the web-based services, such as search engines, mapping, document storage and retrieval. In this example, the front end servers may comprise one or more applications configured to provide services to the users, CPUs that provide faster processing speed, and larger/faster memory for running multiple applications.</p>
<p id="p-0032" num="0031">Further, in this aspect, a server farm may comprise backend storage-focused servers that can provide large amounts of data storage for a server farm. For example, where a server farm may be used to provide online services, the backend servers may be used to store indexes for search engine document retrieval, data to provide maps for an online mapping service, and documents stored by users of a document storage and retrieval service. In this example, the servers may comprise large amounts of disk or other non-volatile data storage, along with network connections for database management, and data storage and retrieval operations.</p>
<p id="p-0033" num="0032">In another aspect, collection of performance metrics for a server farm may be based on a type of analysis that is requested or pre-determined by rules setup by an administrator or automated system manager. In one embodiment, when collecting data for a capacity calculation or forecast, elements of the calculation can be collected by identifying where a bottle neck in the hardware configuration may occur (if at all). For example, during performance metric collection, one may be able to identify that a first bottle neck in the data request/response stream occurs in the CPU, memory, a database connection, or the I/O services. In this way, in this example, resource planning may be undertaken based on identifying potential bottlenecks in the hardware configuration.</p>
<p id="p-0034" num="0033">In one embodiment, the server identification and metric collection can be automated, such that the server farm periodically collects performance metrics for its respective servers and stores the information in the collection database. In this way, in this embodiment, current and historical information may be available for analysis at anytime, for example, by a system administrator or by some automated server farm management tool. In another embodiment, the server identification and metric collection may be in response to a specific command by the system administrator, for example, in response to a specific server farm management request.</p>
<p id="p-0035" num="0034">It will be appreciated that the methods and systems, described herein, are not limited to the performance metrics embodiments described above. These embodiments are illustrative of typical types of performance metrics that can be utilized by the methods and systems, described herein, however, it is anticipated that those skilled in the art may devise alternate performance metrics that can be collected and utilized in these methods and/or systems.</p>
<p id="p-0036" num="0035">Returning to <figref idref="DRAWINGS">FIG. 2</figref>, at <b>208</b> of the exemplary method <b>200</b>, the performance metrics stored in the collection database are analyzed in accordance with a server farm management request. In one embodiment, a server farm management request may comprise an automated request sent by a component in the server farm management component. For example, the server farm management component may wish to periodically determine whether the current resources are capable of handling the expected traffic load at a desired response rate, such as for alerting purpose. In another embodiment, a request may be developed by a system administrator for a particular purpose, such as developing a resource capacity plan for adding new hardware.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 4</figref> is a chart diagram illustrating one embodiment <b>400</b> of how data stored in the collection database may be analyzed. At <b>208</b>, the performance metrics stored in the collection database can be analyzed by determining a resource cost on a server per request per service <b>410</b>, such as how much CPU time, memory, I/O resources, or disk space is used to perform a particular service request. In another embodiment, a function curve of a resource cost on a server per request per second can be determined to illustrate a non-linear relationship between requests and hardware. Further, the performance metrics can be analyzed <b>208</b> by determining a traffic trend of requests per service over time <b>412</b>, such as identifying peak usage of a particular service. Additionally, the performance metrics can be analyzed <b>208</b> by determining a forecast of traffic trends for the server farm <b>414</b>, such as identifying potential increases in traffic for a particular service and/or server. The performance metrics can also be analyzed <b>208</b> by determining a forecasted server farm resource capacity plan <b>416</b>, such as determining what type and amount of new hardware may be used to keep up with potential traffic trends.</p>
<p id="p-0038" num="0037">In this embodiment <b>400</b>, determining a forecasted server farm resource capacity plan <b>416</b> can be based on one or more factors. Existing server farm hardware <b>418</b> (e.g., types of servers, CPU speed, memory size, storage space, I/O resources, etc.), server farm resource usage <b>420</b> (e.g., which servers, storage, I/O, etc. are used more than others), and server farm traffic patterns <b>422</b> (e.g., how many requests for which services) can be utilized for forecasting a resource capacity plan. Further, in this embodiment <b>400</b>, forecasted server farm traffic patterns (e.g., as in <b>414</b>) can be used to plan. Additionally, future releases of application services for the server farm, and available hardware upgrades to the server farm can be utilized when developing a resource capacity plan, such as to determine which applications and/or hardware upgrades can yield an improved response time or resource use per request cost.</p>
<p id="p-0039" num="0038">It will be appreciated that the methods and systems, described herein, are not limited to the analysis embodiments described above. These embodiments are illustrative of typical types of analysis that can be utilized by the methods and systems, described herein, however, it is anticipated that those skilled in the art may devise alternate analysis that can performed by these methods and systems.</p>
<p id="p-0040" num="0039">Returning to <figref idref="DRAWINGS">FIG. 2</figref>, having analyzed the data stored in the collection database, the exemplary method <b>200</b> ends at <b>210</b>.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart diagram illustrating one embodiment <b>500</b> of an application of the methods for collecting and analyzing server farm system information for effectively managing a server farm, described herein. At <b>504</b>, the servers that comprise the server farm are identified. The list of servers is obtained at <b>506</b>, which may be collected from a server farm database that stores information pertaining to the server farm's topology (e.g., hardware and software configurations). In this embodiment, if as server is added to (e.g., new hardware added or restored service to a machine) or removed from (e.g., taken out of service or system error), at <b>508</b>, it may be automatically identified in the list of servers (or removed from the list).</p>
<p id="p-0042" num="0041">At <b>510</b>, it can be determined whether a particular server is actually in service (e.g., operating appropriately) in the server farm. If not, at <b>516</b>, a next server can be identified and determined whether it is in service. If the server is in service, at <b>512</b>, the particular server can be probed for performance metrics, which can be collected. At <b>514</b>, the respective servers are identified and performance metrics are collected for the respective servers, at <b>512</b>.</p>
<p id="p-0043" num="0042">At <b>518</b>, the collected performance metrics can be aggregated, such as by server, service, historically, or some other aggregation, and stored in a collection database, at <b>520</b>. It will be appreciated that the server farm's topology database and the collection database may be comprised in a same component, distributed over the server farm, or maintained as separate entities.</p>
<p id="p-0044" num="0043">At <b>522</b>, the metrics stored in the collection database can be analyzed in accordance with a server farm management request <b>524</b>. A request <b>524</b> may be generated by a server farm management component (e.g., automatically) in response to some activity or occurrence within the server farm, such as an automated resource capacity alert. Further, a request <b>524</b> may be generated by a user interface utilized by a server farm administrator, such as for capacity planning. In this embodiment, <b>500</b>, a response report <b>526</b> can be returned from the analysis <b>522</b>, for example, to the server farm management component or the system administrator.</p>
<p id="p-0045" num="0044">In one embodiment, desired historical performance metrics may not be available for a particular server. As an example, when a new server is brought online, and or a new service is introduced on a server, historical metrics for that server would not be available. In this embodiment, corresponding lab derived performance metrics may be used when analyzing performance metrics. For example, while performance metrics may not be available for a particular server that is recently added to service, performance metrics for a comparable server having a comparable hardware configuration may have been collected in lab testing. In this embodiment, if the hardware configuration of the lab tested hardware is comparable to the newly installed hardware, the corresponding lab data can be used for the analysis of the server.</p>
<p id="p-0046" num="0045">In one embodiment, a lab may utilize fixed hardware to derive a relative hardware cost of requests of different services running in a server farm. In one example, the relative costs between requests of services for the server farm can be derived by applying the relative cost to different physical hardware machines based on performance/resource usage data that has been collected, and deriving a request per cost on those different sets of physical machines. Further, in one embodiment, traffic cost can be forecast on yet to be added machines, based on a machine's relative characteristics as compared with tested hardware configurations. In one example, a resource cost can be obtained through a request pipe-line (e.g., to determine a front end (FE) service cost, middle tier cost and/or backend cost). In general, one backend component (e.g., SQL) supports multiple front end components. There could be a bottle neck on a backend component (e.g., SQL) before front end components experience bottle-necks (e.g., related to CPU, Memory etc), such that capacity planning could use the pipe-line cost module when forecasting whether the capacity of the system can provide adequate support, or whether one or more new hardware matrices should be investigated to provide the needed support.</p>
<p id="p-0047" num="0046">A system may be devised that provides for collecting computing resource consumption information for a server farm, and analyzes the information in association with the server farm's resources to develop capacity planning information, for example. <figref idref="DRAWINGS">FIG. 6</figref> is a component block diagram of an exemplary system <b>600</b> for collecting and analyzing server farm system information for effectively managing a server farm. For example, the exemplary system may be utilized by a system administrator to develop a resource plan for the server farm based on its capacity and use.</p>
<p id="p-0048" num="0047">The exemplary system <b>600</b> comprises a topology information repository <b>602</b> (TIR) that is configured to store information for hardware and services running in the server farm. For example, the server farm may comprise a plurality of servers, each having one or more services (e.g., Internet-based services) running on them. In this example, the TIR <b>602</b> can be used to store server configuration information and respective service configuration for the servers. In one embodiment, the TIR may be comprised in its own storage system; however, the system is not limited to this embodiment. For example, the TIR may comprise a distributed database, distributed over a plurality of servers in the server farm. Further, for example, the TIR may be comprised in a shared database that shares resources with one or more other databases for the server farm.</p>
<p id="p-0049" num="0048">The exemplary system <b>600</b> comprises a capacity collector <b>604</b> that is disposed on one or more servers in the server farm. For example, the capacity collector <b>604</b> may be a component disposed on a specialized server in the server farm, or it may be distributed over a plurality of servers on the server farm. The capacity collector <b>604</b> is configured to collect from the TIR <b>602</b> a list of servers running in the server farm and corresponding services running on the respective servers.</p>
<p id="p-0050" num="0049">The exemplary system <b>600</b> further comprises a performance collector <b>606</b> that is operably coupled to the capacity collector <b>604</b>. The performance collector <b>606</b> is configured to collect performance metrics from the servers and services identified by the capacity collector <b>604</b>. In one embodiment, the performance collector <b>606</b> may be distributed over a plurality of servers in the server farm, and may collect performance metrics from respective servers on which it resides. In this embodiment, the capacity collector <b>604</b> may send information to the distributed performance collector <b>606</b>, identifying respective servers and services.</p>
<p id="p-0051" num="0050">In another embodiment, the performance collector <b>606</b> may reside on a specialized server, from which it probes respective identified servers for performance metrics, for example, pulling the metrics from the servers. In this embodiment, for example, a list of servers and services can be retrieved from (or sent from) the capacity collector <b>604</b>. In another example, respective servers and their corresponding services may be retrieved from (or sent from) the capacity collector <b>604</b> as needed to complete the metrics retrieval process.</p>
<p id="p-0052" num="0051">The exemplary system <b>600</b> further comprises a resource consumption repository <b>608</b> (RCR) that is operably coupled to the performance collector <b>606</b>. The RCR <b>608</b> is configured to store performance metrics collected by the performance collector <b>606</b>. In one embodiment, the RCR may be comprised in its own storage system; however, the system is not limited to this embodiment. For example, the RCR may comprise a distributed database, distributed over a plurality of servers in the server farm. Further, for example, the RCR may be comprised in a shared database that shares resources with one or more other databases for the server farm.</p>
<p id="p-0053" num="0052">In one embodiment, the RCR <b>608</b> may be utilized to store historical performance metrics for the server farm. For example, the exemplary system <b>600</b> may be devised to automatically perform periodic capacity collection and performance collection operations. The automated data collection information can comprise historical information for particular servers and services running in the server farm, such as traffic counts, response times, etc. Therefore, for example, the RCR <b>608</b> may comprise both historical and current performance metrics for the respective servers and services running in the server farm.</p>
<p id="p-0054" num="0053">The exemplary system <b>600</b> further comprises a data analyzer <b>610</b> that is operably coupled to the RCR <b>608</b>. The data analyzer <b>610</b> is configured to analyze performance metrics stored in the RCR <b>608</b> in accordance with a server farm management request <b>650</b>. For example, a request <b>650</b> for analysis may be an automated task from a server farm management component or created by a system administrator. The data analyzer <b>610</b> can facilitate in generating an analysis report <b>652</b> that is responsive to specific request elements (e.g., customized).</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 7</figref> illustrates one embodiment <b>700</b> of the data analyzer <b>610</b>, where the data analyzer <b>610</b> comprises a service trend analyzer <b>702</b>, which can be configured to determine server farm user requests per service type trend information. For example, the service trend analyzer <b>702</b> may use the user requests for a particular service to determine a trend, such as a function that illustrates an increase of requests over time. In this way, in this example, an administrator may be able to identify when a resource limit for the server farm may be reached.</p>
<p id="p-0056" num="0055">In the exemplary embodiment <b>700</b>, the data analyzer <b>610</b> further comprises a hardware trend analyzer <b>704</b> that is configured to determine server farm user requests per hardware type trend information. For example, the hardware trend analyzer <b>702</b> may use the user requests that route to a particular server to determine a trend, such as a function that illustrates a how requests may be increasing over time for the server. In this way, in this example, the trend information may be used to forecast a resource plan that identifies a type and configuration of hardware that may handle the request trends.</p>
<p id="p-0057" num="0056">The data analyzer <b>610</b> further comprises a resource capacity forecaster <b>706</b>, which is configured to determine a resource capacity for the server farm based on the trend information. As an example, the trend information generated by the service trend analyzer <b>702</b> and/or the hardware trend analyzer <b>704</b> may be used by the resource capacity forecaster <b>706</b> to determine when the server farm resources may no longer be capable of handling requests at a desired response rate, or at a desired resource cost per request. In one embodiment, an alert may be generated when the resource capacity forecaster <b>706</b> determines that a threshold for resource capacity is reached by requests. In this way, in this example, an administer may take action to prevent an undesirable response times that could affect user loyalty to an online services site.</p>
<p id="p-0058" num="0057">The data analyzer <b>610</b> further comprises a resource capacity planner <b>708</b> that is configured to determine planned resource additions for the server farm based on the trend information. For example, by utilizing trend information and existing hardware metrics, the resource capacity planner <b>708</b> may be able to determine what type and amount of hardware and/or software upgrades may be needed to meet a desired service level, such as response time and/or resource cost per request. Further, in one embodiment, the resource capacity planner <b>708</b> may be used to compare changes in response time and/or resource cost per request for alternate hardware and/or software upgrade configurations. In this way, for example, an administrator may more readily plan for future upgrade costs and scheduling.</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. 8</figref> is an illustration of an exemplary environment <b>800</b> where one embodiment of the systems described herein may be utilized. In this embodiment, a server farm <b>854</b> comprises a plurality of servers, for example, that may be used to service user requests. For example, a server farm may be utilized by an online services system (e.g., Internet-based search engine and other services), for enterprise data management (e.g., large corporate or government data storage and management), and data traffic routing (e.g., internet service providers, online content providers/aggregators).</p>
<p id="p-0060" num="0059">In this embodiment, the system comprises a server farm configuration updater <b>820</b> that can be configured to update database information for hardware and services running in the server farm <b>854</b> stored in the TIR <b>602</b>. For example, servers, other hardware, and software components may be added (e.g., coming online after a fault, or upgrades), and/or dropped (e.g., system failure, or upgrades) from the server farm on an ongoing basis. In one embodiment, the server farm configuration updater <b>820</b> can detect when a server is added and/or dropped from active service in the server farm and update the TIR <b>602</b> accordingly.</p>
<p id="p-0061" num="0060">In this exemplary embodiment, the capacity collector <b>604</b> comprises a server service determination component <b>822</b> that is configured to determine whether a server identified from the TIR <b>602</b> is in-service in the server farm. While the configuration updater <b>820</b> may be able to provide updated data base information, the server service determination component <b>822</b> can be used to probe a particular server that is identified by the capacity collector <b>604</b> to determine whether it is still active, for example.</p>
<p id="p-0062" num="0061">Further, in the exemplary embodiment, the system comprises a performance metric aggregator <b>824</b>, which is configured to aggregate performance metrics collected by the performance collector <b>606</b> in accordance with pre-determined rules. In one embodiment, an administrator may utilize a user interface <b>826</b> to set up aggregation rules for the performance metric aggregator <b>824</b>. As an example, the aggregation rules may provide for aggregating incoming requests for a particular service on a particular server over a desired period of time. In this way, merely the data that is desired can be collected and aggregated in a useful manner, for example.</p>
<p id="p-0063" num="0062">Additionally, in the exemplary embodiment, the system comprises a user interface <b>826</b> (UI), which can be configured to provide a server farm administrator with an ability to request server farm data analysis. As described above, a request <b>850</b> for data analysis may be automated or can come from a system administrator, for example. In this embodiment, the UI <b>826</b> can be used by the administrator to construct data analysis requests based on particular needs of the administrator. The UI <b>826</b> may be operably coupled with the data analyzer <b>610</b>, which can retrieve information needed for the request from the RCR <b>608</b>. After the requested analysis is performed, a report can be sent back to the UI <b>826</b> and utilized by the administrator.</p>
<p id="p-0064" num="0063">Still another embodiment involves a computer-readable medium comprising processor-executable instructions configured to implement one or more of the techniques presented herein. An exemplary computer-readable medium that may be devised in these ways is illustrated in <figref idref="DRAWINGS">FIG. 9</figref>, wherein the implementation <b>900</b> comprises a computer-readable medium <b>908</b> (e.g., a CD-R, DVD-R, or a platter of a hard disk drive), on which is encoded computer-readable data <b>906</b>. This computer-readable data <b>906</b> in turn comprises a set of computer instructions <b>904</b> configured to operate according to one or more of the principles set forth herein. In one such embodiment <b>902</b>, the processor-executable instructions <b>904</b> may be configured to perform a method, such as the exemplary method <b>200</b> of <figref idref="DRAWINGS">FIG. 2</figref>, for example. In another such embodiment, the processor-executable instructions <b>904</b> may be configured to implement a system, such as the exemplary system <b>600</b> of <figref idref="DRAWINGS">FIG. 6</figref>, for example. Many such computer-readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.</p>
<p id="p-0065" num="0064">Although the subject matter has been described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims.</p>
<p id="p-0066" num="0065">As used in this application, the terms &#x201c;component,&#x201d; &#x201c;module,&#x201d; &#x201c;system&#x201d;, &#x201c;interface&#x201d;, and the like are generally intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to being, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and/or a computer. By way of illustration, both an application running on a controller and the controller can be a component. One or more components may reside within a process and/or thread of execution and a component may be localized on one computer and/or distributed between two or more computers.</p>
<p id="p-0067" num="0066">Furthermore, the claimed subject matter may be implemented as a method, apparatus, or article of manufacture using standard programming and/or engineering techniques to produce software, firmware, hardware, or any combination thereof to control a computer to implement the disclosed subject matter. The term &#x201c;article of manufacture&#x201d; as used herein is intended to encompass a computer program accessible from any computer-readable device, carrier, or media. Of course, those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 10</figref> and the following discussion provide a brief, general description of a suitable computing environment to implement embodiments of one or more of the provisions set forth herein. The operating environment of <figref idref="DRAWINGS">FIG. 10</figref> is only one example of a suitable operating environment and is not intended to suggest any limitation as to the scope of use or functionality of the operating environment. Example computing devices include, but are not limited to, personal computers, server computers, hand-held or laptop devices, mobile devices (such as mobile phones, Personal Digital Assistants (PDAs), media players, and the like), multiprocessor systems, consumer electronics, mini computers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.</p>
<p id="p-0069" num="0068">Although not required, embodiments are described in the general context of &#x201c;computer readable instructions&#x201d; being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media (discussed below). Computer readable instructions may be implemented as program modules, such as functions, objects, Application Programming Interfaces (APIs), data structures, and the like, that perform particular tasks or implement particular abstract data types. Typically, the functionality of the computer readable instructions may be combined or distributed as desired in various environments.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 10</figref> illustrates an example of a system <b>1010</b> comprising a computing device <b>1012</b> configured to implement one or more embodiments provided herein. In one configuration, computing device <b>1012</b> includes at least one processing unit <b>1016</b> and memory <b>1018</b>. Depending on the exact configuration and type of computing device, memory <b>1018</b> may be volatile (such as RAM, for example), non-volatile (such as ROM, flash memory, etc., for example) or some combination of the two. This configuration is illustrated in <figref idref="DRAWINGS">FIG. 10</figref> by dashed line <b>1014</b>.</p>
<p id="p-0071" num="0070">In other embodiments, device <b>1012</b> may include additional features and/or functionality. For example, device <b>1012</b> may also include additional storage (e.g., removable and/or non-removable) including, but not limited to, magnetic storage, optical storage, and the like. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. 10</figref> by storage <b>1020</b>. In one embodiment, computer readable instructions to implement one or more embodiments provided herein may be in storage <b>1020</b>. Storage <b>1020</b> may also store other computer readable instructions to implement an operating system, an application program, and the like. Computer readable instructions may be loaded in memory <b>1018</b> for execution by processing unit <b>1016</b>, for example.</p>
<p id="p-0072" num="0071">The term &#x201c;computer readable media&#x201d; as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory <b>1018</b> and storage <b>1020</b> are examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, Digital Versatile Disks (DVDs) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by device <b>1012</b>. Any such computer storage media may be part of device <b>1012</b>.</p>
<p id="p-0073" num="0072">Device <b>1012</b> may also include communication connection(s) <b>1026</b> that allows device <b>1012</b> to communicate with other devices. Communication connection(s) <b>1026</b> may include, but is not limited to, a modem, a Network Interface Card (NIC), an integrated network interface, a radio frequency transmitter/receiver, an infrared port, a USB connection, or other interfaces for connecting computing device <b>1012</b> to other computing devices. Communication connection(s) <b>1026</b> may include a wired connection or a wireless connection. Communication connection(s) <b>1026</b> may transmit and/or receive communication media.</p>
<p id="p-0074" num="0073">The term &#x201c;computer readable media&#x201d; may include communication media. Communication media typically embodies computer readable instructions or other data in a &#x201c;modulated data signal&#x201d; such as a carrier wave or other transport mechanism and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.</p>
<p id="p-0075" num="0074">Device <b>1012</b> may include input device(s) <b>1024</b> such as keyboard, mouse, pen, voice input device, touch input device, infrared cameras, video input devices, and/or any other input device. Output device(s) <b>1022</b> such as one or more displays, speakers, printers, and/or any other output device may also be included in device <b>1012</b>. Input device(s) <b>1024</b> and output device(s) <b>1022</b> may be connected to device <b>1012</b> via a wired connection, wireless connection, or any combination thereof. In one embodiment, an input device or an output device from another computing device may be used as input device(s) <b>1024</b> or output device(s) <b>1022</b> for computing device <b>1012</b>.</p>
<p id="p-0076" num="0075">Components of computing device <b>1012</b> may be connected by various interconnects, such as a bus. Such interconnects may include a Peripheral Component Interconnect (PCI), such as PCI Express, a Universal Serial Bus (USB), firewire (IEEE 1394), an optical bus structure, and the like. In another embodiment, components of computing device <b>1012</b> may be interconnected by a network. For example, memory <b>1018</b> may be comprised of multiple physical memory units located in different physical locations interconnected by a network.</p>
<p id="p-0077" num="0076">Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example, a computing device <b>1030</b> accessible via network <b>1028</b> may store computer readable instructions to implement one or more embodiments provided herein. Computing device <b>1012</b> may access computing device <b>1030</b> and download a part or all of the computer readable instructions for execution. Alternatively, computing device <b>1012</b> may download pieces of the computer readable instructions, as needed, or some instructions may be executed at computing device <b>1012</b> and some at computing device <b>1030</b>.</p>
<p id="p-0078" num="0077">Various operations of embodiments are provided herein. In one embodiment, one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media, which if executed by a computing device, will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further, it will be understood that not all operations are necessarily present in each embodiment provided herein.</p>
<p id="p-0079" num="0078">Moreover, the word &#x201c;exemplary&#x201d; is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as &#x201c;exemplary&#x201d; is not necessarily to be construed as advantageous over other aspects or designs. Rather, use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application, the term &#x201c;or&#x201d; is intended to mean an inclusive &#x201c;or&#x201d; rather than an exclusive &#x201c;or&#x201d;. That is, unless specified otherwise, or clear from context, &#x201c;X employs A or B&#x201d; is intended to mean any of the natural inclusive permutations. That is, if X employs A; X employs B; or X employs both A and B, then &#x201c;X employs A or B&#x201d; is satisfied under any of the foregoing instances. In addition, the articles &#x201c;a&#x201d; and &#x201c;an&#x201d; as used in this application and the appended claims may generally be construed to mean &#x201c;one or more&#x201d; unless specified otherwise or clear from context to be directed to a singular form.</p>
<p id="p-0080" num="0079">Also, although the disclosure has been shown and described with respect to one or more implementations, equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components (e.g., elements, resources, etc.), the terms used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., that is functionally equivalent), even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition, while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations, such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore, to the extent that the terms &#x201c;includes&#x201d;, &#x201c;having&#x201d;, &#x201c;has&#x201d;, &#x201c;with&#x201d;, or variants thereof are used in either the detailed description or the claims, such terms are intended to be inclusive in a manner similar to the term &#x201c;comprising.&#x201d;</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for collecting and analyzing server farm information for managing a server farm, comprising:
<claim-text>identifying a list of servers running in the server farm;</claim-text>
<claim-text>collecting performance metrics from respective identified servers and storing the performance metrics in a collection database, comprising:
<claim-text>determining that at least some performance metrics are not available for at least a part of a first server;</claim-text>
<claim-text>responsive to determining that at least some performance metrics are not available, determining a hardware configuration for lab tested hardware;</claim-text>
<claim-text>determining that the lab tested hardware is comparable to at least the part of the first server; and</claim-text>
<claim-text>responsive to determining that the lab tested hardware is comparable, collecting performance metrics associated with the lab tested hardware and storing the performance metrics associated with the lab tested hardware in the collection database in association with the first server; and</claim-text>
</claim-text>
<claim-text>analyzing the performance metrics stored in the collection database in accordance with a server farm management request to create an expansion resource capacity plan associated with one or more available hardware upgrades for one or more existing servers within the server farm, the analyzing comprising evaluating a function curve indicative of requests to a server and hardware resource costs of the server to create the expansion resource capacity plan.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, collecting performance metrics comprising one or more of:
<claim-text>collecting one or more hardware configuration metrics for the server; or</claim-text>
<claim-text>collecting one or more server usage metrics for the server.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, collecting one or more hardware configuration metrics comprising collecting data traffic routing information for the server.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, collecting one or more server usage metrics comprising one or more of:
<claim-text>collecting incoming traffic counts over time to the server;</claim-text>
<claim-text>collecting response counts over time from the server; or</claim-text>
<claim-text>collecting transaction types for the server.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, identifying a list of servers comprising identifying two or more servers in the server farm comprising heterogeneous hardware configurations.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, analyzing the performance metrics comprising one or more of:
<claim-text>determining a resource cost on a second server per request based upon request data obtained from a request pipe-line; or</claim-text>
<claim-text>determining a traffic trend of requests per service over time to determine peak usage of a service.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising creating the expansion resource capacity plan based on one or more of:
<claim-text>server farm traffic patterns;</claim-text>
<claim-text>forecasted server farm traffic patterns associated with the one or more available hardware upgrades; or</claim-text>
<claim-text>future releases of application services for the server farm.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, identifying a list of servers running in the server farm comprising one of more of:
<claim-text>detecting when a second server is added to the server farm; or</claim-text>
<claim-text>detecting when a third server is removed from the server farm.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, storing the performance metrics in a collection database comprising storing current and historical performance metrics for the respective servers.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising determining that the lab tested hardware is comparable based upon a comparison of the hardware configuration with the part of the first server.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising activating an alert that is triggered when a desired resource capacity threshold is forecasted based at least in part upon the analyzing.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, analyzing the performance metrics comprising determining a forecast of traffic trends for hardware upgrades that have yet to be added to the server farm.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A system for collecting and analyzing server farm information for managing a server farm, comprising:
<claim-text>a capacity collector disposed on one or more servers in the server farm and configured to collect a list of servers running in the server farm;</claim-text>
<claim-text>a performance collector operably coupled to the capacity collector and configured to collect performance metrics from at least some of the servers on the list;</claim-text>
<claim-text>a resource consumption repository operably coupled to the performance collector and configured to store performance metrics collected by the performance collector; and</claim-text>
<claim-text>a data analyzer operably coupled to the resource consumption repository and configured to:
<claim-text>analyze performance metrics stored in the resource consumption repository in accordance with a server farm management request to create an expansion resource capacity plan associated with one or more available hardware upgrades for one or more existing servers within the server farm;</claim-text>
<claim-text>evaluate a function curve indicative of requests to a server and hardware resource costs of the server to create the expansion resource capacity plan; and</claim-text>
<claim-text>Identify a bottle neck in at least one of a front end associated with the server farm or a back end associated with the server farm to create the expansion resource capacity plan.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, the capacity collector comprising a server service determination component configured to determine whether a server is in-service in the server farm.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, comprising a server farm configuration updater configured to update information for hardware and services running in the server farm.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, comprising a performance metric aggregator configured to aggregate performance metrics collected by the performance collector.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, the data analyzer comprising one or more of:
<claim-text>a service trend analyzer configured to determine server farm user requests per service type trend information;</claim-text>
<claim-text>a hardware trend analyzer configured to determine server farm user requests per hardware type trend information; or</claim-text>
<claim-text>a resource capacity forecaster configured to determine a resource capacity for the server farm based on trend information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, the data analyzer utilizing a hardware unit cost per request per second for capacity determination.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, comprising a user interface configured to provide a server farm administrator with an ability to request server farm data analysis.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A tangible computer readable storage device comprising computer executable instruction that when executed via a processor on a computer perform a method for collecting and analyzing server farm information for managing a server farm, comprising:
<claim-text>identifying a list of servers running in the server farm, comprising:
<claim-text>detecting when a first server is added to the server farm; or</claim-text>
<claim-text>detecting when a second server is removed from the server farm;</claim-text>
</claim-text>
<claim-text>collecting performance metrics from respective identified servers and storing the performance metrics in a collection database, at least some of the performance metrics corresponding to at least two of a central processing unit type, a central processing unit speed, a storage disk size, a storage disk speed, bus weed, a number of one or more connections, a Woe of one or more connections, a number of applications concurrently running on one or more servers, a type of an application comprised in one or more servers, a bandwidth, or a number of databases, collecting performance metrics and storing a performance metrics comprising:
<claim-text>determining that at least some performance metrics are not available for at least a part of a third server;</claim-text>
<claim-text>responsive to determining a that at least some performance metrics are not available, determining lab tested hardware,</claim-text>
<claim-text>determining a that the lab tested hardware is comparable to at least the part of the third server; and</claim-text>
<claim-text>responsive to determining a that the lab tested hardware is comparable, collecting performance metrics associated with the lab tested hardware and storing a the performance metrics associated with the lab tested hardware in the collection database in association with the third server; and</claim-text>
</claim-text>
<claim-text>analyzing the performance metrics stored in the collection database in accordance with a server farm management request to create an expansion resource capacity plan associated with one or more available hardware upgrades for one or more existing servers within the server farm, the analyzing comprising evaluating a function curve indicative of requests to a server and hardware resource costs of the server to create the expansion resource capacity plan, the expansion resource capacity plan at least one of created or modified based upon at least two of:
<claim-text>an identification of a bottle neck in at least one of a front end associated with the server farm or a back end associated with the server farm;</claim-text>
<claim-text>server farm traffic patterns;</claim-text>
<claim-text>forecasted server farm traffic patterns associated with the one or more available hardware upgrades; or</claim-text>
<claim-text>future releases of application services for the server farm. </claim-text>
</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
