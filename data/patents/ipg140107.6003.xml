<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627126-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627126</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13346339</doc-number>
<date>20120109</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="regional">
<country>EP</country>
<doc-number>11150681</doc-number>
<date>20110112</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>179</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>1</main-group>
<subgroup>32</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>713320</main-classification>
<further-classification>711165</further-classification>
<further-classification>713324</further-classification>
</classification-national>
<invention-title id="d2e71">Optimized power savings in a storage virtualization system</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7174471</doc-number>
<kind>B2</kind>
<name>Komarla et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>8321629</doc-number>
<kind>B2</kind>
<name>Hayashi et al.</name>
<date>20121100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711114</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2007/0208921</doc-number>
<kind>A1</kind>
<name>Hosouchi et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2009/0207520</doc-number>
<kind>A1</kind>
<name>Golasky et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2010/0332882</doc-number>
<kind>A1</kind>
<name>Nayak et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713324</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>WO</country>
<doc-number>WO2009032776</doc-number>
<kind>A2</kind>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>711165</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713320</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713324</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120179928</doc-number>
<kind>A1</kind>
<date>20120712</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Haustein</last-name>
<first-name>Nils</first-name>
<address>
<city>Mainz</city>
<country>DE</country>
</address>
</addressbook>
<residence>
<country>DE</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Troppens</last-name>
<first-name>Ulf</first-name>
<address>
<city>Mainz</city>
<country>DE</country>
</address>
</addressbook>
<residence>
<country>DE</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Winarski</last-name>
<first-name>Daniel James</first-name>
<address>
<city>Tucson</city>
<state>AZ</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Wolafka</last-name>
<first-name>Rainer</first-name>
<address>
<city>Mainz</city>
<country>DE</country>
</address>
</addressbook>
<residence>
<country>DE</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Haustein</last-name>
<first-name>Nils</first-name>
<address>
<city>Mainz</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Troppens</last-name>
<first-name>Ulf</first-name>
<address>
<city>Mainz</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Winarski</last-name>
<first-name>Daniel James</first-name>
<address>
<city>Tucson</city>
<state>AZ</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Wolafka</last-name>
<first-name>Rainer</first-name>
<address>
<city>Mainz</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Griffiths &#x26; Seaton PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Wang</last-name>
<first-name>Albert</first-name>
<department>2115</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Various embodiments for optimized power savings in a storage virtualization system are provided. First meta data for physical resources which describes a power status of a storage resource in one of a powered-on/read-write, powered-on/read only, and powered-off power state is created. Second meta data for each of the physical storage resources which determines an actual performance of the physical storage resources and which supports optimization of a powering-on and a powering-off of the physical storage resources is created. A write request from one of a host and application to logical and virtual storage resource is executed.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="202.18mm" wi="151.13mm" file="US08627126-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="216.83mm" wi="125.56mm" file="US08627126-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="216.83mm" wi="168.15mm" file="US08627126-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="188.81mm" wi="109.56mm" file="US08627126-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="167.13mm" wi="108.46mm" file="US08627126-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="202.35mm" wi="150.03mm" file="US08627126-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="104.22mm" wi="85.43mm" file="US08627126-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">PRIORITY CLAIM</heading>
<p id="p-0002" num="0001">This application claims priority to European Patent Application No. 11150681.2, filed Jan. 12, 2011, which is hereby incorporated by reference in its entirety.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to computers, and more specifically, to an optimized power savings in a storage virtualization system.</p>
<p id="p-0005" num="0004">2. Description of Related Art</p>
<p id="p-0006" num="0005">Prior art in the field of storage virtualization improves classical storage management requirements such as tiered storage, hierarchical storage management (HSM), and information life-cycle management (ILM). New methods are required to reduce the power consumption of virtualized storage systems.</p>
<heading id="h-0003" level="1">SUMMARY OF THE DESCRIBED EMBODIMENTS</heading>
<p id="p-0007" num="0006">Storage virtualization means the pooling of physical storage resources from multiple network storage resources into what appears to be a single storage resource that is managed from a central console. Storage virtualization may be used in a storage area network (SAN).</p>
<p id="p-0008" num="0007">Storage virtualization moves the storage virtualization functions from the servers (volume manager, file systems) and disk subsystems (caching, RAID, instant copy, remote mirroring, LUN masking) into the storage network. This creates a new storage virtualization system which, as a result of its positioning in the storage network, spans all servers and storage systems. This new virtualization in the storage network permits the full utilization of the potential of a storage network with regard to the efficient use of resources and data, the improvement of performance and protection against failures. It is object of the present invention to provide an improved method and system for power saving in a storage virtualization system without violating the performance requirements.</p>
<p id="p-0009" num="0008">The present invention teaches a novel method for optimized power saving in storage virtualization system. The storage virtualization system comprises a virtualization controller, which manages storage capacity on storage resources and presents them as logical or virtual storage resources to hosts and applications, and a plurality of storage resources, mapping table for mapping virtual resources to physical storage resources. The power-on or power off of the physical resources is optimized by the inventive method which comprises the steps of: creating first meta data for each physical resource which describes the power status of said storage resource in &#x201c;powered-on/read-write&#x201d;, &#x201c;powered-on/read-only&#x201d;, &#x201c;powered-off&#x201d;, creating second meta data for each physical storage resource which determines the actual performance of said physical storage resources and which supports the optimization of powering-on and powering-off of physical storage resources, executing write request from the host or application to logical or virtual storage resource by the steps of: determining current physical target storage resource by evaluating said mapping table, determining the power-status of said physical storage resource based on said meta data, selecting a new target physical storage resource which is in the power state &#x201c;powered-on/read-write&#x201d; if the said target physical storage resource is &#x201c;powered-off&#x201d; or &#x201c;powered-on/read-only&#x201d;, updating said mapping table to map the virtual resource to said new physical target resource, configuring the optimized set of physical storage resources to be in power status &#x201c;powered-on/read-write&#x201d; by creating a performance target for said set of physical storage resources in power state &#x201c;powered-on/read-write&#x201d; and determining the actual performance of said set of physical storage resources in power state &#x201c;powered-on/read-write&#x201d; and first background process which initiates a power-on on one or more physical storage resources if said performance target is below said determined current performance and a second background process which initiates a power-off of one or more physical storage resources if said performance target is above said determined current performance.</p>
<p id="p-0010" num="0009">In a preferred embodiment the second meta data describes characteristics of each physical storage resource including power consumption, performance, time stamp of last read request, time-out interval for the last read request, capacity, utilization, activity ratio, activity threshold, wherein said activity ratio is defined as the amount of data which is read from physical storage resource within the time-out interval of the physical storage resource (active data).</p>
<p id="p-0011" num="0010">In a further embodiment the first background process includes the steps of: selecting one physical storage resource in power state powered-off or in power state &#x201c;power-on/read-only&#x201d;, initiating the powering-on of said selected physical storage resource if said power-status is powered-off, setting power-status of said selected storage resource to &#x201c;powered-on/read-write&#x201d;, Updating current performance, and repeating said steps if the target performance is still below the updated current performance.</p>
<p id="p-0012" num="0011">In another further embodiment the second background process includes the steps of: selecting one physical storage resource which is in power state &#x201c;powered-on/read-write&#x201d; and which exceeded the time-out interval for the last read request, setting the power status of said selected physical storage resources to powered-off, initiating the powering-off of aid selected physical resources, updating current performance, and repeating said steps if the target performance is still above said current performance.</p>
<p id="p-0013" num="0012">In a further embodiment the second background process includes the steps of: selecting a physical storage resource in power state &#x201c;powered-on/read-write&#x201d; which current activity ratio is below its activity threshold, setting the power status to &#x201c;powered-on/read-only&#x201d;, migrating the active data to another physical storage resource which is in power state &#x201c;powered-on/read-write&#x201d;, updating said mapping table to map the virtual resource to said new physical target resource, and powering-off selected physical storage resource.</p>
<p id="p-0014" num="0013">In general, in the preferred embodiment of the present invention the storage virtualization system runs two kinds of processes. Event driven processes serve read and write requests of the application systems and other time critical tasks. In addition to that a storage virtualization system runs background tasks like data scrubbing, data reorganization and other maintenance tasks. This invention describes potential modifications of read and write requests to keep as many storage resources powered-off as possible. Nevertheless, event driven processes can change the power-state of a storage resource, for instance, a read request can enforce a storage resource to be powered on. Therefore, the amount of powered-on and powered of storage resources changes of the time. Therefore, this invention introduces two new back ground processes for powering-on and powering-off storage resources to optimize the amount of powered on storage resources to satisfy certain performance requirements. Furthermore, this invention describes a new migration policy for migrating active data regions to a single storage resource to increase the number of storage resources, which are eligible for being powered-off.</p>
<p id="p-0015" num="0014">The key characteristics of the inventive method are &#x201c;powered-on/read-only&#x201d;, summarized as follows:</p>
<p id="p-0016" num="0015">The storage virtualization system maintains for each storage resource a power state. The power state of a storage resource can be &#x201c;powered off&#x201d;, &#x201c;powered-on/read-only&#x201d; read access allowed, &#x201c;powered-on/read-write&#x201d; access allowed (&#x201c;powered-on/read-write&#x201d;):</p>
<p id="p-0017" num="0016">Intercepting write access to powered-off storage resources and to &#x201c;powered-off/read-only&#x201d; storage resources. Instead of powering-on the target storage resource, the storage virtualization system updates the mapping table from virtual storage units to local storage units and thus redirects the write operation to a storage resource which is already in the state &#x201c;powered-on/read-write&#x201d; access allowed,</p>
<p id="p-0018" num="0017">Providing a process for powering on storage resources to satisfy service level agreements (SLAs) regarding guaranteed performance, whilst trying to minimize the power consumption,</p>
<p id="p-0019" num="0018">Providing a process for powering off storage resources to reduce the power consumptions, whilst guaranteeing that service level agreements (SLAs) regarding guaranteed performance are still met, and</p>
<p id="p-0020" num="0019">Providing a method of migrating the active regions with read access to another storage resources to power-off the freed-up storage resource.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0021" num="0020">The subject matter, which is regarded as the invention, is particularly pointed out and distinctly claimed in the claims at the conclusion of the specification. The foregoing and other objects, features, and advantages of the invention are apparent from the following detailed description taken in conjunction with the accompanying drawings in which:</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 1</figref> A shows a prior art architecture for storage virtualization in the network;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 1</figref> B shows the prior art process flow for serving a read request of host computer;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 2</figref> A shows a table with new parameters which are used to extend a prior art storage virtualization system and to provide the inventive optimized power saving for the storage virtualization system according to the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 2</figref> B shows the inventive write process;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 2</figref> C shows the inventive process flow for increasing the number of powered-on resources;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 2</figref> D shows the inventive processing flow for decreasing the number of powered-on resources; and</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 2</figref> E shows the enhanced inventive storage virtualization system.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0029" num="0028">The detailed description explains the preferred embodiments of the invention, together with advantages and features, by way of example with reference to the drawings.</p>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF CERTAIN EMBODIMENTS</heading>
<p id="p-0030" num="0029">The architecture of storage virtualization entities can be distinguished in symmetric (in-band) virtualization and asymmetric (out-band) virtualization. Furthermore both architectures can provide block-level virtualization and file-level virtualization.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 1</figref> A shows a prior art architecture for storage virtualization in the network. The storage resources <b>102</b> provide the storage capacity for storing data. A storage resource <b>102</b> can be, for instance, a single disk drive or a complete RAID array comprising multiple disk drives. The storage virtualization system <b>104</b> spans all storage resources <b>102</b> and provides central management for all storage resources. The storage virtualization system <b>104</b> assigns storage capacity to the host computers <b>106</b> for writing and reading data.</p>
<p id="p-0032" num="0031">The prior art architecture presented in <figref idref="DRAWINGS">FIG. 1</figref> A covers a broad range of real life architectures including, but not limited to, symmetric and asymmetric virtualization as well as block-level and file-level virtualization.</p>
<p id="p-0033" num="0032">The storage virtualization system <b>104</b> maps logical storage capacity to physical storage capacity. Depending on the virtualization type, logical storage capacity is organized in blocks, files, parts of files, records of a relational database, or any other logical container for addressing data. The storage virtualization system <b>104</b> maintains a mapping table for mapping such logical resources to physical resources. Physical resources can be blocks, files, parts of files, records of a relational database, or any other physical container for addressing data.</p>
<p id="p-0034" num="0033">Some storage techniques maintain one or more physical copies for each logical copy. For instance the replication of files of the IBM&#xae; GPFS file system keeps two physical copies of each file written by an application. The RAID levels RAID 1 and RAID 10 keep two copies of each block written by an application. For reading data it is sufficient to access only one physical copy of the data. Thus the storage resources <b>102</b> which keep such copies can be powered-off.</p>
<p id="p-0035" num="0034">The power saving system and methods taught in this invention are implemented in the storage virtualization system <b>104</b>. The storage virtualization system <b>104</b> can for example be represented by a disk control unit such as IBM&#xae; DS8000 or by a storage virtualization system such as IBM&#xae; SAN Volume controller.</p>
<p id="p-0036" num="0035">This present invention teaches novel methods for efficient powering-on and powering-off of storage resources. For the implementation of processes <b>200</b>, <b>300</b>, <b>400</b>, and <b>500</b> the storage virtualization system <b>104</b> uses a repository to retain meta data supporting this invention. The meta data items are described below. Let s<sub>1</sub>, s<sub>2</sub>, . . . , s<sub>n</sub>, be the n storage resource <b>102</b> of that configuration. Then we define
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0036">pc<sub>i </sub>as the power consumption of storage resource s<sub>i </sub></li>
        <li id="ul0002-0002" num="0037">p<sub>i </sub>as the performance of storage resource s<sub>i </sub></li>
        <li id="ul0002-0003" num="0038">status<sub>i </sub>as the status of storage resource s<sub>i </sub></li>
        <li id="ul0002-0004" num="0039">tr<sub>i </sub>as the time stamp of the last read request to storage resource s<sub>i </sub></li>
        <li id="ul0002-0005" num="0040">to<sub>i </sub>as the time out interval for the last read request to storage resource s<sub>i </sub></li>
        <li id="ul0002-0006" num="0041">c<sub>i </sub>as the capacity of storage resource s<sub>i </sub></li>
        <li id="ul0002-0007" num="0042">u<sub>i </sub>as the utilization of storage resource s<sub>i </sub></li>
        <li id="ul0002-0008" num="0043">a<sub>i </sub>as the activity ratio of storage resource s<sub>i </sub></li>
        <li id="ul0002-0009" num="0044">at<sub>i </sub>as the activity threshold of storage resource s<sub>i </sub></li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0037" num="0045">The power consumption pc<sub>i </sub>models the power consumption of given storage resource. In one embodiment the power consumption is specified in Watt. In an alternate embodiment the power consumption is represented by a rational number between zero and one. In one embodiment the power consumption weight is configured by the administrator. In an alternate embodiment the storage virtualization system <b>104</b> assigns the power consumption weight based on built-in policies.</p>
<p id="p-0038" num="0046">The performance p<sub>i </sub>models the performance of a given storage resource. In one embodiment the performance is specified in MByte/s. In an alternate embodiment the performance is specified in IOPS/s. In an alternate embodiment the performance is represented by a rational number between zero and one. In one embodiment the performance weight is configured by the administrator. In an alternate embodiment the storage virtualization system <b>104</b> assigns the performance weight based on built-in policies. In an alternate embodiment the storage virtualization system <b>104</b> measures the performance capability of a given storage resource and assigns the performance weight automatically.</p>
<p id="p-0039" num="0047">The status status<sub>i </sub>of the storage resource s<sub>i </sub>can assume the following values:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0048">&#x201c;powered-on/read-write&#x201d; the storage resource is &#x201c;powered-on/read-write&#x201d; read-write-requests are allowed,</li>
        <li id="ul0004-0002" num="0049">&#x201c;powered-on/read-only&#x201d; the storage resource is powered-on, read-requests are allowed,</li>
        <li id="ul0004-0003" num="0050">powered-off the storage resource is powered-off</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0040" num="0051">The status powered-on is used to refer to a status which is either &#x201c;powered-on/read-write&#x201d; or &#x201c;powered-on/read-only&#x201d;. The status status<sub>i </sub>of a storage resource s<sub>i </sub>is updated by the processes introduced below.</p>
<p id="p-0041" num="0052">The time stamp of the last read request tr<sub>i </sub>to storage s<sub>i </sub>keeps track of the point in time for the last read access to storage resource s<sub>i</sub>. The time stamp tr<sub>i </sub>of the last read access to a storage resource s<sub>i </sub>is updated by the processes introduced below.</p>
<p id="p-0042" num="0053">The time out interval to<sub>i </sub>for the last read request specifies the amount of time which must pass before the storage resource s<sub>i </sub>becomes eligible for being powered-off. In one embodiment the time out interval to<sub>i </sub>for the last read request is configured by the administrator. In an alternate embodiment the storage virtualization system <b>104</b> assigns the time out interval to<sub>i </sub>for the last read request based on built-in policies.</p>
<p id="p-0043" num="0054">The capacity c<sub>i </sub>of a storage resource represents capacity of a storage resource s<sub>i</sub>. In the preferred embodiment the capacity is specified in MByte. The utilization u<sub>i </sub>of a storage resource represents the utilization ratio of a storage resource. In the preferred embodiment the utilization ratio u<sub>i </sub>is represented by a rational number between zero and one were it is calculated by dividing the amount of used storage capacity of a storage resource by the amount of total storage capacity c<sub>i </sub>of a storage resource s<sub>i</sub>.</p>
<p id="p-0044" num="0055">The activity ratio a<sub>i </sub>represents the recent activity on a storage resource s<sub>i</sub>. In the preferred embodiment the activity ratio is defined as the amount of data read from a storage resource s<sub>i </sub>within the time-out interval to<sub>i </sub>divided by the overall storage capacity c<sub>i </sub>of storage resource s<sub>i</sub>.</p>
<p id="p-0045" num="0056">The activity threshold at<sub>i </sub>of storage resource s<sub>i </sub>defines the maximal activity ratio a<sub>i </sub>for a storage resource s<sub>i </sub>to become eligible for being powered-off.</p>
<p id="p-0046" num="0057">Based on these parameters the maximal write performance can be defined as
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>P<sub>max</sub>=&#x3a3;p<sub>i </sub><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
and the currently achievable write performance can be calculated as
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>P<sub>cur</sub>=&#x3a3;p<sub>i </sub>where status<sub>i </sub>&#x201c;powered-on/read-write&#x201d; and u<sub>i</sub>&#x3c;100%.<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Furthermore we define
</p>
<p id="p-0047" num="0058">P<sub>SLA </sub>as the performance requirement for the aggregated write performance.</p>
<p id="h-0006" num="0000">The inventive methods introduced by this invention keep the relation
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>P<sub>SLA</sub>&#x3c;&#x3c;P<sub>cur</sub>&#x3c;&#x3c;P<sub>max </sub><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
to power of as much storage resources as possible whilst guaranteeing a certain performance target for aggregated write performance.
</p>
<p id="p-0048" num="0059"><figref idref="DRAWINGS">FIG. 2</figref> A shows how these new parameters are used to extend a prior art storage virtualization system <b>104</b> to provide inventive power saving techniques which are disclosed by this patent application. Next we describe the processes according to this invention implemented in the storage virtualization system <b>104</b> and enabling power saving in a storage system.</p>
<p id="p-0049" num="0060"><figref idref="DRAWINGS">FIG. 1</figref> B shows the prior art process flow <b>200</b> for serving a read request of host computer <b>106</b>. The process <b>200</b> starts in step <b>202</b> where the read command such as a SCSI READ(10) command from a host system <b>106</b> is received by the storage virtualization system <b>104</b>. Upon reception of that read command the process flows to step <b>204</b>.</p>
<p id="p-0050" num="0061">In step <b>204</b> a storage resource for reading the requested data is selected. Thereby prior art is used to determine if one or more copies of the requested data exists. The storage virtualization system <b>104</b> may perform copy, mirror or replication operations according to prior art creating copies for all data. Thereby the storage virtualization system <b>104</b> keeps track of all associated data copies. This mechanism is used here to determine all copies for the data requested as part of the read command, which has been received in step <b>202</b>. If more than one copy exists on distinct storage resources, the storage virtualization system <b>104</b> selects only one storage resource to serve the read request. Thereby different embodiments are used. In one embodiment the copy is selected which resides on a storage resources <b>102</b> in powered-on state. In the case that multiple copies reside on powered-on storage resources, the virtualization <b>104</b> typically takes the time stamp tr<sub>i </sub>for the last read access into account: It selects the most recently used storage resource <b>102</b> to keep the current read activity of the whole infrastructure on as few storage resources <b>102</b> as possible. In an alternate embodiment the virtualization engine selects the storage resource based on activity. For performance reasons, for instance if the storage resource is a &#x201c;hot spot&#x201d; with a huge amount of pending I/O requests, the storage virtualization system <b>104</b> may also select a different storage resource in powered-on state. In yet an another embodiment the selection of the storage resource can take additional environmental conditions into account such as the parameters pc<sub>i</sub>, p<sub>i</sub>, status<sub>i</sub>, tr<sub>i</sub>, to<sub>i</sub>, and at<sub>i </sub>defined above. For example it may select the storage resource with the least utilization u<sub>i</sub>. If none of the storage resources storing a copy of the requested data is powered on then the storage resource with the primary data copy is selected. After the selection of a storage resource s<sub>i </sub>for reading the physical copy of the data the process flows to step <b>206</b>.</p>
<p id="p-0051" num="0062">In step <b>206</b>, the storage virtualization system <b>104</b> checks whether the status of the storage resource s<sub>i </sub>which was selected in step <b>204</b> to read the data is powered-off. If the decision in step <b>206</b> evaluates to NO, the storage resource <b>102</b> is powered-on and the process continues at step <b>214</b> which is explained later. If the decision in step <b>206</b> evaluates to YES, the storage resource <b>102</b> is powered-off and the process flows to step <b>208</b>.</p>
<p id="p-0052" num="0063">In step <b>208</b>, the storage virtualization system <b>104</b> uses prior art to signal the host computer <b>106</b> that the storage resource s<sub>i </sub>which was selected in step <b>204</b> to read the data is busy to gain some time for powering-on the storage resource s<sub>i</sub>. For instance, for a block I/O SCSI read request, the storage virtualization system <b>104</b> can respond a SCSI READ command received in step <b>202</b> with a SCSI status: Device Busy. The flow continues at step <b>210</b>.</p>
<p id="p-0053" num="0064">In step <b>210</b>, the storage virtualization system <b>104</b> powers-on the storage resource s<sub>i </sub>which was selected in step <b>204</b> to read the data. The flow continues at step <b>212</b>.</p>
<p id="p-0054" num="0065">In step <b>212</b>, the storage virtualization system <b>104</b> sets the status status<sub>i </sub>of the storage resource s<sub>i </sub>which was selected in step <b>204</b> to read the data to powered-on/read-write. The flow continues at step <b>214</b>.</p>
<p id="p-0055" num="0066">In step <b>214</b>, the storage virtualization system <b>104</b> reads the data from the storage resource s<sub>i</sub>, which was selected in step <b>204</b> to read the data, and serves the read request of host computer <b>106</b>. The flow continues at step <b>216</b>.</p>
<p id="p-0056" num="0067">In step <b>216</b>, the storage virtualization system <b>104</b> updates the last read time stamp tr<sub>i </sub>of the storage resource s<sub>i</sub>, which was selected in step <b>204</b> to read the data. The process <b>200</b> ends in step <b>299</b>.</p>
<p id="p-0057" num="0068"><figref idref="DRAWINGS">FIG. 2</figref> B shows the flow of process <b>300</b> for serving a write request of host computer <b>106</b>. The process <b>300</b> starts in step <b>302</b> where the write command such as a SCSI WRITE (10) command is received from a host system and flows to step <b>304</b>.</p>
<p id="p-0058" num="0069">In step <b>304</b>, the storage virtualization system <b>104</b> uses prior art to select one or more storage resources s<sub>i </sub>to serve the write request. The storage virtualization system <b>104</b> may select more than one storage resource s<sub>i </sub>to create additional data copies of the data received as part of the write command. Associated functions such as remote mirroring, replication or RAID1 are according to prior art. The storage virtualization system <b>104</b> starts for each selected storage resource s<sub>i </sub>receiving a data copy a separate sub-process which begins at step <b>306</b>.</p>
<p id="p-0059" num="0070">In step <b>306</b>, the storage virtualization system <b>104</b> checks whether the status status<sub>i </sub>of the storage resource s<sub>i </sub>which was selected in step <b>304</b> to write the data is powered-on/read-write. If the decision in step <b>306</b> evaluates to YES, the storage resource s<sub>i </sub>which was selected in step <b>304</b> to write the data is powered-on and eligible for writing data. The process continues at step <b>314</b> which is explained later. If the decision in step <b>306</b> evaluates to NO, the storage resource s<sub>i </sub>which was selected in step <b>304</b> to write the data is not eligible for writing data. Its status status<sub>i </sub>is either powered-off or powered-on/read-only. The process flows to step <b>308</b>.</p>
<p id="p-0060" num="0071">In step <b>308</b>, the storage virtualization system <b>104</b> determines an alternative storage resource s<sub>j </sub>for serving the write request. The selection of the alternative storage resource s<sub>j </sub>must adhere to prior art: For instance it must take into account the requirements for RAID striping to satisfy high performance needs or the requirements for storing copies on different storage resources <b>102</b> to provide high availability. In addition to that, the storage virtualization system <b>104</b> can take additional parameters pertaining to storage resource s<sub>j </sub>into account such as the parameters pc<sub>j</sub>, p<sub>j</sub>, status, tr<sub>j</sub>, to<sub>j</sub>, c<sub>j</sub>, u<sub>j</sub>, a<sub>j</sub>, and at<sub>j </sub>defined above to increase the power-efficiency of the overall solution. For example it may select the storage resource s<sub>j </sub>with the least utilization u<sub>j </sub>in order to balance the capacity across storage resources. Or it may select the storage resource with the highest utilization in order to fill it up first because this would ensure that such device only serves read requests subsequently. For performance reasons the storage resource may be selected which has the least activity ratio a<sub>j</sub>, Once the alternative storage resource s<sub>j </sub>for writing the data is selected, the process flows to step <b>310</b>. In an alternative embodiment, process <b>400</b> can be started to power-on additional storage resources, if no eligible storage resource haven been found.</p>
<p id="p-0061" num="0072">In step <b>310</b>, the storage virtualization system <b>104</b> updates the allocation table for the storage resource s<sub>j </sub>which was selected in step <b>308</b> to mark the respective storage area as used. In addition to that the virtualization instance <b>104</b> discards the old copy of the data and de-allocates the respective storage area on storage resource s<sub>i</sub>, which was determined in step <b>304</b> to keep the old copy of data. The flow continues at step <b>312</b>.</p>
<p id="p-0062" num="0073">In step <b>312</b>, the storage virtualization system <b>104</b> updates the mapping table to map the logical storage to the new location determined in step <b>308</b>. The flow continues in step <b>314</b>.</p>
<p id="p-0063" num="0074">In step <b>314</b>, the storage virtualization system <b>104</b> writes the data to the respective storage resource s<sub>i </sub>or s<sub>j </sub>as indicated in the mapping table. The flow continues at step <b>316</b>.</p>
<p id="p-0064" num="0075">Step <b>316</b> is optional. If step <b>304</b> starts only one sub-process because only one copy of the data is required, then step <b>316</b> can be omitted. If multiple sub-processes are started then prior art can be used to determine when to proceed: For disaster protection reasons, the virtualization instance <b>106</b> may wait, until all sub-processes are completed. This represents a synchronous mirroring function where all data copies are written before the command is completed. Alternatively the storage virtualization system <b>104</b> may continue, when the first sub-process completed and create the other data copies later. This represents the asynchronous mirroring function. Whether the synchronous or asynchronous mirroring function is used is determined either based on the configuration of the virtualization instance or depends on other system or user defined policies. Once a sufficient amount of sub-processes completed, the flow continues at step <b>318</b>.</p>
<p id="p-0065" num="0076">In step <b>318</b>, the storage virtualization system <b>104</b> confirms the write request to the host computer <b>106</b>. The process <b>300</b> ends in step <b>399</b>.</p>
<p id="p-0066" num="0077"><figref idref="DRAWINGS">FIG. 2</figref> C shows the process <b>400</b> for increasing the number of powered-on devices in order to favor the performance requirements. The process <b>400</b> can be started regularly on a time-based schedule or it can be started manually by an administrator. The process <b>400</b> can also be started based on events, for instance when a storage resource <b>102</b> reaches 100% utilization. The process <b>400</b> starts in step <b>402</b> and flows to step <b>404</b>.</p>
<p id="p-0067" num="0078">In step <b>404</b>, the storage virtualization system <b>104</b> determines the set of storage resources which have the status powered-on/read-write and which have a utilization u<sub>i</sub>&#x3c;100% to calculate the current performance (P<sub>cur</sub>). If P<sub>cur </sub>is larger than P<sub>SLA </sub>then a sufficient amount of storage resources is powered-on and the process <b>400</b> ends at step <b>499</b>. P<sub>SLA </sub>is configurable within the storage virtualization system <b>104</b> may represent a fraction of P<sub>max</sub>. If the decision in step <b>404</b> evaluates to NO, more storage resources must be powered-on and the process flows to step <b>406</b>.</p>
<p id="p-0068" num="0079">In step <b>406</b>, the storage virtualization system <b>104</b> selects a storage resource s<sub>i </sub>to be powered-on. Thereby the storage virtualization system <b>104</b> first determines the set of storage resources <b>102</b> with an utilization lower 100% and which are in state powered-off or in state &#x201c;powered-on/read-only&#x201d;. If this set is empty then the all storage resources are powered-on and the process <b>400</b> ends. If the set contains more then one storage resource <b>102</b> the storage virtualization system <b>104</b> uses priorities to select one of the storage resources <b>102</b>. The storage virtualization system <b>104</b> can take additional environmental conditions into account such as the parameters pc<sub>j</sub>, p<sub>j</sub>, status<sub>j</sub>, tr<sub>j</sub>, to<sub>j</sub>, c<sub>j</sub>, u<sub>j</sub>, a<sub>j</sub>, and at<sub>j </sub>defined above to determine the priority of each storage resource <b>102</b>. For example it may select the storage resource s<sub>j </sub>with the least utilization u<sub>j </sub>in order to balance the capacity across storage resources. Or it may select the storage resource with the highest utilization in order to fill it up first because this would ensure that such device only serves read requests subsequently. For performance reasons the storage resource may be selected which has the least activity ratio a<sub>j</sub>. Once a specific storage resource s<sub>i </sub>is selected, the process flows to step <b>408</b>.</p>
<p id="p-0069" num="0080">In step <b>408</b>, the storage virtualization system <b>104</b> checks, whether the status status<sub>i </sub>of the storage resource s<sub>i </sub>determined in step <b>406</b> is &#x201c;powered-on/read-only&#x201d;. If the decision in step <b>408</b> evaluates to YES, the process flows to step <b>412</b> explained later. If the decision in step <b>406</b> evaluates to NO, the storage resource s<sub>i </sub>selected in step <b>406</b> has status status<sub>i </sub>powered-off and the process flows to step <b>410</b>.</p>
<p id="p-0070" num="0081">In step <b>410</b>, the storage virtualization system <b>104</b> powers-on the storage resource s<sub>i </sub>which was selected in step <b>406</b>. The flow continues at step <b>412</b>.</p>
<p id="p-0071" num="0082">In step <b>412</b>, the storage virtualization system <b>104</b> sets the status status<sub>i </sub>of the storage resource s<sub>i </sub>which was selected in step <b>406</b> to status &#x201c;powered-on/read-write&#x201d;. The flow continues at step <b>404</b> for an additional iteration of this process <b>400</b>.</p>
<p id="p-0072" num="0083"><figref idref="DRAWINGS">FIG. 2</figref> D shows the flow of process <b>500</b> for decreasing the number of powered-on storage resources in order to favor the power savings. The process <b>500</b> can be started regularly on a time-based schedule, automatically by the invention in case a predefined total power consumption threshold for all powered-on storage resources &#x3a3;(pc<sub>i</sub>) is exceeded or it can be started manually by an administrator. The process <b>500</b> can also be started based on events, for instance when a storage resource <b>102</b> is powered-on by process <b>200</b> which serves read requests. The process <b>500</b> starts in step <b>502</b> and flows to step <b>504</b>.</p>
<p id="p-0073" num="0084">In step <b>504</b>, the storage virtualization system <b>104</b> determines the amount of storage resources <b>102</b> which have the status &#x201c;powered-on/read-write&#x201d; and have a utilization &#x3c;100% to calculate the current performance (P<sub>cur</sub>). Then it is checked, if P<sub>cur </sub>is smaller than P<sub>SLA</sub>. If the decision in step <b>504</b> evaluates to YES, a sufficient amount of storage resources is powered-off and the process <b>500</b> ends at step <b>599</b>. If the decision in step <b>504</b> evaluates to NO, more storage resources must be powered-off and the process flows to step <b>506</b>.</p>
<p id="p-0074" num="0085">In step <b>506</b>, the storage virtualization system <b>104</b> determines the set of storage resources which have the status of &#x201c;powered-on/read-write&#x201d; and the last read requests to that device (represented by tr<sub>i</sub>) is longer ago than its read time out to<sub>i</sub>. If there are two or more storage resource <b>102</b> which have passed its read timeout to<sub>i</sub>, than the storage virtualization system <b>104</b> selects one of them. In one embodiment the storage virtualization system <b>104</b> selects the storage resource s<sub>i </sub>where the difference between the time tr<sub>i </sub>and to<sub>i </sub>is greatest. In an alternate embodiment the storage virtualization system <b>104</b> selects the storage resource s<sub>i </sub>with the oldest read request tr<sub>i</sub>. In yet an alternate embodiment the storage virtualization system <b>104</b> takes additional environmental conditions into account such as the parameters pc<sub>j</sub>, p<sub>j</sub>, status, tr<sub>j</sub>, to<sub>j</sub>, c<sub>j</sub>, u<sub>j</sub>, a<sub>j</sub>, and at<sub>j </sub>defined above to select a storage resource s<sub>i</sub>. For example it may select the storage resource s<sub>j </sub>with the least utilization u<sub>j </sub>in order to balance the capacity across storage resources. Or it may select the storage resource with the highest utilization in order to fill it up first because this would ensure that such device only serves read requests subsequently. For performance reasons the storage resource may be selected which has the least activity ratio a<sub>j</sub>, As the result of this step <b>506</b> one or zero storage resource s<sub>i </sub>are selected. The process flows to step <b>508</b>.</p>
<p id="p-0075" num="0086">In step <b>508</b>, the storage virtualization system <b>104</b> checks whether in step <b>506</b> a storage resource s<sub>i </sub>could be identified which has passed the read timeout to<sub>i</sub>. If the decision in step <b>508</b> evaluates to NO, then no storage resource s<sub>i </sub>has passed its read time-out to<sub>i </sub>and the process continues at step <b>514</b> which is explained later. If the decision in step <b>508</b> evaluates to YES, then one or more storage resource s<sub>i </sub>have passed its read timeout to<sub>i </sub>and step <b>506</b> selected one of them. The process continues at step <b>510</b>.</p>
<p id="p-0076" num="0087">In step <b>510</b>, the storage virtualization system <b>104</b> sets the status, of the storage resource s<sub>i </sub>which was selected in step <b>506</b> to status powered-off. The flow continues at step <b>512</b>.</p>
<p id="p-0077" num="0088">In step <b>512</b>, the storage virtualization system <b>104</b> powers-off the storage resource s<sub>i </sub>which was selected in step <b>506</b>. The flow continues at step <b>504</b> for an additional iteration of this process <b>500</b>.</p>
<p id="p-0078" num="0089">In step <b>514</b>, the storage virtualization system <b>104</b> searches for storages devices s<sub>i </sub>which have an activity a<sub>i </sub>below their activity threshold at<sub>i</sub>. If there are two or more storage resource s<sub>i</sub>, which are below their activity threshold, than, the storage virtualization system <b>104</b> selects one of them. In one embodiment the storage virtualization system <b>104</b> selects the storage resource which has the lowest activity a<sub>i</sub>. In an alternate embodiment the storage virtualization system <b>104</b> selects the storage resource <b>102</b> where the difference between activity a<sub>i </sub>and activity threshold at<sub>i </sub>is greatest. In an alternate embodiment the storage virtualization system <b>104</b> takes additional environmental conditions into account such as the parameters pc<sub>j</sub>, p<sub>j</sub>, status<sub>j</sub>, tr<sub>j</sub>, to<sub>j</sub>, c<sub>j</sub>, u<sub>j</sub>, a<sub>j</sub>, and at<sub>j </sub>defined above to select a storage resource s<sub>i</sub>. As the result of this step one or zero storage resource s<sub>i </sub>are selected. The process flows to step <b>516</b>.</p>
<p id="p-0079" num="0090">In step <b>516</b>, the storage virtualization system <b>104</b> checks whether in step <b>514</b> a storage resource s<sub>i </sub>has been selected which has an activity a<sub>i </sub>below its activity threshold at<sub>i</sub>. If the decision in step <b>508</b> evaluates to NO, then no storage resource s<sub>i </sub>has an activity a<sub>i </sub>below its activity threshold at<sub>i</sub>. The storage virtualization system <b>104</b> issues an error to the administrator and the process <b>500</b> ends in step <b>599</b>. If the decision in step <b>516</b> evaluates to YES, then at least one storage resource s<sub>i </sub>has an activity a<sub>i </sub>below its activity threshold at<sub>i </sub>and step <b>514</b> selected one of them. The process continues at step <b>518</b>.</p>
<p id="p-0080" num="0091">In step <b>518</b>, the storage virtualization system <b>104</b> sets the status status<sub>i </sub>of the storage resource s<sub>i </sub>which was selected in step <b>514</b> to &#x201c;powered-on/read-only&#x201d;. The flow continues at step <b>520</b>.</p>
<p id="p-0081" num="0092">In step <b>520</b>, the storage virtualization system <b>104</b> migrates the active data of the storage resource s<sub>i</sub>, which was selected in step <b>514</b>. Migration means that the data is read of the storage resource s<sub>i </sub>and written to another storage resource, which is in &#x201c;power-on/read-write&#x201d; status utilizing process <b>300</b>. In one embodiment the storage virtualization system <b>104</b> creates an additional copy of the data, which was read within the read time-out interval to, to another storage resource <b>102</b> utilizing process <b>300</b> and updates the mapping table and the allocation table. In an alternate embodiment the storage virtualization system <b>104</b> copies the data which was read within the read time-out interval and copies it to another storage resource <b>102</b> utilizing process <b>300</b>. Then the storage virtualization system <b>104</b> deletes the data on the storage resource which was selected in step <b>514</b> and updates the mapping table and the allocation table accordingly. In an alternate embodiment the storage virtualization system <b>104</b> fills up the free storage capacity of storage resource s<sub>i </sub>with inactive data of other storage resources <b>102</b> to consolidate inactive data on as few storage resources as possible. The process continues at step <b>510</b> explained earlier.</p>
<p id="p-0082" num="0093"><figref idref="DRAWINGS">FIG. 2</figref> E shows a scenario where a single storage system <b>103</b> provides multiple storage resources <b>102</b> to the storage virtualization system <b>104</b>. Such a storage system <b>103</b> can be, for instance, a disk subsystem such as an IBM&#xae; DS8000 which provides multiple logical volumes as storage resources <b>102</b> to the storage virtualization system <b>104</b>. The presented processes <b>200</b>, <b>300</b>, <b>400</b>, <b>500</b> can be easily adopted to power-on and power-off complete disk subsystems. This is especially advantageous since this saves even more energy than just powering on and of storage resources <b>102</b>.</p>
<p id="p-0083" num="0094">This invention is also not limited to network based storage virtualization. It could also be implemented inside the storage subsystem <b>103</b>.</p>
<p id="p-0084" num="0095">As will be appreciated by one skilled in the art, aspects of the present invention may be embodied as a system, method or computer program product. Accordingly, aspects of the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a &#x201c;circuit,&#x201d; &#x201c;module&#x201d; or &#x201c;system.&#x201d; Furthermore, aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium(s) having computer readable program code embodied thereon.</p>
<p id="p-0085" num="0096">Any combination of one or more computer readable medium(s) may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples (a non-exhaustive list) of the computer readable storage medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a computer readable storage medium may be any tangible medium that may contain, or store a program for use by or in connection with an instruction execution system, apparatus, or device.</p>
<p id="p-0086" num="0097">Program code embodied on a computer readable medium may be transmitted using any appropriate medium, including but not limited to wireless, wired, optical fiber cable, RF, etc., or any suitable combination of the foregoing. Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as Java, Smalltalk, C++ or the like and conventional procedural programming languages, such as the &#x201c;C&#x201d; programming language or similar programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).</p>
<p id="p-0087" num="0098">Aspects of the present invention are described above with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems) and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, may be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.</p>
<p id="p-0088" num="0099">These computer program instructions may also be stored in a computer readable medium that may direct a computer, other programmable data processing apparatus, or other devices to function in a particular manner, such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function/act specified in the flowchart and/or block diagram block or blocks. The computer program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other devices to cause a series of operational steps to be performed on the computer, other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.</p>
<p id="p-0089" num="0100">The flowchart and block diagram in the above figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block might occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, may be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.</p>
<p id="p-0090" num="0101">While one or more embodiments of the present invention have been illustrated in detail, one of ordinary skill in the art will appreciate that modifications and adaptations to those embodiments may be made without departing from the scope of the present invention as set forth in the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method optimized power savings in a storage virtualization system a processor device in a computing environment, the method comprising:
<claim-text>creating first meta data for physical resources which describes a power status of a storage resource in one of a powered-on/read-write, powered-on/read only, and powered-off power state;</claim-text>
<claim-text>creating second meta data for each of the physical storage resources which determines an actual performance of the physical storage resources and which supports optimization of a powering-on and a powering-off of the physical storage resources; and</claim-text>
<claim-text>executing a write request from one of a host and application to logical and virtual storage resource by performing the following:
<claim-text>determining a current physical target storage resource by evaluating a mapping table,</claim-text>
<claim-text>determining the power-status of the physical storage resource based on one of the first and second meta data,</claim-text>
<claim-text>selecting a new target physical storage resource which is in the power state powered-on/read-write if the new target physical storage resource is one of powered-off and powered-on/read-only,</claim-text>
<claim-text>updating the mapping table to map a virtual resource to the new physical target resource,</claim-text>
<claim-text>configuring an optimized set of the physical storage resources to be in the powered-on/read-write power status by creating a performance target for the optimized set of the physical storage resources to be in the powered-on/read-write power status, and</claim-text>
<claim-text>determining the actual performance of the optimized set of the physical storage resources to be in the powered-on/read-write power status and a first background process which initiates a power-on on at least one of the physical storage resources if the performance target is below a determined current performance and a second background process which initiates a power-off of the at least one of the physical storage resources if the performance target is above the determined current performance.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second meta data describes characteristics of each of the physical storage resources including at least a power consumption, a performance, a time stamp of a last read request, a time-out interval for the last read request, capacity, a utilization, an activity ratio, an activity threshold, wherein the activity ratio is defined as the amount of data which is read from the physical storage resources within the time-out interval of the physical storage resources.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further including, in conjunction with the first background process, performing the following:
<claim-text>selecting at least one of the physical storage resources in one of the powered-off power state and in power-on/read-only power state,</claim-text>
<claim-text>initiating the powering-on of a selected one of the physical storage resources if the power status is in the powered-off power state,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-on/read-write power state,</claim-text>
<claim-text>updating the determined current performance, and</claim-text>
<claim-text>continuously performing the selecting, initiating, setting, and updating if the performance target is below the updated determined current performance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further including, in conjunction with the second background process, performing the following:
<claim-text>selecting at least one of the physical storage resources in the powered-on/read-write power state and which exceeded the time-out interval for the last read request,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-off power state,</claim-text>
<claim-text>initiating the powering-off of the selected one of the physical storage resources,</claim-text>
<claim-text>updating the determined current performance, and</claim-text>
<claim-text>continuously performing the selecting, initiating, setting, and updating if the performance target is above the updated determined current performance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further including performing the following:
<claim-text>selecting at least one of the physical storage resources in the powered-on/read-write power state having a current activity ratio is below the activity threshold for the at least one of the physical storage resources,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-on/read-write power state,</claim-text>
<claim-text>migrating active data to an alternative one of the at least one of the physical storage resources which is in the powered-on/read-write power state,</claim-text>
<claim-text>updating the mapping table to map the virtual resource to the new target physical storage resource, and</claim-text>
<claim-text>powering-off the selected one of the physical storage resources.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further including, wherein the storage virtualization system comprises a virtualization controller which manages storage capacity on a plurality of storage resources and presents the plurality of storage resources as one of a logical and a virtual storage resources to one of hosts and applications and the plurality of storage resources, and a mapping table for mapping the virtual storage resources to the physical storage resources, wherein the power-on power state and the power off power state of the physical storage resources is optimized.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A system for optimized power savings in a storage virtualization system in a computing environment, comprising:
<claim-text>a virtualization controller, wherein the virtualization controller is adapted to manages storage capacity on a plurality of storage resources and presents the plurality of storage resources as one of a logical and a virtual storage resources to one of hosts and applications and the plurality of storage resources;</claim-text>
<claim-text>a mapping table in communication with the virtualization controller, wherein the mapping table is adapted to map the virtual storage resources to the physical storage resources and</claim-text>
<claim-text>at least one processor device in communication with the virtualization controller and the mapping table, wherein the processor devices is adapted for:
<claim-text>creating first meta data for physical resources which describes a power status of a storage resource in one of a powered-on/read-write, powered-on/read only, and powered-off power state,</claim-text>
<claim-text>creating second meta data for each of the physical storage resources which determines an actual performance of the physical storage resources and which supports optimization of a powering-on and a powering-off of the physical storage resources, and</claim-text>
<claim-text>executing a write request from one of a host and application to logical and virtual storage resource by performing the following:
<claim-text>determining a current physical target storage resource by evaluating a mapping table,</claim-text>
<claim-text>determining the power-status of the physical storage resource based on one of the first and second meta data,</claim-text>
<claim-text>selecting a new target physical storage resource which is in the power state powered-on/read-write if the new target physical storage resource is one of powered-off and powered-on/read-only,</claim-text>
<claim-text>updating the mapping table to map a virtual resource to the new physical target resource,</claim-text>
<claim-text>configuring an optimized set of the physical storage resources to be in the powered-on/read-write power status by creating a performance target for the optimized set of the physical storage resources to be in the powered-on/read-write power status, and</claim-text>
<claim-text>determining the actual performance of the optimized set of the physical storage resources to be in the powered-on/read-write power status and a first background process which initiates a power-on on at least one of the physical storage resources if the performance target is below a determined current performance and a second background process which initiates a power-off of the at least one of the physical storage resources if the performance target is above the determined current performance.</claim-text>
</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein said second meta data describes characteristics of each of the physical storage resources including at least a power consumption, a performance, a time stamp of a last read request, a time-out interval for the last read request, capacity, a utilization, an activity ratio, an activity threshold, wherein the activity ratio is defined as the amount of data which is read from the physical storage resources within the time-out interval of the physical storage resources.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the processor device is further adapted for, in conjunction with the first background process, performing the following:
<claim-text>selecting at least one of the physical storage resources in one of the powered-off power state and in power-on/read-only power state,</claim-text>
<claim-text>initiating the powering-on of a selected one of the physical storage resources if the power status is in the powered-off power state,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-on/read-write power state,</claim-text>
<claim-text>updating the determined current performance, and</claim-text>
<claim-text>continuously performing the selecting, initiating, setting, and updating if the performance target is below the updated determined current performance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the processor device is further adapted for, in conjunction with the second background process, performing the following:
<claim-text>selecting at least one of the physical storage resources in the powered-on/read-write power state and which exceeded the time-out interval for the last read request,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-off power state,</claim-text>
<claim-text>initiating the powering-off of the selected one of the physical storage resources,</claim-text>
<claim-text>updating the determined current performance, and</claim-text>
</claim-text>
<claim-text>continuously performing the selecting, initiating, setting, and updating if the performance target is above the updated determined current performance.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor device is further adapted for performing the following:
<claim-text>selecting at least one of the physical storage resources in the powered-on/read-write power state having a current activity ratio is below the activity threshold for the at least one of the physical storage resources,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-on/read-write power state,</claim-text>
<claim-text>migrating active data to an alternative one of the at least one of the physical storage resources which is in the powered-on/read-write power state,</claim-text>
<claim-text>updating the mapping table to map the virtual resource to the new target physical storage resource, and</claim-text>
<claim-text>powering-off the selected one of the physical storage resources.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the processor device is further adapted for reading all of the active files from the virtualization controller starting at the starting block address into the reclamation memory.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the processor device is further adapted for writing active data files from the reclamation memory on the tape starting from one of the starting block address and the block address where a last write finished.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A computer program product for optimized power savings in a storage virtualization system by a processor device, the computer program product comprising a non-transitory computer-readable storage medium having computer-readable program code portions stored therein, the computer-readable program code portions comprising:
<claim-text>a first executable portion for creating first meta data for physical resources which describes a power status of a storage resource in one of a powered-on/read-write, powered-on/read only, and powered-off power state;</claim-text>
<claim-text>a second executable portion for creating second meta data for each of the physical storage resources which determines an actual performance of the physical storage resources and which supports optimization of a powering-on and a powering-off of the physical storage resources; and</claim-text>
<claim-text>a third executable portion for executing a write request from one of a host and application to logical and virtual storage resource by performing the following:
<claim-text>determining a current physical target storage resource by evaluating a mapping table,</claim-text>
<claim-text>determining the power-status of the physical storage resource based on one of the first and second meta data,</claim-text>
<claim-text>selecting a new target physical storage resource which is in the power state powered-on/read-write if the new target physical storage resource is one of powered-off and powered-on/read-only,</claim-text>
<claim-text>updating the mapping table to map a virtual resource to the new physical target resource,</claim-text>
<claim-text>configuring an optimized set of the physical storage resources to be in the powered-on/read-write power status by creating a performance target for the optimized set of the physical storage resources to be in the powered-on/read-write power status, and</claim-text>
<claim-text>determining the actual performance of the optimized set of the physical storage resources to be in the powered-on/read-write power status and a first background process which initiates a power-on on at least one of the physical storage resources if the performance target is below a determined current performance and a second background process which initiates a power-off of the at least one of the physical storage resources if the performance target is above the determined current performance.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The computer program product of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said second meta data describes characteristics of each of the physical storage resources including at least a power consumption, a performance, a time stamp of a last read request, a time-out interval for the last read request, capacity, a utilization, an activity ratio, an activity threshold, wherein the activity ratio is defined as the amount of data which is read from the physical storage resources within the time-out interval of the physical storage resources.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The computer program product of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further including a fourth executable portion for, in conjunction with the first background process, performing the following:
<claim-text>selecting at least one of the physical storage resources in one of the powered-off power state and in power-on/read-only power state,</claim-text>
<claim-text>initiating the powering-on of a selected one of the physical storage resources if the power status is in the powered-off power state,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-on/read-write power state,</claim-text>
<claim-text>updating the determined current performance, and</claim-text>
<claim-text>continuously performing the selecting, initiating, setting, and updating if the performance target is below the updated determined current performance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The computer program product of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further including a fourth executable portion for, in conjunction with the second background process, performing the following:
<claim-text>selecting at least one of the physical storage resources in the powered-on/read-write power state and which exceeded the time-out interval for the last read request,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-off power state,</claim-text>
<claim-text>initiating the powering-off of the selected one of the physical storage resources,</claim-text>
<claim-text>updating the determined current performance, and</claim-text>
<claim-text>continuously performing the selecting, initiating, setting, and updating if the performance target is above the updated determined current performance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The computer program product of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further including a fifth executable portion for performing the following:
<claim-text>selecting at least one of the physical storage resources in the powered-on/read-write power state having a current activity ratio is below the activity threshold for the at least one of the physical storage resources,</claim-text>
<claim-text>setting the power status of the selected one of the physical storage resources to the powered-on/read-write power state,</claim-text>
<claim-text>migrating active data to an alternative one of the at least one of the physical storage resources which is in the powered-on/read-write power state,</claim-text>
<claim-text>updating the mapping table to map the virtual resource to the new target physical storage resource, and</claim-text>
<claim-text>powering-off the selected one of the physical storage resources.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The computer program product of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the storage virtualization system comprises a virtualization controller which manages storage capacity on a plurality of storage resources and presents the plurality of storage resources as one of a logical and a virtual storage resources to one of hosts and applications and the plurality of storage resources, and a mapping table for mapping the virtual storage resources to the physical storage resources, wherein the power-on power state and the power off power state of the physical storage resources is optimized. </claim-text>
</claim>
</claims>
</us-patent-grant>
