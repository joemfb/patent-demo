<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627003-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627003</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12410305</doc-number>
<date>20090324</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>953</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>12</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>711114</main-classification>
<further-classification>711  5</further-classification>
<further-classification>711104</further-classification>
<further-classification>711105</further-classification>
<further-classification>711170</further-classification>
</classification-national>
<invention-title id="d2e53">Apparatus, system, and method for memory upgrade path optimization</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6092169</doc-number>
<kind>A</kind>
<name>Murthy et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711170</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6378039</doc-number>
<kind>B1</kind>
<name>Obara et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711114</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7013359</doc-number>
<kind>B1</kind>
<name>Li</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710305</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2006/0206662</doc-number>
<kind>A1</kind>
<name>Ludwig et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711114</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2006/0206675</doc-number>
<kind>A1</kind>
<name>Sato et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711161</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>25</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>13</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100250888</doc-number>
<kind>A1</kind>
<date>20100930</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Cromer</last-name>
<first-name>Daryl</first-name>
<address>
<city>Cary</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Frame</last-name>
<first-name>Donald R.</first-name>
<address>
<city>Apex</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Mettler</last-name>
<first-name>Michael Scott</first-name>
<address>
<city>Durham</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Timmons</last-name>
<first-name>Kenneth Dean</first-name>
<address>
<city>Raleigh</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Cromer</last-name>
<first-name>Daryl</first-name>
<address>
<city>Cary</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Frame</last-name>
<first-name>Donald R.</first-name>
<address>
<city>Apex</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Mettler</last-name>
<first-name>Michael Scott</first-name>
<address>
<city>Durham</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Timmons</last-name>
<first-name>Kenneth Dean</first-name>
<address>
<city>Raleigh</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Kunzler Law Group</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Lenovo (Singapore) Pte. Ltd.</orgname>
<role>03</role>
<address>
<city>Tech Park</city>
<country>SG</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bradley</last-name>
<first-name>Matthew</first-name>
<department>2182</department>
</primary-examiner>
<assistant-examiner>
<last-name>Otto</last-name>
<first-name>Alan</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An apparatus, system, and method are disclosed for memory upgrade optimization. A requirements module <b>402</b> receives one or more of a capacity upgrade goal <b>1306</b> for an overall capacity of the array <b>706</b> and a performance upgrade goal <b>1308</b> for an overall performance of the array <b>706</b>. An analysis module <b>404</b> identifies a first potential capacity change <b>1310</b> that can be achieved at a lower overall performance and a second potential capacity change <b>1314</b> that can be achieved at a higher overall performance. A reconfiguration module <b>406</b> generates one or more of a first reconfiguration recommendation <b>1312</b> calculated to yield an overall capacity improvement that takes into consideration the capacity upgrade goal <b>1306</b> and the first potential capacity change <b>1310</b> and a second reconfiguration recommendation <b>1316</b> calculated to yield an overall performance improvement that takes into consideration the performance upgrade goal <b>1308</b> and the second potential capacity change <b>1314. </b></p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="74.76mm" wi="174.16mm" file="US08627003-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="230.89mm" wi="150.62mm" file="US08627003-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="196.93mm" wi="173.40mm" file="US08627003-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.28mm" wi="182.63mm" file="US08627003-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="228.60mm" wi="177.88mm" file="US08627003-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="204.22mm" wi="179.49mm" file="US08627003-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="228.60mm" wi="143.09mm" file="US08627003-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="229.28mm" wi="143.09mm" file="US08627003-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="239.10mm" wi="163.32mm" file="US08627003-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="226.74mm" wi="167.39mm" file="US08627003-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">1. Field</p>
<p id="p-0003" num="0002">This invention relates to computer system configuration management and more particularly relates to memory configuration.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">A computer is a complex system, frequently requiring configuration management to optimize operational efficiency. Memory configuration is one important dimension of computer operation, both to expand capacity and to improve performance in a cost-efficient way.</p>
<p id="p-0006" num="0005">The multiplicity of computer memory device types and characteristics, computer chip sets, and memory array topographies, all combine to present a formidable challenge in terms of memory configuration. A systematic approach to memory upgrade optimization remains an elusive goal.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0007" num="0006">From the foregoing discussion, it should be apparent that a long-felt unmet need exists for an apparatus, system, and method that automate memory upgrade optimization in a systematic way. Beneficially, such an apparatus, system, and method would balance speed, capacity, and cost so as to assist in optimizing overall system efficiency.</p>
<p id="p-0008" num="0007">The present invention has been developed in response to the present state of the art, and in particular, in response to the problems and needs in the art that have hitherto proven intractable under currently available system configuration management. Accordingly, the present invention has been developed to provide an apparatus, system, and method for memory upgrade optimization that overcome many or all of the above-discussed shortcomings in the art.</p>
<p id="p-0009" num="0008">One approach is to analyze the memory configuration in terms of a single criterion, such as capacity, speed, or cost. A memory that is too slow for system requirements would benefit from faster memory devices. A memory that is too small for system requirements would benefit from more or denser memory devices. A memory that is too expensive for system requirements would benefit from fewer or less costly memory devices.</p>
<p id="p-0010" num="0009">Another approach to memory upgrade optimization is to balance the potentially competing criteria of capacity, speed, and cost. It may be that increasing overall capacity in terms of memory device count would reduce the speed of the array as a whole, even if the individual memory devices were capable of higher speed. In such a case, depending upon system requirements, one might opt to replace the memory devices with lower-cost, slower memory devices to match the overall speed of the array. Another alternative might be to use fewer, denser memory devices, thereby eliminating the overall speed impact of the excessive memory device count. The decision to replace memory devices might also include a consideration of the cost of the new devices and whether the existing devices could be employed more cost-effectively elsewhere.</p>
<p id="p-0011" num="0010">While the tradeoffs between competing configuration alternatives will of necessity be based upon the specific system requirements in any given case, an automated mechanism to recommend one or memory reconfiguration upgrade paths, optimized according to various criteria, would be very helpful in determining whether such tradeoffs might need to be explored. The present invention provides such a mechanism, generating reconfiguration recommendations optimized for capacity, for speed, and for overall system efficiency.</p>
<p id="p-0012" num="0011">The apparatus to optimize memory upgrade paths is provided with a plurality of modules configured to functionally execute the necessary steps of receiving one or more of a capacity upgrade goal for the overall capacity of the array and a performance upgrade goal for the overall performance of the array, identifying a first potential capacity change that can be achieved at a lower overall performance and a second potential capacity change that can be achieved at a higher overall performance, and generating one or more of a first reconfiguration recommendation calculated to yield an overall capacity improvement that takes into consideration the capacity upgrade goal and the first potential capacity change and a second reconfiguration recommendation calculated to yield an overall performance improvement that takes into consideration the performance upgrade goal and the second potential capacity change. These modules in the described embodiments include a requirements module, an analysis module, and a reconfiguration module.</p>
<p id="p-0013" num="0012">The apparatus, in one embodiment, is configured to determine the overall performance based upon a substantially inverse relationship with a highest quantity of members of a subset of the array and a substantially direct relationship with the individual performance capability of the members. Performance may be determined on the basis of one or more of frequency, bandwidth, access time, and latency. As a useful abstraction to suppress the interrelated complexity of these various performance criteria, a &#x201c;performance class&#x201d; may be defined as being representative of those configurations of the array and those individual performance capabilities of the memory devices that would support comparable overall performance.</p>
<p id="p-0014" num="0013">A system of the present invention is also presented to optimize memory upgrade paths. The system may be embodied by a computer having one or more processors and having a computer memory comprising an array of memory devices, the foregoing apparatus, and a control module that activates the requirements module, the analysis module, and the reconfiguration module to optimize the upgrade path of the array. In particular, the system, in one embodiment, may include other memory devices in the computer memory that are not comprised in the array.</p>
<p id="p-0015" num="0014">The system may further include subsets of the array which are associated with each of the one or more processors. The individual performance capability of the memory device may be determined on the basis of one or more of rank, capacity, speed, type, and depth. In a further embodiment, the memory device may comprise a dual in-line memory module (&#x201c;DIMM&#x201d;) and the subset may comprise a channel.</p>
<p id="p-0016" num="0015">A method of the present invention is also presented for optimizing memory upgrade paths. The method in the disclosed embodiments substantially includes the steps necessary to carry out the functions presented above with respect to the operation of the described apparatus and system, including the steps of receiving the goals, identifying the potential capacity changes, and generating the reconfiguration recommendations. In one embodiment, the reconfiguration recommendations may comprise replacing a member of the array with a member having a different individual performance capability, and may also comprise moving a member from a subset of the array to another subset of the array.</p>
<p id="p-0017" num="0016">In a further embodiment, the capacity upgrade goal and the performance upgrade goal may be calculated to achieve an overall efficiency of the system, wherein the overall efficiency is at least partially predicted by the overall capacity according to a first function, and by the overall performance according to a second function. The step of generating may further comprise emphasizing the first reconfiguration recommendation if the overall efficiency predicted by the first function is higher, and emphasizing the second reconfiguration recommendation if the overall efficiency predicted by the second function is higher. In an embodiment, the overall efficiency may comprise a system throughput rate, the first function may be based at least in part on a storage subsystem paging rate, and the second function may be based at least in part on a cache subsystem miss penalty.</p>
<p id="p-0018" num="0017">Reference throughout this specification to features, advantages, or similar language does not imply that all of the features and advantages that may be realized with the present invention should be or are in any single embodiment of the invention. Rather, language referring to the features and advantages is understood to mean that a specific feature, advantage, or characteristic described in connection with an embodiment is included in at least one embodiment of the present invention. Thus, discussion of the features and advantages, and similar language, throughout this specification may, but do not necessarily, refer to the same embodiment.</p>
<p id="p-0019" num="0018">Furthermore, the described features, advantages, and characteristics of the invention may be combined in any suitable manner in one or more embodiments. One skilled in the relevant art will recognize that the invention may be practiced without one or more of the specific features or advantages of a particular embodiment. In other instances, additional features and advantages may be recognized in certain embodiments that may not be present in all embodiments of the invention.</p>
<p id="p-0020" num="0019">These features and advantages of the present invention will become more fully apparent from the following description and appended claims, or may be learned by the practice of the invention as set forth hereinafter.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0021" num="0020">In order that the advantages of the invention will be readily understood, a more particular description of the invention briefly described above will be rendered by reference to specific embodiments that are illustrated in the appended drawings. Understanding that these drawings depict only typical embodiments of the invention and are not therefore to be considered to be limiting of its scope, the invention will be described and explained with additional specificity and detail through the use of the accompanying drawings, in which:</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic block diagram illustrating a possible computer hardware platform upon which the present invention may be at least in part deployed;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic block diagram of a possible computer including a software stack in which the present invention may at least in part reside;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic block diagram illustrating a system of the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic block diagram illustrating a memory upgrade optimization apparatus according to the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic block diagram of memory device organization and structure;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 6</figref> is a schematic block diagram of dual in-line memory module (&#x201c;DIMM&#x201d;) organization and structure;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 7</figref> is a more detailed schematic block diagram of the computer hardware platform;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 8</figref> is a schematic block diagram illustrating an example of a suboptimally configured memory array;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 9</figref> is a schematic block diagram of an upgraded reconfiguration of the memory array calculated to yield an overall performance improvement;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 10</figref> is a schematic block diagram of an upgraded reconfiguration of the memory array calculated to yield an overall capacity improvement;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 11</figref> is a schematic block diagram of an upgraded reconfiguration of the memory array calculated to yield both an overall performance improvement and an overall capacity improvement;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 12</figref> is a schematic flow chart diagram illustrating one embodiment of a method for determining overall performance of a memory array as may be performed by a requirements module in accordance with the present invention; and</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 13</figref> is a schematic flow chart diagram illustrating one embodiment of a method for memory upgrade optimization as may be performed by the memory upgrade optimization apparatus in accordance with the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0035" num="0034">Many of the functional units described in this specification have been labeled as modules, in order to more particularly emphasize their implementation independence. For example, a module may be implemented as a hardware circuit comprising custom VLSI circuits or gate arrays, off-the-shelf semiconductors such as logic chips, transistors, or other discrete components. A module may also be implemented in programmable hardware devices such as field programmable gate arrays, programmable array logic, programmable logic devices or the like.</p>
<p id="p-0036" num="0035">Modules may also be implemented in software for execution by various types of processors. An identified module of executable code may, for instance, comprise one or more physical or logical blocks of computer instructions which may, for instance, be organized as an object, procedure, or function. Nevertheless, the executables of an identified module need not be physically located together, but may comprise disparate instructions stored in different locations which, when joined logically together, comprise the module and achieve the stated purpose for the module.</p>
<p id="p-0037" num="0036">Indeed, a module of executable code may be a single instruction, or many instructions, and may even be distributed over several different code segments, among different programs, and across several memory devices. Similarly, operational data may be identified and illustrated herein within modules, and may be embodied in any suitable form and organized within any suitable type of data structure. The operational data may be collected as a single data set, or may be distributed over different locations including over different storage devices, and may exist, at least partially, merely as electronic signals on a system or network. Where a module or portions of a module are implemented in software, the software portions are stored on one or more computer readable media.</p>
<p id="p-0038" num="0037">Reference throughout this specification to &#x201c;one embodiment,&#x201d; &#x201c;an embodiment,&#x201d; or similar language means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, appearances of the phrases &#x201c;in one embodiment,&#x201d; &#x201c;in an embodiment,&#x201d; and similar language throughout this specification may, but do not necessarily, all refer to the same embodiment.</p>
<p id="p-0039" num="0038">Reference to a computer readable medium may take any form capable of storing machine-readable instructions on a digital processing apparatus. A computer readable medium may be embodied by a transmission line, a compact disk, digital-video disk, a magnetic tape, a Bernoulli drive, a magnetic disk, a punch card, flash memory, integrated circuits, or other digital processing apparatus memory device.</p>
<p id="p-0040" num="0039">Furthermore, the described features, structures, or characteristics of the invention may be combined in any suitable manner in one or more embodiments. In the following description, numerous specific details are provided, such as examples of programming, software modules, user selections, network transactions, database queries, database structures, hardware modules, hardware circuits, hardware chips, etc., to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize, however, that the invention may be practiced without one or more of the specific details, or with other methods, components, materials, and so forth. In other instances, well-known structures, materials, or operations are not shown or described in detail to avoid obscuring aspects of the invention.</p>
<p id="p-0041" num="0040">The schematic flow chart diagrams included herein are generally set forth as logical flow chart diagrams. As such, the depicted order and labeled steps are indicative of one embodiment of the presented method. Other steps and methods may be conceived that are equivalent in function, logic, or effect to one or more steps, or portions thereof, of the illustrated method. Additionally, the format and symbols employed are provided to explain the logical steps of the method and are understood not to limit the scope of the method. Although various arrow types and line types may be employed in the flow chart diagrams, they are understood not to limit the scope of the corresponding method. Indeed, some arrows or other connectors may be used to indicate only the logical flow of the method. For instance, an arrow may indicate a waiting or monitoring period of unspecified duration between enumerated steps of the depicted method. Additionally, the order in which a particular method occurs may or may not strictly adhere to the order of the corresponding steps shown.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a possible computer hardware platform <b>100</b> upon which the present invention may be at least in part deployed. The hardware platform <b>100</b> may include processor(s) <b>102</b>, memory <b>104</b>, a network interface <b>106</b>, and an I/O (Input/Output) device interface <b>108</b>, connected through a bus <b>110</b>.</p>
<p id="p-0043" num="0042">The hardware platform <b>100</b> may be of any form factor or type, including an embedded system, a handheld, a notebook, a personal computer, a minicomputer, a server, a mainframe, a supercomputer, and the like.</p>
<p id="p-0044" num="0043">The processor(s) <b>102</b> may be present in any quantity, including a uniprocessor, and may have any instruction set architecture. In an embodiment, the processor(s) <b>102</b> may have one or more levels of dedicated or shared caches. Possible physical implementations may include multi-chip, single chip, multi-core, hyperthreaded processors, and the like.</p>
<p id="p-0045" num="0044">The memory <b>104</b> may be of any size or organization and may include both read/write and read-only sections. It may also include both global and local sections, and may support both uniform and non-uniform access. It may incorporate memory-mapped I/O and direct memory access. It may support cache coherency, including directory-based and snoop-based protocols.</p>
<p id="p-0046" num="0045">The network interface <b>106</b> may support any network protocol or architecture. It may support both wireless and hard-wired network connections. It may comprise Ethernet, Token Ring, System Network Architecture (&#x201c;SNA&#x201d;), and the like. In one embodiment, it may be integrated with the I/O device interface <b>108</b>.</p>
<p id="p-0047" num="0046">The I/O device interface <b>108</b> may be driven primarily by the processor(s) <b>102</b> or may incorporate an independent I/O processor subsystem. It may comprise Peripheral Component Interconnect (&#x201c;PCI&#x201d;), Small Computer System Interface (&#x201c;SCSI&#x201d;), Fiberchannel (&#x201c;FC&#x201d;), Enterprise System Connection (&#x201c;ESCON&#x201d;), ESCON over Fiberchannel (&#x201c;FICON&#x201d;), and the like. In an embodiment, it may include dedicated local I/O devices.</p>
<p id="p-0048" num="0047">The bus <b>110</b> may comprise one or more of a variety of physical and logical topologies. It may be parallel or serial. It may be unidirectional or bidirectional. It may be flat or hierarchical. It may comprise a full or partial crossbar. It may comprise multiple bridged busses. In an embodiment, the bus <b>110</b> may comprise a high-speed internal network.</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram of a possible computer <b>200</b> including a software stack in which the present invention may at least in part reside. The software stack may include task(s) <b>202</b>, hosted on an operating system <b>204</b>, enabled by firmware <b>206</b>, running on a hardware platform <b>100</b> of which the configuration of <figref idref="DRAWINGS">FIG. 1</figref> is representative.</p>
<p id="p-0050" num="0049">The task(s) <b>202</b> may include both user- and system-level tasks. They may be interactive or batch. They may run in the foreground or background. User-level task(s) <b>202</b> may include applications, programs, jobs, middleware, and the like. System-level task(s) <b>202</b> may include services, drivers, daemons, utilities, and the like.</p>
<p id="p-0051" num="0050">The operating system <b>204</b> may be of any type and version and in any state. Types may include Unix, Linux, Windows, Mac, MVS, VMS, and the like. Versions may include Windows XP, Windows Vista, and the like. States may include a degree of customization, a mode of operation, a system preparation for setup, and the like. The operating system <b>204</b> may be single-user or multi-user. It may be single-tasking or multi-tasking. In an embodiment, the operating system <b>204</b> may be real-time. In another embodiment, the operating system <b>204</b> may be embedded.</p>
<p id="p-0052" num="0051">The firmware <b>206</b> may comprise microcode, which may reside in a microstore of the processor(s) <b>102</b>. In an embodiment, the firmware <b>206</b> may comprise low-level software, which may reside in memory <b>104</b>. In one embodiment, the firmware <b>206</b> may comprise a rudimentary operating system <b>204</b>. In a further embodiment, the firmware <b>206</b> may support virtualization so as to permit the concurrent operation of multiple operating systems <b>204</b> on a hardware platform <b>100</b>.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic block diagram illustrating a system <b>300</b> of the present invention, comprising the computer <b>200</b> and a memory upgrade optimization subsystem <b>302</b>. The subsystem <b>302</b> further comprises a memory upgrade optimization apparatus <b>304</b>, an input module <b>306</b>, and a control module <b>308</b>. In an embodiment, the foregoing components of the subsystem <b>302</b> may be fully or partially implemented within the hardware platform <b>100</b> or the software stack of the computer <b>200</b>. The input module <b>306</b> may receive and convey to one or more other modules input such as configuration information regarding an array of memory devices comprised within the memory <b>104</b> of the hardware platform <b>100</b>. The configuration information may be automatically detected, such as at initial power-on during power-on system test (&#x201c;POST&#x201d;), manually specified, or may comprise both automatic and manual forms of input. The apparatus <b>304</b> may be employed whenever memory upgrade optimization is required in order to effect a given operation of the system <b>300</b>, activated by the control module <b>308</b>. Operations requiring a memory upgrade optimization may include reconfiguration of the memory <b>104</b>, a change or upgrade of other related components within the hardware platform <b>100</b> such as the bus <b>110</b>, system performance tuning, and the like.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic block diagram illustrating the memory upgrade optimization apparatus <b>304</b> according to the present invention, comprising a requirements module <b>402</b>, an analysis module <b>404</b>, and a reconfiguration module <b>406</b>. The requirements module <b>402</b> may receive a capacity upgrade goal, a performance upgrade goal, or both. The requirements module <b>402</b> may also determine an overall capacity of the array and an overall performance of the array based upon the configuration information from the input module <b>306</b>. An upgrade typically denotes an increase in capacity or performance, but may also denote a decrease, particularly if there is an inverse relationship between capacity and performance.</p>
<p id="p-0055" num="0054">The analysis module <b>404</b> identifies a first potential capacity change that can be achieved at a lower overall performance and a second potential capacity change that can be achieved at a higher overall performance. In this context, the terms lower and higher should be understood to be relative to one another. The overall capacity and the overall performance may potentially change in either an upward or downward direction. The potential capacity changes may therefore be either positive or negative. In one embodiment, a lower overall performance may permit a higher overall capacity, whereas a higher overall performance may only permit a lower overall capacity. As a result, the first potential capacity change may be greater than the second potential capacity change.</p>
<p id="p-0056" num="0055">The reconfiguration module <b>406</b> may generate one or more reconfiguration recommendations. A first reconfiguration recommendation may be calculated to yield an overall capacity improvement that takes into consideration the capacity upgrade goal and the first potential capacity change. For example, the current overall performance of the array may correspond to the lower overall performance, and it may be desired to increase the capacity of the array without reducing the current overall performance. The analysis module <b>404</b> would therefore identify a first potential capacity change that would not impact the current overall performance.</p>
<p id="p-0057" num="0056">In one embodiment, the reconfiguration module <b>406</b> may recommend a capacity improvement equal to the capacity upgrade goal if the capacity upgrade goal is less than or equal to the first potential capacity change. In another embodiment, the reconfiguration module <b>406</b> may recommend a capacity improvement equal to the first potential capacity change if the capacity upgrade goal is greater than the first potential capacity change. In a further embodiment, the reconfiguration module <b>406</b> may generate one or more reconfiguration recommendations greater than the first potential capacity change and less than the capacity upgrade goal.</p>
<p id="p-0058" num="0057">A second reconfiguration recommendation may be calculated to yield an overall performance improvement that takes into consideration the performance upgrade goal and the second potential capacity change. For example, the performance upgrade goal may correspond to the higher overall performance. The analysis module <b>404</b> therefore would identify a second potential capacity change that would permit the performance upgrade goal to be achieved.</p>
<p id="p-0059" num="0058">In one embodiment, the reconfiguration module <b>406</b> may recommend a capacity improvement equal to the capacity upgrade goal if the capacity upgrade goal is less than or equal to the second potential capacity change. In another embodiment, the reconfiguration module <b>406</b> may recommend a capacity improvement equal to the second potential capacity change if the capacity upgrade goal is greater than the second potential capacity change. In a further embodiment, the reconfiguration module <b>406</b> may generate one or more reconfiguration recommendations greater than the second potential capacity change and less than the capacity upgrade goal.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic block diagram of memory device organization and structure, including a single-rank memory device <b>500</b>-<b>1</b>, a double-rank memory device <b>500</b>-<b>2</b>, and a quad-rank memory device <b>500</b>-<b>4</b>. The memory device <b>500</b> is comprised of one or more ranks of dynamic random-access memory chips (&#x201c;DRAMs&#x201d;) <b>502</b>. The DRAM <b>502</b> is connected to a bi-directional bus <b>504</b> via a tri-state connection <b>506</b>. The tri-state connection <b>506</b> is enabled to drive the bi-directional bus <b>504</b> when a chip select <b>508</b> is asserted. A rank comprises all of the DRAMs controlled by a given chip select <b>508</b>. First chip selects <b>508</b>-<b>0</b> control the first rank of their respective memory devices <b>500</b>. Second chip selects <b>508</b>-<b>1</b> control the second rank of the double-rank memory device <b>500</b>-<b>2</b> and the quad-rank memory device <b>500</b>-<b>4</b>. Third and fourth chip selects <b>508</b>-<b>2</b> and <b>508</b>-<b>3</b> control the third and fourth ranks respectively of the quad-rank memory device <b>500</b>-<b>4</b>. In the embodiment shown, each rank comprises four DRAMs connected respectively to each of four bi-directional busses <b>504</b> in each memory device <b>500</b>. Other embodiments may comprise a greater or lesser number of DRAMs <b>502</b> per rank.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 6</figref> is a schematic block diagram of dual in-line memory module (&#x201c;DIMM&#x201d;) <b>600</b> organization and structure. DIMMs <b>600</b>-<b>1</b> and <b>600</b>-<b>2</b> are single-rank memory devices <b>500</b>-<b>1</b>, and DIMM <b>600</b>-<b>3</b> is a double-rank memory device <b>500</b>-<b>2</b>. All of the DIMMs <b>600</b> shown have a capacity of 2 gigabytes (GB) with a total depth of 256&#xd7;2<sup>20 </sup>(M) and a total bus width of 64 bits. DIMM <b>600</b>-<b>1</b> is comprised of 16 DRAMs <b>502</b>-<b>1</b>, each of which is 256 M deep and 4 bits wide. DIMM <b>600</b>-<b>2</b> is comprised of 8 DRAMs <b>502</b>-<b>2</b>, each of which is 256 M deep and 8 bits wide. DIMM <b>600</b>-<b>3</b> is comprised of 16 DRAMs <b>502</b>-<b>3</b>, each of which is 128 M deep and 8 bits wide. Other embodiments differing by rank, depth, width, and capacity are also possible.</p>
<p id="p-0062" num="0061">DIMMs <b>600</b> may also vary as to speed in megahertz (MHz) and type. The DIMMs <b>600</b> as shown are unbuffered (type U). DIMMs <b>600</b> may also be fully buffered (type FB), registered (type R), and so forth. Some or all of the foregoing characteristics may affect the individual performance capability of a DIMM <b>600</b>. For example, a first DIMM <b>600</b> having a speed of 1066 MHz and a width of 64 bits would have higher bandwidth than a second DIMM <b>600</b> having a speed of 1333 MHz and a width of 32 bits, even though the speed of the first is lower than that of the second. As another example, higher rank may also affect individual performance capability, possibly due to increased loading on the bi-directional bus <b>504</b> from the higher number of tri-state connections <b>506</b>. Thus a quad-rank memory device <b>500</b>-<b>4</b> may only support a speed of 800 MHz even though its constituent DRAMs <b>502</b> might have otherwise supported a higher speed in a lower-rank configuration.</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. 7</figref> is a more detailed schematic block diagram of the computer hardware platform <b>100</b>, further comprising a storage subsystem <b>702</b> connected via a storage interface <b>704</b> to the input/output device interface <b>108</b>. The memory <b>104</b> comprises an array <b>706</b> of slots <b>708</b> to accommodate the memory devices <b>500</b>. The slots <b>708</b> may be organized into subsets in which the slots <b>708</b> share the same channel <b>710</b>. In the example shown, there are three channels <b>710</b> associated with each processor <b>102</b>. The slots <b>708</b> are also grouped in tiers <b>712</b>. In populating the slots <b>708</b> of a given channel <b>710</b> with memory devices <b>500</b>, the slot <b>708</b> of the first tier <b>712</b>-<b>1</b> must be populated first, followed by the second tier <b>712</b>-<b>2</b>, and then the third tier <b>712</b>-<b>3</b>. There may also be other memory devices <b>714</b> which are not part of the array <b>706</b>. Examples of other such memory devices include read-only memory (&#x201c;ROM&#x201d;), flash memory, complementary metal-oxide-semiconductor memory (&#x201c;CMOS&#x201d;), and the like.</p>
<p id="p-0064" num="0063">In an embodiment, as the quantity of memory devices <b>500</b> populating the slots <b>708</b> of a given channel <b>710</b> increases, the overall performance of the array <b>706</b> may decrease, due to an increased load on the channel <b>710</b> or other design issues. The overall performance may also be limited by the individual performance capability of the lowest-performing device <b>500</b> in the array <b>706</b>. As a result, the overall performance may have a substantially inverse relationship with the highest quantity of memory devices <b>500</b> populating a channel <b>710</b> of the array <b>706</b> and a substantially direct relationship with the lowest individual performance capability of the memory devices <b>500</b> themselves. These competing factors create a trade-off between the overall performance and the overall capacity of the array <b>706</b>.</p>
<p id="p-0065" num="0064">Performance, whether the overall performance of the array <b>706</b>, or the individual performance capability of the memory device <b>500</b>, may comprise one or more criteria such as frequency, bandwidth, access time, latency, and the like. In one embodiment, a single metric such as frequency expressed in MHz may suffice to characterize performance, everything else being equal. However, in another embodiment, the bandwidth might also vary if a configuration change in the array <b>706</b> involves a corresponding change in the width of the bus <b>110</b>. In yet another embodiment, the latency may increase due to memory devices <b>500</b> populating increasingly remote slots <b>708</b> of the array <b>706</b>, while the frequency may be kept constant by employing a pipelining approach.</p>
<p id="p-0066" num="0065">As a useful abstraction to suppress the interrelated complexity of these various performance criteria, we shall hereinafter refer to a &#x201c;performance class&#x201d; as being representative of those processors <b>102</b>, those configurations of the array <b>706</b> and those individual performance capabilities of the memory devices <b>500</b> that would support comparable overall performance. For example, performance class one may comprise processors <b>102</b> and memory devices <b>500</b> having a speed of 1333 MHz or an array <b>706</b> having only the first tier <b>712</b>-<b>1</b> populated, performance class two may comprise processors <b>102</b> and memory devices <b>500</b> having a speed of 1066 MHz or an array <b>706</b> having both the first tier <b>712</b>-<b>1</b> and the second tier <b>712</b>-<b>2</b> populated, and performance class three may comprise processors <b>102</b> and memory devices <b>500</b> having a speed of 800 MHz or an array <b>706</b> having all three tiers <b>712</b> are populated. It will be apparent to one of skill in the art that classification into performance classes could be based upon other performance criteria as well, which other criteria therefore fall within the scope of the present invention.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 8</figref> is a schematic block diagram illustrating an example of a suboptimally configured memory array <b>706</b>. The overall performance of the array <b>706</b> is of performance class is two, because the inherent performance capability of memory device <b>802</b> is of performance class two, and the second tier <b>712</b>-<b>2</b> is populated by a memory device <b>804</b>.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 9</figref> is a schematic block diagram of an upgraded reconfiguration of the memory array <b>706</b> calculated to yield an overall performance improvement to performance class one. First, the memory device <b>802</b> of performance class two has been replaced with a memory device <b>902</b> of performance class one. Secondly, the memory device <b>804</b> has been moved from slot <b>708</b>-<b>2</b> of the second tier <b>712</b>-<b>2</b> to slot <b>708</b>-<b>1</b> of the first tier <b>712</b>-<b>1</b>. As a result, the overall performance of the array <b>706</b> is now of performance class one.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 10</figref> is a schematic block diagram of an upgraded reconfiguration of the memory array <b>706</b> calculated to yield an overall capacity improvement to an overall capacity of 6 memory devices. The capacity upgrade goal is therefore 2 additional memory devices, and there is no performance upgrade goal. Given that the current overall performance is of performance class two, the first potential capacity change would be 8 memory devices, as identified by the 12 slots <b>708</b> to fully populate the first tier <b>712</b>-<b>1</b> and the second tier <b>712</b>-<b>2</b> minus the 4 memory devices <b>500</b> that are already present. Thus there is ample potential capacity to add memory device <b>1002</b> and memory device <b>1004</b>, which are both of performance class two, the same as the current overall performance.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 11</figref> is a schematic block diagram of an upgraded reconfiguration of the memory array <b>706</b> calculated to yield both an overall performance improvement to performance class one and an overall capacity improvement to an overall capacity of 6 memory devices. The capacity upgrade goal is therefore 2 additional memory devices, and the performance upgrade goal is one class higher. Given that the overall performance improvement is to performance class one, the second potential capacity change would be 2 memory devices, as identified by the 6 slots <b>708</b> to fully populate the first tier <b>712</b>-<b>1</b> minus the 4 memory devices <b>500</b> that are already present. Thus there is sufficient potential capacity to add memory device <b>1102</b> and memory device <b>1104</b>, which are both of performance class one, as required to achieve the overall performance improvement. It is further necessary to replace memory device <b>802</b> of performance class two with memory device <b>902</b> of performance class one, and move memory device <b>804</b> from slot <b>708</b>-<b>2</b> of the second tier <b>712</b>-<b>2</b> to slot <b>708</b>-<b>1</b> of the first tier <b>712</b>-<b>1</b>. As a result, the overall performance of the array <b>706</b> is now of performance class one.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 12</figref> is a schematic flow chart diagram illustrating one embodiment of a method for determining overall performance of a memory array <b>706</b> as may be performed by a requirements module <b>402</b> in accordance with the present invention. The method <b>1200</b> starts <b>1202</b> and the overall performance class of the array <b>706</b> and the quantity of memory devices <b>500</b> populating a subset or channel <b>710</b> are initialized <b>1204</b> to one and zero, respectively. The memory devices <b>500</b> are then examined in turn, classifying <b>1206</b> the individual performance capability of the next memory device, and the quantity is incremented <b>1208</b>. If the memory device performance class representing the individual performance capability of the memory device <b>500</b> is greater than <b>1210</b> the overall performance class, then the overall performance class is set equal <b>1212</b> to the memory device performance class. If the quantity is greater than <b>1214</b> the overall performance class, then the overall performance class is set equal <b>1216</b> to the quantity. If the memory device <b>500</b> is not the last <b>1218</b> device in the subset, then the next memory device <b>500</b> is classified <b>1206</b> and the ensuing steps are repeated. If the subset is not the last <b>1220</b> subset in the array <b>706</b>, then the next subset is examined in turn, reinitializing <b>1222</b> the quantity to zero, classifying <b>1206</b> the next memory device <b>500</b>, and repeating the ensuing steps as before. After the last <b>1220</b> subset has been examined, the overall performance class has now been determined as the maximum of the memory device performance class of any individual memory device <b>500</b> and the quantity of memory devices <b>500</b> in any subset, and the method <b>1200</b> ends <b>1224</b>.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 13</figref> is a schematic flow chart diagram illustrating one embodiment of a method for memory upgrade optimization as may be performed by the memory upgrade optimization apparatus <b>304</b> in accordance with the present invention. The method <b>1300</b> starts <b>1302</b> and examines <b>1304</b> the upgrade goals. If there is a capacity upgrade goal then it is received <b>1306</b> and if there is a performance upgrade goal then it is received <b>1308</b>. The first potential capacity change is identified <b>1310</b> and the first reconfiguration recommendation is generated <b>1312</b> if the capacity upgrade goal was received <b>1306</b>. The second potential capacity change is identified <b>1314</b> and the second reconfiguration recommendation is generated <b>1316</b> if the performance upgrade goal was received <b>1308</b>. If the reconfiguration recommendations are not to be prioritized <b>1318</b>, including the case of there being only one reconfiguration recommendation, then the method <b>1300</b> ends <b>1320</b>.</p>
<p id="p-0073" num="0072">If the reconfiguration recommendations are to be prioritized <b>1318</b>, then a first function of the overall capacity that at least partially predicts an overall efficiency of the system <b>300</b> is evaluated <b>1322</b>, and a second function of the overall performance that at least partially predicts the overall efficiency is evaluated <b>1324</b>. If the overall efficiency predicted by the first function is higher <b>1326</b> than that predicted by the second function, then the first reconfiguration recommendation is emphasized <b>1328</b>, and the method <b>1300</b> ends <b>1320</b>. Otherwise, the second reconfiguration recommendation is emphasized <b>1330</b>, and the method <b>1300</b> ends <b>1320</b>.</p>
<p id="p-0074" num="0073">In one embodiment, the overall efficiency is evaluated in terms of system throughput, the first function is based at least in part on a paging rate of the storage subsystem <b>702</b>, and the second function is based at least in part on a cache subsystem miss penalty. For example, the first function may comprise a first factor times the overall capacity. As overall capacity increases, the paging rate decreases, increasing the overall efficiency by the first factor. Similarly, the second function may comprise a second factor times the overall performance. As overall performance increases, the cache subsystem miss penalty decreases, increasing the overall efficiency by the second factor.</p>
<p id="p-0075" num="0074">If the first function predicts lower overall efficiency, the system <b>300</b> is said to be I/O-bound, meaning that the time spent retrieving pages from the storage subsystem <b>702</b> is the dominant constraint on the system throughput rate. Increasing the capacity of the memory array <b>706</b> allows more pages to remain resident, thereby reducing the paging rate and improving the overall efficiency.</p>
<p id="p-0076" num="0075">If the second function predicts lower overall efficiency, the system <b>300</b> is said to be CPU-bound, meaning that the time spent retrieving data from the memory array <b>706</b> into the cache subsystem of the processors <b>102</b> is the dominant constraint on the system throughput rate. Increasing the performance of the memory array <b>706</b> allows the data to be retrieved more quickly from the memory array <b>706</b>, thereby reducing the cache subsystem miss penalty and improving the overall efficiency.</p>
<p id="p-0077" num="0076">As a result, an I/O-bound system <b>300</b> may achieve higher throughput by emphasizing the first reconfiguration recommendation calculated to yield an overall capacity improvement, whereas a CPU-bound system <b>300</b> may achieve higher throughput by emphasizing the second reconfiguration recommendation calculated to yield an overall performance improvement.</p>
<p id="p-0078" num="0077">The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is, therefore, indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An apparatus comprising:
<claim-text>a requirements module that receives one or more of a capacity upgrade goal for an overall capacity of an array of members that are memory devices in a computer memory and a speed-related performance upgrade goal for an overall performance of the array, each member of the array having an individual performance capability wherein the overall performance has a substantially inverse relationship with a highest quantity of members of a subset of the array and a substantially direct relationship with the individual performance capability of the members;</claim-text>
<claim-text>an analysis module that identifies a first potential capacity change that can be achieved at a lower overall performance and a second potential capacity change that can be achieved at a higher overall performance; and</claim-text>
<claim-text>a reconfiguration module that generates one or more of a first physical reconfiguration recommendation calculated to yield an overall capacity improvement that takes into consideration the capacity upgrade goal and the first potential capacity change and a second physical reconfiguration recommendation calculated to yield an overall performance improvement that takes into consideration the performance upgrade goal and the second potential capacity change,</claim-text>
<claim-text>wherein the requirements module, the analysis module, and the reconfiguration module comprise one or more of logic hardware and executable code, the executable code stored on one or more non-transitory computer-readable storage media.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the overall performance and the individual performance capabilities each belong to one of a plurality of performance classes defined as being representative of those configurations of the array and those individual performance capabilities of the memory devices that would support comparable overall performance.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein performance is determined on the basis of one or more of clock frequency in hertz, bandwidth, access time, and latency.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the performance classes are based solely upon clock frequency in hertz.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A system comprising:
<claim-text>a computer having one or more processors and having a computer memory comprising an array of members that are memory devices;</claim-text>
<claim-text>a requirements module that receives one or more of a capacity upgrade goal for an overall capacity of an array of memory devices in a computer memory and a speed-related performance upgrade goal for an overall performance of the array, each member of the array having an individual performance capability wherein the overall performance has a substantially inverse relationship with a highest quantity of members of a subset of the array and a substantially direct relationship with the individual performance capability of the members;</claim-text>
<claim-text>an analysis module that identifies a first potential capacity change that can be achieved at a lower overall performance and a second potential capacity change that can be achieved at a higher overall performance;</claim-text>
<claim-text>a reconfiguration module that generates one or more of a first physical reconfiguration recommendation calculated to yield an overall capacity improvement that takes into consideration the capacity upgrade goal and the first potential capacity change and a second physical reconfiguration recommendation calculated to yield an overall performance improvement that takes into consideration the performance upgrade goal and the second potential capacity change; and</claim-text>
<claim-text>a control module that activates the requirements module, the analysis module, and the reconfiguration module to optimize an upgrade path of the array,</claim-text>
<claim-text>wherein the requirements module, the analysis module, the reconfiguration module, and the control module comprise one or more of logic hardware and executable code, the executable code executable on the processor and stored in one or more of the array of memory devices and another memory device in the computer memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the overall performance and the individual performance capabilities each belong to one of a plurality of performance classes defined as being representative of those configurations of the array and those individual performance capabilities of the memory devices that would support comparable overall performance.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein one or more of the subsets of the array are associated with each of the one or more processors.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the capacity upgrade goal and the performance upgrade goal are calculated to achieve an overall efficiency of the system, wherein the overall efficiency comprises a system throughput rate that is at least partially predicted by the overall capacity according to a first function based at least in part on a storage subsystem paging rate, and by the overall performance according to a second function based at least in part on a cache subsystem miss penalty.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the individual performance capability of the memory device is determined on the basis of one or more of rank, capacity, speed, type, and depth.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the memory device comprises a dual in-line memory module (&#x201c;DIMM&#x201d;) and the subset comprises a channel.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the overall performance and the individual performance capability of at least one member belong to different performance classes.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A computer program product comprising a non-transitory computer-readable storage medium having computer usable program code executable to perform operations, the operations of the computer program product comprising:
<claim-text>receiving one or more of a capacity upgrade goal for an overall capacity of an array of members that are memory devices in a computer memory and a speed-related performance upgrade goal for an overall performance of the array, each member of the array having an individual performance capability wherein the overall performance has a substantially inverse relationship with a highest quantity of members of a subset of the array and a substantially direct relationship with the individual performance capability of the members;</claim-text>
<claim-text>identifying a first potential capacity change that can be achieved at a lower overall performance and a second potential capacity change that can be achieved at a higher overall performance; and</claim-text>
<claim-text>generating one or more of a first physical reconfiguration recommendation calculated to yield an overall capacity improvement that takes into consideration the capacity upgrade goal and the first potential capacity change and a second physical reconfiguration recommendation calculated to yield an overall performance improvement that takes into consideration the performance upgrade goal and the second potential capacity change.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer program product of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the overall performance and the individual performance capabilities each belong to one of a plurality of performance classes defined as being representative of those configurations of the array and those individual performance capabilities of the memory devices that would support comparable overall performance.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The computer program product of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the capacity upgrade goal and the performance upgrade goal are calculated to achieve an overall efficiency of a system, wherein the overall efficiency is at least partially predicted by the overall capacity according to a first function, and by the overall performance according to a second function.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The computer program product of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the step of generating further comprises emphasizing the first physical reconfiguration recommendation if the overall efficiency predicted by the first function is higher, and emphasizing the second physical reconfiguration recommendation if the overall efficiency predicted by the second function is higher.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The computer program product of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the performance classes are based solely upon clock frequency in hertz.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A machine-implemented method comprising the steps of:
<claim-text>receiving one or more of a capacity upgrade goal for an overall capacity of an array of members that are memory devices in a computer memory and a speed-related performance upgrade goal for an overall performance of the array, each member of the array having an individual performance capability wherein the overall performance has a substantially inverse relationship with a highest quantity of members of a subset of the array and a substantially direct relationship with the individual performance capability of the members;</claim-text>
<claim-text>identifying a first potential capacity change that can be achieved at a lower overall performance and a second potential capacity change that can be achieved at a higher overall performance; and</claim-text>
<claim-text>generating one or more of a first physical reconfiguration recommendation calculated to yield an overall capacity improvement that takes into consideration the capacity upgrade goal and the first potential capacity change and a second physical reconfiguration recommendation calculated to yield an overall performance improvement that takes into consideration the performance upgrade goal and the second potential capacity change.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the overall performance and the individual performance capabilities each belong to one of a plurality of performance classes defined as being representative of those configurations of the array and those individual performance capabilities of the memory devices that would support comparable overall performance.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the physical reconfiguration comprises replacing a member of the array with a member having a different individual performance capability.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the physical reconfiguration comprises moving a member from a subset of the array to another subset of the array.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the capacity upgrade goal and the performance upgrade goal are calculated to achieve an overall efficiency of a system comprising the array.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the overall efficiency is at least partially predicted by the overall capacity according to a first function, and by the overall performance according to a second function.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the step of generating further comprises emphasizing the first physical reconfiguration recommendation if the overall efficiency predicted by the first function is higher, and emphasizing the second physical reconfiguration recommendation if the overall efficiency predicted by the second function is higher.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the overall efficiency comprises a system throughput rate, the first function is based at least in part on a storage subsystem paging rate, and the second function is based at least in part on a cache subsystem miss penalty.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the performance classes are based solely upon clock frequency in hertz. </claim-text>
</claim>
</claims>
</us-patent-grant>
