<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624914-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624914</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12744702</doc-number>
<date>20090713</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2008-321842</doc-number>
<date>20081218</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>212</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>40</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>63</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>24</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>048</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>46</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345589</main-classification>
<further-classification>345419</further-classification>
<further-classification>345619</further-classification>
<further-classification>345630</further-classification>
<further-classification>348552</further-classification>
<further-classification>348557</further-classification>
<further-classification>382162</further-classification>
<further-classification>382167</further-classification>
<further-classification>382164</further-classification>
<further-classification>382254</further-classification>
<further-classification>382260</further-classification>
<further-classification>715706</further-classification>
<further-classification>715757</further-classification>
<further-classification>463 31</further-classification>
<further-classification>463 32</further-classification>
</classification-national>
<invention-title id="d2e71">Image processing apparatus and image processing method</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6411744</doc-number>
<kind>B1</kind>
<name>Edwards</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382294</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6785667</doc-number>
<kind>B2</kind>
<name>Orbanes et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>  1  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2005/0179617</doc-number>
<kind>A1</kind>
<name>Matsui et al.</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345  7</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2007/0126749</doc-number>
<kind>A1</kind>
<name>Tzruya</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2007/0252833</doc-number>
<kind>A1</kind>
<name>Kuroki</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345427</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2011/0050684</doc-number>
<kind>A1</kind>
<name>Maegawa et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2011/0122130</doc-number>
<kind>A1</kind>
<name>Vesely et al.</name>
<date>20110500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2012/0287044</doc-number>
<kind>A1</kind>
<name>Bell et al.</name>
<date>20121100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345158</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>JP</country>
<doc-number>2002258785</doc-number>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>2008012103</doc-number>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>WO</country>
<doc-number>2006105660</doc-number>
<kind>A1</kind>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>WO</country>
<doc-number>2008127705</doc-number>
<kind>A1</kind>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>International Preliminary Report on Patentability and Written Opinion for corresponding PCT application PCT/JP2009/003279, Jul. 5, 2011.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Written Opinion for corresponding PCT application PCT/JP2009/003279, Sep. 15, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>International Search Report for corresponding PCT application PCT/JP2009/003279, Sep. 15, 2009.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>European search report issued for corresponding European Patent Application No. 09817066.5, dated Oct. 9, 2013.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Nick: 11 the Co 1 our of (A Lot Of High Profile) Next-Gen Games, Aeropause Games, URL:http://www.aeropause.com/2006/10/the-colour-of-a-lot-of-high-profile-next-gen-games/ pp. 1-7, (Oct. 23, 2006).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>7</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345418-419</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345581</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345589-591</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345593-594</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345619-620</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345624</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345630</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345623</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345625</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345629</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345664</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345960</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348552</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348557-558</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358518-519</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358523</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358537-538</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358540</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358448</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358452-453</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382162</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382164-167</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382170-171</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382254</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382260</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382274</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382276</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382282</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382305</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382285</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715273</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715275</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715700</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715706</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715757</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715764</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715782</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>463 30- 33</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>15</number-of-drawing-sheets>
<number-of-figures>19</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110316869</doc-number>
<kind>A1</kind>
<date>20111229</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kariya</last-name>
<first-name>Shinichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Satoh</last-name>
<first-name>Jin</first-name>
<address>
<city>Nara</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Maegawa</last-name>
<first-name>Hirotoshi</first-name>
<address>
<city>Toyko</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kariya</last-name>
<first-name>Shinichi</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Satoh</last-name>
<first-name>Jin</first-name>
<address>
<city>Nara</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Maegawa</last-name>
<first-name>Hirotoshi</first-name>
<address>
<city>Toyko</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Dernier, Esq.</last-name>
<first-name>Matthew B.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<orgname>Gibson &#x26; Dernier LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
<assignee>
<addressbook>
<orgname>Sony Computer Entertainment Inc.</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Sajous</last-name>
<first-name>Wesner</first-name>
<department>2677</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP2009/003279</doc-number>
<kind>00</kind>
<date>20090713</date>
</document-id>
<us-371c124-date>
<date>20100526</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2010/070778</doc-number>
<kind>A </kind>
<date>20100624</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An inspection apparatus specifies a region for displaying an advertisement from an image of a virtual space. The inspection apparatus comprises: an image mapping unit that maps an image, which uses a color that is not used in the virtual space and where the display status of the advertisement varies in accordance with a viewpoint of a user, on a region where the advertisement is to be displayed in the virtual space; an inspection image acquiring unit that acquires a virtual space that is actually displayed on a screen on a frame-by-frame basis; and an advertisement region extracting unit operative to extract, by color-filtering the acquired image of the virtual space, a region that is rendered with a color that is not used in the virtual space, as a region for displaying the advertisement perceived by a user.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="127.93mm" wi="228.94mm" file="US08624914-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="262.30mm" wi="149.86mm" orientation="landscape" file="US08624914-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="267.72mm" wi="158.07mm" orientation="landscape" file="US08624914-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="154.60mm" wi="209.80mm" file="US08624914-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="234.36mm" wi="168.23mm" file="US08624914-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="146.47mm" wi="162.81mm" file="US08624914-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="274.49mm" wi="166.88mm" orientation="landscape" file="US08624914-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="173.06mm" wi="170.26mm" file="US08624914-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="144.44mm" wi="157.40mm" file="US08624914-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="135.55mm" wi="192.11mm" file="US08624914-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="259.50mm" wi="174.41mm" file="US08624914-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="118.53mm" wi="159.43mm" file="US08624914-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="98.64mm" wi="137.08mm" file="US08624914-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="148.51mm" wi="140.29mm" file="US08624914-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="147.83mm" wi="146.47mm" file="US08624914-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="166.45mm" wi="139.02mm" file="US08624914-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">This invention generally relates to data processing technology, and more particularly, to technology for processing an image of the virtual space of games or the like.</p>
<heading id="h-0002" level="1">DESCRIPTION OF THE RELATED ART</heading>
<p id="p-0003" num="0002">As a technology for detecting the existence of a specific object included in images of a virtual space, a technology is known where reference images are prepared in advance and where the reference images and the images of a virtual space, in which a determination of whether the object exists takes place, are compared with each other.</p>
<p id="p-0004" num="0003">See, for example, Japanese patent application: Publication No. 2008-012103.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<heading id="h-0004" level="1">A Problem to be Solved by the Invention</heading>
<p id="p-0005" num="0004">Some applications of games or the like change the appearance of a virtual space according to the viewpoint that is set by a user and change the display status of objects in the virtual space.</p>
<p id="p-0006" num="0005">In the case of detecting a specific object from the images displaying such a virtual space, the cost increases with the method of comparing the reference images with the images of a virtual space, in which a determination of whether the object exists is made. For example, it is necessary to prepare in advance a lot of images for reference that correspond to a variety of display statuses of the object. Further, a lot of comparison processing is required.</p>
<p id="p-0007" num="0006">In this background, a main purpose of the present invention is to provide technology for easily detecting a specific object in an image of a virtual space where the display status of the space changes according to the view point set by a user.</p>
<p id="p-0008" num="0007">In order to approach the problem mentioned above, an inspection apparatus for specifying a region for displaying a predetermined object from an image of a virtual space is provided, according to one embodiment of the present invention. The inspection apparatus comprises: a image mapping unit operative to map an image, which uses a color that is not used in the virtual space where the display status of the object varies in accordance with a viewpoint of a user, on a region where the object is to be displayed in the virtual space, an image acquiring unit operative to acquire a virtual space that is actually displayed on a screen on a frame-by-frame basis; and a region extracting unit operative to extract, by color-filtering the acquired image of the virtual space, a region which is rendered with a color that is not used in the virtual space, as a region for displaying the object perceived by a user.</p>
<p id="p-0009" num="0008">According to another embodiment of the present invention, a method for specifying a region for displaying a predetermined object from an image of a virtual space is provided. The inspection method comprises: mapping an image, which uses a color that is not used in the virtual space and where the display status of the object varies in accordance with a viewpoint of a user, on a region where the object is to be displayed in the virtual space, acquiring a virtual space that is actually displayed on a screen on a frame-by-frame basis; and extracting, by color-filtering the acquired image of the virtual space, the region that is rendered with the color that is not used in the virtual space, as a region for displaying the object perceived by a user.</p>
<p id="p-0010" num="0009">Optional combinations of the aforementioned constituting elements and implementations of the invention in the form of apparatuses, methods, systems, computer programs, and a recording medium encoded with a program may also be practiced as additional modes of the present invention.</p>
<p id="p-0011" num="0010">The present invention enables the detection of a specific object in the images of a virtual space where the display status of the space changes according to the viewpoint established by a user.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 1</figref> shows the structure of an inspection system according to an embodiment of the present invention;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram showing functional structure of the game device of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 3</figref> shows a screen image of a virtual space;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. 4A</figref>, <b>4</b>B, and <b>4</b>C show the relationship between a virtual space screen and an advertisement region;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 5</figref> shows an example of condition for determining the first index;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram showing the functional structure of the inspection apparatus of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 7</figref> shows a distribution of colors used in a virtual space;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 8</figref> shows a typical advertisement inspection image.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 9</figref> shows an inspection image;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. 10A</figref>, <b>10</b>B, and <b>10</b>C shows a method for generating an advertisement extract image in the inspection image;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 11</figref> schematically shows the boundary of the patches in the advertisement extract image;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 12A</figref> is a flowchart showing the operation of the game device at the preparation stage for the inspection;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 12B</figref> is a flowchart showing the operation of an inspection device at the preparation stage for the inspection;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 13A</figref> is a flowchart showing the operation of the game device at the execution stage of the inspection; and</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 13B</figref> is a flowchart showing the operation of an inspection device at the execution stage of the inspection.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0027" num="0026">First, an explanation on the general outline of embodiments of the present invention will be given before an explanation on the structure thereof will be given.</p>
<p id="p-0028" num="0027">According to the present embodiment, a suggestion is made for technology for inspecting the application of a game that displays a virtual space, such as an urban area, or the like (hereinafter referred to as a &#x201c;game application,&#x201d; as appropriate). In the virtual space according to the present embodiment, the display status of the virtual space changes according to the viewpoint setting that is established by a user. In other words, according to the setting of the viewpoint set up by a user, the appearance of, for example, the shapes or the like of an object in the virtual space changes as seen from the user. In the following description, as an example of objects in a virtual space, objects that display advertisements (hereinafter referred to as merely &#x201c;advertisement&#x201d;) of products or services are assumed.</p>
<p id="p-0029" num="0028">A game application has information on what is displayed and where in the virtual space it is displayed. Therefore, even in case the display status of the virtual space changes according to the viewpoint set by the user, the size (hereinafter referred to as &#x201c;advertisement exposure size,&#x201d; as appropriate) of an area where an advertisement is displayed and exposed so as to be visible to a user in the virtual space can be calculated. A function for calculating the advertisement exposure size in a game application is hereinafter referred to as an &#x201c;advertisement exposure calculating function.&#x201d; By providing the size of the exposure of advertisements from the game application to an external charging processing apparatus, the charging processing apparatus can calculate the appropriate advertisement fee.</p>
<p id="p-0030" num="0029">However, things are different when inspecting the consistency of the advertisement exposure size output from the advertisement exposure calculating function, particularly when inspection is made while the execution status of the game application (e.g., data or the like stored in memory) is in a black box. The display status of the advertisement region constantly varies, and the advertisement exposure size varies, accordingly. Thus, it has been difficult to verify whether or not the advertisement exposure size output from the advertisement exposure calculating function is correct.</p>
<p id="p-0031" num="0030">The present inventor has thought of specifying the advertisement displaying area while utilizing an image of the virtual space output by the game application, finding the advertisement exposure size thereof, and checking both the advertisement exposure size thereof and the advertisement exposure size output from the advertisement exposure calculating function. This enables to verify the consistency of the advertisement exposure size output from the advertisement exposure calculating function of the game application without referring to the execution status of the game application.</p>
<p id="p-0032" num="0031">There are two methods for specifying the advertisement displaying area using the image of a virtual space. The first method is a check by a human inspector with his/her own eyes. The second method is matching the image of the virtual space and a number of reference images that record an advertisement displaying region in a variety of display statuses.</p>
<p id="p-0033" num="0032">However, the former method imposes a heavy burden on the inspector. With the latter method, it is necessary to prepare in advance a lot of images for reference that correspond to a variety of display statuses of the advertisement displaying area. Further, a lot of comparison processing is required. In addition, a part of a billboard is sometimes hidden by a bloc and not displayed, which makes the identification, by image matching, of the advertisement displaying area difficult.</p>
<p id="p-0034" num="0033">Therefore, the present inventor has further thought of a method for specifying an advertisement displaying area using an image of a virtual space, where a color that is not used in the virtual space is set for the advertisement displaying areas in advance. According to this method, by color-filtering the images of the virtual space, the advertisement displaying areas can be specified with ease without depending on the display status of the advertisement displaying areas. An explanation on the structure of embodiments will be given below.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 1</figref> shows the structure of an inspection system according to an embodiment of the present invention. The inspection system <b>1000</b> comprises a game device <b>100</b>, an advertisement distributing apparatus <b>500</b>, a capturing apparatus <b>600</b>, and an inspection apparatus <b>700</b>. These apparatuses are mutually connected via a commonly-known communication means, such as a LAN, a WAN, the Internet, or the like.</p>
<p id="p-0036" num="0035">The game device <b>100</b> is readout from a recording medium <b>400</b> and is executed. Hereinafter, the game device <b>100</b> is assumed to be executing a game application unless expressly noted.</p>
<p id="p-0037" num="0036">The game device <b>100</b> displays the images of a virtual space on the display <b>300</b>. Further, the game device <b>100</b> displays an advertisement on a predetermined area (herein after referred to as &#x201c;advertisement region,&#x201d; as appropriate) of a sign, a billboard, or the like in the virtual space. The game device <b>100</b> calculates an index (hereinafter, referred to as a &#x201c;first index,&#x201d; as appropriate) relating to the amount of exposure of the advertisement in the virtual space and notifies the inspection apparatus <b>700</b> thereof.</p>
<p id="p-0038" num="0037">Further, the game device <b>100</b> detects the user's manipulation of the controller <b>200</b>, changes the viewpoint of the user in the virtual space according to the user's manipulation, and changes the display status of the virtual space according to the change of the viewpoint. When changing the display status of the virtual space, the display status of an advertisement displayed in the virtual space is also changed. For example, assume the user's viewpoint is changed from the status where the user fully faces the advertisement to a status where the user's line of sight is parallel to the advertisement. Then the display status of the advertisement also changes from a status where the advertisement is displayed full face with a large size to a status where the advertisement is displayed on the left or the right side with a relatively small size. A description on the detailed structure of the game device <b>100</b> will be given later.</p>
<p id="p-0039" num="0038">The advertisement distributing apparatus <b>500</b> retains data of advertisements to be displayed in the game device <b>100</b> and provides the game device <b>100</b> with the data on advertisements in response to a request from the game device <b>100</b>. Further, the advertisement distributing apparatus <b>500</b> receives an image (hereinafter referred to as &#x201c;advertisement inspection image,&#x201d; as appropriate) of the advertisement for inspection, performed by the inspection apparatus <b>700</b>, and stores the data. When inspecting the game application, the advertisement inspection image is provided to the game device <b>100</b>.</p>
<p id="p-0040" num="0039">The capturing apparatus <b>600</b> captures an image of the virtual space displayed on the display <b>300</b> and generates moving image data that records the screen image of the virtual space. The capturing apparatus <b>600</b> provides the moving image data to the inspection apparatus <b>700</b>.</p>
<p id="p-0041" num="0040">The inspection apparatus <b>700</b> executes the inspection of the game application recorded on the recording medium <b>400</b>. Here, the consistency of the advertisement exposure calculating function, which is one of the functions of the game application and is executed in the game device <b>100</b>, is inspected in particular.</p>
<p id="p-0042" num="0041">More specifically, from the screen image of the virtual space acquired through the capturing apparatus <b>600</b>, the inspection apparatus <b>700</b> calculates an index (hereinafter, referred to as a &#x201c;second index,&#x201d; as appropriate) relating to the amount of exposure of the advertisement, while using the degree of visibility for users as a basis. The inspection apparatus <b>700</b> then verifies the consistency of the advertisement exposure calculating function of the game application by cross-checking the first index and the second index. A description on the detailed structure of the inspection apparatus <b>700</b> will be given later.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram showing the functional structure of the game device <b>100</b> of <figref idref="DRAWINGS">FIG. 1</figref>. The game device <b>100</b> is provided with an operation detector <b>102</b>, an advertisement acquiring unit <b>104</b>, a game controlling unit <b>106</b>, a display controlling unit <b>108</b>, an exposure indicator calculating unit <b>110</b>, and an exposure indicator transmitting unit <b>112</b>.</p>
<p id="p-0044" num="0043">The blocks as shown in block diagrams of this specification may be implemented, with respect to hardware, by elements such as a CPU of a computer or by a mechanism and, with respect to software, by a computer program or the like. <figref idref="DRAWINGS">FIG. 2</figref> depicts functional blocks implemented by the cooperation of hardware and software. Therefore, it will be obvious to those skilled in the art that the functional blocks may be implemented in a variety of manners by a combination of hardware and software.</p>
<p id="p-0045" num="0044">The operation detector <b>102</b> detects the user's manipulation of the controller <b>200</b> and notifies the game controlling unit <b>106</b> of the details of the manipulation. Upon detecting a predetermined trigger for acquiring an advertisement, for example, when the game is started or when an advertisement is to be updated, the advertisement acquiring unit <b>104</b> acquires, from the advertisement distributing apparatus <b>500</b>, the data on an advertisement to be displayed on the advertisement region in the virtual space.</p>
<p id="p-0046" num="0045">The game controlling unit <b>106</b> executes a variety of calculation processes in the game application that are read out from the recording medium <b>400</b>. More specifically, the game controlling unit <b>106</b> determines the colors to be displayed on the respective pixels of the display <b>300</b> in order to display an image of the virtual space on the display <b>300</b> and notifies the display controlling unit <b>108</b>, accordingly. The display controlling unit <b>108</b> allows the respective pixels on the display <b>300</b> to display the colors instructed by the game controlling unit <b>106</b>.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 3</figref> shows a screen image of the virtual space. On the virtual space screen <b>10</b>, a variety of textures, such as the scenery of an urban area, or the like are displayed. The game controlling unit <b>106</b> acquires the data on an advertisement from the advertisement distributing apparatus <b>500</b> and allows the display controlling unit <b>108</b> to display on the advertisement region <b>12</b> the data on the advertisement. A block <b>14</b> is an object, for example, a character, a building, tree, or the like, that prohibits the advertisement region <b>12</b> from being displayed on the virtual space screen <b>10</b>. <figref idref="DRAWINGS">FIG. 2</figref> will now again be referred to.</p>
<p id="p-0048" num="0047">The exposure indicator calculating unit <b>110</b> acquires from the game controlling unit <b>106</b> data (hereinafter, referred to as &#x201c;actual display data,&#x201d; as appropriate) indicating what is displayed for each of the pixels of every screen image generated by the game controlling unit <b>106</b>, i.e., each frame. The actual display data is, in other words, data indicating which object is displayed on which pixel. In the present embodiment, it is assumed that one frame is generated for every sixtieth of a second ( 1/60 second). The exposure indicator calculating unit <b>110</b> calculates the first index based on the actual display data. The exposure indicator transmitting unit <b>112</b> transmits the first index calculated by the exposure indicator calculating unit <b>110</b> to the inspection apparatus <b>700</b>.</p>
<p id="p-0049" num="0048">A specific explanation on the calculation method of the first index in the exposure indicator calculating unit <b>110</b> will be given. First, the exposure indicator calculating unit <b>110</b> calculates a screen occupancy rate and a valid display rate, which both indicate the actual display record of the advertisement in accordance with the actual display data. By this process, the data chronologically indicating the screen occupancy rate and the valid display rate for the respective frame (hereinafter referred to as &#x201c;basic indices,&#x201d; as appropriate) is calculated.</p>
<p id="p-0050" num="0049">The screen occupancy rate is a ratio of the area of the displayed advertisement region <b>12</b> visible to the user compared to the whole virtual space screen <b>10</b>. For the screen occupancy rate, the exposure indicator calculating unit <b>110</b> calculates, for example, the ratio of the number of pixels on which the displayed advertisement region <b>12</b> is visible to the user compared to the number of whole pixels of the whole virtual space screen <b>10</b>.</p>
<p id="p-0051" num="0050">The valid display rate is a ratio of the area of the displayed advertisement region <b>12</b> visible to the user compared to the whole advertisement region <b>12</b>. As a valid display rate, the exposure indicator calculating unit <b>110</b> calculates, for example, the ratio of the number of pixels on which the displayed advertisement region <b>12</b> is visible to the user compared to the number of pixels of the whole advertisement region <b>12</b>. In the present embodiment, being &#x201c;visible to the user&#x201d; means that the advertisement region <b>12</b> is displayed without running off the edge of the virtual space screen <b>10</b> or without being blocked by a block <b>14</b>, etc.</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 4</figref> shows the relationship between the virtual space screen <b>10</b> and the advertisement region <b>12</b>. An explanation will be given here on a concrete calculated value of the screen occupancy rate and the valid display rate while referring to <figref idref="DRAWINGS">FIG. 4</figref>. <figref idref="DRAWINGS">FIG. 4A</figref> shows the status where a whole advertisement region <b>12</b> is displayed on a virtual space screen <b>10</b> that occupies 25 percent of the screen. In this case, the exposure indicator calculating unit <b>110</b> calculates and determines the screen occupancy rate as 25 percent and the valid display rate as 100 percent. <figref idref="DRAWINGS">FIG. 4B</figref> shows the status where 50 percent of the advertisement region <b>12</b> is displayed on the virtual space screen <b>10</b>. In this case, the exposure indicator calculating unit <b>110</b> calculates and determines the screen occupancy rate as 12.5 percent and the valid display rate as 50 percent. <figref idref="DRAWINGS">FIG. 4C</figref> shows the status where 40 percent of the advertisement region <b>12</b> is obstructed by a block <b>14</b> in the virtual space screen <b>10</b>. In this case, the exposure indicator calculating unit <b>110</b> calculates and determines the screen occupancy rate as 15 percent and the valid display rate as 60 percent.</p>
<p id="p-0053" num="0052">After calculating the basic indices, the exposure indicator calculating unit <b>110</b> calculates the first index based on the basic indices. More specifically, the degree of exposure, which indicates the size of the exposed advertisements in the virtual space during a predetermined period is categorized into three categories, namely, &#x201c;large&#x201d;, &#x201c;medium&#x201d;, and &#x201c;small&#x201d;, and then the number of times that it may respectively fall under these categories is calculated as the first index. The first index that is eventually calculated is, for example, data indicating &#x201c;large: once, medium: twice, small: seven times.&#x201d;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 5</figref> shows an example of the conditions for determining the first index. The &#x201c;evaluation basis&#x201d; field in <figref idref="DRAWINGS">FIG. 5</figref> indicates the data items that are used to determine the degree of exposure. The &#x201c;criterion&#x201d; field indicates the value of evaluation basis that is used as the threshold value.</p>
<p id="p-0055" num="0054">In <figref idref="DRAWINGS">FIG. 5</figref>, all values for &#x201c;display time&#x201d; listed under criterion are three seconds. Therefore, the exposure indicator calculating unit <b>110</b> specifies 180 frames included in the basic indices that are consecutive in a temporal sequence and whose screen occupancy rate is more than 0. If the screen occupancy rate is more than or equal to 25 percent and the valid display rate is more than or equal to 50 percent for any of the 180 frames, the number falling into the category under which the degree of exposure is &#x201c;large&#x201d; is incremented by one. If the condition for the &#x201c;large&#x201d; exposure degree is not met, if the screen occupancy rate is more than or equal to 5 percent, and if the valid display rate is more than or equal to 80 percent for any of the 180 frames, the number falling into the category under which the degree of exposure is &#x201c;medium&#x201d; is incremented by one.</p>
<p id="p-0056" num="0055">If the condition for the exposure degree &#x201c;medium&#x201d; is not met either, if the screen occupancy rate is more than or equal to 1 percent, and if the valid display rate is more than or equal to 95 percent for any of the 180 frames, the number falling into the category under which the degree of exposure is &#x201c;small&#x201d; is incremented by one. If any the conditions are not met, no categories of the degree of exposure are incremented. After specifying the degree of exposure of the aforementioned 180 frames, the exposure indicator calculating unit <b>110</b> executes the specification process for the following 180 frames.</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram showing the functional structure of the inspection apparatus <b>700</b> of <figref idref="DRAWINGS">FIG. 1</figref>. The inspection apparatus <b>700</b> is provided with a preliminary processing unit <b>710</b> and an inspection processing unit <b>720</b>. The preliminary processing unit <b>710</b> generates an advertisement image for the inspection as a preliminary preparation for the calculation of the second index by the inspection processing unit <b>720</b>. The inspection processing unit <b>720</b> cross-checks the first index calculated by using the advertisement inspection image in the game device <b>100</b> and the second index calculated based on the screen image of the virtual space that includes the advertisement inspection image.</p>
<p id="p-0058" num="0057">The preliminary processing unit <b>710</b> includes a preliminary image acquiring unit <b>712</b>, an unused color specifying unit <b>714</b>, and an image mapping unit <b>716</b>. The preliminary image acquiring unit <b>712</b> acquires from the capturing apparatus <b>600</b> the moving image data of the virtual space displayed on the display <b>300</b>. Then the preliminary image acquiring unit <b>712</b> extracts still image data for each frame from the moving image data as a preliminary image.</p>
<p id="p-0059" num="0058">When the capturing apparatus <b>600</b> captures a screen image in the acquisition phase for acquiring the preliminary image, colors that do not later hinder the process of specifying unused color performed by the unused color specifying unit <b>714</b>, which will be described later, are set for the advertisement region <b>12</b> in the virtual space. For example, an advertisement (hereinafter, referred to as &#x201c;dummy advertisement&#x201d;) is set using colors that are not determined to be of the color used in the virtual space screen <b>10</b>. The advertisement distributing apparatus <b>500</b> may provide the game device <b>100</b> with a dummy advertisement where black is set as the non-prohibiting color described above.</p>
<p id="p-0060" num="0059">The unused color specifying unit <b>714</b> specifies a color that is not used in the virtual space provided by the game application. A concrete explanation will be given in the following while referring to <figref idref="DRAWINGS">FIG. 7</figref>. <figref idref="DRAWINGS">FIG. 7</figref> shows a distribution of colors used in the virtual space. In <figref idref="DRAWINGS">FIG. 7</figref>, the vertical axis indicates the distribution of the hue, and the horizontal axis indicates the distribution of the saturation.</p>
<p id="p-0061" num="0060">First, the unused color specifying unit <b>714</b> specifies colors used in each of the plurality of preliminary images extracted by the preliminary image acquiring unit <b>712</b>, and sets the area corresponding to the color as a used region <b>20</b>. Next, the unused color specifying unit <b>714</b> determines a first inspection color range <b>25</b> and a second inspection color range <b>27</b> in the unused region <b>22</b>, which indicates the area other than the used region <b>20</b>. The first inspection color range <b>25</b> and second inspection color range <b>27</b> are a group of colors having certain attributes where hue and saturation are in a predetermined range. In this process, the first inspection color range <b>25</b> and second inspection color range <b>27</b> are preferably determined so that their hues are laid side-by-side, as shown in <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0062" num="0061">Next, the unused color specifying unit <b>714</b> determines one of the colors included in the first inspection color range <b>25</b>, typically a median color, with regard to the hue and saturation in the first inspection color range <b>25</b> and determines the color to be the first inspection color <b>24</b>. In a similar manner, the unused color specifying unit <b>714</b> determines the second inspection color <b>26</b> from the colors included in the second inspection color range <b>27</b>. As will be described later, each color included in the first inspection color range <b>25</b> is identified to be of the same color as the first inspection color <b>24</b>, and each color included in the second inspection color range <b>27</b> is identified to be of the same color as the second inspection color <b>26</b> in the inspection processing unit <b>720</b>. As the size of the first inspection color range <b>25</b> and second inspection color range <b>27</b>, the size that allows each color to be appropriately identified as the same color as the first inspection color <b>24</b> or the second inspection color <b>26</b>, respectively, may be set based on company knowledge or by experiment, performed by the present system. <figref idref="DRAWINGS">FIG. 6</figref> will now again be referred to.</p>
<p id="p-0063" num="0062">The image mapping unit <b>716</b> uses the first inspection color <b>24</b> and the second inspection color <b>26</b> specified by the unused color specifying unit <b>714</b> and generates an advertisement inspection image. The image mapping unit <b>716</b> transmits the generated advertisement inspection image to the advertisement distributing apparatus <b>500</b> and allows the advertisement distributing apparatus <b>500</b> to provide the game device <b>100</b> with the advertisement inspection image when inspecting the game application.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 8</figref> shows a typical advertisement inspection image. As shown in <figref idref="DRAWINGS">FIG. 8</figref>, the image mapping unit <b>716</b> generates an advertisement inspection image <b>28</b> where patches rendered by either the first inspection color <b>24</b> or the second inspection color <b>26</b> are disposed alternately, that is, the patches are disposed so as to form a checkered pattern.</p>
<p id="p-0065" num="0064">Further, when generating the advertisement inspection image <b>28</b>, the image mapping unit <b>716</b> calculates the number of intersecting points formed by the boundaries of patches in the advertisement inspection image <b>28</b> and stores the number into a predetermined storage device. For example, the number of intersecting points is calculated as forty-nine for the advertisement inspection image <b>28</b> shown in <figref idref="DRAWINGS">FIG. 8</figref>. <figref idref="DRAWINGS">FIG. 6</figref> will now again be referred to.</p>
<p id="p-0066" num="0065">The inspection processing unit <b>720</b> includes an exposure indicator acquiring unit <b>722</b>, an inspection image acquiring unit <b>724</b>, an advertisement region extracting unit <b>726</b>, an exposure indicator calculating unit <b>728</b>, and a verification unit <b>730</b>. The exposure indicator acquiring unit <b>722</b> acquires the first index transmitted from the game device <b>100</b>.</p>
<p id="p-0067" num="0066">The inspection image acquiring unit <b>724</b> acquires from the capturing apparatus <b>600</b> a moving image that records screen images of the virtual space where the advertisement inspection image is set. Then, from this moving image, the inspection image acquiring unit <b>724</b> extracts still image data for respective frames as inspection images. <figref idref="DRAWINGS">FIG. 9</figref> shows an inspection image. In the inspection image <b>30</b> of <figref idref="DRAWINGS">FIG. 9</figref>, an advertisement inspection image <b>28</b> is set on the advertisement region <b>12</b>, and a part of the advertisement inspection image <b>28</b> is not visible because of a block <b>14</b>. <figref idref="DRAWINGS">FIG. 6</figref> will now again be referred to.</p>
<p id="p-0068" num="0067">The advertisement region extracting unit <b>726</b> extracts an advertisement region that is displayed to be visible to a user by color-filtering the inspection image acquired by the inspection image acquiring unit <b>724</b> and then generates an image indicating that advertisement region (hereinafter referred to as &#x201c;advertisement extract image,&#x201d; as appropriate). Amore specific explanation on the processing performed by the advertisement region extracting unit <b>726</b> will be given below while referring to <figref idref="DRAWINGS">FIGS. 10A</figref>, <b>10</b>B, and <b>10</b>C.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIGS. 10A</figref>, <b>10</b>B and <b>10</b>C show a method for generating the advertisement extract image in the inspection image <b>30</b>. For a first extract image, the advertisement region extracting unit <b>726</b> first generates an image by extracting the pixels whose pixel value in the inspection image <b>30</b> indicates the first inspection color range <b>25</b>. <figref idref="DRAWINGS">FIG. 10A</figref> shows the first extract image <b>32</b>. Secondly, for a second extract image, the advertisement region extracting unit <b>726</b> generates an image by extracting the pixels whose pixel value in the inspection image <b>30</b> indicates the second inspection color range <b>27</b>. <figref idref="DRAWINGS">FIG. 10B</figref> shows the second extract image <b>34</b>. Next, the advertisement region extracting unit <b>726</b> combines the first extract image <b>32</b> and the second extract image <b>34</b> and generates an advertisement extract image, accordingly. <figref idref="DRAWINGS">FIG. 10C</figref> indicates the advertisement extract image <b>36</b>, where the first extract image <b>32</b> and the second extract image <b>34</b> are combined. In <figref idref="DRAWINGS">FIG. 10C</figref>, an area where the block <b>14</b> is to be displayed is excluded from the advertisement extract image <b>36</b>.</p>
<p id="p-0070" num="0069">The exposure indicator calculating unit <b>728</b> calculates the second index based on the advertisement extract image <b>36</b> generated by the advertisement region extracting unit <b>726</b>. More specifically, pixels that first have pixel values indicating the color of the first inspection color range <b>25</b> or the second inspection color range <b>27</b> are specified as the advertisement region pixels. The advertisement region extracting unit <b>726</b> calculates the screen occupancy rate as the ratio of the number of the advertisement region pixels to the number of pixels of the whole advertisement extract image <b>36</b>.</p>
<p id="p-0071" num="0070">Next, the exposure indicator calculating unit <b>728</b> specifies a part, where pixels having the pixel values of the color of the first inspection color range <b>25</b>, shifts to the pixels having the pixel values of the color of the second inspection color range <b>27</b> among the specified advertisement region pixels as the boundary of patches. Then the exposure indicator calculating unit <b>728</b> specifies the intersections formed by the boundaries of patches and counts the number thereof.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 11</figref> schematically shows the boundary of patches in the advertisement extract image <b>36</b>. In the case of <figref idref="DRAWINGS">FIG. 11</figref>, forty intersections <b>38</b> existing in the advertisement extract image <b>36</b>, that is, those not being hidden by the block <b>14</b>, are counted. The exposure indicator calculating unit <b>728</b> refers to a predetermined storage device and acquires the total number of intersecting points of the advertisement inspection image <b>28</b>, which is calculated by the image mapping unit <b>716</b> beforehand. Then, the valid display rate is calculated as the ratio of the number of intersecting points existing in the advertisement extract image <b>36</b> to the total number of the intersecting points. In the case shown in <figref idref="DRAWINGS">FIG. 11</figref>, the total number of intersecting points is forty-nine, and the number of intersections <b>38</b> in the advertisement extract image is forty. Therefore, the valid display rate is calculated to be 81.6 percent.</p>
<p id="p-0073" num="0072">Next, the exposure indicator calculating unit <b>728</b> calculates the second index based on the screen occupancy rate and the valid display rate. The format of the second index is similar to that of the first index, which is described above. The method for calculating the second index based on the screen occupancy rate and the valid display rate is also similar to that of the first index. Typically, the condition same as that for determining the first index, which is shown in <figref idref="DRAWINGS">FIG. 5</figref>, is also applicable to the calculation of the second index. However, the conditions for determining the first index may be adjusted appropriately when applied as the conditions for determining second index, based on the knowledge of a company or an experiment performed by the present system. <figref idref="DRAWINGS">FIG. 6</figref> will now again be referred to.</p>
<p id="p-0074" num="0073">The verification unit <b>730</b> cross-checks the first index acquired by the exposure indicator acquiring unit <b>722</b> and the second index calculated at the exposure indicator calculating unit <b>728</b>. If the first index and the second index are identical or if the difference between them falls within a predetermined range, the verification unit <b>730</b> determines that the exposure indicator calculating unit <b>110</b> of the game device <b>100</b> functions properly. In other words, the verification unit <b>730</b> determines that the advertisement exposure calculating function of the game application loaded to the game device <b>100</b> is implemented properly. As the predetermined range mentioned above, an appropriate range may be set based on the knowledge of a company or an experiment performed by the present system, etc. The verification unit <b>730</b> stores the results of the determination into a predetermined storage device as appropriate or notifies a predetermined external device of the results of the determination, as appropriate. For example, the determination result may be displayed on a display (not shown) of the inspection apparatus <b>700</b> or may be given as a notice to the PC terminal of the inspector.</p>
<p id="p-0075" num="0074">An explanation on the operation of the configuration described above will be given below.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 12A</figref> is a flowchart showing the operation of the game device <b>100</b> at the preparation stage for the inspection. The advertisement acquiring unit <b>104</b> acquires a dummy advertisement from the advertisement distributing apparatus <b>500</b> (S<b>10</b>). While controlling the game, the game controlling unit <b>106</b> allows, via the display controlling unit <b>108</b>, the display <b>300</b> to display a virtual space where the dummy advertisement is displayed on the advertisement region (S<b>12</b>). In this process, the capturing apparatus <b>600</b> acquires the moving image data of the virtual space displayed on the display <b>300</b>.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 12B</figref> is a flowchart showing the operation of the inspection apparatus <b>700</b> at the preparation stage for inspection. The preliminary image acquiring unit <b>712</b> acquires the moving image data of the virtual space where the dummy advertisement is displayed on the advertisement region from the capturing apparatus <b>600</b> and acquires a plurality of preliminary images on a frame by frame basis from the moving image data (S<b>20</b>). The unused color specifying unit <b>714</b> specifies colors used in the plurality of preliminary images, respectively, and then determines colors to be used for advertisement inspection image, the colors being included in the unused colors in the virtual space (S<b>22</b>). The image mapping unit <b>716</b> sets the advertisement inspection image by using the determined colors (S<b>24</b>) and transmits the advertisement inspection image to the advertisement distributing apparatus <b>500</b> (S<b>26</b>).</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. 13A</figref> is a flowchart showing the operation of the game device <b>100</b> at the execution stage of the inspection. The advertisement acquiring unit <b>104</b> acquires the advertisement inspection image from the advertisement distributing apparatus <b>500</b> (S<b>30</b>). While controlling the game, the game controlling unit <b>106</b> allows, via the display controlling unit <b>108</b>, the display <b>300</b> to display a virtual space where the advertisement inspection image is displayed on the advertisement region (S<b>32</b>). During this process, the capturing apparatus <b>600</b> acquires the moving image data of the virtual space displayed on the display <b>300</b>. The exposure indicator calculating unit <b>110</b> calculates, based on actual display data acquired from the game controlling unit <b>106</b>, the advertisement occupancy rate and the valid display rate for each frame. Then based on those, the exposure indicator calculating unit <b>110</b> calculates the first index (S<b>34</b>). The exposure indicator transmitting unit <b>112</b> transmits the calculated first index to the inspection apparatus <b>700</b> (S<b>36</b>).</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 13B</figref> is a flowchart showing the operation of the inspection apparatus <b>700</b> at the execution stage of the inspection. The exposure indicator acquiring unit <b>722</b> acquires the first index calculated in the game device <b>100</b> (S<b>40</b>). The inspection image acquiring unit <b>724</b> acquires the moving image data of the virtual space where the advertisement inspection image is displayed on the advertisement region from the capturing apparatus <b>600</b> and acquires a plurality of preliminary images on a frame by frame basis from the moving image data (S<b>42</b>). The advertisement region extracting unit <b>726</b> generates the advertisement extract image from respective images for inspection by utilizing color-filtering (S<b>44</b>). The exposure indicator calculating unit <b>728</b> calculates the advertisement occupancy rate and the valid display rate for each advertisement extract image and then calculates the second index according to those rates (S<b>46</b>). The verification unit <b>730</b> verifies the consistency of the advertisement exposure calculating function of the game application that operates on the game device <b>100</b> by cross-checking the first index and the second index (S<b>48</b>).</p>
<p id="p-0080" num="0079">By the inspection apparatus <b>700</b>, according to the present embodiment, the first index calculated in the game device <b>100</b> that operates a game application to be inspected and the second index calculated based on the actual images of the virtual space are cross-checked. This enables one to verify the consistency of the advertisement exposure calculating function of the game application without referring to the execution status of the game application even if the display status of advertisements in the virtual space varies according to the viewpoint set by a user.</p>
<p id="p-0081" num="0080">Further, by the inspection apparatus <b>700</b>, an advertisement inspection image that uses the inspection colors that are not used in the virtual space is mapped on the advertisement region in the virtual space when the game application is inspected. This enables one to specify the displayed advertisement region that is visible to a user easily and speedily by utilizing color-filtering even if the display status of advertisements in the virtual space varies according to the viewpoint set by a user.</p>
<p id="p-0082" num="0081">In addition, by the inspection apparatus <b>700</b>, a displayed advertisement region that is visible to a user is specified, and the advertisement extract image is generated, while the inspection color that is set for the advertisement inspection image and the colors having similar color attributes with that of the inspection color are identified as a same color. Some game application sets a display effect, such as a far-away landscape, in the virtual space displayed opaquely, etc. In this case, the color of the advertisement inspection image set for an advertisement space in the virtual space may be changed when the virtual space is displayed on the screen. Setting a range of colors that are identified as the inspection color helps to appropriately identify the displayed advertisement region that is visible to a user, even in case such display effects are applied.</p>
<p id="p-0083" num="0082">Further, by the inspection apparatus <b>700</b>, the advertisement images are set as a checkered pattern formed by patches rendered with one of the two inspection colors. Then, the valid display rate is calculated as the ratio of the number of intersecting points formed by the boundaries of patches in the advertisement extract image to the number of the intersecting points formed by the boundaries of patches in the advertisement inspection image. In the virtual space, the shape of the advertisement inspection image constantly varies, and a part of the image may not be displayed because of a block or the like. Thus, when calculating the valid display rate based on the inspection image, it is difficult to obtain the total number of pixels of the whole advertisement inspection image, including the part that is not displayed. In other words, even if the number of pixels of the whole advertisement image in one display status has been calculated in advance, since the shape of the advertisement inspection image changes, using the number of pixels calculated beforehand when calculating the valid display rate in accordance with the shape for each frame is sometimes not appropriate. By adopting the number of intersections as a scale for the valid display rate as in the case described above, the valid display rate similar to the valid display rate calculated in the game device <b>100</b> can be calculated by the inspection apparatus <b>700</b> based on the inspection image, even in case where the display status of the advertisement inspection image varies constantly.</p>
<p id="p-0084" num="0083">Further, by the inspection apparatus <b>700</b>, colors having adjacent attributes are adopted as the range of the two inspection colors, which are used as standards when extracting an advertisement extract image from an inspection image. As described above, in the virtual space, the color of the advertisement inspection image is sometimes changed depending on the setting of the display effect. If the attributes of colors belonging to first inspection color range and the second inspection color range differ widely, sometimes it may be difficult to specify to which area a color that is generated as a result of setting the display effect and that has attributes positioned between the first inspection color range and the second inspection color range belongs. By setting respective inspection color ranges so that the attributes thereof lie adjacent to each other, the first inspection color range and the second inspection color range can be distinguished easily. Therefore, the boundaries of the patches can be specified precisely. Further, the intersections formed by the boundaries of the patches can be specified precisely.</p>
<p id="p-0085" num="0084">The description of the invention given above is based upon an illustrative embodiment. This embodiment is intended to be illustrative only, and it will be obvious to those skilled in the art that various modifications to constituting elements and processes could be developed and that such modifications are also within the scope of the present invention.</p>
<p id="p-0086" num="0085">In the embodiment, the first inspection color range <b>25</b> is set as a group of colors that are identified to be of the same color as the first inspection color <b>24</b>, and the second inspection color range <b>27</b> is set as a group of colors that are identified to be of the same color as the second inspection color <b>26</b>. In a variation of the embodiment, the first inspection color range <b>25</b> and second inspection color range <b>27</b> may not be set. In this case, color filtering is performed only for one color, and thus the processing thereof becomes faster and easier. Particularly, this embodiment is preferable in case the color of the advertisement inspection image is not changed, for example, because the display effect is not used in the virtual space, etc.</p>
<p id="p-0087" num="0086">Although a simple checkered pattern is shown as a disposition pattern of patches used for the advertisement inspection image in the embodiment, other variations of the pattern may be adopted for disposition of patches on the advertisement inspection image. For example, on a part of the advertisement region that is assumed to be important, patches may be disposed so that the intersections are disposed with a higher concentration in that part compared to other parts.</p>
<p id="p-0088" num="0087">Although two colors are set as inspection colors to be set on the advertisement inspection image in the embodiment, only one color may be set in a variation. Particularly, this embodiment is preferable in case the valid display rate is not necessary as the basis for evaluating the second index. In yet another variation, more than two colors may be set as the inspection colors. This enables one to distinguish respective intersections, which allows one to adjust the valid display rate depending on which intersection is displayed even if the number of intersections remains the same. For example, if the intersections exist in the center part of the advertisement inspection image in the displayed screen, a higher effective display rate may be calculated as compare to the case where the intersections exist in the end part of the advertisement inspection image.</p>
<p id="p-0089" num="0088">In the embodiment, the first index and the second index that are calculated depending on the screen occupancy rate and the valid display rate are cross-checked. In a variation, the screen occupancy rate and the valid display rate calculated in the game device <b>100</b> and the screen occupancy rate and the valid display rate calculated in the inspection apparatus <b>700</b> may be directly compared. In this case, the screen occupancy rates and the valid display rates that are calculated for identical screen display times or for an identical frame ID relating to the virtual space screen <b>10</b> may be compared, respectively.</p>
<p id="p-0090" num="0089">In the embodiment, the advertisement region extracting unit <b>726</b> extracts the displayed advertisement region visible to a user by color-filtering an image of the virtual space acquired on frame by frame basis (hereinafter referred to as a &#x201c;frame unit image&#x201d;) by the inspection image acquiring unit <b>724</b>. In a variation, the inspection apparatus <b>700</b> may further comprise an image adjusting unit operative to synthesize a plurality of frame unit images acquired by the inspection image acquiring unit <b>724</b> according to a predetermined criterion and to generate a new image, which is a synthesis of a plurality of frame unit images, as an inspection image. In this case, the advertisement region extracting unit <b>726</b> color-filters the inspection image generated in the image adjusting unit and extracts an advertisement region.</p>
<p id="p-0091" num="0090">More specifically, the image adjusting unit may specify pixel values of corresponding pixels for respective frame unit images that are to be synthesized, may calculate an average pixel value, which is the average of those pixel values, and may set the average pixel value as the pixel value for that pixel in the inspection image. The corresponding pixels may be pixels displayed at the same location on the display <b>300</b>. Further, the range of the pixel values may be stored in advance, and if a pixel value deviates from the range, that pixel may be excluded from the pixels to be synthesized, for example, from the pixels to be averaged.</p>
<p id="p-0092" num="0091">According to this variation, since the frame unit images are synthesized and thus the number of the inspection images are reduced, images to be processed during a later processing, for example, the color-filtering process, the advertisement extract image generation process, or the exposure index calculation process, are reduced. This reduces the quantity of system resources that are necessary for the inspection, and fast inspection is realized. In addition, even if a display effect is applied on a part of the frame unit images, the synthesis of a plurality of frame unit images reduces the influence of the display effect, which makes it easier to properly extract the advertisement region.</p>
<p id="p-0093" num="0092">In the embodiment, an explanation on the inspection apparatus <b>700</b>, which inspects the advertisement exposure calculating function of a game application, has been given. However, the scope of the technological idea of the present invention is not limited to an inspection apparatus. For example, according to one embodiment of the present invention, an image using a color that is not used in the virtual space where display status changes according to a viewpoint set by a user is set on the region where the object to be detected is to be displayed. Then the existence of an object is detected by color-filtering the image of the virtual space that is actually displayed. It will be obvious to those skilled in the art that this technological idea is applicable not only to inspection apparatuses but also to entire image processing apparatuses. For example, in this image processing apparatus, after an object to be detected is detected, a predetermined post processing may be executed according to the position or the size in the virtual space of the object to be detected.</p>
<p id="p-0094" num="0093">Combinations of embodiments and/or variations described above may also be practiced as additional modes of the embodiments of the present invention. New embodiments generated from the combinations have both effects of combined embodiments and variations, collectively.</p>
<p id="p-0095" num="0094">It will be obvious to those skilled in the art that the functions to be fulfilled by respective constituent element described in the claims may be practiced by each constituent element by itself or in cooperation with others.</p>
<heading id="h-0007" level="1">DESCRIPTION OF THE REFERENCE NUMERALS</heading>
<p id="p-0096" num="0000">
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0095"><b>100</b> . . . game device, <b>102</b> . . . operation detector, <b>104</b> . . . advertisement acquiring unit, <b>106</b> . . . game controlling unit <b>106</b>, <b>108</b> . . . display controlling unit, <b>110</b> . . . exposure indicator calculating unit, <b>112</b> . . . exposure indicator transmitting unit, <b>700</b> . . . inspection apparatus, <b>712</b> . . . preliminary image acquiring unit, <b>714</b> . . . unused color specifying unit, <b>716</b> . . . image mapping unit, <b>722</b> . . . exposure indicator acquiring unit, <b>724</b> . . . inspection image acquiring unit, <b>726</b> . . . advertisement region extracting unit, <b>728</b> . . . exposure indicator calculating unit, <b>730</b> . . . verification unit, <b>1000</b> . . . inspection system.</li>
    </ul>
    </li>
</ul>
</p>
<heading id="h-0008" level="1">INDUSTRIAL APPLICABILITY</heading>
<p id="p-0097" num="0096">The present invention is applicable to an apparatus for identifying a region where a specific object is to be displayed, the region being included in images of a virtual space.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing apparatus for specifying a region for displaying a predetermined object from an image of a virtual space comprising:
<claim-text>an image mapping unit operative to map an image, which uses a color that is not used in the virtual space where the display status of the object varies in accordance with a viewpoint of a user, on a region where the object is to be displayed in the virtual space,</claim-text>
<claim-text>an image acquiring unit operative to acquire a virtual space that is actually displayed on a screen on a frame-by-frame basis; and</claim-text>
<claim-text>a region extracting unit operative to extract, by color-filtering the acquired image of the virtual space, a region which is rendered with a color that is not used in the virtual space, as a region for displaying the object perceived by a user.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the region extracting unit also extracts the region rendered with a color that is similar to the unused color as the region for displaying the object perceived by a user.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising:
<claim-text>an exposure rate estimating unit; wherein</claim-text>
<claim-text>the image mapping unit specifies a plurality of colors that are not used in the virtual space and maps an image that is divided into a plurality of patches rendered with the respective colors on the region for displaying the object in the virtual space;</claim-text>
<claim-text>the region extracting unit extracts a region that is rendered at least one of the plurality of unused colors as the region for displaying the object perceived by a user; and</claim-text>
<claim-text>the exposure rate estimating unit specifies patches that exist in the extracted region for displaying the object and estimates the ratio of the region for displaying the object perceived by the user to the whole region for displaying the object in accordance with the number of intersections formed by the boundaries of the patches.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The image processing apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein
<claim-text>the image mapping unit specifies a plurality of colors that are not used in the virtual space and where the attributes relating to the colors thereof are similar with each other, and maps an image divided into a plurality of patches rendered with the respective colors on the region for displaying the object in the virtual space.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising:
<claim-text>an image adjusting unit operative to generate a new image by synthesizing a plurality of images of the virtual space acquired for each frame by the image acquiring unit, in accordance with predetermined standard, wherein</claim-text>
<claim-text>the region extracting unit extracts the region for displaying the object perceived by the user by color-filtering the new image generated by the image adjusting unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A method for specifying a region for displaying a predetermined object from an image of a virtual space comprising:
<claim-text>mapping an image, which uses a color that is not used in the virtual space and where the display status of the object varies in accordance with a viewpoint of a user, on a region where the object is to be displayed in the virtual space,</claim-text>
<claim-text>acquiring a virtual space that is actually displayed on a screen of a display device on a frame-by-frame basis; and</claim-text>
<claim-text>extracting, by color-filtering the acquired image of the virtual space, the region that is rendered with the color that is not used in the virtual space, as a region for displaying the object perceived by a user.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A non-transitory, computer readable recording medium having stored thereon a program for specifying a region for displaying a predetermined object from an image of a virtual space, the program comprising:
<claim-text>a mapping module operative to map an image, which uses a color that is not used in the virtual space and where the display status of the object varies in accordance with a viewpoint of a user, on a region where the object is to be displayed in the virtual space,</claim-text>
<claim-text>an acquiring module operative to acquire a virtual space that is actually displayed on a screen on a frame-by-frame basis; and</claim-text>
<claim-text>an extracting module operative to extract, by color-filtering the acquired image of the virtual space, the region that is rendered with the color that is not used in the virtual space, as a region for displaying the object perceived by a user. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
