<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622305-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622305</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12178053</doc-number>
<date>20080723</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1106</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>19</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>23546241</main-classification>
<further-classification>235435</further-classification>
<further-classification>235439</further-classification>
</classification-national>
<invention-title id="d2e53">Efficient multi-image bar code reader</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2005/0011957</doc-number>
<kind>A1</kind>
<name>Attia et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>23546246</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2006/0022051</doc-number>
<kind>A1</kind>
<name>Patel et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>23546214</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2007/0080228</doc-number>
<kind>A1</kind>
<name>Knowles et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>23546242</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2009/0084854</doc-number>
<kind>A1</kind>
<name>Carlson et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>23546241</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>23</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>235375</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235380</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235454</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235462</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20100019042</doc-number>
<kind>A1</kind>
<date>20100128</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Barkan</last-name>
<first-name>Edward D.</first-name>
<address>
<city>Miller Place</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Barkan</last-name>
<first-name>Edward D.</first-name>
<address>
<city>Miller Place</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Fan</last-name>
<first-name>Nong-Qiang</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Symbol Technologies, Inc.</orgname>
<role>02</role>
<address>
<city>Holtsville</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lee</last-name>
<first-name>Michael G</first-name>
<department>2876</department>
</primary-examiner>
<assistant-examiner>
<last-name>Mikels</last-name>
<first-name>Matthew</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An efficient multicamera imaging-based bar code reader for imaging a target bar code on a target object. An imaging system has a plurality of camera assemblies coupled to an image processing system. Each camera assembly includes a sensor array and an imaging lens assembly for focusing a field of view of the camera assembly onto a sensor array as well as including one or more light emitting diodes for illuminating a field of view of that camera assembly. One camera is activated or energized to detect an object and then all cameras are activated for generating images suitable to decode a bar code on the detected object.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="167.22mm" wi="210.65mm" file="US08622305-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="214.63mm" wi="171.53mm" orientation="landscape" file="US08622305-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="168.99mm" wi="165.78mm" orientation="landscape" file="US08622305-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="234.02mm" wi="159.17mm" orientation="landscape" file="US08622305-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="248.24mm" wi="172.13mm" orientation="landscape" file="US08622305-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="232.16mm" wi="137.67mm" file="US08622305-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The present invention relates to a multiple camera imaging-based bar code reader.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Various electro-optical systems have been developed and used for reading optical indicia, such as bar codes. A bar code is a coded pattern of graphical indicia comprised of a series of bars and spaces of varying widths, the bars and spaces having differing light reflecting characteristics. The pattern of the bars and spaces encode information. Bar code may be one dimensional (e.g., UPC bar code) or two dimensional (e.g., DataMatrix bar code). Systems that read, that is, image and decode bar codes employing imaging camera systems are typically referred to as imaging-based bar code readers or bar code scanners.</p>
<p id="p-0004" num="0003">Imaging-based bar code readers may be portable or stationary. A portable bar code reader is one that is adapted to be held in a user's hand and moved with respect to a target indicia, such as a target bar code, to be read, that is, imaged and decoded. Stationary bar code readers are mounted in a fixed position, for example, relative to a point-of-sales counter. Target objects, e.g., a product package that includes a target bar code, are moved or swiped past one of the one or more transparent windows and thereby pass within a field of view of the stationary bar code readers. The bar code reader typically provides an audible and/or visual signal to indicate the target bar code has been successfully imaged and decoded. Sometimes barcodes are presented, as opposed to swiped. This typically happens when the swiped barcode failed to scan, so the operator tries a second time to scan it. Alternately, presentation is done by inexperience users, such as when the reader is installed in a self check out installation.</p>
<p id="p-0005" num="0004">A typical example where a stationary imaging-based bar code reader would be utilized includes a point of sale counter/cash register where customers pay for their purchases. The reader is typically enclosed in a housing that is installed in the counter and normally includes a vertically oriented transparent window and/or a horizontally oriented transparent window, either of which may be used for reading the target bar code affixed to the target object, i.e., the product or product packaging for the product having the target bar code imprinted or affixed to it. The sales person (or customer in the case of self-service check out) sequentially presents each target object's bar code either to the vertically oriented window or the horizontally oriented window, whichever is more convenient given the specific size and shape of the target object and the position of the bar code on the target object.</p>
<p id="p-0006" num="0005">A stationary imaging-based bar code reader that has a plurality of imaging cameras can be referred to as a multi-camera imaging-based scanner or bar code reader. In a multi-camera imaging reader, each camera system typically is positioned behind one of the plurality of transparent windows such that it has a different field of view from every other camera system. While the fields of view may overlap to some degree, the effective or total field of view of the reader is increased by adding additional camera systems. Hence, the desirability of multicamera readers as compared to signal camera readers which have a smaller effective field of view and require presentation of a target bar code to the reader in a very limited orientation to obtain a successful, decodable image, that is, an image of the target bar code that is decodable.</p>
<p id="p-0007" num="0006">The camera systems of a multi-camera imaging reader may be positioned within the housing and with respect to the transparent windows such that when a target object is presented to the housing for reading the target bar code on the target object, the target object is imaged by the plurality of imaging camera systems, each camera providing a different image of the target object. U.S. patent application Ser. No. 11/862,568 filed Sep. 27, 2007 entitled &#x2018;Multiple Camera Imaging Based Bar Code Reader&#x2019; is assigned to the assignee of the present invention and is incorporated herein by reference.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0008" num="0007">The present disclosure concerns a multi-camera imaging-based bar code reader and a method of operating a multicamera imaging-based bar code reader in an efficient manner.</p>
<p id="p-0009" num="0008">In some uses, a barcode reader that has multiple imagers or cameras in a single housing can provide better functionality than a reader having only a single imager. Such readers have multiple illumination systems to illuminate the fields of view of multiple imagers or cameras. For example, a system that uses six imagers will have six illumination systems, one associated with each imager.</p>
<p id="p-0010" num="0009">An illustrative multi-camera imaging-based bar code reader for imaging a target bar code on a target object has a housing supporting one or more transparent windows for viewing objects. An imaging system has a number of cameras positioned within a housing interior region that define a field of view which is different than a field of view of each other camera in the reader. Each camera includes a sensor array and its own illumination system such as one or more light emitting diodes. An image processing system includes a processor having a stored program for evaluating images from a subset of cameras that define the bar code reader field of view to determine a presence of a target object and once a target object is detected, to activate an additional one or more cameras for use in decoding a barcode.</p>
<p id="p-0011" num="0010">These and other objects, advantages, and features of the exemplary embodiment of the invention are described in detail in conjunction with the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 1</figref> is a perspective view of a bar code reader having a vertical and a horizontal window through which bar codes are viewed by multiple cameras within the reader;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 2</figref> is a perspective view of the reader of <figref idref="DRAWINGS">FIG. 1</figref> with a portion of the reader housing removed to illustrate a plurality of cameras;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. 3 and 4</figref> are perspective views showing a position of three additional cameras on a printed circuit board resulting in a total of six cameras;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic block diagram of selected systems and electrical circuitry of the bar code reader of <figref idref="DRAWINGS">FIG. 1</figref>; and</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart of an exemplary embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0017" num="0016">An exemplary embodiment of a multicamera imaging-based bar code scanner or reader <b>10</b> of the present invention is shown schematically in the Figures. As depicted in <figref idref="DRAWINGS">FIG. 7</figref>, the bar code reader <b>10</b> includes circuitry <b>11</b> comprising an image system <b>12</b> which includes a plurality of imaging cameras C<b>1</b>, C<b>2</b>, C<b>3</b>, C<b>4</b>, C<b>5</b>, C<b>6</b>, which produce raw gray scale images, and an image processing system <b>14</b>, which includes one or more processors <b>15</b> and a decoder <b>16</b> that analyzes the gray scale images from the cameras and decodes imaged target bar codes, if present. The imaging system <b>12</b> is capable of reading, that is, imaging and decoding both 1D and 2D bar codes and postal codes. The reader <b>10</b> is also capable of capturing images and signatures. The decoder <b>16</b> may be integrated into the reader <b>10</b> or may be a separate system, as would be understood by one of skill in the art.</p>
<p id="p-0018" num="0017">In one exemplary embodiment, the reader <b>10</b> is stationary and the image and decoder systems are supported within an interior region <b>18</b> of a housing <b>20</b> (see <figref idref="DRAWINGS">FIG. 1</figref>). The housing <b>20</b> may be integrated into a sales counter that of a point of sales system that includes, for example, a cash register, a touch screen visual display or other type user interface and a printer for generating sales receipts. The housing <b>20</b> depicted in <figref idref="DRAWINGS">FIG. 1</figref> includes two transparent windows H, V.</p>
<p id="p-0019" num="0018">In the exemplary embodiment, the cameras C<b>1</b>-C<b>6</b> are mounted to a printed circuit board <b>22</b> inside the housing and each camera defines a two dimensional field of view FV<b>1</b>, FV<b>2</b>, FV<b>3</b>, FV<b>4</b>, FV<b>5</b>, FV<b>6</b>. Positioned behind and adjacent to the windows H, V are reflective mirrors M that help define a given camera field of view such that the respective fields of view FV<b>1</b>-FV<b>6</b> pass from the housing <b>20</b> through the windows creating an effective total field of view TFV for the reader <b>10</b> in a region of the windows H, V, outside the housing <b>20</b>. Because each camera C<b>1</b>-C<b>6</b> has an effective working range WR (shown schematically in <figref idref="DRAWINGS">FIG. 5</figref>) over which a target bar code <b>30</b> may be successfully imaged and decoded, there is an effective target area in front of the windows H, V within which a target bar code <b>30</b> presented for reading may be successfully imaged and decoded.</p>
<p id="p-0020" num="0019">In the exemplary reader, three of the cameras C<b>4</b>-C<b>6</b>, look out of a vertical window V with the help of reflecting mirrors and three cameras C<b>1</b>-C<b>3</b> look out of a horizontal window H. In use, a user slides a package or container <b>32</b> with a barcode through a region in front of the windows. The barcode may be visible to cameras behind the vertical window, or to cameras behind the horizontal window, or both. The barcode may move through the center of the field of view of the cameras, or through one end or the other of the field of view.</p>
<p id="p-0021" num="0020">Each camera assembly C<b>1</b>-C<b>6</b> of the imaging system <b>12</b> captures a series of image frames of its respective field of view FV<b>1</b>-FV<b>6</b>. The series of image frames for each camera assembly C<b>1</b>-C<b>6</b> is shown schematically as IF<b>1</b>, IF<b>2</b>, IF<b>3</b>, IF<b>4</b>, IF<b>5</b>, IF<b>6</b> in <figref idref="DRAWINGS">FIG. 7</figref>. Each series of image frames IF<b>1</b>-IF<b>6</b> comprises a sequence of individual image frames generated by the respective cameras C<b>1</b>-C<b>6</b>. As seen in the drawings, the designation IF<b>1</b>, for example, represents multiple successive images obtained from the camera C<b>1</b>. As is conventional with imaging cameras, the image frames IF<b>1</b>-IF<b>6</b> are in the form of respective digital signals representative of raw gray scale values generated by each of the camera assembly C<b>1</b>-C<b>6</b>.</p>
<p id="p-0022" num="0021">An exemplary illumination system <b>60</b> has one or more high energy light emitting diodes L<b>1</b>-L<b>6</b> associated with each of the cameras C<b>1</b>-C<b>6</b>. These high power LEDs when simultaneously energized generate sufficient heat to raise the internal temperature of the reader <b>10</b> to an undesirable degree. Excessive heat can reduce the reliability and brightness of the LEDs, can reduce the signal quality of the image system and can also reduce the reliability of other electronic systems that are enclosed in the housing interior <b>11</b> along with the imagers and illumination systems <b>60</b>. The housing of the reader must be sealed to keep dust and other contaminants off the optical system so that the reader cannot be cooled with vents or fans that circulate external air into the housing.</p>
<p id="p-0023" num="0022">The image sensors themselves also use power and thus generate heat, adding to the bad effects heat buildup in the housing produce. Since heat cannot be easily expelled from the reader housing, it is one goal of the exemplary system to reduce heat generation within the housing. This is done without degrading the performance of the reader. In particular, bar code readers must be able to read barcodes that are moving through the total field of view TFOV with a speed of approximately 100 inches per second, regardless of the orientation of the target object with respect to the windows and regardless on what side of the object contains the bar code.</p>
<p id="p-0024" num="0023">In accordance with one use, either a sales person or a customer will present a product or target object <b>32</b> selected for purchase to the housing <b>20</b>. More particularly, a target bar code <b>30</b> imprinted or affixed to the target object will be presented in a region near the windows H, V for reading, that is, imaging and decoding of the coded indicia of the target bar code. Upon a successful reading of the target bar code, a visual and/or audible signal will be generated by the reader <b>10</b> to indicate to the user that the target bar code <b>30</b> has been successfully imaged and decoded. The successful read indication may be in the form of illumination of a light emitting diode (LED) <b>34</b><i>a </i>(<figref idref="DRAWINGS">FIG. 5</figref>) and/or generation of an audible sound by a speaker <b>34</b><i>b </i>upon generation of an appropriate signal from the decoder <b>16</b>.</p>
<p id="p-0025" num="0024">In order to reduce heat generation and power consumption, the illumination LEDs and/or image sensors S<b>1</b>-S<b>6</b> are de-energized whenever they are not needed to read barcodes. In order for the scanners performance to not be negatively impacted, however, the components must be energized very quickly as soon as a barcode, or an object that might be bearing a barcode enters the scan field. This energization must be very quick because the ability of the imagers to capture image frames is limited to around 30 or 60 frames per second, depending on what kind of image sensor is being used. A barcode can be traveling through the field so fast that the imager only has the opportunity to capture one or two images of the barcode before it passes out of the field. A delay in energizing either the illumination system or an image sensor can therefore reduce the probability that a good image (an image that contains a decodeable image of a barcode) will be captured.</p>
<p id="p-0026" num="0025">In the preferred embodiment of this invention, one of the cameras, along with its associated illumination system is used to provide an early detection of an object entering the scan field. Once an object is detected, the rest of the imagers and their illumination systems can be activated. As the object moves through the scan field, the multiple imagers capture images in sequence, as described in co-pending patent application Ser. No. 11/862,568, until such time as a decodeable image has been captured and a decode accomplished, whereupon the illumination systems and/or some of the image sensors are immediately turned off and the scanner returns to the starting condition where only one of the cameras is being used to detect an approaching object. It may also be beneficial to use more then one camera to sense an object moving into the field, to assure the full number of cameras is always enabled as soon as possible, but the essence of this invention is that a subset of the cameras is used to first detect an object and then all cameras are used to image it and decode the bar code affixed to it.</p>
<p id="p-0027" num="0026">In a typical installation of this kind of scanner, it is known which direction a barcoded object will be moving as it enters the scan field. For example, in nearly all supermarkets, the scanner will be positioned in a check-stand such that objects move from the right to the left (+x direction in <figref idref="DRAWINGS">FIG. 1</figref>) as seen when facing the vertical window of the scanner.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a bar code reader with an operator moving an object across the scanner from the right to the left. A system of mirrors directs the field of view of two of the cameras upwards at around 45 degrees through a horizontal window. Since the barcode will likely be coming into the field from the right, a camera C<b>1</b> will be the first to be able to detect the approaching object. This camera is therefore chosen as the one that is used to enable all the other cameras as soon as it has been determined that an object has entered its field of view.</p>
<p id="p-0029" num="0028">In some situations different check-stand arrangements might result in different object transport directions, so the reader is adjusted by the user to use different cameras as appropriate as an object identification camera. For example, a user might want the scanner to respond quickly to an object approaching from the left, so he/she can set-up the reader to use camera C<b>3</b> which looks upwards to the left. It will also be possible to set the scanner to use more then one camera if it isn't known which way objects might be approaching. In either case, once a barcode has been decoded, the scanner reverts to only using the specific imagers that have been designated for object detection until an object is detected. The camera that will be used for object detection can be set by scanning a special barcode or by sending appropriate instructions through the interface from the host or by plugging in an auxiliary hand held scanner to a connector provided for that purpose and scanning a barcode. The scanner can also be shipped from the factory set as the user desires, or at a factory determined default condition that is felt to be best for the majority of installations.</p>
<p id="p-0030" num="0029">To make object detection even faster, the object detecting camera(s) can capture partial frames in this object detection mode, as this allows them to capture data at a higher frame rate, so they can respond more quickly. The partial frames can be positioned towards the leading edge of the field of view (the edge of the field of view where it is expected that the object will appear first). Once an object is detected, the imager reverts to full frame (or most of the frame if it has more resolution then necessary) mode so it can read a barcode anywhere in the frame.</p>
<p id="p-0031" num="0030">To avoid accidental detection of objects that are too far away to be readable barcodes, the images collected when the camera is in sensing or object detection mode can be examined for sharp transitions between light and dark areas. Objects that are close enough to the scanner to be in the focus range of the imager optical system will have sharp edges, while those that are too far away to decode will be out of focus will have slow transitions between light and dark areas. If the slope of the transition between light and dark (or dark and light) is higher then a threshold, the scanner determines that the object is close enough to permit decoding a barcode on the object, and all of the imagers and their illumination systems are actuated until decode occurs. If decode doesn't occur after a predetermined interval (user programmable) it is decided that the scanner was falsely enabled and it returns to object detection mode. In some cases it should also be possible to program the scanner to make all the imagers remain activated for a few seconds after a barcode is decoded. This will allow it to read more than one barcode in the field if the user moves more than one object into the field at one time.</p>
<p id="p-0032" num="0031">The image processor or processors <b>15</b> controls operation of the cameras C<b>1</b>-C<b>6</b>. The cameras C<b>1</b>-C<b>6</b>, when operated during an imaging system, generate digital signals <b>35</b>. The signals <b>35</b> are raw, digitized gray scale values which correspond to a series of generated image frames for each camera. For example, for the camera C<b>1</b>, the signal <b>35</b> corresponds to digitized gray scale values corresponding to a series of image frames IF<b>1</b>. For the camera C<b>2</b>, the signal <b>35</b> corresponds to digitized gray scale values corresponding to a series of image frame IF<b>2</b>, and so on. The digital signals <b>35</b> are coupled to a bus interface <b>42</b>, where the signals are multiplexed by a multiplexer <b>43</b> and then communicated to a memory <b>44</b> in an organized fashion so that the processor knows which image representation belong to a given camera.</p>
<p id="p-0033" num="0032">The image processors <b>15</b> access the image frames IF<b>1</b>-IF<b>6</b> from memory <b>44</b> and search for image frames that include an imaged target bar code <b>30</b>&#x2032;. If the imaged target bar code <b>30</b>&#x2032; is present and decodable in one or more image frames, the decoder <b>16</b> attempts to decode the imaged target bar code <b>30</b>&#x2032; using one or more of the image frames having the imaged target bar code <b>30</b>&#x2032; or a portion thereof.</p>
<p id="p-0034" num="0033">For any individual presentation of a target bar code <b>30</b> to the reader windows H, V the exact orientation and manner of presentation of the target bar code <b>30</b> to the windows will determine which camera or cameras generate suitable images for decoding. As stated above, it is likely that, for example, sales persons generally or a given sales person, specifically, will develop a pattern of presentation of a target bar code <b>30</b> to the windows H, V that results in certain cameras having a higher probability of generating an image frame that includes the imaged target bar code <b>30</b>&#x2032; and is suitable for decoding the imaged bar code <b>30</b>&#x2032;, either alone or in conjunction with other image frames.</p>
<p id="p-0035" num="0034">Each camera includes a charged coupled device (CCD), a complementary metal oxide semiconductor (CMOS), or other imaging pixel array, operating under the control of the imaging processing system <b>40</b>. In one exemplary embodiment, the sensor array comprises a two dimensional (2D) CMOS array with a typical size of the pixel array being on the order of 752&#xd7;480 pixels. The illumination-receiving pixels of the sensor array define a sensor array surface secured to a printed circuit board for stability. The sensor array surface is substantially perpendicular to an optical axis of the imaging lens assembly, that is, a z axis that is perpendicular to the sensor array surface would be substantially parallel to the optical axis of the focusing lens. The pixels of the sensor array surface are disposed in an orthogonal arrangement of rows and columns of pixels.</p>
<p id="p-0036" num="0035">The reader circuitry <b>11</b> includes imaging system <b>12</b>, the memory <b>44</b> and a power supply <b>11</b><i>a</i>. The power supply <b>11</b><i>a </i>is electrically coupled to and provides power to the circuitry <b>11</b> of the reader. Optionally, the reader <b>10</b> may include an illumination system <b>60</b> (shown schematically in <figref idref="DRAWINGS">FIG. 7</figref>) which provides illumination to illuminate the effective total field of view to facilitate obtaining an image <b>30</b>&#x2032; of a target bar code <b>30</b> that has sufficient resolution and clarity for decoding.</p>
<p id="p-0037" num="0036">The energy savings aspects of the exemplary reader are explained in relation to the flowchart <b>110</b> of <figref idref="DRAWINGS">FIG. 6</figref>. For a subset of cameras (typically one such as the camera C<b>3</b>) an associated sensor array and light emitting diode is enabled or activated <b>120</b> during an object detection period and images (possibly of lower resolution that used in decoding) of the field of view of the camera or cameras of the subset are captured <b>122</b>. The processor <b>15</b> associated with the camera then determines <b>124</b> if a target is within the field of view of the particular camera say camera C<b>1</b>, by evaluating each image frame of the series of image frames IF<b>1</b>. If the processor determines an object is present in an image, the processor then (optionally) determines <b>126</b> if the object is within the working range of the reader.</p>
<p id="p-0038" num="0037">If an object is detected the processor <b>15</b> activates <b>130</b> all the camera assemblies C<b>1</b>-C<b>6</b> which begin to capture 132 series of image frames IF<b>1</b>-IF<b>6</b> from all six cameras. Since many of these captured frames IF<b>1</b>-IF<b>6</b> will not include an imaged target bar code <b>30</b>&#x2032;, the image processors <b>15</b> of the image processing system <b>14</b> analyze the stored image frames IF<b>1</b>-IF<b>6</b> in memory <b>44</b> to find and decode the bar code.</p>
<p id="p-0039" num="0038">The one or more processors check images <b>134</b> to determine if a successful read has occurred. A successful image decode causes the processor or processors to process that in a variety of ways such as provide a signal, transmit the bar code data and set up criteria for use by the processors in determining <b>140</b> whether to suspend decode leads to a decision step <b>140</b> where the processors determine whether to suspend imaging operation of all six cameras and put the reader back into object detection mode or try to decode more barcodes. This is based on the knowledge that a successful decode may be followed by a user swiping a number of objects in succession and therefore the need to power down a number of cameras is decreased.</p>
<p id="p-0040" num="0039">For each camera assembly C<b>1</b>-C<b>6</b>, electrical signals are generated by reading out of some or all of the pixels of the pixel array after an exposure period generating the gray scale value digital signal <b>35</b>. This occurs as follows: within each camera, the light receiving photosensor/pixels of the sensor array are charged during an exposure period. Upon reading out of the pixels of the sensor array, an analog voltage signal is generated whose magnitude corresponds to the charge of each pixel read out. The image signals <b>35</b> of each camera assembly C<b>1</b>-C<b>6</b> represents a sequence of photosensor voltage values, the magnitude of each value representing an intensity of the reflected light received by a photosensor/pixel during an exposure period.</p>
<p id="p-0041" num="0040">Processing circuitry of the camera assembly, including gain and digitizing circuitry, then digitizes and coverts the analog signal into a digital signal whose magnitude corresponds to raw gray scale values of the pixels. The series of gray scale values GSV represent successive image frames generated by the camera assembly. The digitized signal <b>35</b> comprises a sequence of digital gray scale values typically ranging from 0-255 (for an eight bit A/D converter, i.e., 2<sup>8</sup>=256), where a 0 gray scale value would represent an absence of any reflected light received by a pixel during an exposure or integration period (characterized as low pixel brightness) and a 255 gray scale value would represent a very intense level of reflected light received by a pixel during an exposure period (characterized as high pixel brightness). In some sensors, particularly CMOS sensors, all pixels of the pixel array are not exposed at the same time, thus, reading out of some pixels may coincide in time with an exposure period for some other pixels.</p>
<p id="p-0042" num="0041">As is best seen in <figref idref="DRAWINGS">FIG. 5</figref>, the digital signals <b>35</b> are received by the bus interface <b>42</b> of the image processing system <b>40</b>, which may include the multiplexer <b>43</b>, operating under the control of an ASIC <b>46</b>, to serialize the image data contained in the digital signals <b>35</b>. The digitized gray scale values of the digitized signal <b>35</b> are stored in the memory <b>44</b>. The digital values GSV constitute a digitized gray scale version of the series of image frames IF<b>1</b>-IF<b>6</b>, which for each camera assembly C<b>1</b>-C<b>6</b> and for each image frame is representative of the image projected by the imaging lens assembly onto the pixel array during an exposure period. If the field of view of the imaging lens assembly includes the target bar code <b>30</b>, then a digital gray scale value image <b>30</b>&#x2032; of the target bar code <b>30</b> would be present in the digitized image frame.</p>
<p id="p-0043" num="0042">The decoding circuitry <b>14</b> then operates on selected image frames and attempts to decode any decodable image within the image frames, e.g., the imaged target bar code <b>30</b>&#x2032;. If the decoding is successful, decoded data <b>56</b>, representative of the data/information coded in the target bar code <b>30</b> is then output via a data port <b>58</b> to an external computer which also may communicate data to the reader used in reprogramming the camera used to detect objects. A successful decode can also be displayed to a user of the reader <b>10</b> via a display output <b>59</b>. Upon achieving a good read of the target bar code <b>30</b>, that is, the bar code <b>30</b> was successfully imaged and decoded, the speaker <b>34</b><i>b </i>and/or an indicator LED <b>34</b><i>a </i>is activated by the bar code reader circuitry <b>11</b> to indicate to the user that the target bar code <b>30</b> has successfully read.</p>
<p id="p-0044" num="0043">While the present invention has been described with a degree of particularity, it is the intent that the invention includes all modifications and alterations from the disclosed design falling within the spirit or scope of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>I claim: </us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A multi-camera imaging-based bar code reader for imaging a target bar code on a target object, the bar code reader comprising:
<claim-text>a housing supporting one or more transparent windows and defining an interior region, a target object being presented in relation to the housing for imaging a target bar code;</claim-text>
<claim-text>an imaging system including a plurality of cameras wherein each camera is positioned within the housing interior region and defines a field of view which is different than a field of view of each other camera of the plurality of cameras and combine to form a bar code reader field of view, each camera including a sensor array; and</claim-text>
<claim-text>an image processing system comprising a processor having a stored program for evaluating images from a subset of cameras that define the bar code reader field of view to determine a presence of a target object and once a target object is detected, to activate an additional one or more cameras for use in decoding a barcode.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The bar code reader of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processing system determines an optimum subset of cameras for determining a presence of a target object based on a user input.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The bar code reader of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein in determining a presence of a target object based on images from the subset of cameras the image processing system evaluates partial images.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The bar code reader of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the image processing system determines if the object is within a working range of the reader.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A method of operating a multi-camera imaging-based bar code reader for imaging a target bar code comprising:
<claim-text>providing an imaging-based bar code reader including a housing supporting one or more transparent windows and defining an interior region;</claim-text>
<claim-text>positioning multiple cameras having sensor arrays within the housing interior to define different fields of view for each of said plurality of cameras to define a bar code reader field of view;</claim-text>
<claim-text>activating a subset of cameras less than a totality of cameras in said reader to detect an object moving through or occupying a position within a field of view of one or more cameras in said subset of cameras;</claim-text>
<claim-text>activating additional cameras not in said subset and obtaining images from said additional cameras to decode a bar code on said target object; and</claim-text>
<claim-text>interpreting images from the multiple cameras to decode a bar code on the target object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein before activating the additional cameras, a processor determines if the object that was sensed is moving or located within a working range of the reader.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein the subset is a single camera and wherein the single camera is chosen based on typical user tendencies in scanning objects through the reader's field of view.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein the step of activating additional cameras includes turning on an LED associated with the additional cameras as well as activating sensor arrays of said additional cameras.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> additionally comprising adjusting the subset of cameras based on varying parameters.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> additionally comprising evaluating the position of the object before activating the additional cameras.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein the step of evaluating a position of the object is performed by evaluating transitions from dark to light in the image.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein the object detection is performed on partial image frames from the subset of cameras to speed object detection.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein a leading edge of an image is used in detecting the object.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. An imaging system for use in a multi-camera imaging-based bar code reader having a housing supporting one or more transparent windows and defining an interior region, a target object being presented to the plurality of windows for imaging a target bar code on a target object, the imaging system comprising:
<claim-text>a plurality of camera assemblies coupled to an image processing system, each camera assembly of the plurality of camera assemblies being positioned within the housing interior position and defining a field of view which is different than a field of view of each other camera assembly of the plurality of camera assemblies, each camera assembly including a sensor array, an imaging lens assembly for focusing the field of view of the camera assembly onto the sensor array and an illumination device that helps define a camera field of view; and</claim-text>
<claim-text>one or more processors for evaluating images captured by one camera assembly to first determine a presence of an object within a reader field of view and then to search for decodable bar code on an object from images from other camera assemblies of said plurality of camera assemblies.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The imaging system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the one or more processors activate sensor arrays and illuminating devices for certain camera assemblies only after an object is detected in a reader field of view.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The imaging system of <claim-ref idref="CLM-00014">claim 14</claim-ref> including a communications port for communicating with other devices for reprogramming an object search routine of said one or more processors.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The imaging system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the one or more processors evaluate lower resolution images from the one camera assembly in determining a presence of an object in the reader field of view.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A multi-camera imaging-based bar code reader for imaging a target bar code on a target object, the bar code reader comprising:
<claim-text>housing means supporting a plurality of transparent windows and defining an interior region bounded in part by the plurality of windows for imaging a target bar code;</claim-text>
<claim-text>imaging means including a plurality of camera assemblies means coupled to an image processing system means wherein each camera assembly means of the plurality of camera assemblies means is positioned within the housing interior and define a field of view which is different than a field of view of each other camera assembly means of the plurality of camera assemblies means;</claim-text>
<claim-text>sensing means for each camera assembly means including a sensor array, an imaging lens assembly for focusing the field of view of the camera assembly means onto the sensor array, and an illuminating device for shining light onto a camera assembly field of view;</claim-text>
<claim-text>memory means for storing images from the sensing means;</claim-text>
<claim-text>processing means for determining a presence of an object by activating one camera assembly, evaluating images from the one camera assembly and activating additional camera assemblies once an object is detected; and</claim-text>
<claim-text>decoder means for evaluating images from a plurality of camera assemblies for determining a content of an identified bar code on a detected object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. Computer-readable media having computer-executable instructions for performing a method of operating an imaging-based bar code reader having multiple cameras for efficiently imaging a target bar code on a target object, the steps of the method comprising:
<claim-text>activating a subset of cameras less than a totality of cameras in said reader to detect a target object moving through or occupying a position within a field of view of one or more cameras in said subset of cameras;</claim-text>
<claim-text>activating additional cameras not in said subset and obtaining images from said additional cameras and storing said images in a memory; and</claim-text>
<claim-text>interpreting images from the multiple cameras in the bar code reader to decode a bar code on the target object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The computer readable medium of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein before activating the additional cameras the instructions determine if the object that was sensed is moving or located within a working range of the reader.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The computer readable medium of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein the subset is a single camera and wherein the instructions choose said single camera based on typical user tendencies in scanning objects through the reader's field of view.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The computer readable medium of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein the instructions activate additional cameras including turning on an LED associated with the additional cameras as well as activating sensor arrays of said additional cameras.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The computer readable medium of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein the instructions adjust the subset of cameras based on varying parameters. </claim-text>
</claim>
</claims>
</us-patent-grant>
