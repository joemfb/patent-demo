<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625577-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625577</doc-number>
<kind>B1</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11292231</doc-number>
<date>20051130</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1513</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>1</main-group>
<subgroup>64</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>M</subclass>
<main-group>3</main-group>
<subgroup>42</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>370352</main-classification>
<further-classification>379 75</further-classification>
<further-classification>379 85</further-classification>
<further-classification>37920701</further-classification>
<further-classification>455417</further-classification>
</classification-national>
<invention-title id="d2e53">Method and apparatus for providing audio recording</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5740543</doc-number>
<kind>A</kind>
<name>Maeda</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4555501</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6671353</doc-number>
<kind>B1</kind>
<name>Goh</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 671</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2002/0067810</doc-number>
<kind>A1</kind>
<name>Barak et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 8825</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2002/0118798</doc-number>
<kind>A1</kind>
<name>Langhart et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 671</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2004/0131161</doc-number>
<kind>A1</kind>
<name>Schwartz et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 68</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2005/0226395</doc-number>
<kind>A1</kind>
<name>Benco et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 85</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2008/0159509</doc-number>
<kind>A1</kind>
<name>Whitfield et al.</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37920201</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>9</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>370252</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370352</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37920701</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379 75</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379 35</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>379 85</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>455417</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Henderson</last-name>
<first-name>Donnie</first-name>
<address>
<city>Manalapan</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Henderson</last-name>
<first-name>Donnie</first-name>
<address>
<city>Manalapan</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>AT&#x26;T Intellectual Property II, L.P.</orgname>
<role>02</role>
<address>
<city>Atlanta</city>
<state>GA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Jensen</last-name>
<first-name>Nicholas</first-name>
<department>2468</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and apparatus for enabling a packet network based service feature to record verbal notes or other spoken (or even artificially generated audio) information on behalf of a subscriber while in a conversation are disclosed. In one embodiment, the present method allows a subscriber to effectively self-record or verbally transcribe desired portions of a conversation without the fear of privacy invasion.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="175.43mm" wi="265.18mm" file="US08625577-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="267.89mm" wi="174.41mm" orientation="landscape" file="US08625577-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="244.69mm" wi="173.65mm" orientation="landscape" file="US08625577-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="193.38mm" wi="124.54mm" file="US08625577-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="157.48mm" wi="154.69mm" file="US08625577-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">The present invention relates generally to communication networks and, more particularly, to a method and apparatus for providing conversation information recording in packet networks, e.g., Voice over Internet Protocol (VoIP) networks.</p>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Very often, a subscriber wishes to record real-time conversational information or verbal notes while in conversation with another party on the phone in a non-privacy intrusive fashion. Legally, the subscriber cannot record the conversation of the other party without permission of the other party, but sometimes the other party provides useful verbal information to the subscriber and the subscriber cannot write down the information fast enough. It will be extremely useful if the subscriber can simply repeat the given information or add any additional information verbally and save it within the network for later retrieval.</p>
<p id="p-0004" num="0003">Therefore, a need exists for a method and apparatus for enabling conversation information recording in a packet network, e.g., a VoIP network.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0005" num="0004">In one embodiment, the present invention enables a packet network based service feature, e.g., a VoIP network based service feature, to record verbal notes or other spoken (or even artificially generated audio) information on behalf of a subscriber while in a conversation. The present invention allows a subscriber to effectively self-record or verbally transcribe desired portions of a conversation without the fear of privacy invasion or legal complication associated with recording a conversation without the consent of the other party. Namely, the recording only comprises verbal notes or other spoken (or even artificially generated audio or other external or ambient audio) information of the subscriber and not the other party. Such a service feature would be extremely useful and service differentiating and can be effectively implemented in a packet network, e.g., a Voice over IP (VoIP) infrastructure.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0006" num="0005">The teaching of the present invention can be readily understood by considering the following detailed description in conjunction with the accompanying drawings, in which:</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an exemplary Voice over Internet Protocol (VoIP) network related to the present invention;</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of the network based audio notes self-recording service feature of the present invention;</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a flowchart of a method for enabling conversation information recording in a VoIP network of the present invention; and</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a high level block diagram of a general purpose computer suitable for use in performing the functions described herein.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0011" num="0010">To facilitate understanding, identical reference numerals have been used, where possible, to designate identical elements that are common to the figures.</p>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0012" num="0011">To better understand the present invention, <figref idref="DRAWINGS">FIG. 1</figref> illustrates a communication architecture <b>100</b> having an example network, e.g., a packet network such as a VoIP network related to the present invention. Exemplary packet networks include internet protocol (IP) networks, asynchronous transfer mode (ATM) networks, frame-relay networks, and the like. An IP network is broadly defined as a network that uses Internet Protocol to exchange data packets. Thus, a VoIP network or a SoIP (Service over Internet Protocol) network is considered an IP network.</p>
<p id="p-0013" num="0012">In one embodiment, the VoIP network may comprise various types of customer endpoint devices connected via various types of access networks to a carrier (a service provider) VoIP core infrastructure over an Internet Protocol/Multi-Protocol Label Switching (IP/MPLS) based core backbone network. Broadly defined, a VoIP network is a network that is capable of carrying voice signals as packetized data over an IP network. The present invention is described below in the context of an illustrative VoIP network. Thus, the present invention should not be interpreted to be limited by this particular illustrative architecture.</p>
<p id="p-0014" num="0013">The customer endpoint devices can be either Time Division Multiplexing (TDM) based or IP based. TDM based customer endpoint devices <b>122</b>, <b>123</b>, <b>134</b>, and <b>135</b> typically comprise of TDM phones or Private Branch Exchange (PBX). IP based customer endpoint devices <b>144</b> and <b>145</b> typically comprise IP phones, software phones or IP PBX. The Terminal Adaptors (TA) <b>132</b> and <b>133</b> are used to provide necessary interworking functions between TDM customer endpoint devices, such as analog phones, and packet based access network technologies, such as Digital Subscriber Loop (DSL) or Cable broadband access networks. TDM based customer endpoint devices access VoIP services by using either a Public Switched Telephone Network (PSTN) <b>120</b>, <b>121</b> or a broadband access network via a TA <b>132</b> or <b>133</b>. IP based customer endpoint devices access VoIP services by using a Local Area Network (LAN) <b>140</b> and <b>141</b> with a VoIP gateway or router <b>142</b> and <b>143</b>, respectively.</p>
<p id="p-0015" num="0014">The access networks can be either TDM or packet based. A TDM PSTN <b>120</b> or <b>121</b> is used to support TDM customer endpoint devices connected via traditional phone lines. A packet based access network, such as Frame Relay, ATM, Ethernet or IP, is used to support IP based customer endpoint devices via a customer LAN, e.g., <b>140</b> with a VoIP gateway and router <b>142</b>. A packet based access network <b>130</b> or <b>131</b>, such as DSL or Cable, when used together with a TA <b>132</b> or <b>133</b>, is used to support TDM based customer endpoint devices.</p>
<p id="p-0016" num="0015">The core VoIP infrastructure comprises of several key VoIP components, such the Border Element (BE) <b>112</b> and <b>113</b>, the Call Control Element (CCE) <b>111</b>, and VoIP related servers <b>114</b>. The BE resides at the edge of the VoIP core infrastructure and interfaces with customers endpoints over various types of access networks. A BE is typically implemented as a Media Gateway and performs signaling, media control, security, and call admission control and related functions. The CCE resides within the VoIP infrastructure and is connected to the BEs using the Session Initiation Protocol (SIP) over the underlying IP/MPLS based core backbone network <b>110</b>. The CCE is typically implemented as a Media Gateway Controller or a softswitch and performs network wide call control related functions as well as interacts with the appropriate VoIP service related servers when necessary. The CCE functions as a SIP back-to-back user agent and is a signaling endpoint for all call legs between all BEs and the CCE. The CCE may need to interact with various VoIP related servers in order to complete a call that require certain service specific features, e.g. translation of an E.164 voice network address into an IP address.</p>
<p id="p-0017" num="0016">For calls that originate or terminate in a different carrier, they can be handled through the PSTN <b>120</b> and <b>121</b> or the Partner IP Carrier <b>160</b> interconnections. For originating or terminating TDM calls, they can be handled via existing PSTN interconnections to the other carrier. For originating or terminating VoIP calls, they can be handled via the Partner IP carrier interface <b>160</b> to the other carrier.</p>
<p id="p-0018" num="0017">In order to illustrate how the different components operate to support a VoIP call, the following call scenario is used to illustrate how a VoIP call is setup between two customer endpoints. A customer using IP device <b>144</b> at location A places a call to another customer at location Z using TDM device <b>135</b>. During the call setup, a setup signaling message is sent from IP device <b>144</b>, through the LAN <b>140</b>, the VoIP Gateway/Router <b>142</b>, and the associated packet based access network, to BE <b>112</b>. BE <b>112</b> will then send a setup signaling message, such as a SIP-INVITE message if SIP is used, to CCE <b>111</b>. CCE <b>111</b> looks at the called party information and queries the necessary VoIP service related server <b>114</b> to obtain the information to complete this call. If BE <b>113</b> needs to be involved in completing the call; CCE <b>111</b> sends another call setup message, such as a SIP-INVITE message if SIP is used, to BE <b>113</b>. Upon receiving the call setup message, BE <b>113</b> forwards the call setup message, via broadband network <b>131</b>, to TA <b>133</b>. TA <b>133</b> then identifies the appropriate TDM device <b>135</b> and rings that device. Once the call is accepted at location Z by the called party, a call acknowledgement signaling message, such as a SIP-ACK message if SIP is used, is sent in the reverse direction back to the CCE <b>111</b>. After the CCE <b>111</b> receives the call acknowledgement message, it will then send a call acknowledgement signaling message, such as a SIP-ACK message if SIP is used, toward the calling party. In addition, the CCE <b>111</b> also provides the necessary information of the call to both BE <b>112</b> and BE <b>113</b> so that the call data exchange can proceed directly between BE <b>112</b> and BE <b>113</b>. The call signaling path <b>150</b> and the call media path <b>151</b> are illustratively shown in <figref idref="DRAWINGS">FIG. 1</figref>. Note that the call signaling path and the call media path are different because once a call has been setup up between two endpoints, the CCE <b>111</b> does not need to be in the data path for actual direct data exchange.</p>
<p id="p-0019" num="0018">Media Servers (MS) <b>115</b> are special servers that typically handle and terminate media streams, and to provide services such as announcements, bridges, transcoding, and Interactive Voice Response (IVR) messages for VoIP service applications.</p>
<p id="p-0020" num="0019">Note that a customer in location A using any endpoint device type with its associated access network type can communicate with another customer in location Z using any endpoint device type with its associated network type as well. For instance, a customer at location A using IP customer endpoint device <b>144</b> with packet based access network <b>140</b> can call another customer at location Z using TDM endpoint device <b>123</b> with PSTN access network <b>121</b>. The BEs <b>112</b> and <b>113</b> are responsible for the necessary signaling protocol translation, e.g., SS7 to and from SIP, and media format conversion, such as TDM voice format to and from IP based packet voice format.</p>
<p id="p-0021" num="0020">Very often, a subscriber wishes to record real-time conversational information or verbal notes while in conversation with another party on the phone in a non-privacy intrusive fashion, and in a fashion that does not interfere with the conversation substantially. Legally, the subscriber cannot record the conversation of the other party without permission of the other party, but sometimes the other party provides useful verbal information to the subscriber and the subscriber cannot write down the information fast enough. It will be extremely useful if the subscriber can simply repeat the given information or add any additional information verbally and save it within the network for later retrieval.</p>
<p id="p-0022" num="0021">To address this need, the present invention enables a packet network, e.g., a VoIP network based service feature to record verbal notes or other spoken (or even artificially generated audio) information on behalf of a subscriber while in a conversation. The present invention allows a subscriber to effectively self-record or verbally transcribe desired portions of a conversation without the fear of privacy invasion or legal complication associated with recording a conversation without the consent of the other party. Such a service feature would be extremely useful and service differentiating and can be effectively implemented in a packet network, e.g., a VoIP infrastructure.</p>
<p id="p-0023" num="0022">Consider the scenario that, while on a live call, a subscriber wants to be able to record audio notes to oneself. This allows the subscriber to capture information from another call party without actually recording the conversation of the other party. For instance, while on a call, a subscriber can use a pre-defined Dual Tone Multiple Frequency (DTMF) sequence, or some other signaling including, but is not limited to, a dedicated button or a pre-defined speech command, that causes only the subscriber's spoken input to be recorded. The present invention can be considered a specialized audio notepad type function. For instance, a subscriber has subscribed to this service feature and enabled it on the subscriber's phone service. The subscriber is on a call using a mobile phone. The other call party is about to give the subscriber driving directions. The subscriber simply keys in a pre-defined DTMF sequence or a dedicated special button on the phone. This action engages the recording function in the VoIP network for this call. In one embodiment, the subscriber's spoken input is now routed directly to a recording element, and not to the other call party. Now as the other call party speaks, the subscriber simply listens and dictates to the phone repeating the directions and adding other verbal information or other audio input as desired. The subscriber can terminate the recording via another DTMF sequence or a dedicated special button on the phone.</p>
<p id="p-0024" num="0023">After the subscriber finishes the phone call, the subscriber can call the recording element storage system using a pre-defined phone number, or other subscriber dial in feature or interface provided by the VoIP service provider to retrieve the recorded audio notes. Alternatively, the subscriber can use the Internet to login to a website that allows the subscriber to access and retrieve the recorded audio notes. Moreover, the network provider can even provide the option to the subscriber to configure an email address to which the recorded audio notes will be sent to automatically. A service might include recording statistics and resource usage information in such recording related messages sent to the subscriber.</p>
<p id="p-0025" num="0024">In an alternative embodiment, the subscriber's speech or audio notes while being recorded can also be transmitted to the other party. This implementation offers the advantage that it will maintain the two way nature of the conversation, while the recording is taking place. However, if the subscriber is also making additional audio notes, such audio notes will be heard by the other party which may not be desirable in some instances.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an example of the network based audio notes self-recording service feature of the present invention. In <figref idref="DRAWINGS">FIG. 2</figref>, a caller A (e.g., a call party), <b>201</b>, and caller Z, <b>202</b>, are engaged in an ongoing call. Call media path <b>251</b> shows the A to Z direction of the existing call connection. Call media path <b>252</b> shows the Z to A direction of the existing call connection. Caller Z is a subscriber of the network based audio notes self-recording service feature. During the conversation, caller Z would like to self-record some information provided by caller A. While caller A is providing the information, caller Z enters a pre-defined DTMF sequence <b>260</b> to activate the self-record service feature. Upon receiving the pre-defined DTMF sequence <b>260</b>, BE <b>213</b> processes the service feature activation signal and diverts the Z to A direction call media path <b>252</b> from BE <b>213</b> to Media Server/IVR (Interactive Voice Response) System <b>214</b> using the modified call media path segment <b>253</b>. In one embodiment, the call media path segment from BE <b>213</b> to Caller A, <b>201</b>, in the direction from Z to A has now been placed on hold. Media Server/IVR System <b>214</b> records the incoming audio notes (broadly defined as media information) from caller Z and stores them for later retrieval by caller Z. A Media Server (MS) is a special server that typically handles and terminates media streams, and to provide services such as announcements, bridges, transcoding, and Interactive Voice Response (IVR) messages. Because the active Z to A direction call media path has been diverted by BE <b>213</b>, the audio notes being recorded by the network cannot be heard by caller A at all; however, the A to Z direction call media path remains active and caller Z continues to hear the conversation from caller A. When caller Z finishes dictating the audio notes, caller Z enters another pre-defined DTMF sequence <b>261</b> to terminate the self-record service feature. Upon receiving the pre-defined DTMF sequence <b>261</b>, BE <b>213</b> processes the service feature termination signal and reverts the modified Z to A direction call media path to the original Z to A direction call media path <b>252</b>. After the call is finished, caller Z can call to access Media Server/IVR System <b>214</b>, or use the Internet to login to Media Server/IVR System <b>214</b> to retrieve the recorded audio notes. Caller Z also has the option to configure an email address to which recorded audio notes will be emailed by Media Server/IVR System <b>214</b> to the caller Z automatically.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a flowchart of an exemplary method for enabling conversation information recording in a packet network, e.g., a VoIP network of the present invention. Method <b>300</b> starts in step <b>305</b> and proceeds to step <b>310</b>.</p>
<p id="p-0028" num="0027">In step <b>310</b>, the method receives from the subscriber a pre-defined signal to activate the audio notes self-record feature. The pre-defined signal can be, but is not limited to, a specific DTMF sequence defined by the network provider or a specific voice command spoken by the subscriber.</p>
<p id="p-0029" num="0028">In step <b>320</b>, the method diverts the outgoing media path of the subscriber to the Media Server/IVR System. In one embodiment, the call media path is diverted by the edge component of the VoIP network associated with the subscriber's endpoint, such as a BE that serves as a VoIP network gateway or an IP gateway.</p>
<p id="p-0030" num="0029">In step <b>330</b>, the method records the audio notes from the subscriber. For example, the audio notes are recorded by a Media Server/IVR System.</p>
<p id="p-0031" num="0030">In step <b>340</b>, the method receives from the subscriber a pre-defined signal to terminate the audio notes self-record feature. The pre-defined signal can be, but is not limited to, a specific DTMF sequence defined by the network provider or a specific voice command spoken by the subscriber.</p>
<p id="p-0032" num="0031">In step <b>350</b>, the method reverts the outgoing call media path back to the original call media path to the other call party. The method ends in step <b>360</b>.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 4</figref> depicts a high level block diagram of a general purpose computer suitable for use in performing the functions described herein. As depicted in <figref idref="DRAWINGS">FIG. 4</figref>, the system <b>400</b> comprises a processor element <b>402</b> (e.g., a CPU), a memory <b>404</b>, e.g., random access memory (RAM) and/or read only memory (ROM), a Conversation Information Recording module <b>405</b>, and various input/output devices <b>406</b> (e.g., storage devices, including but not limited to, a tape drive, a floppy drive, a hard disk drive or a compact disk drive, a receiver, a transmitter, a speaker, a display, a speech synthesizer, an output port, and a user input device (such as a keyboard, a keypad, a mouse, and the like)).</p>
<p id="p-0034" num="0033">It should be noted that the present invention can be implemented in software and/or in a combination of software and hardware, e.g., using application specific integrated circuits (ASIC), a general purpose computer or any other hardware equivalents. In one embodiment, the present Conversation Information Recording module or process <b>405</b> can be loaded into memory <b>404</b> and executed by processor <b>402</b> to implement the functions as discussed above. As such, the present Conversation Information Recording process <b>405</b> (including associated data structures) of the present invention can be stored on a computer readable medium or carrier, e.g., RAM memory, magnetic or optical drive or diskette and the like.</p>
<p id="p-0035" num="0034">While various embodiments have been described above, it should be understood that they have been presented by way of example only, and not limitation. Thus, the breadth and scope of a preferred embodiment should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for recording audio information of a subscriber during a call in a communication network, comprising:
<claim-text>establishing the call between an endpoint device of the subscriber and an endpoint device of a call party, wherein the call comprises the audio information of the subscriber and audio information of the call party, wherein the call is established by a border element of the communication network, wherein the communication network comprises a service provider infrastructure;</claim-text>
<claim-text>receiving, by the border element, a first signal from the endpoint device of the subscriber to record the call, wherein the first signal is a first predefined voice command;</claim-text>
<claim-text>diverting, by the border element, a call media path in a direction from the endpoint device of the subscriber toward the communication network to a recording element within the communication network in response to receiving the first signal; and</claim-text>
<claim-text>recording, by the recording element within the communication network, only the audio information of the subscriber during the call while preventing the endpoint device of the call party from receiving the audio information of the subscriber, wherein the endpoint device of the subscriber continues to receive the audio information of the call party on the call during the recording, wherein the recording element is distinct from the endpoint device of the subscriber and from the endpoint device of the call party, wherein the recording element is an interactive voice response system, wherein the recording comprises:
<claim-text>storing the audio information from the subscriber by the recording element;</claim-text>
<claim-text>receiving a second signal from the endpoint device of the subscriber to stop recording the call, wherein the second signal is a second predefined voice command; and</claim-text>
<claim-text>reverting the call media path back to an original call media path.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the communication network is an internet protocol network.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the audio information recording is stored by the recording element indexed by a time and a date.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>forwarding the audio information that is recorded to the subscriber via an email.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A computer-readable non-transitory medium storing instructions which, when executed by a processor of a border element in a communication network, cause the processor to perform operations for recording audio information of a subscriber during a call in the communication network, the operations comprising:
<claim-text>establishing the call between an endpoint device of the subscriber and an endpoint device of a call party, wherein the call comprises the audio information of the subscriber and audio information of the call party;</claim-text>
<claim-text>receiving a first signal from the endpoint device of the subscriber to record</claim-text>
<claim-text>the call, wherein the first signal is a predefined voice command;</claim-text>
<claim-text>diverting a call media path in a direction from the endpoint device of the subscriber toward the communication network to a recording element within the communication network in response to receiving the first signal, wherein the communication network comprises a service provider infrastructure, wherein the recording element is for recording only the audio information of the subscriber during the call while preventing the endpoint device of the call party from receiving the audio information of the subscriber, wherein the endpoint device of the subscriber continues to receive the audio information of the call party on the call during the recording, wherein the recording element is distinct from the endpoint device of the subscriber and from the endpoint device of the call party, wherein the recording element is an interactive voice response system, wherein the recording comprises storing the audio information from the subscriber by the recording element;</claim-text>
<claim-text>receiving a second signal from the endpoint device of the subscriber to stop recording the call, wherein the second signal is a second predefined voice command; and</claim-text>
<claim-text>reverting the call media path back to an original call media path.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The computer-readable non-transitory medium of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the communication network is an internet protocol network.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer-readable non-transitory medium of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the audio information recording is stored by the recording element indexed by a time and a date.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer-readable non-transitory medium of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising:
<claim-text>forwarding the audio information that is recorded to the subscriber via an email.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A system for recording audio information of a subscriber during a call in a communication network, comprising:
<claim-text>a call control element for establishing the call between an endpoint device of the subscriber and an endpoint device of a call party, wherein the call comprises the audio information of the subscriber and audio information of the call party;</claim-text>
<claim-text>a border element for receiving a first signal from the endpoint device of the subscriber to record the call, wherein the first signal is a predefined voice command, and for diverting a call media path in a direction from the endpoint device of the subscriber toward the communication network to a recording element within the communication network in response to receiving the first signal, wherein the communication network comprises a service provider infrastructure; and</claim-text>
<claim-text>the recording element within the communication network for recording only the audio information of the subscriber during the call while preventing the endpoint device of the call party from receiving the audio information of the subscriber, wherein endpoint device of the subscriber continues to receive the audio information of the call party on the call during the recording, wherein the recording element is distinct from the endpoint device of the subscriber and from the endpoint device of the call party, wherein the recording element is an interactive voice response system, wherein the recording comprises:
<claim-text>storing the audio information from the subscriber by the recording element;</claim-text>
<claim-text>receiving a second signal from the endpoint device of the subscriber to stop recording the call, wherein the second signal is a second predefined voice command; and</claim-text>
<claim-text>reverting the call media path back to an original call media path. </claim-text>
</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
