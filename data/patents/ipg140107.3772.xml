<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624838-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624838</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11632505</doc-number>
<date>20050704</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2004-208065</doc-number>
<date>20040715</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>819</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>08</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>033</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345158</main-classification>
<further-classification>345156</further-classification>
</classification-national>
<invention-title id="d2e71">Electronic apparatus</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6069594</doc-number>
<kind>A</kind>
<name>Barnes et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345  7</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6313827</doc-number>
<kind>B1</kind>
<name>Honjyou</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345163</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>7145551</doc-number>
<kind>B1</kind>
<name>Bathiche et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345158</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7173604</doc-number>
<kind>B2</kind>
<name>Marvit et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7180500</doc-number>
<kind>B2</kind>
<name>Marvit et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7365737</doc-number>
<kind>B2</kind>
<name>Marvit et al.</name>
<date>20080400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2002/0140666</doc-number>
<kind>A1</kind>
<name>Bradski</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2003/0216176</doc-number>
<kind>A1</kind>
<name>Shimizu et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2005/0212759</doc-number>
<kind>A1</kind>
<name>Marvit et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2005/0212760</doc-number>
<kind>A1</kind>
<name>Marvit et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345156</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0212766</doc-number>
<kind>A1</kind>
<name>Reinhardt et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345157</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2005/0212767</doc-number>
<kind>A1</kind>
<name>Marvit et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345158</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2005/0216867</doc-number>
<kind>A1</kind>
<name>Marvit et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715863</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2007/0061301</doc-number>
<kind>A1</kind>
<name>Ramer et al.</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2007/0118533</doc-number>
<kind>A1</kind>
<name>Ramer et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2007/0290998</doc-number>
<kind>A1</kind>
<name>Choi et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345158</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2008/0014987</doc-number>
<kind>A1</kind>
<name>Kusuda et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>4555561</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2010/0123660</doc-number>
<kind>A1</kind>
<name>Park et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345157</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>GB</country>
<doc-number>2347593</doc-number>
<kind>A</kind>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>07-064754</doc-number>
<date>19950300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>09-044297</doc-number>
<date>19970200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>JP</country>
<doc-number>2000-214988</doc-number>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>JP</country>
<doc-number>2002-330210</doc-number>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>JP</country>
<doc-number>2003-334379</doc-number>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>WO</country>
<doc-number>WO 0186920</doc-number>
<kind>A2</kind>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>WO</country>
<doc-number>WO 02/41178</doc-number>
<kind>A1</kind>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>WO</country>
<doc-number>WO 2007/080413</doc-number>
<kind>A1</kind>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345156-184</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>178 1801- 2004</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>16</number-of-drawing-sheets>
<number-of-figures>16</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080254821</doc-number>
<kind>A1</kind>
<date>20081016</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kusuda</last-name>
<first-name>Hirohisa</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Nishide</last-name>
<first-name>Yasuhiro</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Tsujino</last-name>
<first-name>Daisuke</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Yamazaki</last-name>
<first-name>Jun</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Katayama</last-name>
<first-name>Takashi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Moroto</last-name>
<first-name>Mineko</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kusuda</last-name>
<first-name>Hirohisa</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Nishide</last-name>
<first-name>Yasuhiro</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Tsujino</last-name>
<first-name>Daisuke</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Yamazaki</last-name>
<first-name>Jun</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Katayama</last-name>
<first-name>Takashi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Moroto</last-name>
<first-name>Mineko</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Muirhead and Saturnelli, LLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Vodafone Group PLC</orgname>
<role>03</role>
<address>
<city>Newbury, Berkshire</city>
<country>GB</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Eisen</last-name>
<first-name>Alexander</first-name>
<department>2697</department>
</primary-examiner>
<assistant-examiner>
<last-name>Marinelli</last-name>
<first-name>Patrick F</first-name>
</assistant-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP2005/012315</doc-number>
<kind>00</kind>
<date>20050704</date>
</document-id>
<us-371c124-date>
<date>20080304</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2006/008946</doc-number>
<kind>A </kind>
<date>20060126</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An electronic apparatus includes key operation means, control means, detection means, storage means and memory means. The detection means detects motion of the electronic apparatus. The storage means stores motion identification data obtained from detection data on a motion after a predetermined key operation in the key operation means after predetermined guidance information is outputted or data obtained by computing the detection data, in the memory means. The control means executes the specific process according to the comparison results between detection data obtained by detecting a motion of the electronic apparatus after the motion identification data is stored or data obtained by computing the detection data, and the motion identification data.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="234.87mm" wi="270.09mm" file="US08624838-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="236.56mm" wi="186.86mm" orientation="landscape" file="US08624838-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="241.22mm" wi="194.82mm" orientation="landscape" file="US08624838-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="171.53mm" wi="183.64mm" file="US08624838-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="240.62mm" wi="183.64mm" orientation="landscape" file="US08624838-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="119.04mm" wi="170.94mm" file="US08624838-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="176.02mm" wi="190.92mm" file="US08624838-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="164.51mm" wi="186.86mm" file="US08624838-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="240.03mm" wi="164.85mm" file="US08624838-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="196.09mm" wi="190.92mm" file="US08624838-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="138.43mm" wi="164.85mm" file="US08624838-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="116.50mm" wi="178.65mm" file="US08624838-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="240.96mm" wi="160.36mm" file="US08624838-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="246.04mm" wi="163.24mm" file="US08624838-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="198.97mm" wi="180.42mm" file="US08624838-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="241.98mm" wi="166.03mm" file="US08624838-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="195.07mm" wi="185.59mm" file="US08624838-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to an electronic apparatus such as a mobile communication terminal, a personal digital assistance (PDA), or a game machine, etc.</p>
<heading id="h-0002" level="1">BACKGROUND ART</heading>
<p id="p-0003" num="0002">As such an electronic apparatus, there is known a small-sized information processing apparatus including attitude detection means for detecting an attitude as described in, for example, Patent Document 1. In this small-sized information processing apparatus, when a scroll start switch as key operation means is depressed, a tilt angle (tilt angle with respect to the gravity direction) of the display unit at this point in time is detected by a tilt sensor as detection means. After this detection, the tilt angle of the display unit is detected again by the tilt sensor, and from the tilt angle detected at this time, the tilt angle at the time of depressing (basic attitude data) is subtracted, thereby a relative tilt angle from the angle at the time of depressing is calculated. Then, based on this relative tilt angle, the screen of the display unit is scrolled. More specifically, by this relative tilt angle, the relative tilt direction of the display unit from the time of depressing is recognized, and a process for scrolling the display screen toward a direction corresponding to the tilt direction is performed. A process for lowering the scrolling speed of the display screen is also performed when this relative tilt angle is less than a predetermined angle (motion identification data), and increasing the scrolling speed of the display screen when the angle is not less than the predetermined angle.</p>
<p id="p-0004" num="0003">There is also known a mobile terminal having acceleration detection means for detecting acceleration as described in Patent Document 2. This mobile terminal includes means for determining whether acceleration generated when a user shakes this terminal is not less than a predetermined threshold value (motion identification data). In this Patent Document 2, a detailed example is described in which the number of times when the acceleration becomes not less than the predetermined threshold value is counted and a process for calling a phone number corresponding to the count is performed. The threshold value is a value set for distinguishing acceleration generated when a user shakes this terminal from a vibration applied when the user does not shake the terminal, for example, when the user uses a means of transportation. In the Patent Document 2, as a method for setting this threshold value, it is described that when the &#x201c;FCN&#x201d; key and &#x201c;5&#x201d; key as key operation means are depressed, the mode shifts to a mode of threshold value detection, and a value obtained by adding a maximum value of acceleration detected by the acceleration detection means in 24 hours with a value of several to 50 percent of the maximum value is used as the threshold value. This maximum value of acceleration detected in 24 hours is a maximum value of acceleration generated when the user does not shake the terminal. Therefore, by using a value obtained by adding a value of several to 50 percent of the maximum value as the threshold value, the acceleration generated when a user shakes the terminal can be distinctively recognized from the acceleration generated when the user does not shake the terminal.
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0004">Patent Document 1: Japanese Unexamined Patent Application Publication No. H07-64754</li>
    <li id="ul0001-0002" num="0005">Patent Document 2: Japanese Unexamined Patent Application Publication No. 2002-330210</li>
</ul>
</p>
<p id="p-0005" num="0006">In the small-sized information processing apparatus of the Patent Document 1, a handling method when the attitude of the entire apparatus is changed so as to tilt the display unit differs among users. Therefore, as the predetermined angle that becomes a threshold value for determining fast or slow scrolling speed of the display screen, the respective angles most suitable for the respective users are used. However, in this small-sized information processing apparatus, the predetermined angle is fixed in advance regardless of the users. Therefore, a user has trouble in operating the apparatus if the fixed angle is not suitable for him/her.</p>
<p id="p-0006" num="0007">In addition, in this small-sized information processing apparatus, when the scroll start switch is depressed, a tilt angle of the display unit at this point in time is detected to acquire basic attitude data, and at the same time, a process for scrolling the display screen of the display unit is started. In such a case where the basic attitude data acquisition timing and the start timing of the process using this basic attitude data are concurrent with each other, it becomes impossible to separately start a process using the basic attitude data after the basic attitude data is acquired. Therefore, for a user who does not want to use the attitude of the display unit at the start time of the process as the basic attitude, the basic attitude of the process is not the same as his/her desired basic attitude. As a result, operability for the process is deteriorated.</p>
<p id="p-0007" num="0008">In addition, in the mobile terminal of Patent Document 2, the magnitude of the acceleration generated when a user shakes the mobile terminal changes depending on the shaking manner and the shaking force. The shaking manner and force differ among users. Accordingly, the optimum threshold value for distinguishing the acceleration generated when a user shakes the mobile terminal and acceleration generated when the user does not shake the mobile terminal is different among users. Therefore, when the threshold value set according to the threshold value setting method described in Patent Document 2, etc., so as to enable distinction between the acceleration generated when a user shakes the mobile terminal and the acceleration generated when the user does not shake is not suitable for the user, operability for the user is low.</p>
<p id="p-0008" num="0009">The description given above concerns an example in which a process for changing a scrolling speed of a display screen and a process for calling a phone number are performed when the mobile terminal is moved so as to change in attitude or generate acceleration, however, the problem is not limited to these processes.</p>
<p id="p-0009" num="0010">Accordingly, it would be desirable to provide an electronic apparatus which can improve operability when a specific process is executed by moving the electronic apparatus by shaking or tilting it by a user.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0011">The electronic apparatus relating to the present invention includes key operation means including keys to be operated by a user; detection means for detecting motions of the electronic apparatus; memory means for memorizing motion identification data for identifying motions of the electronic apparatus; guidance information output means for outputting guidance information for urging a predetermined key operation for the key operation means and urging an operation of the electronic apparatus for generating motion of the electronic apparatus corresponding to a specific process after the predetermined key operation; storage means for storing motion identification data obtained from detection data on the motion of the electronic apparatus detected by the detection means after the predetermined key operation after the guidance information is outputted from the guidance information output means or data obtained by computing the detection data, in the memory means; and control means for executing the predetermined process according to the comparison results between the detection data obtained by detecting motion of the electronic apparatus with the detection means after the motion identification data is stored or data obtained by computing the detection data, and the motion identification data.</p>
<p id="p-0011" num="0012">First, in this electronic apparatus, guidance information is outputted for making a user perform a predetermined key operation, and operate the electronic apparatus to cause motion corresponding to the specific process after the key operation. When this motion is detected by the detection means, motion identification data obtained from the detection data or data obtained by computing the detection data (hereinafter, referred to as &#x201c;detection data, etc.&#x201d; as appropriate) are stored in the memory means. This motion identification data is for identifying a motion of the electronic apparatus for performing the specific process. This motion identification data may be the detection data, etc., itself, or may be data for identifying a range of motion of the electronic apparatus obtained based on the detection data, etc. At an arbitrary timing after this storage, when the user moves the electronic apparatus and this motion is detected by the detection means, the detection data, etc., obtained by this detection and the motion identification data are compared with each other, and according to these comparison results, the specific process is executed.</p>
<p id="p-0012" num="0013">Thereby, motion identification data obtained from the detection data, etc., on a motion suitable for a user is stored as motion identification data for identifying a motion for executing the specific process. Accordingly, a motion suitable for a user can be set as a motion for executing the specific process. Therefore, operability when the specific process is executed by shaking or tilting the electronic apparatus by a user can be improved.</p>
<p id="p-0013" num="0014">In the electronic apparatus, preferably, the guidance information output means outputs various guidance information for a plurality of specific processes that the control means can execute; the storage means performs, for the plurality of specific processes, a process for storing the motion identification data obtained from detection data on a motion of the electronic apparatus detected by the detection means after the predetermined key operation after one piece of guidance information is outputted by the guidance information output means or data obtained by computing the detection data, as motion identification data corresponding to the specific process according to the one piece of guidance information, in the memory means; and the control means compares the detection data obtained by performing the motion detection with the detection means or data obtained by computing the detection data and a plurality of motion identification data memorized in the memory means, and executes the specific process corresponding to the motion identification data including the detection data or data obtained by computing the detection data.</p>
<p id="p-0014" num="0015">In this electronic apparatus, by outputting various guidance information on a plurality of specific processes, a user is made to perform an operation of the electronic apparatus to cause motions corresponding to the respective specific processes after a predetermined key operation. The predetermined key operation for causing motions corresponding to the specific processes may be the same among the specific processes or may be different among the specific processes. The motions corresponding to the respective specific processes are detected by the detection means, and motion identification data obtained from the detection data, etc., are stored in the memory means as motion identification data corresponding to the respective specific processes. Then, when a user moves the electronic apparatus at an arbitrary timing after this storage, among the plurality of specific processes, the specific process corresponding to motion identification data including detection data, etc., relating to this motion is performed. Therefore, the plurality of specific processes can be selectively executed in response to a motion suitable for a user according to a motion difference.</p>
<p id="p-0015" num="0016">In the electronic apparatus, as the detection means, acceleration detection means for detecting acceleration generated in this electronic apparatus is preferably used. In this electronic apparatus, a user shakes or moves the electronic apparatus to generate acceleration, thereby the electronic apparatus can be made to execute the specific process.</p>
<p id="p-0016" num="0017">In the electronic apparatus, it is preferable that the acceleration detection means detects the magnitude and direction of the acceleration. In this electronic apparatus, according to the magnitude and direction of shaking the electronic apparatus or the speed and direction of moving the electronic apparatus by a user, the motions of the electronic apparatus can be detected in greater detail. Therefore, it becomes possible to prevent execution of the specific process by mistake when the user does not intend it. As a result, in order to make the electronic apparatus execute the specific process, the user is required to more accurately move the electronic apparatus, however, this motion is optimized for each user, so that the operability is not deteriorated.</p>
<p id="p-0017" num="0018">In the above-described electronic apparatus, as the detection means, attitude change detection means for detecting an attitude change of the electronic apparatus is preferably used. In this electronic apparatus, a user tilts or rotates the electronic apparatus to change the attitude of the electronic apparatus, thereby the user can make the electronic apparatus execute the specific process.</p>
<p id="p-0018" num="0019">In the electronic apparatus, as the attitude change detection means, rotation detection means for detecting a rotation angular displacement or a rotation angular velocity and a rotation direction generated in the electronic apparatus is preferably used. In this electronic apparatus, from a rotation angular displacement or rotation angular velocity and rotation direction generated when a user tilts or rotates the electronic apparatus, an attitude change of the electronic apparatus can be detected in greater detail. Therefore, this brings about an excellent effect of preventing erroneous execution of the specific process when a user does not intend it. As a result, in order to make the electronic apparatus execute the specific process, the user is required to more accurately move the electronic apparatus, however, such motion is optimized for each user, so that the operability is not deteriorated.</p>
<p id="p-0019" num="0020">Another electronic apparatus of the present invention includes key operation means having keys to be operated by a user; detection means for detecting an attitude of the electronic apparatus; basic attitude data memory means for memorizing basic attitude data for identifying a basic attitude of the electronic apparatus; storage means for storing the basic attitude data obtained from detection data on an attitude of the electronic apparatus detected by the detection means at the time of key operation on a specific key of the key operation means or data obtained by computing the detection data, in the basic attitude data memory means; and control means for executing a specific process based on differences between detection data obtained by detecting an attitude of the electronic apparatus with the detection means after the basic attitude data are stored or data obtained by computing the detection data, and the basic attitude data.</p>
<p id="p-0020" num="0021">In this electronic apparatus, when a user performs a key operation on a specific key, the attitude of the electronic apparatus at this time is detected by the detection means, and basic attitude data obtained from this detection data or data obtained by computing the detection data are stored in the basic attitude data memory means. Then, after this storage, based on differences between the detection data detected by the detection means or data obtained by computing the detection data and the basic attitude data stored in the basic attitude data memory means, the specific process is executed. Thus, according to this electronic apparatus, the specific process using basic attitude data can be performed after the basic attitude data are stored. Accordingly, a user can determine a basic attitude by operating a specific key independently from the attitude of the electronic apparatus at the start time of the specific process. Therefore, the operability of execution of the specific process by moving the electronic apparatus by shaking or moving it by a user can be improved.</p>
<p id="p-0021" num="0022">The above-described &#x201c;electronic apparatus&#x201d; includes not only a mobile communication terminal but also a Personal Digital Assistance (PDA), a game machine, etc. The above-described &#x201c;mobile communication terminal&#x201d; includes a PDC (Personal Digital Cellular) type, a GSM (Global System for Mobile Communications) type and a TIA (Telecommunication Industry Association) type mobile phone, a mobile phone standardized by IMT (International Mobile Telecommunication)-2000, a TD-SCDMA (MC: Multi Carrier) type mobile phone that is one of the TD-SCDMA (Time Division Synchronous Code Division Multiple Access) type, a PHS (Personal Handyphone System), a car phone, etc. The &#x201c;mobile communication terminal&#x201d; also includes a mobile communication terminal added with a mobile phone module. The &#x201c;electronic apparatus&#x201d; also includes an electronic apparatus without communication functions.</p>
<p id="p-0022" num="0023">Control in the electronic apparatus can also be realized by executing a predetermined program in a computer provided therein. The program to be used in this computer may be provided by using a recording medium such as an FD or CD-ROM storing the program as digital information, or may be provided by using a communication network such as a computer network.</p>
<p id="p-0023" num="0024">According to the present invention, operability of execution of the specific process by moving an electronic apparatus by shaking or tilting it by a user can be improved.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0024" num="0025"><figref idref="DRAWINGS">FIG. 1</figref> is an explanatory view for describing an entire configuration of a mobile communication system that can be utilized by a mobile phone in an embodiment according to the present invention.</p>
<p id="p-0025" num="0026"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic configuration diagram showing hardware configuration of a download server constituting the mobile communication system.</p>
<p id="p-0026" num="0027"><figref idref="DRAWINGS">FIG. 3</figref> is a front view showing an external appearance of the mobile phone.</p>
<p id="p-0027" num="0028"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic configuration diagram showing hardware configuration of the mobile phone.</p>
<p id="p-0028" num="0029"><figref idref="DRAWINGS">FIG. 5</figref> is a functional block diagram of the mobile phone.</p>
<p id="p-0029" num="0030"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram showing a main configuration of the mobile phone.</p>
<p id="p-0030" num="0031"><figref idref="DRAWINGS">FIG. 7</figref> is an explanatory view of a software structure in the mobile phone.</p>
<p id="p-0031" num="0032"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart showing a flow of process for executing an application program in the mobile phone.</p>
<p id="p-0032" num="0033"><figref idref="DRAWINGS">FIG. 9</figref> is a sequence flow diagram when the application program is executed in the mobile phone.</p>
<p id="p-0033" num="0034"><figref idref="DRAWINGS">FIG. 10A</figref> is an explanatory view of a basic attitude before the attitude of the mobile phone is changed.</p>
<p id="p-0034" num="0035"><figref idref="DRAWINGS">FIG. 10B</figref> is an explanatory view when the phone is changed in attitude by rotating it around the X-axis.</p>
<p id="p-0035" num="0036"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing a flow of initial setting process for setting a maximum pitch angle and a maximum roll angle to be used in an application program to be executed in the mobile phone.</p>
<p id="p-0036" num="0037"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing a flow of process for setting a mode selecting operation method to be performed on a menu screen when the application program is executed in the mobile phone.</p>
<p id="p-0037" num="0038"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart showing a flow of process of mode selection on the menu screen.</p>
<p id="p-0038" num="0039"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart showing a flow of process for setting a mode selecting operation method to be performed on a menu screen relating to another operation example.</p>
<p id="p-0039" num="0040"><figref idref="DRAWINGS">FIG. 15</figref> is a flowchart showing a flow of process of mode selection on the menu screen.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF VARIOUS EMBODIMENTS</heading>
<p id="p-0040" num="0041">Hereinafter, an embodiment of the present invention will be described with reference to the drawings.</p>
<p id="p-0041" num="0042"><figref idref="DRAWINGS">FIG. 1</figref> is an explanatory view for describing an entire configuration of a mobile communication system that can be utilized by mobile phones according to the present embodiment.</p>
<p id="p-0042" num="0043">In this mobile communication system, the mobile phone <b>20</b> that a user <b>1</b> uses has a configuration capable of executing an application program registered by the user <b>1</b>. In the present embodiment, this application is developed according to object-oriented programming which does not depend on a platform. As such an application program, there are available application programs written in JAVA (registered trademark, the same applies to the description below), and application programs which work in an application execution environment of BREW (registered trademark, the same applies to the description below). This mobile phone <b>20</b> is connectable to a mobile phone network <b>10</b> as a communication network. To this mobile phone network <b>10</b>, an application program download server (hereinafter, referred to as &#x201c;download server&#x201d;) <b>11</b> as a program providing server is connected. When this download server <b>11</b> accepts a download request from the mobile phone <b>20</b>, the download server <b>11</b> transmits an application program relating to this request to the mobile phone <b>20</b>.</p>
<p id="p-0043" num="0044">The application program provided from the download server <b>11</b> is provided from a developer <b>2</b> of the application program. More specifically, for example, from a personal computer, etc., on the application program developer <b>2</b> side, the application program is uploaded to the download server <b>11</b> via an exclusive line or public line and provided. It is also possible that a recording medium such as an optical disk or magnetic disk on which the developed application program has been recorded is delivered from the application program developer <b>2</b> to a communication carrier who manages and operates the download server <b>11</b> and the application program in the recording medium is read by the download server <b>11</b> and provided. The thus provided application program is registered on the download server <b>11</b> in a state that it can be downloaded into the mobile phone <b>20</b> via the mobile phone network <b>10</b>.</p>
<p id="p-0044" num="0045"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic configuration diagram showing hardware configuration of the download server <b>11</b>.</p>
<p id="p-0045" num="0046">This download server <b>11</b> includes a system bus <b>100</b>, a CPU <b>101</b>, an internal memory device, an external memory device <b>104</b>, an input device <b>105</b>, and an output device <b>106</b>. The internal memory device is comprised of a RAM <b>102</b> and a ROM <b>103</b>, etc. The external memory device is comprised of a hard disk drive (HDD) or an optical disk drive, etc. The input device <b>105</b> is comprised of the external memory device <b>104</b>, a mouse, and a keyboard, etc. The output device <b>106</b> includes a display and a printer, etc. Furthermore, this download server <b>11</b> includes a mobile phone communication device <b>107</b> for communicating with the mobile phones <b>20</b> of each user <b>1</b> via the mobile phone network <b>10</b>.</p>
<p id="p-0046" num="0047">Components such as the CPU <b>101</b> and the RAM <b>102</b> exchange data and program commands, etc., with each other via the system bus <b>100</b>. A program for operating this download server <b>11</b> according to predetermined procedures is memorized in the ROM <b>103</b> or the external memory device <b>104</b>, and it is called out to a work area on the CPU <b>101</b> and the RAM <b>102</b> and executed as appropriate. In this download server <b>11</b>, the application program to be provided to the mobile phone <b>20</b> is memorized in the external memory device <b>104</b>. The download server <b>11</b> has a function for transmitting the application program memorized in the external memory device <b>104</b> to the mobile phone <b>20</b> via the mobile phone communication network <b>10</b> by cooperation of the CPU <b>101</b>, RAM <b>102</b>, and communication device <b>107</b>, etc., for a mobile phone communication network in response to a download request from the mobile phone <b>20</b>. This download server <b>11</b> may be constructed as an exclusive control unit, or may be constructed by using a general-purpose computer system. It may be constructed by one computer, or may be constructed by connecting a plurality of computers having a plurality of functions, respectively, to each other by a network.</p>
<p id="p-0047" num="0048"><figref idref="DRAWINGS">FIG. 3</figref> is a front view showing the external appearance of the mobile phone <b>20</b>, and <figref idref="DRAWINGS">FIG. 4</figref> is a schematic configuration diagram showing hardware configuration of the mobile phone <b>20</b>.</p>
<p id="p-0048" num="0049">This mobile phone <b>20</b> is a clam shell (folding) type mobile phone, and includes an internal control device including a system bus <b>200</b>, a CPU <b>201</b>, a RAM <b>202</b>, and a ROM <b>203</b>, etc., an input device <b>204</b>, an output device <b>205</b>, a mobile phone communication device <b>206</b>, an acceleration sensor <b>207</b>, and a geomagnetic sensor <b>208</b>, etc. Components such as the CPU <b>201</b> and the RAM <b>202</b> exchange various data and program commands described later, etc., with each other via the system bus <b>200</b>. The input device <b>204</b> is comprised of data input keys (numeric keypad, * key, # key) <b>21</b>, a call start key <b>22</b>, a call termination key <b>23</b>, a scroll key <b>24</b>, a multifunction key <b>25</b>, and a microphone <b>26</b>, etc. The output device <b>205</b> is comprised of a liquid crystal display (LCD) <b>27</b> as display means that is guidance information output means, and a speaker <b>28</b>, etc. This guidance information output means including the liquid crystal display (LCD) <b>27</b>, etc., outputs guidance information for urging the key operation means <b>220</b> to perform a predetermined key operation and urging an operation of the mobile phone <b>20</b> to cause a motion of the mobile phone <b>20</b> corresponding to a specific process after the predetermined key operation. The mobile phone communication device <b>206</b> is for communicating with other mobile phones and the download server <b>11</b> via the mobile phone network <b>10</b>. The RAM <b>202</b> includes a platform memory area as first memory means to be managed by a phone platform described later and an application memory area as second memory means <b>224</b> to be managed in an application execution environment described later.</p>
<p id="p-0049" num="0050">The acceleration sensor <b>207</b> is a triaxial acceleration sensor for detecting accelerations &#x3b1;<sub>X </sub>and &#x3b1;<sub>Y </sub>in the two directions (the X-axis direction and Y-axis direction in <figref idref="DRAWINGS">FIG. 3</figref>) orthogonal to each other within a plane parallel to the operation surface on which the data input keys are provided and acceleration &#x3b1;<sub>Z </sub>in the normal line direction (the Z-axis direction in <figref idref="DRAWINGS">FIG. 3</figref>) of the plane. This acceleration sensor <b>207</b> is mounted on a circuit board that is not shown, provided inside the mobile phone <b>20</b>, and a known sensor capable of detecting the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>can be used.</p>
<p id="p-0050" num="0051">Furthermore, the geomagnetic sensor <b>208</b> is a triaxial sensor for detecting magnetic field intensity components (magnetic flux density components) of geomagnetism on a three-dimensional coordinate system consisting of the X-axis, the Y-axis, and the Z-axis. In the present embodiment, by using the detection results performed by this geomagnetic sensor <b>208</b>, the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>around the X-axis, the Y-axis, and the Z-axis are detected. More specifically, a change amount of the geomagnetic direction with respect to a reference geomagnetic direction (reference direction) is detected by using the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>around the X-axis, Y-axis, and Z-axis. Thereby, when the mobile phone changes in attitude from an attitude in which the geomagnetic direction is in the reference direction, the changed attitude can be identified from the respective angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z</sub>. In the description given below, the angle &#x3b8;<sub>X </sub>around the X-axis is referred to as a pitch angle, the angle &#x3b8;<sub>Y </sub>around the Y-axis is referred to as a roll angle, and the angle &#x3b8;<sub>Z </sub>around the Z-axis is referred to as a yaw angle. The yaw angle &#x3b8;<sub>Z </sub>referred to herein indicates an angle between a horizontal projection Y-axis on a horizontal plane of the Y-axis and the north direction. Therefore, from this yaw angle &#x3b8;<sub>Z</sub>, the direction of the horizontal projection Y-axis of the mobile phone <b>20</b> can be recognized. This geomagnetic sensor <b>208</b> is also mounted on the circuit board that is not shown, provided inside the mobile phone <b>20</b>.</p>
<p id="p-0051" num="0052">The acceleration sensor <b>207</b> and the geomagnetic sensor <b>208</b> may be constructed as devices separate from the main body of the mobile phone <b>20</b>. In this case, concerning the acceleration sensor <b>207</b> and the geomagnetic sensor <b>208</b>, an external unit including these sensors <b>207</b> and <b>208</b> is integrally connected to the main body of the mobile phone <b>20</b>, more specifically, to the liquid crystal display <b>27</b> of the mobile phone <b>20</b>.</p>
<p id="p-0052" num="0053"><figref idref="DRAWINGS">FIG. 5</figref> is a functional block diagram of the mobile phone <b>20</b> according to the present invention. <figref idref="DRAWINGS">FIG. 6</figref> is a block diagram showing the main configuration of the mobile phone <b>20</b>, and <figref idref="DRAWINGS">FIG. 7</figref> is an explanatory view of a software structure in the mobile phone <b>20</b>.</p>
<p id="p-0053" num="0054">This mobile phone <b>20</b> includes a phone communication unit <b>211</b> and a data communication unit <b>212</b> as radio communication means, an operation unit <b>213</b> as the key operation means <b>220</b>, an application program execution management unit <b>214</b> as the application program execution means, a main control unit <b>215</b>, an output unit <b>216</b>, a sensor detection unit <b>217</b> as the detection means <b>222</b>, etc.</p>
<p id="p-0054" num="0055">The phone communication unit <b>211</b> is for radio communication with base stations of the mobile phone network <b>10</b> to make phone communication with other mobile phones or fixed line phones, and corresponds to a mobile phone communication device <b>206</b>, etc., on the hardware configuration described above.</p>
<p id="p-0055" num="0056">The data communication unit <b>212</b> corresponds to the mobile phone communication device <b>206</b>, etc., on the above-described hardware configuration similarly to the phone communication unit <b>211</b>. This data communication unit <b>212</b> is for exchanging mail with other mobile phones via the mobile phone network <b>10</b> or for exchanging electronic mail or browsing web pages on the Internet by being connected to an external communication network such as the Internet via a gateway server from the mobile phone network <b>10</b>. This data communication unit <b>212</b> is also used for downloading an application program provided by the download server <b>11</b> via the mobile phone network <b>10</b>.</p>
<p id="p-0056" num="0057">The operation unit <b>213</b> is comprised of the above-described numeric keypad <b>21</b>, call start key <b>22</b>, and call termination key <b>23</b>, etc., to be operated by the user <b>1</b>. By operating various keys of the operation unit <b>213</b>, a user can input data such as a URL into the mobile phone <b>20</b>, start or terminate calling when an incoming call is received, and select, start, and stop an application program. In addition, by operating various keys of the operation unit <b>213</b>, a user can download application programs from the download server <b>11</b>.</p>
<p id="p-0057" num="0058">The application program execution management unit <b>214</b> is comprised of the above-described system bus <b>200</b>, the CPU <b>201</b>, and a part of the RAM <b>202</b>, etc. The application memory area in the RAM <b>202</b> functions as the memory means <b>224</b> for memorizing motion identification data for identifying the motion of the mobile phone <b>20</b> for making the mobile phone <b>20</b> execute a specific process. The application program execution management unit <b>214</b> functions as the storage means <b>223</b> for storing motion identification data obtained from detection data on the motion of the mobile phone <b>20</b> after the predetermined key operation detected by the detection means <b>222</b> or data obtained by computing the detection data in the memory means <b>224</b>. The application execution management unit <b>214</b> functions as the control means for executing the specific process according to the comparison results between detection data obtained by detecting the motion of the mobile phone <b>20</b> by the detection means <b>222</b> after the motion identification data is stored or data obtained by computing this detection data and the motion identification data.</p>
<p id="p-0058" num="0059">The application program execution management unit <b>214</b> corresponds to an &#x201c;application execution environment&#x201d; at the center of the software structure of <figref idref="DRAWINGS">FIG. 7</figref>, provides software such as a class library, an execution environment managing library, and application management to be used for application programs developed according to object-oriented programming, and manages an application program execution environment. This application execution environment is properly selected according to an application program to be executed. For example, when the application program to be executed is written in JAVA, the JAVA application execution environment is selected. When the application program to be executed is a program written in C language which works in a BREW execution environment, the BREW application execution environment is selected. When the application program to be executed is written in JAVA, the JAVA application execution environment is further created on the BREW application execution environment, thereby the application program can be executed.</p>
<p id="p-0059" num="0060">The application program can be used by calling class libraries of functions, etc., in the application execution environment via a class library API (application interface). The calling history of the class library of functions, etc., is memorized in an application memory area in the RAM <b>202</b> until the virtual execution environment (virtual machine: VM) of the application program is ended. Also, in the application execution environment, various data to be used for the application execution program is also stored in the application memory area. When the various data are used, they are read out from and written on this application memory area. The execution environment management library in the application execution environment can be used by calling a phone platform library in a phone platform described later via a phone platform API.</p>
<p id="p-0060" num="0061">In the present embodiment, detection data (accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z</sub>, pitch angle &#x3b8;<sub>X</sub>, roll angle &#x3b8;<sub>Y</sub>, and yaw angle &#x3b8;<sub>Z</sub>) detected by the sensor detection unit <b>217</b> described later composing the acceleration sensor <b>207</b> and the geomagnetic sensor <b>208</b>, etc., are used in the application program. In a conventional application execution environment, the means for using the detection data in the application program was not provided, so that in the present embodiment, a new class (orientation class) is added to the class library. In this orientation class, methods as command sets including getXGravity( ), getYGravity( ), and getZGravity( ) for acquiring data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>X </sub>and getPitch( ), getRoll( ), and getCompassBearing( ) for acquiring data of the pitch angle &#x3b8;<sub>X</sub>, roll angle &#x3b8;<sub>Y</sub>, an yaw angle &#x3b8;<sub>Z</sub>, etc., are prepared. Therefore, according to the present embodiment, the application program can acquire the detection data by using these methods and use the data.</p>
<p id="p-0061" num="0062">The main control unit <b>215</b> controls the phone communication unit <b>211</b>, the data communication unit <b>212</b>, the output unit <b>216</b>, and the sensor detection unit <b>217</b>, and is comprised of the above-described system bus <b>200</b>, the CPU <b>201</b>, and the RAM <b>202</b>, etc. This main control unit <b>215</b> exchanges control commands and various data with the application program execution management unit <b>214</b>, and performs controlling in cooperation with it. The main control unit <b>215</b> corresponds to the &#x201c;phone platform&#x201d; on the lowest side of the software structure of <figref idref="DRAWINGS">FIG. 7</figref>, and executes a control program for controlling the phone communication unit <b>211</b>, etc., and a user interface, and provides a phone platform library. This phone platform enables execution of various execution environment processes in the application execution environment and calling and use of software of application management in the application execution environment via the application management API. When the application execution environment calls the phone platform library via the phone platform API and uses it, the phone platform executes the process corresponding to the phone platform library. For example, the phone platform reads data memorized in a platform memory area managed by the phone platform in the RAM <b>202</b> based on an instruction from the application execution environment using the phone platform library and transfers these data into the application memory area.</p>
<p id="p-0062" num="0063">The output unit <b>216</b> is comprised of the output device <b>205</b>, etc., including the above-described liquid crystal display <b>27</b> and the speaker <b>28</b>, etc. This output unit <b>216</b> displays a web page screen received by the data communication unit <b>212</b> on the liquid crystal display <b>27</b>. The liquid crystal display <b>27</b> of this output unit <b>216</b> is used for informing a user that the phone communication unit <b>211</b> and the data communication unit <b>212</b> have received information. More specifically, when the information is received, by the main control unit <b>215</b>, a receipt informing image is displayed on the liquid crystal display <b>27</b> of the output unit <b>216</b> or a ring tone is outputted from the speaker <b>28</b>. Furthermore, this output unit <b>216</b> is also used for, during execution of an application program executed in an application execution environment, displaying a menu screen, etc., displaying a guidance screen of guidance information for explaining an operation method, and outputting music relating to the program execution.</p>
<p id="p-0063" num="0064">The sensor detection unit <b>217</b> is comprised of the acceleration sensor <b>207</b> and the geomagnetic sensor <b>208</b>, etc. This sensor detection unit <b>217</b> works under the control of the main control unit <b>215</b>, and the main control unit <b>215</b> acquires the detection data detected by the sensor detection unit. The data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>and the data of the pitch angle &#x3b8;<sub>X</sub>, roll angle &#x3b8;<sub>Y</sub>, and yaw angle &#x3b8;<sub>Z </sub>as the detection data are memorized in the platform memory area of the RAM <b>202</b> as described above. For example, when a user shakes or moves the mobile phone <b>20</b> and acceleration is generated in the mobile phone <b>20</b>, components in the X-axis direction, the Y-axis direction, and the Z-axis direction of the acceleration are detected by the acceleration sensor <b>207</b> constituting the sensor detection unit <b>217</b>. When the detection data are inputted into the main control unit <b>215</b>, the main control unit <b>215</b> can grasp the accelerations in the X-axis direction, the Y-axis direction, and the Z-axis direction from the detection data. The data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>are temporarily stored in the platform memory area in the RAM <b>202</b> by the main control unit <b>215</b>.</p>
<p id="p-0064" num="0065">When the attitude of the mobile phone <b>20</b> changes, magnetic field intensity components (magnetic flux density components) after this attitude change are detected by the geomagnetic sensor <b>208</b> constituting the sensor detection unit <b>217</b>. The sensor detection unit <b>217</b> calculates the respective angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>after change in attitude from detection signals detected by the geomagnetic sensor <b>208</b>. The data of the respective calculated angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>are outputted to the main control unit <b>215</b> and temporarily stored in the platform memory area in the RAM <b>202</b> by the main control unit <b>215</b> in the same manner as in the case of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z</sub>.</p>
<p id="p-0065" num="0066">When the orientation of the mobile phone <b>20</b> changes, magnetic field intensity components (magnetic flux density components) after this orientation change are detected by the geomagnetic sensor <b>208</b> constituting the sensor detection unit <b>217</b>. The sensor detection unit <b>217</b> calculates the yaw angle &#x3b8;<sub>Z </sub>after the orientation change from detection signals detected by the geomagnetic sensor <b>208</b>. The data of the calculated yaw angle &#x3b8;<sub>Z </sub>is also outputted to the main control unit <b>215</b> and temporarily stored in the platform memory area in the RAM <b>202</b> by the main control unit <b>215</b>.</p>
<p id="p-0066" num="0067">As a method for acquiring the data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>and the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>to be stored in the platform memory area from the sensor detection unit <b>217</b> by the main control unit <b>215</b>, the following methods are available. For example, there is an acquiring method in which the main control unit <b>215</b> sends a request to the sensor detection unit <b>217</b>, and in response thereto, the sensor detection unit <b>217</b> outputs the data and the main control unit <b>215</b> receives the data. Also, for example, an acquiring method may be employed in which data continuously outputted from the sensor detection unit <b>217</b> regardless of receiving of a request is received by the main control unit <b>215</b> as appropriate. It is also possible to employ an acquiring method in which the main control unit <b>215</b> sends a request to the sensor detection unit <b>217</b> in response to a request outputted by the application program via the application program execution management unit <b>214</b>, and in response thereto, the sensor detection unit <b>217</b> outputs data and the main control unit <b>215</b> receives the data.</p>
<p id="p-0067" num="0068">A control program for creating a phone platform to operate the mobile phone <b>20</b> according to predetermined procedures is memorized in the RAM <b>202</b> and ROM <b>203</b>. The basic OS (operating system) programs, programs for creating the application execution environment, and application programs are also memorized in the RAM <b>202</b> and the ROM <b>203</b>. These programs are called out to a work area in the CPU <b>201</b> and RAM <b>202</b> and executed as appropriate.</p>
<p id="p-0068" num="0069">Next, operations for executing an application program using the data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>and the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>will be described. In the present embodiment, this application program is a flight simulator as a game.</p>
<p id="p-0069" num="0070"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart showing a flow of process for executing an application program for the flight simulator. <figref idref="DRAWINGS">FIG. 9</figref> is a sequence flow diagram when the application program for the flight simulator is executed.</p>
<p id="p-0070" num="0071">First, the user <b>1</b> acquires the application program for the flight simulator by downloading from the download server <b>11</b>, and registers the application program (S<b>1</b>). More specifically, the user <b>1</b> accesses the download server <b>11</b> by operating the keys of the operation unit <b>213</b>. Thereby, a download selection screen for selecting a downloadable application program is displayed on the liquid crystal display <b>27</b>. In this download selection screen, the application program to be executed is selected by using the scroll key <b>24</b>, and by depressing the multifunction key <b>25</b>, the main control unit <b>215</b> controls the data communication unit <b>212</b> and downloads the application program from the download server <b>11</b>. The thus downloaded application program is memorized in the RAM <b>102</b> by the main control unit <b>215</b>.</p>
<p id="p-0071" num="0072">In order to execute the downloaded application program, the user <b>1</b> makes the liquid crystal display <b>27</b> display an application selection screen for selecting the application program to be executed by operating the keys of the operation unit <b>213</b>. Then, in this application selection screen, the user selects the application program for the flight simulator to be executed by using the scroll key <b>24</b> and depresses the multifunction key <b>25</b>. Then, in the phone platform shown in <figref idref="DRAWINGS">FIG. 7</figref>, that is, in the main control unit <b>215</b> shown in <figref idref="DRAWINGS">FIG. 6</figref>, an application program execution instruction is inputted (S<b>2</b>). Thereby, the main control unit <b>215</b> reads out the application program for the flight simulator and starts the application program (S<b>3</b>). When the application program starts, in the application execution environment shown in <figref idref="DRAWINGS">FIG. 7</figref>, that is, on the application program execution management unit <b>214</b> shown in <figref idref="DRAWINGS">FIG. 6</figref>, the application program works.</p>
<p id="p-0072" num="0073">When this program starts, first, a menu screen is displayed on the liquid crystal display <b>27</b> (S<b>4</b>). This menu screen is a screen for selecting either one of the game mode and the setting mode described later. When the user <b>1</b> selects the setting mode described later by operating the scroll key <b>24</b> of the operation unit <b>213</b> or moving the mobile phone as set by execution of the setting mode of the second operation example 2 described later (S<b>5</b>), an initial setting process is performed (S<b>20</b>). Details of this initial setting process will be described later.</p>
<p id="p-0073" num="0074">On the other hand, when the user <b>1</b> starts the game, he/she selects a game mode by operating the scroll key <b>24</b> of the operation unit <b>213</b> or moving the mobile phone as set by execution of the setting mode described later (S<b>5</b>). Thereby, on the liquid crystal display <b>27</b> of the output unit <b>216</b>, guidance information about setting of the basic attitude is displayed (S<b>6</b>). This guidance information is indicated as a message such as &#x201c;determine the way of holding the mobile phone when playing the game and depress the multifunction key.&#x201d; Concerning output of this guidance information, along with or instead of the indication on the liquid crystal display <b>27</b>, guidance may be given by voice by using an external speaker, etc., of the output unit <b>216</b>. The contents of the guidance information may be described in a user's manual, etc., and outputting of the guidance information may be omitted. The user <b>1</b> guided by this guidance information holds the mobile phone in the way which makes it easy to play the game, for example, enables the mobile phone to take the attitude shown in <figref idref="DRAWINGS">FIG. 10A</figref>, and then depresses the multifunction key <b>25</b> as a specific key (S<b>7</b>). Then, the application program execution management unit <b>214</b> functions as the storage means <b>223</b> and stores angle data &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>acquired by the application program when the key was depressed as basic attitude data &#x3b8;<sub>X0</sub>, &#x3b8;<sub>Y0</sub>, and &#x3b8;<sub>Z0 </sub>in the application memory area (basic attitude data memory means <b>224</b>) in the RAM <b>202</b> (S<b>8</b>, S<b>9</b>). Based on the basic attitude data, the attitude (basic attitude) of the mobile phone <b>20</b> when the multifunction key is depressed can be recognized.</p>
<p id="p-0074" num="0075">Thereafter, when the user <b>1</b> performs a key operation for staring the game (S<b>10</b>), the game is started. Thereby, on the liquid crystal display <b>27</b> of the output unit <b>216</b>, a game screen imitating the field of view from a pilot's seat of an airplane is displayed. Then, the application program starts an angle data acquisition process for acquiring data of the pitch angle &#x3b8;<sub>X</sub>, roll angle &#x3b8;<sub>Y</sub>, and yaw angle &#x3b8;<sub>Z </sub>to be detected by the sensor detection unit <b>217</b> substantially in real time. The program updates the contents of the game screen displayed on the liquid crystal display <b>27</b> according to the acquired data. For example, when the user <b>1</b> tilts the antenna side of the mobile phone <b>20</b> vertically downward, the pitch angle &#x3b8;<sub>X </sub>changes accordingly, and the game screen is updated to a game screen for which the nose of the airplane in the game tilts vertically downward. For example, when the user <b>1</b> tilts the display surface of the liquid crystal display <b>27</b> of the mobile phone <b>20</b> to the left, the roll angle &#x3b8;<sub>Y </sub>changes accordingly, and the game screen is updated to a game screen for which the airplane in the game tilts to the left.</p>
<p id="p-0075" num="0076">More specifically, for example, when the user <b>1</b> tilts the mobile phone <b>20</b> toward the direction shown by the arrow A in <figref idref="DRAWINGS">FIG. 10A</figref> so as to turn the nose of the airplane in the game vertically downward, the mobile phone <b>20</b> takes the attitude shown in <figref idref="DRAWINGS">FIG. 10B</figref>. The attitude after this attitude change is detected by the geomagnetic sensor <b>208</b> of the sensor detection unit <b>217</b>, and the data of the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>are delivered to the application program (S<b>11</b>). Thereby, the application program execution management unit <b>214</b> updates the game screen information for displaying a game screen on the liquid crystal display <b>27</b> according to the contents of the application program (S<b>12</b>). For example, when the attitude of the mobile phone <b>20</b> is changed from the basic attitude of <figref idref="DRAWINGS">FIG. 10A</figref> to the attitude shown in <figref idref="DRAWINGS">FIG. 10B</figref>, the game screen imitating the field of view from a pilot's seat of an airplane is scrolled to the upper side of the screen, and the game screen information is updated as if the nose of the airplane in the game turned vertically downward. Thereafter, a process for drawing the updated game screen on the display surface of the liquid crystal display <b>27</b> is executed (S<b>13</b>). By thus performing updating of the game screen information based on an attitude change from the basic attitude, regardless of the attitude of the mobile phone when the user <b>1</b> plays the game, proper updating can be performed.</p>
<p id="p-0076" num="0077">In the angle data acquisition process, as shown in <figref idref="DRAWINGS">FIG. 9</figref>, the started application program sends an angle data acquisition request to the application program execution management unit <b>214</b> in the application execution environment. The application program execution management unit <b>214</b> that received the request sends an angle data acquisition request as a data transfer command to the main control unit <b>215</b> of the phone platform. The main control unit <b>215</b> that received the request sends the data of the pitch angle &#x3b8;<sub>X</sub>, the roll angle &#x3b8;<sub>Y</sub>, and the yaw angle &#x3b8;<sub>Z </sub>memorized in the platform memory area in the RAM <b>202</b> to the application program execution management unit <b>214</b>, and these data are delivered to the application program. Then, the application program which received the data of the pitch angle &#x3b8;<sub>X</sub>, the roll angle &#x3b8;<sub>Y</sub>, and the yaw angle &#x3b8;<sub>Z </sub>memorizes the data in the application memory area in the RAM <b>202</b>. Then, it updates the game screen information to be outputted to the output unit <b>216</b> based on the pitch angle &#x3b8;<sub>X</sub>, the roll angle &#x3b8;<sub>Y</sub>, and the yaw angle &#x3b8;<sub>Z</sub>.</p>
<p id="p-0077" num="0078">Details of the updating of the game screen information are as follows.</p>
<p id="p-0078" num="0079">The application program execution management unit <b>214</b> which executes the application program calculates differences between the data of the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>acquired at S<b>9</b> described above and the basic attitude data &#x3b8;<sub>X0</sub>, &#x3b8;<sub>Y0</sub>, and &#x3b8;<sub>Z0 </sub>memorized in the application memory area. Herein, for example, it is assumed that the mobile phone <b>20</b> has been changed from the basic attitude of <figref idref="DRAWINGS">FIG. 10A</figref> to the attitude of <figref idref="DRAWINGS">FIG. 10B</figref>. In this case, only the pitch angle &#x3b8;<sub>X </sub>changes from the basic attitude. By calculating a difference between the data of the pitch angle &#x3b8;<sub>X </sub>at this time and the basic attitude data &#x3b8;<sub>X0</sub>, the rotation angle (rotation angular displacement) of the Y-axis of the mobile phone <b>20</b> to the minus direction (rotation direction) around the X-axis from the basic attitude shown in <figref idref="DRAWINGS">FIG. 10A</figref> can be recognized. Then, according to the recognized rotation direction and rotation angular displacement, the application program execution management unit <b>214</b> updates the game screen information as if the nose of the airplane in the game turned vertically downward by scrolling the game screen imitating the field of view from a pilot's seat of an airplane to the upper side of the screen.</p>
<heading id="h-0006" level="1">First Operation Example</heading>
<p id="p-0079" num="0080">Next, an initial setting process as a feature of the present invention will be described.</p>
<p id="p-0080" num="0081"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing a flow of process for setting a maximum pitch angle and a maximum roll angle in the initial setting process to be performed when the user <b>1</b> selects the setting mode on the menu screen. Herein, setting of a maximum pitch angle means setting of a pitch angle &#x3b8;<sub>X </sub>corresponding to a maximum pitch angle for controlling an airplane in the game. Setting of a maximum roll angle means setting of a roll angle &#x3b8;<sub>Y </sub>corresponding to a maximum roll angle for controlling the airplane in the game. In the present embodiment, yaw angle data is not used for controlling the airplane in the game, so that setting of a maximum yaw angle is not performed.</p>
<p id="p-0081" num="0082">On a setting mode selection screen displayed according to selection of the setting mode on the menu screen by the user <b>1</b>, when the user <b>1</b> selects the setting mode for the maximum pitch angle and the maximum roll angle, guidance information about setting of the maximum pitch angle is displayed on the liquid crystal display <b>27</b> of the output unit <b>216</b> (S<b>21</b>). This guidance information is indicated as a message such as &#x201c;after depressing the multifunction key, tilt the mobile phone so as to move the antenna to the deeper side to an angle as a maximum pitch angle for controlling the airplane in the game, and then depress the multifunction key again.&#x201d; Concerning the outputting of this guidance information, along with or instead of the indication on the liquid crystal display <b>27</b>, the guidance information may be given by voice by using an external speaker, etc., of the output unit <b>216</b>. The same applies to the guidance information described later. When the user <b>1</b> guided by this guidance information depresses the multifunction key (S<b>22</b>), the application program starts an angle data acquisition process for acquiring data of the pitch angle &#x3b8;<sub>X </sub>detected by the sensor detection unit <b>217</b> substantially in real time (S<b>23</b>). Then, the user <b>1</b> gradually tilts the mobile phone <b>20</b>, and when its pitch angle &#x3b8;<sub>X </sub>reaches his/her preferred angle that becomes a maximum pitch angle for controlling the airplane in the game, the user depresses the multifunction key. Thereby, the application program execution management unit <b>214</b> functions as the storage means <b>223</b> and stores the data of the pitch angle &#x3b8;<sub>X </sub>at this point in time of depressing as maximum pitch angle reference data &#x3b8;<sub>Xmax </sub>that are motion identification data in the reference data memory area (memory means <b>224</b>) in the application memory area in the RAM <b>202</b> (S<b>24</b>).</p>
<p id="p-0082" num="0083">When the maximum pitch angle setting process is thus finished, setting of the maximum roll angle is subsequently performed. More specifically, when the storage process of S<b>24</b> is finished, guidance information about setting of the maximum roll angle is displayed on the liquid crystal display <b>27</b> of the output unit <b>216</b> (S<b>25</b>). This guidance information is indicated as a message such as &#x201c;after depressing the multifunction key, tilt the mobile phone around the vertical axis (Y-axis) on the key operation surface as a rotation axis to an angle as a maximum roll angle for controlling the airplane in the game, and depress the multifunction key again.&#x201d; When the user <b>1</b> guided by this guidance information depresses the multifunction key (S<b>26</b>), the application program starts an angle data acquisition process for acquiring data of the roll angle &#x3b8;<sub>Y </sub>detected by the sensor detection unit <b>217</b> substantially in real time (S<b>27</b>). Then, the user <b>1</b> gradually tilts the mobile phone <b>20</b>, and when its pitch angle &#x3b8;<sub>Y </sub>reaches his/her preferred angle that becomes a maximum roll angle for controlling the airplane in the game, the user depresses the multifunction key. Thereby, the application program execution management unit <b>214</b> functions as the storage means <b>222</b> and stores the data of the roll angle &#x3b8;<sub>Y </sub>at the point in time of depressing as maximum roll angle reference data &#x3b8;<sub>Imax </sub>that are motion identification data in the reference data memory area in the application memory area in the RAM <b>202</b> (S<b>28</b>).</p>
<p id="p-0083" num="0084">After the initial setting process of the maximum pitch angle and the maximum roll angle is thus finished, the user <b>1</b> starts the game. In game screen information updating during this game, first, the application program execution management unit <b>214</b> calculates differences between the data of the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>acquired at S<b>9</b> described above and the basic attitude data &#x3b8;<sub>X0</sub>, &#x3b8;<sub>Y0</sub>, and &#x3b8;<sub>Z0 </sub>memorized in the reference data memory area. Herein, for example, when the mobile phone <b>20</b> is changed from the basic attitude of <figref idref="DRAWINGS">FIG. 10A</figref> to the attitude of <figref idref="DRAWINGS">FIG. 10B</figref>, difference data between the data of the pitch angle &#x3b8;<sub>X </sub>at this time and the basic attitude data &#x3b8;<sub>X0 </sub>is calculated. Thereby, the rotation angle (rotation angular displacement) of the Y-axis of the mobile phone <b>20</b> to the minus direction (rotation direction) around the X-axis from the basic attitude shown in <figref idref="DRAWINGS">FIG. 10A</figref> can be recognized. Then, the application program execution management unit <b>214</b> functions as the control means <b>221</b> and calculates a value by dividing an absolute value of the calculated difference data by the maximum pitch angle reference data &#x3b8;<sub>Xmax </sub>memorized in the reference data memory area. This calculated value indicates what percent of the maximum pitch angle the Y-axis of the mobile phone <b>20</b> rotated around the X-axis from the basic attitude shown in <figref idref="DRAWINGS">FIG. 10A</figref>. Thereafter, the application program execution management unit <b>214</b> performs a process (specific process) for updating the game screen information corresponding to the calculated value and the recognized rotation direction.</p>
<p id="p-0084" num="0085">As the calculated value becomes larger, the change in pitch angle of the airplane in the game becomes greater, and as the calculated value becomes smaller, the change in pitch angle of the airplane in the game becomes smaller. Therefore, a user who wants to sensitively control the airplane in the game can set the maximum pitch angle reference data &#x3b8;<sub>Xmax </sub>to a large value at the time of initial setting process of the maximum pitch angle. In this case, if the pitch angle &#x3b8;<sub>X </sub>when the mobile phone <b>20</b> changes in attitude is the same, the calculated value becomes smaller than in the case where the maximum pitch angle reference data &#x3b8;<sub>Xmax </sub>is small, and the change in pitch angle of the airplane in the game becomes smaller. Therefore, it becomes possible to finely change the pitch angle of the airplane in the game, and sensitive control becomes possible.</p>
<p id="p-0085" num="0086">Not only the rotation angular displacement but also the rotation angular velocity may be reflected in the control of the airplane in the game. For example, if the mobile phone <b>20</b> is suddenly changed in attitude, the rotation angular velocity of the pitch angle &#x3b8;<sub>X </sub>becomes great. In this case, it is regarded that the pitch angle of the airplane in the game has also been suddenly changed and this can be reflected in the game contents. As the rotation angular velocity, for example, concerning the pitch angle &#x3b8;<sub>X</sub>, a value obtained by dividing the acquired pitch angle &#x3b8;<sub>X </sub>by the acquisition time period can be used.</p>
<p id="p-0086" num="0087">In the above description, the pitch angle &#x3b8;<sub>X </sub>is described, however, the same effect can also be obtained for the roll angle &#x3b8;<sub>Y</sub>.</p>
<heading id="h-0007" level="1">Second Operation Example</heading>
<p id="p-0087" num="0088">Next, in the initial setting process which is performed when the user selects the setting mode on the menu screen, a process for setting an operation method of mode selection will be described. This process is for setting an operation method for selecting either the game mode or the setting mode on the menu screen according to the preference of the user <b>1</b>.</p>
<p id="p-0088" num="0089"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing a flow of the process for setting an operation method of mode selection. On a setting mode selection screen displayed when the user <b>1</b> selects the setting mode on the menu screen, when the user <b>1</b> selects an operation method setting mode of mode selection, guidance information about setting of a cursor moving operation is displayed on the liquid crystal display <b>27</b> of the output unit <b>216</b> (S<b>31</b>). This guidance information is indicated as a message such as &#x201c;after depressing the multifunction key, act to move the cursor on the menu screen.&#x201d; When the user <b>1</b> who was guided by this guidance information depresses the multifunction key (S<b>32</b>), the application program starts an acceleration data acquisition process for acquiring data of accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>detected by the sensor detection unit <b>217</b> substantially in real time (S<b>33</b>). Then, the user <b>1</b> moves the mobile phone <b>20</b> in his/her preferred direction with his/her preferred force. Thereby, the application program execution management unit <b>214</b> acquires maximum values of absolute values of the data of the respective accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>until the accelerations become zero since generation of the accelerations in the mobile phone <b>20</b>. Then, the application program execution management unit <b>214</b> functions as the storage means <b>222</b> and stores the data for identifying predetermined magnitude ranges around the maximum values of the acquired accelerations and predetermined angle ranges around the directions of the accelerations (hereinafter, these ranges are referred to as &#x201c;acceleration ranges&#x201d;) as cursor movement reference data that are motion identification data in the reference data memory area (memory means <b>224</b>) of the application memory area in the RAM <b>202</b> (S<b>34</b>).</p>
<p id="p-0089" num="0090">When the cursor moving operation setting process is thus finished, a selection determining operation setting process is subsequently performed. More specifically, when the storage process of S<b>34</b> is finished, guidance information about setting of a selection determining operation is displayed on the liquid crystal display <b>27</b> of the output unit <b>216</b> (S<b>35</b>). This guidance information is indicated as a message such as &#x201c;after depressing the multifunction key, act to determine the selection of the cursor on the menu screen. However, act differently from the action for moving the cursor on the menu screen.&#x201d; When the user guided by this guidance information depresses the multifunction key (S<b>36</b>), the application program starts an acceleration data acquisition process for acquiring data of accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>detected by the sensor detection unit <b>217</b> substantially in real time (S<b>37</b>). Then, the user <b>1</b> moves the mobile phone <b>20</b> in a direction with a force according to his/her preference differently from those in the motion set for the cursor moving operation. Thereby, the application program execution management unit <b>214</b> acquires maximum vales of absolute values of the data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>until the accelerations become zero since generation of the accelerations in the mobile phone. Then, the application program execution management unit <b>214</b> functions as the storage means <b>222</b> and stores data for identifying acceleration ranges of the acquired accelerations as selection determining reference data that are motion identification data in the reference data memory area (memory means <b>224</b>) (S<b>38</b>).</p>
<p id="p-0090" num="0091"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart showing a flow of process of mode selection on the menu screen.</p>
<p id="p-0091" num="0092">After the initial setting process for the mode selection operation method is finished, mode selection is performed on the menu screen displayed on the liquid crystal display <b>27</b>. In this case, the user <b>1</b> acts as set in the mode selection operation method setting process to move the cursor on the menu screen or determine the mode selected by the cursor. More specifically, when the menu screen is displayed on the liquid crystal display <b>27</b> (S<b>41</b>), if the user <b>1</b> moves the mobile phone <b>20</b>, accelerations are detected by the acceleration sensor <b>207</b> of the sensor detection unit <b>217</b>, and the data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>are delivered to the application program (S<b>42</b>). The application program execution management unit <b>214</b> functions as the control means <b>221</b> and determines whether the data of the acquired accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>are included in the acceleration ranges identified from the cursor movement reference data memorized in the reference data memory area (S<b>43</b>). When it is determined at S<b>43</b> that the data are included, the application program execution management unit <b>214</b> performs a cursor movement process (specific process) (S<b>44</b>). More specifically, a process for moving the position of the cursor image displayed on the menu screen to the position of the next mode is performed. On the other hand, when it is determined at S<b>43</b> that the data are not included, the application program execution management unit <b>214</b> determines whether the data of the acquired accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>are included in acceleration ranges identified from the selection determining reference data memorized in the reference data memory area (S<b>45</b>). When it is determined at S<b>45</b> that the data are included, the application program execution management unit <b>214</b> performs a process for shifting to the mode selected by the cursor on the menu screen (specific process) (S<b>46</b>). More specifically, when the cursor selects the game mode, the above-described game is started, and when the cursor selects the setting mode, the above-described setting mode is started.</p>
<p id="p-0092" num="0093">In the above description, the case where cursor movement and selection determination are performed by using the data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>is described, however, these can also be performed by using the data of the respective angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z</sub>.</p>
<p id="p-0093" num="0094"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart showing a flow of process for setting an operation method of mode selection by using the data of the respective angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z</sub>. On the setting mode selection screen displayed when the user <b>1</b> selects the setting mode on the menu screen, when the user <b>1</b> selects the mode selection operation method setting mode, guidance information about setting of the cursor moving operation is displayed on the liquid crystal display <b>27</b> of the output unit <b>216</b> (S<b>51</b>). This guidance information is indicated as a message such as &#x201c;after depressing the multifunction key, act to move the cursor on the menu screen.&#x201d; When the user <b>1</b> guided by this guidance information depresses the multifunction key (S<b>52</b>), the application program starts an angle data acquisition process for acquiring data of the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>detected by the sensor detection unit <b>217</b> substantially in real time (S<b>53</b>). Then, the user <b>1</b> changes the attitude of the mobile phone <b>20</b> from the basic attitude of <figref idref="DRAWINGS">FIG. 10</figref> to, for example, the attitude shown in <figref idref="DRAWINGS">FIG. 10B</figref>. The application program execution management unit <b>214</b> calculates differences between the data of the respective angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>acquired at S<b>53</b> described above and the basic attitude data &#x3b8;<sub>X0</sub>, &#x3b8;<sub>Y0</sub>, and &#x3b8;<sub>Z0 </sub>memorized in the application memory area. Then, the application program execution management unit <b>214</b> stores data for identifying predetermined angle ranges around the differences of the respective calculated angles as cursor movement reference data that are motion identification data in the reference data memory area (memory means <b>224</b>) in the application memory area in the RAM <b>202</b> (S<b>54</b>).</p>
<p id="p-0094" num="0095">When the cursor moving operation setting process is thus finished, a selection determining operation setting process is subsequently performed. More specifically, when the storage process of S<b>54</b> is finished, guidance information about setting of the selection determining operation is displayed on the liquid crystal display <b>27</b> of the output unit <b>216</b> (S<b>55</b>). This guidance information is indicated as a message such as &#x201c;after depressing the multifunction key, act to determine the selection of the cursor on the menu screen. However, act differently from the action for moving the cursor on the menu screen.&#x201d; When the user <b>1</b> guided by this guidance information depresses the multifunction key (S<b>56</b>), the application program starts an angle data acquisition process for acquiring the data of the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>detected by the sensor detection unit <b>217</b> substantially in real time (S<b>57</b>). Then, the user <b>1</b> changes the attitude of the mobile phone <b>20</b> in a direction at an angle according to his/her preference differently from the motion set for the cursor moving operation from the basic attitude. The application program execution management unit <b>214</b> calculates differences between the data of the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>acquired at S<b>57</b> described above and the basic attitude data &#x3b8;<sub>X0</sub>, &#x3b8;<sub>Y0</sub>, and &#x3b8;<sub>Z0 </sub>memorized in the application memory area. Then, the application program execution management unit <b>214</b> stores data for identifying angle ranges of the differences of the respective acquired angles as selection determining reference data that are motion identification data in the reference data memory area (memory means <b>224</b>) (S<b>58</b>).</p>
<p id="p-0095" num="0096"><figref idref="DRAWINGS">FIG. 15</figref> is a flowchart showing a flow of process of mode selection on the menu screen. After the initial setting process for the mode selection operation method is finished, mode selection is performed on the menu screen displayed on the liquid crystal display <b>27</b>. In this case, the user <b>1</b> can move the cursor on the menu screen or determine a mode selected by the cursor by acting as set in the mode selecting operation method setting process. More specifically, when the menu screen is displayed on the liquid crystal display <b>27</b> (S<b>61</b>), if the user <b>1</b> changes the attitude of the mobile phone <b>20</b> from the basic attitude, the angles are detected by the geomagnetic sensor <b>208</b> of the sensor detection unit <b>217</b>, and the data of the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>are delivered to the application program (S<b>42</b>). The application program execution management unit <b>214</b> calculates differences between the data of the respective acquired angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>and the basic attitude data &#x3b8;<sub>X0</sub>, &#x3b8;<sub>Y0</sub>, and &#x3b8;<sub>Z0</sub>, and determines whether the calculated difference data of the angles are included in angle ranges identified from the mode selection reference data memorized in the reference data memory area (S<b>63</b>). When it is determined at S<b>43</b> that the data are included, the application program execution management unit <b>214</b> performs a cursor movement process (specific process) (S<b>64</b>). More specifically, a process for moving the position of the cursor image displayed on the menu screen to the position of the next mode is performed. On the other hand, when it is determined at S<b>63</b> that the data are not included, the application program execution management unit <b>214</b> determines whether the difference data of the acquired angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>are included in angle ranges identified from the selection determining reference data memorized in the reference data memory area (S<b>65</b>). When it is determined at S<b>65</b> that the data are included, the application program execution management unit <b>214</b> performs a process (specific process) for shifting the mode to the mode selected by the cursor on the menu screen (S<b>66</b>). More specifically, when the cursor selects the game mode, the game is started, and when the cursor selects the setting mode, the setting mode is started.</p>
<p id="p-0096" num="0097">A preferred embodiment of the present invention has been described above, however, various changes can be added to the disclosed embodiment within the scope of the technical matter described in the claims without deviating from the scope and spirit of the present invention.</p>
<p id="p-0097" num="0098">For example, in the present embodiment, the case where the data of the accelerations &#x3b1;<sub>X</sub>, &#x3b1;<sub>Y</sub>, and &#x3b1;<sub>Z </sub>and the angles &#x3b8;<sub>X</sub>, &#x3b8;<sub>Y</sub>, and &#x3b8;<sub>Z </sub>sent from the sensor detection unit <b>217</b> are used in an application program that works in an application execution environment created on the phone platform and does not depend on a platform is described, however, the same applies to the application program depending on the platform, that is, the application program directly working on the phone platform.</p>
<p id="p-0098" num="0099">The present invention is also effectively applicable to, for example, a game in which a virtual ball in the game is dropped in a hole on the game screen displayed on the liquid crystal display <b>27</b> as well as games like the above-described flight simulator. In this case, for example, the application program has contents that by tilting the mobile phone <b>20</b>, the virtual ball moves toward the tilting direction.</p>
<p id="p-0099" num="0100">In the present embodiment, a process for controlling an airplane in a game and a process for selecting a mode on a menu screen are described by way of example, however, the present invention is also widely applicable to other processes. For example, the present invention is also applicable in the same manner to screen scrolling of a mail browsing screen and a registered data browsing screen for browsing registered phone numbers, etc., of acquaintances.</p>
<p id="p-0100" num="0101">Also, the present invention is widely applicable to general electronic apparatuses as well as the above-described mobile phone <b>20</b>, and in this case the same effect can be obtained.</p>
<p id="p-0101" num="0102">Other embodiments of the invention will be apparent to those skilled in the art from a consideration of the specification or practice of the invention disclosed herein. It is intended that the specification and examples be considered as exemplary only, with the true scope and spirit of the invention being indicated by the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An electronic apparatus, comprising:
<claim-text>a display;</claim-text>
<claim-text>key operation means including keys to be operated by a user;</claim-text>
<claim-text>detection means for detecting a motion of the electronic apparatus;</claim-text>
<claim-text>memory means for storing motion identification data for identifying the motion of the electronic apparatus, wherein the motion identification data is stored in response to a predetermined key operation by the user on the key operation means, wherein the motion identification data includes reference data that is determined in response to the predetermined key operation and that identifies a range of motion of the electronic apparatus corresponding to a specific process executed on the electronic apparatus, the range of motion being set using the predetermined key operation, and wherein the reference data is used to control the specific process according to the range of motion that is set using the predetermined key operation, wherein the predetermined key operation is operated at least a first time to start a setting process for setting the range of motion and is operated at least a second time to finish the setting process for setting the range of motion;</claim-text>
<claim-text>guidance information output means for outputting guidance information for guiding an operation of the electronic apparatus for generating motion of the electronic apparatus corresponding to the specific process after the predetermined key operation;</claim-text>
<claim-text>storage means for storing detection data on the motion of the electronic apparatus, the motion being detected by the detection means after the predetermined key operation and after the guidance information output means outputs the guidance information; and</claim-text>
<claim-text>control means for executing the specific process according to the comparison results between the detection data, obtained by detecting the motion of the electronic apparatus with the detection means after storing the motion identification data, and the motion identification data, wherein the specific process includes altering an image displayed on the display according to the comparison results between the detection data and the motion identification data, and</claim-text>
<claim-text>wherein the display guides operation of the predetermined key operation for the setting process to set the range of motion using the guidance information displayed on the display according to the following:</claim-text>
<claim-text>(a) the guidance information guides operation of the predetermined key operation to start a setting process for a maximum pitch angle, guides tilting of the electronic apparatus to a pitch angle selected by a user as the maximum pitch angle, and, while the electronic apparatus is at the pitch angle selected as the maximum pitch angle, guides operation of the predetermined key operation again to finish the setting process for the maximum pitch angle;</claim-text>
<claim-text>(b) the guidance information guides operation of the predetermined key operation to start a setting process for a maximum roll angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum roll angle, and, while the electronic apparatus is at the roll angle selected as the maximum roll angle, guides operation of the predetermined key operation again to finish the setting process for the maximum roll angle; and</claim-text>
<claim-text>(c) the guidance information guides operation of the predetermined key operation to start a setting process for a maximum yaw angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum yaw angle, and, while the electronic apparatus is at the yaw angle selected as the maximum yaw angle, guides operation of the predetermined key operation again to finish the setting process for the maximum yaw angle.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The electronic apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the guidance information output means outputs various guidance information for a plurality of specific processes that the control means can execute;</claim-text>
<claim-text>the storage means performs, for the plurality of specific processes, a process for storing the detection data on the motion of the electronic apparatus detected by the detection means after the predetermined key operation and after the guidance information output means outputs one piece of guidance information or the data obtained by computing the detection data, as motion identification data corresponding to the specific process relating to the one piece of guidance information, in the memory means; and</claim-text>
<claim-text>the control means compares the detection data obtained by detecting the motion with detection means or the data obtained by computing the detection data and a plurality of motion identification data stored in the memory means, and executes the specific process corresponding to the motion identification data including the detection data or the data obtained by computing the detection data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The electronic apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein acceleration means for detecting acceleration generated in the electronic apparatus is used as the detection means.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The electronic apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the acceleration detection means detects a magnitude and direction of the acceleration.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The electronic apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein attitude change detection means for detecting an attitude change of the electronic apparatus is used as the detection means.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The electronic apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein rotation detection means for detecting rotation angular displacement or rotation angular velocity and rotation direction generated in the electronic apparatus is used as the attitude change detection means.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The electronic apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein acceleration means for detecting acceleration generated in the electronic apparatus is used as the detection means.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The electronic apparatus according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the acceleration detection means detects a magnitude and direction of the acceleration.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The electronic apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein attitude change detection means for detecting an attitude change of the electronic apparatus is used as the detection means.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The electronic apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein rotation detection means for detecting rotation angular displacement or rotation angular velocity and rotation direction generated in the electronic apparatus is used as the attitude change detection means.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An electronic apparatus, comprising:
<claim-text>a display;</claim-text>
<claim-text>key operation means including keys to be operated by a user;</claim-text>
<claim-text>detection means for detecting an attitude of the electronic apparatus;</claim-text>
<claim-text>basic attitude data memory means for storing basic attitude data for identifying a basic attitude of the electronic apparatus, wherein the basic attitude data is stored in response to a key operation by the user of a specific key of the key operation means, wherein the basic attitude data includes reference data that is determined in response to the key operation and that identifies a range of motion of the electronic apparatus corresponding to a specific process executed on the electronic apparatus, the range of motion being set using the key operation, and wherein the reference data is used to control the specific process according to the range of motion that is set using the key operation, wherein the key operation is operated at least a first time to start a setting process for setting the range of motion and is operated at least a second time to finish the setting process for setting the range of motion;</claim-text>
<claim-text>storage means for storing detection data on the attitude of the electronic apparatus detected by the detection means after storing the basic attitude data; and</claim-text>
<claim-text>control means for executing the specific process based on differences between the detection data, obtained by detecting the attitude of the electronic apparatus with the detection means after storing the basic attitude data, and the basic attitude data, wherein the specific process includes altering an image displayed on the display according to the differences between the detection data and the basic attitude data, and</claim-text>
<claim-text>wherein the display guides operation of the predetermined operation for the setting process to set the range of motion using guidance information displayed on the display according to the following:</claim-text>
<claim-text>(a) the guidance information guides operation of the key operation to start a setting process for a maximum pitch angle, guides tilting of the electronic apparatus to a pitch angle selected by a user as the maximum pitch angle, and, while the electronic apparatus is at the pitch angle selected as the maximum pitch angle, guides operation of the key operation again to finish the setting process for the maximum pitch angle;</claim-text>
<claim-text>(b) the guidance information guides operation of the key operation to start a setting process for a maximum roll angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum roll angle, and, while the electronic apparatus is at the roll angle selected as the maximum roll angle, guides operation of the key operation again to finish the setting process for the maximum roll angle; and</claim-text>
<claim-text>(c) the guidance information guides operation of the key operation to start a setting process for a maximum yaw angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum yaw angle, and, while the electronic apparatus is at the yaw angle selected as the maximum yaw angle, guides operation of the key operation again to finish the setting process for the maximum yaw angle.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An electronic apparatus, comprising:
<claim-text>a display;</claim-text>
<claim-text>an interface operation device including an interface to be operated by a user;</claim-text>
<claim-text>a sensor that detects attitude and motion of the electronic apparatus;</claim-text>
<claim-text>a memory that stores reference attitude data from the sensor identifying a reference attitude of the electronic apparatus in response to an operation of a predetermined operation by the user on the interface operation device, wherein the reference attitude data identifies a range of motion of the electronic apparatus corresponding to a specific process executed on the electronic apparatus, the range of motion being set using the predetermined operation, and wherein the reference attitude data is used to control the specific process according to the range of motion that is set using the predetermined operation, wherein the predetermined operation is operated at least a first time to start a setting process for setting the range of motion and is operated at least a second time to finish the setting process for setting the range of motion; and</claim-text>
<claim-text>a controller that executes the specific process based on differences between the reference attitude data and detection data obtained after storing the reference attitude data in the memory by detecting, using the sensor, at least one of: an acceleration and a change in attitude of the electronic apparatus, wherein the specific process includes altering an image displayed on the display according to the differences between the reference attitude data and the detection data, and</claim-text>
<claim-text>wherein the display guides operation of the predetermined operation for the setting process to set the range of motion using guidance information displayed on the display according to the following:</claim-text>
<claim-text>(a) the guidance information guides operation of the predetermined operation to start a setting process for a maximum pitch angle, guides tilting of the electronic apparatus to a pitch angle selected by a user as the maximum pitch angle, and, while the electronic apparatus is at the pitch angle selected as the maximum pitch angle, guides operation of the predetermined operation again to finish the setting process for the maximum pitch angle;</claim-text>
<claim-text>(b) the guidance information guides operation of the predetermined operation to start a setting process for a maximum roll angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum roll angle, and, while the electronic apparatus is at the roll angle selected as the maximum roll angle, guides operation of the predetermined operation again to finish the setting process for the maximum roll angle; and</claim-text>
<claim-text>(c) the guidance information guides operation of the predetermined operation to start a setting process for a maximum yaw angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum yaw angle, and, while the electronic apparatus is at the yaw angle selected as the maximum yaw angle, guides operation of the predetermined operation again to finish the setting process for the maximum yaw angle.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The electronic apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the specific process is a process of an application executed on the electronic apparatus.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The electronic apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the sensor detects a magnitude and direction of the acceleration of electronic apparatus.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The electronic apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein sensor detects rotation angular displacement or rotation angular velocity and rotation direction generated in the electronic apparatus.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The electronic apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the electronic apparatus is a mobile communication terminal.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The electronic apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the electronic apparatus is a gaming machine.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A non-transitory computer readable medium storing software for altering an image displayed on an electronic apparatus, the software comprising:
<claim-text>executable code that provides an interface of the electronic apparatus to be operated by a user;</claim-text>
<claim-text>executable code that receives data identifying attitude and motion of the electronic apparatus determined by a sensor;</claim-text>
<claim-text>executable code that stores reference attitude data from the sensor identifying a reference attitude of the electronic apparatus at a time of operation of a predetermined operation on the interface, wherein the reference attitude data identifies a range of motion of the electronic apparatus corresponding to a specific process executed on the electronic apparatus, the range of motion being set using the predetermined operation, and wherein the reference attitude data is used to control the specific process according to the range of motion that is set using the predetermined operation, wherein the predetermined operation is operated at least a first time to start a setting process for setting the range of motion and is operated at least a second time to finish the setting process for setting the range of motion;</claim-text>
<claim-text>executable code that executes the specific process based on differences between the reference attitude data and detection data obtained after storing the reference attitude data in the memory by detecting, using the sensor, at least one of an acceleration and a change in attitude of the electronic apparatus, wherein the specific process includes altering an image displayed on the electronic apparatus according to the differences between the reference attitude data and the detection data; and</claim-text>
<claim-text>executable code that displays guidance information for guiding operation of the predetermined operation for the setting process to set the range of motion according to the following:</claim-text>
<claim-text>(a) the guidance information guides operation of the predetermined operation to start a setting process for a maximum pitch angle, guides tilting of the electronic apparatus to a pitch angle selected by a user as the maximum pitch angle, and, while the electronic apparatus is at the pitch angle selected as the maximum pitch angle, guides operation of the predetermined operation again to finish the setting process for the maximum pitch angle;</claim-text>
<claim-text>(b) the guidance information guides operation of the predetermined operation to start a setting process for a maximum roll angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum roll angle, and, while the electronic apparatus is at the roll angle selected as the maximum roll angle, guides operation of the predetermined operation again to finish the setting process for the maximum roll angle; and</claim-text>
<claim-text>(c) the guidance information guides operation of the predetermined operation to start a setting process for a maximum yaw angle, guides tilting of the electronic apparatus to a roll angle selected by a user as the maximum yaw angle, and, while the electronic apparatus is at the yaw angle selected as the maximum yaw angle, guides operation of the predetermined operation again to finish the setting process for the maximum yaw angle.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The non-transitory computer readable medium according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the specific process is a process of an application executed on the electronic apparatus.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The non-transitory computer readable medium according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the electronic apparatus is at least one of: a mobile communication terminal and a gaming machine. </claim-text>
</claim>
</claims>
</us-patent-grant>
