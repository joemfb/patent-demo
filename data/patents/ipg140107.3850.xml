<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624917-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624917</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13447787</doc-number>
<date>20120416</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>P2001-014822</doc-number>
<date>20010123</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>17</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>02</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345603</main-classification>
<further-classification>345590</further-classification>
</classification-national>
<invention-title id="d2e73">Image input unit and image input method</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5726682</doc-number>
<kind>A</kind>
<name>Lum et al.</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5737032</doc-number>
<kind>A</kind>
<name>Stenzel et al.</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5798767</doc-number>
<kind>A</kind>
<name>Poole et al.</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6219457</doc-number>
<kind>B1</kind>
<name>Potu</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6268847</doc-number>
<kind>B1</kind>
<name>Glen</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6486889</doc-number>
<kind>B1</kind>
<name>Meyers et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6510242</doc-number>
<kind>B1</kind>
<name>Westerman</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6518970</doc-number>
<kind>B1</kind>
<name>Glen</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6694379</doc-number>
<kind>B1</kind>
<name>Hanko et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6903753</doc-number>
<kind>B1</kind>
<name>Gray, III et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6958772</doc-number>
<kind>B1</kind>
<name>Sugimori</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7034828</doc-number>
<kind>B1</kind>
<name>Drebin et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2002/0063801</doc-number>
<kind>A1</kind>
<name>Richardson</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348589</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>JP</country>
<doc-number>61-257071</doc-number>
<kind>A</kind>
<date>19861100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>JP</country>
<doc-number>62-219082</doc-number>
<kind>A</kind>
<date>19870900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>JP</country>
<doc-number>63-146573</doc-number>
<kind>A</kind>
<date>19880600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>JP</country>
<doc-number>2-142292</doc-number>
<kind>A</kind>
<date>19900500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>JP</country>
<doc-number>05-011641</doc-number>
<kind>U</kind>
<date>19930200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>JP</country>
<doc-number>5-30344</doc-number>
<kind>A</kind>
<date>19930200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>5-183743</doc-number>
<kind>A</kind>
<date>19930700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>2001-008026</doc-number>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>WO</country>
<doc-number>99/25123</doc-number>
<kind>A</kind>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>5</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345590</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345603</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12104640</doc-number>
<date>20080417</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8159502</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13447787</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11797570</doc-number>
<date>20070504</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7830398</doc-number>
<date>20101109</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12104640</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11396578</doc-number>
<date>20060404</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7230631</doc-number>
<date>20070612</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11797570</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10618690</doc-number>
<date>20030715</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7042465</doc-number>
<date>20060509</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11396578</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>PCT/JP02/00478</doc-number>
<date>20020123</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10618690</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120200870</doc-number>
<kind>A1</kind>
<date>20120809</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Shiohara</last-name>
<first-name>Ryuichi</first-name>
<address>
<city>Suwa</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Shiohara</last-name>
<first-name>Ryuichi</first-name>
<address>
<city>Suwa</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sughrue Mion, PLLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Seiko Epson Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>McDowell, Jr.</last-name>
<first-name>Maurice L</first-name>
<department>2677</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The invention is characterized by the fact that an area sensor for outputting an analog signal responsive to the light reception amount of light of CMYG is used and when CMYG image data is converted into RGB image data, RGB image data having a domain also in negative values is generated without performing processing of putting the RGB image data into values of 0 or more, without decreasing the information amount of the CMYG image data. Further, the invention is characterized by the fact that when the image data is recorded in a file section <b>16</b> finally as a JPEG file, the pixel data of each color of YCbCr is represented as data type of eight bits and the information amount per pixel is 24 bits for recording more color information without increasing the memory capacity.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="139.78mm" wi="231.73mm" file="US08624917-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="185.08mm" wi="126.15mm" file="US08624917-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="245.19mm" wi="164.25mm" orientation="landscape" file="US08624917-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="220.22mm" wi="136.14mm" file="US08624917-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<p id="p-0002" num="0001">This is a Continuation of application Ser. No. 12/104,640 filed Apr. 17, 2008, which is a Continuation of application Ser. No. 11/797,570 filed May 4, 2007, now U.S. Pat. No. 7,830,398 issued Nov. 9, 2010, which is a Continuation Application of Ser. No. 11/396,578 filed Apr. 4, 2006, now U.S. Pat. No. 7,230,631 issued Jun. 12, 2007, which is a Continuation of application Ser. No. 10/618,690 filed Jul. 15, 2003, now U.S. Pat. No. 7,042,465 issued May 9, 2006, which is a Continuation-in-Part of PCT Application No. PCT/JP02/00478 filed Jan. 23, 2002. The entire disclosures of the prior applications, application Ser. Nos. 12/104,640, 11/797,570, 11/396,578, 10/618,690 and PCT/JP02/0078 are considered part of the disclosure of the accompanying continuation application and are hereby incorporated by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates to an image input unit and an image input method for inputting a color image to be printed out.</p>
<p id="p-0004" num="0003">Hitherto, in a printer, complementary color ink has been used to finally output image data representing the values of CMY (Cyan, Magenta, Yellow) or CMYK (Cyan, Magenta, Yellow, black) and in a monitor, image data representing the value of RGB (Red, Green Blue) is finally output. Generally, in image processing using a computer, color matching is performed with the display colors of a monitor as the reference and therefore in an image input unit such as a digital still camera, image data is represented in the area of RGB color space with the RGB values taking 0 or more. For example, in not only a digital still camera using primary color CCD, but also a digital still camera using complementary color CCD, when CMYG (Cyan, Magenta, Yellow, Green) image data provided from an input image is converted into RGB image data, processing of adjusting the components of a conversion matrix or replacing negative values with 0 is performed and only RGB values of 0 or more are output.</p>
<p id="p-0005" num="0004">For example, in sRGB standard, color coordinates of RGB are determined and RGB color space wherein the RGB values are 0 or more is defined. However, the sRGB color space is narrower than the color space that can be recognized by the visual sense of a human being and thus only a color space in a narrower range than the visual sense of a human being can be represented in an image input unit for outputting an image represented in the sRGB color space.</p>
<p id="p-0006" num="0005">On the other hand, in a printer, a color space wherein the CMY or CMYK values are 0 or more can be represented by printing. A printer for outputting an image represented in the color space wherein the CMY or CMYK values are 0 or more can use pigments for color development on the outside of the sRGB color space as CMY ink, thereby representing a wider color space than the sRGB-defined color space by printing. Likewise, the printer can represent a wider color space by printing than a color monitor manufactured with sRGB display as the reference.</p>
<p id="p-0007" num="0006">For such a printer to print image data recorded in an image input unit such as a digital still camera for recording an image represented in a color space wherein RGB colors represented in sRGB are 0 or more, the image is represented only in a narrower range than the color representation area of the printer, and the characteristics of the printer are not used effectively; this is a problem.</p>
<p id="p-0008" num="0007">In recent years, image data format standards allowing negative values in the colors of sRGB64, RIMM-RGB, etc., have been developed. However, if an attempt is made to allow negative values and improve the image quality, the information amount per pixel is increased three bits and thus the image data formats result in an increase in the data capacity.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">The invention is embodied considering such problems and it is an object of the invention to provide an image input unit and an image input method for expanding color space of a print image without increasing the data capacity.</p>
<p id="p-0010" num="0009">It is another object of the invention to provide an image input unit and an image input method for expanding color space of a print image without impairing the compatibility with an image file format in a digital camera in a related art.</p>
<p id="p-0011" num="0010">In order to solve the aforesaid object, the invention is characterized by having the following arrangement.
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0011">(1) An image, input unit comprising:</li>
</ul>
</p>
<p id="p-0012" num="0012">a data generator which generates RGB image data representing each value of RGB for each pixel as signed data type from an input image; and</p>
<p id="p-0013" num="0013">a data converter which converts the RGB image data into YCbCr image data representing each value of YCbCr for each pixel.
<ul id="ul0002" list-style="none">
    <li id="ul0002-0001" num="0014">(2) The image input unit according to (1), wherein the data generator generates CMY or CMYG image data representing each value of CMY or CMYG for each pixel as unsigned data type from the input image, and converts the CMY or CMYG image data into the RGB image data.</li>
    <li id="ul0002-0002" num="0015">(3) The image input unit according to (2), wherein the data generator includes a signed arithmetic circuit for converting the CMY or CMYG image data into the RGB image data.</li>
    <li id="ul0002-0003" num="0016">(4) The image input unit according to (2), wherein the data generator generates CMY or CMYG image data representing each value of CMY or CMYG for each pixel as unsigned data type of 10 bits or more from the input image.</li>
    <li id="ul0002-0004" num="0017">(5) The image input unit according to (1), wherein</li>
</ul>
</p>
<p id="p-0014" num="0018">the RGB image data representing each value of RGB for each pixel generated by the data generator is signed data type of nine bits or more, and</p>
<p id="p-0015" num="0019">the RGB image data into YCbCr image data representing each value of YCbCr for each pixel converted by the data converter is unsigned data type of eight bits.
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0020">(6) The image input unit according to (1), wherein the data converter enlarges color saturation represented by CbCr.</li>
    <li id="ul0003-0002" num="0021">(7) An image input method comprising:</li>
</ul>
</p>
<p id="p-0016" num="0022">a data generation step of generating RGB image data representing each value of RGB for each pixel as signed data type from an input image; and</p>
<p id="p-0017" num="0023">a data conversion step of converting the RGB image data into YCbCr image data representing each value of YCbCr for each pixel.
<ul id="ul0004" list-style="none">
    <li id="ul0004-0001" num="0024">(8) The image input method according to (7), wherein at the data generation step, CMY or CMYG image data representing each Value of CMY or CMYG for each pixel as unsigned data type is generated from the input image, and the CMY or CMYG image data is converted into the RGB image data.</li>
    <li id="ul0004-0002" num="0025">(9) The image input method according to (8), wherein at the data generation step, CMY or CMYG image data representing each value of CMY or CMYG for each pixel as unsigned data type of 10 bits or more is generated from the input image.</li>
    <li id="ul0004-0003" num="0026">(10) The image input method according to (7), wherein</li>
</ul>
</p>
<p id="p-0018" num="0027">RGB image data representing each value of RGB for each pixel generated at the data generation step is signed data type of nine bits or more is generated, and</p>
<p id="p-0019" num="0028">YCbCr image data representing each value of YCbCr for each pixel converted from the RGB image data at the data conversion step is unsigned data type of eight bits.
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0029">(11) The image input method according to (7), wherein at the data conversion step, color saturation represented by CbCr is enlarged.</li>
</ul>
</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0020" num="0030"><figref idref="DRAWINGS">FIG. 1</figref> is a data flowchart to show the contents of data transferred between blocks shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0021" num="0031"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram to show a digital still camera <b>1</b> as one embodiment of an image input unit according to the invention.</p>
<p id="p-0022" num="0032"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic drawing to show an area sensor of the digital still camera according to the embodiment of the invention.</p>
<p id="p-0023" num="0033"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic drawing to make a comparison between the area of RGB color space and that of color space that can be recognized by a human being.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading>
<p id="p-0024" num="0034">One embodiment of the invention will be discussed with reference with the accompanying drawings.</p>
<p id="p-0025" num="0035"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram to show a digital still camera <b>1</b> as one embodiment of an image input unit according to the invention. <figref idref="DRAWINGS">FIG. 1</figref> is a data flowchart to show the contents of data transferred between the blocks shown in <figref idref="DRAWINGS">FIG. 2</figref>. An optical system <b>10</b>, an area sensor <b>11</b>, an AFE (Analog Front End) <b>12</b>, and an image processing section <b>13</b> corresponds to a data generator in Claims, and a color space conversion section <b>14</b> corresponds to a data converter in Claims.</p>
<p id="p-0026" num="0036">The optical system <b>10</b> is constituted by an optical lens, an infrared cut filter, an optical low-pass filter, etc., for forming a subject image as an input image on the area sensor <b>11</b>.</p>
<p id="p-0027" num="0037">The area sensor <b>11</b> is an optical sensor of CCD, a CMOS sensor, etc., comprising photoelectric conversion elements for converting light into an electric signal, and each photoelectric conversion element is provided with a complementary color filter for allowing light of wavelength of any of C (Cyan), M (Magenta), Y (Yellow), or G (Green) to pass through. The photoelectric conversion elements are placed like a matrix as shown in <figref idref="DRAWINGS">FIG. 3</figref>. The description to follow assumes that the area sensor comprising the photoelectric conversion elements each provided with a complementary color filter of any of C, M, Y, or G is used, but complementary color filters of three colors of CMY may be used as the filters of the photoelectric conversion elements. The purpose of acquiring color information of G in addition to color information of CMY is to directly acquire color information of G recognized sensitively by the visual sense, thereby improving the image quality. The area sensor <b>11</b> outputs an analog signal responsive to the light reception amount of light of wavelength of any of CMYG in each photoelectric conversion element to the AFE <b>12</b>.</p>
<p id="p-0028" num="0038">The AFE <b>12</b> is constituted by a program gain amplifier, a CDS circuit, an A/D converter, etc., for sampling the analog signal output from each photoelectric conversion element and generating a digital signal representing the value of any of CMYG in each photoelectric conversion element as 10 to 12-bit data type. The analog signal is quantized to a digital signal of data type having a length of 10 bits or more, whereby high-quality YCbCr image data can be generated in the color space conversion section <b>14</b>. The digital signal of CMYG is input to the image processing section <b>13</b> directly or after it is stored in buffer memory.</p>
<p id="p-0029" num="0039">The image processing section <b>13</b> is implemented as an ASIC or DSP (Digital Signal Processor) engine implementing a predetermined algorithm as a logical circuit. If the image processing section <b>13</b> is implemented as an ASIC, processing can be speeded up as compared with the case where processing is performed by execution of a program in a DSP engine. The image processing section <b>13</b> performs AE (Auto Exposure), AWB (Auto White Balance), image generation processing, conversion processing from CMYG color space to RGB color space, &#x3b3; correction processing, etc. The image generation processing mentioned here is mainly processing of generating CMYG image data having four values of CMYG for each pixel by performing interpolation processing, etc., using a digital signal representing the value of any of CMYG in each photoelectric conversion element. The conversion processing from CMYG color, space to RGB color space is performed by a 4&#xd7;3 matrix arithmetic processing circuit of ASIC or a multiplication circuit and an addition-subtraction circuit of DSP, CPU <b>19</b>, etc. To allow negative values as the values of RGB output as a result of the conversion processing, the matrix arithmetic processing circuit, the multiplication circuit, the addition-subtraction circuit, and the like used for the conversion processing are formed as signed arithmetic circuits. The RGB image data representing each value of RGB is represented as data type having a larger number of bits than the number of bits of CMYG image data by one bit corresponding to a sign bit. For example, if CMYG image data is data type of a length of 12 bits having a domain of each color ranging from 0 to 2<sup>12</sup>&#x2212;1, RGB image data becomes signed data type of a length of 13 bits having a domain of each color ranging from &#x2212;2<sup>12</sup>&#x2212;1 to +2<sup>12</sup>&#x2212;1. It is desirable that data type of a length of each color nine bits or more should be assigned to RGB image data for representing the data at least in the range of &#x2212;64 to 255. Further, if the domain is expanded to the range of &#x2212;160 to 255, an image particularly good in color reproducibility can be provided. Taking the domain of R large in both positive and negative ranges leads particularly to improvement of the image quality.</p>
<p id="p-0030" num="0040">The color space conversion section <b>14</b> is constituted by a 3&#xd7;3 matrix arithmetic processing circuit or a multiplication circuit and an addition-subtraction circuit of DSP, CPU <b>19</b>, etc. The color space conversion section <b>14</b> performs linear conversion using a 3&#xd7;3 matrix, thereby generating YCbCr image data representing the values of YCbCr from RGB image data. The matrix arithmetic processing circuit, the multiplication circuit, the addition-subtraction circuit, and the like used for the conversion processing are formed as signed arithmetic circuits. To compress and record image data in removable memory in a JPEG file format, the color space conversion section <b>14</b> needs to output YCbCr image data rounded to eight bits. For the color space conversion, using the following expressions conforming to ITU-R BT.601
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Y=</i>0.299<i>R+</i>0.587<i>G+</i>0.114<i>B </i><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Cb</i>=(&#x2212;0.299<i>R&#x2212;</i>0.587<i>G+</i>0.886<i>B</i>)&#xd7;0.564+offset<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Cr</i>=(0.701<i>R&#x2212;</i>0.587<i>G&#x2212;</i>0.114<i>B</i>)&#xd7;0.713+offset<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>for example, the conversion expressions<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Y=</i>0.2990<i>R+</i>0.5870<i>G+</i>0.11408<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Cb=&#x2212;</i>0.1687<i>R&#x2212;</i>0.3313<i>G&#x2212;</i>0.50008+128<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Cr=</i>0.5000<i>R&#x2212;</i>0.4187<i>G&#x2212;</i>0.08138+128<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
can be used.
</p>
<p id="p-0031" num="0041">In the conversion processing using the expressions, arithmetic processing is performed internally with precision of nine bits or more with a sign and at the final output time, YCbCr is rounded to precision of eight bits and each value of YCbCr is output as unsigned data type of the length of eight bits having a domain ranging from 0 to 255. The purpose of rounding YCbCr to precision of eight bits at the final output time is to make the image data compatible with JPEG compression processing. In the process of the conversion processing, the values of CbCr may be increased in an equal ratio for enlarging the sizes of vectors represented by the values of CbCr, thereby increasing the brightness of an image. When color saturation is enlarged, the color saturation is made large in response to the color saturation before enlargement so as to enlarge the distribution area of the color saturation of each pixel. For example, the color saturation before enlargement is multiplied by a constant, thereby making the color saturation large. Such processing results in diametrically enlarging a Munsell color solid that can be represented by the values of YCbCr. Such processing is fitted particularly for simulatedly compensating for brightness information lost in the process of performing arithmetic processing of the values of RGB.</p>
<p id="p-0032" num="0042">A compression processing section <b>15</b> may be implemented as an ASIC dedicated to compression processing or may be implemented as a DSP, CPU <b>19</b>, etc. The compression processing section <b>15</b> performs compression processing conforming to the JPEG standard using DCT (Discrete Cosine Transform) and Huffman coding, and outputs a JPEG bit stream to a file section <b>16</b>.</p>
<p id="p-0033" num="0043">The file section <b>16</b> records image data compressed in the JPEG file format in removable memory such as flash memory. The image file format need not be JPEG and if the image file format is an image file format consisting of information of YCbCr, the invention can be applied; for example, the image data may be recorded in the image file format of TIFF-YCbCr.</p>
<p id="p-0034" num="0044">A control section <b>17</b> includes: ROM <b>20</b> recording a control program, etc. (thus forming a non-transitory computer-readable medium); a CPU <b>19</b> for executing the control program, thereby controlling the optical system <b>10</b>, the area sensor <b>11</b>, the AFE <b>12</b>, and ASIC or DSP implementing the image processing section <b>13</b>, the color space conversion section <b>14</b>, and the compression processing section <b>15</b>; and RAM <b>18</b> for storing various pieces of data as the control program is executed. The ROM <b>20</b>, the CPU <b>19</b>, and the RAM <b>18</b> are connected to each other by a bus.</p>
<p id="p-0035" num="0045">The embodiment is characterized by the fact that the area sensor <b>11</b> for outputting an analog signal responsive to the light reception amount of light of wavelength of any of CMYG for each photoelectric conversion element is used to generate CMYG image data and when the CMYG image data is converted into RGB image data, RGB image data having a domain also in negative values is generated without performing processing of putting the RGB image data into values of 0 or more, namely, without decreasing the information amount of the CMYG image data. <figref idref="DRAWINGS">FIG. 4</figref> schematically shows the color space of RGB taking values of 0 or more and the color space that can be recognized by, a human being. As shown in <figref idref="DRAWINGS">FIG. 4</figref>, the color space that can be recognized by a human being is wider than the color space of RGB taking values of 0 or more. Thus, if conversion is executed from the color space of CMY taking values of 0 or more to the color space of RGB taking values of 0 or more as in the related art, loss of color information that can be recognized by a human being occurs, resulting in color distortion before and after the conversion. In the above-described embodiment, negative values are allowed as input of the color space conversion section <b>14</b>, so that the color space that can be represented by an image consisting of color information of RGB is expanded and, for example, when an image is printed out using complementary color ink, it is made possible to exhaustively represent the color information provided at the input time.</p>
<p id="p-0036" num="0046">Further, the embodiment is characterized by the fact that to record the image data in the file section <b>16</b> finally as a JPEG file, the YCbCr image data is represented as unsigned data type of eight bits and the information amount per pixel just before compression processing is performed is 24 bits for recording more color information without increasing the memory capacity. This uses the nature such that even if the RGB image data contains a negative value, if the RGB image data is converted into YCbCr image data according to the above-described conversion expressions, the YCbCr image data is put in a value of 0 or more.</p>
<p id="p-0037" num="0047">That is, according to the embodiment, negative values are allowed for RGB image data and image processing is performed with precision of nine bits or more for each color of RGB until just before conversion to YCbCr color space, and after conversion to YCbCr color space, the data is rounded to the precision of each color eight bits, whereby the image data can be recorded without increasing the data capacity. Therefore, on the output side, the values of RGB are output as data type having a domain to negative values at the inverse conversion time from the color space represented by YCbCr to the RGB color space, and conversion is executed from the RGB color spade to the CMY color space without losing the color information provided at the input time, so that color matching between the input image of the digital still camera <b>1</b> and the print image can be improved.</p>
<p id="p-0038" num="0048">In the description of the embodiment, an input image is provided through the area sensor <b>11</b> comprising complementary color filters. However, if the area sensor <b>11</b> uses primary color filters of RGB, the image processing section <b>13</b> generates RGB image data provided with negative values by performing matrix arithmetic processing from RGB image data having a value of 0 or more in each color, whereby it is also possible to widen the area of the color space provided after correction processing, for example.</p>
<p id="p-0039" num="0049">In the description of the embodiment, the digital still camera is illustrated as the image input unit, but the invention can also be applied to other image input units of a digital video camera, a scanner, a facsimile, etc.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing apparatus comprising:
<claim-text>a data getter configured to get YCbCr image data; and</claim-text>
<claim-text>a data converter configured to convert the YCbCr image data into RGB image data representing each value of R, G and B as a signed data type,
<claim-text>wherein, the RGB image data, which is converted from the YCbCr image data, represents a color space including a negative value in at least one of R, G and B,</claim-text>
<claim-text>the number of bits of R, G and B of the RGB image data is larger than the number of bits of Y, Cb and Cr of the YCbCr image data, and</claim-text>
</claim-text>
<claim-text>a maximum value of a gradation level of R, G and B of the RGB image data is equal to or larger than a maximum value of a gradation level of Y, Cb and Cr of the YCbCr image data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the RGB image data, which is converted from the YCbCr image data, represents a color space including a maximum value in values that can be represented in the number of bits larger than that representing each value of Y, Cb and Cr in the YCbCr image data by one bit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein
<claim-text>the data converter converts the YCbCr image data into the RGB image data without clipping color information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A non-transitory computer-readable recording medium storing a computer program causing a computer to execute a method of processing image data, the method comprising:
<claim-text>getting YCbCr image data; and</claim-text>
<claim-text>converting the YCbCr image data into RGB image data representing each value of R, G and B as a signed data type,
<claim-text>wherein, the RGB image data, which is converted from the YCbCr image data, represents a color space including a negative value in at least one of R, G and B,</claim-text>
<claim-text>the number of bits of R, G and B of the RGB image data is larger than the number of bits of Y, Cb and Cr of the YCbCr image data, and</claim-text>
<claim-text>a maximum value of a gradation level of R, G and B of the RGB image data is equal to or larger than a maximum value of a gradation level of Y, Cb and Cr of the YCbCr image data.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A method of processing image data, the method comprising:
<claim-text>getting YCbCr image data; and</claim-text>
<claim-text>converting the YCbCr image data into RGB image data representing each value of R, G and B as a signed data type,</claim-text>
<claim-text>wherein, the RGB image data, which is converted from the YCbCr image data, represents a color space including a negative value in at least one of R, G and B,</claim-text>
<claim-text>the number of bits of R, G and B of the RGB image data is larger than the number of bits of Y, Cb and Cr of the YCbCr image data,</claim-text>
<claim-text>a maximum value of a gradation level of R, G and B of the RGB image data is equal to or larger than a maximum value of a gradation level of Y, Cb and Cr of the YCbCr image data, and</claim-text>
<claim-text>at least one of the getting the YCbCr image data and the converting the YCbCr image is performed by a processor. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
