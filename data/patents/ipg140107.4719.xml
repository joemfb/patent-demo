<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625812-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625812</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12044727</doc-number>
<date>20080307</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1396</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>R</subclass>
<main-group>29</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>K</subclass>
<main-group>11</main-group>
<subgroup>16</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>381 56</main-classification>
<further-classification>381 711</further-classification>
<further-classification>381 712</further-classification>
<further-classification>381 713</further-classification>
<further-classification>381 714</further-classification>
<further-classification>381 715</further-classification>
<further-classification>381 716</further-classification>
<further-classification>381 72</further-classification>
<further-classification>381 74</further-classification>
<further-classification>381 60</further-classification>
</classification-national>
<invention-title id="d2e53">Acoustic dampening compensation system</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6741707</doc-number>
<kind>B2</kind>
<name>Ray et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381 7111</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7177433</doc-number>
<kind>B2</kind>
<name>Sibbald</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381 716</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2005/0049492</doc-number>
<kind>A1</kind>
<name>Sweeney et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2006/0045294</doc-number>
<kind>A1</kind>
<name>Smyth</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2006/0158956</doc-number>
<kind>A1</kind>
<name>Laugharn et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2007/0237335</doc-number>
<kind>A1</kind>
<name>O'Sullivan</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381 63</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>22</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>381 72</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 74</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 56</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 60</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>381 711- 716</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60893617</doc-number>
<date>20070307</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080219456</doc-number>
<kind>A1</kind>
<date>20080911</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Goldstein</last-name>
<first-name>Steven W.</first-name>
<address>
<city>Delray Beach</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Usher</last-name>
<first-name>John</first-name>
<address>
<city>Montreal</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Keady</last-name>
<first-name>John P.</first-name>
<address>
<city>Boca Raton</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Goldstein</last-name>
<first-name>Steven W.</first-name>
<address>
<city>Delray Beach</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Usher</last-name>
<first-name>John</first-name>
<address>
<city>Montreal</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Keady</last-name>
<first-name>John P.</first-name>
<address>
<city>Boca Raton</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Personics Holdings, Inc</orgname>
<role>02</role>
<address>
<city>Boca Raton</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Goins</last-name>
<first-name>Davetta W</first-name>
<department>2655</department>
</primary-examiner>
<assistant-examiner>
<last-name>Ganmavo</last-name>
<first-name>Kuassi</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An acoustic management system configured to compensate for acoustical dampening is provided. The system includes a microphone configured to detect a first acoustic signal from an acoustic environment and a logic circuit. The logic circuit detects an onset of the acoustical dampening between the acoustic environment and the microphone. The logic circuit generates an acoustic damping compensation filter, which is applied to the first acoustic signal to generate a drive signal.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="231.99mm" wi="127.08mm" file="US08625812-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="217.17mm" wi="167.72mm" file="US08625812-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="239.18mm" wi="136.74mm" file="US08625812-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="165.44mm" wi="145.29mm" file="US08625812-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="229.45mm" wi="172.38mm" file="US08625812-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="187.11mm" wi="168.57mm" file="US08625812-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="223.10mm" wi="177.29mm" file="US08625812-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="193.80mm" wi="159.51mm" file="US08625812-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="202.27mm" wi="177.29mm" file="US08625812-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="237.91mm" wi="164.68mm" file="US08625812-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="161.12mm" wi="176.78mm" file="US08625812-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims the benefit of U.S. provisional patent application No. 60/893,617 filed on 7 Mar. 2007. The disclosure of which is incorporated herein by reference in its entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates to acoustic signal manipulation, and more particularly, though not exclusively, to the acoustic compensation of acoustic dampening by headwear on detected acoustic signals.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Some acoustic detecting and/or measuring devices (e.g., earpieces, room microphones), that measure ambient acoustic signals can be adversely affected when an acoustic dampening occurs between the source of an acoustic signal in an environment and the detecting and/or measuring device. The effect can be frequency dependent and can adversely effect the quality (e.g., spectral characteristics) of the measured acoustic signal.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0005" num="0004">At least one exemplary embodiment is directed to an acoustic management system configured to compensate for acoustical dampening comprising: a microphone configured to detect a first acoustic signal from an acoustic environment; and a logic circuit, where the logic circuit detects an onset of acoustical dampening between the acoustic environment and the microphone, and where the logic circuit generates an acoustic damping compensation filter, where the acoustic damping compensation filter is applied to the first acoustic signal generating a drive signal.</p>
<p id="p-0006" num="0005">At least one exemplary embodiment is directed to a method of compensating for acoustical dampening comprising: detecting a first acoustic signal from an acoustic environment; detecting an onset of acoustical dampening between the acoustic environment and a microphone; generating an acoustic damping compensation filter; and filtering the first acoustic signal using the acoustic damping compensation filter to generate a drive signal.</p>
<p id="p-0007" num="0006">At least one exemplary embodiment is directed to an acoustic dampening detection system comprising: a receiver to generate a first sound field; a microphone configured to measure an acoustic signal; and a logic circuit, where if a magnitude of the measured acoustic signal averaged over the duration of the generation of the first sound field is substantially equal to a reference magnitude, the logic circuit identifies that an acoustic dampening event has occurred.</p>
<p id="p-0008" num="0007">At least one exemplary embodiment is directed to a method of detecting acoustical dampening comprising: emitting a first acoustic wave; detecting a second acoustic wave over a time duration of the first acoustic wave; comparing an averaged magnitude of the second acoustic wave with a reference magnitude and determining if acoustical dampening is present, where acoustical dampening is determined to be present if the averaged magnitude of the second acoustic wave is substantially equal to a reference magnitude.</p>
<p id="p-0009" num="0008">At least one exemplary embodiment is directed to a method of detecting acoustical dampening comprising: emitting a first acoustic wave from an external receiver using a first electronic drive signal; detecting a second acoustic wave over a time duration of the first acoustic wave; performing a cross-correlation between the first electronic drive signal and an electronic representation of the second acoustic wave; obtaining a measured magnitude of the cross-correlation at a lag-time; comparing the measured magnitude with a reference magnitude value; and determining if acoustical dampening is present, where acoustic dampening is determined to be present if the measured magnitude is greater than the reference magnitude value.</p>
<p id="p-0010" num="0009">At least one exemplary embodiment is directed to an acoustic dampening detection system comprising: a microphone configured to measure an acoustic signal; and a logic circuit where if a rate of change of the acoustic signal at a time t is greater than a threshold value, the average value of the acoustic signal after time t has decreased an amount greater than a second threshold value, and the acoustic signal after time t has an average value above a third threshold value the logic circuit identifies that an acoustic dampening event has occurred.</p>
<p id="p-0011" num="0010">Further areas of applicability of exemplary embodiments of the present invention will become apparent from the detailed description provided hereinafter. It should be understood that the detailed description and specific examples, while indicating exemplary embodiments of the invention, are intended for purposes of illustration only and are not intended to limit the scope of the invention.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011">Exemplary embodiments of present invention will become more fully understood from the detailed description and the accompanying drawings, wherein:</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1A</figref> illustrates one example of an acoustic dampening compensation device;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1B</figref> illustrates one example of a situation of an acoustic dampening element affecting an acoustic signal;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 2</figref><i>a </i>is a flow chart of an acoustic compensation system according to at least one exemplary embodiment;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2</figref><i>b </i>is a block diagram of a microphone signal conditioner;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>illustrates at least one method of detecting whether an acoustic dampening event occurs in accordance with at least one exemplary embodiment;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref><i>b </i>illustrates at least one further method of detecting whether an acoustic dampening event occurs in accordance with at least one exemplary embodiment;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref><i>a </i>illustrates at least one further method of detecting whether an acoustic dampening event occurs in accordance with at least one exemplary embodiment;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 4</figref><i>b </i>illustrates a user voice spectral profile acquisition system in accordance with at least one exemplary embodiment;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 5</figref><i>a </i>illustrates a block diagram of a parameter look up system in accordance with at least one exemplary embodiment;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 5</figref><i>b </i>illustrates a headwear equalization system in accordance with at least one exemplary embodiment; and</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an example of detecting a drop in sound pressure levels using the rate of change, mean values, slopes and other parameters in accordance with at least one exemplary embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS OF THE PRESENT INVENTION</heading>
<p id="p-0024" num="0023">The following description of exemplary embodiment(s) is merely illustrative in nature and is in no way intended to limit the invention, its application, or uses.</p>
<p id="p-0025" num="0024">Exemplary embodiments are directed to or can be operatively used on various wired or wireless earpieces devices (e.g., earbuds, headphones, ear terminals, behind the ear devices or other acoustic devices as known by one of ordinary skill, and equivalents).</p>
<p id="p-0026" num="0025">Processes, techniques, apparatus, and materials as known by one of ordinary skill in the art may not be discussed in detail but are intended to be part of the enabling description where appropriate. For example specific computer code may not be listed for achieving each of the steps discussed, however one of ordinary skill would be able, without undo experimentation, to write such code given the enabling disclosure herein. Such code is intended to fall within the scope of at least one exemplary embodiment.</p>
<p id="p-0027" num="0026">Additionally exemplary embodiments are not limited to earpieces, for example some functionality can be implemented on other systems with speakers and/or microphones for example computer systems, PDAs, BlackBerry&#xae; smartphones, cell and mobile phones, and any other device that emits or measures acoustic energy. Additionally, exemplary embodiments can be used with digital and non-digital acoustic systems. Additionally various receivers and microphones can be used, for example MEMs transducers, diaphragm transducers, for example Knowles' FG and EG series transducers.</p>
<p id="p-0028" num="0027">Notice that similar reference numerals and letters refer to similar items in the following figures, and thus once an item is defined in one figure, it may not be discussed or further defined in the following figures.</p>
<p id="p-0029" num="0028">At least one exemplary embodiment of the present invention is illustrated in <figref idref="DRAWINGS">FIG. 1A</figref>. The embodiment is a small headphone that is inserted in the ear of the user. The headphone consists of the sound-attenuating earplug <b>100</b> inserted into the ear. At the inner (eardrum-facing) surface of the earplug <b>100</b>, an ear-canal loudspeaker receiver <b>102</b> is located for delivering an audio signal to the listener. At the outer (environment-facing) surface of the earplug <b>100</b>, an ambient-sound microphone <b>104</b> is located. Both the loudspeaker <b>102</b> and the microphone <b>104</b> are connected to the electronic signal processing unit <b>106</b>. The signal processing unit <b>106</b> also has a connector <b>108</b> for input of the audio signal. Additionally, an ear-canal microphone <b>110</b> is placed at the inner (eardrum-facing) surface of the earplug <b>100</b> and an external loudspeaker <b>112</b> is placed on the outer (environment-facing) surface of the earplug <b>100</b> for performing other functions of the headphone system not described here (such as monitoring of sound exposure and ear health conditions, headphone equalization, headphone fit testing, noise reduction, and customization).</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 1B</figref> illustrates an example of an acoustic dampening element <b>120</b><i>a</i>, moving <b>140</b><i>a </i>into the path of an acoustic signal or wave <b>130</b><i>a </i>generated by an acoustic source <b>100</b><i>a </i>in ambient environment. The acoustic signal or wave <b>130</b><i>a </i>can be acoustically damped to some level by acoustic damping element <b>120</b><i>a</i>, so that the acoustic signal measured by the microphone <b>110</b><i>a </i>is effected.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 2</figref><i>a </i>depicts a general &#x201c;top-level&#x201d; overview of the Headwear acoustic Equalization System (HEQS). Initialization of the HEQS <b>142</b> may be manually invoked in a number of ways. One way is a manual activation; by either the HEQS user (i.e. that person wearing the headset system in <figref idref="DRAWINGS">FIG. 1A</figref>), or manually by a second person in a local or remote location (e.g. a supervisor). Another activation method is with an automatic mode, for instance in response to a loud sound or when the user dons headwear (e.g. a helmet). There are a number of methods for detecting headwear, as disclosed by the systems in <figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>4</b><i>a</i>. When headwear detection systems determine that headwear is worn, then decision unit <b>101</b> invokes a system <b>103</b> to determine the frequency dependent acoustic transmission index of the headwear (ATI_HW). An inverse of ATI_HW (inverse ATI_HW) <b>105</b> is calculated. The method for determining ATI_HW is described in <figref idref="DRAWINGS">FIGS. 5</figref><i>a </i>and <b>5</b><i>b</i>. The ASM signal is then filtered <b>107</b> with a filter with a response approximating the inverse ATI_HW <b>105</b>. This gives a modified ASM signal which approximates that the ASM signal with the headwear removed. The filter system <b>107</b> may use entirely analog circuitry or may use digital signal processing, e.g. using an FIR-type digital filter. Depending on the particular operating mode of the HEQS the ATI_HW may be updated on a continuous or intermittent basis, as determined by decision unit <b>109</b>. If the operating mode is such that ATI_HW is calculated just once, then the update sequence is terminated <b>111</b>.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 2</figref><i>b </i>describes an optional beam-forming platform <b>138</b>. The beam forming platform <b>138</b> allows for the direction-dependent sensitivity of the microphones in the headset in <figref idref="DRAWINGS">FIG. 1</figref> to be electronically manipulated. For instance, the sensitivity may be increased in the direction of the HEQS user's voice, and decreased in the direction of local noise sources, such as machine noise. The beam-forming platform <b>138</b> takes as its inputs at least three Ambient Sound Microphones (ASMs) <b>114</b>, <b>122</b>, <b>130</b>. The analog signal is then amplified (amp) <b>116</b>, <b>124</b>, <b>132</b>, and then filtered with a Low Pass Filter (LPF) <b>118</b>, <b>126</b>, <b>134</b> to prevent frequency aliasing by the Analog to Digital Converters (ADC) <b>120</b>, <b>128</b>, <b>136</b>. The beam-forming platform <b>138</b> may also take as its input signal the output signal from ASMs in both the left and right headsets worn by the HEQS user. The output signal <b>140</b> for each headset is considered the &#x201c;conditioned ASM signal&#x201d; in other figures in the present invention.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>depicts the SONAR-based headwear detection platform. This system detects the presence of headwear using a SONAR-based system. Activation of this system <b>142</b> may be manually by a remote second person <b>144</b> or by the HEQS user <b>141</b>, or may be automatic <b>140</b> e.g. with a computer timer. A SONAR test signal is reproduced with the External Receiver (ER) <b>112</b> whilst simultaneously recording <b>143</b> the conditioned ASM signal <b>148</b>. The SONAR test signal <b>145</b> may be one of a number of specific test signals, as described in <figref idref="DRAWINGS">FIG. 3</figref><i>b</i>. The recorded ASM signal <b>143</b> is analyzed <b>146</b> to extract the time-domain impulse response (IR) or frequency domain transfer function <b>150</b>. The frequency-domain transfer function may be obtained empirically by dividing the spectral frequency profile of the SONAR test signal <b>145</b> by the spectral frequency profile of the recorded ASM signal <b>143</b> (if the spectral frequency profile is logarithmic, then this would be a subtraction of the two profiles). Alternatively, an adaptive filter such as one based on the LMS algorithm may be used to iteratively approximate the time-domain impulse response or frequency domain transfer function. If a maximum-length sequence (MLS) SONAR test signal is used, then the time-domain IR may be obtained by cross-correlation of the MLS and recorded ASM signal <b>143</b>. The resulting IR is then analyzed to detect headwear. This is undertaken by detecting features in the IR representative of strong sound reflections at time delays consistent with headwear; for instance, if a helmet is worn, then a reflection from the brim is expected at about 0.6 ms for a brim that is 10 cm from the headset. If close-fitting headwear is worn, such as a balaclava or fire-proof hood, then a higher-level IR would be observed (especially at high frequencies) compared with the case when no headwear is worn. If no headwear is worn, then decision unit <b>152</b> determines that no additional filtering of the ASM signal is undertaken <b>154</b>. However, if the analysis of the obtained IR <b>146</b> predicts that headwear is worn, then depending on the particular operating mode <b>156</b> (which may be set with the initialization system <b>142</b>) filtering of the ASM signal may be invoked with either a look-up table based EQ system (<figref idref="DRAWINGS">FIG. 5</figref><i>a</i>) or a voice-based EQ system (<figref idref="DRAWINGS">FIG. 5</figref><i>b</i>).</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 3</figref><i>b </i>depicts the assembly for generating the SONAR test signal used by the SONAR-based headwear detection platform in <figref idref="DRAWINGS">FIG. 3</figref><i>b</i>, and also for the system which determines the acoustic transmission index of the headwear described in <figref idref="DRAWINGS">FIG. 5</figref><i>a</i>. When the SONAR test signal is needed, the activation command <b>158</b> initializes a counter <b>160</b> which keeps a record of the number of repetitions of the test stimulus (i.e. how many averages the analysis system makes). The particular test signal used may be one of a number of signals; a frequency sweep <b>164</b> (ideally this so-called chirp signal is from a lower frequency to a higher frequency with a logarithmic rather than linear incremental sweep). Single or multi-frequency sine-waves may also be used to give a frequency-dependent acoustic transfer function. A Maximum Length Sequence (MLS) signal <b>166</b> is often used to measure acoustic impulse responses. Transient (Dirac) impulses <b>168</b> give a IR directly. Music audio <b>170</b> may be used to measure the transfer function, as well as noise bursts <b>171</b> which may be narrow-band filtered. Once the audio test signal is acquired <b>162</b>, the signal is sent <b>172</b> to the external receiver (ER) <b>112</b> via digital to analog conversion (DAC) <b>174</b> and analog amplification (amp) <b>176</b> (which may be frequency-dependent to compensate for the electroacoustic sensitivity of the loudspeaker). A digital counter <b>180</b> tracks the number of times the audio test signal is repeatedly reproduced with the ER, and decision unit <b>182</b> terminates reproduction of the test signal <b>184</b> when the number of repeats is sufficient.</p>
<p id="p-0035" num="0034">Alternative to the SONAR-based system in <figref idref="DRAWINGS">FIG. 3</figref><i>a </i>is the Voice-based headwear detection platform described in <figref idref="DRAWINGS">FIG. 4</figref><i>a</i>. This system detects the presence of headwear using a user-generated voice. Activation of this system <b>142</b> may be manually by a remote second person <b>144</b> or by the HEQS user <b>141</b>, or may be automatic <b>140</b> e.g. with a computer timer. The headwear is detected by analyzing the conditioned ASM signal <b>148</b> in response to user-generated voice <b>186</b>. The prompting system for the user to speak is described in <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>. The recorded ASM signal is analyzed by unit <b>143</b> when there is no headwear present to give a reference user voice spectral profile <b>187</b>. When the user dons headwear, they are prompted to speak (see <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>) and a second ASM recording is made to give a current user voice spectral profile <b>188</b>. The reference user voice spectral profile <b>187</b> and current user voice spectral profile <b>188</b> are compared with unit <b>189</b> to give a transfer function which is analyzed to predict if headwear is worn. This analysis system may, for instance, determine that headwear is worn if the transfer function indicates that high-frequency content (e.g. at particular frequencies such as 1 kHz and 4 kHz) are attenuated in the current user voice spectral profile <b>188</b> compared with the reference user voice spectral profile <b>187</b> (e.g. are &#x3c;5 dB at these particular frequencies). If this analysis unit <b>189</b> determines that headwear is not worn, then decision unit <b>152</b> does not filter the ASM signal <b>154</b>. Alternately, if analysis unit <b>189</b> determines that headwear IS worn, then decision unit <b>152</b> further determines the frequency dependent acoustic transmission index of the headwear (ATI_HW) that is used to filter the ASM signal (i.e. with a filter response approximating the inverse of ATI_HW). ATI_HW is calculated depending on the particular operating mode, as determined by unit <b>156</b>. These two operating modes are described in <figref idref="DRAWINGS">FIG. 5</figref><i>a </i>and <figref idref="DRAWINGS">FIG. 5</figref><i>b. </i></p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 4</figref><i>b </i>describes the user-prompting system for the voice-based headwear detection platform. Activation command <b>190</b> initializes a counter <b>191</b> which keeps a record of the number of repetitions of the test stimulus. Either a pre-recorded verbal message <b>192</b> or non-verbal message <b>194</b> (e.g. a tone) is acquired <b>193</b> as a prompt message. The prompt message sent <b>172</b> to external receiver <b>112</b> (after digital to analog conversion <b>174</b> and analog amplification <b>176</b>) and is reproduced with the External Receiver <b>112</b> for the user to speak either a specific set of words (e.g. a phonetically balanced word list) or general words (e.g. normal conversation) or non-speech sounds (such as a whistle or hand-clap). This prompt may be repeated a number of times, according to the incremental repeat counter <b>196</b> and decision unit <b>198</b> which terminates <b>200</b> the prompt message after a pre-defined number of repeated message prompts.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 5</figref><i>a </i>describes a system for determining the acoustic transmission index of the headwear (ATI_HW). This is a frequency dependent value for the free-field acoustic absorption of the headwear from an external sound source to a measurement point on the other side of the headwear (specifically, measured at the entrance to the user's ear canal). The system uses the SONAR headwear detection platform described in <figref idref="DRAWINGS">FIG. 3</figref><i>a </i>to obtain a headwear impulse response <b>150</b>. It should be noted that this is not the same as the ATI_HW; rather, it is the impulse response obtained by emitting a SONAR test signal from the external receiver (<b>112</b> in <figref idref="DRAWINGS">FIG. 1</figref>) and recording the sound response at the ASM <b>104</b> (or conditioned ASM signal <b>140</b> in <figref idref="DRAWINGS">FIG. 2</figref><i>b</i>). In a particular optional learn mode <b>202</b>, the IR of different headwear may be measured empirically, and their corresponding ATI_HW is also measured and stored in computer memory <b>204</b>. The recently measured headwear IR <b>150</b> is then compared and matched with measured IRs in the database <b>204</b> using matching unit <b>206</b> (matching may be accomplished using a standard least mean squares difference approach). When the current headwear has been matched to one in the database, then the ASM signal <b>140</b> is filtered with an impulse response (or frequency-domain transfer function) which approximates the inverse of the matched ATI_HW <b>208</b>. The filtering of the ASM signal by unit <b>210</b> may be accomplished using a digital FIR-type filter or an HR-type digital filter, or a multi-band analog audio signal filter. Depending on the particular operating mode of the HEQS selected by the user (or automatically selected) with selecting device <b>212</b>, the ATI_HW may be continually updated by decision unit <b>214</b>. The process may be terminated at step <b>216</b>.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 5</figref><i>b </i>describes an alternative method to that system in <figref idref="DRAWINGS">FIG. 5</figref><i>a</i>, for determining the ATI_HW of the headwear worn by the HEQS user. The method in <figref idref="DRAWINGS">FIG. 5</figref><i>b </i>begins at step <b>218</b> and uses a measure of the user's reference voice spectral profile <b>187</b>. This is a spectral profile of the (conditioned) ASM signals when no headwear is worn in response to user-generated speech or non-speech (e.g. hand-claps). This is compared to the current ASM spectral profile <b>188</b> when the user is wearing headwear. The comparison is undertaken by unit <b>189</b>, which may be a simple spectral subtraction (in the logarithmic or decibel domain), or may be a division of the linear spectral magnitude. The resulting transfer function approximates ATI_HW, and its inverse is calculated by unit <b>220</b> to give a data vector which can be used to filter the ASM signals with filter unit <b>210</b> (as previously described for <figref idref="DRAWINGS">FIG. 5</figref><i>a</i>). The process may be terminated at step <b>216</b>.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an acoustic signal <b>600</b> displayed in a non-limiting manner as the sound pressure level versus time, t. In this non-limiting example acoustic signal <b>600</b> is broken into three regions. The first region can be characterized by an average value SPL-M1, with an associated baseline (e.g., a line fit utilizing least squares) having a slope SLP-1. Similarly the second and third regions can be characterized by an average value SPL-M2 and SPL-M3 respectively, with an associated baseline (e.g., a line fit utilizing least squares) having slopes SLP-2 and SLP-3 respectively. <figref idref="DRAWINGS">FIG. 6</figref> illustrates the situation where a microphone (throughout the duration) is measuring the acoustic signal <b>600</b>, the measurement plotted in <figref idref="DRAWINGS">FIG. 6</figref>. At the onset of an acoustic dampening event (e.g., sheet placed on microphone, headwear placed over earpiece microphone) the measured Sound Pressure Level (SPL) value decreases from SPL-M1 to SPL-M2 over a period of time Dt1. The rate of decrease, [(SPL-M2)&#x2212;(SPL-M1)]/Dt1=R1, can be compared to a threshold value T1 to aid in determining if an acoustic dampening event has occurred. For example if R1=20 dB/1 sec, and T1=10 dB/sec, and the criteria for an acoustic dampening effect (e.g., rather than an acoustic source shut off) is |R1|&#x3c;T1, then if |R1|&#x3c;T1 (note that a criteria R1&#x3e;T1 can also be used as well as an equality relationship) as it is in the example can be used as an indication of an acoustic dampening event rather than an acoustic source shut off. Note that in the example illustrated in <figref idref="DRAWINGS">FIG. 6</figref>, the acoustic dampening event is removed resulting in an increase from SPL-M2 to SPL-M3 in time Dt2. The rate of change, R2=[(SPL-M3)&#x2212;(SPL-M2)]/Dt2, can be compared with a threshold T2 in a similar manner as described above for T1. Another threshold that can be used is the dropped sound pressure levels (DSPL1, DSPL2) average baseline value, for example if SPL-M2&#x3e;SPL-T3 then this can be used as an indication that an acoustic dampening event has occurred rather than an acoustic source shut off. For example if the threshold value SPL-T3 is effective quiet (e.g., 80 dB) then if SPL-M2 drops to below SPL-T3 then this can be indicative of an acoustic source being turned off.</p>
<p id="p-0040" num="0039">Other criteria can also be used as indicators of an acoustic dampening event occurring. For example if the slopes of the baselines before and after shifting are significantly different this can be indicative of an acoustic source shut off rather than an acoustic dampening event. For example if |SLP-2-SLP-1|&#x3e;|(SLP-&#xbd;)|, this could be indicative that an acoustic source has been turned off and that possibly the slope of the second baseline (SLP-2) is close to zero.</p>
<heading id="h-0007" level="1">Further Exemplary Embodiments</heading>
<p id="p-0041" num="0040">The following paragraphs list various other exemplary embodiments of the invention. The list is meant as illustrative only not as a limitative list of embodiments.</p>
<p id="p-0042" num="0041">A self-contained Headwear Acoustic Equalization system (HEQS) to compensate for the acoustic filtering of headwear (hats, helmets, fire-proof headwear etc.) is herein described. The Headwear Acoustic Equalization System (HEQS) empirically measures or determines the acoustic filtering properties of a head garment on a continuous, intermittent, or discrete basis. The acoustic filtering properties are used to compensate for the change in response of a microphone mounted on the user's head (e.g. at or near the entrance to the ear canals) from an external sound source (e.g. voice) by filtering the microphone signal with an audio signal filter (which may be adaptive or one from a pre-defined filter database). The HEQS comprises:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0042">A. An assembly to monitor the acoustic field in a user's immediate environment using one or more Ambient Sound Microphones (ASMs) located near to or at the entrance to one or both occluded ear canals.</li>
        <li id="ul0002-0002" num="0043">B. A signal processing circuit to amplify the signals from the ASMs in (A) and to equalize for the frequency sensitivity of the microphones and to low-pass filter (LPF) the signals prior to digital conversion to prevent aliasing (with the cut-off frequency of the LPF equal or less than half the sampling frequency of the digital sampling system).</li>
        <li id="ul0002-0003" num="0044">C. An analog-to-digital converter (ADC) to convert the filtered analog signals in (B) to a digital representation.</li>
        <li id="ul0002-0004" num="0045">D. An optional beam-forming platform that takes as its inputs the digital signals from the ASMs from one or both headsets to selectively affect the spatial sensitivity of the headset to sound in the user's local environment.</li>
        <li id="ul0002-0005" num="0046">E. An assembly to generate a desired SPL at or near the entrance to one or both occluded (or partly occluded) ear canals consisting of a loudspeaker receiver mounted in an earplug that forms an acoustic seal of the ear canal. (This is the External Receiver; ER).</li>
        <li id="ul0002-0006" num="0047">F. A signal processing circuit to amplify the signal to the ER to equalize for the frequency sensitivity of the transducer.</li>
        <li id="ul0002-0007" num="0048">G. A digital-to-analog converter (DAC) to convert a digital audio signal into an analog audio signal for reproduction with the ER.</li>
        <li id="ul0002-0008" num="0049">H. A HEQS initialization system to start the HEQS; which may be manually initialized by the user with voice-activation or with a physical switch, or may include remote activation by a second person, or may be automatically activated by a system which detects when headwear is adjusted or fitted, or may be activated on a continuous or intermittent basis.</li>
        <li id="ul0002-0009" num="0050">I. A system to detect whether the HEQS user is wearing headwear. Examples of headwear include: a military helmet, a SWAT hood, balaclava, cold-weather face mask, helmet liner, neoprene camouflage face mask, religious headwear such as a burka or turban, or a fireproof face mask as typically worn by fighter pilots and fire-service workers (fire men/women).</li>
        <li id="ul0002-0010" num="0051">J. A system to determine the frequency-dependent acoustic attenuation of the headwear from an ambient sound source (such as the user's voice or a sound-creating object in the environment of the user) to the ASM(s). This attenuation transmission index is called ATIHW.</li>
        <li id="ul0002-0011" num="0052">K. A system to filter the ASM signal with the inverse of the ATI_HW of the headwear, so as to give an ASM signal similar to that with the headwear absent.</li>
        <li id="ul0002-0012" num="0053">L. A system to update the ATI_HW automatically on a continuous basis.</li>
        <li id="ul0002-0013" num="0054">M. A system to update the ATI_HW manually from either a user-generated command or a command issued by a second remote person.</li>
        <li id="ul0002-0014" num="0055">N. A system to update the ATI_HW automatically on an intermittent basis (e.g. every 10 minutes).</li>
        <li id="ul0002-0015" num="0056">O. A system to transmit the ATI_HW to a data storage or analysis system using a wired or wireless data transmission system.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0043" num="0057">Another embodiment of the invention enables the HEQS to automatically determine if headwear is worn using a self-contained SONAR-based headwear detection platform. A SONAR test sound is emitted with an external receiver mounted on the headset device, and its sound reflection is detected using one or more ambient sound microphones mounted on the same headset. The reflected sound is analyzed to determine the presence of headwear. This SONAR-based headwear detection platform comprises:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0058">A. An assembly to monitor the acoustic field in a user's immediate environment using one or more Ambient Sound Microphones (ASMs) located near to or at the entrance to one or both occluded ear canals.</li>
        <li id="ul0004-0002" num="0059">B. A signal processing circuit to amplify the signals from the ASMs in (A) and to equalize for the frequency sensitivity of the microphones and to low-pass filter (LPF) the signals prior to digital conversion to prevent aliasing (with the cut-off frequency of the LPF equal or less than half the sampling frequency of the digital sampling system).</li>
        <li id="ul0004-0003" num="0060">C. An analog-to-digital converter (ADC) to convert the filtered analog signals in (B) to a digital representation.</li>
        <li id="ul0004-0004" num="0061">D. An optional beam-forming platform that takes as its inputs the digital signals from the ASMs from one or both headsets to selectively affect the spatial sensitivity of the headset to sound in the user's local environment.</li>
        <li id="ul0004-0005" num="0062">E. An assembly to generate a desired SPL at or near the entrance to one or both occluded (or partly occluded) ear canals consisting of a loudspeaker receiver mounted in an earplug that forms an acoustic seal of the ear canal. (This is the External Receiver; ER).</li>
        <li id="ul0004-0006" num="0063">F. A signal processing circuit to amplify the signal to the ER to equalize for the frequency sensitivity of the transducer.</li>
        <li id="ul0004-0007" num="0064">G. A digital-to-analog converter (DAC) to convert a digital audio signal into an analog audio signal for reproduction with the ER.</li>
        <li id="ul0004-0008" num="0065">H. An initialization system to start the SONAR-based headwear detection platform; which may be manually activated by the user with voice-activation or with a physical switch, or may be remotely activated by a second person, or may be automatically activated by a system which detects when headwear is adjusted or fitted, or may be activated on a continuous or intermittent basis.</li>
        <li id="ul0004-0009" num="0066">I. A system to generate or retrieve from computer memory a SONAR audio data test signal. This signal may be one of the following types:
        <ul id="ul0005" list-style="none">
            <li id="ul0005-0001" num="0067">a. Swept sine &#x201c;chirp&#x201d; signal.</li>
            <li id="ul0005-0002" num="0068">b. Maximum Length Sequence (MLS) test signal.</li>
            <li id="ul0005-0003" num="0069">c. Dirac transient click signal.</li>
            <li id="ul0005-0004" num="0070">d. Music audio signal.</li>
            <li id="ul0005-0005" num="0071">e. Noise signal (white noise or pink noise).</li>
        </ul>
        </li>
        <li id="ul0004-0010" num="0072">J. Circuitry to reproduce the audio test signal in (I) with the external receiver.</li>
        <li id="ul0004-0011" num="0073">K. A system to simultaneously record the ASM signal whilst the test signal in (I) is reproduced with the ER.</li>
        <li id="ul0004-0012" num="0074">L. A system to repeat the reproduction of the test signal in (I).</li>
        <li id="ul0004-0013" num="0075">M. A system to analyze the recorded ASM signal in response to the SONAR test signal to determine if headwear is worn. This system comprises a method to deconvolve the recorded ASM signal to give a time domain impulse response or frequency domain transfer function with reference to the original SONAR test audio signal.</li>
        <li id="ul0004-0014" num="0076">N. A system to determine if headwear is worn by analysis of the deconvolved test impulse response (IR) or transfer function (TF) in (M) with respect to a reference IR or TF made with no headwear worn.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0044" num="0077">Another embodiment of the invention enables the HEQS to automatically determine the frequency-dependent acoustic absorption characteristics of the headwear worn by a user (this is the Headwear acoustic Attenuation Transmission Index or ATI_HW). Once obtained, the ASM signal is filtered with a filter corresponding to the inverse of ATI_HW. This self-contained SONAR-based headwear determination platform uses a SONAR test sound emitted with an external receiver mounted on the headset device, and its sound reflection is detected using one or more ambient sound microphones mounted on the same headset. The reflected sound is analyzed to determine the headwear using a look-up table analysis with previous measurements of known headwear. This SONAR-based headwear determination platform comprises:
<ul id="ul0006" list-style="none">
    <li id="ul0006-0001" num="0000">
    <ul id="ul0007" list-style="none">
        <li id="ul0007-0001" num="0078">A. An assembly to monitor the acoustic field in a user's immediate environment using one or more Ambient Sound Microphones (ASMs) located near to or at the entrance to one or both occluded ear canals.</li>
        <li id="ul0007-0002" num="0079">B. A signal processing circuit to amplify the signals from the ASMs in (A) and to equalize for the frequency sensitivity of the microphones and to low-pass filter (LPF) the signals prior to digital conversion to prevent aliasing (with the cut-off frequency of the LPF equal or less than half the sampling frequency of the digital sampling system).</li>
        <li id="ul0007-0003" num="0080">C. An analog-to-digital converter (ADC) to convert the filtered analog signals in (B) to a digital representation.</li>
        <li id="ul0007-0004" num="0081">D. An optional beam-forming platform that takes as its inputs the digital signals from the ASMs from one or both headsets to selectively affect the spatial sensitivity of the headset to sound in the user's local environment.</li>
        <li id="ul0007-0005" num="0082">E. An assembly to generate a desired SPL at or near the entrance to one or both occluded (or partly occluded) ear canals consisting of a loudspeaker receiver mounted in an earplug that forms an acoustic seal of the ear canal. (This is the External Receiver; ER).</li>
        <li id="ul0007-0006" num="0083">F. A signal processing circuit to amplify the signal to the ER to equalize for the frequency sensitivity of the transducer.</li>
        <li id="ul0007-0007" num="0084">G. A digital-to-analog converter (DAC) to convert a digital audio signal into an analog audio signal for reproduction with the ER.</li>
        <li id="ul0007-0008" num="0085">H. An initialization system to start the SONAR-based headwear detection platform; which may be manually activated by the user with voice-activation or with a physical switch, or may be remotely activated by a second person, or may be automatically activated by a system which detects when headwear is adjusted or fitted, or may be activated on a continuous or intermittent basis.</li>
        <li id="ul0007-0009" num="0086">I. A system to generate or retrieve from computer memory a SONAR audio data test signal. This signal may be one of the following types:
        <ul id="ul0008" list-style="none">
            <li id="ul0008-0001" num="0087">a. Swept sine &#x201c;chirp&#x201d; signal.</li>
            <li id="ul0008-0002" num="0088">b. Maximum Length Sequence (MLS) test signal.</li>
            <li id="ul0008-0003" num="0089">c. Dirac transient click signal.</li>
            <li id="ul0008-0004" num="0090">d. Music audio signal.</li>
            <li id="ul0008-0005" num="0091">e. Noise signal (white noise or pink noise).</li>
        </ul>
        </li>
        <li id="ul0007-0010" num="0092">J. Circuitry to reproduce the audio test signal in (I) with the external receiver.</li>
        <li id="ul0007-0011" num="0093">K. A system to simultaneously record the ASM signal whilst the test signal in (I) is reproduced with the ER.</li>
        <li id="ul0007-0012" num="0094">L. A system to repeat the reproduction of the test signal in (I).</li>
        <li id="ul0007-0013" num="0095">M. A system to analyze the recorded ASM signal in response to the SONAR test signal to determine if headwear is worn. This system comprises a method to deconvolve the recorded ASM signal to give a time domain impulse response or frequency domain transfer function with reference to the original SONAR test audio signal.</li>
        <li id="ul0007-0014" num="0096">N. A system to determine if headwear is worn by analysis of the deconvolved test impulse response (IR) or transfer function (TF) in (M) with respect to a reference IR or TF made with no headwear worn.</li>
        <li id="ul0007-0015" num="0097">O. A system to determine what headwear is worn by the user by comparing the empirically obtained IR or TR with a library of measured IRs or TRs previously obtained. The empirically obtained IR or TR is matched with the particular previously measured IR or TR using, for example, the method of least-squared difference.</li>
        <li id="ul0007-0016" num="0098">P. A system to obtain the ATI_HW of the worn headwear using a look-up table of previously measured ATI_HW's corresponding to particular headwear IR's.</li>
        <li id="ul0007-0017" num="0099">Q. A system to filter the ASM signal with a filter corresponding to the inverse of the obtained ATI_HW. In an exemplary embodiment, this filter is a digital FIR-type filter.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0045" num="0100">Another embodiment of the invention enables the HEQS to automatically determine if headwear is worn using a self-contained Voice-based headwear detection platform. A Voice test sound is generated by the HEQS user, and is simultaneously detected using one or more ambient sound microphones mounted on the same headset. In some embodiments the user-generated sound is a non-voice sound such as a hand-clap or mouth whistle. The measured sound is analyzed to determine the presence of headwear. This Voice-based headwear detection platform comprises:
<ul id="ul0009" list-style="none">
    <li id="ul0009-0001" num="0000">
    <ul id="ul0010" list-style="none">
        <li id="ul0010-0001" num="0101">A. An assembly to monitor the acoustic field in a user's immediate environment using one or more Ambient Sound Microphones (ASMs) located near to or at the entrance to one or both occluded ear canals.</li>
        <li id="ul0010-0002" num="0102">B. A signal processing circuit to amplify the signals from the ASMs in (A) and to equalize for the frequency sensitivity of the microphones and to low-pass filter (LPF) the signals prior to digital conversion to prevent aliasing (with the cut-off frequency of the LPF equal or less than half the sampling frequency of the digital sampling system).</li>
        <li id="ul0010-0003" num="0103">C. An analog-to-digital converter (ADC) to convert the filtered analog signals in (B) to a digital representation.</li>
        <li id="ul0010-0004" num="0104">D. An optional beam-forming platform that takes as its inputs the digital signals from the ASMs from one or both headsets to selectively affect the spatial sensitivity of the headset to sound in the user's local environment.</li>
        <li id="ul0010-0005" num="0105">E. A digital-to-analog converter (DAC) to convert a digital audio signal into an analog audio signal for reproduction with the ER.</li>
        <li id="ul0010-0006" num="0106">F. An initialization system to start the Voice-based headwear detection platform; which may be manually activated by the user with voice-activation or with a physical switch, or may be remotely activated by a second person, or may be automatically activated by a system which detects when headwear is adjusted or fitted, or may be activated on a continuous or intermittent basis.</li>
        <li id="ul0010-0007" num="0107">G. A system to obtain a Reference User Voice Profile (rUVP); when activated by the system in (F), the rUVP acquisition system works by the user generating some general or predefined verbal messages (e.g. a collection of phonemically balanced words, prompted by a messaging system reproduced with the ear canal receiver). Alternatively, the user may be asked to generate non-verbal sound stimuli, such as hand claps or mouth-whistles. Whilst the user creates the Reference sound message, the ASM signals are simultaneously recorded. The resulting spectral profile is the rUVP.</li>
        <li id="ul0010-0008" num="0108">H. A system to obtain a Current User Voice Profile (cUVP); when activated by the system in (F), the cUVP acquisition system works by the user generating some general or predefined verbal messages (e.g. a collection of phonemically balanced words, prompted by a messaging system reproduced with the ear canal receiver). Alternatively, the user may be asked to generate non-verbal sound stimuli, such as hand claps or mouth-whistles. Whilst the user creates the Reference sound message, the ASM signals are simultaneously recorded. The resulting spectral profile is the cUVP.</li>
        <li id="ul0010-0009" num="0109">I. A system to compare the rUVP and cUVP, and thus determine if headwear is used. This comparison may be in the time domain, but in an exemplary embodiment the comparison is in the frequency domain. If the frequency content of the cUVP is less than the rUVP at particular frequencies (e.g. &#x2153;<sup>rd </sup>octave measurements made at 1 kHz and 4 kHz) by a pre-defined amount (e.g. 5 dB), then it may be deemed that headwear is currently being worn.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0046" num="0110">Another embodiment of the invention enables the HEQS to automatically determine the frequency-dependent acoustic absorption characteristics of the headwear worn by a user (this is the Headwear acoustic Attenuation Transmission Index or ATI_HW). Once obtained, the ASM signal is filtered with a filter corresponding to the inverse of ATI_HW. This self-contained Voice-based headwear determination platform uses a Voice or non-voice (e.g. hand-clap) test sound created by the HEQS user, and is simultaneously recorded using one or more ambient sound microphones mounted on a headset near to or in the user's ear canal. The recorded sound is analyzed to determine the particular headwear and its corresponding ATI_HW using a look-up table analysis with previous measurements of known headwear. This Voice-based headwear determination platform comprises:
<ul id="ul0011" list-style="none">
    <li id="ul0011-0001" num="0000">
    <ul id="ul0012" list-style="none">
        <li id="ul0012-0001" num="0111">A. An assembly to monitor the acoustic field in a user's immediate environment using one or more Ambient Sound Microphones (ASMs) located near to or at the entrance to one or both occluded ear canals.</li>
        <li id="ul0012-0002" num="0112">B. A signal processing circuit to amplify the signals from the ASMs in (A) and to equalize for the frequency sensitivity of the microphones and to low-pass filter (LPF) the signals prior to digital conversion to prevent aliasing (with the cut-off frequency of the LPF equal or less than half the sampling frequency of the digital sampling system).</li>
        <li id="ul0012-0003" num="0113">C. An analog-to-digital converter (ADC) to convert the filtered analog signals in (B) to a digital representation.</li>
        <li id="ul0012-0004" num="0114">D. An optional beam-forming platform that takes as its inputs the digital signals from the ASMs from one or both headsets to selectively affect the spatial sensitivity of the headset to sound in the user's local environment.</li>
        <li id="ul0012-0005" num="0115">E. A digital-to-analog converter (DAC) to convert a digital audio signal into an analog audio signal for reproduction with the ER.</li>
        <li id="ul0012-0006" num="0116">F. An initialization system to start the Voice-based headwear detection platform; which may be manually activated by the user with voice-activation or with a physical switch, or may be remotely activated by a second person, or may be automatically activated by a system which detects when headwear is adjusted or fitted, or may be activated on a continuous or intermittent basis.</li>
        <li id="ul0012-0007" num="0117">G. A system to obtain a Reference User Voice Profile (rUVP); when activated by the system in (F), the rUVP acquisition system works by the user generating some general or predefined verbal messages (e.g. a collection of phonemically balanced words, prompted by a messaging system reproduced with the ear canal receiver). Alternatively, the user may be asked to generate non-verbal sound stimuli, such as hand claps or mouth-whistles. Whilst the user creates the Reference sound message, the ASM signals are simultaneously recorded. The resulting spectral profile is the rUVP.</li>
        <li id="ul0012-0008" num="0118">H. A system to obtain a Current User Voice Profile (cUVP); when activated by the system in (F), the cUVP acquisition system works by the user generating some general or predefined verbal messages (e.g. a collection of phonemically balanced words, prompted by a messaging system reproduced with the ear canal receiver). Alternatively, the user may be asked to generate non-verbal sound stimuli, such as hand claps or mouth-whistles. Whilst the user creates the Reference sound message, the ASM signals are simultaneously recorded. The resulting spectral profile is the cUVP.</li>
        <li id="ul0012-0009" num="0119">I. A system to compare the rUVP and cUVP, and to determine the particular headwear worn by the user. This comparison may be in the time domain, but in an exemplary embodiment the comparison is in the frequency domain. If the frequency content of the cUVP is less than the rUVP at particular frequencies (e.g. &#x2153;<sup>rd </sup>octave measurements made at 1 kHz and 4 kHz) by a pre-defined amount (e.g. 5 dB), then it may be deemed that headwear is currently being worn. The transfer function of rUVP to cUVP is compared to a database of measurements made with particular headwear with a known Headwear acoustic Attenuation Transmission Index or ATI_HW.
<br/>
Alternative to the ATI_HW determination system in (I), a system to empirically to determine ATI_HW which is calculated as the ratio of rUVP to cUVP.
</li>
        <li id="ul0012-0010" num="0120">J. A system to filter the ASM signal with a filter corresponding to the inverse of the obtained ATI_HW (i.e. obtained in process 1 or 3). In the at least one exemplary embodiment, this filter is a digital FIR-type filter.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0047" num="0121">While the present invention has been described with reference to exemplary embodiments, it is to be understood that the invention is not limited to the disclosed exemplary embodiments. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all modifications, equivalent structures and functions of the relevant exemplary embodiments. Thus, the description of the invention is merely exemplary in nature and, thus, variations that do not depart from the gist of the invention are intended to be within the scope of the exemplary embodiments of the present invention. Such variations are not to be regarded as a departure from the spirit and scope of the present invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An acoustic management system configured to compensate for acoustical dampening comprising:
<claim-text>a microphone configured to detect a first acoustic signal from an acoustic environment; and</claim-text>
<claim-text>a logic circuit configured to: detect an onset of the acoustical dampening between the acoustic environment and the microphone based on a change in a characteristic of the first acoustic signal and, responsive to the detected onset of the acoustical dampening, apply an acoustic damping compensation filter to the first acoustic signal to form a drive signal that is reproduced, the acoustic damping compensation filter approximating an inverse of the acoustical dampening between the acoustic environment and the microphone.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising:
<claim-text>a receiver configured to emit a second acoustic signal, where the second acoustic signal is emitted in response to the drive signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, where the microphone is an ambient sound microphone.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, where the receiver is an ear receiver configured to direct the second acoustic signal to a user's ear.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, where the acoustic damping compensation filter is frequency dependent.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, where the acoustic damping compensation filter is added to a spectral signature of the first acoustic signal to generate a spectral signature of the drive signal.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, where the ambient sound microphone is operatively connected to an earpiece.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system according to <claim-ref idref="CLM-00007">claim 7</claim-ref> where the earpiece is an earmuff.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the processor is configured to generate the acoustic damping compensation filter based on at least one of an impulse response or a transfer function between the first acoustic signal and a reference signal.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, where the reference signal includes at least one of a chirp signal, a single frequency sine-wave signal, a multi-frequency sine-wave signal, a maximum length sequence signal or a reference voice signal.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A method of compensating for acoustical dampening comprising:
<claim-text>detecting a first acoustic signal from an acoustic environment via a microphone;</claim-text>
<claim-text>detecting an onset of the acoustical dampening between the acoustic environment and the microphone based on a change in a characteristic of the first acoustic signal; and</claim-text>
<claim-text>responsive to the detected onset of the acoustical dampening, filtering the first acoustic signal using an acoustic damping compensation filter to form a drive signal that is reproduced, the acoustic damping compensation filter approximating an inverse of the acoustical dampening between the acoustic environment and the microphone.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<claim-text>sending the drive signal to a receiver, where the receiver generates a second acoustic signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, where the acoustic damping compensation filter is frequency dependent.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, where the step of filtering the first acoustic signal includes:
<claim-text>generating a spectral signature of the acoustic damping compensation filter; and</claim-text>
<claim-text>applying the spectral signature of the acoustic damping compensation filter to a spectral signature of the first acoustic signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<claim-text>generating the acoustic damping compensation filter based on at least one of an impulse response or a transfer function between the first acoustic signal and a reference signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, where the reference signal includes at least one of a chirp signal, a single frequency sine-wave signal, a multi-frequency sine-wave signal, a maximum length sequence signal or a reference voice signal.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. An acoustic dampening detection system comprising:
<claim-text>a receiver configured to generate a sound field;</claim-text>
<claim-text>a microphone configured to measure an acoustic signal; and</claim-text>
<claim-text>a logic circuit, where if a magnitude of the measured acoustic signal averaged over a duration of the generation of the first sound field conforms to a reference magnitude, the logic circuit identifies that an acoustic dampening event has occurred.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A method of detecting acoustical dampening comprising:
<claim-text>emitting a first acoustic wave;</claim-text>
<claim-text>detecting a second acoustic wave over a time duration of the first acoustic wave;</claim-text>
<claim-text>comparing an averaged magnitude of the second acoustic wave with a reference magnitude; and</claim-text>
<claim-text>determining if the acoustical dampening is present, where the acoustical dampening is determined to be present if the averaged magnitude of the second acoustic wave conforms to a reference magnitude.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising:
<claim-text>filtering the detected second acoustic wave using a band-pass filter.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. A method of detecting acoustical dampening comprising:
<claim-text>emitting a first acoustic wave from an external receiver using a first electronic drive signal;</claim-text>
<claim-text>detecting a second acoustic wave over a time duration of the first acoustic wave;</claim-text>
<claim-text>performing a cross-correlation between the first electronic drive signal and an electronic representation of the second acoustic wave;</claim-text>
<claim-text>obtaining a measured magnitude of the cross-correlation at a lag-time;</claim-text>
<claim-text>comparing the measured magnitude with a reference magnitude value; and</claim-text>
<claim-text>determining if the acoustical dampening is present, where the acoustical dampening is determined to be present if the measured magnitude is greater than the reference magnitude value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The Method according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, further comprising:
<claim-text>filtering the detected second acoustic wave using a band-pass filter.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. An acoustic dampening detection system comprising:
<claim-text>a microphone configured to measure an acoustic signal; and</claim-text>
<claim-text>a logic circuit where if a rate of change of the acoustic signal at a time t is less than a first threshold value, an average value of the acoustic signal after the time t decreases by an amount greater than a second threshold value, and the acoustic signal after the time t has the average value above a third threshold value the logic circuit identifies that an acoustic dampening event has occurred. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
