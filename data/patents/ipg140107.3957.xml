<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625025-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625025</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13114058</doc-number>
<date>20110524</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>TW</country>
<doc-number>100105493 A</doc-number>
<date>20110218</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>47</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>11</main-group>
<subgroup>20</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>46</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>14</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>64</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348452</main-classification>
<further-classification>348441</further-classification>
<further-classification>348558</further-classification>
<further-classification>348700</further-classification>
</classification-national>
<invention-title id="d2e71">Apparatus and method for detecting flexible video cadence</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5563651</doc-number>
<kind>A</kind>
<name>Christopher et al.</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 97</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5828786</doc-number>
<kind>A</kind>
<name>Rao et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382236</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6201577</doc-number>
<kind>B1</kind>
<name>Swartz</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348558</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6525774</doc-number>
<kind>B1</kind>
<name>Sugihara</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348459</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6542199</doc-number>
<kind>B1</kind>
<name>Manbeck et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348459</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6563550</doc-number>
<kind>B1</kind>
<name>Kahn et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348700</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6704055</doc-number>
<kind>B1</kind>
<name>He et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348449</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6867814</doc-number>
<kind>B2</kind>
<name>Adams et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7039111</doc-number>
<kind>B2</kind>
<name>Lee</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524016</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7075581</doc-number>
<kind>B1</kind>
<name>Ozgen et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7116828</doc-number>
<kind>B2</kind>
<name>Wells</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382233</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7129990</doc-number>
<kind>B2</kind>
<name>Wredenhagen et al.</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348449</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>7154555</doc-number>
<kind>B2</kind>
<name>Conklin</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>7212246</doc-number>
<kind>B2</kind>
<name>Jung et al</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>7233361</doc-number>
<kind>B2</kind>
<name>Yang et al.</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348441</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>7349029</doc-number>
<kind>B1</kind>
<name>Chou</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>7446818</doc-number>
<kind>B2</kind>
<name>Chao</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348558</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>7489350</doc-number>
<kind>B2</kind>
<name>De Haan et al.</name>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348252</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>7605866</doc-number>
<kind>B2</kind>
<name>Conklin</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>7705914</doc-number>
<kind>B2</kind>
<name>Yamauchi</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>7738037</doc-number>
<kind>B2</kind>
<name>Tang et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348441</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>7800692</doc-number>
<kind>B2</kind>
<name>Wredenhagen et al.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348449</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>7898598</doc-number>
<kind>B2</kind>
<name>Chen et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348558</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>8004607</doc-number>
<kind>B2</kind>
<name>Eymard et al.</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348452</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>8120703</doc-number>
<kind>B2</kind>
<name>Adams</name>
<date>20120200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2002/0057368</doc-number>
<kind>A1</kind>
<name>Fakhruddin</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348558</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2003/0098924</doc-number>
<kind>A1</kind>
<name>Adams et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2004/0135924</doc-number>
<kind>A1</kind>
<name>Conklin</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2007/0002169</doc-number>
<kind>A1</kind>
<name>Munsil et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348446</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2007/0052846</doc-number>
<kind>A1</kind>
<name>Adams</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348452</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2007/0188662</doc-number>
<kind>A1</kind>
<name>Winger et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348701</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2008/0062308</doc-number>
<kind>A1</kind>
<name>Zhai et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2008/0158414</doc-number>
<kind>A1</kind>
<name>Capps</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348448</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2008/0252721</doc-number>
<kind>A1</kind>
<name>Suzuki</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 97</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>2010/0253838</doc-number>
<kind>A1</kind>
<name>Garg et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348452</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>2012/0162507</doc-number>
<kind>A1</kind>
<name>Shin et al.</name>
<date>20120600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348446</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348 48-449</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348452</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348458</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348459</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348558</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348700-701</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120212666</doc-number>
<kind>A1</kind>
<date>20120823</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Tung-Hsin</first-name>
<address>
<city>Hsinchu</city>
<country>TW</country>
</address>
</addressbook>
<residence>
<country>TW</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Tung-Hsin</first-name>
<address>
<city>Hsinchu</city>
<country>TW</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Jianq Chyun IP Office</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Novatek Microelectronics Corp.</orgname>
<role>03</role>
<address>
<city>Hsinchu</city>
<country>TW</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Yenke</last-name>
<first-name>Brian</first-name>
<department>2422</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A flexible video cadence detecting apparatus includes a motion detecting unit, a cycle detecting unit, a film detecting unit, and a de-interlacing unit. The motion detecting unit receives a plurality of continuous field images and determines whether or not there is motion in each field image. The motion detecting unit assigns a first or a second value according to whether or not there is motion in the field image, so as to obtain a value stream. The cycle detecting unit receives the value stream and detects whether or not the first or the second value has a cycle, so as to output a cycle determinant. The film detecting unit receives the value stream and the cycle determinant and determines whether or not the field images are a film, to output a cadence pattern. The de-interlacing unit restores the field images into an original film according to the cadence pattern.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="125.81mm" wi="402.93mm" file="US08625025-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="239.27mm" wi="191.52mm" file="US08625025-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="235.80mm" wi="178.56mm" file="US08625025-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="230.38mm" wi="132.93mm" orientation="landscape" file="US08625025-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="134.28mm" wi="147.24mm" file="US08625025-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application claims the priority benefit of Taiwan application serial no. 100105493, filed on Feb. 18, 2011. The entirety of the above-mentioned patent application is hereby incorporated by reference herein and made a part of this specification.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention generally relates to a video cadence detecting technique, and more particularly, to a flexible video cadence detecting technique.</p>
<p id="p-0005" num="0004">2. Description of Related Art</p>
<p id="p-0006" num="0005">The shooting speed of a film is usually different from the play speed thereof. The film shooting speed may be 24 Hz, while the general play speed may be 60 Hz in the NTSC standard and 50 Hz in the PAL&#x26;SECAM standard. Thus, a film is pulled down to the desired play standard in order to be played in the NTSC standard or the PAL&#x26;SECAM standard.</p>
<p id="p-0007" num="0006">For example, when the play speed of a film is to be changed from 24 Hz to 50 Hz in the PAL standard, each image is split into an even image and an odd image. As generally known, an even image is composed of pixels taken from even-numbered scan lines in an original image, and an odd image is composed of pixels taken from odd-numbered scan lines in an original image. By splitting an image into an even image and an odd image, the play speed can be changed from 24 Hz into about 50 Hz. In other words, original images are split according to the speed required by the play standard and a selected video cadence and played in an interlaced manner.</p>
<p id="p-0008" num="0007">Contrarily, if field images are to be restored into original images, the video cadence of the field images needs to be detected so that the field images can be restored into the original images according to the video cadence.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> is a system block diagram illustrating how conventionally field images are restored into an original film. Referring to <figref idref="DRAWINGS">FIG. 1</figref>, the motion detecting unit <b>100</b> determines whether or not there is motion in a current field image by referring to a previous field image and a next field image. For example, if the current field image and the next field image are respectively an even image and an odd image from the same original image, the motion detecting unit <b>100</b> determines that there is no motion in the current field image. If the current field image and the next field image are respectively an even image and an odd image from different original images, the motion detecting unit <b>100</b> determines that there is no motion in the current field image. In other words, whether or not there is motion in each field image is determined to obtain a pattern.</p>
<p id="p-0010" num="0009">The cadence pattern recognizing unit <b>102</b> compares the pattern detected by the motion detecting unit <b>100</b> with data in the cadence database <b>104</b> to obtain a corresponding cadence pattern. Finally, the de-interlacing unit <b>106</b> restores each original image (also referred as a frame) according to the cadence pattern.</p>
<p id="p-0011" num="0010">In the conventional technique described above, the cadence database <b>104</b> is disposed for storing different cadence patterns, so as to correctly restore field images into an original film. Besides, the system cannot work properly if more cadence patterns are used and these cadence patterns are not stored in the cadence database <b>104</b>.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0012" num="0011">Accordingly, the invention is directed to an apparatus and a method for detecting a flexible video cadence, wherein the cadence pattern of a film can be detected without being limited to a fixed number of cadence patterns.</p>
<p id="p-0013" num="0012">According to an embodiment of the invention, a flexible video cadence detecting apparatus including a motion detecting unit, a cycle detecting unit, a film detecting unit, and a de-interlacing unit is provided. The motion detecting unit receives a plurality of continuous field images and determines whether or not there is motion in each of the field images. The motion detecting unit assigns a first value if there is no motion in a field image and assigns a second value if there is motion in the field image, so as to obtain a value stream. The cycle detecting unit receives the value stream and detects whether or not the first value or the second value has a cycle, so as to output a cycle determinant. The film detecting unit receives the value stream and the cycle determinant and determines whether or not the received field images are in a film format, so as to output a cadence pattern. The de-interlacing unit restores the field images into an original film according to the cadence pattern output by the film detecting unit.</p>
<p id="p-0014" num="0013">According to an embodiment of the invention, a film and interlacing cadence detecting apparatus including a motion detecting unit, a cycle detecting unit, and a film detecting unit is provided. The motion detecting unit receives a plurality of continuous field images and determines whether or not there is motion in each of the field images. The motion detecting unit assigns a first value if there is no motion in a field image and assigns a second value if there is motion in the field image, so as to obtain a value stream. The cycle detecting unit receives the value stream, detects whether or not the first value or the second value has a cycle, and outputs the cycle. The film detecting unit receives the value stream, determines whether or not the field images are in a film format according to the cycle, and determines an interlacing cadence according to variations of the first value and the second value in the cycle.</p>
<p id="p-0015" num="0014">According to an embodiment of the invention, a film and interlacing cadence detecting method adapted to detect a plurality of field images continuously input to a detecting apparatus is provided. The present method includes determining whether or not there is motion in each of the field images, wherein a first value is assigned if there is no motion in the field image, and a second value is assigned if there is motion in the field image, so that a value stream is obtained. The present method also includes detecting whether or not the first value or the second value has a cycle in the value stream, determining whether or not the field images are in a film format according to the value stream, and determining an interlacing cadence according to variations of the first value and the second value in the cycle.</p>
<p id="p-0016" num="0015">These and other exemplary embodiments, features, aspects, and advantages of the invention will be described and become more apparent from the detailed description of exemplary embodiments when read in conjunction with accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0017" num="0016">The accompanying drawings are included to provide a further understanding of the invention, and are incorporated in and constitute a part of this specification. The drawings illustrate embodiments of the invention and, together with the description, serve to explain the principles of the invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a system block diagram illustrating how conventionally field images are restored into an original film.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating a 2:2 splitting mechanism according to an embodiment.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating a 2:3 splitting mechanism according to an embodiment.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram illustrating the relationship between a value stream in <figref idref="DRAWINGS">FIG. 3</figref> and a cadence pattern.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram illustrating how a value stream with a predetermined number of bits is analyzed.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram illustrating the structure of a flexible video cadence detecting apparatus according to an embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DESCRIPTION OF THE EMBODIMENTS</heading>
<p id="p-0024" num="0023">Reference will now be made in detail to the present preferred embodiments of the invention, examples of which are illustrated in the accompanying drawings. Wherever possible, the same reference numbers are used in the drawings and the description to refer to the same or like parts.</p>
<p id="p-0025" num="0024">According to the invention, a cadence pattern is directly detected from a plurality of field images without being limited to a fixed number of cadence patterns so that the field images can be restored into an original film according to any different cadence pattern. Below, embodiments of the invention will be described but not intended to limit the scope of the invention. In addition, techniques described in following embodiments may be appropriately integrated.</p>
<p id="p-0026" num="0025">The mechanism for detecting whether or not there is motion in each field image will be described herein.</p>
<p id="p-0027" num="0026">Herein it is assumed that a film is split based on the ratio of 3:2. Namely, a previous image is split into three field images, and the image that follows is split into two field images. A pattern 10100 in the sequence from a closest field image to a farthest field image is obtained through the operation of a motion detecting unit, wherein 1 represents that there is motion in a field image and 0 represents that there is no motion in the field image.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating a 2:2 splitting mechanism according to an embodiment. Referring to <figref idref="DRAWINGS">FIG. 2</figref>, it is assumed that the film is shot in unit of frame and the shooting speed is in unit of Hz. In the present embodiment, four frames (for example, frames 1-4) are taken as examples. In the present embodiment, the 2:2 splitting mechanism is adopted and each frame is split into field images (an even image and an odd image of 50/60 Hz). In the present embodiment, the film is played by starting from an even image or an odd image. After each frame is split into an even image and an odd image, the even images and odd images are composed into field images according to a play standard to be played (for example, in a TV). The field images composed from the frames 1-4 may be field images 1-8. Taking the frame 1 as an example, because field image 1 and field image 2 are from the same frame 1 and are woven by using an even image and an odd image, no motion is detected when field image 2 is compared with field image 1 and accordingly field image is marked as 0. Next, when field image 3 is compared with field image 2, a motion is detected. This is because that field image 2 is an image of the frame 1, while field image 3 is an image of frame 2. field image 2 is marked as 1 unless these images are static.</p>
<p id="p-0029" num="0028">Analogic to what have been mentioned above, the other field images 3-8 have the same recurrent pattern. Accordingly, a specific cadence pattern (which is 01010101 in the present embodiment) is determined. Because each field image has only one state (i.e., 0 or 1), the binary value can be indicated by using one bit. Accordingly, a value stream is obtained. Herein the binary values 0 and 1 are adopted. However, generally speaking, foregoing two states may also be indicated by using other different values. In other words, one value is used for indicating the situation of no motion while another value is used for indicating the situation of motion.</p>
<p id="p-0030" num="0029">In the embodiment illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, the first bit has a value 0, and the value 0 appears every other bit, as indicated by the arrows.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating a 2:3 splitting mechanism according to an embodiment. Referring to <figref idref="DRAWINGS">FIG. 3</figref>, because the 2:3 splitting mechanism is adopted, the frame 2 is split into three images. Based on the same mechanism illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, there is motion in the field image of the adjacent new frame and accordingly the field image is marked as 1. In the present embodiment, the cadence pattern is the recurrence of 01001.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram illustrating the relationship between the value stream in <figref idref="DRAWINGS">FIG. 3</figref> and a cadence pattern. A value stream having 20 bits is analyzed herein. If the detection cycle is 5, the value of the first bit from the left is taken for detection and which is expected to re-appear after every four bits. If the detection cycle is not 5, the value 0 does not appear recurrently, which means the value stream does not have a correct cycle.</p>
<p id="p-0033" num="0032">In addition, if each value 1 comes with a value 0 before and after it, it is determined that different frames are played (i.e., dynamic play of the film). If each value 1 comes with a value 0 before and after it and there is a fixed cycle, it is determined that a film is played and the frames can be restored into original film frames according to the cadence pattern of the cycle.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram illustrating how a value stream with a predetermined number of bits is analyzed. Referring to <figref idref="DRAWINGS">FIG. 5</figref>, in order to effectively detect every possible cycle or cadence pattern, a value stream having a predetermined number of bits is obtained. In the present embodiment, a value stream having 31 bits is obtained and analyzed. When a value stream corresponding to no motion is obtained, several possible cycles or any selected cycle may be detected in the value stream to determine whether or not any cycle exists. The detection cycles may be 5, 10, 12, 15, and 25, etc. However, the invention is not limited thereto. The cadence patterns in the cycles 5, 10, 12, 15, and 25 are corresponding to different splitting mechanism:</p>
<p id="p-0035" num="0034">cycle 5: (3 2);</p>
<p id="p-0036" num="0035">cycle 10: (2 2), (2 2 2 4), (2 3 3 2), (5 5), (6 4);</p>
<p id="p-0037" num="0036">cycle 12: (3 2 3 2 2);</p>
<p id="p-0038" num="0037">cycle 15: (8 7);</p>
<p id="p-0039" num="0038">cycle 25: (2 2 2 2 2 2 2 2 2 2 2 3).</p>
<p id="p-0040" num="0039">Regarding the actual selection of a cycle, the cycle n may be selected from a plurality of factors of 50/60 Hz.</p>
<p id="p-0041" num="0040">The splitting mechanism illustrated in <figref idref="DRAWINGS">FIG. 5</figref> may be 3:3:2:2. According to this splitting mechanism, the first frame among the original frames is split into three even and odd image, the second frame, same as the first frame, is split into three images, the third frame is split into two images, and the fourth frame is also split into two images. The value stream obtained based on the splitting mechanism 2:3:3:2 has a similar cycle pattern 01001001010100100101 as the value stream obtained based on the splitting mechanism 3:3:2:2. The split images retain the even-odd or the odd-even sequence. In the present embodiment, the value 0 of the first bit is taken as a reference. In this case, if cycle 5 is detected, since the value of the 6th bit is 1, it is determined that no cycle 5 exists. If cycle 10 is detected, since the value 0 reappears after every 10 bits, it is determined that cycle 10 exists. If cycle 12 is detected, since the value of the 13th bit is 1, it is determined that no cycle 12 exists. If cycle 15 is detected, since the value of the 16th bit is 1, it is determined that no cycle 15 exists. If cycle 25 is detected, since the value of the 26th bit is 1, it is determined that no cycle 25 exists. Additionally, since cycle 5 is a factor of cycle 10, the detection of cycle 5 can be considered as the detection of cycle 10. The cadence pattern is determined through such a technique, wherein the cycle 10 contains many different splitting mechanisms. However, the correct combination can still be obtained to restore the original frame data according to the cadence pattern of cycle 10.</p>
<p id="p-0042" num="0041">The value stream is corresponding to the play format of the film. In the present embodiment, the values before and after each value 1 are always 0 in the mechanism for detecting whether or not the field images are a dynamic film.</p>
<p id="p-0043" num="0042">The mechanisms and methods described above can be implemented in a flexible video cadence detecting apparatus. <figref idref="DRAWINGS">FIG. 6</figref> is a diagram illustrating the structure of a flexible video cadence detecting apparatus according to an embodiment. The flexible video cadence detecting apparatus includes a motion detecting unit <b>200</b>, a cycle detecting unit <b>202</b>, a film detecting unit <b>204</b>, and a de-interlacing unit <b>206</b>. The motion detecting unit <b>200</b> receives a plurality of continuous field images and determines whether or not there is motion in each field image. The motion detecting unit <b>200</b> assigns a first value (for example, 0) if there is no motion in a field image and assigns a second value (for example, 1) if there is motion in the field image, so that a value stream (for example, a bit stream) is obtained. The cycle detecting unit <b>202</b> receives the value stream and detects whether or not the first value or the second value has a cycle, so as to output a cycle determinant. The cycle determinant is not limited to any specific form or information and may be any suitable determinant indicating the existence of a cycle.</p>
<p id="p-0044" num="0043">Next, the film detecting unit <b>204</b> receives the value stream and the cycle determinant and determines whether or not the received field images are in a film format, so as to output a cadence pattern. The de-interlacing unit <b>206</b> restores the field images into an original film according to the cadence pattern output by the film detecting unit <b>204</b>. The de-interlacing unit <b>206</b> can determine the technique for splitting original frames into field images and the data that can be substantially restored into original frames according to the cadence pattern.</p>
<p id="p-0045" num="0044">Moreover, when the motion detecting unit <b>200</b> and the de-interlacing unit <b>206</b> are in operation, a current field image is processed by referring to one or both of a previous field image and a next field image. However, how a current field image is processed is determined by the adopted motion detection and de-interlacing mechanisms but is not limited to a specific pattern. In embodiments of the invention, a value stream is generated, and a cadence pattern is directly detected from the value stream. Thereby, the cadence pattern of a film can be detected without being limited to a fixed number of cadence patterns.</p>
<p id="p-0046" num="0045">It will be apparent to those skilled in the art that various modifications and variations can be made to the structure of the present invention without departing from the scope or spirit of the invention. In view of the foregoing, it is intended that the present invention cover modifications and variations of this invention provided they fall within the scope of the following claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A flexible video cadence detecting apparatus, comprising:
<claim-text>a motion detecting unit, receiving a plurality of continuous field images and determining whether or not there is motion in each of the field images, wherein the motion detecting unit assigns a first value when there is no motion in the field image and assigns a second value when there is motion in the field image, so as to obtain a value stream;</claim-text>
<claim-text>a cycle detecting unit, at a first stage, receiving the value stream and detecting whether or not the first value or the second value has a cycle only from one of a group of candidate cycles, so as to output a cycle determinant;</claim-text>
<claim-text>a film detecting unit, at a second stage after the first stage, for receiving the value stream and the cycle determinant and determining whether or not the field images are in a film format, so as to output a cadence pattern, wherein one only from a group of a plurality of candidate cadence patterns corresponding to the cycle determinant is determined as the cadence pattern; and</claim-text>
<claim-text>a de-interlacing unit, for restoring the field images into an original film according to the cadence pattern output by the film detecting unit.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The flexible video cadence detecting apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the motion detecting unit determines whether or not there is motion in a current field image by comparing the current field image with a next field image or a previous field image.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The flexible video cadence detecting apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the first value and the second value is respectively recorded in one bit to obtain a bit stream having a predetermined number of bits.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The flexible video cadence detecting apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the cycle detecting unit detects whether or not a binary value of a selected bit appears after each detection cycle and whether or not a plurality of subsequent bit streams have the same detection cycle, wherein the determined detection cycle is the cycle.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The flexible video cadence detecting apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the cycle detecting unit detects a cycle of n bits, wherein n is selected among a plurality of factors of 50/60 Hz.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The flexible video cadence detecting apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the film detecting unit obtains the cycle and detects whether or not the two bits before and after the bit having the second value in the bit stream have the first value, so as to determine whether or not the field images are in the film format.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The flexible video cadence detecting apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the field images comprise a plurality of even images and a plurality of odd images arranged in a sequence of an interlacing cadence, wherein regarding the original film, image data on even-numbered scan lines is taken to form the corresponding even image, and image data on odd-numbered scan lines is taken to form the corresponding odd image.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The flexible video cadence detecting apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the first value is 0, and the second value is 1.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A film and interlacing cadence detecting apparatus, comprising:
<claim-text>a motion detecting unit, receiving a plurality of continuous field images and determining whether or not there is motion in each of the field images, wherein the motion detecting unit assigns a first value when there is no motion in the field image and assigns a second value when there is motion in the field image, so as to obtain a value stream;</claim-text>
<claim-text>a cycle detecting unit, at a first stage, receiving the value stream, detecting whether or not the first value or the second value has a cycle only from one of a group of candidate cycles, and outputting the cycle; and</claim-text>
<claim-text>a film detecting unit, at a second stage after the first stage, receiving the value stream, determining whether or not the field images are in a film format according to the cycle, and determining an interlacing cadence according to variations of the first value and the second value in the cycle, wherein one only from a group of a plurality of candidate cadence patterns corresponding to the cycle is determined as the interlacing cadence.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The film and interlacing cadence detecting apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the motion detecting unit compares a current field image with a next field image or a previous field image to determine whether or not there is motion in the current field image.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The film and interlacing cadence detecting apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the first value and the second value is respectively recorded in one bit to obtain a bit stream having a predetermined number of bits.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The film and interlacing cadence detecting apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the cycle detecting unit detects whether or not a binary value of a selected bit appears after each detection cycle and whether or not a plurality of subsequent bit streams have the same detection cycle, wherein the determined detection cycle is the cycle.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The film and interlacing cadence detecting apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the cycle detecting unit detects a cycle of n bits, wherein n is selected among a plurality of factors of 50/60 Hz.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The film and interlacing cadence detecting apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the film detecting unit obtains the cycle and detects whether or not the two bits before and after the bit having the second value in the bit stream have the first value.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The film and interlacing cadence detecting apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the field images comprise a plurality of even images and a plurality of odd images arranged in a sequence of an interlacing cadence, wherein regarding the original film, image data on even-numbered scan lines are taken to form the corresponding even image, and image data on odd-numbered scan lines are taken to form the corresponding odd image.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A film and interlacing cadence detecting method, for detecting a plurality of field images continuously input to a detecting apparatus, the film and interlacing cadence detecting method comprising:
<claim-text>determining whether or not there is motion in each of the field images, wherein a first value is assigned when there is no motion in the field image, and a second value is assigned when there is motion in the field image, so as to obtain a value stream;</claim-text>
<claim-text>detecting at a first stage to decide whether or not the first value or the second value has a cycle only from one of a group of candidate cycles in the value stream;</claim-text>
<claim-text>determining whether or not the field images are in a film format according to the value stream; and</claim-text>
<claim-text>determining an interlacing cadence at a second stage after the first stage, according to variations of the first value and the second value in the cycle, wherein one only from a group of a plurality of candidate cadence patterns corresponding to the cycle is determined as the interlacing cadence.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The film and interlacing cadence detecting method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the field images comprise a plurality of even images and a plurality of odd images arranged in a sequence of an interlacing cadence.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The film and interlacing cadence detecting method according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein a current field image is compared with a next field image or a previous field image to determine whether or not there is motion in the current field image.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The film and interlacing cadence detecting method according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the first value and the second value is respectively recorded in one bit to obtain a bit stream having a predetermined number of bits.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The film and interlacing cadence detecting method according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the step of detecting whether or not the first value or the second value has the cycle in the value stream comprises:
<claim-text>selecting a bit to be detected, and using a binary value of the bit as a reference; and</claim-text>
<claim-text>detecting whether or not the binary value of the bit appears after each detection cycle and whether or not a plurality of subsequent bit streams have the same detection cycle, wherein the determined detection cycle is the cycle. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
