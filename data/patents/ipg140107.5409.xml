<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626509-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626509</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12055653</doc-number>
<date>20080326</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1475</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>L</subclass>
<main-group>15</main-group>
<subgroup>08</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>17</main-group>
<subgroup>30</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>704255</main-classification>
<further-classification>704275</further-classification>
<further-classification>707777</further-classification>
<further-classification>707778</further-classification>
</classification-national>
<invention-title id="d2e53">Determining one or more topics of a conversation using a domain specific model</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4908866</doc-number>
<kind>A</kind>
<name>Goldwasser et al.</name>
<date>19900300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5694558</doc-number>
<kind>A</kind>
<name>Sparks et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715854</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5860063</doc-number>
<kind>A</kind>
<name>Gorin et al.</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6161087</doc-number>
<kind>A</kind>
<name>Wightman et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6192110</doc-number>
<kind>B1</kind>
<name>Abella et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 8801</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6233575</doc-number>
<kind>B1</kind>
<name>Agrawal et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6578032</doc-number>
<kind>B1</kind>
<name>Chandrasekar et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6754626</doc-number>
<kind>B2</kind>
<name>Epstein</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704235</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7096179</doc-number>
<kind>B2</kind>
<name>Zhu et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704  9</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7158935</doc-number>
<kind>B1</kind>
<name>Gorin et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704257</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7184539</doc-number>
<kind>B2</kind>
<name>Colson et al.</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37926501</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>7320031</doc-number>
<kind>B2</kind>
<name>Konig et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>7395511</doc-number>
<kind>B1</kind>
<name>Robertson et al.</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715810</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>7460650</doc-number>
<kind>B2</kind>
<name>Bushey et al.</name>
<date>20081200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 8803</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>7487094</doc-number>
<kind>B1</kind>
<name>Konig et al.</name>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704270</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>7526461</doc-number>
<kind>B2</kind>
<name>Srinivasa et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>7603353</doc-number>
<kind>B2</kind>
<name>Knepper et al.</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>7672845</doc-number>
<kind>B2</kind>
<name>Beranek et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704251</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2001/0049688</doc-number>
<kind>A1</kind>
<name>Fratkina et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>7071041</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2002/0103793</doc-number>
<kind>A1</kind>
<name>Koller et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2003/0065502</doc-number>
<kind>A1</kind>
<name>Zhu et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704  4</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2003/0065655</doc-number>
<kind>A1</kind>
<name>Syeda-Mahmood</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2003/0105634</doc-number>
<kind>A1</kind>
<name>Abella et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704257</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2003/0110023</doc-number>
<kind>A1</kind>
<name>Bangalore et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2003/0130841</doc-number>
<kind>A1</kind>
<name>Bangalore et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704231</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2005/0044487</doc-number>
<kind>A1</kind>
<name>Bellegarda et al.</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715511</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2005/0283475</doc-number>
<kind>A1</kind>
<name>Beranek et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  6</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2006/0023863</doc-number>
<kind>A1</kind>
<name>Joseph et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37926502</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2006/0080107</doc-number>
<kind>A1</kind>
<name>Hill et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704275</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>2006/0149553</doc-number>
<kind>A1</kind>
<name>Begeja et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704275</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>2006/0149554</doc-number>
<kind>A1</kind>
<name>Begeja et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704275</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>2007/0100624</doc-number>
<kind>A1</kind>
<name>Weng et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704257</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>2007/0179966</doc-number>
<kind>A1</kind>
<name>Li et al.</name>
<date>20070800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707102</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>2007/0244690</doc-number>
<kind>A1</kind>
<name>Peters</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>2008/0256063</doc-number>
<kind>A1</kind>
<name>Nasukawa et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  5</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>2009/0150436</doc-number>
<kind>A1</kind>
<name>Godbole et al.</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>7071041</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>2012/0076283</doc-number>
<kind>A1</kind>
<name>Ajmera et al.</name>
<date>20120300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 9317</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00038">
<othercit>F. Bechet, G. Riccardi and D. Hakkani-Tur; &#x201c;Mining Spoken Dialogue Corpora for System Evaluation and Modeling&#x201d;; <i>Conference on Empirical Methods in Natural Language Processing </i>(<i>EMNLP</i>); Jul. 2004; Barcelona, Spain.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00039">
<othercit>S. Douglas, D. Agarwal, T. Alonso, R.M. Bell, M. Gilbert, D.F. Swayne and C. Volinsky; &#x201c;Mining Customer Care Dialogs for Daily News&#x201d;; <i>IEEE Trans. on Speech and Audio Processing</i>; 2005; 13(5):652-660.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00040">
<othercit>P. Haffner, G. Tur and J.H. Wright; &#x201c;Optimizing SVMs for Complex Call Classification&#x201d;; <i>IEEE International Conference on Acoustics, Speech, and Signal Processing</i>; Apr. 6-10, 2003; Hong Kong.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00041">
<othercit>X. Jiang and A-H. Tan; &#x201c;Mining Ontological Knowledge from Domain-Specific Documents&#x201d;; <i>IEEE International Conference on Data Mining</i>; Nov. 26-30, 2005; New Orleans, Louisiana, USA.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00042">
<othercit>K. Kummamuru, R. Lotlikar, S. Roy, K. Singal and R. Krishnapuram;.&#x201c;A hierarchical monothetic document clustering algorithm for summarization and browsing search results&#x201d;; <i>International Conference on World Wide Web</i>; 2004; New York, NY, USA.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00043">
<othercit>H-K J. Kuo and C-H. Lee; &#x201c;Discriminative Training of Natural Language Call Routers&#x201d;; <i>IEEE Trans. on Speech and Audio Processing</i>; 2003; 11(1):24-35.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00044">
<othercit>A.D. Lawson, D.M. Harris and J.J. Grieco; &#x201c;Effect of Foreign Accent on Speech. Recognition in the NATO N-4 Corpus&#x201d;; <i>Eurospeech</i>; Sep. 1-4, 2003; Geneva, Switzerland.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00045">
<othercit>G. Mishne, D. Carmel, R. Hoory, A. Roytman and A. Soffer; &#x201c;Automatic Analysis of Call-center Conversations&#x201d;; <i>Conference on Information and Knowledge Management</i>; Oct. 31-Nov. 5, 2005; Bremen, Germany.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00046">
<othercit>M. Padmanabhan, G. Saon, J. Huang, B. Kingsbury and L. Mangu;.&#x201c;Automatic Speech Recognition Performance on a Voicemail Transcription Task&#x201d;; <i>IEEE Trans. on Speech and Audio Processing</i>; 2002; 10(7):433-442.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00047">
<othercit>M. Tang, B. Pellom and K. Hacioglu; &#x201c;Call-type Classification and Unsupervised Training for the Call Center Domain&#x201d;; <i>Automatic Speech Recognition and Understanding Workshop</i>; Nov. 30-Dec. 4, 2003; St Thomas, US Virgin Islands.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00048">
<othercit>J. Wright, A. Gorin and G. Riccardi; &#x201c;Automatic Acquisition of Salient Grammar Fragments for Call-type Classification&#x201d;; <i>Eurospeech</i>; Sep. 1997; Rhodes, Greece.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00049">
<othercit>T. Kawahara and S. Doshita; &#x201c;Topic independent language model for key-phrase detection and verification&#x201d;; <i>IEEE International Conference on Acoustics, Speech, and Signal Processing</i>; Proceedings; 1999; ICASSP99 (Cat. No. 99CH36258), pt. 2, p. 685-8, vol. 2.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>704235</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704257</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704275</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704255</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>706 55</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707771</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707777</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707778</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11549173</doc-number>
<date>20061013</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12055653</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20080177538</doc-number>
<kind>A1</kind>
<date>20080724</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Roy</last-name>
<first-name>Shourya</first-name>
<address>
<city>New Delhi</city>
<country>IN</country>
</address>
</addressbook>
<residence>
<country>IN</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Subramaniam</last-name>
<first-name>Laxminarayan Venkata</first-name>
<address>
<city>Gurgaon</city>
<country>IN</country>
</address>
</addressbook>
<residence>
<country>IN</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Roy</last-name>
<first-name>Shourya</first-name>
<address>
<city>New Delhi</city>
<country>IN</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Subramaniam</last-name>
<first-name>Laxminarayan Venkata</first-name>
<address>
<city>Gurgaon</city>
<country>IN</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Wolf Greenfield &#x26; Sacks, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Nuance Communications, Inc.</orgname>
<role>02</role>
<address>
<city>Burlington</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lerner</last-name>
<first-name>Martin</first-name>
<department>2657</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Applications of a domain specific model are described. A domain specific model may encode information about a domain. Information available in the domain specific model may be used to identify a topic of a conversation, such as a topic of a call to a call center. Callers' complaints can be categorized into coarse as well as fine topic categories by analyzing an initial part of a call and by examining a distribution of topic specific descriptive and discriminative features within the initial portion of the call. Once a call has been identified as belonging to a topic, a call-center agent may be prompted with information about the topic, such as questions and answers and actions related to the topic. Generic to specific information may be provided to the agent as the call progresses.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="154.60mm" wi="175.18mm" file="US08626509-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="173.65mm" wi="178.90mm" file="US08626509-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="160.19mm" wi="167.22mm" file="US08626509-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="211.92mm" wi="102.45mm" orientation="landscape" file="US08626509-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="129.79mm" wi="136.31mm" file="US08626509-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="242.32mm" wi="159.34mm" orientation="landscape" file="US08626509-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="232.75mm" wi="178.48mm" orientation="landscape" file="US08626509-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="247.48mm" wi="165.02mm" orientation="landscape" file="US08626509-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="188.04mm" wi="142.41mm" file="US08626509-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 11/549,173 filed Oct. 13, 2006, the complete disclosure of which, in its entirety, is herein incorporated by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to speech processing and, in particular, to the generation of domain models from transcriptions of conversation recordings.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">Call-center is a general term used in relation to help desks, information lines and customer service centers. Many companies today operate call-centers to handle a diversity of customer issues. Such may include product and services related issues and grievance redress. Call-centers are constantly trying to increase customer satisfaction and call handling efficiency by aiding agents and agent monitoring.</p>
<p id="p-0005" num="0004">Call-centers may use a dialog-based support, relying on voice conversations and on line chat, and email support where a user communicates with a professional agent via email. A typical call-center agent handles over a hundred calls in a day. These calls are typically recorded. As a result, gigabytes of data are produced every day in the form of speech audio, speech transcripts, email etc. This data is valuable for doing analysis at many levels. For example, the data may be used to obtain statistics about the type of problems and issues associated with different products and services. The data may also be used to evaluate call center agents and train the agents to improve their performance.</p>
<p id="p-0006" num="0005">Today's call-centers handle a wide variety of domains, such as computer sales and support, mobile phones, apparel, care rental, etc. To analyze the calls in any domain, analysts need to identify the key issues in the domain. Further, there may be variations within a domain based on the service providers. An example of a domain where variations within the domain exist that are based on the service providers is the domain of mobile phones.</p>
<p id="p-0007" num="0006">In the past an analyst would generate a domain model through manual inspection of the data. Such a domain model can include a listing of the call categories, types of problems solved in each category, listing of the customer issues, typical question-answers, appropriate call opening and closing styles etc. In essence, these domain models provide a structured view of the domain.</p>
<p id="p-0008" num="0007">Manually building such domain models for various domains may become prohibitively resource intensive. Many of the domain models are also dynamic in nature and therefore change over time. For example, when a new version of a mobile phone is introduced, when a new software product is launched in a country, or when a new computer virus starts an attack, the domain model may need to be refined.</p>
<p id="p-0009" num="0008">In view of the foregoing, a need exists for an automated approach of creating and maintaining domain models.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0010" num="0009">It is an object of the present invention to substantially overcome, or at least ameliorate, one or more disadvantages of existing arrangements.</p>
<p id="p-0011" num="0010">According to an aspect of the present invention there is provided a method of building a domain specific model from transcriptions. The method starts by applying text clustering to the transcriptions to form text clusters. The text clustering is applied at a plurality of different granularities, and groups topically similar phrases in the transcriptions. The relationship between text clusters resulting from the text clustering at different granularities is then identified to form a taxonomy. The taxonomy is augmented with topic specific information.</p>
<p id="p-0012" num="0011">Preferably the taxonomy is augmented with one or more of: typical issues raised and solutions to those issues; typical questions and answers; and statistics relating to conversations associated with said transcriptions.</p>
<p id="p-0013" num="0012">In a further preferred implementation the method starts with the initial step of extracting from the transcriptions n-grams based upon their respective frequency of occurrences.</p>
<p id="p-0014" num="0013">The identifying step preferably identifies relationships between text clusters resulting from the text clustering at granularities of adjacent levels.</p>
<p id="p-0015" num="0014">Other aspects of the invention are also disclosed.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015">One or more embodiments of the present invention will now be described with reference to the drawings, in which:</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> shows a schematic flow diagram of a method of building a domain specific model from a collection of telephonic conversation recordings;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> shows a partial transcript of a dialog from the internal IT help desk of a company;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3</figref> shows a part of the taxonomy obtained from the dialogs from the internal IT help desk of a company;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 4</figref> shows a part of topic specific information that has been generated for the &#x201c;default properti&#x201d; node in <figref idref="DRAWINGS">FIG. 3</figref> from an example case;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 5</figref> shows average call duration and corresponding average transcription lengths for topics of interest;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6</figref> shows variation in prediction accuracy as a function of the fraction of a call;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 7</figref> shows a graph of the prediction accuracy achieved for various clusters after analyzing 25%, 50%, 75% and 100% of the call; and</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 8</figref> is a schematic block diagram of a general purpose computer upon which arrangements described can be practiced.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 1</figref> shows a schematic flow diagram of a method <b>100</b> of building a domain specific model <b>190</b> from a collection of conversation recordings <b>105</b>, such as telephonic conversation recordings. The domain specific model <b>190</b> built by the method <b>100</b> comprises primarily a topic taxonomy, where every node in the taxonomy is characterized for example by topic(s), typical Question-Answers (QAs), typical actions call statistics etc.</p>
<p id="p-0026" num="0025">The method <b>100</b> is described in the context of a call-center where a customer phones a call-center agent for assistance. However, the method <b>100</b> is not so limited. In the embodiment described the conversation recordings <b>105</b> comprise dialog between the call-center agent and the customer.</p>
<p id="p-0027" num="0026">The method <b>100</b> of building a domain specific model from a collection of conversation recordings <b>105</b> may be practiced using a general-purpose computer system <b>800</b>, such as that shown in <figref idref="DRAWINGS">FIG. 8</figref> wherein the processes of <figref idref="DRAWINGS">FIG. 1</figref> may be implemented as software, such as an application program executing within the computer system <b>800</b>. In particular, the steps of the method <b>100</b> are affected by instructions in the software that are carried out by the computer system <b>800</b>. The software may be stored in a computer readable medium. The software is loaded into the computer system <b>800</b> from the computer readable medium, and then executed by the computer system <b>800</b>. A computer readable medium having such software or computer program recorded on it is a computer program product. The use of the computer program product in the computer system <b>800</b> preferably effects an advantageous apparatus for building a domain specific model <b>190</b> from a collection of conversation recordings <b>105</b>.</p>
<p id="p-0028" num="0027">The computer system <b>800</b> is formed by a computer module <b>801</b>, input devices such as a keyboard <b>802</b>, output devices including a display device <b>814</b>. The computer module <b>801</b> typically includes at least one processor unit <b>805</b>, and a memory unit <b>806</b>. The module <b>801</b> also includes an number of input/output (I/O) interfaces including a video interface <b>807</b> that couples to the display device <b>814</b>, and an I/O interface <b>813</b> for the keyboard <b>802</b>. A storage device <b>809</b> is provided and typically includes at least a hard disk drive and a CD-ROM drive. The components <b>805</b> to <b>813</b> of the computer module <b>801</b> typically communicate via an interconnected bus <b>804</b> and in a manner which results in a conventional mode of operation of the computer system <b>800</b> known to those in the relevant art.</p>
<p id="p-0029" num="0028">Typically, the application program is resident on the storage device <b>809</b> and read and controlled in its execution by the processor <b>805</b>. In some instances, the application program may be supplied to the user encoded on a CD-ROM or floppy disk and read via a corresponding drive, or alternatively may be read by the user from a network via a modem device. Still further, the software can also be loaded into the computer system <b>800</b> from other computer readable media. The term &#x201c;computer readable medium&#x201d; as used herein refers to any storage medium that participates in providing instructions and/or data to the computer system <b>800</b> for execution and/or processing.</p>
<p id="p-0030" num="0029">The method <b>100</b> may alternatively be implemented in dedicated hardware such as one or more integrated circuits performing the functions or sub functions of method <b>100</b>.</p>
<p id="p-0031" num="0030">Referring again to <figref idref="DRAWINGS">FIG. 1</figref>, the method <b>100</b> starts in step <b>110</b> where the dialog of the conversation recordings <b>105</b> is automatically transcribed to form transcription output <b>115</b>. For example, in the case of telephonic conversation recordings automatic speech recognition (ASR) may be used to automatically transcribe the dialog of the conversation recordings <b>105</b>.</p>
<p id="p-0032" num="0031">The transcription output <b>115</b> comprises information about the recognized words along with their durations, i.e. start and end times of the words. Further, speaker turns are marked, so the speaker portions are demarcated without exactly naming which part belongs to which speaker.</p>
<p id="p-0033" num="0032">However, the transcription output <b>115</b> contains many errors and a high degree of noise. The method <b>100</b> is capable of managing the errors and noise through various feature engineering techniques.</p>
<p id="p-0034" num="0033">Before describing the feature engineering techniques in more detail the origin of the errors and noise is first discussed. Current ASR technology, when applied to telephone conversations, has moderate to high word error rates. This is particularly true for telephone conversations arising from call-center calls, because call-centers are now located in different parts of the world, resulting in a diversity of accents that the ASR has to contend with. This high error rate implies that many wrong deletions of actual words and wrong insertion of dictionary words are common phenomena. Also, speaker turns are often not correctly identified and portions of both speakers are assigned to a single speaker.</p>
<p id="p-0035" num="0034">In addition to speech recognition errors, there are other challenges that arise from recognition of spontaneous speech. For example, there are no punctuation marks. Silence periods are marked, but it is not possible to find sentence boundaries based on these silences. There are also repeated words, false starts, many pause filling words such as &#x201c;um&#x201d; and &#x201c;uh&#x201d;, etc.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 2</figref> shows a partial transcript of a dialog from the internal IT help desk of a company. As can be seen from the partial transcript, due to the high error rate and introduced noise, the transcription output <b>115</b> is difficult for humans to interpret.</p>
<p id="p-0037" num="0036">Referring again to <figref idref="DRAWINGS">FIG. 1</figref>, in order to combat the noise introduced by the ASR, the method <b>100</b> continues to step <b>120</b> where various feature engineering techniques are employed to perform noise removal. More particularly, a sequence of cleansing operations are performed to remove generic stopwords such as &#x201c;the&#x201d;, &#x201c;of&#x201d;, etc., as well as domain specific stopwords such as &#x201c;serial&#x201d;, &#x201c;seven&#x201d;, &#x201c;dot&#x201d; etc. Pause filling words, such as &#x201c;um&#x201d;, &#x201c;uh&#x201d;, and &#x201c;huh&#x201d; are also removed.</p>
<p id="p-0038" num="0037">The words remaining in the transcription output are passed through a stemmer. The stemmer determines a root form of a given inflected (or, sometimes, derived) word form. For example, the root &#x201c;call&#x201d; is determined from the word &#x201c;called&#x201d;. In the preferred implementation Porter's stemmer is used.</p>
<p id="p-0039" num="0038">The next action performed in step <b>120</b> is that all n-grams which occur more frequently than a threshold, and do not contain any stopword, are extracted from the noisy transcriptions.</p>
<p id="p-0040" num="0039">Next, in step <b>130</b>, text clustering is applied to the output of step <b>120</b> to group topically similar conversations together. In the preferred implementation the clustering high dimensional datasets package (CLUTO package) is used for the text clustering, with the default repeated bisection technique and the cosine function as the similarity metric.</p>
<p id="p-0041" num="0040">The transcriptions do not contain well formed sentences. Therefore, step <b>130</b> applies clustering at different levels of granularity. In the preferred implementation 5 clusters are firstly generated from the transcriptions. Next, 10 clusters from the same set of transcriptions are generated, and so on. At the finest level 100 clusters are generated.</p>
<p id="p-0042" num="0041">The relationship between groups at different levels of granularity is identified by generating a taxonomy of conversation types in step <b>140</b>. Step <b>140</b> firstly removes clusters containing less than a predetermined number of transcriptions, and secondly, introduces directed edges from cluster &#x3bd;<sub>1 </sub>to cluster &#x3bd;<sub>2 </sub>if clusters &#x3bd;<sub>1 </sub>and &#x3bd;<sub>2 </sub>share at least one transcription between them, where cluster &#x3bd;<sub>2 </sub>is one level finer than cluster &#x3bd;<sub>1</sub>. Clusters &#x3bd;<sub>1 </sub>and &#x3bd;<sub>2 </sub>thereby become nodes in adjacent layers in the taxonomy. Each node in the taxonomy may be termed a topic.</p>
<p id="p-0043" num="0042">A top-down approach is preferred over a bottom-up approach because it indicates the link between clusters of various levels of granularity and also gives the most descriptive and discriminative set of features associated with each node (topic). Descriptive features are the set of features which contribute the most to the average similarity between transcriptions belonging to the same cluster. Similarly, discriminative features are the set of features which contribute the most to the average dissimilarity between transcriptions belonging to different clusters. These features are later used for generating topic specific information.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 3</figref> shows a part of the taxonomy obtained from the dialogs from the internal IT help desk of a company. The labels shown in <figref idref="DRAWINGS">FIG. 3</figref> are the most descriptive and discriminative features of a node given the labels of its ancestors.</p>
<p id="p-0045" num="0044">Referring again to method <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>, the taxonomy generated in step <b>140</b> is augmented in step <b>150</b> with various topic specific information related to each node, thereby creating an augmented taxonomy. The topic specific information includes phrases that describe typical actions, typical QAs and call statistics for each topic (node) in the taxonomy.</p>
<p id="p-0046" num="0045">Typical actions correspond to typical issues raised by the customer, problems and strategies for solving such problems. The inventors have observed that action related phrases are mostly found around topic features. Accordingly, step <b>150</b> starts by searching and collecting all the phrases containing topic words from the documents belonging to the topic. In the preferred implementation a 10-word window is defined around the topic features, and all phrases from the documents are harvested. The set of collected phrases are then searched for n-grams with frequency above a preset threshold. For example, both the 10-grams &#x201c;note in click button to set up for all stops&#x201d; and &#x201c;to action settings and click the button to set up&#x201d; increase the support count of the 5-gram &#x201c;click button to set up&#x201d;.</p>
<p id="p-0047" num="0046">The search for the n-grams proceeds based on a threshold on a distance function that counts the insertions necessary to match two phrases. For example, the phrase &#x201c;can you&#x201d; is closer to the phrase &#x201c;can &#x3c;<img id="CUSTOM-CHARACTER-00001" he="3.13mm" wi="3.89mm" file="US08626509-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x3e; you&#x201d; than to the phrase &#x201c;can &#x3e;<img id="CUSTOM-CHARACTER-00002" he="3.13mm" wi="3.89mm" file="US08626509-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x3c;&#x3e;<img id="CUSTOM-CHARACTER-00003" he="3.13mm" wi="3.89mm" file="US08626509-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>&#x3e; you&#x201d;. Longer n-grams are allowed a higher distance threshold than shorter n-grams. Next, all the phrases that frequently occur within the cluster are extracted.</p>
<p id="p-0048" num="0047">Step <b>150</b> continues by performing phrase tiling and ordering. Phrase tiling constructs longer n-grams from sequences of overlapping shorter n-grams. The inventors have noted that the phrases have more meaning if they are ordered by their respective appearance. For example, if the phrase &#x201c;go to the program menu&#x201d; typically appears before the phrase &#x201c;select options from program menu&#x201d;, then it is more useful to present the phrases in the order of their appearance. The order is established based on the average turn number in the dialog where a phrase occurs.</p>
<p id="p-0049" num="0048">Consider next a situation or a case of typical Question-Answers sessions in a call centre. To understand a caller's issue the call center agent needs to ask the appropriate set of questions. Asking the right questions is the key to handle calls effectively. All the questions within a topic are searched for by defining question templates. The question templates look for all phrases beginning with the terms &#x201c;how&#x201d;, &#x201c;what&#x201d;, &#x201c;can I&#x201d;, &#x201c;can you&#x201d;, &#x201c;were there&#x201d; etc. All 10-word phrases conforming to the question templates are collected and phrase harvesting, tiling and ordering is done on those 10-word phrases. For the answers a search is conducted for phrases in the vicinity immediately following the question.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 4</figref> shows a part of the topic specific information that has been generated for the &#x201c;default properti&#x201d; node in <figref idref="DRAWINGS">FIG. 3</figref> from an example case comprising <b>200</b> transcription outputs <b>115</b>. 123 of the transcription outputs <b>115</b> contained the topic &#x201c;default properti&#x201d;. In the example case, phrases that occur at least 5 times in these 123 transcription outputs <b>115</b> were selected. The general opening and closing styles used by the call-center agents in addition to typical actions and QAs for the topic have been captured. The transcription outputs <b>115</b> associated with the &#x201c;default properti&#x201d; node in <figref idref="DRAWINGS">FIG. 3</figref> pertain to queries on setting up a new network connection, for example from AT&#x26;T. Most of the topic specific issues that have been captured relate to the call-center agent leading the caller through the steps for setting up the network connection.</p>
<p id="p-0051" num="0050">The following observations can be made from the topic specific information that has been generated:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0051">Despite the fact that the ASR step <b>110</b> introduces a lot of noise, the phrases captured are well formed. The resulting phrases, when collected over the clusters, are clean.</li>
        <li id="ul0002-0002" num="0052">Some phrases appear in multiple forms. Consider for example the phrases, &#x201c;thank you for calling how can i help you&#x201d;, &#x201c;how may i help you today&#x201d;, &#x201c;thanks for calling can i be of help today&#x201d;. While tiling is able to merge matching phrases, semantically similar phrases are not merged.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0052" num="0053">With regards to call statistics, various aggregate statistics for each node in the topic taxonomy are captured as part of the domain specific model namely (1) average call duration (in seconds), (2) average transcription length (number of words) (3) average number of speaker turns and (4) number of calls. Generally the call durations and number of speaker turns varies significantly from one topic to another.</p>
<p id="p-0053" num="0054"><figref idref="DRAWINGS">FIG. 5</figref> shows average call duration and corresponding average transcription lengths for a few topics of interest. It can be seen that in topic cluster-<b>1</b>, which relates to expense reimbursement and associated issues, most of the queries were answered relatively quickly when compared to topic cluster-<b>5</b>, for example. Cluster-<b>5</b> relates to connection related issues. Calls associated with connection related issues require more information from callers and are therefore generally longer in duration. Interestingly, topic cluster-<b>2</b> and topic cluster-<b>4</b> have similar average call durations but substantially different average transcription lengths. Cluster-<b>4</b> is primarily about printer related queries where the customer is often not ready with details, such as printer name and the Internet Protocol (IP) address of the printer, resulting in long hold times. In contrast thereto, cluster-<b>2</b> which relates to online courses have a shorter transcription length because users generally have details like course name etc. ready and are interactive in nature. It should be apparent to a person skilled in the art that various other clusters may be formed and used, which fall within the scope of the present invention.</p>
<p id="p-0054" num="0055">A hierarchical index of type {topic&#x2192;information} based on this automatically generated domain specific model is then built for each topic in the topic taxonomy. An entry of this index contains topic specific information namely (1) typical QAs, (2) typical actions, and (3) call statistics. The information associated with each topic becomes more and more specific the further one goes down this hierarchical index.</p>
<p id="p-0055" num="0056">The domain specific model may be further refined by semantically clustering topic specific information so that redundant topics are eliminated. Topics in the model may also be linked to technical manuals, catalogs etc. already available on the different topics in the given domain.</p>
<p id="p-0056" num="0057">Having described the method <b>100</b> of building a domain specific model from a collection of telephonic conversation recordings <b>105</b>, applications of the domain specific model are next described.</p>
<p id="p-0057" num="0058">Information retrieval from spoken dialog data is an important requirement for call-centers. Call-centers constantly endeavor to improve the call handling efficiency and identify key problem areas. The described domain specific model provides a comprehensive and structured view of the domain that can be used to do both. The domain specific model encodes three levels of information about the domain, namely:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0059">General: The taxonomy along with the labels gives a general view of the domain. The general information can be used to monitor trends on how the number of calls in different categories changes over time e.g. daily, weekly, monthly.</li>
        <li id="ul0004-0002" num="0060">Topic level: This includes a listing of the specific issues related to the topic, typical customer questions and problems, usual strategies for solving the problems, average call durations, etc. The topic level of information can be used to identify primary issues, problems and solutions pertaining to any category.</li>
        <li id="ul0004-0003" num="0061">Dialog level: This includes information on how agents typically open and close calls, ask questions and guide customers, average number of speaker turns, etc. The dialog level information can be used to monitor whether agents are using courteous language in their calls, whether they ask pertinent questions, etc.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0058" num="0062">The {topic&#x2192;information} index requires identification of the topic for each call to make use of information available in the domain specific model. Many of the callers' complaints can be categorized into coarse as well as fine topic categories by analyzing only the initial part of the call. Exploiting this observation fast topic identification is performed using a simple technique based on distribution of topic specific descriptive and discriminative features within the initial portion of the call.</p>
<p id="p-0059" num="0063"><figref idref="DRAWINGS">FIG. 6</figref> shows variation in prediction accuracy using the method <b>100</b> as a function of the fraction of a call observed for 5, 10 and 25 clusters. It can be seen, at coarse level, nearly 70% prediction accuracy can be achieved by analyzing the initial 30% of the call and more than 80% of the calls can be correctly categorized by analyzing only the first half of the call.</p>
<p id="p-0060" num="0064"><figref idref="DRAWINGS">FIG. 7</figref> shows a graph of the prediction accuracy achieved for various clusters after analyzing 25%, 50%, 75% and 100% of the call. It can be seen that calls related to some clusters can be quickly detected compared to some other clusters.</p>
<p id="p-0061" num="0065">A further application of the domain specific model is in an aiding and administrative tool. One such a tool operates by aiding call-center agents to efficient handle calls, thereby improving customer satisfaction as well as to reduce call handling time. Another is an administrative tool for agent appraisal and training.</p>
<p id="p-0062" num="0066">Call-centre agent aiding is primarily driven by topic identification. As can be see from <figref idref="DRAWINGS">FIG. 6</figref>, in order to achieve 75% prediction accuracy, a &#x201c;level-1&#x201d; topic, which corresponds to the 5-cluster level, can be identified within the first 30% of the calls. Similarly, a &#x201c;level-2&#x201d; topic, which corresponds to a 10-cluster level, can be identified within the first 42% of the calls, and a &#x201c;level-3&#x201d; topic, which corresponds to a 25-cluster level, can be identified within the first 62% of the calls.</p>
<p id="p-0063" num="0067">The hierarchical nature of the model assists in providing generic to specific information to the agent as the call progresses. For example, once a call has been identified as belonging to topic {lotusnot} (<figref idref="DRAWINGS">FIG. 3</figref>), the call-center agent is prompted with generic Lotus Notes related QAs and actions. Within the next, say, 45 seconds the tool identifies the topic to be the {copi archive replic} topic, and the typical QAs and actions in the prompts change accordingly. Finally, the tool identifies the topic as the {servercopi localcopi} topic and comes up with suggestions for solving the replication problem in Lotus Notes.</p>
<p id="p-0064" num="0068">The administrative tool is primarily driven by dialog and topic level information. This post-processing tool is used for comparing completed individual calls with corresponding topics based on the distribution of QAs, actions and call statistics. Based on the topic level information it can be verified whether the agent identified the issues correctly, and offered the known solutions on a given topic. The dialog level information is used to check whether the call-center agent used courteous opening and closing sentences. Calls that deviate from the topic specific distributions are identified in this way and agents handling these calls can be offered further training on the subject matter, courtesy etc. This kind of post-processing tool may also be used to identify abnormally long calls, agents with high average call handle times etc.</p>
<p id="p-0065" num="0069">The foregoing describes only some embodiments of the present invention, and modifications and/or changes can be made thereto without departing from the scope and spirit of the invention, the embodiments being illustrative and not restrictive.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>We claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>receiving a first set of one or more features of at least a first part of a conversation between at least a first speaker and a second speaker;</claim-text>
<claim-text>comparing, using at least one processor, the first set of one or more features of the at least the first part of the conversation to information regarding a node of a taxonomy of a domain specific model to determine whether the at least the first part of the conversation relates to a topic to which the node of the taxonomy corresponds, wherein the taxonomy of the domain specific model is hierarchical and comprises a plurality of nodes arranged in different levels of a hierarchy, wherein a higher-level node of the taxonomy corresponds to a broad topic and a lower-level node below the higher-level node in the taxonomy corresponds to a specific topic that relates to the broad topic and is more specific than the broad topic, and wherein comparing the first set of one or more features of the at least the first part of the conversation to the information regarding the node comprises comparing the first set of one or more features to information regarding the higher-level node of the taxonomy to determine whether the at least the first part of the conversation relates to the broad topic, wherein the comparing of the first set of one or more features to the information regarding the higher-level node has a first probability of providing a first prediction accuracy in identifying whether the at least the first part of the conversation relates to the broad topic;</claim-text>
<claim-text>in response to determining that a result of the comparing indicates that the at least the first part of the conversation relates to the broad topic, presenting, to a user interface of a device operated by the first speaker, topic-specific information related to the broad topic;</claim-text>
<claim-text>receiving a second set of one or more features of at least a second part of the conversation, the second part of the conversation including both the first part of the conversation and a subsequent part occurring in the conversation following the first part;</claim-text>
<claim-text>in response to determining that the result of the comparing of the first set of the one or more features to the information regarding the higher-level node indicates that the at least the first part of the conversation relates to the broad topic, comparing the second set of one or more features of the first part and the subsequent part to information regarding the lower-level node to determine whether the at least the second part of the conversation relate to the specific topic related to the broad topic, wherein the comparing of the second set of one or more features to the information regarding the lower-level node has a second probability of providing a second prediction accuracy in identifying whether the at least the second part of the conversation relates to the specific topic, the second prediction accuracy being higher than the first prediction accuracy; and</claim-text>
<claim-text>in response to determining that a result of the comparing of the second set of one or more features to the information regarding the lower-level node indicates that the at least the second part of the conversation relates to the specific topic, presenting to the first speaker topic-specific information related to the specific topic.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein receiving the one or more features of the at least the part of the conversation between at least the first speaker and the second speaker comprises receiving one or more features of at least a part of a conversation between a call-center agent and a caller regarding an issue, and
<claim-text>wherein presenting to the first speaker topic-specific information comprises, in response to determining that the result of the comparing indicates that the issue relates to the topic to which the node corresponds, presenting the topic-specific information to the call-center agent to aid the call-center agent in resolving the issue.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein presenting the topic-specific information to the first speaker comprises presenting suggestions to the first speaker of information to provide to the second speaker in the conversation and/or information to obtain from the second speaker in the conversation.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>comparing the first set of one or more features to the information regarding the higher-level node, presenting the topic-specific information related to the broad topic, comparing the second set of one or more features to the information regarding the lower-level node, and presenting topic-specific information related to the specific topic are carried out during the conversation,</claim-text>
<claim-text>comparing the first set of one or more features to information regarding the higher-level node and presenting the topic-specific information related to the broad topic are carried out after receipt of the first set of one or more features of the at least the first part of the conversation and before receipt of the second set of one or more features of the at least the second part of the conversation, and</claim-text>
<claim-text>comparing the second set of one or more features to the information regarding the lower-level node and presenting the topic-specific information related to the specific topic are carried out after receipt of the first set of one or more features of the at least the first part of the conversation and after receipt of the second set of one or more features of the at least the second part of the conversation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the node of the taxonomy is associated with at least one commonly-appearing feature commonly appearing in conversations related to the topic to which the node corresponds, the at least one commonly-appearing feature comprising one or more words and/or phrases, and
<claim-text>wherein comparing the first set of one or more features to the information regarding the node comprises comparing the first set of one or more features of the at least the part of the conversation to the at least one commonly-appearing feature associated with the node.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein:
<claim-text>the node of the taxonomy is further associated with at least one second feature that is more likely to appear in conversations related to the topic to which the node corresponds than to appear in conversations unrelated to the topic to which the node corresponds; and</claim-text>
<claim-text>wherein comparing the one or more features to the information regarding the node comprises comparing the one or more features of the at least the part of the conversation to the at least one commonly-appearing feature and to the at least one second feature associated with the node.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the receiving, comparing, and presenting are performed on the device operated by the first speaker.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the broad topic to which the higher-level node of the taxonomy corresponds is a first broad topic;</claim-text>
<claim-text>the specific topic to which the lower-level node corresponds is a first specific topic;</claim-text>
<claim-text>the taxonomy of the domain-specific model comprises at least one sibling node to the higher-level node at a same level in the hierarchy as the higher-level node, each of the at least one sibling node corresponding to at least one second broad topic;</claim-text>
<claim-text>the taxonomy of the domain-specific model comprises a plurality of child nodes of the higher-level node, the plurality of child nodes comprising the lower-level node and at least one second child node, each of the at least one second child node corresponding to at least one second specific topic related to the first broad topic to which the higher-level node corresponds;</claim-text>
<claim-text>the method further comprises determining a broad topic to which the at least the first part of the conversation relates, the determining comprising the comparing the first set of the one or more features of the at least the first part of the conversation to information regarding the higher-level node and comparing the first set of the one or more features to information regarding the at least one sibling node; and</claim-text>
<claim-text>the method further comprises determining a specific topic to which the at least the second part of the conversation relate, the determining comprising the comparing, in response to determining that the result of the comparing of the first set of the one or more features to the information regarding the higher-level node indicates that the at least the first part of the conversation relates to the first broad topic, the second set of the one or more features to the information regarding the lower-level node and comparing the second set of the one or more features to information regarding each of the at least one second child node of the higher-level node.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the higher-level node of the taxonomy is associated with information comprising a first distribution of features in conversations related to the broad topic;</claim-text>
<claim-text>the lower-level node of the taxonomy is associated with information comprising a second distribution of features in conversations related to the specific topic;</claim-text>
<claim-text>comparing the first set of one or more features of the at least the first part of the conversation to the information regarding the higher-level node comprises comparing information regarding the first set of one or more features in the at least the first part of the conversation to the first distribution of features in conversations related to the broad topic to determine whether the at least the first part of the conversation relates to the broad topic; and</claim-text>
<claim-text>comparing the second set of one or more features of the at least the second part of the conversation to the information regarding the lower-level node comprises comparing information regarding the second set of one or more features of the at least the second part of the conversation to the second distribution of features in conversations related to the specific topic to determine whether the at least the second part of the conversation relate to the specific topic.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An apparatus comprising:
<claim-text>at least one processor; and</claim-text>
<claim-text>at least one computer-readable storage medium having encoded thereon processor-executable instructions that, when executed by the at least one processor, cause the at least one processor to carry out a method comprising:
<claim-text>receiving a first set of one or more features of at least a first part of a conversation between at least a first speaker and a second speaker;</claim-text>
<claim-text>comparing, using at least one processor, the first set of one or more features of the at least the first part of the conversation to information regarding a node of a taxonomy of a domain specific model to determine whether the at least the first part of the conversation relates to a topic to which the node of the taxonomy corresponds, wherein the taxonomy of the domain specific model is hierarchical and comprises a plurality of nodes arranged in different levels of a hierarchy, wherein a higher-level node of the taxonomy corresponds to a broad topic and a lower-level node below the higher-level node in the taxonomy corresponds to a specific topic that relates to the broad topic and is more specific than the broad topic, and wherein comparing the first set of one or more features of the at least the first part of the conversation to the information regarding the node comprises comparing the first set of one or more features to information regarding the higher-level node of the taxonomy to determine whether the at least the first part of the conversation relates to the broad topic, wherein the comparing of the first set of one or more features to the information regarding the higher-level node has a first probability of providing a first prediction accuracy in identifying whether the at least the first part of the conversation relates to the broad topic;</claim-text>
<claim-text>in response to determining that a result of the comparing indicates that the at least the first part of the conversation relates to the broad topic, presenting, to a user interface of a device operated by the first speaker, topic-specific information related to the broad topic;</claim-text>
<claim-text>receiving a second set of one or more features of at least a second part of the conversation, the second part of the conversation including both the first part of the conversation and a subsequent part occurring in the conversation following the first part;</claim-text>
<claim-text>in response to determining that the result of the comparing of the first set of the one or more features to the information regarding the higher-level node indicates that the at least the first part of the conversation relates to the broad topic, comparing the second set of one or more features of the first part and the subsequent part to information regarding the lower-level node to determine whether the at least the second part of the conversation relate to the specific topic related to the broad topic, wherein the comparing of the second set of one or more features to the information regarding the lower-level node has a second probability of providing a second prediction accuracy in identifying whether the at least the second part of the conversation relates to the specific topic, the second prediction accuracy being higher than the first prediction accuracy; and</claim-text>
<claim-text>in response to determining that a result of the comparing of the second set of one or more features to the information regarding the lower-level node indicates that the at least the second part of the conversation relates to the specific topic, presenting to the first speaker topic-specific information related to the specific topic.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:
<claim-text>comparing the first set of one or more features to the information regarding the higher-level node, presenting the topic-specific information related to the broad topic, comparing the second set of one or more features to the information regarding the lower-level node, and presenting topic-specific information related to the specific topic are carried out during the conversation,</claim-text>
<claim-text>comparing the first set of one or more features to information regarding the higher-level node and presenting the topic-specific information related to the broad topic are carried out after receipt of the first set of one or more features of the at least the first part of the conversation and before receipt of the second set of one or more features of the at least the second part of the conversation, and</claim-text>
<claim-text>comparing the second set of one or more features to the information regarding the lower-level node and presenting the topic-specific information related to the specific topic are carried out after receipt of the first set of one or more features of the at least the first part of the conversation and after receipt of the second set of one or more features of the at least the second part of the conversation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein presenting the topic-specific information to the first speaker comprises presenting suggestions to the first speaker of information to provide to the second speaker in the conversation and/or information to obtain from the second speaker in the conversation.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the apparatus is the device operated by the first speaker.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:
<claim-text>the broad topic to which the higher-level node of the taxonomy corresponds is a first broad topic;</claim-text>
<claim-text>the specific topic to which the lower-level node corresponds is a first specific topic;</claim-text>
<claim-text>the taxonomy of the domain-specific model comprises at least one sibling node to the higher-level node at a same level in the hierarchy as the higher-level node, each of the at least one sibling node corresponding to at least one second broad topic;</claim-text>
<claim-text>the taxonomy of the domain-specific model comprises a plurality of child nodes of the higher-level node, the plurality of child nodes comprising the lower-level node and at least one second child node, each of the at least one second child node corresponding to at least one second specific topic related to the first broad topic to which the higher-level node corresponds;</claim-text>
<claim-text>the method further comprises determining a broad topic to which the at least the first part of the conversation relates, the determining comprising the comparing the first set of the one or more features of the at least the first part of the conversation to information regarding the higher-level node and comparing the first set of the one or more features to information regarding the at least one sibling node; and</claim-text>
<claim-text>the method further comprises determining a specific topic to which the at least the second part of the conversation relate, the determining comprising the comparing, in response to determining that the result of the comparing of the first set of the one or more features to the information regarding the higher-level node indicates that the at least the first part of the conversation relates to the first broad topic, the second set of the one or more features to the information regarding the lower-level node and comparing the second set of the one or more features to information regarding each of the at least one second child node of the higher-level node.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:
<claim-text>the higher-level node of the taxonomy is associated with information comprising a first distribution of features in conversations related to the broad topic;</claim-text>
<claim-text>the lower-level node of the taxonomy is associated with information comprising a second distribution of features in conversations related to the specific topic;</claim-text>
<claim-text>comparing the first set of one or more features of the at least the first part of the conversation to the information regarding the higher-level node comprises comparing information regarding the first set of one or more features in the at least the first part of the conversation to the first distribution of features in conversations related to the broad topic to determine whether the at least the first part of the conversation relates to the broad topic; and</claim-text>
<claim-text>comparing the second set of one or more features of the at least the second part of the conversation to the information regarding the lower-level node comprises comparing information regarding the second set of one or more features of the at least the second part of the conversation to the second distribution of features in conversations related to the specific topic to determine whether the at least the second part of the conversation relate to the specific topic.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. At least one computer-readable storage medium having encoded thereon processor-executable instructions that, when executed by at least one processor, cause the at least one processor to carry out a method comprising:
<claim-text>receiving a first set of one or more features of at least a first part of a conversation between at least a first speaker and a second speaker;</claim-text>
<claim-text>comparing, using at least one processor, the first set of one or more features of the at least the first part of the conversation to information regarding a node of a taxonomy of a domain specific model to determine whether the at least the first part of the conversation relates to a topic to which the node of the taxonomy corresponds, wherein the taxonomy of the domain specific model is hierarchical and comprises a plurality of nodes arranged in different levels of a hierarchy, wherein a higher-level node of the taxonomy corresponds to a broad topic and a lower-level node below the higher-level node in the taxonomy corresponds to a specific topic that relates to the broad topic and is more specific than the broad topic, and wherein comparing the first set of one or more features of the at least the first part of the conversation to the information regarding the node comprises comparing the first set of one or more features to information regarding the higher-level node of the taxonomy to determine whether the at least the first part of the conversation relates to the broad topic, wherein the comparing of the first set of one or more features to the information regarding the higher-level node has a first probability of providing a first prediction accuracy in identifying whether the at least the first part of the conversation relates to the broad topic;</claim-text>
<claim-text>in response to determining that a result of the comparing indicates that the at least the first part of the conversation relates to the broad topic, presenting, to a user interface of a device operated by the first speaker, topic-specific information related to the broad topic;</claim-text>
<claim-text>receiving a second set of one or more features of at least a second part of the conversation, the second part of the conversation including both the first part of the conversation and a subsequent part occurring in the conversation following the first part;</claim-text>
<claim-text>in response to determining that the result of the comparing of the first set of the one or more features to the information regarding the higher-level node indicates that the at least the first part of the conversation relates to the broad topic, comparing the second set of one or more features of the first part and the subsequent part to information regarding the lower-level node to determine whether the at least the second part of the conversation relate to the specific topic related to the broad topic, wherein the comparing of the second set of one or more features to the information regarding the lower-level node has a second probability of providing a second prediction accuracy in identifying whether the at least the second part of the conversation relates to the specific topic, the second prediction accuracy being higher than the first prediction accuracy; and</claim-text>
<claim-text>in response to determining that a result of the comparing of the second set of one or more features to the information regarding the lower-level node indicates that the at least the second part of the conversation relates to the specific topic, presenting to the first speaker topic-specific information related to the specific topic.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The at least one computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein:
<claim-text>comparing the first set of one or more features to the information regarding the higher-level node, presenting the topic-specific information related to the broad topic, comparing the second set of one or more features to the information regarding the lower-level node, and presenting topic-specific information related to the specific topic are carried out during the conversation,</claim-text>
<claim-text>comparing the first set of one or more features to information regarding the higher-level node and presenting the topic-specific information related to the broad topic are carried out after receipt of the first set of one or more features of the at least the first part of the conversation and before receipt of the second set of one or more features of the at least the second part of the conversation, and</claim-text>
<claim-text>comparing the second set of one or more features to the information regarding the lower-level node and presenting the topic-specific information related to the specific topic are carried out after receipt of the first set of one or more features of the at least the first part of the conversation and after receipt of the second set of one or more features of the at least the second part of the conversation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The at least one computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein presenting the topic-specific information to the first speaker comprises presenting suggestions to the first speaker of information to provide to the second speaker in the conversation and/or information to obtain from the second speaker in the conversation.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The at least one computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein presenting the topic-specific information to the first speaker comprises displaying the topic-specific information to the first speaker.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The at least one computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein:
<claim-text>the broad topic to which the higher-level node of the taxonomy corresponds is a first broad topic;</claim-text>
<claim-text>the specific topic to which the lower-level node corresponds is a first specific topic;</claim-text>
<claim-text>the taxonomy of the domain-specific model comprises at least one sibling node to the higher-level node at a same level in the hierarchy as the higher-level node, each of the at least one sibling node corresponding to at least one second broad topic;</claim-text>
<claim-text>the taxonomy of the domain-specific model comprises a plurality of child nodes of the higher-level node, the plurality of child nodes comprising the lower-level node and at least one second child node, each of the at least one second child node corresponding to at least one second specific topic related to the first broad topic to which the higher-level node corresponds;</claim-text>
<claim-text>the method further comprises determining a broad topic to which the at least the first part of the conversation relates, the determining comprising the comparing the first set of the one or more features of the at least the first part of the conversation to information regarding the higher-level node and comparing the first set of the one or more features to information regarding the at least one sibling node; and</claim-text>
<claim-text>the method further comprises determining a specific topic to which the at least the second part of the conversation relate, the determining comprising the comparing, in response to determining that the result of the comparing of the first set of the one or more features to the information regarding the higher-level node indicates that the at least the first part of the conversation relates to the first broad topic, the second set of the one or more features to the information regarding the lower-level node and comparing the second set of the one or more features to information regarding each of the at least one second child node of the higher-level node. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
