<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08626682-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08626682</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13046266</doc-number>
<date>20110311</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>278</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>18</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>706 12</main-classification>
</classification-national>
<invention-title id="d2e53">Automatic data cleaning for machine learning classifiers</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2002/0111755</doc-number>
<kind>A1</kind>
<name>Valadarsky et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702 58</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2004/0024769</doc-number>
<kind>A1</kind>
<name>Forman et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2006/0282415</doc-number>
<kind>A1</kind>
<name>Shibata et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2008/0162390</doc-number>
<kind>A1</kind>
<name>Kapoor et al.</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 20</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2010/0332474</doc-number>
<kind>A1</kind>
<name>Birdwell et al.</name>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2011/0282878</doc-number>
<kind>A1</kind>
<name>Bird et al.</name>
<date>20111100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2012/0197890</doc-number>
<kind>A1</kind>
<name>Franks et al.</name>
<date>20120800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>EP</country>
<doc-number>1903479</doc-number>
<kind>A1</kind>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>WO</country>
<doc-number>03/021421</doc-number>
<kind>A1</kind>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00010">
<othercit>Nigam K et al, &#x201c;Text Classification from Labeled and Unlabeled Documents using EM&#x201d;, Machine Learning, Kluwer Academic Publishers, Boston, US, vol. 39, No. 2/3, Jan. 1, 2000, pp. 103-134.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00011">
<othercit>Hassan H Malik et al, &#x201c;Automatic Training Data Cleaning for Text Classification&#x201d;, Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on, IEEE, Dec. 11, 2011, pp. 442-449.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00012">
<othercit>US Office Action issued in a related U.S. Appl. No. 13/107,665 dated Oct. 19, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00013">
<othercit>Hassan H Malik, &#x201c;Efficient Algorithms for clustering and Classifying High dimensional Text and Discretized Data using Interesting Patterns&#x201d;, submitted in partial fulfillment of the Requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences, Retrieved from the Internet: URL:http://www.cs.columbia.edu/-hhm2104/papers/Malik thesis.pdf, Dec. 31, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00014">
<othercit>Hassan H Malik et al, &#x201c;High Quality,Efficient Hierarchical Document Clustering Using Closed Interesting Itemsets&#x201d;, Data Mining, 2006. ICDM '06. Sixth International Conference on, IEEE, PI, Dec. 1, 2006, pp. 991-996.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00015">
<othercit>Padmanabhan B et al: &#x201c;Unexpectedness as a Measure of Interestingness in Knowledge Discovery&#x201d;, Decision Support Systems, Elsevier Science Publishers, Amsterdam, NL, vol. 27, No. 3, Dec. 13, 1997, pp. 303-318.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00016">
<othercit>Hassan H Malik et al, &#x201c;Exploring the corporate ecosystem with a semi-supervised entity graph&#x201d;, Proceedings of the 20th ACM Conference on Information and Knowledge Management, CIKM 201, Retrieved from the Internet: URL:http://www.cs.columbia.edu/-hhm2104/papers/Atlas CIKM 2011.pdf, Oct. 28, 2011, pp. 1857-1866.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00017">
<othercit>Jacobs P S et al, &#x201c;A friendly merger of conceptual expectations and linguistic analysis in a text processing system,&#x201d; Proceedings of the Conference on Artificial Intelligence Applications. San Diego. Mar. 16-18, 1988; [Proceedings of the Conference on Artificial Intelligence Applications]. Washington. IEEE COMPo Soc. Press. US. vol. Conf. 4,Mar. 14, 1988, pp. 351-356.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00018">
<othercit>Peggy M. Andersen et al, &#x201c;Automatic Extraction of Facts from Press Releases to Generate News Stories&#x201d;, ANLC '92 Proceedings of the Third Conference on Applied Natural Language Processing, Jan. 1, 1992, pp. 170-177.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00019">
<othercit>Alexander Hogenboom et al, &#x201c;Semantics-based information extraction for detecting economic events&#x201d;, Multimedia Tools and Applications, Jan. 1, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00020">
<othercit>Jethro Borsje et al, &#x201c;Semi-Automatic Financial Events Discovery Based on Lexico-Semantic Patterns&#x201d;, International Journal of Web Engineering and Technology, vol. 6. No. 2, Jan. 1, 2010, pp. 115-140.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00021">
<othercit>Martina Naughton et al, &#x201c;Investigating Statistical Techniques for Sentence-Level Event Classification&#x201d;, Proceedings of the 22nd International Conference on Computational Linguistics (Coling '08), Aug. 1, 2008, pp. 617-624.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00022">
<othercit>Wang Y-Y et al, &#x201c;Combination of Statistical and Rule-Based Approaches for Spoken Language Understanding&#x201d;, Proceedings of the International Conference on Spoken LanguageProcessing, XX, XX, Sep. 1, 2002, pp. 609-612.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00023">
<othercit>Hassan H. Malik et al, &#x201c;Accurate Information Extraction for Quantitative Financial Events&#x201d;, Proceedings of the 20th ACM Conference on Information and Knowledge Management, CIKM 201, Oct. 28, 2011, pp. 2497-2500.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00024">
<othercit>Cooper J W et al, &#x201c;Detecting Similar Documents Using Salient Terms&#x201d;, CIKM'02; [International Conference on Information Knowledge Management], Virginia, USA, Retrieved from the Internet: URL:http://portal.acm.org/ft<sub>&#x2014;</sub>gateway.cfm?id=584835&#x26;type=pdf&#x26;coll=GUIDE&#x26;dl=GUIDE&#x26;CFID=95314629&#x26;CFTOKEN=916126962002-11-04, pp. 1-6</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00025">
<othercit>Toru Takaki et al, &#x201c;Associative document retrieval by query subtopic analysis and its application to invalidity patent search&#x201d;, Proceedings of the Thirteenth ACM Conference on Information and Knowledge Management. CIKM '04. Jan. 1, 2004, p. 399.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00026">
<othercit>Henning Rode, &#x201c;From Document to Entity Retrieval&#x201d;, CTIT Ph.D. Thesis Series No. 08-120, University Twente. Netherlands, Retrieved from the Internet: URL:http://doc.utwente.nl/60765/1/thesis HRode.pdf, Dec. 31, 2008.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00027">
<othercit>International Search Report and Written Opinion of the International Searching Authority issued for the related PCT International application No. PCT/US2012/025930 on Aug. 21, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00028">
<othercit>International Search Report and Written Opinion of the International Searching Authority issued for the related PCT International application No. PCT/US2012/025937 on Jul. 24, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00029">
<othercit>International Search Report and Written Opinion of the International Searching Authority issued for the related PCT International application No. PCT/US2012/034871 on Oct. 19, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00030">
<othercit>International Search Report and Written Opinion of the International Searching Authority issued for the related PCT International application No. PCT/US2012/025942 on Jul. 26, 2012.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>27</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>706 12</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61445236</doc-number>
<date>20110222</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120215727</doc-number>
<kind>A1</kind>
<date>20120823</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Malik</last-name>
<first-name>Hassan H.</first-name>
<address>
<city>Monmouth Junction</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Olof-Ors</last-name>
<first-name>Mans</first-name>
<address>
<city>Lucerne</city>
<country>CH</country>
</address>
</addressbook>
<residence>
<country>CH</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Malik</last-name>
<first-name>Hassan H.</first-name>
<address>
<city>Monmouth Junction</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Olof-Ors</last-name>
<first-name>Mans</first-name>
<address>
<city>Lucerne</city>
<country>CH</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>DiVita</last-name>
<first-name>Bartholomew</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<orgname>Thomson Reuters</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Thomson Reuters Global Resources</orgname>
<role>03</role>
<address>
<city>Baar</city>
<country>CH</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Gaffin</last-name>
<first-name>Jeffrey A</first-name>
<department>2129</department>
</primary-examiner>
<assistant-examiner>
<last-name>Afolabi</last-name>
<first-name>Ola Olude</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Systems and techniques for improving the training of machine learning classifiers are disclosed. A classifier is trained using a set of validated documents that are accurately associated with a set of class labels. A subset of non-validated documents is also identified and is used to further train and improve accuracy of the classifier.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="165.10mm" wi="263.65mm" file="US08626682-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="199.31mm" wi="184.57mm" file="US08626682-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="263.40mm" wi="164.08mm" orientation="landscape" file="US08626682-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="237.74mm" wi="148.67mm" orientation="landscape" file="US08626682-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="175.60mm" wi="178.14mm" file="US08626682-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims priority to U.S. Provisional Application No. 61/445,236 filed Feb. 22, 2011, entitled &#x2018;Information Processing and Visualization Methods and Systems&#x2019;, the content of which is incorporated herein by reference in its entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">TECHNICAL FIELD</heading>
<p id="p-0003" num="0002">This disclosure relates to machine learning, and more particularly to systems and methods for improving accuracy of machine learning classifiers.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">Today, there is increasing interest in the use of machine learning for analyzing data. Machine learning refers to the design and development of computer algorithms that allow computers to recognize complex patterns and make intelligent decisions based on empirical data.</p>
<p id="p-0005" num="0004">Typically, a machine learning system that performs text classification on documents includes a classifier. The classifier is provided training data in which each document is already labeled (e.g., identified) with a correct label or class. The labeled document data is used to train a learning algorithm of the classifier which is then used to label/classify similar documents. The accuracy of the classifier is inextricably dependent upon the quality and quantity of correctly labeled documents included in the training data.</p>
<p id="p-0006" num="0005">Typically, training data for the classifier is derived from experts that manually assign class labels to documents. Manual assignment, however, inherently exhibits a certain level of inconsistency because experts with varying levels of domain knowledge and experience may interpret the same class differently. In addition, the tedious nature of manual assignment can further aggravate the requirement that large amounts of correctly labeled documents be provided to classifiers in order to generalize well. Furthermore, manual assignment of class labels by experts can be an expensive process.</p>
<p id="p-0007" num="0006">Accordingly, there is a need for improved systems and techniques for generating training data for classifiers.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0008" num="0007">Systems and techniques for improving the training of machine learning classifiers are disclosed. A classifier is trained using a set of validated documents that are accurately associated with a set of class labels. A subset of non-validated documents is also identified and is used to further train and improve accuracy of the classifier.</p>
<p id="p-0009" num="0008">Various aspects of the system relate to generating training data and training classifiers using the generated training data.</p>
<p id="p-0010" num="0009">For example, according to one aspect, a method of training an initially trained classifier (ITC) that was generated using a set of verified documents associated with a set of class labels is disclosed. The set of verified documents is divided into a training set of documents and a test set of documents, and each class of the set of class labels is associated with a class list. The training set of documents having been further divided into an integer number of verified document sets (INVDS), the method including automatically inputting a set of unverified documents into the ITC, the set of unverified documents divided into an integer number of unverified document sets (UNVDS), and automatically identifying a subset of documents from the set of unverified documents. The method also includes automatically generating a final set of training documents based on the subset of documents and the set of verified documents, and training the ITC using the final set of training documents. The method can also include training a plurality of classifiers using the final set of training documents, and applying the plurality of classifiers to the test set of documents.</p>
<p id="p-0011" num="0010">In one embodiment, the method further includes executing a first loop code segment including a first loop construct written in a computer programming language, wherein the first loop code segment is executed at run time at least n times, wherein n is a value at run time of a first variable in a first loop termination condition, executing a second loop code segment including a second loop construct written in the computer programming language, wherein the second loop code segment is executed at least p&#xd7;n times, wherein p is a value at run time of a second variable in a second loop termination condition, and executing a third loop code segment comprising a third loop construct written in the computer programming language, wherein the third loop code segment is executed p&#xd7;n&#xd7;q times, wherein q is a value at run time of a third variable in a third loop termination condition.</p>
<p id="p-0012" num="0011">In one embodiment, for each of the n times the first loop code is executed, the method includes assigning a first portion of the INVDS to a first set of documents, assigning a second portion of the INVDS to a second set of documents, the first portion different from the second portion, and training the ITC for each class associated with the set of class labels using documents in the first set of documents. The method also includes applying a plurality of classifiers to the documents in the second set of documents, and computing a first set of F1 scores associated with documents in the second set of documents. The first set of documents and the second set of documents may have no documents in common.</p>
<p id="p-0013" num="0012">In another embodiment, for each of the p times the second loop code is executed, the method includes applying at least one profile of a set of profiles to each document of the UNVDS, the at least one profile defining a rule to be applied to each document of the UNVDS, comparing at least one document of the UNVDS to all of the documents included in the first set of documents, and deleting the at least one document from the UNVDS based on the comparison. The rule may include a class label retention scheme, a class label addition scheme, or a combination thereof.</p>
<p id="p-0014" num="0013">The method can include applying a plurality of profiles included in the set of profiles to each document of the UNVDS in a decreasing order of profile strictness. In addition, in one embodiment, if the at least one document from the UNVDS is similar to any of the documents included in the first set of documents, the at least one document from the UNVDS is deleted. Comparing the at least one document can include computing a cosine similarity for the at least one document.</p>
<p id="p-0015" num="0014">In yet another embodiment, for each of the p times the second loop code is executed, the method includes forming a third set of documents by merging documents included in the first set of documents with documents not deleted from the UNVDS, and clustering the third set of documents using a clustering algorithm.</p>
<p id="p-0016" num="0015">The method can also include, for each of the q times the third loop code is executed, applying the ITC to all documents in the UNVDS for each class defined in the set of class labels, forming a subset of documents from the UNVDS, each document of the subset of documents having at least one class associated therewith, training a second classifier using documents in the subset of documents and the first set of documents, and applying the second classifier to the second set of documents.</p>
<p id="p-0017" num="0016">In one embodiment, the method further includes computing a second set of F1 scores associated with documents in the second set of documents, comparing an F1 score associated with a class label from the second set of F1 scores to a corresponding F1 score associated with the class label from the first set of F1 scores, updating a best score for the class label based on the comparison, and adding documents from the subset of documents to the list of class labels based on the comparison.</p>
<p id="p-0018" num="0017">A system, as well as articles that include a machine-readable medium storing machine-readable instructions for implementing the various techniques, are disclosed. Details of various embodiments are discussed in greater detail below.</p>
<p id="p-0019" num="0018">Additional features and advantages will be readily apparent from the following detailed description, the accompanying drawings and the claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic of an exemplary computer-based classifier system according to one embodiment of the present invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. 2A-B</figref> illustrate an exemplary method of improving training data for classifiers according to one embodiment of the present invention</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 3</figref> is an example of label retention and addition schemes according to one embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0023" num="0022">Like reference symbols in the various drawings indicate like elements.</p>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0024" num="0023">The present invention includes methods and systems which facilitate automatic data cleansing (e.g., removal of noise, inconsistent data and errors) of data for training classifiers. In particular, methods and systems for optimizing the amount of training data available to train an initially trained classifier (ITC) are disclosed. The present invention is particularly beneficial in scenarios in which training data is limited, which can have a significant effect on the accuracy of a classifier.</p>
<p id="p-0025" num="0024">It is known that data cleansing of training data often yields higher accuracy gains than improvements in machine learning algorithms. This invention is useful by providing gains in classifier accuracy as a result of training on larger sets of cleaner data. Decreased production costs can also be obtained by not requiring experts to manually assign class labels to all training documents. Advantageously, the present invention can be used with different types of classifiers and domains as a general purpose method to be used when developing and training machine learning classifiers.</p>
<p id="p-0026" num="0025">The following definitions are provided to facilitate understanding of the disclosure and are standard machine learning terms.</p>
<p id="p-0027" num="0026">As used herein, the term &#x201c;classifier&#x201d; refers to a software component that accepts unlabeled documents as inputs and returns discrete classes. Classifiers are trained on labeled documents prior to being used on unlabeled documents.</p>
<p id="p-0028" num="0027">As used herein, the term &#x201c;training&#x201d; refers to the process by which a classifier generates models and/or patterns from a training data set. A training data set comprises documents that have been mapped (e.g., labeled) to &#x201c;known-good&#x201d; classes.</p>
<p id="p-0029" num="0028">As used herein, the term &#x201c;document&#x201d; refers to a set of information input into a classifier. Example documents include, but are not limited to, electronic files and records.</p>
<p id="p-0030" num="0029">As used herein, the term &#x201c;class&#x201d; refers to a discrete category with which a document is associated. The classifier's function is to predict the discrete category (e.g., label, class) to which a document belongs.</p>
<p id="p-0031" num="0030">As used herein, the term &#x201c;labeling&#x201d; refers to the process of associating a document to a set of correct classes.</p>
<p id="p-0032" num="0031">As used herein, the term &#x201c;accuracy&#x201d; refers to the rate of correct or incorrect labeling performed by a classifier over a test data set.</p>
<p id="p-0033" num="0032">As used herein, the phrase &#x201c;test data&#x201d; refers to a data set used for estimating accuracy. Turning now to <figref idref="DRAWINGS">FIG. 1</figref>, an example of a suitable computing system <b>10</b> within which embodiments of the present invention may be implemented is disclosed. The computing system <b>10</b> is only one example and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing system <b>10</b> be interpreted as having any dependency or requirement relating to any one or combination of illustrated components.</p>
<p id="p-0034" num="0033">For example, the present invention is operational with numerous other general purpose or special purpose computing consumer electronics, network PCs, minicomputers, mainframe computers, laptop computers, as well as distributed computing environments that include any of the above systems or devices, and the like.</p>
<p id="p-0035" num="0034">The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, loop code segments and constructs, etc. that perform particular tasks or implement particular abstract data types. The invention can be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules are located in both local and remote computer storage media including memory storage devices. Tasks performed by the programs and modules are described below and with the aid of figures. Those skilled in the art can implement the description and figures as processor executable instructions, which can be written on any form of a computer readable media.</p>
<p id="p-0036" num="0035">In one embodiment, with reference to <figref idref="DRAWINGS">FIG. 1</figref>, the system <b>10</b> includes a server device <b>12</b> configured to include a processor <b>14</b>, such as a central processing unit (&#x2018;CPU&#x2019;), random access memory (&#x2018;RAM&#x2019;) <b>16</b>, one or more input-output devices <b>18</b>, such as a display device (not shown) and keyboard (not shown), and non-volatile memory <b>20</b>, all of which are interconnected via a common bus <b>22</b> and controlled by the processor <b>14</b>. As shown in the <figref idref="DRAWINGS">FIG. 1</figref> example, in one embodiment, the non-volatile memory <b>20</b> is configured to include a classifier analyzer <b>24</b> for generating a set of training documents, and one or more machine learning classifiers <b>26</b> that are trained using the generated set of training documents. In one embodiment, the machine learning classifiers are binary text classifiers. Additional details of the classifier module <b>24</b> and machine learning classifiers <b>26</b> are discussed in greater detail below.</p>
<p id="p-0037" num="0036">The network <b>28</b> can include various devices such as routers, server, and switching elements connected in an Intranet, Extranet or Internet configuration. In one embodiment, the network <b>28</b> uses wired communications to transfer information between an access device (not shown), the server device <b>12</b>, and an operational data store <b>30</b>. In another embodiment, the network <b>28</b> employs wireless communication protocols to transfer information between the access device, the server device <b>12</b>, and operational data store <b>30</b>. In yet other embodiments, the network employs a combination of wired and wireless technologies to transfer information between the access device, the server device <b>12</b>, and the operational data store <b>30</b>.</p>
<p id="p-0038" num="0037">The operational data store <b>30</b> is a repository that maintains and stores information utilized by the classifier analyzer <b>24</b> and the machine learning classifiers <b>26</b>. In one embodiment, the operational data store <b>30</b> is a relational database. In another embodiment, the operational data store <b>30</b> is a directory server, such as a Lightweight Directory Access Protocol (&#x2018;LDAP&#x2019;). In yet another embodiment, the operational data store <b>30</b> is an area of non-volatile memory <b>20</b> of the server <b>12</b>.</p>
<p id="p-0039" num="0038">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, in one embodiment, the operational data store <b>30</b> includes a class data store (CLS) <b>32</b> that stores an taxonomy of class labels that are used in classifying a document into one or more discrete categories. An uncertified document data store (UDS) <b>33</b> is also provided that includes a set of documents having zero (0) or more class labels associated with each document, and which has not been independently validated by an expert, and a certified document data store (CDS) <b>34</b> that includes a set of documents having one (1) or more class labels associated with each document and which has been independently verified by an expert.</p>
<p id="p-0040" num="0039">As shown in the <figref idref="DRAWINGS">FIG. 1</figref> example, the operational data store <b>30</b> is also configured to maintain and store a profile data store (PROFILES) <b>35</b> that include profiles defining rules/schemas for adding and retaining class labels associated with documents, and a result data store (FTDS) <b>36</b> that includes training data generated by the classifier analyzer <b>24</b> by combining documents stored in the CDS <b>34</b> with a select subset of documents stored in the UDS <b>33</b>. Additional details of each of these data stores <b>32</b>-<b>36</b> are discussed in connection with <figref idref="DRAWINGS">FIGS. 2A-B</figref>.</p>
<p id="p-0041" num="0040">Although the operational data store <b>30</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> is connected to the network <b>28</b>, it will be appreciated by one skilled in the art that the operational data store <b>30</b> and/or any of the data stores <b>32</b>-<b>36</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>, can be distributed across various servers and be accessible to the server <b>12</b> over the network <b>28</b>, be coupled directly to the server <b>12</b>, or be configured in an area of non-volatile memory <b>20</b> of the server <b>12</b>.</p>
<p id="p-0042" num="0041">Further, it should be noted that the system <b>10</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> is one embodiment of the disclosure. Other system embodiments of the disclosure may include additional structures that are not shown, such as secondary storage and additional computational devices. In addition, various other embodiments of the disclosure include fewer structures than those shown in <figref idref="DRAWINGS">FIG. 1</figref>. For example, in one embodiment, the disclosure is implemented on a single computing device in a non-networked standalone configuration. Data input is communicated to the computing device via an input device, such as a keyboard and/or mouse. Data output of the system is communicated from the computing device to a display device, such as a computer monitor.</p>
<p id="p-0043" num="0042">Referring now to <figref idref="DRAWINGS">FIGS. 2A-B</figref>, a computer-implemented method for training an initially trained classifier (ITC) using a set of training documents generated by the classifier analyzer <b>24</b> is disclosed. The method includes executing a plurality of loop code segments that include loop constructs written in a computer programming language. Each of the loop code segments is executed at run time a number of times based on a value at run time of variables included in corresponding loop termination conditions. In one embodiment, the method is implemented using three loop code segments and corresponding loop termination conditions. In another embodiment, as set forth below, the method is implemented using four loop code segments with corresponding loop termination conditions.</p>
<p id="p-0044" num="0043">For example, in one embodiment, as shown at step <b>40</b> of <figref idref="DRAWINGS">FIG. 2A</figref>, the classifier analyzer <b>24</b> initializes a list of document candidates (LST) for each class defined in the CLS data store <b>32</b>. The document list LST is used by the classifier analyzer <b>24</b> to store document candidates that are to be added to training data. At initialization, the LST includes no documents. Next, at step <b>42</b>, the classifier analyzer <b>24</b> initializes a plurality of counter variables C1, C2, C3 and C4 to a value of one (1). Each of the plurality of counter variables C1, C2, C3, C4 is used to determine the number of times loop code segments are to be executed. Once counter variable and list initializations are complete, at step <b>44</b>, the classifier analyzer <b>24</b> divides documents included in the CDS data store <b>34</b> into a training set (TRN) and a test set (TST) of documents. The TRN data set includes documents that have been accurately labeled to known-group classes and the TST data set includes documents that are used for estimating accuracy of machine learning classifiers trained on the TRN data set. In one embodiment, the classifier analyzer <b>24</b> randomly splits the set of documents into the TRN and TST set of documents based on a user-defined percentage associated with the TRN and TST set of documents, respectively.</p>
<p id="p-0045" num="0044">Next, at step <b>46</b>, the classifier analyzer <b>24</b> divides the TRN data set into a plurality of K document sets, where K is an integer value. In one embodiment, the number of documents included in each of the K document sets is approximately equal. Once the TRN data set is divided into K document sets, at step <b>48</b>, the classifier analyzer <b>24</b> assigns all documents of the K document sets to a total document set (TD) excluding one of the documents sets referenced by counter variable C1, hereinafter referred to as the K(C1) data set. Next, at step <b>50</b>, the classifier analyzer <b>24</b> assigns the K(C1) data set to a single document set (SD).</p>
<p id="p-0046" num="0045">Next, at step <b>52</b>, a first classifier of the machine learning classifiers <b>26</b> is trained for each class in the CLS data store <b>32</b> using documents in the TD set. The classifier analyzer <b>24</b>, at step <b>54</b>, next applies all machine learning classifiers <b>26</b> to the SD set of documents. In one embodiment, the classifier analyzer <b>24</b> computes and records F1 scores (e.g., a measure of a test's accuracy that considers both the precision (p) and recall (r) of the test, as known in the art) for each class determined. Once the machine learning classifiers <b>26</b> are trained, at step <b>56</b>, the classifier analyzer <b>24</b> divides documents from the UDS <b>33</b> into N data sets of UDS documents, where N is an integer value.</p>
<p id="p-0047" num="0046">Once documents from the UDS <b>33</b> are divided into N data sets, the classifier analyzer <b>24</b>, at step <b>58</b>, applies a plurality of label retention and addition rules/schemes accessed from the PROFILES data store <b>35</b> to one of the N data sets. The particular N data set is identified based on the value stored in counter variable C2, hereinafter referred to as N(C2), and the particular label retention and addition rule/scheme applied to the N data set is based on the value of counter variable C3. Each rule is associated with a criterion that if met, triggers the rule. In one embodiment, the rules are applied to the N data set based on a descending order of strictness (e.g., criteria that must be met).</p>
<p id="p-0048" num="0047">Example label retention and addition schemes are shown in connection with <figref idref="DRAWINGS">FIG. 3</figref>. These schemes add or retain labels by considering how well the existing labeled data predicts classes for each unlabeled document. The phrase &#x201c;cluster neighborhood&#x201d; refers to a set of documents that appear in any cluster. An unlabeled document is considered part of a &#x201c;high-confidence&#x201d; cluster neighborhood for a class &#x201c;c&#x201d; if it is clustered with at-least K labeled documents that belong to class &#x201c;c.&#x201d; Other clustering algorithm specific criteria are also possible for considering a cluster neighborhood as &#x201c;high-confidence.&#x201d;</p>
<p id="p-0049" num="0048">For example, the criteria for the scheme shown in <figref idref="DRAWINGS">FIG. 3</figref> item 1 requires that in order to retain a class label &#x201c;c&#x201d; that is already assigned to an unlabeled document &#x201c;d&#x201d;, or to add class label &#x201c;c&#x201d; to unlabeled document &#x201c;d&#x201d;, document &#x201c;d&#x201d; must appear in the &#x201c;high-confidence&#x201d;neighborhood for &#x201c;c&#x201d; and be assigned with class label &#x201c;c&#x201d; by a classifier trained on labeled data. The criteria for the scheme shown in <figref idref="DRAWINGS">FIG. 3</figref> item 2 requires that in order to retain a class label &#x201c;c&#x201d; that is already assigned to an unlabeled document &#x201c;d&#x201d;, or to add class label &#x201c;c&#x201d; to unlabeled document &#x201c;d&#x201d;, document &#x201c;d&#x201d; must appear in at least one cluster that also contains at least one existing document that is labeled with &#x201c;c&#x201d;, and be assigned with class label &#x201c;c&#x201d; by a classifier trained on labeled data.</p>
<p id="p-0050" num="0049">Referring back to <figref idref="DRAWINGS">FIG. 2A</figref>, at step <b>60</b>, the classifier analyzer <b>24</b> removes any document in the N(C2) data set that is similar to any document in the TD data set. In one embodiment, the classifier analyzer <b>24</b> applies cosine similarity to determine document similarity and removes any document from the N(C2) data set where the computed cosine value equals or exceeds a pre-determined value. The classifier analyzer <b>24</b>, at step <b>62</b>, then forms a new set L of documents by merging all remaining documents in the N(C2) data set with the TD data set. In one embodiment, at step <b>64</b>, the classifier analyzer <b>24</b> then clusters the set L of documents using a clustering algorithm. Various clustering techniques known in the art can be used to cluster the set L of documents.</p>
<p id="p-0051" num="0050">Next, at step <b>66</b>, the first classifier of the machine learning classifiers <b>26</b> is trained on all remaining documents of the N(C2) data set associated with a class in the CLS data store <b>32</b>, which is referenced by a value stored in the C4 variable. At step <b>68</b>, the classifier analyzer <b>24</b> then applies label retention and addition rules/schemes accessed from the PROFILES data store <b>35</b> to all documents in the N(C2) data set for the associated class.</p>
<p id="p-0052" num="0051">Once the label retention and addition rules have been applied, at step <b>70</b>, the classifier analyzer <b>24</b> forms a Q document data store from a subset of the N(C2) data set where the class, referenced by the C4 variable, has been assigned. At step <b>72</b>, a second classifier of the machine learning classifiers <b>26</b> is then trained using documents of the TD data set and the Q document data store. Next, at step <b>74</b>, the second classifier of the machine learning classifiers <b>26</b> is applied to the SD data set and an F1 score for the class in the CLS data store <b>32</b> referenced by the value C4 is computed by the classifier analyzer <b>24</b>.</p>
<p id="p-0053" num="0052">At step <b>76</b>, the classifier analyzer <b>24</b> compares the computed F1 score for the class referenced by the value C4 with a current best score for the class. If the classifier analyzer <b>24</b> determines that the computed F1 score for the class is higher than a previously stored best score for the class, as shown in step <b>78</b>, the classifier analyzer <b>24</b> updates the best score value for the class, as indicated in step <b>80</b>, adds documents from the Q document data store to the list of document candidates LST, as indicated in step <b>82</b>, and then increments C4, as indicated in step <b>84</b>.</p>
<p id="p-0054" num="0053">Next, at step <b>86</b>, a first loop termination condition is evaluated. The classifier analyzer <b>24</b> determines whether the value store in counter variable C4 is greater than the total number of classes stored in the CLS data store <b>32</b>. If the value of counter variable C4 is not greater than the total number of classes, steps <b>66</b>-<b>86</b> of the above described method are repeated in a first loop code segment. Otherwise, as shown at step <b>87</b>, the classifier analyzer <b>24</b> increments C2.</p>
<p id="p-0055" num="0054">Next, at step <b>88</b>, a second loop termination condition is evaluated. The classifier analyzer <b>24</b> determines whether the value stored in the counter variable C2 is greater than the number of N data sets. If the value of counter variable C2 is not greater than the number of N data sets, steps <b>60</b>-<b>88</b> of a second loop code segment are repeated. Otherwise, if the value of the C2 variable exceeds the number of N data sets, at step <b>90</b>, the classifier analyzer <b>24</b> increments C3.</p>
<p id="p-0056" num="0055">Next, at step <b>92</b>, the classifier analyzer <b>24</b> compares the value of variable C3 to a total number of label retention and addition rules/schemes stored in the PROFILES data store <b>35</b>. If the value of counter variable C3 does not exceed the total number of label retention and addition rules/schemes stored in the PROFILES data store <b>35</b>, steps <b>58</b>-<b>92</b> of a third loop code segment are repeated. Otherwise, if the value of the counter variable C3 exceeds the total number of label retention and addition rule/schemes, as shown at step <b>94</b>, the classifier analyzer <b>24</b> increments C1, and determines at step <b>96</b> whether the value of counter variable C1 exceeds the total number of K data sets. If the value of counter variable C1 does not exceed the total number of K data sets, steps <b>48</b>-<b>96</b> of a fourth loop code segment are repeated.</p>
<p id="p-0057" num="0056">Otherwise, at step <b>98</b>, for each class defined in the CLS data store, a predetermined number of documents are added to the TRN data set. For example, in one embodiment, the top 20 documents from the list of document candidates LST are added to the TRN data store. Next, at step <b>100</b>, all machine learning classifiers are retrained using all of the documents in the original TRN data set as both positive and negative documents and documents identified from the LST data store as being positive. The positive and negative documents for a class &#x201c;c&#x201d; are used by machine learning classifiers to generate a model that is likely to assign class &#x201c;c&#x201d; to unlabeled documents that match more characteristics of documents that were marked as positive for &#x201c;c&#x201d;, and less characteristics of documents that were marked as negative for &#x201c;c.&#x201d; All retrained machine learning classifiers <b>26</b> are then applied to the TST data store, as indicated in step <b>102</b>. Lastly, as indicated in step <b>104</b>, the classifier analyzer <b>24</b> stores all documents in the TRN data set in the FTDS <b>104</b> for subsequent use by the machine learning classifiers <b>26</b>.</p>
<p id="p-0058" num="0057">Various features of the system may be implemented in hardware, software, or a combination of hardware and software. For example, some features of the system may be implemented in one or more computer programs executing on programmable computers. Each program may be implemented in a high level procedural or object-oriented programming language to communicate with a computer system or other machine. Furthermore, each such computer program may be stored on a storage medium such as read-only-memory (ROM) readable by a general or special purpose programmable computer or processor, for configuring and operating the computer to perform the functions described above.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of training an initially trained classifier (ITC), the ITC having been generated using a set of verified documents associated with a set of class labels, the set of verified documents having been divided into a training set of documents and a test set of documents, and each class of the set of class labels associated with a class list, the training set of documents having been further divided into an integer number of verified document sets (INVDS), the method comprising:
<claim-text>automatically inputting a set of unverified documents into the ITC, the set of unverified documents divided into an integer number of unverified document sets (UNVDS);</claim-text>
<claim-text>automatically identifying a subset of documents from the UNVDS;</claim-text>
<claim-text>automatically generating a final set of training documents based on the subset of documents and the INVDS;</claim-text>
<claim-text>clustering at least one subset of documents from the INVDS and one subset of documents from the UNVDS using a flat clustering or hierarchical clustering technique; and</claim-text>
<claim-text>training the ITC using the final set of training documents.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>executing a first loop code segment comprising a first loop construct written in a computer programming language, wherein the first loop code segment is executed at run time at least n times, wherein n is a value at run time of a first variable in a first loop termination condition;</claim-text>
<claim-text>executing a second loop code segment comprising a second loop construct written in the computer programming language, wherein the second loop code segment is executed at least p&#xd7;n times, wherein p is a value at run time of a second variable in a second loop termination condition; and</claim-text>
<claim-text>executing a third loop code segment comprising a third loop construct written in the computer programming language, wherein the third loop code segment is executed p&#xd7;n&#xd7;q times, wherein q is a value at run time of a third variable in a third loop termination condition.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising, for each of the n times the first loop code is executed:
<claim-text>assigning a first portion of the INVDS to a first set of documents;</claim-text>
<claim-text>assigning a second portion of the INVDS to a second set of documents, the first portion different from the second portion;</claim-text>
<claim-text>training the ITC for each class associated with the set of class labels using documents in the first set of documents;</claim-text>
<claim-text>applying a plurality of classifiers to the documents in the second set of documents; and</claim-text>
<claim-text>computing a first set of F1 scores associated with documents in the second set of documents.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the first set of documents and the second set of documents have no documents in common.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising, for each of the p times the second loop code is executed:
<claim-text>applying at least one profile of a set of profiles to each document of the UNVDS, the at least one profile defining rule to be applied to each document of the UNVDS;</claim-text>
<claim-text>comparing at least one document of the UNVDS to all of the documents included in the first set of documents; and</claim-text>
<claim-text>deleting the at least one document from the UNVDS based on the comparison.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the rule defines one of a class label
<claim-text>retention scheme, class label addition scheme, or combination thereof.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, comprising applying a plurality of profiles included in the set of profiles to each document of the UNVDS in a decreasing order of profile strictness.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the at least one document from the UNVDS is deleted if the at least one document from the UNVDS is similar to any of the documents included in the first set of documents.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein comparing the at least one document comprises computing a cosine similarity for the at least one document.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising, for each of the p times the second loop code is executed:
<claim-text>forming a third set of documents by merging documents included in the first set of documents with documents not deleted from the UNVDS ; and</claim-text>
<claim-text>clustering the third set of documents using the flat clustering or the hierarchical clustering technique.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising, for each of the q times the third loop code is executed:
<claim-text>applying the ITC to all documents in the UNVDS for each class defined in the set of class labels;</claim-text>
<claim-text>forming the subset of documents from the UNVDS, each document of the subset of documents having at least one class associated therewith;</claim-text>
<claim-text>training a second classifier using documents in the subset of documents and the first set of documents;</claim-text>
<claim-text>applying the second classifier to the second set of documents;</claim-text>
<claim-text>computing a second set of F1 scores associated with documents in the second set of documents;</claim-text>
<claim-text>comparing an F1 score associated with a class label from the second set of F1 scores to a corresponding F1 score associated with the class label from the first set of F1 scores;</claim-text>
<claim-text>updating a best score for the class label based on the comparison; and</claim-text>
<claim-text>adding documents from the subset of documents to a list of candidate documents based on the comparison.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein generating the final set of training documents comprises adding at least one document associated with the list of candidate documents to the training set of documents.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>training a plurality of classifiers using the final set of training documents; and</claim-text>
<claim-text>applying the plurality of classifiers to the test set of documents.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A system comprising:
<claim-text>a data store including a set of verified documents and a set of unverified documents, the set of verified documents divided into a training set of documents and a test set of documents, the training set of documents divided into an integer number of verified document sets (INVDS), and the set of unverified documents divided into an integer number of unverified document sets (UNVDS);</claim-text>
<claim-text>a server including a processor and memory operatively coupled to the data store, the memory storing instructions that, in response to receiving a request for access to a service, cause the processor to:
<claim-text>automatically identify a subset of documents from the UNVDS in response to inputting the set of unverified documents into an initially trained classifier (ITC);</claim-text>
<claim-text>automatically generate a final set of training documents based on the subset of documents and the INVDS;</claim-text>
</claim-text>
<claim-text>clustering at least one subset of documents from the INVDS and one subset of documents from the UNVDS using a flat clustering or hierarchical clustering technique; and
<claim-text>train the ITC using the final set of training documents.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the memory stores instructions that, in response to receiving the request, cause the processor to:
<claim-text>execute a first loop code segment comprising a first loop construct, wherein the first loop code segment is executed at run time at least n times, wherein n is a value at run time of a first variable in a first loop termination condition;</claim-text>
<claim-text>execute a second loop code segment comprising a second loop construct, wherein the second loop code segment is executed at least p&#xd7;n times, wherein p is a value at run time of a second variable in a second loop termination condition; and</claim-text>
<claim-text>execute a third loop code segment comprising a third loop construct, wherein the third loop code segment is executed p&#xd7;n&#xd7;q times, wherein q is a value at run time of a third variable in a third loop termination condition.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the memory stores instructions that, for each of the n times the processor executes the first loop, cause the processor to:
<claim-text>assign a first portion of the INVDS to a first set of documents;</claim-text>
<claim-text>assign a second portion of the INVDS to a second set of documents, the first portion different from the second portion;</claim-text>
<claim-text>train the ITC for each class associated with the set of class labels using documents in the first set of documents;</claim-text>
<claim-text>apply a plurality of classifiers to the documents in the second set of documents; and</claim-text>
<claim-text>compute a first set of F1 scores associated with documents in the second set of documents.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the first set of documents and the second set of documents have no documents in common.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the memory stores instructions that, for each of the p times the second loop code is executed, cause the processor to:
<claim-text>apply at least one profile of a set of profiles to each document of the UNVDS, the at least one profile defining a rule to be applied to each document of the UNVDS;</claim-text>
<claim-text>compare at least one document of the UNVDS to all of the documents included in the first set of documents; and</claim-text>
<claim-text>delete the at least one document from the UNVDS based on the comparison.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the rule defines a class label retention scheme, class label addition scheme, or combination thereof.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the memory stores instructions that cause the processor to apply a plurality of profiles included in the set of profiles to each document of the UNVDS in a decreasing order of profile strictness.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the memory stores instructions that cause the processor to delete the at least one document from the UNVDS if the at least one document from the UNVDS is similar to any of the documents included in the first set of documents.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the memory stores instructions that cause the processor to compute a cosine similarity for the at least one document to be used during the comparison.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the memory stores instructions that, for each of the p times the second loop code is executed, cause the processor to:
<claim-text>form a third set of documents by merging documents included in the first set of documents with documents not deleted from the UNVDS ; and</claim-text>
<claim-text>cluster the third set of documents using the flat clustering or hierarchical clustering technique.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the memory stores instructions that, for each of the q times the third loop code is executed, cause the processor to:
<claim-text>apply the ITC to all documents in the UNVDS for each class defined in the set of class labels;</claim-text>
<claim-text>form the subset of documents from the UNVDS, each document of the subset of documents having at least one class associated therewith;</claim-text>
<claim-text>train a second classifier using documents in the subset of documents and the first set of documents;</claim-text>
<claim-text>apply the second classifier to the second set of documents;</claim-text>
<claim-text>compute a second set of F1 scores associated with documents in the second set of documents;</claim-text>
<claim-text>compare an F1 score associated with a class label from the second set of F1 scores to a corresponding F1 score associated with the class label from the first set of F1 scores;</claim-text>
<claim-text>update a best score for the class label based on the comparison; and</claim-text>
<claim-text>add documents from the subset of documents to a list of candidate documents based on the comparison.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the memory stores instructions that, in response to receiving the request, cause the processor to add at least one document associated with the list of candidate documents to the training set of documents to form the final set of training documents.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the memory stores instructions that, in response to receiving the request, cause the processor to:
<claim-text>train a plurality of classifiers using the final set of training documents; and</claim-text>
<claim-text>apply the plurality of classifiers to the test set of documents.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. An article comprising a non-transitory machine-readable medium storing machine-readable instructions that, when applied to the machine, cause the machine to:
<claim-text>automatically identify a subset of documents from an integer number of unverified document sets (UNVDS) in response to inputting the UNVDS into an initially trained classifier (ITC);</claim-text>
<claim-text>automatically generate a final set of training documents based on the subset of documents and the INVDS;</claim-text>
<claim-text>clustering at least one subset of documents from the INVDS and one subset of documents from the UNVDS using a flat clustering or hierarchical clustering technique; and</claim-text>
<claim-text>train the ITC using the final set of training documents.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
