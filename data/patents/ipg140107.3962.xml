<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625031-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625031</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13978194</doc-number>
<date>20111129</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2011-017710</doc-number>
<date>20110131</date>
</priority-claim>
<priority-claim sequence="02" kind="national">
<country>JP</country>
<doc-number>2011-081389</doc-number>
<date>20110401</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>14</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>21</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348630</main-classification>
<further-classification>348672</further-classification>
<further-classification>348675</further-classification>
<further-classification>382167</further-classification>
<further-classification>382274</further-classification>
</classification-national>
<invention-title id="d2e79">Video display device</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5959696</doc-number>
<kind>A</kind>
<name>Hwang</name>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348678</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6373533</doc-number>
<kind>B1</kind>
<name>Kawabata et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348672</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6650774</doc-number>
<kind>B1</kind>
<name>Szeliski</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382169</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7133307</doc-number>
<kind>B2</kind>
<name>Baker</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>365148</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7158686</doc-number>
<kind>B2</kind>
<name>Gindele</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382274</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7592996</doc-number>
<kind>B2</kind>
<name>Brown Elliott et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345102</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7839456</doc-number>
<kind>B2</kind>
<name>Sato et al.</name>
<date>20101100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348674</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>8315473</doc-number>
<kind>B1</kind>
<name>Tao et al.</name>
<date>20121100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382260</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2002/0180893</doc-number>
<kind>A1</kind>
<name>Nicolas et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348672</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2004/0066980</doc-number>
<kind>A1</kind>
<name>Gindele et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382274</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2006/0082689</doc-number>
<kind>A1</kind>
<name>Moldvai</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2007/0046828</doc-number>
<kind>A1</kind>
<name>Miyazawa</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348674</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2008/0136835</doc-number>
<kind>A1</kind>
<name>Abe et al.</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2008/0198180</doc-number>
<kind>A1</kind>
<name>Langendijk</name>
<date>20080800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2009/0167956</doc-number>
<kind>A1</kind>
<name>Miyazawa</name>
<date>20090700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348672</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2009/0244386</doc-number>
<kind>A1</kind>
<name>Norgaard</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348672</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>JP</country>
<doc-number>9-80378</doc-number>
<kind>A</kind>
<date>19970300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>JP</country>
<doc-number>2006-146178</doc-number>
<kind>A</kind>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>JP</country>
<doc-number>2009-9082</doc-number>
<kind>A</kind>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>2009-500654</doc-number>
<kind>A</kind>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>2010-271480</doc-number>
<kind>A</kind>
<date>20101200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>WO</country>
<doc-number>WO 2007/004194</doc-number>
<kind>A2</kind>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>WO</country>
<doc-number>2010-130399</doc-number>
<kind>A</kind>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>7</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348241</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348242</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348252-256</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348606</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348607</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348612</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348624</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348630</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348645</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348671</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348672</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348674</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348675</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348678</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348679</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382162</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382167-169</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382254</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382274</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358518-523</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358448</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358447</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358461</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345589</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345690</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345600-602</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345 63</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345 88</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345 89</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20130278830</doc-number>
<kind>A1</kind>
<date>20131024</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Noutoshi</last-name>
<first-name>Tomoharu</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kanda</last-name>
<first-name>Takashi</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Fujine</last-name>
<first-name>Toshiyuki</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
<residence>
<country>JP</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Noutoshi</last-name>
<first-name>Tomoharu</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Kanda</last-name>
<first-name>Takashi</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Fujine</last-name>
<first-name>Toshiyuki</first-name>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Birch, Stewart, Kolasch &#x26; Birch, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sharp Kabushiki Kaisha</orgname>
<role>03</role>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kostak</last-name>
<first-name>Victor</first-name>
<department>2422</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP2011/077518</doc-number>
<kind>00</kind>
<date>20111129</date>
</document-id>
<us-371c124-date>
<date>20130703</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2012/105117</doc-number>
<kind>A </kind>
<date>20120809</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A histogram generation portion calculates a prescribed feature value of a pixel and the maximum feature value for the pixel, for each pixel of one frame of an input video signal. Then, the ratio of the feature value of the pixel to the maximum feature value is calculated for each pixel as an index of color brightness, and a histogram generated wherein the numbers of pixels are integrated by index value. An enhancement processing portion applies gain and carries out an enhancement for pixel values wherein the index in the histogram which the histogram generation portion generates is greater than or equal to a prescribed threshold. The feature value is treated as a luminosity (L*) which is defined with CIELAB chroma space. Additionally, the feature value may be data which has the maximum tone value among pixel RGB data, or may be a luminosity value (Y) of the pixel.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="199.05mm" wi="97.11mm" file="US08625031-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="202.52mm" wi="62.65mm" orientation="landscape" file="US08625031-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="224.37mm" wi="133.10mm" file="US08625031-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="230.29mm" wi="150.28mm" file="US08625031-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="226.06mm" wi="125.90mm" file="US08625031-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="162.48mm" wi="137.41mm" file="US08625031-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="208.53mm" wi="157.48mm" file="US08625031-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="221.40mm" wi="167.05mm" file="US08625031-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="153.50mm" wi="135.38mm" file="US08625031-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="213.87mm" wi="98.21mm" file="US08625031-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="188.81mm" wi="189.15mm" orientation="landscape" file="US08625031-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to a video display device, and more particularly to a video display device provided with an enhancement function for improving image quality of a displayed video.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">In a video display device, an enhancement function for improving image quality of a displayed video is known. In a case where the enhancement function is executed, generally, when a maximum value of a tone is detected for each frame of a video signal and the level of the maximum value is low, gain is applied to a video signal in a part with a high tone for emphasis. In addition, when a minimum value of atone of a video signal is detected and the minimum value is high, compression gain is applied to a video signal in a part with a low tone to lower the tone. Such an enhancement function is used, so that a signal range of a video signal is broadened and contrast feeling of a displayed image is increased, thus improving image quality.</p>
<p id="p-0004" num="0003">For example, Patent Document 1 discloses a liquid crystal display device automatically controlling contrast so that, along with the adjustment of luminance of a backlight, brightness/darkness of an image also comes close to the state before the adjustment. In this liquid crystal display device, an operator turns on/off a light source of a backlight device, thereby allowing to change luminance of an image and aim for power saving, an enhancement function works when the luminance is changed, contrast of a displayed image is controlled to be suited to the luminance, and even though the luminance of the backlight device is lowered, it is possible to obtain almost same level of brightness/darkness of the image as before the luminance is lowered.</p>
<heading id="h-0003" level="1">PRIOR ART DOCUMENT</heading>
<heading id="h-0004" level="1">Patent Documents</heading>
<p id="p-0005" num="0000">
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0004">Patent Document 1: Japanese Laid-Open Patent Publication No. 9-80378</li>
</ul>
</p>
<heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading>
<heading id="h-0006" level="1">Problem to be Solved by the Invention</heading>
<p id="p-0006" num="0005">In a conventional enhancement function, processing is performed such that a maximum value or a minimum value of a pixel value of a video signal is checked to emphasize and raise a high part of a tone or compress and reduce a low part of a tone. Such enhancement processing is performed by checking a pixel value of an image, thus does not necessarily improve video quality sufficiently to be coincident with a human visual performance. For example, among object colors at the time of shooting various objects, there exists a color which is luminous in appearance although luminance thereof is low as a video signal.</p>
<p id="p-0007" num="0006">In addition, in the case of considering on an xy chromaticity diagram, it is possible to represent all colors by chromaticity identified on a two-dimensional plane by x and y, and Y indicating lightness in a vertical direction to the two-dimensional plane. In a case where a color from an object is only reflected light, the lightness Y at each chromaticity is limited up to an identified value. A maximum of lightness at the time is a maximum lightness. Only with the reflected light, an upper limit of lightness of each chromaticity is the maximum lightness while in a case where an object itself is emitting light, lightness is allowed to have a value which is greater than or equal to the maximum lightness. A color having the lightness which is greater than or equal to the maximum lightness is generally referred to as a luminescent color. It is generally difficult to represent the luminescent color on a video signal.</p>
<p id="p-0008" num="0007">That is, there is sometimes a gap between a value of a video signal, and what is seen and felt. When an enhancement is carried out by detecting a color which looks bright by human eyes, it is possible to obtain an effect of further highlighting a color which is luminous on a screen to improve image quality, however, enhancement processing based on such an idea has not been conventionally performed.</p>
<p id="p-0009" num="0008">The present invention has been devised in view of circumstances as described above and aims to provide a video display device capable of improving video quality in a state more suited to a human visual performance by focusing on color brightness of a video signal and performing enhancement processing for emphasizing and highlighting a bright color more.</p>
<heading id="h-0007" level="1">Means for Solving the Problem</heading>
<p id="p-0010" num="0009">To solve the above problems, a first technical means of the present invention is a video display device for enhancing and displaying an input video signal based on a feature value of the input video signal, comprising: a histogram generation portion for generating a histogram of the feature value of the input video signal; and an enhancement processing portion for regarding a top region in a prescribed range of the histogram generated by the histogram generation portion as a luminescent color and enhancing a pixel value of the luminescent color; and a compression gain processing portion for uniformly decreasing gain over the entire pixels of one frame subjected to enhancement processing after the enhancement processing portion performs the enhancement processing, wherein the histogram generation portion calculates, for each pixel of one frame of an input video signal, the feature value of a pixel and a possible maximum of the feature value of the pixel, calculates, for each pixel, a ratio of the feature value of the pixel to the maximum of the feature value as an index value of color brightness, and generates a histogram in which the number of pixels is integrated according to the index value, the enhancement processing portion regards a pixel in which the index value in the histogram generated by the histogram generation portion is greater than or equal to a prescribed threshold as the top region and carries out an enhancement by giving gain-up for a pixel value in the top region, the enhancement processing portion integrates, at the time of enhancing the pixel which is greater than or equal to the threshold, the number of pixels from a pixel having a highest feature value in a direction of low feature value of the histogram, applies gain-up in which the M-th (M is a prescribed value) percentile pixel of the total number of pixels is displayed in a displayable highest tone, and temporarily permits that the pixel value exceeds the displayable highest tone by the applied gain-up, and the compression gain processing portion performs, in a case where the pixel value exceeds the displayable highest tone even after the compression gain processing portion applies gain-down for the temporarily permitted pixel value, soft clip so that the pixel exceeding the highest tone is output in a tone within the highest tone as well as that an output value in a region from the highest tone up to a prescribed low tone gradually lowers in a curve.</p>
<p id="p-0011" num="0010">A second technical means is the video display device of the first technical means, wherein the enhancement processing portion determines, the threshold &#x2018;thresh&#x2019; by &#x2018;thresh&#x2019;=A+N&#x3c3; (N is a constant) where the prescribed threshold is a &#x2018;thresh&#x2019;, an average value of the index value of the histogram is A, and a standard deviation is &#x3c3;.gram is A, and a standard deviation is &#x3c3;.</p>
<p id="p-0012" num="0011">A third technical means is the video display device of the first technical means, wherein the enhancement processing portion exponentiates a logarithmic average of a luminance value of a pixel of one frame of an input video signal to calculate a geometric average value, and carries out the enhancement by the gain-up in a case where the calculated geometric average value is lower than a prescribed value.</p>
<p id="p-0013" num="0012">A fourth technical means is the video display device of the third technical means, wherein the enhancement processing portion sets a second prescribed value which is lower than the prescribed value of the geometric average value, gradually increases gain which is applied as the enhancement in order from the prescribed value up to the second prescribed value in a region from the prescribed value to the second prescribed value, and keeps the gain constant in a region where the geometric average value is lower than the second prescribed value.</p>
<p id="p-0014" num="0013">A fifth technical means is the video display device of the first technical means, wherein the feature value of the pixel is luminance L* which is specified by CIELAB color space.</p>
<p id="p-0015" num="0014">A sixth technical means is the video display device of the first technical means, wherein the feature value of the pixel is data including a maximum tone value among pixel RGB data.</p>
<p id="p-0016" num="0015">A seventh technical means is the video display device of the first technical means, wherein the feature value of the pixel is a luminance value Y of a pixel.</p>
<heading id="h-0008" level="1">Effect of the Invention</heading>
<p id="p-0017" num="0016">According to the video display device of the present invention, it is possible to improve video quality in a state more suited to a human visual performance by focusing on color brightness of a video signal and performing enhancement processing for emphasizing and highlighting a bright color more.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0009" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing a partial configuration example of a video display device according to the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram explaining luminescent color enhancement processing that is executed in the video, display device of the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram explaining a setting example of gain for performing enhancement processing.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram showing a state where a CMI histogram in <figref idref="DRAWINGS">FIG. 2</figref> is enhanced using calculated gain.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram showing an example of a state before and after carrying out an enhancement with a tone curve.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram showing a tone curve with RGBLUT created from RGB data shown by the tone curve in <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram showing a tone curve in a case where output of the tone curve in <figref idref="DRAWINGS">FIG. 5</figref> is used as input in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram schematically showing a luminescent color boundary where CMI=100 in relation between saturation and lightness.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram showing a histogram of a luminance and chromaticity of a real object or the like, and a histogram after standardization thereof.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 10</figref> is a diagram explaining a method of calculating CMI from a broadcast video signal to be displayed on the video display device.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram showing an example of a CMI histogram.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 12</figref> is a diagram showing a response curve of a human photoreceptor cell with respect to luminance.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart for explaining luminescent color enhancement processing in a first embodiment of the video display device according to the present invention.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 14</figref> is a diagram explaining an optimal color in a pixel having RGB data.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0010" level="1">PREFERRED EMBODIMENTS OF THE INVENTION</heading>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing a partial configuration example of a video display device according to the present invention, where provided area video signal processing portion <b>1</b>, a histogram generation portion <b>2</b>, an enhancement processing portion <b>3</b> and a compression gain processing portion <b>4</b>. The video display device includes, other than these components, a not shown display portion such as a liquid crystal panel, a backlight for illuminating the display portion and the like. In the video display device, signal processing for an audio signal and output processing to a speaker and an audio output terminal are also performed.</p>
<p id="p-0033" num="0032">The video signal processing portion <b>1</b> performs video signal processing as with conventional processing for inputting a video signal separated from a broadcast signal and a video signal input from an external device. For example, I/P conversion, noise reduction, scaling processing, &#x3b3; adjustment, white balance adjustment and the like are appropriately executed. Moreover, contrast, a color tone and the like are controlled based on a user setting value.</p>
<p id="p-0034" num="0033">A video subjected to signal processing is input to the histogram generation portion <b>2</b> to create a histogram for each frame. The histogram generation portion <b>2</b> calculates, for each pixel of one frame of the input video signal, a prescribed feature value related to color brightness of an input video signal and a possible maximum feature value of each pixel while holding chromaticity, and calculates for each pixel a ratio of a feature value of the pixel to the maximum feature value as an index value of color brightness. Then, a histogram is generated in which the number of pixels is integrated according to the index value. The above-described prescribed feature value is luminance L* specified by CIELAB color space. Further, in another example, the above-described feature value is data including a maximum tone value among pixel RGB data. In still another example, the above-described feature value is a luminance value Y of a pixel.</p>
<p id="p-0035" num="0034">The enhancement processing portion <b>3</b> applies gain (increases gain) and carries out an enhancement for a tone of a pixel that is regarded as a luminescent color. The enhancement processing portion <b>3</b> calculates a threshold based on an average value A of the above-described index value of the histogram and a standard deviation &#x3c3;, and applies gain and carries out an enhancement for a pixel value of a pixel having the above-described index value which is greater than or equal to a threshold.</p>
<p id="p-0036" num="0035">Further, the enhancement processing portion <b>3</b> raises a logarithmic average of a luminance value of a pixel of one frame of the input video signal to calculate a geometric average value, and carries out an enhancement by applying gain in a case where the calculated geometric average value is lower than a prescribed value.</p>
<p id="p-0037" num="0036">The enhanced video signal is input to the compression gain processing portion <b>4</b>. After the enhancement processing portion <b>3</b> performs enhancement processing, the compression gain processing portion <b>4</b> uniformly applies compression gain (decreases gain) over the entire pixels of one frame subjected to enhancement processing. A compression amount is decided according to prescribed conditions of screen average luminance and the like.</p>
<p id="p-0038" num="0037">In an embodiment of a liquid crystal display device according to the present invention, a luminescent color is detected from a video signal to perform enhancement processing for the detected luminescent color. The luminescent color refers to a color with a prescribed level or more of brightness on a lightness axis in a color represented on a chromaticity diagram, and the enhancement processing is performed for a video signal concerning a pixel of a color with a color brightness level which is greater than or equal to a prescribed threshold. The threshold in this case is a relative value that is defined according to a histogram for each image of one frame, and enhancement processing is performed for an image with a relatively prescribed level or more of brightness in images.</p>
<p id="p-0039" num="0038">Enhancement processing is performed for a luminescent color, so that it is possible to perform enhancement processing for an actually bright color in appearance. Then, for a video with the enhanced luminescent color, compression gain is uniformly applied to lower a tone. Since brightness of the entire screen becomes higher in the case of holding an enhancing state, compression gain is applied again to lower the brightness of the screen. Since enhancement processing is performed for a luminescent color, thereafter applying compression gain to the entire screen, the processing in this case is equal to processing for redistributing luminance on the screen. Such processing allows a part with a high luminescent color to be especially highlighted.</p>
<p id="p-0040" num="0039">In luminescent color enhancement processing that is executed in the video display device according to the present invention, as described above, a luminescent color is detected from an input video signal to perform enhancement processing for emphasizing a tone for the video signal of the luminescent color. In the processing, first, a geometric average value (GAve) and a CMI (color mode index) histogram are detected from the input video signal. The CMI is one of the feature values for performing enhancement processing according to the present invention.</p>
<p id="p-0041" num="0040">The geometric average value is not an average of signal luminance but a luminance average value in which an average of luminance of a liquid crystal panel is calculated as a value that is coincident with a visual performance. Further, the CMI histogram is a histogram created based on a video signal and coincident with a human visual performance in which the number of pixels is integrated according to an index indicating color brightness, which is different from a Y histogram or the like in which the number of pixels is integrated according to the luminance value Y of a video signal. Description will be given below for specific definitions and calculation methods of the geometric average value and CMI histogram.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram explaining the luminescent color enhancement processing that is executed in the video display device of the preset invention, showing an example of the CMI histogram that is generated from an input video signal. When the CMI histogram is detected, an average value (Ave) and a standard deviation (&#x3c3;) are calculated from the CMI histogram to be used for calculating a threshold, &#x2018;thresh&#x2019;, by
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x2018;thresh&#x2019;=<i>Ave+N&#x3c3;, </i><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where N is a prescribed constant. Other methods including at least identifying the top of the population may also be applied as the calculation method of the threshold.
</p>
<p id="p-0043" num="0042">For example, assuming that the CMI histogram as shown in <figref idref="DRAWINGS">FIG. 2</figref> is detectable from one frame of an input video signal, a horizontal axis of the CMI histogram is CMI, and indicates the CMI of the brightest color in all colors on a chromaticity diagram as 100. That is, color brightness is different according to tones of video signals, and the CMI is calculated from the tones to integrate the number of pixels. A vertical axis indicates the number of pixels (frequency) integrated by color brightness (CMI).</p>
<p id="p-0044" num="0043">Additionally, the &#x2018;thresh&#x2019; calculated as described above is applied to the CMI histogram. The &#x2018;thresh&#x2019; is used for determining a luminescent color from the CMI histogram, and a pixel with the CMI that is greater than the &#x2018;thresh&#x2019; is defined as a pixel for displaying a luminescent color.</p>
<p id="p-0045" num="0044">Then, among pixels with the CMI that is greater than the &#x2018;thresh&#x2019; in the CMI histogram, pixels are accumulated in order from the highest CMI to the lowest CMI to calculate gain for an enhancement so that the CMI of the M-th percentile pixel among all pixels becomes 100. The value of gain thereof is a maximum value of gain (MAX) that is decided according to a geometric average value which will be described next.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram explaining a setting example of gain for performing enhancement processing. Gain that is applied in the luminescent color enhancement processing is calculated using the geometric average value calculated as described above and the maximum value of gain that is calculated based on the M-th percentile pixel from the maximum value of the CMI.</p>
<p id="p-0047" num="0046">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, in the case of a video having a geometric average value that is greater than or equal to a first value g1 of a predetermined geometric average value (GAve), an enhancement is not carried out for the video (frame). A video with a high geometric average value is a video which is entirely bright, and when this video is compressed again after carrying out an enhancement, an impression that a screen becomes dark by compression is greater than an impression that a luminescent color is highlighted by an enhancement. Thus, an enhancement is not carried out for the video having the geometric average value that is greater than or equal to a prescribed level of the geometric average value g1. That is, gain=1.0.</p>
<p id="p-0048" num="0047">Moreover, between a first geometric average value g1 and a second geometric average value g1 that is lower than the former, gain is gradually increased in order from g1 to g2 from 1.0 up to the maximum value. The maximum value of gain (MAX) is a value calculated so that the above-described CMI of the M-th percentile pixel becomes 100.</p>
<p id="p-0049" num="0048">In a case where the geometric average value is smaller than g2, gain with which the CMI of the M-th percentile pixel becomes 100 is applied. At the time, a pixel with the CMI larger than that of the M-th percentile pixel may have the CMI that is larger than 100 as a result of application of gain. In this case, the pixel with the CMI that is larger than 100 is subjected to clipping in actual display, thus causing crush, thereby allowing no half-toning.</p>
<p id="p-0050" num="0049">In this case, since the brightest level of a pixel is originally illuminated with a high tone, it is less important to finely represent a tone. On the other hand, for example, in the case of calculating gain based on the highest value of the CMI, it is possible to perform half-toning for all pixels, however, a pixel having a specifically high CMI in a video influences gain, and thus the gain has substantially little effect in some cases. In the case of not allowing a certain level of gain to be applied, a subsequent compression amount becomes small, and it is impossible to sufficiently attain an object of the present invention that a luminescent color is enhanced to increase image quality. Thus, gain calculation is performed so as to allow crush of pixels up to the M-th percentile in order to secure a certain amount of gain. However, because of also having pixels with the CMI that is lowered again by applying compression gain after carrying out an enhancement by applying gain, all pixels with the CMI which are larger than M-th percentile are not necessarily subjected to clipping. Moreover, in actual processing, for an area which is crushed after compression, processing is performed for holding a tone as far as possible by performing soft clip processing described below.</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram showing a state where the CMI histogram in <figref idref="DRAWINGS">FIG. 2</figref> is enhanced using the gain calculated as described above. When gain for an enhancement is calculated in the above-described processing, the gain is applied to carry out an enhancement. A target pixel for carrying out an enhancement is a pixel with the CMI which is greater than or equal to the &#x2018;thresh&#x2019;, and enhanced by applying gain to a luminance L* component in the CIELAB color space of the pixel. Thereafter, the color space is returned to RGB color space. The amount of gain is calculated based on the geometric average value of a video and maximum gain based on the CMI. That is, based on the &#x2018;thresh&#x2019; calculated from the CMI histogram, a pixel of a bright color is emphasized by carrying out an enhancement, while a pixel of a dark color is kept as-is.</p>
<p id="p-0052" num="0051">At the time, in the state with the enhancement in <figref idref="DRAWINGS">FIG. 4</figref>, a pixel with CMI exceeding 100 also is not clipped and kept allowed. The value with CMI exceeding 100 is a value exceeding 255 of a tone value represented with eight bits, for example, and thus is not allowed to be represented on a screen, however, at this time point, the CMI exceeding 100 is allowed because it is considered that there is a pixel with the CMI lowered again since compression gain is applied to the entire video at next processing. The highest value of the CMI at the time of enhancement is obtained by
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>gain <i>X</i>(Max&#x2212;&#x2018;thresh&#x2019;)+&#x2018;thresh&#x2019;.<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0053" num="0052">Subsequently, in the state where the luminescent color is enhanced as shown in <figref idref="DRAWINGS">FIG. 4</figref>, the entire video signal is compressed. The compression gain is uniformly applied to pixels of the entire screen. Accordingly, the luminescent color is emphasized more than pixels of other non-luminescent colors by an effect of the enhancement and a luminescent color part is allowed to be highlighted. That is, this processing is equal to redistribution of luminance on a screen. Moreover, an amount of gain is changed according to a geometric average value and an enhancement is not carried out in a bright image, thus inhibiting the entire screen from becoming dark by compressing the bright image after the enhancement thereof.</p>
<p id="p-0054" num="0053">The amount of the compression gain is defined based on prescribed conditions specifying brightness of a screen and the like. For example, when display is performed only by carrying out an enhancement, a screen average picture level (APL) of a video signal is increased. This is returned to an original APL level by the compression gain, the APL of the entire screen is thereby maintained, and in addition, it is possible to redistribute luminance so as to highlight the luminescent color by carrying out the enhancement to compression gain processing. Moreover, relation between gain at the time of the enhancement and the compression gain may be defined in advance.</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram showing an example of a state before and after carrying out the enhancement to the compression processing with a tone curve. As described above, in the embodiment according to the present invention, a pixel with the CMI which is greater than or equal to the &#x2018;thresh&#x2019; is regarded as a luminescent color, and an enhancement is carried out for the pixel. The enhancement is carried out for L* in CIELAB color space and then returned to RGB data. Subsequently, the compression gain is applied to the entire video.</p>
<p id="p-0056" num="0055">The tone curve shown in <figref idref="DRAWINGS">FIG. 5</figref> shows tone characteristics of input and output of the RGB data, and is displayed with 0 to 255 tones with eight bits. Additionally, symbol &#x2018;a&#x2019; indicates a state before the enhancement while symbol &#x2018;b&#x2019; indicates a state after the enhancement and compression processing. A luminescent color boundary is a tone corresponding to a &#x2018;thresh&#x2019; of a CMI, atone curve is more greatly inclined due to the enhancement in a tone which is greater than or equal to the luminescent color boundary, and an output tone exceeds 255 in the vicinity of the highest tone (255). This is because a CMI greater than 1.0 is allowed without being clipped even in a case where a CMI becomes greater than CMI <b>100</b> at the time of the enhancement as shown in <figref idref="DRAWINGS">FIG. 4</figref>. Even after the compression gain is applied thereto, the output tone exceeds 255 in some cases.</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram showing a tone curve with an RGBLUT created from RGB data shown by the tone curve in <figref idref="DRAWINGS">FIG. 5</figref>. In the diagram, a MAX output tone is detected from data after compression of <figref idref="DRAWINGS">FIG. 5</figref>. Then, the RGBLUT so as to output a 255 tone when a tone signal as with the MAX output tone is input is created. At the time, the LUT is such that relation between input and output is linear as far as output is 0 to 255&#xd7;N % (N is a prescribed constant). A quadratic function Y(x)=A+B&#xd7;(x&#x2212;x1)+C&#xd7;(x&#x2212;x1)2 passing through (x1, y1)=(255&#xd7;N, 255&#xd7;N) and (x2, y2)=(MAX, 255) is then calculated. Conditions thereof are based on (1) y(x1)=y1 (linear LUT and coordinates are continuous), (2) y&#x2032;(x1)=y1/x1 (linear LUT and an inclination are continuous), and (3) y(x2)=y2 (initial conditions). An obtained tone curve c is, as shown in <figref idref="DRAWINGS">FIG. 6</figref>, formed such that relation is linear where input and output have the same values as far as input is 0 to 255&#xd7;N %, an inclination is changed when input is greater than or equal to 255&#xd7;N %, and output is 255 when input is MAX.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram showing a tone curve (b) in a case where output of the tone curve (b) in <figref idref="DRAWINGS">FIG. 5</figref> is used as input in <figref idref="DRAWINGS">FIG. 6</figref>. Accordingly, in a tone which is greater than or equal to the luminescent color boundary, a tone curve in a curved shape is formed toward (x, y)=(255, 255) so that an output value does not exceed 255, thereby performing clip softly to keep a tone as far as possible and reducing a sense of discomfort on display. Note that, the above-described processing may be executed by operation processing of software without using an LUT in which an output value for input is prepared in advance.</p>
<p id="p-0059" num="0058">As described above, in the luminescent color enhancement processing according to the present invention, a luminescent color which is a bright color is detected from a CMI histogram of a video signal, and the luminescent color is enhanced when a geometric average value of the video signal is smaller than a prescribed value, that is, a video is dark. The video signal after the enhancement is then compressed to redistribute luminance. This makes it possible to perform high-quality video display by highlighting a part in a luminescent color. The effect of the enhancement is great especially in a video with a dark input video. Moreover, in a video having many luminescent color regions as well as many parts in which a tone is saturated, it is possible to avoid that a screen looks dark due to compression processing after the enhancement by not carrying out a luminescent color enhancement.</p>
<p id="h-0011" num="0000">(CMI Detection Processing)</p>
<p id="p-0060" num="0059">Next, description will be specifically given for detection processing of the CMI which is used in the above-described luminescent color enhancement processing.</p>
<p id="p-0061" num="0060">As described above, a CMI (Color Mode Index) is an index showing to what extent a color of interest is bright. Here, the CMI is different from luminance and shows brightness to which information of a color is added. The CMI is defined by
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>L*/L</i>*modeboundary&#xd7;100&#x2003;&#x2003;formula (1).<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0062" num="0061">The above-described L* is an index of relative color brightness, and becomes lightness of white which is the brightest as an object color when L*=100. In the above-described formula (1), L* is lightness of a color of interest, while L*modeboundary is lightness of a boundary which looks like emitting light in chromaticity as with the color of interest. Here, it is known that L*modeboundary&#x2248;lightness of an optimal color (brightest color among object colors). Lightness of a color in which CMI=100 is referred to as a luminescent color boundary, and it is defined as emitting light (being a luminescent color) in the case of exceeding CMI=100. The luminescent color boundary where CMI=100 in relation between saturation and lightness is schematically shown in <figref idref="DRAWINGS">FIG. 8</figref>.</p>
<p id="p-0063" num="0062">In the real world, objects with brightness exceeding that of the brightest object color (optimal color) (objects emitting light) exist and are allowed to be seen by a human. That is, there exist many colors in which CMI&#x3e;100. Here, for a broadcast signal or image data, a luminance range is compressed by a stop of a camera or the like at the time of shooting, and moreover, standardized and made into data in a color gamut according to standards such as NTSC or EBU. Accordingly, even a reflected color or a luminescent color is standardized, so that a video signal is in a state of having no color in which the CMI exceeds 100 (that is, exceeding lightness of the optimal color).</p>
<p id="p-0064" num="0063">For example, a luminance histogram of a real object or the like is shown in <figref idref="DRAWINGS">FIG. 9(A)</figref> while a histogram after standardization is shown in <figref idref="DRAWINGS">FIG. 9(B)</figref>. In the diagrams, symbols &#x2018;h1&#x2019; and &#x2018;h2&#x2019; show luminance histograms in two scenes of the real world, in which h1 is a luminance histogram in a relatively dark scene while h2 is a luminance histogram in a relatively bright scene. In the example of <figref idref="DRAWINGS">FIG. 9(A)</figref>, the luminance histogram of a real object or the like has brightness of 10,000 cd/m<sup>2 </sup>at maximum on h1 and brightness of 100 cd/m<sup>2 </sup>at maximum on h2. When the scene of the real world is made into data by imaging or the like, histogram data is standardized as shown in <figref idref="DRAWINGS">FIG. 9(B)</figref>. Then, video signal data thereof has 255 tones in both cases with luminance of the object of 10,000 cd/m<sup>2 </sup>and that of 100 cd/m<sup>2</sup>. In other words, the luminance range is compressed, and thus original luminance information is lost.</p>
<p id="p-0065" num="0064">Based on the above-described circumstances, description will be given for a method of calculating a CMI from a broadcast video signal to be displayed on the video display device with reference to <figref idref="DRAWINGS">FIG. 10</figref>. The broadcast video signal is standardized based on the BT.709 standard to be transmitted. Accordingly, first of all, RGB data of the broadcast video signal is converted into data of tristimulus values XYZ using a transformation matrix for the BT.709. Lightness L* is then calculated from Y using transformation. It is assumed that L* of a color of interest was at a position P<b>1</b> in <figref idref="DRAWINGS">FIG. 10</figref>. Next, chromaticity is calculated from the converted XYZ to check L* of the optimal color with chromaticity as with the color of interest (L*modeboundary) from data of the optimal color which is already known. A position thereof on <figref idref="DRAWINGS">FIG. 10</figref> is P<b>2</b>.</p>
<p id="p-0066" num="0065">The CMI is calculated from these values using the above-described formula (1). The CMI is indicated by a ratio between L* of a pixel of interest and L* of the optimal color of chromaticity thereof (L*modeboundary).</p>
<p id="p-0067" num="0066">The CMI is obtained for each pixel of a video signal by the method as described above. The broadcast signal is standardized, and thus all pixels have any CMI in a range from 0 to 100. Then, a CMI histogram is created for a video of one frame with CMI on a horizontal axis and a frequency on a vertical axis. An example of the CMI histogram is shown in <figref idref="DRAWINGS">FIG. 11</figref>. An average A and a standard deviation &#x3c3; are calculated from the created CMI histogram.</p>
<p id="p-0068" num="0067">It is impossible to appropriately detect a pixel which is emitting light based on a certain absolute value calculated from the standardized video signal. Accordingly, whether or not light is emitted is distinguished with relative distribution of a video signal of one frame. Here, a strikingly bright pixel in the entire video of one frame is defined as a pixel which is emitting light. In this case, a CMI higher than the average A by N&#x3c3; (N is a prescribed constant) (A+N&#x3c3;) is defined as a luminescent color boundary, and a pixel having CMI which is greater than or equal to the luminescent color boundary is regarded as emitting light. A value of the constant N is not limited, however, N=2.8, for example.</p>
<p id="p-0069" num="0068">By specific processing as described above, a CMI histogram is generated from a video signal, a &#x2018;thresh&#x2019; is calculated from the histogram, and thereby making it possible to execute luminescent color enhancement processing as described above based on a geometric average value.</p>
<p id="h-0012" num="0000">(Geometric Average Value Detection Processing)</p>
<p id="p-0070" num="0069">Next, description will be given specifically for detection processing of a geometric average value which is used in the above-described luminescent color enhancement processing. The geometric average value (Geometric Average) is not an average of signal luminance but a luminance average value in which an average of luminance of a liquid crystal panel is calculated as a value that is coincident with a visual performance, and is specifically represented by the following formula (2).</p>
<p id="p-0071" num="0070">[Formula I]</p>
<p id="p-0072" num="0071">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>GeometricAve</mi>
          <mo>.</mo>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mi>exp</mi>
          <mo>&#x2061;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mfrac>
                <mn>1</mn>
                <mi>n</mi>
              </mfrac>
              <mo>&#x2062;</mo>
              <mrow>
                <munder>
                  <mo>&#x2211;</mo>
                  <mi>pixels</mi>
                </munder>
                <mo>&#x2062;</mo>
                <mrow>
                  <mi>log</mi>
                  <mo>&#x2061;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mi>&#x3b4;</mi>
                      <mo>+</mo>
                      <msub>
                        <mi>Y</mi>
                        <mi>hum</mi>
                      </msub>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mi>formula</mi>
        <mo>&#x2062;</mo>
        <mstyle>
          <mspace width="0.8em" height="0.8ex"/>
        </mstyle>
        <mo>&#x2062;</mo>
        <mrow>
          <mo>(</mo>
          <mn>2</mn>
          <mo>)</mo>
        </mrow>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0073" num="0072">In the above-described formula (2), &#x3b4; is a minute value which is not able to diverge calculation, and, for example, &#x3b4;=0.00001. Additionally, Ylum indicates panel luminance, having a value of 0 to 1.0. The Ylum is allowed to be represented as (signal luminance/MAX luminance)^&#x3b3;. Moreover, n indicates the number of pixels and &#x201c;pixels&#x201d; indicates the total number of pixels. In this way, in the formula (2), a logarithmic average of a luminance value of a pixel of a video is raised, in other words, a value of a geometric mean of luminance is indicated, and the value is greatly influenced by black.</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 12</figref> is a diagram showing a response curve of a human photoreceptor cell with respect to luminance. As shown in <figref idref="DRAWINGS">FIG. 12</figref>, the response curve of a human photoreceptor cell depends on a luminance value having a logarithm (luminance (log cd/m<sup>2</sup>)). This is generally referred to as the Mickaelis-Menten Equation.</p>
<p id="p-0075" num="0074">A geometric average value is obtained by raising a logarithmic average of a luminance value of a pixel as described above, and thus the geometric average value may be referred to as a value that response of eyes to an image (that is, how bright the image looks) is quantified. That is, it may be said that the geometric average value is close to a human sensory amount, and this value is used as a video feature value to determine in the CMI histogram whether or not luminescent color enhancement processing is performed.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart for explaining luminescent color enhancement processing in a first embodiment of the video display device according to the present invention, showing a flow of luminescent color enhancement processing for one frame of a video signal.</p>
<p id="p-0077" num="0076">First, a CMI histogram is created from an input video signal (step S<b>1</b>). The CMI histogram is obtained from a ratio between L* and L* of the optimal color (L:modeboundary) of each pixel. A geometric average value is then calculated from the CMI histogram (step S<b>2</b>). Subsequently, a &#x2018;thresh&#x2019; for deciding a CMI region in which a luminescent color enhancement is carried out is calculated from the CMI histogram (step S<b>3</b>). The &#x2018;thresh&#x2019; is calculated from an average value and a standard deviation of the histogram. An order of calculating the geometric average value and calculating the &#x2018;thresh&#x2019; may be reversed.</p>
<p id="p-0078" num="0077">Next, based on the calculated geometric average value, whether or not the luminescent color enhancement is carried out for the video of the frame is judged (step S<b>4</b>). When the video has a geometric average value which is greater than or equal to a prescribed level, the luminescent color enhancement is not carried out. In a case where the luminescent color enhancement is carried out, for example, by calculating gain such that a pixel at a 2% position from a maximum CMI of the histogram has CMI=100, and applying the gain to a pixel which is greater than or equal to the &#x2018;thresh&#x2019;, the luminescent color enhancement is carried out (step S<b>5</b>). With the luminescent color enhancement, a tone of a pixel regarded as a luminescent color is emphasized.</p>
<p id="p-0079" num="0078">Next, compression gain is calculated (step S<b>6</b>). The compression gain is defined based on prescribed conditions to specify brightness of a screen and the like, or defined in relation to enhancing gain in advance. The calculated compression gain is then applied to the entire video to compress a tone (step S<b>7</b>). This compresses a tone of the entire video which is enhanced. Redistribution of luminance in a screen is performed from the enhancement to compression processing. That is, emphasis is further performed for a bright color part while a tone is lowered for a dark color part.</p>
<p id="p-0080" num="0079">Finally, soft clip processing is performed (step S<b>8</b>). Here, soft clip is performed for a pixel exceeding a highest tone (255, for example) even after compression by using a quadratic function.</p>
<heading id="h-0013" level="1">Second Embodiment</heading>
<p id="p-0081" num="0080">Next, description will be given for a second embodiment of the video display device according to the present invention. In the above-described first embodiment, the &#x2018;thresh&#x2019; is calculated from the CMI histogram, and the luminescent color enhancement is carried out for the pixel which is greater than or equal to the &#x2018;thresh&#x2019;. On the other hand, in the present embodiment, an operation is performed by using an RGB histogram or a Y histogram without using the CMI histogram. RGB data and luminance value Y data correspond to another example of a feature value of the present invention.</p>
<p id="p-0082" num="0081">In the above-described first embodiment, the RGB data of the video signal is converted into XYZ by using a determinant to calculate chromaticity, and a CMI is obtained by a ratio between the chromaticity and L* of the optimal color. In this case, an operation amount for calculating the CMI is a considerable amount. While it may be said that the CMI is preferable for the luminescent color enhancement processing since the CMI is a feature value that is coincident with a human visual performance, in the second embodiment, the RGB histogram or the Y histogram is used in place of the CMI for the purpose of simplifying the operation amount.</p>
<p id="p-0083" num="0082">The CMI is a value indicating how bright the color of the pixel of interest is, compared to the optimal color with chromaticity as with the pixel of interest as described above. On the other hand, in a combination of RGB, a case where two colors have same chromaticity is equal to that an RGB ratio is not changed. That is, processing of performing operation of the optimal color with same chromaticity in the CMI is processing of obtaining a combination of RGB when atone of RGB data becomes the greatest in a case where a ratio of RGB data is not changed and multiplied by a certain number.</p>
<p id="p-0084" num="0083">For example, a pixel having RGB data with a tone as shown in <figref idref="DRAWINGS">FIG. 14(A)</figref> is assumed to be a pixel of interest. When multiplying RGB data of the pixel of interest by a certain number, as shown in <figref idref="DRAWINGS">FIG. 14</figref> (B), a color when any one of RGB is saturated first is the brightest color with chromaticity as with an original pixel. When a tone of the pixel of interest of the color which is saturated first (R in this case) is r1, and a tone of R of the optimal color is r2, a value similar to the CMI is allowed to be obtained by
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>r</i>1<i>/r</i>2&#xd7;100&#x2003;&#x2003;formula (3).<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
A color which is saturated first when RGB is multiplied by a certain number is a color having the greatest tone among RGB of the pixel of interest.
</p>
<p id="p-0085" num="0084">In the present embodiment, a value by the formula (3) as described above is calculated for each pixel to create a histogram. With this histogram, processing as with the CMI histogram in the first embodiment is performed. That is, an average value and a standard deviation are calculated from the histogram by the formula (3) to decide a &#x2018;thresh&#x2019;. Then, a geometric average value is calculated from the histogram to enhance a pixel corresponding to data which is greater than the &#x2018;thresh&#x2019; according to the level of the geometric average value to be compressed thereafter. By such processing, it is possible to reduce a burden of the operation more than the operation processing of the CMI, and to perform processing by, for example, a general-purpose IC or the like, and thus simplification is performed on a circuit scale.</p>
<p id="p-0086" num="0085">Further, in the case of focusing only on brightness of a pixel, it is possible to extract a luminance Y signal from a video signal, calculate a ratio between luminance of a pixel of interest and the maximum luminance to create a similar histogram, and perform enhancement processing by processing similar to the above-described processing. However, the Y histogram, with no information related to color, is inconsistent with the above-described processing by the CMI or the RGB histogram. Note that, in processing of creating the Y histogram to carry out an enhancement, effective enhancement processing is possible with a simple configuration without raising a major obstacle.</p>
<p id="p-0087" num="0086">Note that, in the above-described embodiment, the histogram is created based on the feature value of the video signal and the enhancement is carried out by video signal processing for a pixel of the top of a prescribed range thereof, however, in performing the enhancement processing, a backlight light source for illuminating a liquid crystal panel may be controlled to control brightness on a display screen.</p>
<p id="p-0088" num="0087">In this case, for example, in uniformly decreasing gain over the entire pixels of one frame, in addition to applying the compression gain to the video signal, luminance of the backlight may be uniformly reduced to lower screen luminance. At the time, the compression gain of the video signal and the backlight may work in concert to realize lowering of luminance as desired.</p>
<heading id="h-0014" level="1">EXPLANATIONS OF LETTERS OR NUMERALS</heading>
<p id="p-0089" num="0088"><b>1</b> . . . video signal processing portion; <b>2</b> . . . histogram generation portion; <b>3</b> . . . enhancement processing portion; and <b>4</b> . . . compression gain processing portion.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US08625031-20140107-M00001.NB">
<img id="EMI-M00001" he="9.57mm" wi="76.20mm" file="US08625031-20140107-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A video display device for enhancing and displaying an input video signal based on a feature value of the input video signal, comprising:
<claim-text>a histogram generation portion for generating a histogram of the feature value of the input video signal;</claim-text>
<claim-text>an enhancement processing portion for regarding a top region in a prescribed range of the histogram generated by the histogram generation portion as a luminescent color and enhancing a pixel value of the luminescent color; and</claim-text>
<claim-text>a compression gain processing portion for uniformly decreasing gain over the entire pixels of one frame subjected to enhancement processing after the enhancement processing portion performs the enhancement processing, wherein</claim-text>
<claim-text>the histogram generation portion calculates, for each pixel of one frame of an input video signal, the feature value of a pixel and a possible maximum of the feature value of the pixel, calculates, for each pixel, a ratio of the feature value of the pixel to the maximum of the feature value as an index value of color brightness, and generates a histogram in which the number of pixels is integrated according to the index value,</claim-text>
<claim-text>the enhancement processing portion regards a pixel in which the index value in the histogram generated by the histogram generation portion is greater than or equal to a prescribed threshold as the top region and carries out an enhancement by giving gain-up for a pixel value in the top region,</claim-text>
<claim-text>the enhancement processing portion integrates, at the time of enhancing the pixel which is greater than or equal to the threshold, the number of pixels from a pixel having a highest feature value in a direction of low feature value of the histogram, applies gain-up in which the M-th (M is a prescribed value) percentile pixel of the total number of pixels is displayed in a displayable highest tone, and temporarily permits that the pixel value exceeds the displayable highest tone by the applied gain-up, and</claim-text>
<claim-text>the compression gain processing portion performs, in a case where the pixel value exceeds the displayable highest tone even after the compression gain processing portion applies gain-down for the temporarily permitted pixel value, soft clip so that the pixel exceeding the highest tone is output in a tone within the highest tone as well as that an output value in a region from the highest tone up to a prescribed low tone gradually lowers in a curve.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The video display device as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the enhancement processing portion determines, the threshold &#x2018;thresh&#x2019; by
<claim-text>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x2018;thresh&#x2019;=<i>A+N</i>&#x3c3;(<i>N </i>is a constant)<?in-line-formulae description="In-line Formulae" end="tail"?>
</claim-text>
</claim-text>
<claim-text>where the prescribed threshold is a &#x2018;thresh&#x2019;, an average value of the index value of the histogram is A, and a standard deviation is &#x3c3;.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The video display device as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the enhancement processing portion exponentiates a logarithmic average of a luminance value of a pixel of one frame of an input video signal to calculate a geometric average value, and carries out the enhancement by the gain-up in a case where the calculated geometric average value is lower than a prescribed value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The video display device as defined in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein
<claim-text>the enhancement processing portion sets a second prescribed value which is lower than the prescribed value of the geometric average value, gradually increases gain which is applied as the enhancement in order from the prescribed value up to the second prescribed value in a region from the prescribed value to the second prescribed value, and keeps the gain constant in a region where the geometric average value is lower than the second prescribed value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The video display device as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the feature value of the pixel is luminance L* which is specified by CIELAB color space.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The video display device as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the feature value of the pixel is data including a maximum tone value among pixel RGB data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The video display device as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the feature value of the pixel is a luminance value Y of a pixel.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
