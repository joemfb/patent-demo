<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08625860-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08625860</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13078924</doc-number>
<date>20110401</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<us-term-extension>310</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382118</main-classification>
<further-classification>382115</further-classification>
<further-classification>382164</further-classification>
<further-classification>382162</further-classification>
<further-classification>382254</further-classification>
<further-classification>382288</further-classification>
<further-classification>382293</further-classification>
<further-classification>382269</further-classification>
</classification-national>
<invention-title id="d2e53">Adaptive face recognition using online learning</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>7881505</doc-number>
<kind>B2</kind>
<name>Schneiderman et al.</name>
<date>20110200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382118</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2005/0157952</doc-number>
<kind>A1</kind>
<name>Gohda et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382305</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2009/0060290</doc-number>
<kind>A1</kind>
<name>Sabe et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382118</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2010/0142762</doc-number>
<kind>A1</kind>
<name>Morita</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382115</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2011/0182482</doc-number>
<kind>A1</kind>
<name>Winters et al.</name>
<date>20110700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382116</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2012/0250950</doc-number>
<kind>A1</kind>
<name>Papakipos et al.</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382118</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>10</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382118</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382115</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382164</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382162</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382254</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382288</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382293</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707769</main-classification>
</classification-national>
<classification-cpc-text>G06K 9/00221</classification-cpc-text>
<classification-cpc-text>G06K 9/00295</classification-cpc-text>
<classification-cpc-text>G06K 9/00302</classification-cpc-text>
<classification-cpc-text>G06K 9/00677</classification-cpc-text>
<classification-cpc-combination-text>G06K 9/00221</classification-cpc-combination-text>
<classification-cpc-combination-text>G06K 9/00295</classification-cpc-combination-text>
<classification-cpc-combination-text>G06K 9/00302</classification-cpc-combination-text>
<classification-cpc-combination-text>G06K 9/00677</classification-cpc-combination-text>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120250952</doc-number>
<kind>A1</kind>
<date>20121004</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kveton</last-name>
<first-name>Branislav</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lyons</last-name>
<first-name>Kenton M.</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Kveton</last-name>
<first-name>Branislav</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Lyons</last-name>
<first-name>Kenton M.</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Caven &#x26; Aghevli LLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Intel Corporation</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Rahmjoo</last-name>
<first-name>Mike</first-name>
<department>2667</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">In one embodiment an electronic device comprises an input/output module, a memory coupled to the input/output module, and logic to store a first image of a face in the memory module, associate an identity with the first image of a face, subsequently collect a second image of a face, determine a correlation between features on the first image of a face and the second image of a face, and store the correlation between the first image and the second image. Other embodiments may be described.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="115.99mm" wi="90.00mm" file="US08625860-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="251.04mm" wi="182.20mm" file="US08625860-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="258.32mm" wi="197.02mm" file="US08625860-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="210.57mm" wi="151.89mm" file="US08625860-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="234.95mm" wi="175.60mm" file="US08625860-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">None.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">The subject matter described herein relates generally to the field of electronic devices and more particularly to a system and method to implement face recognition using electronic devices.</p>
<p id="p-0004" num="0003">Electronic devices such as, e.g., computer systems, present security risks associated with unauthorized access of said computer systems. By way of example, unauthorized users of computer systems may access restricted files and/or resources, or engage in fraudulent electronic commerce using the electronic device. Portable electronic devices such as, e.g., mobile phones, personal digital assistants (PDAs) and laptop computers may be misplaced and/or stolen, and therefore have magnified security risks associated with the unauthorized use of electronic devices.</p>
<p id="p-0005" num="0004">Many electronic devices include one or more cameras integrated into the hardware of the device. This presents the opportunity to use image recognition such as facial recognition as a component of a security regime. Accordingly systems and techniques for image recognition and particularly for face recognition in electronic devices may find utility.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0006" num="0005">The detailed description is described with reference to the accompanying figures.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic illustration of an exemplary electronic device which may be adapted to implement in accordance with some embodiments.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIGS. 2-3</figref> are flowcharts illustrating operations in a method to implement transaction integrity in accordance with some embodiments.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic illustration of a face association graph constructed in accordance with face recognition techniques in accordance with some embodiments.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic illustration of an electronic device which may be adapted to implement client hardware authenticated transactions accordance with some embodiments.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0011" num="0010">Described herein are exemplary systems and methods to implement face recognition in electronic devices. In the following description, numerous specific details are set forth to provide a thorough understanding of various embodiments. However, it will be understood by those skilled in the art that the various embodiments may be practiced without the specific details. In other instances, well-known methods, procedures, components, and circuits have not been illustrated or described in detail so as not to obscure the particular embodiments.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic illustration of an exemplary system <b>100</b> which may be adapted to implement face recognition techniques in accordance with some embodiments. In one embodiment, system <b>100</b> includes an electronic device <b>108</b> and one or more accompanying input/output devices including a display <b>102</b> having a screen <b>104</b>, one or more cameras <b>106</b>, a keyboard <b>110</b>, one or more other I/O device(s) <b>112</b>, and a mouse <b>114</b>. The other I/O device(s) <b>112</b> may include a touch screen, a voice-activated input device, a track ball, a geolocation device, an accelerometer/gyroscope and any other device that allows the system <b>100</b> to receive input from a user.</p>
<p id="p-0013" num="0012">In various embodiments, the electronic device <b>108</b> may be embodied as a personal computer, a laptop computer, a personal digital assistant, a mobile telephone, an entertainment device, or another computing device. The particular implementation of the electronic device is not critical. The electronic device <b>108</b> includes system hardware <b>120</b> and memory <b>130</b>, which may be implemented as random access memory and/or read-only memory. A file store <b>180</b> may be communicatively coupled to computing device <b>108</b>. File store <b>180</b> may be internal to computing device <b>108</b> such as, e.g., one or more hard drives, CD-ROM drives, DVD-ROM drives, or other types of storage devices. File store <b>180</b> may also be external to computer <b>108</b> such as, e.g., one or more external hard drives, network attached storage, or a separate storage network.</p>
<p id="p-0014" num="0013">System hardware <b>120</b> may include one or more processors <b>122</b>, graphics processors <b>124</b>, network interfaces <b>126</b>, and bus structures <b>128</b>. In one embodiment, processor <b>122</b> may be embodied as an Intel&#xae; Core2 Duo&#xae; processor available from Intel Corporation, Santa Clara, Calif., USA. As used herein, the term &#x201c;processor&#x201d; means any type of computational element, such as but not limited to, a microprocessor, a microcontroller, a complex instruction set computing (CISC) microprocessor, a reduced instruction set (RISC) microprocessor, a very long instruction word (VLIW) microprocessor, or any other type of processor or processing circuit.</p>
<p id="p-0015" num="0014">Graphics processor(s) <b>124</b> may function as adjunct processor that manages graphics and/or video operations. Graphics processor(s) <b>124</b> may be integrated into the packaging of processor(s) <b>122</b>, onto the motherboard of computing system <b>100</b> or may be coupled via an expansion slot on the motherboard.</p>
<p id="p-0016" num="0015">In one embodiment, network interface <b>126</b> could be a wired interface such as an Ethernet interface (see, e.g., Institute of Electrical and Electronics Engineers/IEEE 802.3-2002) or a wireless interface such as an IEEE 802.11a, b or g-compliant interface (see, e.g., IEEE Standard for IT-Telecommunications and information exchange between systems LAN/MAN&#x2014;Part II: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) specifications Amendment 4: Further Higher Data Rate Extension in the 2.4 GHz Band, 802.11G-2003). Another example of a wireless interface would be a general packet radio service (GPRS) interface (see, e.g., Guidelines on GPRS Handset Requirements, Global System for Mobile Communications/GSM Association, Ver. 3.0.1, December 2002).</p>
<p id="p-0017" num="0016">Bus structures <b>128</b> connect various components of system hardware <b>128</b>. In one embodiment, bus structures <b>128</b> may be one or more of several types of bus structure(s) including a memory bus, a peripheral bus or external bus, and/or a local bus using any variety of available bus architectures including, but not limited to, 11-bit bus, Industrial Standard Architecture (ISA), Micro-Channel Architecture (MSA), Extended ISA (EISA), Intelligent Drive Electronics (IDE), VESA Local Bus (VLB), Peripheral Component Interconnect (PCI), Universal Serial Bus (USB), Advanced Graphics Port (AGP), Personal Computer Memory Card International Association bus (PCMCIA), and Small Computer Systems Interface (SCSI).</p>
<p id="p-0018" num="0017">Memory <b>130</b> may include an operating system <b>140</b> for managing operations of computing device <b>108</b>. In one embodiment, operating system <b>140</b> includes a hardware interface module <b>154</b> that provides an interface to system hardware <b>120</b>. In addition, operating system <b>140</b> may include a file system <b>150</b> that manages files used in the operation of computing device <b>108</b> and a process control subsystem <b>152</b> that manages processes executing on computing device <b>108</b>.</p>
<p id="p-0019" num="0018">Operating system <b>140</b> may include (or manage) one or more communication interfaces that may operate in conjunction with system hardware <b>120</b> to transceive data packets and/or data streams from a remote source. Operating system <b>140</b> may further include a system call interface module <b>142</b> that provides an interface between the operating system <b>140</b> and one or more application modules resident in memory <b>130</b>. Operating system <b>140</b> may be embodied as a UNIX operating system or any derivative thereof (e.g., Linux, Solaris, etc.) or as a Windows&#xae; brand operating system, or other operating systems.</p>
<p id="p-0020" num="0019">In some embodiments memory <b>130</b> comprises a face recognition module <b>160</b> which comprises logic to implement facial recognition techniques. In one embodiment, the face recognition module <b>160</b> may be embodied as logic instructions stored in the computer readable memory module <b>130</b> of the system <b>100</b>. In other embodiments the face recognition module <b>160</b> may be reduced to firmware which may be stored with a basic input/output system (BIOS) for the system <b>100</b>, or to hardwired logic circuitry, e.g., an integrated circuit (IC). Additional details about the operations implemented by graphics processor selection module are described below.</p>
<p id="p-0021" num="0020">Having described various structures of an electronic device adapted to implement face recognition techniques, aspects of face recognition techniques will be explained with reference to <figref idref="DRAWINGS">FIGS. 2-3</figref>, which are flowcharts illustrating operations in a method to implement transaction integrity in accordance with some embodiments. In some embodiments the operations depicted in the flowcharts of <figref idref="DRAWINGS">FIGS. 2-3</figref> may be implemented by the face recognition module <b>160</b>.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart illustrating high-level operations of face recognition techniques implemented by face recognition module <b>160</b>. Referring to <figref idref="DRAWINGS">FIG. 2</figref>, at operation <b>210</b> the face recognition module <b>160</b> stores a plurality of images of faces in a portion of memory <b>130</b>. In some embodiments at least a subset of the plurality of faces have an identity associated with the image of the face. At operation <b>215</b> the images of faces are stored in memory in a virtual graph format such that the faces are positioned as nodes on the graph and images which have sufficiently high correlations for facial features are logically linked on the graph (See, <figref idref="DRAWINGS">FIG. 4</figref>). One skilled in the art will recognize that the graph may be implemented as a virtual constructed stored in the memory module <b>130</b>.</p>
<p id="p-0023" num="0022">At operation <b>220</b> the face recognition module <b>160</b> receives one or more images of unknown faces. At operation <b>225</b> the face recognition module <b>160</b> determines a correlation between features of the received image of an unknown face or faces, and at operation <b>230</b> the face recognition module <b>160</b> establishes a logical connection between the received image of an unknown face and one or more images in the graph. One skilled in the art will recognize that the operations of <figref idref="DRAWINGS">FIG. 2</figref> may be implemented iteratively, resulting in an expanding graph which correlates images of faces.</p>
<p id="p-0024" num="0023">Operations implemented by the face recognition module <b>160</b> will be explained in greater detail with reference to <figref idref="DRAWINGS">FIG. 3</figref>. Referring to <figref idref="DRAWINGS">FIG. 3</figref>, at operation <b>310</b> the face recognition module <b>160</b> receives one or more images of a face or faces. By way of example, in some embodiments the images by be acquired by an input/output device such as camera <b>106</b> on electronic device <b>108</b> and stored in memory <b>130</b>, where they can be accessed by face recognition module <b>160</b>.</p>
<p id="p-0025" num="0024">At operation <b>315</b> an identity may be associated with at least one image of a face received in operation <b>310</b>. By way of example, a user of the electronic device may input one or more images of his or her face to the electronic device via camera <b>106</b> and may associate his or her identity by entering his or her name via a keyboard <b>112</b>. The image(s) and name(s) may be stored in logical association in the memory <b>130</b> or the file store <b>180</b> of electronic device. Alternatively, a file comprising images logically associated with identities may be received in the electronic device, e.g., via a network interface <b>124</b>, and stored in the memory <b>130</b> or file store <b>180</b> of electronic device.</p>
<p id="p-0026" num="0025">At operation <b>320</b> the face recognition module <b>160</b> receives one or more images of unknown faces. By way of example, a user of the electronic device may input additional images of his or her face to the electronic device via camera <b>106</b>. Alternatively, a file comprising facial images which are not logically associated with identities may be received in the electronic device, e.g., via a network interface <b>124</b>, and stored in the memory <b>130</b> or file store <b>180</b> of electronic device.</p>
<p id="p-0027" num="0026">At operation <b>325</b> the face recognition module <b>160</b> analyzes the received facial images and determines a correlation between the unknown images and one or more facial images stored in the memory <b>130</b> or the file store <b>180</b> of electronic device. By way of example, in some embodiments images of faces may be stored in a data adjacency graph (<figref idref="DRAWINGS">FIG. 4</figref>) in the memory <b>130</b> or the file store <b>180</b> of electronic device. The vertices of the data adjacency graph are images of the faces and the weights on its edges are a measure of the correlation between selected facial features.</p>
<p id="p-0028" num="0027">At operation <b>330</b>, the images of unknown faces are added to the data adjacency graph (<figref idref="DRAWINGS">FIG. 4</figref>) as new unlabeled vertices. The vertices are connected to the data adjacency graph by edges. The weights on the edges are correlations, which are computed at operation <b>325</b>.</p>
<p id="p-0029" num="0028">At operation <b>335</b>, if the data adjacency graph (<figref idref="DRAWINGS">FIG. 4</figref>) contains more than k unlabeled vertices, the set of unlabeled vertices in the graph is compressed to no more than k vertices such that the new vertices cover (approximately) all original vertices. This is essential to make the time complexity of operation <b>340</b> independent of the number of all previously seen faces. The parameter k controls the quality of the approximation. Higher values of k result in better approximations but also higher computational costs (and vice versa). One way of compressing the graph efficiently and with theoretical guarantees is by using the online k-center clustering algorithm of Charikar et al. (1997).</p>
<p id="p-0030" num="0029">At operation <b>340</b>, the structure of the data adjacency graph (<figref idref="DRAWINGS">FIG. 4</figref>) is used to establish logical associations between correlated faces. One way of inferring the logical associations is to compute the harmonic function solution:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>l</i><sub>u</sub>=(<i>L</i><sub>uu</sub>+&#x3b3;<sub>g</sub><i>I</i>)<sup>&#x2212;1</sup><i>W</i><sub>ul</sub><i>l</i><sub>l</sub>&#x2003;&#x2003;Eq. 1<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where l is the vector of predictions, L is the Laplacian of the data adjacency graph W, which is represented by a matrix W of pairwise similarities, and u and 1 are the sets of labeled and unlabeled vertices in the graph W, respectively. The parameter &#x3b3;<sub>g </sub>controls the quality of identity predictions. The higher the value of &#x3b3;<sub>g</sub>, the higher the precision and the lower the recall (and vice versa). The i-th element of the vector l represents the probability that the i-th vertex in the data adjacency graph W corresponds to a person whose face is registered in the graph.
</p>
<p id="p-0031" num="0030">At operation <b>345</b> the face recognition module <b>160</b> receives one or more images of known faces. By way of example, a user of the electronic device may input additional images of his or her face to the electronic device via camera <b>106</b>. Alternatively, a file comprising facial images which are not logically associated with identities may be received in the electronic device, e.g., via a network interface <b>124</b>, and stored in the memory <b>130</b> or file store <b>180</b> of electronic device.</p>
<p id="p-0032" num="0031">At operation <b>350</b> the face recognition module <b>160</b> analyzes the received facial images and determines a correlation between the known images and one or more facial images stored in the memory <b>130</b> or the file store <b>180</b> of electronic device. By way of example, in some embodiments images of faces may be stored in a data adjacency graph (<figref idref="DRAWINGS">FIG. 4</figref>) in the memory <b>130</b> or the file store <b>180</b> of electronic device. The vertices of the data adjacency graph are images of the faces and the weights on its edges are a measure of the correlation between selected facial features.</p>
<p id="p-0033" num="0032">At operation <b>355</b>, the images of known faces are added to the data adjacency graph (<figref idref="DRAWINGS">FIG. 4</figref>) as new labeled vertices. The vertices are connected to the data adjacency graph by edges. The weights on the edges are correlations, which are computed at operation <b>350</b>. In addition, the corresponding entry of the prediction vector l is set to 1. In particular, l<sub>i</sub>=1 whenever one of the known and newly added faces was added as the vertex i. This means that the probability that the i-th vertex in the graph corresponds to a person whose face is registered in the graph is 1.</p>
<p id="p-0034" num="0033">Control then passes back to operation <b>310</b> and the face recognition module waits to receive more images of faces to implement an interactive process by which new images may be added to the graph depicted in <figref idref="DRAWINGS">FIG. 4</figref> and correlated with existing pictures on the graph. This provides a mechanism by which an electronic device can learn to recognize faces. Further, the technique allows the electronic device to accommodate changes in face shape, orientation, and changes in lighting conditions.</p>
<p id="p-0035" num="0034">As described above, in some embodiments the electronic device may be embodied as a computer system. <figref idref="DRAWINGS">FIG. 5</figref> is a schematic illustration of a computer system <b>500</b> in accordance with some embodiments. The computer system <b>500</b> includes a computing device <b>502</b> and a power adapter <b>504</b> (e.g., to supply electrical power to the computing device <b>502</b>). The computing device <b>502</b> may be any suitable computing device such as a laptop (or notebook) computer, a personal digital assistant, a desktop computing device (e.g., a workstation or a desktop computer), a rack-mounted computing device, and the like.</p>
<p id="p-0036" num="0035">Electrical power may be provided to various components of the computing device <b>502</b> (e.g., through a computing device power supply <b>506</b>) from one or more of the following sources: one or more battery packs, an alternating current (AC) outlet (e.g., through a transformer and/or adaptor such as a power adapter <b>504</b>), automotive power supplies, airplane power supplies, and the like. In some embodiments, the power adapter <b>504</b> may transform the power supply source output (e.g., the AC outlet voltage of about 110 VAC to 240 VAC) to a direct current (DC) voltage ranging between about 7 VDC to 12.6 VDC. Accordingly, the power adapter <b>504</b> may be an AC/DC adapter.</p>
<p id="p-0037" num="0036">The computing device <b>502</b> may also include one or more central processing unit(s) (CPUs) <b>508</b>. In some embodiments, the CPU <b>508</b> may be one or more processors in the Pentium&#xae; family of processors including the Pentium&#xae; II processor family, Pentium&#xae; III processors, Pentium&#xae; IV, CORE2 Duo processors, or Atom processors available from Intel&#xae; Corporation of Santa Clara, Calif. Alternatively, other CPUs may be used, such as Intel's Itanium&#xae;, XEON&#x2122;, and Celeron&#xae; processors. Also, one or more processors from other manufactures may be utilized. Moreover, the processors may have a single or multi core design.</p>
<p id="p-0038" num="0037">A chipset <b>512</b> may be coupled to, or integrated with, CPU <b>508</b>. The chipset <b>512</b> may include a memory control hub (MCH) <b>514</b>. The MCH <b>514</b> may include a memory controller <b>516</b> that is coupled to a main system memory <b>518</b>. The main system memory <b>518</b> stores data and sequences of instructions that are executed by the CPU <b>508</b>, or any other device included in the system <b>500</b>. In some embodiments, the main system memory <b>518</b> includes random access memory (RAM); however, the main system memory <b>518</b> may be implemented using other memory types such as dynamic RAM (DRAM), synchronous DRAM (SDRAM), and the like. Additional devices may also be coupled to the bus <b>510</b>, such as multiple CPUs and/or multiple system memories.</p>
<p id="p-0039" num="0038">The MCH <b>514</b> may also include a graphics interface <b>520</b> coupled to a graphics accelerator <b>522</b>. In some embodiments, the graphics interface <b>520</b> is coupled to the graphics accelerator <b>522</b> via an accelerated graphics port (AGP). In some embodiments, a display (such as a flat panel display) <b>540</b> may be coupled to the graphics interface <b>520</b> through, for example, a signal converter that translates a digital representation of an image stored in a storage device such as video memory or system memory into display signals that are interpreted and displayed by the display. The display <b>540</b> signals produced by the display device may pass through various control devices before being interpreted by and subsequently displayed on the display.</p>
<p id="p-0040" num="0039">A hub interface <b>524</b> couples the MCH <b>514</b> to an platform control hub (PCH) <b>526</b>. The PCH <b>526</b> provides an interface to input/output (I/O) devices coupled to the computer system <b>500</b>. The PCH <b>526</b> may be coupled to a peripheral component interconnect (PCI) bus. Hence, the PCH <b>526</b> includes a PCI bridge <b>528</b> that provides an interface to a PCI bus <b>530</b>. The PCI bridge <b>528</b> provides a data path between the CPU <b>508</b> and peripheral devices. Additionally, other types of I/O interconnect topologies may be utilized such as the PCI Express&#x2122; architecture, available through Intel&#xae; Corporation of Santa Clara, Calif.</p>
<p id="p-0041" num="0040">The PCI bus <b>530</b> may be coupled to an audio device <b>532</b> and one or more disk drive(s) <b>534</b>. Other devices may be coupled to the PCI bus <b>530</b>. In addition, the CPU <b>508</b> and the MCH <b>514</b> may be combined to form a single chip. Furthermore, the graphics accelerator <b>522</b> may be included within the MCH <b>514</b> in other embodiments.</p>
<p id="p-0042" num="0041">Additionally, other peripherals coupled to the PCH <b>526</b> may include, in various embodiments, integrated drive electronics (IDE) or small computer system interface (SCSI) hard drive(s), universal serial bus (USB) port(s), a keyboard, a mouse, parallel port(s), serial port(s), floppy disk drive(s), digital output support (e.g., digital video interface (DVI)), and the like. Hence, the computing device <b>502</b> may include volatile and/or nonvolatile memory.</p>
<p id="p-0043" num="0042">Thus, there is described herein systems and associated methods to implement adaptive face recognition using online learning in electronic devices. In still other embodiments an electronic device, comprises an input/output module, a memory coupled to the input/output module and logic to store a plurality of images of faces in a memory module, wherein a first subset of the plurality of images have a known identity, construct a graph of the plurality of images of faces in the memory module, wherein the images of faces are positioned as nodes on the graph and images of faces which have a correlation that exceeds a threshold are linked on the graph, subsequently receive an unknown image of a face, determine a correlation between one or more features of the unknown image and one or more features on one or more images of faces in the graph and establish a logical association between the unknown image of a face and the second image of a face.</p>
<p id="p-0044" num="0043">In some embodiments the electronic device may further comprise logic to determine a correlation between one or more features the images and one or more features on one or more images of faces in the graph and establish a logical association between the unknown image of a face. In further embodiments the electronic device may comprise logic to determine a distance parameter between the unknown image and an image in the graph and logic to divide the distance parameter by a heat parameter.</p>
<p id="p-0045" num="0044">The terms &#x201c;logic instructions&#x201d; as referred to herein relates to expressions which may be understood by one or more machines for performing one or more logical operations. For example, logic instructions may comprise instructions which are interpretable by a processor compiler for executing one or more operations on one or more data objects. However, this is merely an example of machine-readable instructions and embodiments are not limited in this respect.</p>
<p id="p-0046" num="0045">The terms &#x201c;computer readable medium&#x201d; as referred to herein relates to media capable of maintaining expressions which are perceivable by one or more machines. For example, a computer readable medium may comprise one or more storage devices for storing computer readable instructions or data. Such storage devices may comprise storage media such as, for example, optical, magnetic or semiconductor storage media. However, this is merely an example of a computer readable medium and embodiments are not limited in this respect.</p>
<p id="p-0047" num="0046">The term &#x201c;logic&#x201d; as referred to herein relates to structure for performing one or more logical operations. For example, logic may comprise circuitry which provides one or more output signals based upon one or more input signals. Such circuitry may comprise a finite state machine which receives a digital input and provides a digital output, or circuitry which provides one or more analog output signals in response to one or more analog input signals. Such circuitry may be provided in an application specific integrated circuit (ASIC) or field programmable gate array (FPGA). Also, logic may comprise machine-readable instructions stored in a memory in combination with processing circuitry to execute such machine-readable instructions. However, these are merely examples of structures which may provide logic and embodiments are not limited in this respect.</p>
<p id="p-0048" num="0047">Some of the methods described herein may be embodied as logic instructions on a computer-readable medium. When executed on a processor, the logic instructions cause a processor to be programmed as a special-purpose machine that implements the described methods. The processor, when configured by the logic instructions to execute the methods described herein, constitutes structure for performing the described methods. Alternatively, the methods described herein may be reduced to logic on, e.g., a field programmable gate array (FPGA), an application specific integrated circuit (ASIC) or the like.</p>
<p id="p-0049" num="0048">In the description and claims, the terms coupled and connected, along with their derivatives, may be used. In particular embodiments, connected may be used to indicate that two or more elements are in direct physical or electrical contact with each other. Coupled may mean that two or more elements are in direct physical or electrical contact. However, coupled may also mean that two or more elements may not be in direct contact with each other, but yet may still cooperate or interact with each other.</p>
<p id="p-0050" num="0049">Reference in the specification to &#x201c;one embodiment&#x201d; or &#x201c;some embodiments&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least an implementation. The appearances of the phrase &#x201c;in one embodiment&#x201d; in various places in the specification may or may not be all referring to the same embodiment.</p>
<p id="p-0051" num="0050">Although embodiments have been described in language specific to structural features and/or methodological acts, it is to be understood that claimed subject matter may not be limited to the specific features or acts described. Rather, the specific features and acts are disclosed as sample forms of implementing the claimed subject matter.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method, comprising:
<claim-text>storing a first image of a face in a memory;</claim-text>
<claim-text>associating an identity with the first image of a face;</claim-text>
<claim-text>subsequently collecting a plurality of additional images of faces;</claim-text>
<claim-text>storing the additional images in the memory;</claim-text>
<claim-text>constructing a data adjacency graph which provides a logical link between images of faces on the graph, wherein each image of a face is represented as a node on the graph and the graph comprises correlations between images;</claim-text>
<claim-text>determining a correlation between features on the first image of a face and one or more of the plurality of additional images of faces;</claim-text>
<claim-text>establishing a logical association between the first image of a face and one or more of the plurality of additional images of faces by computing a harmonic function solution
<claim-text>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x3bb;<sub>u</sub>=(<i>L</i><sub>uu</sub>+&#x3b3;<sub>g</sub><i>I</i>)<sup>&#x2212;1</sup><i>W</i><sub>ul</sub>&#x3bb;<sub>l</sub>, where:<?in-line-formulae description="In-line Formulae" end="tail"?>
</claim-text>
<claim-text>&#x3bb; is a vector of predictions;</claim-text>
<claim-text>L is a Laplacian of the data adjacency graph (W), which is represented by a matrix (W) of pairwise similarities, and u and l are sets of labeled and unlabeled vertices in the data adjacency graph (W), respectively; and</claim-text>
</claim-text>
<claim-text>storing the correlation between the first image and the one or more of the plurality of additional images of faces.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein associating an identity with at least a first image of the face comprises receiving an identifier associated with the face via an input/output module.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining a correlation between features on the first image of a face and the second image of a face comprises determining a distance parameter between the first image and the second image.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. An electronic device, comprising:
<claim-text>an input/output module;</claim-text>
<claim-text>a memory coupled to the input/output module; and</claim-text>
<claim-text>logic to:
<claim-text>store a first image of a face in the memory;</claim-text>
<claim-text>associate an identity with the first image of a face;</claim-text>
<claim-text>subsequently collect a plurality of additional images of faces;</claim-text>
<claim-text>store the additional images in the memory;</claim-text>
<claim-text>construct a data adjacency graph which provides a logical link between images of faces on the graph, wherein each image of a face is represented as a node on the graph and the graph comprises correlations between images;</claim-text>
<claim-text>determine a correlation between features on the first image of a face and the one or more of the plurality of additional images of faces;</claim-text>
<claim-text>establish a logical association between the first image of a face and one or more of the plurality of additional images of faces by computing a harmonic function solution
<claim-text>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x3bb;<sub>u</sub>=(<i>L</i><sub>uu</sub>+&#x3b3;<sub>g</sub><i>I</i>)<sup>&#x2212;1</sup><i>W</i><sub>ul</sub>&#x3bb;<sub>l</sub>, where:<?in-line-formulae description="In-line Formulae" end="tail"?>
</claim-text>
<claim-text>&#x3bb; is a vector of predictions;</claim-text>
<claim-text>L is a Laplacian of the data adjacency graph (W), which is represented by a matrix (W) of pairwise similarities, and u and l are sets of labeled and unlabeled vertices in the data adjacency graph (W), respectively; and</claim-text>
</claim-text>
<claim-text>store the correlation between the first image and the one or more of the plurality of additional images of faces.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The electronic device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising logic to receive an identifier associated with the face via the input/output module.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The electronic device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising logic to determine a distance parameter between the first image and the second image.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A computer program product comprising logic instruction stored on a non-transitory computer-readable medium which, when executed by a processor, configure the processor to implement a method, comprising:
<claim-text>storing a first image of a face in a memory;</claim-text>
<claim-text>associating an identity with the first image of a face;</claim-text>
<claim-text>subsequently collecting a plurality of additional images of faces;</claim-text>
<claim-text>storing the additional images in the memory;</claim-text>
<claim-text>constructing a data adjacency graph which provides a logical link between images of faces on the graph, wherein each image of a face is represented as a node on the graph and the graph comprises correlations between images;</claim-text>
<claim-text>determining a correlation between features on the first image of a face and one or more of the plurality of additional images of faces;</claim-text>
<claim-text>establishing a logical association between the first image of a face and one or more of the plurality of additional images of faces by computing a harmonic function solution
<claim-text>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>&#x3bb;<sub>u</sub>=(<i>L</i><sub>uu</sub>+&#x3b3;<sub>g</sub><i>I</i>)<sup>&#x2212;1</sup><i>W</i><sub>ul</sub>&#x3bb;<sub>l</sub>, where:<?in-line-formulae description="In-line Formulae" end="tail"?>
</claim-text>
<claim-text>&#x3bb; is a vector of predictions;</claim-text>
<claim-text>L is a Laplacian of the data adjacency graph (W), which is represented by a matrix (W) of pairwise similarities, and u and l are sets of labeled and unlabeled vertices in the data adjacency graph (W), respectively; and</claim-text>
</claim-text>
<claim-text>storing the correlation between the first image and the one or more of the plurality of additional images of faces.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer program product of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein associating an identity with at least a first image of the face comprises receiving an identifier associated with the face via an input/output module.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer program product of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein determining a correlation between features on the first image of a face and the second image of a face comprises determining a distance parameter between the first image and the second image.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer program product of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein:
<claim-text>each image of a face is represented as a node on the graph;</claim-text>
<claim-text>images which have correlations that exceed the first threshold value are linked to one another on the graph; and</claim-text>
<claim-text>images which have correlations does not exceed second threshold value are isolated on the graph as outliers.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
