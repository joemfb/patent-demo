<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08622303-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08622303</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13230516</doc-number>
<date>20110912</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>7</main-group>
<subgroup>10</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>23546201</main-classification>
<further-classification>23547201</further-classification>
</classification-national>
<invention-title id="d2e51">Decoding utilizing image data</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4097847</doc-number>
<kind>A</kind>
<name>Forsen et al.</name>
<date>19780600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4538060</doc-number>
<kind>A</kind>
<name>Sakai et al.</name>
<date>19850800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4542528</doc-number>
<kind>A</kind>
<name>Sanner et al.</name>
<date>19850900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>4721849</doc-number>
<kind>A</kind>
<name>Davis et al.</name>
<date>19880100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>4758717</doc-number>
<kind>A</kind>
<name>Shepard et al.</name>
<date>19880700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>4760248</doc-number>
<kind>A</kind>
<name>Swartz et al.</name>
<date>19880700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>4818847</doc-number>
<kind>A</kind>
<name>Hara et al.</name>
<date>19890400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>4825058</doc-number>
<kind>A</kind>
<name>Poland</name>
<date>19890400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>4841132</doc-number>
<kind>A</kind>
<name>Kajitani et al.</name>
<date>19890600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>4877949</doc-number>
<kind>A</kind>
<name>Danielson et al.</name>
<date>19891000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>4930848</doc-number>
<kind>A</kind>
<name>Knowles</name>
<date>19900600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>4945216</doc-number>
<kind>A</kind>
<name>Tanabe et al.</name>
<date>19900700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>4964167</doc-number>
<kind>A</kind>
<name>Kunizawa et al.</name>
<date>19901000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>4983818</doc-number>
<kind>A</kind>
<name>Knowles</name>
<date>19910100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5019699</doc-number>
<kind>A</kind>
<name>Koenck</name>
<date>19910500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>5099110</doc-number>
<kind>A</kind>
<name>Shepard et al.</name>
<date>19920300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>5168149</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19921200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>5216233</doc-number>
<kind>A</kind>
<name>Main et al.</name>
<date>19930600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>5223701</doc-number>
<kind>A</kind>
<name>Batterman et al.</name>
<date>19930600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>5235167</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19930800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>5272323</doc-number>
<kind>A</kind>
<name>Martino</name>
<date>19931200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>5280165</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19940100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>5304787</doc-number>
<kind>A</kind>
<name>Wang</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>5311001</doc-number>
<kind>A</kind>
<name>Joseph et al.</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>5313053</doc-number>
<kind>A</kind>
<name>Koenck et al.</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>5317136</doc-number>
<kind>A</kind>
<name>Hasegawa et al.</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>5331176</doc-number>
<kind>A</kind>
<name>Sant' Anselmo et al.</name>
<date>19940700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>5354977</doc-number>
<kind>A</kind>
<name>Roustaei</name>
<date>19941000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>5367151</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19941100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>5373148</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19941200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>5378883</doc-number>
<kind>A</kind>
<name>Batterman et al.</name>
<date>19950100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>5404002</doc-number>
<kind>A</kind>
<name>Tang</name>
<date>19950400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>5408081</doc-number>
<kind>A</kind>
<name>Barkan</name>
<date>19950400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>5410141</doc-number>
<kind>A</kind>
<name>Koenck et al.</name>
<date>19950400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>5412198</doc-number>
<kind>A</kind>
<name>Dvorkis</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>5418357</doc-number>
<kind>A</kind>
<name>Inoue et al.</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>5420411</doc-number>
<kind>A</kind>
<name>Salatto, Jr. et al.</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>5478997</doc-number>
<kind>A</kind>
<name>Bridgelall et al.</name>
<date>19951200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>5479000</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19951200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>5486944</doc-number>
<kind>A</kind>
<name>Bard et al.</name>
<date>19960100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>5504316</doc-number>
<kind>A</kind>
<name>Bridgelall et al.</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>5504367</doc-number>
<kind>A</kind>
<name>Arackellian et al.</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>5543610</doc-number>
<kind>A</kind>
<name>Bard et al.</name>
<date>19960800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>5552592</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19960900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>5557095</doc-number>
<kind>A</kind>
<name>Clark et al.</name>
<date>19960900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>5561283</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>5576529</doc-number>
<kind>A</kind>
<name>Koenck et al.</name>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>5579487</doc-number>
<kind>A</kind>
<name>Meyerson et al.</name>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>5581067</doc-number>
<kind>A</kind>
<name>Grosfeld et al.</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>5581070</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>5585616</doc-number>
<kind>A</kind>
<name>Roxby et al.</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>5589679</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>5591955</doc-number>
<kind>A</kind>
<name>Laser</name>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>5598007</doc-number>
<kind>A</kind>
<name>Bunce et al.</name>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>5600119</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19970200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>5621371</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>5637856</doc-number>
<kind>A</kind>
<name>Bridgelall et al.</name>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00058">
<document-id>
<country>US</country>
<doc-number>5648650</doc-number>
<kind>A</kind>
<name>Sugifune et al.</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00059">
<document-id>
<country>US</country>
<doc-number>5682029</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00060">
<document-id>
<country>US</country>
<doc-number>5691528</doc-number>
<kind>A</kind>
<name>Wyatt et al.</name>
<date>19971100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00061">
<document-id>
<country>US</country>
<doc-number>5693929</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00062">
<document-id>
<country>US</country>
<doc-number>5696607</doc-number>
<kind>A</kind>
<name>Yamana et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00063">
<document-id>
<country>US</country>
<doc-number>5698835</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00064">
<document-id>
<country>US</country>
<doc-number>5703349</doc-number>
<kind>A</kind>
<name>Meyerson et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00065">
<document-id>
<country>US</country>
<doc-number>5705799</doc-number>
<kind>A</kind>
<name>Li</name>
<date>19980100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00066">
<document-id>
<country>US</country>
<doc-number>5714746</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00067">
<document-id>
<country>US</country>
<doc-number>5717195</doc-number>
<kind>A</kind>
<name>Feng et al.</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00068">
<document-id>
<country>US</country>
<doc-number>5717221</doc-number>
<kind>A</kind>
<name>Li et al.</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00069">
<document-id>
<country>US</country>
<doc-number>5736726</doc-number>
<kind>A</kind>
<name>VanHorn et al.</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00070">
<document-id>
<country>US</country>
<doc-number>5739518</doc-number>
<kind>A</kind>
<name>Wang</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00071">
<document-id>
<country>US</country>
<doc-number>5750975</doc-number>
<kind>A</kind>
<name>Myerson et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00072">
<document-id>
<country>US</country>
<doc-number>5756981</doc-number>
<kind>A</kind>
<name>Roustaei et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00073">
<document-id>
<country>US</country>
<doc-number>5763863</doc-number>
<kind>A</kind>
<name>Grosfeld et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00074">
<document-id>
<country>US</country>
<doc-number>5763864</doc-number>
<kind>A</kind>
<name>O'Hagan et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00075">
<document-id>
<country>US</country>
<doc-number>5767500</doc-number>
<kind>A</kind>
<name>Cordes et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00076">
<document-id>
<country>US</country>
<doc-number>5773810</doc-number>
<kind>A</kind>
<name>Hussey et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00077">
<document-id>
<country>US</country>
<doc-number>5780831</doc-number>
<kind>A</kind>
<name>Seo et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00078">
<document-id>
<country>US</country>
<doc-number>5784102</doc-number>
<kind>A</kind>
<name>Hussey et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00079">
<document-id>
<country>US</country>
<doc-number>5786582</doc-number>
<kind>A</kind>
<name>Roustaei et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00080">
<document-id>
<country>US</country>
<doc-number>5801371</doc-number>
<kind>A</kind>
<name>Kahn et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00081">
<document-id>
<country>US</country>
<doc-number>5802179</doc-number>
<kind>A</kind>
<name>Yamamoto et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00082">
<document-id>
<country>US</country>
<doc-number>5814827</doc-number>
<kind>A</kind>
<name>Katz</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00083">
<document-id>
<country>US</country>
<doc-number>5818528</doc-number>
<kind>A</kind>
<name>Roth et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00084">
<document-id>
<country>US</country>
<doc-number>5821518</doc-number>
<kind>A</kind>
<name>Sussmeier et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00085">
<document-id>
<country>US</country>
<doc-number>5821521</doc-number>
<kind>A</kind>
<name>Bridgelall et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00086">
<document-id>
<country>US</country>
<doc-number>5825006</doc-number>
<kind>A</kind>
<name>Longacre, Jr. et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00087">
<document-id>
<country>US</country>
<doc-number>5825013</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00088">
<document-id>
<country>US</country>
<doc-number>5825617</doc-number>
<kind>A</kind>
<name>Kochis et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00089">
<document-id>
<country>US</country>
<doc-number>5837986</doc-number>
<kind>A</kind>
<name>Barile et al.</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00090">
<document-id>
<country>US</country>
<doc-number>5848064</doc-number>
<kind>A</kind>
<name>Cowan</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00091">
<document-id>
<country>US</country>
<doc-number>5850078</doc-number>
<kind>A</kind>
<name>Giordano et al.</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00092">
<document-id>
<country>US</country>
<doc-number>5859417</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00093">
<document-id>
<country>US</country>
<doc-number>5859970</doc-number>
<kind>A</kind>
<name>Pleso</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00094">
<document-id>
<country>US</country>
<doc-number>5861615</doc-number>
<kind>A</kind>
<name>Bridgelall et al.</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00095">
<document-id>
<country>US</country>
<doc-number>5872354</doc-number>
<kind>A</kind>
<name>Hanson</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00096">
<document-id>
<country>US</country>
<doc-number>5874720</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00097">
<document-id>
<country>US</country>
<doc-number>5877487</doc-number>
<kind>A</kind>
<name>Tani et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00098">
<document-id>
<country>US</country>
<doc-number>5880542</doc-number>
<kind>A</kind>
<name>Leary et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00099">
<document-id>
<country>US</country>
<doc-number>5886338</doc-number>
<kind>A</kind>
<name>Arackellian et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00100">
<document-id>
<country>US</country>
<doc-number>5894348</doc-number>
<kind>A</kind>
<name>Bacchi et al.</name>
<date>19990400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00101">
<document-id>
<country>US</country>
<doc-number>5900613</doc-number>
<kind>A</kind>
<name>Koziol et al.</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00102">
<document-id>
<country>US</country>
<doc-number>5900617</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00103">
<document-id>
<country>US</country>
<doc-number>5905251</doc-number>
<kind>A</kind>
<name>Knowles</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00104">
<document-id>
<country>US</country>
<doc-number>5917173</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00105">
<document-id>
<country>US</country>
<doc-number>5918194</doc-number>
<kind>A</kind>
<name>Banaska et al.</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00106">
<document-id>
<country>US</country>
<doc-number>5920061</doc-number>
<kind>A</kind>
<name>Feng</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00107">
<document-id>
<country>US</country>
<doc-number>5923025</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00108">
<document-id>
<country>US</country>
<doc-number>5925872</doc-number>
<kind>A</kind>
<name>Wyatt et al.</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00109">
<document-id>
<country>US</country>
<doc-number>5929418</doc-number>
<kind>A</kind>
<name>Ehrhart et al.</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00110">
<document-id>
<country>US</country>
<doc-number>5942741</doc-number>
<kind>A</kind>
<name>Longacre, Jr. et al.</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00111">
<document-id>
<country>US</country>
<doc-number>5945659</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00112">
<document-id>
<country>US</country>
<doc-number>5949056</doc-number>
<kind>A</kind>
<name>White</name>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00113">
<document-id>
<country>US</country>
<doc-number>5984188</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00114">
<document-id>
<country>US</country>
<doc-number>5988506</doc-number>
<kind>A</kind>
<name>Schaham et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00115">
<document-id>
<country>US</country>
<doc-number>5988508</doc-number>
<kind>A</kind>
<name>Bridgelall et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00116">
<document-id>
<country>US</country>
<doc-number>5992744</doc-number>
<kind>A</kind>
<name>Smith et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00117">
<document-id>
<country>US</country>
<doc-number>6000619</doc-number>
<kind>A</kind>
<name>Reddersen et al.</name>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00118">
<document-id>
<country>US</country>
<doc-number>6015088</doc-number>
<kind>A</kind>
<name>Parker et al.</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>23546201</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00119">
<document-id>
<country>US</country>
<doc-number>6053408</doc-number>
<kind>A</kind>
<name>Stoner</name>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00120">
<document-id>
<country>US</country>
<doc-number>6056200</doc-number>
<kind>A</kind>
<name>Dvorkis et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00121">
<document-id>
<country>US</country>
<doc-number>6115678</doc-number>
<kind>A</kind>
<name>Lieb et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00122">
<document-id>
<country>US</country>
<doc-number>6123261</doc-number>
<kind>A</kind>
<name>Roustaei</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00123">
<document-id>
<country>US</country>
<doc-number>6123263</doc-number>
<kind>A</kind>
<name>Feng</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00124">
<document-id>
<country>US</country>
<doc-number>6155490</doc-number>
<kind>A</kind>
<name>Ackley</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00125">
<document-id>
<country>US</country>
<doc-number>6155491</doc-number>
<kind>A</kind>
<name>Dueker et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00126">
<document-id>
<country>US</country>
<doc-number>6164546</doc-number>
<kind>A</kind>
<name>Kumagai et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00127">
<document-id>
<country>US</country>
<doc-number>6179208</doc-number>
<kind>B1</kind>
<name>Feng</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00128">
<document-id>
<country>US</country>
<doc-number>6189788</doc-number>
<kind>B1</kind>
<name>Sherman et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00129">
<document-id>
<country>US</country>
<doc-number>6199044</doc-number>
<kind>B1</kind>
<name>Ackley et al.</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00130">
<document-id>
<country>US</country>
<doc-number>6213397</doc-number>
<kind>B1</kind>
<name>Rando</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00131">
<document-id>
<country>US</country>
<doc-number>6223988</doc-number>
<kind>B1</kind>
<name>Batterman et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00132">
<document-id>
<country>US</country>
<doc-number>6227450</doc-number>
<kind>B1</kind>
<name>Blake et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00133">
<document-id>
<country>US</country>
<doc-number>6283372</doc-number>
<kind>B1</kind>
<name>Li</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00134">
<document-id>
<country>US</country>
<doc-number>6330973</doc-number>
<kind>B1</kind>
<name>Bridgelall et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00135">
<document-id>
<country>US</country>
<doc-number>6347163</doc-number>
<kind>B2</kind>
<name>Roustaei</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00136">
<document-id>
<country>US</country>
<doc-number>6348773</doc-number>
<kind>B1</kind>
<name>Dvorkis et al.</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00137">
<document-id>
<country>US</country>
<doc-number>6389182</doc-number>
<kind>B1</kind>
<name>Ihara et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00138">
<document-id>
<country>US</country>
<doc-number>6412697</doc-number>
<kind>B1</kind>
<name>Bridgelall et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00139">
<document-id>
<country>US</country>
<doc-number>6419633</doc-number>
<kind>B1</kind>
<name>Robinson et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00140">
<document-id>
<country>US</country>
<doc-number>6439461</doc-number>
<kind>B2</kind>
<name>Dvorkis et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00141">
<document-id>
<country>US</country>
<doc-number>6488209</doc-number>
<kind>B1</kind>
<name>Hunt et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00142">
<document-id>
<country>US</country>
<doc-number>6491223</doc-number>
<kind>B1</kind>
<name>Longacre, Jr. et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00143">
<document-id>
<country>US</country>
<doc-number>6491225</doc-number>
<kind>B1</kind>
<name>Dvorkis et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00144">
<document-id>
<country>US</country>
<doc-number>6497368</doc-number>
<kind>B1</kind>
<name>Friend et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00145">
<document-id>
<country>US</country>
<doc-number>6505778</doc-number>
<kind>B1</kind>
<name>Reddersen et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00146">
<document-id>
<country>US</country>
<doc-number>6507864</doc-number>
<kind>B1</kind>
<name>Klein et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00147">
<document-id>
<country>US</country>
<doc-number>6527180</doc-number>
<kind>B1</kind>
<name>Dvorkis et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00148">
<document-id>
<country>US</country>
<doc-number>6539059</doc-number>
<kind>B1</kind>
<name>Sriram et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524025</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00149">
<document-id>
<country>US</country>
<doc-number>6539422</doc-number>
<kind>B1</kind>
<name>Hunt et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00150">
<document-id>
<country>US</country>
<doc-number>6575370</doc-number>
<kind>B1</kind>
<name>Dvorkis et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00151">
<document-id>
<country>US</country>
<doc-number>6578766</doc-number>
<kind>B1</kind>
<name>Parker et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00152">
<document-id>
<country>US</country>
<doc-number>6585160</doc-number>
<kind>B2</kind>
<name>Dvorkis et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00153">
<document-id>
<country>US</country>
<doc-number>6602194</doc-number>
<kind>B2</kind>
<name>Roundhill et al.</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00154">
<document-id>
<country>US</country>
<doc-number>6616042</doc-number>
<kind>B1</kind>
<name>Gofman et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00155">
<document-id>
<country>US</country>
<doc-number>6637658</doc-number>
<kind>B2</kind>
<name>Barber et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00156">
<document-id>
<country>US</country>
<doc-number>6708866</doc-number>
<kind>B2</kind>
<name>Holman et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00157">
<document-id>
<country>US</country>
<doc-number>6714983</doc-number>
<kind>B1</kind>
<name>Koenck et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00158">
<document-id>
<country>US</country>
<doc-number>6715685</doc-number>
<kind>B2</kind>
<name>Dvorkis</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00159">
<document-id>
<country>US</country>
<doc-number>6732915</doc-number>
<kind>B1</kind>
<name>Nelson et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00160">
<document-id>
<country>US</country>
<doc-number>6732933</doc-number>
<kind>B2</kind>
<name>Waxelbaum</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00161">
<document-id>
<country>US</country>
<doc-number>6819715</doc-number>
<kind>B2</kind>
<name>Nishi et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524025</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00162">
<document-id>
<country>US</country>
<doc-number>6869016</doc-number>
<kind>B2</kind>
<name>Waxelbaum</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00163">
<document-id>
<country>US</country>
<doc-number>6874689</doc-number>
<kind>B2</kind>
<name>Blake et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00164">
<document-id>
<country>US</country>
<doc-number>7055747</doc-number>
<kind>B2</kind>
<name>Havens et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00165">
<document-id>
<country>US</country>
<doc-number>7086596</doc-number>
<kind>B2</kind>
<name>Meier et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00166">
<document-id>
<country>US</country>
<doc-number>7090132</doc-number>
<kind>B2</kind>
<name>Havens et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00167">
<document-id>
<country>US</country>
<doc-number>7195164</doc-number>
<kind>B2</kind>
<name>Patel</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00168">
<document-id>
<country>US</country>
<doc-number>7296751</doc-number>
<kind>B2</kind>
<name>Barber et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00169">
<document-id>
<country>US</country>
<doc-number>7389929</doc-number>
<kind>B2</kind>
<name>Havens et al.</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00170">
<document-id>
<country>US</country>
<doc-number>7500614</doc-number>
<kind>B2</kind>
<name>Barber et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00171">
<document-id>
<country>US</country>
<doc-number>7690572</doc-number>
<kind>B2</kind>
<name>Meier et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00172">
<document-id>
<country>US</country>
<doc-number>2003/0222147</doc-number>
<kind>A1</kind>
<name>Havens et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00173">
<document-id>
<country>US</country>
<doc-number>2004/0020990</doc-number>
<kind>A1</kind>
<name>Havens et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00174">
<document-id>
<country>US</country>
<doc-number>2004/0164165</doc-number>
<kind>A1</kind>
<name>Havens et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00175">
<document-id>
<country>US</country>
<doc-number>2005/0100099</doc-number>
<kind>A1</kind>
<name>Nishi et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524025</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00176">
<document-id>
<country>US</country>
<doc-number>2006/0255144</doc-number>
<kind>A1</kind>
<name>Meier et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235454</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00177">
<document-id>
<country>EP</country>
<doc-number>456095</doc-number>
<kind>A2</kind>
<date>19911100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00178">
<document-id>
<country>EP</country>
<doc-number>517957</doc-number>
<kind>A2</kind>
<date>19921200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00179">
<document-id>
<country>EP</country>
<doc-number>540781</doc-number>
<kind>A2</kind>
<date>19930500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00180">
<document-id>
<country>EP</country>
<doc-number>590537</doc-number>
<kind>A2</kind>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00181">
<document-id>
<country>EP</country>
<doc-number>653723</doc-number>
<kind>A2</kind>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00182">
<document-id>
<country>EP</country>
<doc-number>690404</doc-number>
<kind>A2</kind>
<date>19960100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00183">
<document-id>
<country>EP</country>
<doc-number>730241</doc-number>
<kind>A2</kind>
<date>19960900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00184">
<document-id>
<country>EP</country>
<doc-number>818750</doc-number>
<kind>A2</kind>
<date>19980100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00185">
<document-id>
<country>EP</country>
<doc-number>910032</doc-number>
<kind>A2</kind>
<date>19990400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00186">
<document-id>
<country>EP</country>
<doc-number>974924</doc-number>
<kind>A2</kind>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00187">
<document-id>
<country>EP</country>
<doc-number>999514</doc-number>
<kind>A1</kind>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00188">
<document-id>
<country>EP</country>
<doc-number>1079466</doc-number>
<kind>A2</kind>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00189">
<document-id>
<country>EP</country>
<doc-number>1128315</doc-number>
<kind>A1</kind>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00190">
<document-id>
<country>EP</country>
<doc-number>1310903</doc-number>
<kind>A1</kind>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00191">
<document-id>
<country>GB</country>
<doc-number>2128549</doc-number>
<kind>A</kind>
<date>19840500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00192">
<document-id>
<country>JP</country>
<doc-number>04330583</doc-number>
<kind>A</kind>
<date>19921100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00193">
<document-id>
<country>JP</country>
<doc-number>2002-150215</doc-number>
<kind>A</kind>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00194">
<document-id>
<country>WO</country>
<doc-number>9708647</doc-number>
<date>19970300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00195">
<document-id>
<country>WO</country>
<doc-number>9728512</doc-number>
<kind>A1</kind>
<date>19970800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00196">
<document-id>
<country>WO</country>
<doc-number>01/26036</doc-number>
<kind>A2</kind>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00197">
<document-id>
<country>WO</country>
<doc-number>02073953</doc-number>
<kind>A2</kind>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00198">
<document-id>
<country>WO</country>
<doc-number>03102858</doc-number>
<kind>A1</kind>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00199">
<othercit>International Preliminary Examination Report for Application No. PCT/US03/17516 dated Aug. 23, 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00200">
<othercit>International Search Report for Application No. PCT/US03/17516 dated Sep. 23, 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00201">
<othercit>International Search Report for Application No. PCT/US03/17516 dated Sep. 30, 2003.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00202">
<othercit>U.S. Appl. No. 60/437,959, filed Jan. 3, 2003, priority of which is claimed in U.S. Appl. No. 10/425,694, filed Apr. 29, 2003, 25 pages.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00203">
<othercit>U.S. 5,637,857, 06/1997, Dvorkis et al. (withdrawn).</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00204">
<othercit>Written Opinion for Application No. PCT/US03/17516 dated Apr. 1, 2005.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>15</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>2354621-46225</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>23547201-47203</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>26</number-of-drawing-sheets>
<number-of-figures>56</number-of-figures>
</figures>
<us-related-documents>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>12754368</doc-number>
<date>20100405</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>8016196</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>13230516</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>11442666</doc-number>
<date>20060526</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7690572</doc-number>
<date>20100406</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>12754368</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10339439</doc-number>
<date>20030109</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7086596</doc-number>
<date>20060808</date>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11442666</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120000981</doc-number>
<kind>A1</kind>
<date>20120105</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Meier</last-name>
<first-name>Timothy P</first-name>
<address>
<city>Camillus</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Gardiner</last-name>
<first-name>Robert C.</first-name>
<address>
<city>Fayetteville</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Harper</last-name>
<first-name>Jeffrey Dean</first-name>
<address>
<city>Charlotte</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Izzo</last-name>
<first-name>John</first-name>
<address>
<city>Auburn</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="005" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Koziol</last-name>
<first-name>Thomas J.</first-name>
<address>
<city>Camillus</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="006" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Longacre, Jr.</last-name>
<first-name>Andrew</first-name>
<address>
<city>Skaneateles</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="007" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Pettinelli</last-name>
<first-name>John A.</first-name>
<address>
<city>Camillus</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Meier</last-name>
<first-name>Timothy P</first-name>
<address>
<city>Camillus</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Gardiner</last-name>
<first-name>Robert C.</first-name>
<address>
<city>Fayetteville</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Harper</last-name>
<first-name>Jeffrey Dean</first-name>
<address>
<city>Charlotte</city>
<state>NC</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Izzo</last-name>
<first-name>John</first-name>
<address>
<city>Auburn</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="005" designation="us-only">
<addressbook>
<last-name>Koziol</last-name>
<first-name>Thomas J.</first-name>
<address>
<city>Camillus</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="006" designation="us-only">
<addressbook>
<last-name>Longacre, Jr.</last-name>
<first-name>Andrew</first-name>
<address>
<city>Skaneateles</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="007" designation="us-only">
<addressbook>
<last-name>Pettinelli</last-name>
<first-name>John A.</first-name>
<address>
<city>Camillus</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Additon, Higgins, Pendleton &#x26; Ashe, P.A.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hand Held Products, Inc.</orgname>
<role>02</role>
<address>
<city>Fort Mill</city>
<state>SC</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Le</last-name>
<first-name>Thien M</first-name>
<department>2887</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The invention relates to decoding utilizing image data. The image data can be received from a source. A processor can process the image data for decoding. A processing for decoding can be responsive to determined information.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="127.08mm" wi="117.26mm" file="US08622303-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="243.59mm" wi="168.99mm" file="US08622303-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="246.97mm" wi="175.09mm" file="US08622303-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="225.55mm" wi="168.40mm" file="US08622303-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="180.85mm" wi="155.53mm" file="US08622303-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="206.16mm" wi="151.55mm" file="US08622303-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="261.03mm" wi="172.38mm" orientation="landscape" file="US08622303-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="243.16mm" wi="180.85mm" orientation="landscape" file="US08622303-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="243.08mm" wi="165.95mm" file="US08622303-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="224.37mm" wi="178.73mm" file="US08622303-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="249.68mm" wi="169.42mm" file="US08622303-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="254.51mm" wi="180.85mm" file="US08622303-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="251.88mm" wi="159.26mm" file="US08622303-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="241.81mm" wi="152.65mm" file="US08622303-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="257.81mm" wi="158.50mm" file="US08622303-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="252.81mm" wi="157.65mm" file="US08622303-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="250.53mm" wi="151.89mm" file="US08622303-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="258.57mm" wi="162.14mm" file="US08622303-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="260.69mm" wi="171.03mm" file="US08622303-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="237.74mm" wi="175.68mm" file="US08622303-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="203.37mm" wi="187.11mm" file="US08622303-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="264.24mm" wi="168.15mm" file="US08622303-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="254.51mm" wi="180.85mm" file="US08622303-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="184.32mm" wi="179.83mm" file="US08622303-20140107-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="201.42mm" wi="164.17mm" orientation="landscape" file="US08622303-20140107-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="251.54mm" wi="159.60mm" file="US08622303-20140107-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00026" num="00026">
<img id="EMI-D00026" he="197.19mm" wi="172.47mm" file="US08622303-20140107-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a divisional of U.S. patent application Ser. No. 12/754,368, filed Apr. 5, 2010 entitled &#x201c;Decoder Board For An Optical Reader Utilizing A Plurality Of Imaging Formats,&#x201d; which is incorporated herein by reference, which is a continuation of U.S. patent application Ser. No. 11/442,666, filed May 26, 2006 entitled &#x201c;Decoder Board For An Optical Reader Utilizing A Plurality Of Imaging Formats&#x201d; (now U.S. Pat. No. 7,690,572), which is incorporated herein by reference, which is a divisional of U.S. patent application Ser. No. 10/339,439 filed Jan. 9, 2003, entitled &#x201c;Decoder Board For An Optical Reader Utilizing A Plurality Of Imaging Formats&#x201d; (now U.S. Pat. No. 7,086,596), which is incorporated herein by reference. This application is related to the applications enumerated below, all of which are being filed with the United States Patent and Trademark Office on Jan. 9, 2003, and all of which are subject to assignment to the same assignee of this application, the disclosure of each of which is incorporated herein by reference in its entirety: U.S. patent application Ser. No. 10/339,275, entitled &#x201c;Housing for an Optical Reader&#x201d; (now U.S. Pat. No. 7,147,162); U.S. patent application Ser. No. 10/339,424 (now abandoned), entitled &#x201c;Optical Reader System Comprising Digital Conversion&#x201d; (U.S. Patent Publication No. 2004/0004128); U.S. patent application Ser. No. 10/339,004 (now abandoned), entitled &#x201c;Analog-to-Digital Converter with Automatic Range and Sensitivity Adjustment&#x201d; (U.S. Patent Publication No. 2004/0134988); U.S. patent application Ser. No. 10/339,061 (now abandoned), entitled &#x201c;Manufacturing Methods for a Decoder Board for an Optical Reader Utilizing a Plurality of Imaging Formats&#x201d; (U.S. Patent Publication No. 2003/0222144); and U.S. patent application Ser. No. 10/339,281 (now abandoned), entitled &#x201c;Optical Reader Having Position Responsive Decode Launch Circuit&#x201d; (U.S. Patent Publication No. 2003/0168512).</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The invention relates to decoding in general and particularly to decoding utilizing image data.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Decodable indicia such as bar codes and OCR decodable characters are finding increased use in an ever expanding variety of applications. For example, bar codes are being applied to paper substrate surfaces, plastic bags, glass, and directly on finished articles. Decodable indicia that can be applied deliberately to objects include a variety of formats, comprising geometrical features (e.g., one-dimensional (1D) symbols, two-dimensional (2D) symbols), and features of tonality and/or color (e.g., symbols comprising gray scales and symbols comprising colors). Decodable indicia can also occur naturally, for example in the form of biometric indicia such as fingerprints, retinal patterns, facial features and the like. Some of these natural indicia may also be applied, deliberately or inadvertently, to other surfaces, for example as fingerprints.</p>
<p id="p-0005" num="0004">Often, different types of decodable indicia require imaging modules that provide different data formats. The term &#x201c;imaging module&#x201d; is intended in one embodiment to describe the image sensor device itself. The sensor when disposed within a housing, and including, as required, imaging optics, lenses, filters and the like, and electronic circuitry used to operate the image sensor device or used in conjunction with the image sensor device, is referred to as an optical reader. Historically, one type of decoder module has been used with imaging modules providing data having a first format (for example, 1D data), and another type of decoder module has been used with imaging modules providing data having a second format (for example, 2D data). In general, the computational power required to decode more densely encoded decodable indicia causes decoder modules suitable for such decoding to be relatively expensive as compared to decoder modules with only sufficient computational power to decode less complex decodable indicia. This relationship is generally referred to as a &#x201c;price-performance trade-off.&#x201d;</p>
<p id="p-0006" num="0005">A number of problems in imaging different decodable indicia arise because of the circumstances of use of the decodable indicia. For example, where decodable symbols or characters have been applied to particularly reflective &#x201c;shiny&#x201d; surfaces (such as glass, plastic, or metallic surfaces), &#x201c;specular reflection&#x201d; decode failures have been observed. &#x201c;Specular reflection&#x201d; occurs where a light ray incident on a highly reflective (mirror) surface is reflected at an angle substantially equal to an angle of incidence measured with respect to a direction that is substantially normal to the surface. In optical readers, light sources are positioned to emit light along a path closely adjacent a centrally located imaging axis. An optical reader light is directed at a reflective target and, therefore, the illumination light tends to be reflected secularly in the direction of the reader's photodetector elements. Specular reflection can result in the captured image data failing to exhibit adequate contrast between dark and light markings of a decodable indicia. With the increased miniaturization of optical readers, light sources for illuminating a target are being positioned in closer proximity with a photodetector element of the reader, thereby rendering the modern reader more susceptible to specular reflection read failures.</p>
<p id="p-0007" num="0006">The proliferation of the use of decodable markings has brought to light additional problems with presently available optical readers. It has become more common to encode more information into single decodable indicia, e.g. with use of &#x201c;high density&#x201d; bar codes, to affix more than one decodable indicia in need of decoding, possibly having different formats, onto an article or package, and to make bar codes wider so that they can encode more information. &#x201c;High density&#x201d; bar codes are best decoded with the use of a high resolution optical reader which is configured to have a short &#x201c;best focus&#x201d; position. Extra wide bar codes and scenes having more than one bar code are best decoded with use of readers having a longer best focus position. Commercially available optical readers cannot easily read high density extra wide decodable symbols or multiple symbols from a scene which are encoded in high density.</p>
<p id="p-0008" num="0007">There is a need for an optical reader which can decode a variety of different formats of image data, so as render it impervious to decode failures resulting from specular reflection, and which is adapted to read large or multiple high density decodable symbols, possibly having a plurality of formats, formed on a target.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0009" num="0008">The objects and features of the invention can be better understood with reference to the drawings described below, and the claims. The drawings are not necessarily to scale, emphasis instead generally being placed upon illustrating the principles of the invention. In the drawings, like numerals are used to indicate like parts throughout the various views.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>i </i>illustrate exemplary embodiments of optical readers comprising a microprocessor-based decoder module according to the invention;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>-<b>2</b><i>f </i>illustrate exemplary embodiments of microprocessor-based decoder modules according to the invention;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref><i>g </i>is a timing diagram illustrating an exemplary relation for control signals, exposure periods and frame acquisition, according to the invention;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. 2</figref><i>h</i>-<b>2</b><i>j </i>illustrate additional exemplary embodiments of microprocessor-based decoder modules according to the invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>e </i>are drawings that illustrate the features of imaging modules that are useful for practicing the invention;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. 4</figref><i>a</i>-<b>4</b><i>c </i>are flow diagrams depicting exemplary methods of practicing the invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. 4</figref><i>d</i>-<b>4</b><i>e </i>illustrate examples of images captured using a plurality of imaging sensors;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. 4</figref><i>f</i>-<b>4</b><i>g </i>are flow diagrams illustrating examples of the image data acquisition and decoding process according to the invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 4</figref><i>h </i>is an exemplary flow diagram illustrating an example of identification of an imaging module according to the invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref><i>i </i>is an exemplary flow diagram illustrating an example of locating a selected imaging module according to the invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIGS. 5</figref><i>a</i>-<b>5</b><i>e </i>illustrate exemplary optical readers that embody features of the invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. 6</figref><i>a</i>-<b>6</b><i>b </i>are schematic diagrams illustrating exemplary means and methods of connecting a plurality of imaging modules to a microprocessor-based decoder module of the invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6</figref><i>c </i>is a schematic diagram of an illustrative hardware connection of a microprocessor-based decoder module of the invention with a plurality of imaging modules, and the relations of code modules present when the microprocessor is operating, according to principles of the invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref><i>d </i>is a schematic diagram of an illustrative memory map showing the relationships between and among computer code modules present in a microprocessor-based decoder module during operation, according to principles of the invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 7</figref><i>a</i>-<b>7</b><i>b </i>schematically illustrate features of exemplary imaging modules useful for practicing the invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. 8</figref><i>a</i>-<b>8</b><i>b </i>schematically illustrate features of an illustrative decoding algorithm and an equivalent decoder circuit embodiment that operate according to principles of the invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 9</figref><i>a</i>-<b>9</b><i>d </i>illustrate embodiments of microprocessor-based decoder modules and products comprising the same, according to principles of the invention;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 10</figref><i>a </i>illustrates an embodiment of a microprocessor-based decoder module that includes an audio output module that allows the microprocessor-based decoder module to communicate with a user in natural language, according to principles of the invention; and</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 10</figref><i>b </i>illustrates an embodiment of a microprocessor-based decoder module that includes an audio input module that permits a user using natural language to communicate commands to the microprocessor-based decoder module, according to principles of the invention;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 10</figref><i>c </i>illustrates interconnections that exist among components of an illustrative system providing bar code to text to speech functionality, according to principles of the invention; and</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. 10</figref><i>d</i>-<b>10</b><i>f </i>illustrate flow diagrams that show methods of speech enunciation that embody the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0031" num="0030">In one aspect, the invention relates to a circuit component for an optical reader. The optical reader utilizes a selected one of a one-dimensional (1D) imaging module and a two-dimensional (2D) imaging module. The circuit component comprises a microprocessor-based decoder module that, when operative, decodes a frame of image data provided by a selected one of the one-dimensional (1D) imaging module and the two-dimensional (2D) imaging module. The decoding is responsive to information selected from one of information relating to the selected imaging module and information relating to the frame of image data.</p>
<p id="p-0032" num="0031">In one embodiment, the information relating to the selected imaging module comprises at least one of a bus address of the module, an ID code of the module, a model identifier of the module, and an electrical characteristic of the module. The microprocessor-based decoder module, when operative, determines which of the 1D imaging module and the 2D imaging module provides a particular frame of image data. Alternatively, the microprocessor-based decoder module, when operative, decodes the frame of image data according to the determination of which imaging module provided the frame. The information relating to the frame of image data comprises information representing a frame size, information identifying a frame format, information identifying a word size, and information identifying a source of the frame.</p>
<p id="p-0033" num="0032">In one embodiment, the microprocessor-based decoder module decodes the frame of image data in a time period less than or equal one second. In a more preferred embodiment, the time period is less than or equal to 1/30th of a second. In a still more preferred embodiment, the time period is less than or equal to 1/270th of a second.</p>
<p id="p-0034" num="0033">In one embodiment, the microprocessor-based decoder module comprises a microprocessor, a random access memory (RAM), and a read only memory (ROM). In one embodiment, the microprocessor-based decoder module comprises at least one of a field programmable gate array (FPGA), a programmable logic device (PLD), a complex programmable logic device (CPLD), and an application-specific integrated circuit (ASIC). In one embodiment, the microprocessor-based decoder module comprises an integrated circuit device having integrated therein a microprocessor, an analog-to-digital converter, a digital-to-analog converter, a direct memory access (DMA) channel, a bi-directional communication line for communication with an imaging module, and a channel for data receipt from an imaging module. In one embodiment, the integrated circuit device comprises a selected one of a semiconductor, an optical material, and a photonic bandgap material.</p>
<p id="p-0035" num="0034">In one embodiment, the invention includes an optical reader comprising the circuit component.</p>
<p id="p-0036" num="0035">In another aspect, the invention features, a method of decoding a frame of image data. The frame of image data has one of a 1D format and a 2D format. The method comprises the steps of providing at least one imaging module selected from a one-dimensional (1D) imaging module and a two-dimensional (2D) imaging module; acquiring a frame of image data in the selected imaging module; communicating the frame of image data to a microprocessor-based decoder module; determining the format of the frame of image data; as necessary, activating at least one command to prepare the microprocessor-based decoder module to decode the communicated frame of image data; and decoding the communicated frame of imaging data accordingly.</p>
<p id="p-0037" num="0036">In one embodiment, the format of the frame of image data is determined in response to one of information about the selected imaging module that acquired the communicated frame of imaging data, and information about the frame of image data.</p>
<p id="p-0038" num="0037">In one embodiment, the decoding step comprises converting 2D image data to at least one 1D representation of image data.</p>
<p id="p-0039" num="0038">In one embodiment, the decoding step further comprises converting the at least one 1D representation of image data to transition location information. In one embodiment, the steps of converting 2D image data to at least one 1D representation of image data, and converting the at least one 1D representation of image data to transition location information are performed iteratively.</p>
<p id="p-0040" num="0039">In one embodiment, the step of determining which of the 1D and the 2D imaging modules acquired the communicated frame further comprises evaluating a parameter characteristic of one of the 1D and the 2D imaging modules. In one embodiment, the decoding step further comprises executing a selected one of at least one computer instruction which when operating on a computer decodes a frame of image data acquired by the 1D imaging module and at least one computer instruction which when operating on a computer decodes a frame of image data acquired by the 2D imaging module. In one embodiment, the at least one computer instruction which when operating on a computer decodes a frame of image data acquired by the 1D imaging module comprises a plurality of computer instructions executed in sequence. In one embodiment, the at least one computer instruction which when operating on a computer decodes a frame of image data acquired by the 2D imaging module comprises a plurality of computer instructions executed in sequence.</p>
<p id="p-0041" num="0040">In one embodiment, a time period of less than or equal to one second elapses in performing the steps of determining which of the selected imaging modules acquired the communicated frame of imaging data; as necessary, activating at least one command to prepare the microprocessor-based decoder module to decode the communicated frame of image data; and decoding the communicated frame of imaging data accordingly. In a preferred embodiment, the time period is less than or equal to 1/30th of a second. In a more preferred embodiment, the time period is less than or equal to 1/270th of a second.</p>
<p id="p-0042" num="0041">In another aspect, the invention relates to a computer program, recorded on a machine-readable medium. The computer program, when operative on a programmable computer, performs the steps of receiving a frame of image data acquired by a selected one of a 1D imaging module and a two-dimensional (2D) imaging module; determining which of the selected imaging modules acquired the received frame of imaging data; and decoding the frame of imaging data accordingly.</p>
<p id="p-0043" num="0042">In one embodiment, the decoding step comprises converting 2D image data to at least one 1D representation of image data. In one embodiment, the decoding step further comprises converting the at least one 1D representation of image data to transition location information. In one embodiment, the steps of converting 2D image data to at least one 1D representation of image data, and converting the at least one 1D representation of image data to transition location information are performed iteratively. In one embodiment, the invention includes an optical reader comprising the computer program.</p>
<p id="p-0044" num="0043">In yet another aspect, the invention features a computer program, recorded on a machine-readable medium. The computer program comprises a module that receives a frame of image data acquired by a selected one of a 1D imaging module and a two-dimensional (2D) imaging module; a module that determines which of the selected imaging modules acquired the received frame of imaging data; and a module that decodes the frame of imaging data accordingly.</p>
<p id="p-0045" num="0044">In one embodiment, the invention includes a dynamically linked library module for communicating information from the computer program to the selected imaging module. In another embodiment, the invention includes a dynamically linked library module for communicating image data from the selected imaging module to the module of the computer program that receives a frame of image data. In a further embodiment, the invention includes an optical reader comprising the computer program.</p>
<p id="p-0046" num="0045">In a further aspect, the invention relates to a circuit board component for an optical reader. The optical reader utilizes at least one of a one-dimensional (1D) imaging module and a two-dimensional (2D) imaging module. The circuit board comprises a circuit board substrate having at least one plane of electrical connecting structures thereon; and an integrated circuit comprising a microprocessor-based decoder mounted on and electrically connected to the circuit board substrate to form a circuit board component, that, when operative, decodes a frame of image data provided by a selected one of the one-dimensional (1D) imaging module and the two-dimensional (2D) imaging module.</p>
<p id="p-0047" num="0046">In one embodiment, the circuit board component further comprises a connector in electrical communication with the integrated circuit. The connector provides the ability to demountably electrically connect the integrated circuit and at least one of the 1D imaging module and the 2D imaging module.</p>
<p id="p-0048" num="0047">In one embodiment, the circuit board component further comprises at least one of the 1D imaging module and the 2D imaging module.</p>
<p id="p-0049" num="0048">In one embodiment, the invention includes an optical reader comprising the circuit board component.</p>
<p id="p-0050" num="0049">In yet another aspect, the invention features an electrical component for an optical reader. The optical reader utilizes at least one of a one-dimensional (1D) imaging module and a two-dimensional (2D) imaging module. The electrical component comprises means for, when operative, decoding a frame of image data provided by a selected one of the one-dimensional (1D) imaging module and the two-dimensional (2D) imaging module.</p>
<p id="p-0051" num="0050">In one embodiment, the electrical component further comprises connector means, in electrical communication with the electrical component that provides the ability to demountably electrically connect the electrical component and at least one of the 1D imaging module and the 2D imaging module.</p>
<p id="p-0052" num="0051">In one embodiment, the electrical component further comprises at least one of the 1D imaging module and the 2D imaging module. In another embodiment, the invention includes an optical reader comprising the electrical component.</p>
<p id="p-0053" num="0052">The foregoing and other objects, aspects, features, and advantages of the invention will become more apparent from the following description and from the claims.</p>
<p id="p-0054" num="0053">Imaging modules that provide different formats of image data are useful in obtaining images of decodable indicia having different attributes, such as the geometrical, tonal, and color attributes described above. The present invention provides a microprocessor-based decoder module for decoding data in a selected format of a plurality of formats as provided by a selected one of a plurality of different types of imaging modules. In one embodiment, the microprocessor-based decoder module is useful for decoding data in a selected format of a plurality of formats as provided by a selected one of a plurality of different types of imaging modules in hand held optical readers. Other uses will be apparent to those of ordinary skill from the description of the microprocessor-based decoder module presented herein.</p>
<p id="p-0055" num="0054">Exemplary embodiments of microprocessor-based decoder modules that accept and decode a frame of image data in any of a plurality of formats are described below. The image data is provided by a selected one of a plurality of sensors or imaging modules at least two of which provide a frame of image data in a format different from the format of the image data provided by the other, recognizing that only one such sensor need be available for use at any particular time. As will be apparent from the description herein, in some embodiments, a plurality of sensors can be available simultaneously, while in other embodiments, a single selected sensor is available. In either circumstance, a microprocessor-based decoder module according to the invention can determine how to decode a specific image frame that is received from an active sensor. The sensors can include, but are not limited to, 1D imaging modules, 2D imaging modules, gray scale imaging modules, color imaging modules, and biometric imaging modules. Optical readers comprising such microprocessor-based decoder modules are also described herein.</p>
<p id="p-0056" num="0055">There are many benefits that flow from the use of a microprocessor-based decoder module of the kind described and claimed herein. Some of the benefits relate to improvements in business methods, including such advantages as: having fewer models of parts that need to be manufactured, inventoried, and made available for product assembly and maintenance; having fewer models of parts for which personnel need to be trained, thereby improving manufacturing efficiency, maintenance efficiency, and improved knowledge and familiarity of the personnel of the features and required practices associated with a lesser number of models of parts that are handled more frequently; and opportunities to obtain advantageous commercial terms (e.g., volume discounts, better service, and the like) as a consequence of ordering larger quantities of components or parts used in making a specific quantity of a single model of a product as compared to lesser quantities of particular components required if the total same number of units were to be produced in a plurality of discrete models each using different components or parts.</p>
<p id="p-0057" num="0056">Additional business method benefits can accrue from the use of a single microprocessor-based decoder module that can be &#x201c;personalized&#x201d; or &#x201c;reprogrammed&#x201d; to accept and decode frames of image data having different formats from a plurality of different sensors. By way of example, some of the advantages that can accrue include: the ability to add additional sensor models and types as such sensors are developed, including sensors having formats that may be new and/or different from existing formats, through the ability to provide a dynamically linked library module (e.g., a .dll or .ocx module) that provides either or both of communicating information from a computer program operating on the microprocessor-based decoder module to the imaging module, and communicating image data from the imaging module to a module of the computer program operating on the microprocessor-based decoder module that receives a frame of image data; quickly and conveniently switching operation from a first sensor providing a frame of image data of a first format to a second sensor providing a frame of image data of a second format by the simple expedient of redirecting the microprocessor-based decoder module to use a different computer program and/or a different dynamically linked library module; and improved ease of testing and troubleshooting products during manufacture through the use of a test facility comprising one or more of the microprocessor-based decoder modules, that duplicates the operation of a particular microprocessor-based decoder module with any of the sensors intended for use therewith, thereby permitting the pre-assembly testing of components, and eliminating &#x201c;rework&#x201d; of products that are faulty.</p>
<p id="p-0058" num="0057">Embodiments of optical readers having more than one imaging module are shown in <figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>i</i>. In <figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>b </i>a gun style optical reader <b>5</b>-<b>1</b> is shown including first and second imaging modules <b>10</b><i>a </i>and <b>10</b><i>b </i>incorporated in housing <b>7</b>. Imaging modules <b>10</b> can be of the type shown in <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>d</i>. Imaging module <b>10</b>, <b>10</b>-<b>1</b> as shown in <figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>3</b><i>c </i>includes a support assembly <b>80</b> having a containment section <b>81</b> and a retainer section <b>82</b>, a first circuit board <b>14</b><i>a </i>carrying an image sensor <b>32</b>, a second circuit board <b>14</b><i>b</i>, illumination LEDs <b>16</b> aiming LEDs <b>18</b>, an optical plate <b>26</b> carrying aiming and illumination optics <b>25</b>, <b>27</b>, and support posts <b>84</b> holding the various components of the module together. In another embodiment, an imaging module can comprise as little as the image sensor <b>32</b> alone. Image sensor <b>32</b> can comprise a substantially linear array of picture elements (pixels), which can be for example a 1&#xd7;N array (e.g., 1&#xd7;3500), or an M&#xd7;N pixel array that has an aspect ratio that is close to 1&#xd7;N, for example 2&#xd7;2000 (e.g., M/N=0.001), 5&#xd7;2500 (e.g., M/N=0.002), or even 20&#xd7;2000 (e.g., M/N=0.01). Further details of imaging module <b>10</b>-<b>1</b> are described in application Ser. No. 10/092,789 filed Mar. 7, 2002 entitled &#x201c;Optical Reader Imaging Module,&#x201d; (now U.S. Patent Publication No. 2003/0029917) which is hereby incorporated herein by reference in its entirety. As indicated by <figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>3</b><i>b </i>imaging modules <b>10</b> can be built as a modularly installable self-contained unit. That is, module <b>10</b> can be assembled into the packaged form shown in <figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>3</b><i>b </i>at an assembly location prior to being installed in a cavity defined by reader housing <b>7</b>.</p>
<p id="p-0059" num="0058">Imaging module <b>10</b> can be screw mounted on any rigid member within housing <b>7</b> in the manner described in application Ser. No. 10/092,789 filed Mar. 7, 2002, entitled: &#x201c;Optical Reader Imaging Module,&#x201d; (now U.S. Patent Publication No. 2003/0029917) incorporated herein by reference above. Module <b>10</b> can include screw holes <b>810</b> for facilitating mounting of module <b>10</b> on a rigid member. As indicated by support assembly <b>80</b> of <figref idref="DRAWINGS">FIG. 3</figref><i>d</i>, support assembly <b>80</b> can include wings <b>80</b><i>w </i>having screw holes <b>810</b>. Reader <b>5</b> can include a main circuit board <b>15</b> or &#x201c;mother board&#x201d; which includes control circuit circuitry as described in detail in connection with <figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>-<b>2</b><i>j</i>. In one embodiment, as indicated by reader <b>5</b>-<b>2</b> of <figref idref="DRAWINGS">FIG. 1</figref><i>d</i>, a plurality of imaging modules <b>10</b> can be mounted to a rigid member provided by a common main circuit board <b>15</b>. Imaging modules <b>10</b> can be interfaced with mother board <b>15</b> with use flex strip connectors <b>17</b> known in the art.</p>
<p id="p-0060" num="0059">Module <b>10</b><i>a </i>and module <b>10</b><i>b </i>are disposed in a common cavity <b>6</b>. A wall <b>8</b> formed in housing <b>7</b> dividing cavity <b>6</b> into two spaces would not create two separate cavities since cavity <b>6</b> of reader <b>5</b>-<b>1</b> would still be delimited by the common outer peripheral wall of housing <b>7</b>.</p>
<p id="p-0061" num="0060">Incorporating more than one imaging module <b>10</b> in an optical reader housing <b>7</b> yields a number of advantages. One benefit is that the presence of a plurality of imaging modules <b>10</b> of different types permits a single optical reader to capture images from different kinds of decodable indicia.</p>
<p id="p-0062" num="0061">As another example, if an attempt to decode a decodable indicia by capturing and subjecting to decoding an image captured via actuation of first module <b>10</b><i>a </i>fails, a second decoding attempt can be made by capturing and subjecting to decoding image captured via actuation of second imaging module <b>10</b><i>b</i>. Further, reader <b>5</b> can be actuated to capture and subject to decoding a frame of image data captured by actuation of an image sensor <b>32</b> of a first module <b>10</b><i>a </i>and illumination LEDs <b>16</b> of a second imaging module <b>10</b><i>b</i>. The spacing between illumination LEDs <b>16</b> of a second module <b>10</b><i>b </i>and an image sensor <b>32</b> of a first imaging module <b>10</b><i>a </i>renders the frame of image data capture by the described method substantially impervious to specular reflection image degradation.</p>
<p id="p-0063" num="0062">In addition, image data of several frames captured by actuation of several different imaging modules can be combined, by one of several possible image frame combination methods, to yield a larger frame of image data. The larger image representation is yielded by combining multiple frames of image data and can be subjected to decoding, thereby facilitating decoding of larger decodable indicia or multiple decodable indicia printed over a large area of a target substrate. Specular reflection avoidance and frame image combination methods will be described in greater detail herein.</p>
<p id="p-0064" num="0063">In the embodiment of <figref idref="DRAWINGS">FIGS. 1</figref><i>c </i>and <b>1</b><i>d</i>, reader <b>5</b>-<b>2</b> comprises three imaging modules including a first imaging module <b>10</b><i>a</i>, second imaging module <b>10</b><i>b </i>and third imaging module <b>10</b><i>c </i>each having a respective imaging axis <b>11</b><i>a</i>, <b>11</b><i>b</i>, and <b>11</b><i>c</i>. Like reader <b>5</b>-<b>1</b> (<figref idref="DRAWINGS">FIGS. 1</figref><i>a </i>and <b>1</b><i>b</i>) the imaging axes of reader <b>5</b>-<b>2</b> of <figref idref="DRAWINGS">FIGS. 1</figref><i>c </i>and <b>1</b><i>d </i>are in converging relation. In other embodiments, the axes can be in parallel relation or in diverging relation. Configuring reader <b>5</b>-<b>2</b> so that modules <b>10</b> are in converging relation assures that each of a reader's imaging modules (<b>10</b><i>a</i>, <b>10</b><i>b</i>, and <b>10</b><i>c </i>in reader <b>5</b>-<b>2</b>) are positioned to capture images corresponding to substantially the same area of a target substrate. Accordingly, as will be explained in further detail herein readers <b>5</b>-<b>1</b> and <b>5</b>-<b>2</b> as shown in <figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>d </i>are particularly well suited for reducing specular reflection misreads.</p>
<p id="p-0065" num="0064">Referring now to <figref idref="DRAWINGS">FIGS. 1</figref><i>e </i>and <b>1</b><i>f</i>, dumbbell style multiple imaging module optical reader <b>5</b>-<b>5</b> is described.</p>
<p id="p-0066" num="0065">Dumbbell reader <b>5</b>-<b>5</b> is a reader including three housing portions <b>7</b> and each defining a cavity <b>6</b>. Reader <b>5</b>-<b>5</b> of <figref idref="DRAWINGS">FIGS. 1</figref><i>e </i>and <b>1</b><i>f </i>includes a central handle <b>19</b> which supports a pair of laterally disposed head sections <b>20</b>. Handle <b>19</b> may include a thumb-actuated trigger <b>13</b><i>t</i>. Installed in each head section <b>20</b> is an imaging module <b>10</b> which may be of the type described in connection with <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>d</i>. Imaging module <b>10</b> of reader <b>5</b>-<b>5</b> as in the case of readers <b>5</b>-<b>1</b>, <b>5</b>-<b>2</b>, <b>5</b>-<b>3</b>, and <b>5</b>-<b>4</b> may be screw mounted on any rigid member within head sections <b>20</b>. Head sections <b>20</b> of housing <b>7</b> are mounted to the major body of housing <b>7</b> by ball and socket type connectors <b>21</b>. Ball and socket connectors <b>21</b> may be provided, for example, by a ball and socket connector of a type available from R-A-M Mounting Systems, Inc. of Chandler, Ariz. Ball and socket connectors <b>21</b> may include mechanical detent mechanisms providing feel feedback as to the position of head section <b>20</b> so that a user may click head sections <b>20</b> into one or more normally defined positions. Flexible cable <b>18</b> as shown in <figref idref="DRAWINGS">FIGS. 1</figref><i>e </i>and <b>1</b><i>f </i>can be disposed to provide electrical communication between modules <b>10</b> and a main circuit board <b>15</b> within a cavity defined by a handle portion of housing <b>7</b>. Main circuit board <b>15</b> of reader <b>5</b>-<b>5</b> may carry components of a multiple module electrical circuit, e.g. circuit <b>105</b> described with reference to <figref idref="DRAWINGS">FIG. 2</figref><i>f. </i></p>
<p id="p-0067" num="0066">In the embodiment of <figref idref="DRAWINGS">FIG. 1</figref><i>g</i>, handle <b>19</b> of dumbbell style reader <b>5</b>-<b>7</b> includes a central aperture <b>19</b><i>a </i>which is fittable about post <b>45</b>. Handle <b>19</b> includes knob actuated bolt <b>46</b> for securing dumbbell style reader <b>5</b>-<b>6</b> against post <b>45</b>. Post <b>45</b> in the embodiment of <figref idref="DRAWINGS">FIG. 1</figref><i>g </i>is part of a presentation style reader <b>5</b>-<b>7</b> which, in addition to including detachable dumbbell style reader <b>5</b>-<b>6</b> further includes stand <b>47</b> including knob actuated bolt <b>48</b> for enabling a vertical position of post <b>45</b> to be adjusted, and top head section <b>20</b><i>a </i>disposed at a top of post <b>45</b>. Head section <b>20</b><i>a </i>may be mounted to post <b>45</b> with use of ball and socket connector <b>21</b>. Dumbbell style optical reader <b>5</b>-<b>6</b> may be removed from post <b>45</b> so that dumbbell style reader <b>5</b>-<b>6</b> can be used in a hand held mode. For realization of a hand held mode, knob actuated bolt <b>48</b> is loosened and post <b>45</b> is removed from stand <b>47</b>. Knob actuated bolt <b>46</b> is then loosened and dumbbell style reader <b>5</b>-<b>6</b> is removed from post <b>45</b> to allow hand held use.</p>
<p id="p-0068" num="0067">A dumbbell style reader e.g. <b>5</b>-<b>5</b> and <b>5</b>-<b>6</b> is particularly well suited for use in applications wherein specular reflection read failures can be expected. In the example of <figref idref="DRAWINGS">FIG. 1</figref><i>f</i>, dumbbell style reader <b>5</b>-<b>5</b> is shown in a mode wherein head sections <b>20</b> are canted in a position such that imaging axes <b>11</b><i>a </i>and <b>11</b><i>b </i>of module <b>10</b><i>a </i>and module <b>10</b><i>b </i>are in converging relation and positioned so the imaging modules <b>10</b><i>a </i>and <b>10</b><i>b </i>generate image data corresponding to substantially the same scene at a target substrate, S, when reader <b>5</b>-<b>5</b> is at certain reader-to-target distance. If module <b>10</b><i>a </i>is positioned with respect to a reflective target T such that specular reflection from target T results in a decode failure, a frame of image data captured by actuation of illumination light sources <b>16</b> and an image sensor <b>32</b> of second module <b>10</b><i>b </i>can be subjected to a second decoding attempt. In addition, an expectedly specular reflection-free frame of image data can be captured by actuation of image sensor <b>32</b> of first imaging module <b>10</b><i>a </i>in combination with actuation of illumination of second imaging module <b>10</b><i>b </i>in place of illumination from first imaging module. The term &#x201c;target&#x201d; herein refers to subject matter (e.g. decodable indicia) presently in a field or view of at least one module of reader <b>5</b>. The term &#x201c;target substrate&#x201d; refers to a member (e.g. a piece of paper, an equipment part) bearing subject matter to which reader may be directed.</p>
<p id="p-0069" num="0068">The multiple imaging module optical readers as shown in <figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>c </i>include 2D imaging modules, which may be for example Model IT 4200, Model IT 4250, or Model IT 4000 imaging modules of the type available from Hand Held Products, Inc. of Skaneateles Falls, N.Y. It will be understood that a 1D imaging module having a 1D image sensor can replace a 2D imaging module of any of the readers shown. An example of a 1D imaging module which can be incorporated in any one of readers <b>5</b>-<b>1</b>, <b>5</b>-<b>2</b>, <b>5</b>-<b>3</b>, <b>5</b>-<b>4</b>, <b>5</b>-<b>5</b>, <b>5</b>-<b>6</b>, and <b>5</b>-<b>7</b> is shown in <figref idref="DRAWINGS">FIG. 3</figref><i>e</i>. Imaging module <b>10</b>-<b>2</b> includes a 1D image sensor <b>32</b>, a support assembly or frame <b>80</b>, imaging optics <b>40</b>, illumination light sources <b>18</b>, and illumination optics including lens <b>25</b> carried by plate <b>26</b> and aiming apertures <b>43</b>. Further details of an exemplary 1D imaging module are described in U.S. Pat. No. 6,119,939,entitled &#x201c;Optical Assembly For Bar Code Scanner,&#x201d; which is hereby incorporated herein by reference in its entirety. In an image sensor array based 1D imaging module e.g. module <b>10</b>-<b>2</b> illumination and aiming light sources are normally provided by the same light sources which project a single illumination pattern which also serves as an aiming pattern. However, a 1D imaging module can also include light sources which project different illumination and aiming patterns. An imaging module of the invention can also comprise a laser diode based 1D imaging engine including a single photodetector, a laser diode and means for sweeping the laser beam projected by the laser diode across a target area. It will be understood that other sensors or imaging modules (not shown), for example gray scale imaging modules, color imaging modules, and biometric imaging modules known in the imaging arts can be substituted for one or both of a 1D imaging module and a 2D imaging module, or provided in addition to one or both of a 1D imaging module and a 2D imaging module, as will be described below in greater detail.</p>
<p id="p-0070" num="0069">Reader <b>5</b>-<b>9</b> of <figref idref="DRAWINGS">FIG. 1</figref><i>i </i>is an exemplary illustration of an optical reader having a plurality of imaging modules, one of which provides a frame of image data that has a format different from the format of a frame of image data provided by another imaging module. In the embodiment shown in <figref idref="DRAWINGS">FIG. 1</figref><i>i</i>, center module <b>10</b><i>c </i>of reader <b>5</b>-<b>9</b> is a 1D imaging module while laterally disposed modules <b>10</b><i>a </i>and <b>10</b><i>b </i>are 2D modules. Configuring reader <b>5</b>-<b>9</b> so that reader <b>5</b>-<b>9</b> includes a center 1D imaging module <b>10</b><i>c</i>, <b>10</b>-<b>2</b> and laterally disposed 2D imaging modules <b>10</b>-<b>1</b> provides certain advantages, as recited above. Reader <b>5</b>-<b>9</b> can provide frames of image data having two different formats captured from decodable indicia of different types. Reader <b>5</b>-<b>9</b> can be programmed in accordance with a decode operation control program wherein a reader (1) first captures and subjects to decoding an image captured via actuation of first imaging module <b>10</b><i>c</i>, and if the decoding attempt fails, (2) automatically captures and subjects to decoding a second image captured via actuation of an image sensor and illumination of one of laterally disposed 2D modules <b>10</b><i>a </i>and <b>10</b><i>b</i>. In an alternative embodiment, any of 1D module <b>10</b><i>c</i>, 2D module <b>10</b><i>a</i>, and 2D module <b>10</b><i>b </i>can be selected and activated as the module of choice to provide a frame of image data.</p>
<p id="p-0071" num="0070">One-dimensional bar code symbols are more common than 2D bar code symbols. Further, 1D bar code symbols are generally decoded more quickly and more accurately by capturing and processing 1D slice image data captured via actuation of a 1D image sensor than capturing and processing 2D image data captured via actuation of a 2D image sensor. Still further, an imaging axis <b>11</b><i>c </i>of center imaging module <b>10</b><i>c </i>disposed in a gun-style housing <b>7</b> can more readily be aligned with an indicia of a target, T, than lateral imaging modules <b>10</b><i>a </i>and <b>10</b><i>b</i>. Accordingly, it can be seen that reader <b>5</b>-<b>9</b> programmed in accordance with the above-described decode program is a reader which is both mechanically configured and programmed for optimization of the decoding of 1D symbols, while still having the capacity to decode matrix 2D symbols where matrix 2D symbols are present within a target, T.</p>
<p id="p-0072" num="0071">In other embodiments, the decodable indicia may have attributes of geometry (e.g., one or two dimensional decodable indicia such as barcodes, two-dimensional codes, alphanumeric symbols, and the like), attributes of tone, such as black-and-white (two tone, or 1-bit tonality), or gray scale (e.g., from three to as many as 2<sup>N </sup>tones, where the exponent N is an integer greater than 1, or N-bit tonality), attributes of color (e.g., having a an optical appearance characterized as being within a narrow spectral region of the electromagnetic spectrum, such as red, green, or blue, or combinations thereof). In still other embodiments, the decodable indicia can have attributes relating to biometric features, such as fingerprints, retinal patterns, facial features, and the like.</p>
<p id="p-0073" num="0072">Various electrical circuits <b>100</b>, <b>101</b>, <b>102</b>, <b>103</b>, <b>104</b>, and <b>105</b> which can be utilized to control optical readers are shown and described with reference to <figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>, <b>2</b><i>b</i>, <b>2</b><i>c</i>, <b>2</b><i>d</i>, <b>2</b><i>e</i>, and <b>2</b><i>f</i>. While the present invention relates in one aspect to optical readers having more than one imaging module, <figref idref="DRAWINGS">FIGS. 2</figref><i>a </i>and <b>2</b><i>b </i>show electrical circuits for operating optical readers having a single imaging module. Numerous principles of circuit operation discussed in relation to circuits <b>100</b>, <b>101</b> are incorporated into multiple imaging module electrical circuits <b>102</b>, <b>103</b>, <b>104</b>, <b>105</b> discussed in relation to <figref idref="DRAWINGS">FIGS. 2</figref><i>c</i>-<b>2</b><i>f. </i></p>
<p id="p-0074" num="0073">In <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>a block diagram of an optical reader electrical circuit is shown having a multi-functional processor IC chip <b>180</b> including an integrated frame grabber block <b>148</b>. Electrical circuit <b>100</b> shown in <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>can be utilized for control of a single 2D imaging module optical reader as is shown for example in U.S. application Ser. No. 09/954,081 filed Sep. 17, 2001, entitled &#x201c;Optical Reader Having Image Parsing Mode,&#x201d; (now U.S. Pat. No. 6,561,428) which is hereby incorporated herein by reference in its entirety.</p>
<p id="p-0075" num="0074">In the specific embodiment of <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>, electrical circuit <b>100</b> includes a control circuit <b>140</b> comprising CPU <b>141</b>, system RAM <b>142</b> and system ROM <b>143</b> and frame grabber block <b>148</b>. Electrical circuit <b>100</b> further includes an image sensor <b>32</b> typically provided by a photosensitive array and an illumination block <b>160</b> having illumination LEDs <b>16</b> and aiming LEDs <b>18</b> as shown in the physical form view of <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>c</i>. Image sensor <b>32</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>is shown as being provided by a 2D photo diode array. If a 1D image sensor replaces image sensor <b>32</b>, then aiming LEDs <b>18</b> and illumination LEDs <b>16</b> may be constituted by one set of LEDs. In the embodiment shown, image sensor <b>32</b> incorporated in an image sensor IC chip <b>182</b> which typically further includes an image sensor electrical circuit block <b>134</b>. Image sensor electrical block <b>134</b> includes control circuit <b>135</b> for controlling image sensor <b>32</b>, an A/D conversion circuit <b>136</b>, for converting analog signals received from image sensor <b>32</b> into digital form and integrated clock <b>137</b> sometimes referred to as an oscillator.</p>
<p id="p-0076" num="0075">In the embodiment shown in <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>, CPU <b>141</b> and frame grabber block <b>148</b> are incorporated in a multi-functional IC chip <b>180</b> which in addition to including CPU <b>141</b> includes numerous other integrated hardware components. Namely, multifunctional IC chip <b>180</b> may include a display control block <b>106</b>, several general purpose I/O ports <b>116</b>, several interface blocks such as a USB circuit block <b>107</b> and a UART block <b>108</b> for facilitating RS <b>232</b> communications, a UART block <b>109</b> for facilitating infra-red communications (including communication according to standards promulgated by the INFRARED DATA ASSOCIATION<sub>7 </sub>(IrDA<sub>7</sub>), a trade association for defining infrared standards), and a pulse width modulation (PWM) output block <b>110</b>. Multi-functional processor IC chip <b>180</b> can also have other interfaces such as a PCMCIA interface <b>111</b>, a compact flash interface <b>112</b>, and a multimedia interface <b>113</b>. If reader <b>5</b> includes a display <b>13</b><i>d</i>, display <b>13</b><i>d </i>may be in communication with chip <b>180</b> via display interface <b>106</b>. Trigger <b>13</b><i>t </i>and keypad <b>13</b><i>k </i>may be in communication with chip <b>180</b> via general purpose I/O interface <b>116</b>. Physical form views of readers having displays and keyboards are shown for example in U.S. application Ser. No. 10/137,484, filed May 2, 2002, entitled &#x201c;Optical Reader Comprising Keyboard,&#x201d; (now U.S. Patent Publication No. 2003/0206150) which is hereby incorporated herein by reference in its entirety. Multi-functional processor IC chip <b>180</b> may be one of an available type of multifunctional IC processor chips which are presently available such as a Dragonball MX1 IC processor chip or a Dragonball MXL IC processor chip available from Motorola, a DSC IC chip of the type available from Texas Instruments, an O-Map IC chip of the type available from Texas Instruments, or a multifunctional IC processor chip of a variety known as Clarity SOCs (e.g., system on a chip) available from Sound Vision, Inc.</p>
<p id="p-0077" num="0076">In one embodiment, multi-functional processor IC chip <b>180</b> comprises components that provide at least the functions provided by a CPU <b>140</b>, system RAM <b>142</b> and system ROM <b>143</b>. In some embodiments, it is advantageous that microprocessor-based decoder module <b>180</b> comprises an integrated circuit device having integrated therein a microprocessor, an analog-to-digital converter, a digital-to-analog converter, a direct memory access (DMA) channel, a bi-directional communication line for communication with a sensor such as either or both of line <b>151</b> and <b>152</b>, and a channel for data receipt from a sensor, such as data line <b>159</b> that brings data to frame grabber <b>148</b>. The microprocessor-based IC chip <b>180</b> can comprise semiconductor materials, optical materials, and photonic bandgap materials. In some embodiments, it is advantageous that the multi-functional processor IC Chip <b>180</b> further comprise I/O <b>116</b> suitable to accept user input (for example from a keyboard <b>13</b><i>k</i>), interface capability for &#x201c;flash&#x201d; memory devices such as &#x201c;Multimedia&#x201d; (MMC), &#x201c;Smart Media,&#x201d; &#x201c;Compact Flash,&#x201d; and &#x201c;Memory Stick.&#x201d; Other features that may be used to advantage include pulse width modulators (PWMs), serial communication channels (e.g., UARTs, SPIs, and USBs), display drivers and controllers such as for an LCD, wireless communication capability such as Bluetooth and 802.11(a), (b), and (g)-compatible transmitter/receivers, sequence control modules such as timer banks, sensor controllers, audio generators, audio coder/decoders (&#x201c;codecs&#x201d;), speech synthesizers, and speech recognition hardware and/or software.</p>
<p id="p-0078" num="0077">There are many ways in which the microcomputer-based decoder module can determine which imaging module provides a frame of image data or the format of a provided frame of image data. In one embodiment, the microcomputer-based decoder module uses the Inter-IC (I<sup>2</sup>C) bus protocol and circuitry operating according to the protocol. As an illustrative example, for 2D imaging modules, the I<sup>2</sup>C communication link from the microcomputer-based decoder module is used to communicate directly to an imaging module. Each 2D imaging module or sensor has a unique address for I<sup>2</sup>C communication. The microcomputer-based decoder module can interrogate an address or can attempt to communicate with an address in order to communicate with a specific imaging module. If the wrong address is used for I<sup>2</sup>C communication, the I<sup>2</sup>C communication fails. In an alternative embodiment, each 2D imaging module or sensor has an &#x201c;ID&#x201d; register which holds a unique value that provides an identification number. A query to the ID register of the imaging module via the I<sup>2</sup>C communication link can cause the return of the ID value stored in the register. In the event that the microcomputer-based decoder module receives the correct ID value, which also implies that the I<sup>2</sup>C bus address used is correct, there is a very high probability that the correct imaging module is being addressed. In another embodiment, resistor packs connected to port pins are used to identify a specific module. In some embodiments, different auto-detection routines are used for each imaging module.</p>
<p id="p-0079" num="0078">In one embodiment, the auto-detection algorithm to identify a specific imaging module cycles through each of the defined parameters (such as an I<sup>2</sup>C address and/or ID parameter) for imaging modules until a match is found. The identity of the module is determined by comparing the matching defined parameters with information in a collection of stored data, such as a lookup table in a memory. The imaging module is identified from the data in the stored data. In order to locate a specific imaging module, stored data can be interrogated to locate the I<sup>2</sup>C address and/or the ID of the imaging module, which information can be used to communicate with the selected imaging module. The stored data can include information that specifies the format of a frame of image data provided by a selected imaging module. The information about the format can be used to determine whether the then current state of the microprocessor-based decoding module is suitable for decoding the format of imaging information provided by the selected module or whether the state of microprocessor based decoding module should be adjusted, for example by loading or activating a software module, in order to correctly decode the frame of image data that is provided.</p>
<p id="p-0080" num="0079">In another alternative embodiment, an FPGA can be used to perform logical or manipulative operations on a frame of imaging data. In some embodiments, the FPGA program can handle any of the different transfer types by writing to a register, or by setting or clearing one or more specified bits. Configuration of the register or of the bit(s) in response to the detection of a given image module starts the appropriate decoding algorithm for the imaging module that is detected. Alternatively, once a given imaging module is detected, the FPGA is configured with the appropriate program to decode the format of image data provided by the imaging module. In embodiments wherein the FPGA communicates in the imaging module auto-detection process, the FPGA is programmed with the appropriate configuration, and then performs the detection process. The FPGA then performs the data decoding. In some embodiments the FPGA is reprogrammed to prepare the FPGA to do the decoding. In other embodiments, adaptable circuits such as reconfigurable FPGAs or logic circuits are used.</p>
<p id="p-0081" num="0080">Frame grabber block <b>148</b> of IC chip <b>180</b> replaces the function of a frame grabbing field programmable gate array (FPGA) as discussed in commonly assigned application Ser. No. 09/954,081, filed Sep. 17, 2001, entitled &#x201c;Imaging Device Having Indicia-Controlled Image Parsing Mode,&#x201d; (now U.S. Pat. No. 6,561,428) and application Ser. No. 09/904,697, filed Jul. 13, 2001, entitled &#x201c;An Optical Reader Having a Color Imager,&#x201d; (now U.S. Pat. No. 6,772,569) both of which are hereby incorporated herein by reference in their entirety. More particularly, frame grabber block <b>148</b> is specifically adapted collection of hardware elements programmed to carry out, at video rates or higher, the process of receiving digitized image data from image sensor chip <b>182</b> and writing digitized image data to system RAM <b>142</b> which in the embodiment shown is provided on a discreet IC chip. Frame grabber block <b>148</b> includes hardware elements preconfigured to facilitate image frame capture. Frame grabber block <b>148</b> can be programmed by a user to capture images according to a user's system design requirements. Programming options for programming frame grabber block <b>148</b> include options enabling block <b>148</b> to be customized to facilitate frame capture that varies in accordance with image sensor characteristics such as image sensor resolution, clock out rating, and fabrication technology (e.g. CCD, CMOS, CID), dimension (1D or 2D), tonality (from 1 to N-bits), color (monochrome or color), biometric features, such as fingerprints, retinal patterns, facial features, and one- and two-dimensional patterns that can provide information, such as chromatography patterns and electrophoretic patterns of mixtures of substances, including substances such as biological samples comprising DNA.</p>
<p id="p-0082" num="0081">Aspects of the operation of circuit <b>100</b> when circuit <b>100</b> captures image data into RAM <b>140</b> are now described. Circuit <b>100</b> can perform a cycle of receiving a frame of image data, performing internal programming functions, and decoding the frame of image data in a time period of less than or equal to a second. In a more preferred embodiment, the circuit <b>100</b> performs the cycle in a time period of less than or equal to 1/30 of a second. It is expected that in a still more preferred embodiment, the time period can be less than or equal to 1/270 of a second. When trigger <b>13</b><i>t </i>is pulled, CPU <b>141</b>, under the operation of a program stored in system ROM <b>143</b>, writes an image capture enable signal to image sensor chip <b>182</b> via communication line <b>151</b>. Line <b>151</b>, like the remainder of communication lines described herein represents one or more physical communication lines. In the embodiment shown, wherein image sensor chip <b>182</b> is of a type available from IC Media Corp., I<sup>2</sup>C interface <b>115</b> of chip <b>180</b> is utilized to facilitate communication with chip <b>182</b> (if another image sensor chip is selected another type of interface e.g. interface <b>116</b> may be utilized). Other types of signals may be sent over line <b>151</b> during the course of image capture. Line <b>151</b> may carry, for example, timing initialization, gain setting and exposure setting signals.</p>
<p id="p-0083" num="0082">When control block <b>135</b> of image sensor chip <b>182</b> receives an image capture enable instruction, control block <b>135</b> sends various signals to frame grabber block <b>148</b>. Image sensor control block <b>135</b> typically sends various types of synchronization signals to frame grabber block <b>148</b> during the course of capturing frames of image data. In particular, control block <b>135</b> may send to frame grabber block <b>148</b> &#x201c;start of frame signals&#x201d; which inform frame grabber block <b>148</b> that chip <b>182</b> is ready to transmit a new frame of image data, &#x201c;data valid window&#x201d; signals which indicate periods in which a row of image data is valid, and &#x201c;data acquisition clock&#x201d; signals as established by clock <b>137</b> controlling the timing of image data capture operations. In the embodiment described, line <b>152</b> represents three physical communication lines, each carrying one of the above types of signals. In an alternative embodiment, vertical and horizontal synchronization signals are processed by frame grabber <b>148</b> to internally generate a data valid window signal. Frame grabber block <b>148</b> appropriately responds to the respective synchronization signals, by establishing buffer memory locations within integrated RAM <b>149</b> of block <b>148</b> for temporary storage of the image data received from image sensor chip <b>182</b> over data line <b>159</b>. At any time during the capture of a frame of image data into system RAM <b>142</b>, buffer RAM <b>149</b> of frame grabber block <b>148</b> may store a partial (e.g. about 0.1 to 0.8) or a full line of image data.</p>
<p id="p-0084" num="0083">Referring to further aspects of electrical circuit <b>100</b>, circuit <b>100</b> includes a system bus <b>150</b>. Bus <b>150</b> may be in communication with CPU <b>141</b> via a memory interface such as EIM interface <b>117</b> of IC chip <b>180</b>. System RAM <b>142</b> and system ROM <b>143</b> are also connected to bus <b>150</b> and in communication with CPU <b>141</b> via bus <b>150</b>. In the embodiment shown, RAM <b>142</b> and ROM <b>143</b> are provided by discreet IC chips. System RAM <b>142</b> and system ROM <b>143</b> could also be incorporated into processor chip <b>180</b>.</p>
<p id="p-0085" num="0084">In addition to having system RAM <b>142</b>, sometimes referred to as &#x201c;working&#x201d; RAM, electrical circuit <b>100</b> may include one or more long term storage devices. Electrical circuit <b>100</b> can include for example a &#x201c;flash&#x201d; memory device <b>120</b>. Several standardized formats are available for such flash memory devices including: &#x201c;Multimedia&#x201d; (MMC), &#x201c;Smart Media,&#x201d; &#x201c;Compact Flash,&#x201d; and &#x201c;Memory Stick.&#x201d; Flash memory devices are conveniently available in card structures which can be interfaced to CPU <b>141</b> via an appropriate &#x201c;slot&#x201d; electromechanical interface in communication with IC chip <b>180</b>. Flash memory devices are particularly useful when reader <b>5</b> must archive numerous frames of image data. Electrical circuit <b>100</b> can also include other types of long term storage such as a hard drive which may be interfaced to bus <b>150</b> or to an appropriate I/O interface of processor IC chip <b>180</b>.</p>
<p id="p-0086" num="0085">In a further aspect of electrical circuit <b>100</b>, control circuit <b>140</b> is configured to control the turning off and turning on of LEDs <b>16</b>, <b>18</b> of illumination block <b>160</b>. Control circuit <b>140</b> preferably controls illumination block <b>160</b> in a manner that is coordinated with the capturing of the frames of image data. Illumination LEDs <b>16</b> are typically on during at least a portion of frame capture periods. Configuring circuit <b>140</b> so that LEDs <b>16</b>, <b>18</b> have off periods significantly reduces the power consumption of circuit <b>100</b>.</p>
<p id="p-0087" num="0086">In a further aspect of the electrical circuit <b>100</b>, electrical circuit <b>100</b> can be configured so that PWM output interface <b>114</b> of IC chip <b>180</b> controls illumination LEDs of an imaging module such as illumination LEDs <b>16</b> of module <b>10</b>-<b>1</b> or aiming/illumination LEDs <b>18</b> of module <b>10</b>-<b>2</b>.</p>
<p id="p-0088" num="0087">In one embodiment, illumination block <b>160</b> is in communication with PWM output interface <b>114</b> and configured in such manner that LEDs <b>16</b> are turned on at a leading edge of PWM pulses output at PWM interface <b>114</b>, and are turned off at falling edges of PWM pulses output at PWM interface <b>114</b>. PWM interface <b>114</b> should be configured so that several pulses are generated and sent over communication line <b>153</b><i>i </i>during the time that a single row of pixels of image data are exposed to light prior to clocking out of pixel values corresponding to that row. Thus, illumination LEDs <b>16</b> would be turned on and off several times during the exposure period for exposing a row of pixels to light. Further, the number of pulses output by PWM output <b>114</b> during the time that a single row of pixels are exposed should not vary substantially from row to row. The pixel clock signal received at frame grabber block <b>148</b> of IC chip <b>180</b> can be utilized to generate the PWM output. It can be seen, therefore, that multifunctional IC chip <b>180</b> including frame grabber block <b>148</b> and PWM output <b>114</b> greatly simplifies the task of developing PWM signals for use in controlling illumination LEDs <b>16</b> of module <b>10</b>.</p>
<p id="p-0089" num="0088">In another embodiment, PWM output <b>114</b> and illumination block <b>160</b> are configured so that PWM output <b>114</b> controls the intensity of illumination, not the on time/off time of illumination. Illumination LED block <b>160</b> in such an embodiment can include a power supply circuit which is interfaced to PWM output <b>114</b> such that the PWM signal output at PWM output <b>114</b> varies the voltage or current supplied to LEDs <b>16</b>.</p>
<p id="p-0090" num="0089">In a further aspect of electrical circuit <b>100</b>, aiming LEDs <b>18</b> of circuit <b>100</b> can be controlled by a signal transmitted by a general purpose I/O port <b>116</b> of IC chip <b>180</b> over communication line <b>153</b><i>a</i>. Multifunctional processor IC chip <b>180</b> can be programmed so that an aiming LED control signal <b>168</b>, as is shown in the timing diagram of <figref idref="DRAWINGS">FIG. 2</figref><i>g</i>, is caused to change to an &#x201c;on&#x201d; state when frame grabber block <b>148</b> completes the process of capturing a complete frame of image data. In the time line of <figref idref="DRAWINGS">FIG. 2</figref><i>g</i>, frame exposure periods P<b>1</b>, P<b>2</b>, and P<b>3</b> are plotted against an aiming LED control signal <b>168</b>. Frame grabber block <b>148</b> may be configured to generate an &#x201c;end of acquisition&#x201d; or &#x201c;end of frame&#x201d; signal when frame grabber block <b>148</b> completes the process of capturing a complete frame of image data into RAM <b>142</b>. When CPU <b>141</b> receives an &#x201c;end of acquisition&#x201d; signal, CPU <b>141</b> controls I/O port <b>116</b> to change the state of LED control signal <b>168</b>. Control circuit <b>140</b> may also change the state of LED control signal <b>168</b> when generating a start of frame signal. As indicated by the time line of <figref idref="DRAWINGS">FIG. 2</figref><i>g</i>, control circuit <b>140</b> may execute a delay prior to changing the state of signal <b>168</b>. Control circuit <b>140</b> is programmed so that LED control signal <b>168</b> remains in an &#x201c;ON&#x201d; state known to be sufficiently short duration so as not to cause actuation of an aiming LED <b>18</b> during a succeeding frame exposure period. Configured in the manner described, aiming LEDs <b>18</b> are selectively pulsed on for a short duration during intermediate successive frame exposure periods, e.g. frame exposure periods P<b>1</b> and P<b>2</b>.</p>
<p id="p-0091" num="0090">Referring now to <figref idref="DRAWINGS">FIG. 2</figref><i>b</i>, electrical circuit <b>101</b> is described. Electrical circuit <b>101</b> controls operation of a single imaging module optical reader comprising a low cost 1D CCD image sensor <b>32</b> incorporated on IC chip <b>183</b>. Image sensor <b>32</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>b </i>may be provided for example by a Toshiba Model TCD 1304 AP linear image sensor. Further aspects of an exemplary 1D imaging module are described, for example, in application Ser. No. 09/658,811, filed Sep. 11, 2000, entitled &#x201c;Optical Assembly for Barcode Scanner,&#x201d; (now U.S. Pat. No. 6,607,128) which is hereby incorporated herein by reference in its entirety.</p>
<p id="p-0092" num="0091">Referring to aspects of electrical circuit <b>101</b> in detail, electrical circuit <b>101</b> includes a control circuit <b>140</b> which, like control circuit <b>140</b> of circuit <b>100</b> is partially incorporated in a multifunctional processor IC chip <b>180</b> including CPU <b>141</b> and a frame grabber block <b>148</b>. Control circuit <b>140</b> of circuit <b>101</b> further includes system RAM <b>142</b> system ROM <b>143</b> and supplementary central processor unit (CPU) <b>147</b>, integrated on processor IC chip <b>179</b>. System RAM <b>142</b> and system RAM <b>143</b> are in communication with EIM interface <b>117</b> of IC chip <b>180</b> via bus <b>150</b>.</p>
<p id="p-0093" num="0092">Processor IC chip <b>179</b> provides control and timing operations similar to that provided by electrical block <b>134</b> of image sensor chip <b>182</b> described in <figref idref="DRAWINGS">FIG. 1</figref><i>a</i>. Processor IC chip <b>179</b>, in general, sends synchronization signals and digital clocking signals to IC chip <b>180</b>, and sends digital clocking signals to A/D conversion circuit <b>136</b> and image sensor <b>32</b>. Processor IC chip <b>179</b> of circuit <b>101</b> may be a relatively low power processor IC chip such as an 8-bit Cypress Programmable System-on-Chip&#x2122; (PSoC&#x2122;) CY8C26Z33-24PZI Microcontroller processor IC chip available from Cypress MicroSystems of Bothell, Wash.</p>
<p id="p-0094" num="0093">Aspects of the operation of IC chip <b>179</b> in during the course of capturing slice image data will now be described in detail. When trigger <b>13</b><i>t </i>is pulled, CPU <b>141</b> transmits enable image capture instructions over communication line <b>151</b>. In response to receipt of an image capture enable instructions received from chip <b>180</b>, processor IC chip <b>179</b> performs a variety of operations. Processor IC chip <b>179</b> may send synchronization signals, such as &#x201c;start of scan,&#x201d; &#x201c;data valid window,&#x201d; and &#x201c;data acquisition clock&#x201d; signals to frame grabber block <b>148</b> via communication line <b>152</b>. Processor IC chip <b>179</b> may also send timing signals and digital clocking signals (e.g. master clock, integration clear gate, and shift gate pulse) to image sensor <b>32</b>. Processor IC chip <b>179</b> typically also transmits a master clock signal to A/D conversion circuit <b>136</b>. Referring to further aspects of IC chip <b>180</b> of circuit <b>101</b>, CPU <b>141</b> of chip <b>180</b>, may also send e.g. gain setting, exposure setting, and timing initialization signals via line <b>151</b> to IC chip <b>179</b>. Communication between IC chip <b>180</b> and IC chip <b>179</b> may be made via an SPI interface or I/O interface <b>116</b> of chip <b>180</b> and chip <b>179</b>.</p>
<p id="p-0095" num="0094">As will be explained with reference to circuit <b>104</b>, shown in <figref idref="DRAWINGS">FIG. 2</figref><i>e</i>, processor IC chip <b>179</b> may be replaced by a programmable logic circuit, e.g. a PLD, CPLD, or an FPGA. IC chip <b>179</b> could also be replaced by an ASIC. Electrical circuit <b>101</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>b </i>includes what may be termed a &#x201c;digital digitizer&#x201d; in that analog voltage levels transmitted by CCD image sensor <b>32</b> on line <b>155</b> are converted into gray scale pixel values by A/D converter <b>136</b> and transmitted via line <b>159</b> to frame grabber block <b>148</b>. Circuit <b>101</b> could also include an analog digitizer which processes an analog signal generated by image sensor <b>32</b> to generate a two-state output signal that changes state in accordance with light-to-dark and dark-do-light transitions of the image sensor analog output signal.</p>
<p id="p-0096" num="0095">Processor IC chip <b>179</b> also controls LED bank <b>160</b>. LED bank <b>160</b> of a 1D image sensor reader typically includes a single bank of LEDs which simultaneously illuminates a target area and provides an aiming pattern facilitating aligning of the reader with a target indicia. LEDs <b>18</b> of 1D imaging module <b>10</b>-<b>2</b> like LEDs <b>16</b> of module <b>10</b>-<b>1</b> can be pulsed so as to reduce energy consumption by LEDs <b>18</b>.</p>
<p id="p-0097" num="0096">Electrical circuit <b>100</b> and electrical circuit <b>101</b> form a family of 1D and 2D optical readers electrical circuits, which may be manufactured by a single manufacturing entity wherein both of the 1D and 2D readers include the same main processor chip, namely, multifunctional processor IC chip <b>180</b>. Multifunctional processor IC chip <b>180</b> of circuit <b>100</b> and circuit <b>101</b> can both be provided by e.g. a Dragonball MX1 IC chip or a Dragonball MXL IC chip of the type available from Motorola, Inc. Multifunctional processor IC chip <b>180</b> of electrical circuit <b>101</b> includes far more processing power than is necessary to provide the functionality of a 1D optical reader. Nevertheless, the inventors have discovered that the overall cost of electrical circuit <b>101</b> is reduced by incorporating frame grabbing multifunctional IC chip <b>180</b> in circuit <b>101</b>, for reasons including that such incorporation reduces overall engineering cost relative to the development costs of two different 1D and 2D electrical circuits comprising two different main processor types.</p>
<p id="p-0098" num="0097">Various electrical circuit architectures for operating a reader having more than one imaging module <b>10</b> are shown in <figref idref="DRAWINGS">FIGS. 2</figref><i>c</i>-<b>2</b><i>f. </i></p>
<p id="p-0099" num="0098">In the architecture of <figref idref="DRAWINGS">FIG. 2</figref><i>c</i>, electrical circuit <b>102</b> includes a pair of imaging modules <b>10</b> and a control circuit <b>140</b>. Control circuit <b>140</b> includes a field programmable gate array (FPGA) <b>161</b>, a multifunctional processor IC Chip <b>180</b> including a CPU <b>141</b> and frame grabber block <b>148</b>, a system RAM <b>142</b> and a system ROM <b>143</b>. Processor IC chip <b>180</b> may be, for example, a Dragonball MX1 IC chip or a Dragonball MXL IC chip of the type available from Motorola, Inc. Imaging modules <b>10</b><i>a </i>and <b>10</b><i>b </i>shown in block form in <figref idref="DRAWINGS">FIG. 2</figref><i>c </i>correspond to the physical 2D imaging module <b>10</b>-<b>1</b> shown in <figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<b>3</b><i>c</i>. System RAM <b>142</b> and system ROM <b>143</b> are in communication with processor IC Chip <b>180</b> via system bus <b>150</b>. In general, FPGA <b>161</b> of circuit <b>102</b> is programmed to execute a multiplexer function indicated by block <b>155</b>. In response to module select signals received from multifunctional processor IC chip <b>180</b>, multiplexer <b>155</b> receives image data over one of data lines <b>159</b><i>a</i>, <b>159</b><i>b </i>from a selected one of module <b>10</b><i>a </i>and module <b>10</b><i>b </i>and sends the data to frame grabber block <b>148</b> of processor IC chip <b>180</b>. Multiplexer <b>155</b> can be deleted if imaging modules <b>10</b> are selected to include image sensor IC chips which generate high impedance (tri-statable) synchronization signals when not actuated. In some embodiments, FPGAs described herein can be replaced by another programmable circuit. For example, a programmable logic device (PLD), a complex programmable logic device (CPLD) or another device such as an ASIC or processor chip (e.g. such as chip <b>179</b> or chip <b>180</b>) can replace FPGA <b>161</b>. In alternative embodiments, imaging modules can be exchanged (e.g., by physical substitution or by moving a cable connection from one socket to another socket) for other types of imaging modules. In yet other embodiments, imaging modules can be switched into or out of communication with the microprocessor-based decoder module, either manually or under computer control, thereby substituting one imaging module for another, or changing the number of imaging modules that are available at a specified time.</p>
<p id="p-0100" num="0099">Referring to the operation of electrical circuit <b>102</b> in further detail, processor IC chip <b>180</b> sends an image capture enable signal to FPGA <b>161</b> via line <b>170</b> when trigger <b>13</b><i>t </i>is actuated and to an appropriate one of modules <b>10</b><i>a </i>and <b>10</b><i>b </i>via one of lines <b>151</b><i>a</i>, <b>151</b><i>b</i>. The selected module, <b>10</b><i>a </i>or <b>10</b><i>b</i>, then sends synchronization signals, and the digital clocking signals as described previously to FPGA <b>161</b> and IC chip <b>180</b>, over the appropriate one of lines <b>152</b><i>a</i>, <b>152</b><i>b. </i></p>
<p id="p-0101" num="0100">FPGA <b>161</b> transmits image data to multifunctional processor IC Chip <b>180</b> over data line <b>171</b> which in turn transmits image data to RAM <b>142</b> over system bus <b>150</b>. Lines <b>151</b><i>a</i>, <b>151</b><i>b </i>may carry PWM interface illumination control signals as described previously in connection with electrical circuit <b>100</b>.</p>
<p id="p-0102" num="0101">In the architecture of <figref idref="DRAWINGS">FIG. 2</figref><i>d</i>, electrical circuit <b>103</b> includes a plurality of N imaging modules <b>10</b>, which may be incorporated in a single housing <b>7</b>, where N is an integer greater than one. Electrical circuit <b>103</b> includes a control circuit <b>140</b> having an FPGA <b>162</b>, a processor IC Chip <b>179</b>, a system RAM <b>142</b> and a system ROM <b>143</b>. FPGA <b>162</b> is in communication with processor IC Chip <b>179</b> via system bus <b>150</b>. Processor IC chip <b>179</b> and FPGA <b>162</b> are also in communication via bus arbitration communication line <b>167</b> which carries bus hand shaking (e.g. bus request, bus grant) signals.</p>
<p id="p-0103" num="0102">Various embodiments of FPGA <b>162</b> are described with reference to <figref idref="DRAWINGS">FIGS. 2</figref><i>h </i>and <b>2</b><i>i</i>. In the embodiment of <figref idref="DRAWINGS">FIG. 2</figref><i>h</i>, FPGA <b>162</b><i>c </i>is programmed to include multiplexer block <b>162</b><i>m</i>, control register <b>162</b><i>c</i>, and a solitary frame grabber block <b>162</b><i>f</i>. Image capture enable signals for actuating image capture via one of a plurality of modules e.g. <b>10</b><i>a </i>are received at control register <b>162</b> in response to an actuation of trigger <b>13</b><i>t</i>. Control register <b>162</b><i>c </i>on receipt of an image capture enable signal sends the image capture enable signal to the selected module <b>10</b> and utilizes the signal to associate frame grabber block <b>162</b><i>f </i>to the selected module e.g. <b>10</b><i>a</i>. It will be understood that control register <b>162</b><i>c </i>can be adapted to send during one type of frame capture method, e.g. illumination actuation signals to a second imaging module, <b>10</b><i>c </i>while actuating an image sensor <b>32</b> of a first module, e.g. <b>10</b><i>a </i>without sending illumination actuation signals to first module <b>10</b><i>a. </i></p>
<p id="p-0104" num="0103">In the embodiment of FPGA <b>162</b> illustrated in <figref idref="DRAWINGS">FIG. 2</figref><i>i</i>, multiplexer block <b>162</b><i>m </i>is deleted. FPGA <b>162</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>i </i>includes N frame grabber blocks <b>162</b><i>f</i>. With use of FPGA <b>162</b> configured as shown in <figref idref="DRAWINGS">FIG. 2</figref><i>i</i>, electrical circuit <b>103</b> can be operated to capture several frames of image data contemporaneously by contemporaneous actuation of each of several imaging modules e.g. <b>10</b><i>a </i>and <b>10</b><i>c</i>. A selected frame of image data can be decoded to recover information encoded in the decodable indicia represented by the frame.</p>
<p id="p-0105" num="0104">Referring to further aspects of electrical circuit <b>103</b>, of <figref idref="DRAWINGS">FIG. 2</figref><i>d </i>processor IC chip <b>179</b> can be provided by general purpose processor IC chip such as a Power PC IC chip of the type available from Motorola. Other suitable IC chips for providing the function of IC chip <b>179</b> of circuit <b>103</b> include, for example, an Intel SA1110 chip and an Xscale family of processor IC chips, also available from Intel.</p>
<p id="p-0106" num="0105">Referring now to <figref idref="DRAWINGS">FIG. 2</figref><i>e</i>, electrical circuit <b>104</b> controls a pair of imaging modules wherein a first imaging module <b>10</b>-<b>1</b> is a 2D imaging module and a second imaging module <b>10</b>-<b>2</b> is a 1D imaging module. Control circuit <b>140</b> includes CPU <b>141</b>, 2D frame grabber block <b>148</b>, FPGA <b>164</b>, system RAM <b>142</b> and system ROM <b>143</b>. Frame grabber block <b>148</b> and CPU <b>141</b> are both incorporated on multifunctional processor IC chip <b>180</b> (e.g. a Motorola Dragonball MX1 IC chip or Dragonball MXL IC chip), as described previously in connection with <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>. A main program executed by CPU <b>141</b> of multifunctional processor IC chip <b>180</b> controls operation of both first imaging module <b>10</b>-<b>1</b> and second imaging module <b>10</b>-<b>2</b>.</p>
<p id="p-0107" num="0106">For capture of a 2D image, processor IC chip <b>180</b> in response to actuation of trigger <b>13</b><i>t </i>sends an image capture enable signal to module <b>10</b>-<b>1</b> via a communication line <b>151</b>. During image capture, 2D imaging module <b>10</b>-<b>1</b> sends synchronization and digital clocking signals to frame grabber block <b>148</b> via communication line <b>152</b> which as explained previously and like all lines represented herein may represent a plurality of physical lines. Further, 2D imaging module <b>10</b>-<b>1</b> sends digitized image data to frame grabber block <b>148</b> via data line <b>159</b><i>a</i>. Processor IC chip <b>180</b> stores image data in RAM <b>142</b> by writing image data stored in buffer memory locations of frame grabber block <b>148</b> to RAM <b>142</b> via system bus <b>150</b>. An illumination control signal communication line is also typically interposed between IC chip <b>180</b> and module <b>10</b>-<b>1</b>. Line <b>151</b> represents an illumination signal communication line.</p>
<p id="p-0108" num="0107">For capture of a 1D &#x201c;slice&#x201d; image representation, processor IC chip <b>180</b> sends a 1D image capture enable signal to FPGA <b>164</b> via system bus <b>150</b>. Processor IC chip <b>180</b> and FPGA <b>164</b> are further in communication via communication line <b>167</b> which carries bus handshaking (e.g. bus request and bus grant) signals. On receipt of an image capture enable signal from processor IC chip <b>180</b>, FPGA <b>164</b> sends digital clocking signals to A/D converter <b>136</b> via line <b>156</b>, to image sensor <b>32</b> via line <b>154</b>, and illumination control signals to illumination LEDs <b>18</b> as shown in the physical form view of <figref idref="DRAWINGS">FIG. 3</figref><i>e </i>via line <b>153</b>. Image sensor <b>32</b> sends analog image signals to A/D converter <b>136</b> via output line <b>155</b> and A/D converter <b>136</b> in turn converts the signals into N (typically 8) bit gray scale pixel values. A/D converter <b>136</b> sends the digitized image data to FPGA <b>164</b> which stores the image data to RAM <b>142</b>.</p>
<p id="p-0109" num="0108">As indicated by the block diagram of <figref idref="DRAWINGS">FIG. 2</figref><i>j</i>, FPGA <b>164</b> of electrical circuit <b>104</b> includes frame grabber block <b>164</b><i>f </i>for fast transfer of image data into system RAM <b>142</b>, image sensor illumination and control block <b>164</b><i>c </i>for controlling LEDs <b>18</b> and for developing synchronization signals, and clock <b>164</b><i>k </i>for generating digital clocking pulses.</p>
<p id="p-0110" num="0109">A computer program (software) recorded on a machine-readable medium is provided for use on a multi-functional processor IC Chip <b>180</b>. When operating, individual modules of the computer program perform the steps of receiving a frame of image data acquired by a selected one of a 1D imaging module and a two-dimensional (2D) imaging module; determining the format of the frame of image data, for example by determining which of said selected imaging modules acquired said received frame of imaging data. Alternatively, one or more modules of the computer program use information about the frame of image data to determine the format of the frame of image data. The computer program comprises one or more modules that decode said frame of imaging data accordingly. The information about the imaging module that acquired the frame of imaging data can include, but is not limited to, at least one of a bus address of the imaging module, an ID code of the imaging module, the model of the imaging module, and an electrical parameter of the imaging module, such as the value of a resistance.</p>
<p id="p-0111" num="0110">The software includes instructions that are performed only as necessary, comprising at least one command to prepare said microprocessor-based decoder module to decode said communicated frame of image data if the microprocessor-based decoder module is not already properly configured to perform the decoding process. As is described in greater detail in conjunction with <figref idref="DRAWINGS">FIGS. 4</figref><i>f</i>-<b>4</b><i>i</i>, <figref idref="DRAWINGS">FIGS. 6</figref><i>a</i>-<b>6</b><i>d</i>, <figref idref="DRAWINGS">FIGS. 7</figref><i>a</i>-<b>7</b><i>b</i>, and <figref idref="DRAWINGS">FIGS. 8</figref><i>a</i>-<b>8</b><i>b</i>, the process for receiving and decoding a frame of image data from a selected imaging module involves several operative steps. In one portion of the process, the microprocessor-based decoder module recognizes the format of the frame of image data by determining one or more of source of the frame of image data and a parameter associated with the frame of image data. As necessary, a module such as a dynamically linked library (for example, a .dll or an .ocx) module is invoked to translate the format of the incoming frame of image data provided by the selected imaging module into a format suitable for further processing. When a different imaging module is selected, the corresponding .dll file is located in memory (or if needed, is read from a machine-readable repository), and is activated. The frame of imaging data is then decoded according to a procedure that depends on the format of the frame of data. For example, a 2D frame of image data is decoded by converting the 2D data into a succession of 1D data segments having 8-bit resolution, converting each 1D data segment into transition location information having one bit resolution, and decoding the transition location information. The process can be programmed as an iterative process, as is explained in greater detail below. Transition location information is information that correlates a transition in reflected light to a position or location in the decodable indicia, such as a change from white to black or black to white at various positions within a conventional 1D bar code. The width or shape of a feature can be deduced from observing successive transition locations.</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 2</figref><i>f </i>depicts another electrical circuit for controlling a plurality of imaging modules. Electrical circuit <b>105</b> includes a pair of frame grabbing FPGAs <b>165</b>, <b>166</b>. First FPGA <b>165</b> is dedicated for frame capture of image data generated by first imaging module <b>10</b><i>a </i>while second frame grabbing FPGA <b>166</b> is dedicated for capture of image data generated by second imaging module <b>10</b><i>b</i>. The architecture of <figref idref="DRAWINGS">FIG. 2</figref><i>f </i>is especially well suited for contemporaneous capture of multiple frames of image data via contemporaneous actuation of image sensors of two separate imaging modules <b>10</b><i>a </i>and <b>10</b><i>b</i>. The image data can be decoded from its location in memory.</p>
<p id="p-0113" num="0112">Control circuit <b>140</b> of electrical circuit <b>105</b> includes CPU <b>141</b> which may be incorporated on a general purpose 32-bit processor IC chip <b>179</b>, frame grabbing FPGAs <b>165</b> and <b>166</b>, system RAM <b>142</b> and system ROM <b>143</b>. Processor IC chip <b>179</b> may transmit image capture enable instruction via communication lines <b>151</b><i>a </i>and <b>151</b><i>b</i>. Processor IC chip <b>179</b> may also send illumination control signals via lines <b>151</b><i>a </i>and <b>151</b><i>b</i>. For example, in a mode of operation that will be described herein processor IC chip may send an image capture enable signal to module <b>10</b><i>a </i>over line <b>151</b><i>a </i>(and an illumination disabling signal over line <b>151</b><i>a</i>), and an illumination control signal to module <b>10</b><i>b </i>over line <b>151</b><i>b </i>with use of a specific image capture method wherein images are captured in such a manner so as to be substantially impervious to specular reflection decode failures.</p>
<p id="p-0114" num="0113">In a further aspect of electrical circuit <b>105</b>, imaging modules <b>10</b><i>a </i>and <b>10</b><i>b </i>send synchronization and digital clocking signals to FPGAs <b>165</b> and <b>166</b> respectively, via lines <b>152</b><i>a </i>and <b>152</b><i>b</i>, and image data to FPGAs <b>165</b> and <b>166</b> respectively over, data lines <b>159</b><i>a </i>and <b>159</b><i>b</i>. Processor IC chip <b>179</b> is in communication with frame grabbing FPGAs <b>165</b> and <b>166</b> via system bus <b>150</b> and via bus arbitration communication lines <b>167</b><i>a </i>and <b>167</b><i>b </i>over which bus handshaking signals (e.g. bus request, bus grant) are sent. While the invention in a major aspect relates to optical readers having multiple imaging modules, another commercial optical product according to another aspect of the invention is described with reference to <figref idref="DRAWINGS">FIGS. 5</figref><i>a</i>-<b>5</b><i>e. </i></p>
<p id="p-0115" num="0114">In <figref idref="DRAWINGS">FIG. 5</figref><i>a </i>an optical reader is shown having an electrical circuit <b>100</b> as described in <figref idref="DRAWINGS">FIGS. 2</figref><i>a </i>wherein an imaging module <b>10</b> is incorporated on a compact flash card <b>510</b>. Compact flash card <b>510</b> carrying circuit <b>100</b> as will be explained herein may be interfaced with a host processor assembly such as a personal data assistant (PDA) <b>540</b> or a personal computer (PC) <b>550</b>. Other embodiments of optical readers can be produced as compact flash cards.</p>
<p id="p-0116" num="0115">As best seen in <figref idref="DRAWINGS">FIG. 5</figref><i>c </i>or <b>5</b><i>d</i>, PDA <b>540</b> can include a compact flash slot <b>544</b> for receiving a compact flash card <b>510</b>, which incorporates an imaging module <b>10</b>.</p>
<p id="p-0117" num="0116">Various features of compact flash card <b>510</b> incorporating module <b>10</b> are described with reference to <figref idref="DRAWINGS">FIG. 5</figref><i>a</i>. As seen in <figref idref="DRAWINGS">FIG. 5</figref><i>a</i>, electrical circuit <b>100</b> including multifunctional frame grabbing IC chip <b>180</b>, system RAM <b>142</b>, and system ROM <b>143</b> are incorporated on compact flash card <b>510</b> which further carries imaging module <b>10</b>. Imaging module <b>10</b> may be a 2D imaging module as described with reference to <figref idref="DRAWINGS">FIG. 3</figref><i>a</i>-<b>3</b><i>c</i>, or a 1D module, e.g. as described with reference <figref idref="DRAWINGS">FIG. 3</figref><i>e</i>. Card <b>510</b> typically further comprises a protective cover (not shown).</p>
<p id="p-0118" num="0117">Compact flash card <b>510</b> including electrical circuit <b>100</b> as indicated by block diagram <figref idref="DRAWINGS">FIG. 5</figref><i>b</i>, is interfaced to a host processor system <b>68</b>. As will be explained further herein, host processor system <b>68</b> can be included in e.g. a personal data assistant (PDA) <b>540</b> as shown in <figref idref="DRAWINGS">FIG. 5</figref><i>b </i>or a personal computer (PC) <b>550</b> as shown in <figref idref="DRAWINGS">FIG. 5</figref><i>e. </i></p>
<p id="p-0119" num="0118">Referring to further aspects of the block diagram of <figref idref="DRAWINGS">FIG. 5</figref><i>b</i>, circuit <b>515</b> includes FPGA <b>520</b> which facilitates communication between electrical circuit <b>100</b> and host system <b>68</b>. A physical form view of FPGA <b>520</b> is shown in physical form diagram of <figref idref="DRAWINGS">FIG. 5</figref><i>a</i>. FPGA <b>520</b> may be programmed to perform a variety of functions. FPGA <b>520</b> may be programmed to (1) communicate with host <b>68</b> to inform host <b>68</b> that compact flash card <b>510</b> is connected to host <b>68</b> when it is first connected, (2) to perform all compact flash bus timing, and (3) to provide all buffer interfaces required to receive from circuit <b>100</b> data in a form supported by electrical circuit <b>100</b> and to allow that data to be received in a compact flash format as is required by host <b>68</b>.</p>
<p id="p-0120" num="0119">FPGA <b>520</b> can be connected via a communication line <b>504</b> to UART interface <b>108</b> of multifunctional processor IC chip <b>180</b>. UART interface <b>108</b> may transmit data in e.g. an RS <b>232</b> format while FPGA <b>520</b>, appropriately programmed, converts that data into a compact flash format. Further connected to FPGA <b>520</b> via line <b>526</b> is a compact flash female connector <b>530</b>, which is formed on an edge of compact flash card <b>510</b>, and comprises a plurality of sockets <b>530</b><i>s </i>as indicated in the exploded section view of <figref idref="DRAWINGS">FIG. 5</figref><i>a. </i></p>
<p id="p-0121" num="0120">Compact flash card <b>510</b> including an electrical circuit <b>100</b> having imaging module <b>10</b> can operate in a first integrated mode or a second &#x201c;free-standing&#x201d; which in one specific embodiment can be considered a &#x201c;tethered&#x201d; mode. An integrated mode of operation of card <b>510</b> is described with reference to <figref idref="DRAWINGS">FIGS. 5</figref><i>c </i>and <b>5</b><i>d</i>. In an integrated mode, card <b>510</b> is integrated into a device such as a PDA <b>540</b>. To electrically and mechanically connect card <b>510</b> to a host, device female end <b>530</b> is connected to male end compact flash connector <b>531</b>, comprising a plurality of pins, within a housing of the host device.</p>
<p id="p-0122" num="0121">A free-standing mode of operation is illustrated with reference to <figref idref="DRAWINGS">FIG. 5</figref><i>e</i>. In a free-standing mode of operation, compact flash card <b>510</b> including module <b>10</b> is positioned in a position spaced apart from a host device e.g. device <b>550</b>. Compact flash card <b>510</b> may rest on a table top or else may be mounted to a fixed member spaced apart from the host device e.g. PC <b>550</b>. In a free-standing mode, card <b>510</b> may be connected to a host device via a flexible cable connector <b>560</b>. When card <b>510</b> is connected to a host assembly via a flexible connector, card <b>510</b> may be considered to be operating in a &#x201c;tethered&#x201d; mode. Card <b>510</b> may also be wirelessly connected to a host via an RF link, an IR link, or a link using a similar wireless connection like Bluetooth or 802.11 compatible hardware. In the embodiment of <figref idref="DRAWINGS">FIG. 5</figref><i>e </i>cable connector <b>560</b> is interfaced to host device <b>550</b> on one end and to compact flash card <b>510</b> on another end. Cable connector <b>560</b> includes male compact flash connector <b>531</b> for facilitating communication between connector <b>560</b> and card <b>510</b>. Card <b>510</b> can further include feet <b>565</b> of height substantially the same as connector <b>531</b> disposed on an under surface thereof so that card <b>510</b> can rest substantially horizontally on a table surface when operating in a free-standing mode. Host device <b>550</b> in the free-standing mode diagram illustrated by <figref idref="DRAWINGS">FIG. 5</figref><i>e </i>is shown as a PC. It will be understood that a host device in a free-standing mode could also be provided by PDA <b>540</b> or another mobile or non-mobile computer device.</p>
<p id="p-0123" num="0122">The multiple imaging module electrical circuits <b>102</b>, <b>103</b>, <b>104</b>, and <b>105</b> described herein can be implemented for operation of imaging modules spread out over several housings or for operation of imaging modules incorporated in a housing <b>7</b> of multiple imaging module reader <b>5</b>-<b>1</b>, <b>5</b>-<b>2</b>, <b>5</b>-<b>3</b>, <b>5</b>-<b>4</b>, <b>5</b>-<b>5</b>, <b>5</b>-<b>6</b>, and <b>5</b>-<b>7</b>, <b>5</b>-<b>8</b> and <b>5</b>-<b>9</b> as shown in physical form views <b>1</b><i>a</i>-<b>1</b><i>i. </i></p>
<p id="p-0124" num="0123">Methods for operating a multiple imaging module optical reader according to the invention will now be described in greater detail. Flow diagrams of <figref idref="DRAWINGS">FIGS. 4</figref><i>a</i>-<b>4</b><i>c </i>and <figref idref="DRAWINGS">FIGS. 4</figref><i>f</i>-<b>4</b><i>i </i>illustrate operation of a multiple imaging module optical reader having at least two imaging modules <b>10</b><i>a</i>, <b>10</b><i>b</i>. The modules described in the illustrative example given herein are 1D and 2D imaging modules.</p>
<p id="p-0125" num="0124">As will be recognized by practitioners of ordinary skill, any number of modules that provide image data in any of a plurality of formats, such as 1D imaging modules, 2D imaging modules, gray scale imaging modules, color imaging modules, and biometric imaging modules can be present in any combination, limited only by the ability to design and to build multiplexed input and output connections to the microprocessor-based decoder module, such as an N port by M line multiplexer that handles N imaging modules, each imaging module having a total of no more than M data and control lines, where N and M represent positive integers. As will be recognized, in a properly designed system, a programmed computer can select one of the plurality of imaging modules present by suitably driving the multiplexer. Alternatively, a user can select one of the plurality of available imaging modules, for example by activating a switch manually or connecting a cable to a cable connector.</p>
<p id="p-0126" num="0125">In the reader methods described herein &#x201c;actuation of an image sensor&#x201d; generally refers to at least one step in the process of sending appropriate signals to an image sensor <b>32</b> to cause exposure of image sensor pixels to light and to cause clocking out of electrical signals corresponding to light received at pixels of the array. These steps are described in greater detail in for example, U.S. application Ser. No. 09/766,922, filed Jan. 22, 2001, entitled &#x201c;Optical Reader Having Reduced Parameter Determination Delay,&#x201d; (now U.S. Patent Publication No. 2002/0125317) which application is incorporated herein by reference in its entirety. &#x201c;Actuation of illumination&#x201d; herein generally refers to the step of sending electrical current to a light source e.g. <b>16</b>, <b>18</b> to turn on the light source.</p>
<p id="p-0127" num="0126">Referring to the reader operating method of <figref idref="DRAWINGS">FIG. 4</figref><i>a</i>, at block <b>404</b> after a trigger <b>13</b><i>t </i>is pulled (block <b>402</b>) control circuit <b>140</b> actuates image sensor <b>32</b> of first imaging module <b>10</b><i>a </i>and illumination light sources <b>16</b> of first imaging module <b>10</b><i>a </i>during a frame capture period in which a first frame of image data is captured. At block <b>406</b> control circuit <b>140</b> subjects the first captured frame of image data to a decode attempt. If the decode attempt is not successful (block <b>408</b>), control circuit <b>140</b> executes block <b>410</b> to capture a second frame of image data. Control circuit <b>140</b> actuates image sensor <b>32</b> and illumination light sources <b>16</b> of second imaging module <b>10</b><i>b </i>when capturing a second frame of image data. Instead of capturing a second frame of image subsequent to subjecting a first frame to a decode attempt (<b>406</b>) control circuit <b>140</b> can capture a second frame as described in connection with block <b>410</b> prior to the decode attempt of block <b>406</b>. Control circuit <b>140</b> can capture a first frame as described in connection with block <b>404</b> and a second frame as described in connection with block <b>410</b> in any order and can capture the frames contemporaneously. At block <b>412</b> control circuit <b>140</b> subjects the indicia representation of the second frame to a decode attempt, and at block <b>410</b> outputs a decoded out data message if decoding is successful (block <b>414</b>). The attempt to decode a decodable indicia may be in accordance with a method for decoding decodable indicia such as are described in U.S. application Ser. No. 09/904,697, filed Jul. 13, 2001, entitled &#x201c;Applying a Color Imager To A Hand Held Reader For Indicia Reading Image Capture,&#x201d; (now U.S. Pat. No. 6,772,569) which is incorporated herein by reference in its entirety. The reader control method described with reference to the flow diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>a </i>is highly useful wherein specular reflection decode failures can be expected. Referring to the example of two module reader <b>5</b>-<b>1</b> shown in <figref idref="DRAWINGS">FIGS. 1</figref><i>a </i>and <b>1</b><i>b </i>note that if there may be a specular reflection decode failure when a first frame corresponding to a mirrored planar surface is captured via actuation of first module <b>10</b><i>a </i>then there likely will not be a specular reflection decode failure when a second frame captured via actuation of second module <b>10</b><i>b </i>is subjected to decoding.</p>
<p id="p-0128" num="0127">A &#x201c;wait for trigger pull&#x201d; control loop, as described in connection with block <b>402</b>, <figref idref="DRAWINGS">FIG. 4</figref><i>a</i>, block <b>420</b>, <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>, block <b>444</b>, <figref idref="DRAWINGS">FIG. 4</figref><i>c </i>will now be described in greater detail. When a trigger <b>13</b><i>t </i>of reader <b>5</b> is actuated, control circuit <b>140</b> generates a trigger signal to cause branching of program control as described in <figref idref="DRAWINGS">FIGS. 4</figref><i>a</i>, <b>4</b><i>b</i>, and <b>4</b><i>c</i>. According to the invention, a trigger signal can also be generated automatically in response to a decodable indicia being presented in a field of view of a module of reader <b>5</b>. A method of automatically generating what can be considered a trigger signal based on detected edge transitions without a physical trigger pull is described in copending application Ser. No. 09/432,282 filed Nov. 2, 1999, entitled &#x201c;Indicia Sensor System for Optical Reader,&#x201d; (now U.S. Pat. No. 6,585,159) which is incorporated herein by reference in its entirety. It will be understood that any of the control loops indicated by blocks <b>402</b>, <b>420</b>, and <b>440</b> can be substituted for by a control loop wherein control circuit <b>140</b> waits for trigger signal automatically generated when a decodable indicia <b>15</b> moved into a field of view of a module of reader <b>5</b>.</p>
<p id="p-0129" num="0128">In one possible variation of the invention, first and second imaging modules <b>10</b><i>a</i>, <b>10</b><i>b</i>, and possibly all N modules of an N imaging module optical reader are configured so that each module has a different best focus distance. For example, module <b>10</b><i>c </i>of reader <b>5</b>-<b>2</b> can be configured to a best focus distance of about 3 inches, module <b>10</b><i>a </i>can be configured to have a best focus distance of about 6 inches, while module <b>10</b><i>b </i>can be configured to have a best focus distance of about 9 inches. It will be seen that configuring a reader of the invention so that each of the modules has a different best focus distance increases the overall depth of field of the reader.</p>
<p id="p-0130" num="0129">A multiple module reader of the invention wherein each module has a different best focus distance can be operated in accordance with the flow diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>a </i>to the end that the reader automatically reads target indicia disposed at a wide range of reader-to-target distance. If an object being read is disposed at a distance closer to the best focus distance of a second module but a substantial distance from a best focus distance of a first module, the reader operating in accordance with the flow diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>a </i>may successfully decode the indicia at block <b>412</b> (second frame decode attempt) after failing to decode the indicia at block <b>406</b> (first frame decode attempt).</p>
<p id="p-0131" num="0130">While block <b>404</b> of the flow diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>a </i>and other operating blocks herein refers to capturing a &#x201c;first&#x201d; frame of image data, it will be understood that a &#x201c;first&#x201d; captured frame as referred to herein is not necessarily the initial frame captured by a reader subsequent to actuation of trigger <b>13</b><i>t</i>. For example, as explained in application Ser. No. 09/766,922, filed Jan. 22, 2001, entitled &#x201c;Optical Reader Having Reduced Parameter Determination Delay,&#x201d; (now U.S. Patent Publication No. 2002/0125317) which application is incorporated herein by reference in its entirety, optical readers commonly process one or more &#x201c;test&#x201d; frames of image data to establish exposure levels and other operating parameters.</p>
<p id="p-0132" num="0131">Another method for operating a multiple imaging module optical reader is described with reference to the flow diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>. After trigger <b>13</b><i>t </i>is pulled at block <b>420</b> control circuit <b>140</b> captures a first frame of image data at block <b>422</b>. Control circuit <b>140</b> captures a first frame image data via actuation of an image sensor <b>32</b> of first module <b>10</b><i>a </i>and illumination light source <b>16</b> of first imaging module <b>10</b><i>a</i>. That is, image sensor <b>32</b> of first module <b>10</b><i>a </i>is actuated to generate image signals while a target is illuminated by illumination light sources <b>16</b> of first imaging module <b>10</b><i>a</i>. At block <b>424</b> control circuit <b>140</b> subjects the first frame of capture image data to a decoding attempt. If decoding is not successful (block <b>426</b>), then control circuit <b>140</b> automatically proceeds to block <b>428</b> to capture a second frame of image data. Control circuit <b>140</b> can also capture a second frame of image data as described in connection with block <b>428</b> prior to subjecting a first frame of image data to a decode attempt (block <b>424</b>). Control circuit <b>140</b> can capture a first frame as described in connection with block <b>422</b>, a second frame as described in block <b>428</b>, and a third frame (block <b>434</b>) in any order. Control circuit <b>140</b> can capture first, second, and third frames of image data (blocks <b>422</b>, <b>428</b> and <b>434</b>) contemporaneously. When control circuit <b>140</b> captures a second frame of image data at block <b>428</b> control circuit <b>140</b> once again actuates image sensor <b>32</b> of first imaging module <b>10</b><i>a </i>as in the step of block <b>422</b>. However, when capturing a second frame of image data via actuation of first image sensor, control circuit <b>140</b> actuates illumination light sources <b>16</b> of second imaging module <b>10</b><i>b </i>without actuating illumination sources <b>16</b> of first imaging module <b>10</b><i>a</i>. Because image sensor <b>32</b> of first module <b>10</b><i>a </i>and illumination sources <b>16</b> of second module <b>10</b><i>b </i>are substantially spaced apart, the frame of image data captured at block <b>428</b> is substantially impervious to specular reflection read failures. The operating method described with reference to <figref idref="DRAWINGS">FIG. 4</figref><i>b </i>can be utilized with any use of readers <b>5</b>-<b>1</b>, <b>5</b>-<b>2</b>, <b>5</b>-<b>3</b>, <b>5</b>-<b>4</b>, <b>5</b>-<b>5</b>, <b>5</b>-<b>6</b>, <b>5</b>-<b>7</b>, <b>5</b>-<b>8</b>, and <b>5</b>-<b>9</b>. As indicated by block <b>434</b> a reader having three imaging modules <b>10</b><i>a</i>, <b>10</b><i>b</i>, and <b>10</b><i>c </i>e.g. of reader <b>5</b>-<b>2</b> can be further configured so that the control circuit <b>140</b> captures a third frame of image by actuation of image sensor <b>32</b> of first module e.g., <b>10</b><i>a </i>together with actuation of illumination light sources of third module <b>10</b><i>c. </i></p>
<p id="p-0133" num="0132">A still further method for operating an optical reader having a plurality of imaging modules is described with reference to the flow diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>c</i>. Referring to the flow diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>c </i>control circuit <b>140</b> at block <b>446</b> captures first and second frames of image data. The first frame of image data captured at block <b>446</b> may be captured via actuation of image sensor and illumination light sources of first imaging module e.g., module <b>10</b><i>a </i>of reader <b>5</b>, <figref idref="DRAWINGS">FIG. 1</figref><i>a</i>. The second frame of image data captured at block <b>446</b> may be captured via actuation of image sensor <b>32</b> and illumination light sources <b>16</b> of second imaging module <b>10</b><i>c</i>. Referring to further aspects of image capture block <b>446</b>, control circuit <b>140</b> may capture first and second frames at block <b>446</b> sequentially (the first frame is captured in its entirety and then the second frame is captured) or contemporaneously (the capture of the second frame begins before capture of the first frame is complete). At block <b>448</b> control circuit <b>140</b> subjects the first captured frame to a decode attempt. If decoding fails, control circuit <b>140</b> proceeds to block <b>456</b> to combine the first captured frame captured by actuation of an image sensor of a first module <b>10</b><i>a </i>with a second captured frame of image data captured via actuation of a second imaging module <b>10</b><i>c </i>to generate a third image representation. At block <b>458</b> control circuit <b>140</b> subjects the third image representation derived from the first and second frames to a decoding attempt. If decoding is successful, control circuit <b>140</b> outputs the decoded out message at block <b>462</b>.</p>
<p id="p-0134" num="0133">At several stages of the operating methods described herein, multiple imaging module reader <b>5</b> executes the steps of attempting to decode decodable indicia and branching control of an operating program if the decoding attempt is not successful. In a further aspect of the invention, the step of attempting to decode in any one of the operating programs described with reference to <figref idref="DRAWINGS">FIGS. 4</figref><i>a</i>, <b>4</b><i>b</i>, and <b>4</b><i>c </i>can be substituted for or supplemented with the step of preliminarily evaluating image data to determine whether decoding will likely be successful. A step of preliminarily evaluating image data can eliminate the need to actually launch decoding processing to determine whether indicia representation(s) within a frame of image data can be decoded.</p>
<p id="p-0135" num="0134">The step of preliminarily evaluating image data to determine whether decoding will be successful can take on a variety of forms. In one example of the preliminary image data evaluating step, a preliminary image data evaluating step can include the step of examining gray scale values of a frame of image data to determine if the image data has become saturated. If a saturation condition (sometimes referred to as a &#x201c;white out&#x201d; condition) is present there is a substantial likelihood of specular reflection misread or other type of misread attributable to excessive illumination. A saturated condition can be considered to be present for example if a sum total of all gray scale values exceeds a predetermined value, or if an average gray scale value exceeds a predetermined threshold white level. All pixel values may be evaluated during the preliminary evaluation step. More typically, however, a sample of pixel values comprising less than all pixel values of a frame are evaluated to speed processing. The sampling of pixels may be predetermined and/or adaptive.</p>
<p id="p-0136" num="0135">The step of preliminarily evaluating image data to determine whether decoding will be successful can also include the step of estimating a module-to-target distance. If an estimated module-to-target distance exceeds a best focus distance by a threshold amount (which may be a predetermined threshold), control circuit <b>140</b> may preliminarily determine that decoding will likely not be successful without actually subjecting image data of a frame to a decode attempt. A method for generating a signal that varies with module to target distance is described in commonly assigned U.S. Pat. No. 5,773,810, entitled &#x201c;Method of Generating Real Time Degree of Focus Signal For Hand Held Imaging Device,&#x201d; which is hereby incorporated herein by reference in its entirety.</p>
<p id="p-0137" num="0136">The preliminary evaluation of a frame of image data to determine the format of the data, or to determine which imaging module acquired the frame of image data takes place as described above with regard to <figref idref="DRAWINGS">FIGS. 4</figref><i>f</i>-<b>4</b><i>g. </i></p>
<p id="p-0138" num="0137">Referring to the operating method described with reference to <figref idref="DRAWINGS">FIG. 4</figref><i>c </i>in further detail, a number of different methods may be utilized to execute block <b>456</b> (combining the first and second frame of image data).</p>
<p id="p-0139" num="0138">In one method for combining a first frame and a second frame of image data, cross correlation image combination methods can be utilized. In a cross correlation image combination method statistical analyses are executed to compare two or more frames of image data and frames of image data are shifted relative to one another until correlation is optimized.</p>
<p id="p-0140" num="0139">In another method for combining first and second frames of image data, areas of overlap between two frames of image data e.g. <b>610</b>, <b>614</b> are determined and then the image data contribution from one of the frames corresponding to the overlapping area is deleted or modified in a manner depending on the overlapping region image data of the other frame to generate a third image representation <b>630</b>. In the example of <figref idref="DRAWINGS">FIG. 4</figref><i>d</i>, showing first, second, and third frames of image data <b>610</b>, <b>612</b>, and <b>614</b>, overlapping regions <b>619</b> and <b>621</b> are defined between the first and third frames <b>610</b> and <b>614</b> and between the third and second frames <b>614</b> and <b>612</b>. Overlapping regions of image data <b>619</b>, <b>621</b> are regions e.g. of image data from two separate frames of image data that correspond to a common region of a target substrate.</p>
<p id="p-0141" num="0140">The area of overlap between frames of image data captured via actuation of the image sensors of neighboring imaging modules can be determined based on known characteristics of the neighboring imaging modules <b>10</b> of reader <b>5</b>, such as the spacing between imaging modules of reader <b>5</b> (e.g. modules <b>10</b><i>a </i>and <b>10</b><i>c </i>of reader <b>5</b>-<b>3</b>), power of imaging optics <b>40</b> of the particular imaging module <b>10</b>, and the respective module-to-target distances of the neighboring modules. A distance of a module to a target can be estimated via analysis of captured image data, for example by a method for developing a degree of focus signal as is described in commonly assigned U.S. Pat. No. 5,773,810, entitled &#x201c;Method For Generating Real Time Degree of Focus Signal For Hand Held Imaging Device,&#x201d; which is hereby incorporated herein by reference in its entirety. It can be seen that the image frame diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>d </i>may correspond to a parallel-axis reader <b>5</b> having a plurality of imaging modules comprising parallel imaging axes while the image frame diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>e </i>(wherein frames <b>652</b> and <b>654</b> are distorted) may correspond to a diverging axis three module reader <b>5</b>.</p>
<p id="p-0142" num="0141">Referring to the frame diagram of <figref idref="DRAWINGS">FIG. 4</figref><i>e </i>in further detail, overlapping regions <b>659</b> and <b>661</b> are defined between first frame <b>652</b> and third frame <b>656</b> and between third frame <b>656</b> and second frame <b>654</b>. When combining two frames of image data in the example of <figref idref="DRAWINGS">FIG. 4</figref><i>e</i>, it is particularly important to correct for skew errors (sometimes referred to as distortion errors) when combining frames of image data and when calculating regions of overlap between two frames of image data. In the example of <figref idref="DRAWINGS">FIG. 4</figref><i>e</i>, skew errors can readily be corrected for by, in part, utilizing a skew correction factor determined from the known relative angles between two imaging axes of a multiple module reader such axes <b>11</b><i>a </i>and <b>11</b><i>b </i>of reader <b>5</b>-<b>1</b>, and the spacing between modules of a multiple module reader such as reader <b>5</b>-<b>1</b>. Further skew correction of a frame of image data can be carried out in a manner described in copending application Ser. No. 09/954,081, filed Sep. 17, 2001, entitled &#x201c;Imaging Device Having Indicia-Controlled Image Parsing Mode,&#x201d; (now U.S. Pat. No. 6,561,428) which is hereby incorporated herein by reference in its entirety. In that application, a method is described wherein graphical analysis and interpolation processing are employed to determine a distortion factor affecting a frame of image data, and further wherein the determined distortion factor is utilized to back out distortion from an image.</p>
<p id="p-0143" num="0142">Still further, graphical feature analysis can be utilized in combining frames of image data. If a common graphical feature (e.g. a straight line, a bullseye, a circle, a character) is found in two frames of image data, the common graphical feature can be utilized to establish a common orientation, spacing, and skew basis between the frames of image data to be combined.</p>
<p id="p-0144" num="0143"><figref idref="DRAWINGS">FIG. 4</figref><i>f </i>is a flow diagram <b>400</b> that illustrates one embodiment of a data acquisition and decoding process of the invention. The process begins at the &#x201c;start&#x201d; oval <b>402</b>. The process involves obtaining a frame of image data, as indicated by box <b>404</b>. The correct decode algorithm for decoding the frame of image data is identified in response to the format of the frame of image data, as indicated at box <b>406</b>. The format information used to determine the correct decode algorithm can be any information representing a frame size, information identifying a frame format, information identifying a word size, and information identifying a source of said frame. The process, which in one embodiment comprises computer instructions operating on the microprocessor-based decoder module, determines whether the correct decode algorithm is active, as indicated by decision diamond <b>408</b>. If the correct decode algorithm is active, decoding proceeds as indicated at box <b>412</b>. However, if the correct decode algorithm is not active, the process follows the &#x201c;no&#x201d; arrow from decision diamond <b>408</b> to box <b>410</b>, which represents making the correct decode algorithm active. In one embodiment, the decode algorithm is embodied in a module (e.g., a dynamically linked library module, or .dll module). If the necessary .dll module is not loaded into memory, the .dll can be invoked, loaded, and linked thereby providing the necessary decoding module. Once the correct decode module is operational, the decoding step of box <b>412</b> is performed. The process ends at oval <b>414</b>, labeled &#x201c;end.&#x201d;</p>
<p id="p-0145" num="0144">In an alternative decoding process, depicted in <figref idref="DRAWINGS">FIG. 4</figref><i>g</i>, the same process steps are performed in an alternative sequence. As indicated in the flow diagram <b>420</b> of <figref idref="DRAWINGS">FIG. 4</figref><i>g</i>, the process starts at the oval <b>402</b> labeled &#x201c;start.&#x201d; The correct decode algorithm for decoding the frame of image data is identified in response to the format of the frame of image data, as indicated at box <b>406</b>. The format information used to determine the correct decode algorithm can be any information representing a frame size, information identifying a frame format, information identifying a word size, and information identifying a source of said frame. The process, which in the alternative embodiment comprises computer instructions operating on the microprocessor-based decoder module, determines whether the correct decode algorithm is active, as indicated by decision diamond <b>408</b>. If the correct decode algorithm is not active, the process follows the &#x201c;no&#x201d; arrow from decision diamond <b>408</b> to box <b>410</b>, which represents making the correct decode algorithm active. In one embodiment, the decode algorithm is embodied in a module (e.g., a .dll module). If the necessary .dll module is not loaded into memory, the .dll can be invoked, loaded, and linked, thereby providing the necessary decoding module. Once the correct decode algorithm is active, the frame of image data to be decoded is obtained as indicated at box <b>404</b>, and the decoding process is performed as indicated by box <b>412</b>. The process is completed as indicated at the oval <b>414</b> labeled &#x201c;end.&#x201d;</p>
<p id="p-0146" num="0145"><figref idref="DRAWINGS">FIG. 4</figref><i>h </i>is an exemplary flow diagram <b>430</b> illustrating an example of identification of an imaging module according to the invention. The identification process starts at the oval <b>432</b> labeled &#x201c;start.&#x201d; A parameter is selected for use in identification of an imaging module, as indicated at box <b>434</b>. The parameter is information that comprises at least one of a bus address of the module, an ID code of the module, a model identifier of the module, and an electrical characteristic of the module, such as a characteristic resistance. The process of identifying the imaging module, or sensor, involves polling the sensor to recover a responsive signal, as indicated at box <b>436</b>. As indicated at decision diamond <b>438</b>, the response is compared with the selected parameter, to determine if the correct parameter has been received. If the correct response is observed, as indicated by the arrow marked &#x201c;yes,&#x201d; the sensor is identified as indicated at box <b>442</b>. However, if an incorrect response is observed, as indicated by the arrow labeled &#x201c;no,&#x201d; the process continues with the selection of a new parameter, as indicated at box <b>440</b>. The sensor polled again, at box <b>436</b>, and the response is tested at diamond <b>438</b>. The steps of selecting a parameter, polling the sensor, and checking whether the correct response is obtained can be iterated until the sensor is identified.</p>
<p id="p-0147" num="0146"><figref idref="DRAWINGS">FIG. 4</figref><i>i </i>is an exemplary flow diagram <b>450</b> illustrating an example of locating a selected imaging module according to the invention. The imaging module location process is designed to identify a particular imaging module out of a plurality of imaging modules. The process starts at oval <b>452</b> labeled &#x201c;start.&#x201d; A parameter is selected for use in identification of an imaging module, as indicated at box <b>454</b>. The parameter is information that comprises at least one of a bus address of the module, an ID code of the module, a model identifier of the module, and an electrical characteristic of the module, such as a characteristic resistance. A first sensor or imaging module is polled, as indicated at box <b>456</b>. The response from the sensor is evaluated at decision diamond <b>458</b>. If the response indicates that the sensor that was polled is not the desired sensor, as indicated by the &#x201c;no&#x201d; arrow exiting the diamond <b>458</b>, another sensor is polled with the same parameter, as indicated by box <b>460</b>. A negative response to the polling can be a response that is not the desired or expected response, or the absence of a response after a suitable time period has elapsed.</p>
<p id="p-0148" num="0147">In the circumstance where a negative response is observed, the cycle of polling another sensor and evaluating the response can be repeated, or iterated, as many times as desired, and in any event as many times as there are sensors to be polled. If the response from some sensor is the expected, or appropriate, response, the sensor is deemed to have been located, as indicated at box <b>462</b>. The identification system can optionally retest the presumed known sensor, if high assurance of the correct identification is desired, as indicated at diamond <b>464</b>. If the identification is deemed acceptable, the process proceeds to oval <b>474</b>, marked &#x201c;end.&#x201d;</p>
<p id="p-0149" num="0148">If a higher level of confidence is desired, the process can select another parameter that is expected to be valid for the identified sensor, as indicated at box <b>466</b>. The presumed known sensor is polled, as indicated at box <b>468</b>. The response is tested, as indicated at diamond <b>470</b>. If the response is appropriate, as indicated by the arrow marked &#x201c;yes,&#x201d; the identity of the sensor is confirmed (e.g., the desired sensor is found with high confidence), and the process ends at the oval <b>474</b>. However, if the second polling response is not correct, the system halts and indicates an error condition, as indicated at box <b>472</b>.</p>
<p id="p-0150" num="0149"><figref idref="DRAWINGS">FIG. 6</figref><i>a </i>is a schematic diagram <b>600</b> illustrating an exemplary means and method of connecting a plurality of imaging modules to a microprocessor-based decoder module of the invention using a multiplexer (&#x201c;mux&#x201d;) <b>610</b>. In some embodiments, the mux <b>610</b> can be operated under the control of a programmed microprocessor, such as the microprocessor <b>180</b> present on the microprocessor-based decoder module of the invention. In <figref idref="DRAWINGS">FIG. 6</figref><i>a </i>the decoder <b>180</b> has a single data line <b>625</b> connected to the mux <b>610</b>. The data line <b>625</b> can include as many bit lines as are needed for serial or parallel transmission of data from the mux <b>610</b> to the decoder <b>180</b>, and can further include as many signal lines as are required for communication of control signals between the decoder <b>180</b> and the mux <b>610</b>. In the illustrative embodiment, three sensors or imaging modules <b>630</b>, <b>640</b>, <b>650</b> are depicted. Each imaging module <b>630</b>, <b>640</b>, <b>650</b> has a respective connection line <b>632</b>, <b>642</b>, <b>652</b> connected to a respective input port of the mux <b>610</b>. Each connection line <b>632</b>, <b>642</b>, <b>652</b> includes all the data and control lines necessary to operate a sensor and to obtain a frame of image data therefrom. The decoder <b>180</b> can command the mux <b>610</b> via the connection <b>625</b> as to which of the sensors is to be selected, for example by reducing a resistance of a switch connecting the mux <b>610</b> to each line of the data and control lines connecting the mux <b>610</b> with the selected sensor. In this manner, the decoder <b>180</b> can select any imaging module of the available imaging modules <b>630</b>, <b>640</b>, <b>650</b> by issuing a suitable command to the mux <b>610</b>, which command may include instructions that are communicated to the selected sensor. Sensors <b>630</b>, <b>640</b> and <b>650</b> can include at least two types of imaging modules that provide image data having formats that are different from one another.</p>
<p id="p-0151" num="0150"><figref idref="DRAWINGS">FIG. 6</figref><i>b </i>is a schematic diagram <b>602</b> illustrating an exemplary means and methods of connecting a plurality of imaging modules to a microprocessor-based decoder module of the invention using manual connection by a user. Again, a decoder <b>180</b> is provided. The decoder <b>180</b> has at least two connection lines <b>622</b>, <b>624</b>. Each connection line <b>622</b>, <b>624</b> includes all the data and control lines necessary to operate a sensor and to obtain a frame of image data therefrom. As in <figref idref="DRAWINGS">FIG. 6</figref><i>a</i>, there are shown three sensors <b>630</b>, <b>640</b>, <b>650</b>, having respective connection lines <b>632</b>, <b>642</b>, <b>652</b>, which are initially unconnected to the decoder <b>180</b>. Each connection line <b>632</b>, <b>642</b>, <b>652</b> includes all the data and control lines necessary to operate a sensor and to obtain a frame of image data therefrom. The user can connect a selected sensor of sensors <b>630</b>, <b>640</b>, <b>650</b> to a first connection line of the decoder <b>180</b>, and can connect additional sensors selected from sensors <b>630</b>, <b>640</b> and <b>650</b> to the remaining connection line of decoder <b>180</b>. As those of ordinary skill will recognize, the decoder <b>180</b> can be provided with more than two connection lines, and there can be more than three sensors <b>630</b>, <b>640</b>, and <b>650</b>. Sensors <b>630</b>, <b>640</b> and <b>650</b> can include at least two types of imaging modules that provide image data having formats that are different from one another.</p>
<p id="p-0152" num="0151"><figref idref="DRAWINGS">FIG. 6</figref><i>c </i>is a schematic diagram <b>604</b> of an illustrative hardware connection of a microprocessor-based decoder module <b>180</b> of the invention with a plurality of imaging modules <b>630</b>, <b>640</b>, <b>650</b>, <b>660</b>, and the relations of code modules <b>672</b>, <b>674</b>, <b>676</b> operating on the microprocessor <b>180</b>, according to principles of the invention. In <figref idref="DRAWINGS">FIG. 6</figref><i>c </i>there are four sensors, including sensors <b>630</b>, <b>640</b>, <b>650</b> and <b>660</b>. The sensors are connected to the microprocessor-based decoder module via the mux <b>610</b> as described above. In an illustrative example of operation of the decoder <b>180</b>, sensors <b>630</b>, <b>640</b>, <b>650</b> and <b>660</b> are all designed to provide frames of image data in formats that are mutually incompatible. The microprocessor-based decoder module <b>180</b> has resident in a memory thereof three dynamically linked library files (as .dll, .ocx or equivalent kinds of files), namely DLL<b>1</b> <b>672</b>, DLL<b>2</b> <b>674</b> and DLL<b>3</b> <b>676</b>. By way of illustration, DLL<b>1</b> <b>672</b> is a file that converts the input format of a frame of image data from one of the image modules, for example image module S<b>2</b> <b>640</b>, into a format that microprocessor-based decoder module <b>180</b> can decode. Similarly, DLL<b>2</b> <b>674</b> is available to convert the input format of a frame of image data from one of the image modules, for example image module S<b>3</b> <b>650</b>, into a format that microprocessor-based decoder module <b>180</b> can decode. Similarly as well, DLL<b>3</b> <b>676</b> coverts the input format of a frame of image data from a third module, for example S<b>1</b> <b>630</b>, into a format that microprocessor-based decoder module <b>180</b> can decode. In addition, in some embodiments, any of DLL<b>1</b> <b>672</b>, DLL<b>2</b> <b>674</b> and DLL<b>3</b> <b>676</b> can communicate with the corresponding sensor to transmit instructions thereto. In yet another embodiment, other .dlls are provided for communication of instructions from the microprocessor-based decoder module to selected sensors, and DLL<b>1</b> <b>672</b>, DLL<b>2</b> <b>674</b> and DLL<b>3</b> <b>676</b> are configured only to receive and convert information representing a frame of image data in a particular format or formats from a respective sensor, but not to communicate instructions to the sensor. In operation, if any of imaging modules <b>630</b>, <b>640</b> or <b>650</b> are used to obtain image data, there is no problem to manipulate that data into a suitable format for decoding by activating the appropriate one of DLL<b>3</b> <b>676</b>, DLL<b>1</b> <b>672</b> and DLL<b>2</b> <b>674</b>, respectively when the corresponding imaging module is operational. The DLL that is required can be activated by setting a pointer in memory, by setting up the appropriate call, or by the use of an equivalent redirectable software command that can direct program flow to the necessary software module as needed. In the circumstance where imaging module S<b>4</b> <b>660</b> is activated, an additional DLL file, which has been prepared to convert frames of image data from the format provided by imaging module S<b>4</b> <b>660</b> to a format that microprocessor-based decoder module <b>180</b> can decode, is read into an available section of memory, and the core program running on the microprocessor is redirected to use the newly installed DLL. More information on the installation of DLLs (e.g., .dll or .ocx files) and redirection of program flow is discussed in conjunction with <figref idref="DRAWINGS">FIG. 6</figref><i>d</i>.</p>
<p id="p-0153" num="0152"><figref idref="DRAWINGS">FIG. 6</figref><i>d </i>is a schematic diagram <b>606</b> of an illustrative memory map <b>680</b> showing the relationships between and among computer code modules present and operating in a microprocessor-based decoder module according to principles of the invention. In <figref idref="DRAWINGS">FIG. 6</figref><i>d</i>, all memory locations are expressed in hexadecimal notation, as is common in the programming arts; however, as is well known, other representations of memory location can be used. In <figref idref="DRAWINGS">FIG. 6</figref><i>d</i>, the core program or &#x201c;kernel&#x201d; <b>682</b> is depicted as being present from memory location x<b>0000</b> to memory location xA<b>0</b>B<b>9</b>. Pointers <b>684</b> are located from the memory location immediately following the kernel <b>682</b>, e.g., xAOBA, to memory location xABFF. DLL<b>1</b> <b>672</b> resides in memory locations xAC<b>00</b>-xACD<b>7</b>. DLL<b>2</b> <b>674</b> resides in memory locations xACD<b>8</b>-xADAD. DLL<b>3</b> <b>676</b> resides in memory locations xADAE-xBDF<b>2</b>. Memory from xBDF<b>3</b> and higher is available for computation memory (e.g., scratch memory <b>685</b>) and other uses. By way of illustration, when a frame of image data from sensor <b>660</b> is to be manipulated, a new DLL, e.g., DLL<b>4</b> <b>686</b>, needs to be made available. In this exemplary description, if the memory region from xBDF<b>3</b> to xCEB<b>1</b> is used for holding data or computational results, DLL<b>4</b> <b>686</b> can be loaded into memory in the memory area extending from xCEB<b>2</b> to xCEF<b>4</b> <b>688</b> that is large enough to accommodate DLL<b>4</b> <b>686</b>. A pointer in the pointer section <b>684</b> of memory <b>680</b> can be loaded with the location xCEB<b>2</b> as the entry location for DLL<b>4</b> <b>686</b> when the core program needs to invoke DLL<b>4</b>. The remaining section <b>690</b> of memory <b>680</b>, from xCEF<b>5</b> to xFFFF, is available as for the use of the core program as needed. While the example described herein has been described for simplicity of exposition as an example for a memory of only 2<sup>16 </sup>bits, or 64K, those of ordinary skill will recognize that the use of memory of any convenient size is contemplated. Furthermore, while the present example describes the loading of a DLL into memory, those of ordinary skill will recognize that any convenient means of invoking the DLL, including the use of media such as non-volatile memory (e.g., hard or floppy disks, CR-ROM, ROMs, PROMs, EPROMs, EEPROMs, or other storage media) and even connections over networks such as LANs, WANs, and the Internet to allow the use of remotely stored DLL files, are all contemplated herein.</p>
<p id="p-0154" num="0153"><figref idref="DRAWINGS">FIG. 7</figref><i>a </i>is a drawing <b>700</b> that schematically illustrates some of the features of an exemplary imaging module <b>710</b> useful for practicing the invention. In the illustrative example, imaging module <b>710</b> include two memory locations ID <b>720</b> and I<sup>2</sup>C Address <b>730</b>. In the example shown, the memory location ID <b>720</b> is a nonvolatile memory that can be programmed to contain a unique identification symbol, such as a number or an alphanumeric string. The ID <b>720</b> location of imaging module <b>710</b> is connected to a bus <b>740</b>. The microprocessor-based decoder module <b>180</b> of the invention can interrogate ID <b>720</b> by way of the bus <b>740</b>. An exemplary command that can be issued includes a request to transmit the contents of the ID <b>720</b> memory location over the bus for the use of the microprocessor-based decoder module <b>180</b>. I<sup>2</sup>C Address <b>730</b> is a memory location that contains an address for the imaging module <b>710</b> on the bus <b>740</b>. Imaging module <b>710</b> responds when the address corresponding to the contents of I<sup>2</sup>C Address <b>730</b> is applied to the bus <b>740</b>, and does not respond when a different address is applied to the bus, according to the I<sup>2</sup>C protocol. The microprocessor-based decoder module <b>180</b> can issue any of several commands to obtain information about imaging module <b>710</b>, including requests to have imaging module <b>710</b> perform actions, to have imaging module <b>710</b> report the start and/or the completion of the requested action, and reporting the address in I<sup>2</sup>C Address <b>730</b> memory.</p>
<p id="p-0155" num="0154"><figref idref="DRAWINGS">FIG. 7</figref><i>b </i>depicts an alternative embodiment of an imaging sensor <b>710</b> that has a resistance <b>750</b> present therein. The resistance <b>750</b> is in communication with the bus <b>740</b> via a switching mechanism (not shown) to avoid having multiple imaging modules applying resistance to the bus. The microprocessor-based decoding module <b>180</b> can interrogate the resistance <b>750</b> by activating the switching mechanism. Resistance <b>750</b> is depicted as a group of resistances R<b>1</b> <b>752</b>, R<b>2</b> <b>754</b>, and R<b>3</b> <b>756</b> that are connected in parallel. In one embodiment, R<b>1</b> <b>752</b>, R<b>2</b> <b>754</b>, and R<b>3</b> <b>756</b> are precision resistors having fixed resistance relationships, such as R<b>1</b> is twice the resistance of R<b>2</b> and four times the resistance of R<b>3</b>. One can program the resistance seen between terminals <b>760</b> and <b>770</b> of imaging module <b>710</b> by cutting conductors so as to disconnect one or more of R<b>1</b>, R<b>2</b> and R<b>3</b>. For example, one can obtain values of 1&#xd7;R<b>3</b>, 2&#xd7;R<b>3</b> (by leaving only R<b>2</b> in the circuit) and 4&#xd7;R<b>3</b> (by leaving only R<b>1</b> in the circuit) as well as 4/3 R<b>3</b> (R<b>1</b> and R<b>2</b> in parallel), 2/3 R<b>3</b> (R<b>2</b> and R<b>3</b> in parallel), 4/5 R<b>3</b> (R<b>1</b> and R<b>3</b> in parallel), and 4/7 R<b>3</b> (all three resistors in parallel). The value of infinite resistance (all resistors disconnected) can also be used, but leaves as a possibility that no module <b>710</b> is connected at all. One can measure the resistance and determine which resistors were left in the circuit, thereby identifying a particular imaging module <b>710</b>.</p>
<p id="p-0156" num="0155">Referring to <figref idref="DRAWINGS">FIG. 8</figref><i>a</i>, which shows an illustrative flow diagram of an embodiment of an iterative decoding process <b>800</b>, a frame of image data <b>810</b> is provided to the microprocessor-based decoding module <b>820</b> upon which a suitable computer program <b>830</b> is running The microprocessor-based decoding module <b>820</b> is programmed to handle the data of the format provided, as explained above. In the illustrative flow diagram <b>800</b>, the frame of image data is a frame of image data from a 2D imaging module <b>10</b>, such as those of <figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>i</i>. The microprocessor-based decoding module <b>820</b> converts the 2D data <b>810</b> into a series of P 1D data segments <b>812</b>, where P is an integer greater than 1. Each of the P 1D data segments <b>812</b> is further converted into a transition location information sequence <b>814</b>. In an illustrative embodiment, the conversion of data from an N-bit format (for example, N=8) to a 1-bit format occurs according to a prescriptive rule, or algorithm. For example, one rule could be that data greater than 50% of full scale (e.g., greater than or equal to 128) is by definition translated to a &#x201c;1&#x201d; or &#x201c;on,&#x201d; and data less than 50% of full scale (e.g., less than or equal to 127) is by definition translated to &#x201c;0&#x201d; or &#x201c;off&#x201d; Other rules can equally well be implemented. The decoding is iterative in that at least the decoding at the lowest level (N-bit to 1-bit) is performed repeatedly for each segment of 1D data <b>812</b>. The decoding is recursive in that data of higher than 1D format requires a plurality of passes through the decoding algorithm, wherein at each pass each decoding level above the N-bit to 1-bit level invokes a decoding step one level below itself, which ultimately ends at the lowest N-bit to 1-bit decoding. Finally, decoded information <b>816</b> is provided as output by the decoding module <b>830</b>.</p>
<p id="p-0157" num="0156">In an alternative embodiment shown in schematic diagram <b>805</b> of <figref idref="DRAWINGS">FIG. 8</figref><i>b</i>, the same decoding process can be performed using hard wired logic in integrated circuit chips IC<b>1</b> <b>850</b> and IC<b>2</b> <b>860</b>. The integrated circuit chips can be FPGAs programmed to perform the required logic, or the integrated circuit chips can be ASICs. As in the embodiment of <figref idref="DRAWINGS">FIG. 8</figref><i>a</i>, a frame of image data <b>810</b> is provided by a 2D imaging module <b>10</b>, such as those of <figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>i</i>. IC<b>1</b> <b>850</b> performs the same conversion functions that are performed by the microprocessor-based decoding module <b>820</b> of <figref idref="DRAWINGS">FIG. 8</figref><i>a</i>, that is, IC<b>1</b> <b>850</b> converts the 2D data <b>810</b> into a series of P 1D data segments <b>812</b>, where P is an integer greater than 1. Each of the P 1D data segments <b>812</b> is further converted into a transition location information sequence <b>814</b>. In an illustrative embodiment, the conversion of data from an N-bit format (for example, N=8) to a 1-bit format occurs according to a prescriptive rule, or algorithm. The rule can be the same rule as given above with regard to the microprocessor-based decoder module. Finally, IC<b>2</b> <b>860</b> decodes the converted data <b>814</b> to obtain decoded information <b>816</b> as output. As will be apparent to those of skill in the programming arts, it is also possible to perform the decoding process using some functions that are described as being provided in a microprocessor-based system in conjunction with other functions provided in hard wired logic to accomplish the necessary end.</p>
<p id="p-0158" num="0157">As more powerful processors (e.g., faster processors or ones using more bits of data per operation) become available, it is possible that one or more of the decoding steps can be omitted. For example, with sufficient processing power, the necessity to convert 1D data segments having 8-bits of resolution to transition location information having only 1-bit of resolution may cease. The conversion of 8-bit data to one bit data in fact implies the loss of the majority of the information content of the 8-bit data. Therefore, with sufficient processing power (e.g., wider data width and/or shorter cycle time) it is possible, and in fact is advantageous, not to convert the 8-bit data to 1-bit data, but rather to provide improved performance (e.g., higher resolution, better color rendition, and/or higher confidence in a match). As yet more processing power becomes available, the conversion of 2D data to a sequence of 1D data segments may become unnecessary without causing an undue increase in the time to decode information encoded in decodable indicia.</p>
<p id="p-0159" num="0158"><figref idref="DRAWINGS">FIG. 9</figref><i>a </i>illustrates an embodiment of a microprocessor-based decoder module <b>920</b> in the form of a PC card. In another embodiment, the microprocessor-based decoder module <b>920</b> is provided in the form of a PCMCIA module. Other specific embodiments will be apparent to those of skill in the circuitry arts. Microprocessor-based decoder module <b>920</b> contains therein the microprocessor <b>910</b> which is illustrated in phantom as a region in the interior of module <b>920</b>. Module <b>920</b> has a plurality of electrical contacts <b>912</b> for demountable connection of the module <b>920</b> to a product that employs the module, such as a digital camera <b>960</b> as is shown in <figref idref="DRAWINGS">FIG. 9</figref><i>c </i>and that is described in greater detail below. The module <b>920</b> may receive power from the device in which it is demountably mounted, by way of two or more of the contacts <b>912</b>. Module <b>920</b> may be &#x201c;keyed&#x201d; or otherwise mechanically indexed to allow insertion into the device in which it is demountably mounted in only the correct orientation. As one form of keying or indexing, the contacts <b>912</b> may be disposed in a pattern that permits seating of the module <b>920</b> within the device, such as digital camera <b>960</b>, only in the proper orientation, e.g., the contacts may be asymmetrically disposed with regard to a mirror plane or rotation axis of the module <b>920</b>.</p>
<p id="p-0160" num="0159"><figref idref="DRAWINGS">FIG. 9</figref><i>b </i>illustrates an embodiment of a microprocessor-based decoder module <b>940</b> in the form of a circuit board. For simplicity of exposition, only the substrate <b>915</b> of the circuit board <b>940</b> is depicted, with a microprocessor-based decoder <b>910</b> mounted to a surface of the substrate. The electrical traces common to printed circuit boards are not depicted. However, as is well known in the circuitry arts, electrical traces on one or more surface are provided to connect the microprocessor-based decoder <b>910</b> to a connector <b>918</b>. The connector <b>918</b> is conveniently disposed on a peripheral edge of module <b>940</b>, for convenient demountable connection of module <b>940</b> to an imaging module <b>930</b>. The connector <b>918</b> can take any convenient form, such as a card edge connector comprising a plurality of plated metallic &#x201c;fingers,&#x201d; a &#x201c;D&#x201d; connector having a plurality of metal pins, or a plug connector. In one embodiment, the module <b>940</b> is connected to an imaging module <b>930</b> by a connector <b>932</b> that is the mate for connector <b>918</b>. In other embodiments, a multiple conductor cable <b>935</b> is used to connect module <b>940</b> with imaging module <b>930</b>. The cable <b>935</b> has at a first end thereof a first connector <b>933</b> that mates to connector <b>918</b> and at a second end thereof a connector <b>937</b> that is the mate to connector <b>932</b> of the imaging module <b>930</b>. In some embodiments, the connectors <b>918</b> and <b>932</b> are not mating connectors, and a cable such as cable <b>935</b> is required to accomplish the connection, the cable having two dissimilar connectors <b>933</b>, <b>937</b> that respectively mate to connectors <b>918</b> and <b>932</b>. Module <b>940</b> may include additional connections (not shown) for provision of power and to provide decoded information for the benefit of a user. Circuit board module <b>940</b> is adapted to be housed semi-permanently within a device such as hand held optical reader <b>980</b>, as shown and described in more detail below with regard to <figref idref="DRAWINGS">FIG. 9</figref><i>d. </i></p>
<p id="p-0161" num="0160"><figref idref="DRAWINGS">FIG. 9</figref><i>c </i>illustrates an embodiment of a digital camera <b>960</b> comprising the microprocessor-based decoder module <b>920</b>. The camera <b>960</b> comprise a body <b>961</b> that houses and supports a optical imaging device <b>966</b> which can be activated by a user-activated switch, such as button <b>964</b>. An entryway <b>962</b> is defined within the body <b>961</b> for insertion of the microprocessor-based decoder module <b>920</b> of <figref idref="DRAWINGS">FIG. 9</figref><i>a </i>into the camera <b>960</b>, as indicated by the phantom <b>968</b>. The camera <b>960</b> further comprises a power supply, such as a battery (not shown) and mating connectors (not shown) to power and electrically connect to module <b>920</b> when it is present within camera <b>960</b>.</p>
<p id="p-0162" num="0161"><figref idref="DRAWINGS">FIG. 9</figref><i>d </i>illustrates an embodiment of a hand-held optical reader <b>980</b> comprising the microprocessor-based decoder module <b>940</b>, which is shown in phantom. The module <b>940</b> may be connected to the reader <b>980</b>, as has been described in conjunction with <figref idref="DRAWINGS">FIGS. 1</figref><i>a</i>-<b>1</b><i>g </i>above. The optical reader <b>960</b> further comprises an imaging module <b>984</b> that is electrically connected to the module <b>940</b> by way of cable <b>986</b>. Cable <b>986</b> is similar to cable <b>935</b> described above. A switch <b>982</b> is provided for use by a user in activating optical reader <b>980</b> including its various components. Optical reader <b>980</b> may be powered by a battery (not shown) or may be powered by a remote power supply via a power cable (not shown), as may be convenient for the intended method of use of optical reader <b>980</b>. Optical reader <b>980</b> further comprises an output, which may be a display, an enunciator, or a means of recording results for later examination by a user. The output may be local to optical reader <b>980</b>, or may be remote from optical reader <b>980</b>. In embodiments where the output is remote, the output data may be transmitted via cable, via wireless or RF connection, via infrared or optical technology, by being recorded on a disk or other medium for later physical transfer, or by any other convenient means.</p>
<p id="p-0163" num="0162">Another embodiment of the invention involves providing speech capability to the microprocessor-based decoder module. In one embodiment, the module is capable of recognizing commands provided in spoken form, and is capable of providing a response to a user in conventional spoken language. In the examples that are presented herein, the language is English. It will be understood that any language can be implemented that is capable of being spoken by a user or understood by a user.</p>
<p id="p-0164" num="0163">Technology that can convert material presented in the form of a decodable indicium, such as a bar code, to vocalized information provides many advantageous opportunities, ranging from convenience, to permitting the &#x201c;hands-free&#x201d; operation of a process, to providing information to individuals who are poorly literate, illiterate, sight-impaired or otherwise have problems reading. In the case of a decodable indicium, which is expressed in a format that decodes into alphanumeric values, there is the possibility of enunciating the result in whatever language would benefit the user. In principle, the same symbol, such as a barcode, can be vocally expressed in any language of choice. For example, a bar code on a package of food could be read, and the symbol could be used to enunciate the contents, the weight or volume, the price and other relevant information in a language selected by the user. Alternatively, a symbol could be encoded with information such as text, so as to compress the space required to convey a quantity of information compared to the space required to print the information in a format readable directly by the user. In some embodiments, the conversion of the textual content into an encoded symbol also renders the textual information more secure or less readily available to individuals who are not authorized to access the information.</p>
<p id="p-0165" num="0164">One embodiment involves the decoding of a symbol such as a barcode into text, and the conversion of the text into audible speech. Examples of systems that can perform such data manipulation include a reader/decoder for the bar code, in conjunction with text to speech capability. Examples of applications for such technology include a spoken response to a user of a reader for encoded indicia such as the indication that the symbol was correctly read; vocalization of identification information, such as material read from a document such as a license, a ticket, an identification badge or tag, or other printed material, for such purposes as indicating permission for entry to a theater, sporting event or the like, enunciation of permission to engage in an activity having an age requirement (e.g., drinking alcoholic beverages or buying tobacco), law enforcement purposes, enunciation of a security access authorization, or enunciation of information (e.g., instructions or the like) printed in the form of a decodable indicium. The technology can be applied in various settings, such as in a retail setting, in a warehouse, factory, or assembly and/or repair facility, and in settings involving visually handicapped individuals or individuals with poor literacy skills.</p>
<p id="p-0166" num="0165">Turning to <figref idref="DRAWINGS">FIG. 10</figref><i>a</i>, in a first embodiment, the microprocessor-based decoder module <b>180</b> includes an audio output module <b>1010</b>. An output terminal or port of the microprocessor-based decoder module <b>180</b> is connected to an input terminal or port of the audio output module <b>1010</b>. The audio output module <b>1010</b> can be powered by way of the output terminal of the microprocessor-based decoder module <b>180</b>, or it can be powered by an auxiliary conventional source of power (not shown) such as a power supply using a battery or a mains-connected power supply. In an exemplary embodiment, the audio output module <b>1010</b> comprises an audio codec (e.g., audio coder/decoder) <b>1012</b> connected to an output channel of the microprocessor-based decoder module <b>180</b>, a D/A converter <b>1014</b> having an input terminal connected to an output terminal of the audio codec <b>1012</b>, an audio amplifier <b>1016</b> having an input terminal connected to an output terminal of the D/A converter <b>1014</b>, and a speaker <b>1018</b> connected to an output terminal of the audio amplifier <b>1016</b>. The operation of the audio codec <b>1012</b>, the D/A converter <b>1014</b>, the audio amplifier <b>1016</b> and the speaker <b>1018</b> are all conventional and will not be described herein in detail. The microprocessor-based decoder module <b>180</b> can use as input to the audio output module <b>1010</b> a message recorded in a memory as digital information, such as a code corresponding to a prerecorded message stored in a memory in the audio output module <b>1010</b>, or as the digital message that the audio output module <b>1010</b> can decode. In other embodiments, the message is recorded as a wav. file, or in another audio file format. The message can be a digitized version of a pre-recorded message spoken by a person. The microprocessor-based decoder module <b>180</b> provides a signal in response to a condition that it determines. The signal activates the audio output module <b>1010</b> to provide an aural response to a user. When the microprocessor-based decoder module <b>180</b> is configured to operate with audio output, audible spoken responses can be provided to a user in response to actions or conditions that the microprocessor-based decoder module <b>180</b> encounters. As a non-exhaustive set of exemplary audible responses, the microprocessor-based decoder module <b>180</b> can cause the audio output module <b>1010</b> to enunciate such messages as: &#x201c;Good read&#x201d; (or alternatively &#x201c;Read good&#x201d;) in response to an acceptable reading of a decodable indicium; &#x201c;No symbol found&#x201d; in response to the apparent lack of a readable symbol within the region examined by a reader; &#x201c;Image too dark&#x201d; or &#x201c;Image too light&#x201d; in response to aberrant illumination conditions, faulty symbols or a combination of both; &#x201c;Symbology is code 3 of 9,&#x201d; &#x201c;Symbology is Aztec,&#x201d; or any other recognized symbology format in response to a determination of a symbology format; and &#x201c;Download complete&#x201d; in response to the completion of a download, as well as other similar audible responses.</p>
<p id="p-0167" num="0166">In a second embodiment, shown in <figref idref="DRAWINGS">FIG. 10</figref><i>b</i>, the microprocessor-based decoder module <b>180</b> includes an audio input module <b>1020</b>. An input terminal or port of the microprocessor-based decoder module <b>180</b> is connected to an output terminal or port of the audio input module <b>1020</b>. The audio input module <b>1020</b> can be powered by way of the input terminal of the microprocessor-based decoder module <b>180</b>, or it can be powered by an auxiliary conventional source of power (not shown) such as a power supply using a battery or a mains-connected power supply. In an exemplary embodiment, the audio input module <b>1020</b> comprises an audio codec (e.g., audio coder/decoder) <b>1022</b> having an output terminal connected to an input channel of the microprocessor-based decoder module <b>180</b>, an A/D converter <b>1024</b> having an output terminal connected to an input terminal of the audio codec <b>1020</b>, an audio amplifier <b>1026</b> having an output terminal connected to an input terminal of the A/D converter <b>1024</b>, and a microphone <b>1028</b> having an output terminal connected to an input terminal of the audio amplifier <b>1026</b>. The operation of the audio codec <b>1022</b>, the A/D converter <b>1024</b>, the audio amplifier <b>1026</b> and the microphone <b>1028</b> are all conventional and will not be described herein in detail. The microprocessor-based decoder module <b>180</b> can use input from the audio input module <b>1020</b> to recognize a command by comparing the input signal to a message recorded in a memory as digital information, such as a digitized version of a pre-recorded message spoken by a person. In other embodiments, the microprocessor-based decoder module <b>180</b> uses conventional voice recognition software and or hardware, such as is used by other voice recognition systems. The microprocessor-based decoder module <b>180</b> causes the performance of a function in response to a command that it recognizes A user activates the microprocessor-based decoder module <b>180</b> by speaking a command. When the command is recognized by the microprocessor-based decoder module <b>180</b>, it controls an imaging module or an entire reader in response to the command. The signal activates the audio input module <b>1020</b> to provide an aural response to a user. When the microprocessor-based decoder module <b>180</b> is configured to operate with audio input, audible spoken command from a user can initiate actions or conditions that the microprocessor-based decoder module <b>180</b> carries out. As a non-exhaustive set of exemplary audible command that a user can give, and that the microprocessor-based decoder module <b>180</b> can respond to are such commands as: &#x201c;Scan&#x201d;, which causes a response comprising the initiation of the scanning of a decodable indicium; &#x201c;Trigger,&#x201d; which causes the same behavior as the mechanical depression of a trigger switch; &#x201c;Capture&#x201d; or &#x201c;Capture image,&#x201d; which causes the initiation of image capture; &#x201c;snap shot&#x201d;, which causes the initiation of a snapshot image capture; &#x201c;Menu,&#x201d; which activates a menu routine, and which can then be followed by further commands that cause the navigation of a logical sequence of menu commands; &#x201c;Sleep,&#x201d; which initiates a sleep cycle; &#x201c;Send image,&#x201d; which initiates the transfer of an image in memory to another piece of hardware; &#x201c;Decode,&#x201d; which initiates the decode cycle of an image analysis routine; as well as other similar commands.</p>
<p id="p-0168" num="0167">As will be apparent to those of ordinary skill in the decoder arts, a sequence of audible interactions between a user and a microprocessor-based decoder module <b>180</b> having both an audio input module <b>1020</b> and an audio output module <b>1010</b> can occur. As an exemplary interaction, the user can issue the commands &#x201c;Scan&#x201d; and &#x201c;Trigger.&#x201d; The microprocessor-based decoder module <b>180</b> might respond &#x201c;Good read.&#x201d; The user could then issue the command &#x201c;Capture image.&#x201d; The microprocessor-based decoder module <b>180</b> might then respond &#x201c;Symbology is . . . (UPC) . . . .&#x201d; The user could command &#x201c;Decode.&#x201d; Upon successful decoding of the image and enunciation of the result, if no further images need to be decoded, the user could issue the command &#x201c;Sleep.&#x201d; In such a manner, the user operates the microprocessor-based decoder module <b>180</b> and the imaging hardware connected to it without the need to touch or manipulate anything, simply by issuing voice commands and by receiving audible responses that inform the user of the status and outcome of actions the user has commanded, as well as notification of error conditions that arise or the like.</p>
<p id="p-0169" num="0168">Turning to <figref idref="DRAWINGS">FIG. 10</figref><i>c</i>, there are illustrated interconnections that exist among components of an illustrative system providing bar code to speech or bar code to text to speech functionality. In general a detector <b>1032</b> acquires an image of the encoded indicium, and provides the encoded information therein to a decoder <b>1034</b>. The decoder <b>1034</b> analyses the encoded information. Based at least in part on the analysis, the decoder <b>1034</b> can obtain text or other information from a local memory or from a remote memory, using such data interface and communication media <b>1036</b> as RF, infrared, computer or telephone networks, and/or hardwire connections. The decoder <b>1034</b> communicates the information to be enunciated by way of serial or parallel communication channels, such as a bus, to a text to speech converter <b>1038</b>, which drives a speaker <b>1039</b>, thereby enunciating the information as audible speech.</p>
<p id="p-0170" num="0169"><figref idref="DRAWINGS">FIGS. 10</figref><i>d</i>-<b>10</b><i>f </i>illustrate flow diagrams that show methods of speech enunciation that embody the invention. In <figref idref="DRAWINGS">FIG. 10</figref><i>d</i>, the detector <b>1032</b> acquires a bar code or other decodable indicium, as indicated in box <b>1042</b>. The decoder <b>1034</b> decodes the information, as indicated by box <b>1044</b>. In one embodiment, based at least in part on the content of the decoded information, a decision is made as to whether a spoken message is to be provided, as indicated at diamond <b>1046</b>. If a spoken message is required, the message is expressed is indicated by box <b>1048</b>. However, if no spoken message is required, the action taken at box <b>1048</b> is suppressed, as indicated by the arrow that bypasses box <b>1048</b>. The determination whether the information will be enunciated as speech can be based in part of the content of the information as compared to a test criterion. The test criterion can be the presence or absence of a particular string or symbol in the decoded information, the presence or absence of a decodable symbol of a particular symbology type (e.g., UPC) or the presence or absence of a particular type of information (e.g., a menu, an instruction, or the like), the source of the information (e.g., speak so as to convey the bar code, or so as to convey information provided as an alternative input, such as the current price, whether and how many of an item are in stock, colors, sizes, or other features of the item, and the like), and criteria such as speak everything (e.g., &#x201c;chatterbox&#x201d;), or speak nothing (e.g., silence). After the decision whether or not to provide spoken information is decided and acted upon, the system can perform other tasks, such as determining whether data should be presented in another format (e.g., printed, recorded, and so forth) at decision diamond <b>1047</b>, and the system then acts on the decision at box <b>1047</b>.</p>
<p id="p-0171" num="0170">In <figref idref="DRAWINGS">FIG. 10</figref><i>e </i>a system loops until data is obtained (e.g., idle <b>1050</b>, followed by data input test diamond <b>1052</b> and return arrow if the test returns negative). Once data is available, a test for a spoken response occurs (e.g., diamond <b>1046</b>). If a spoken message is required, the message is expressed is indicated by box <b>1048</b>. However, if no spoken message is required, the action taken at box <b>1048</b> is suppressed, as indicated by the arrow that bypasses box <b>1048</b>. The criteria for making the decision are described above with regard to <figref idref="DRAWINGS">FIG. 10</figref><i>d</i>. Thereafter, another function can be tested, as indicated at diamond <b>1058</b>, and can be performed at indicated at box <b>1059</b>, or can be bypassed as indicated by the arrow that bypasses box <b>1059</b>, depending on the outcome of the test. The order of the spoken response and the other function can be interchanged as needed, which would be represented by a flow diagram similar to <figref idref="DRAWINGS">FIG. 10</figref><i>e</i>, in which the sequence of diamond <b>1058</b>, box <b>1059</b> and the corresponding bypassing arrow are positioned after the input loop and before diamond <b>1046</b> and box <b>1048</b>.</p>
<p id="p-0172" num="0171"><figref idref="DRAWINGS">FIG. 10</figref><i>f </i>depicts a flow diagram that illustrates yet another method of the invention, in which the detector <b>1032</b> observes a decodable indicium, as indicated in the box <b>1060</b> labeled &#x201c;acquire bar code.&#x201d; The decoder <b>1034</b> decodes the bar code, as indicated schematically in the box <b>1062</b> labeled &#x201c;decode.&#x201d; Based on the content of the decoded information, or on a type of bar code, or in response to another feature of the decoded information, the decoder requests information by communicating by way of data interface and communication media <b>1036</b>, as indicated in box <b>1064</b> labeled &#x201c;request information.&#x201d; The decoder <b>1034</b> receives a response as indicated by box <b>1066</b> labeled &#x201c;receive feedback.&#x201d; The system determines at diamond <b>1046</b> labeled &#x201c;speech?&#x201d; whether a spoken communication is required. If a spoken message is required, the message is expressed is indicated by box <b>1048</b>. However, if no spoken message is required, the action taken at box <b>1048</b> is suppressed, as indicated by the arrow that bypasses box <b>1048</b>. The criteria for making the decision are described above with regard to <figref idref="DRAWINGS">FIG. 10</figref><i>d. </i></p>
<p id="p-0173" num="0172">Those of ordinary skill will recognize that many functions of electrical and electronic apparatus can be implemented in hardware (for example, hard-wired logic), in software (for example, logic encoded in a program operating on a general purpose processor), and in firmware (for example, logic encoded in a non-volatile memory that is invoked for operation on a processor as required). The present invention contemplates the substitution of one implementation of hardware, firmware and software for another implementation of the equivalent functionality using a different one of hardware, firmware and software. To the extent that an implementation can be represented mathematically by a transfer function, that is, a specified response is generated at an output terminal for a specific excitation applied to an input terminal of a &#x201c;black box&#x201d; exhibiting the transfer function, any implementation of the transfer function, including any combination of hardware, firmware and software implementations of portions or segments of the transfer function, is contemplated herein.</p>
<p id="p-0174" num="0173">While the present invention has been explained with reference to the structure disclosed herein, it is not confined to the details set forth and this invention is intended to cover any modifications and changes as may come within the scope of the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>We claim: </us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer readable medium storing instructions for performance of a method executable by processor for use in decoding information, the method comprising (a) recognizing a format of a received frame of image data, the received frame of image data being received from a source, wherein the recognizing includes determining an ID value for the source; and (b) activating a certain decode algorithm for processing an image data frame received from the source, the processing being a processing for decoding a decodable indicia that can be represented in the image data frame, the activating being responsive to a result of the recognizing.</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the recognizing includes determining a parameter associated with the frame of image data.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The computer readable medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the parameter is frame size.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The computer readable medium of column <b>1</b>, wherein the recognizing includes determining the source of the frame of image data and wherein the recognizing includes determining a parameter associated with the frame of image data.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image data frame is the frame of image data.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A computer readable medium storing instructions for performance of a method executable by processor for use in decoding information, the method comprising (a) determining a source of a frame of image data, wherein the determining includes determining an ID value of the source; and (b) activating a certain decode algorithm for processing an image data frame received from the source, the processing being a processing for decoding decodable indicia that can be represented in the image data frame, the activating being responsive to a result of the determining.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer readable medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the determining includes polling the source.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer readable medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the activating includes loading the certain decoding algorithm into memory.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer readable medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the image data frame is the frame of image data.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer readable medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the activating includes loading the certain decoding algorithm into memory.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A method for use in decoding information, the method including:
<claim-text>(a) determining utilizing a processor source of a frame of image data, wherein the determining includes determining an ID value of the source; and</claim-text>
<claim-text>(b) activating a certain decode algorithm for processing utilizing the processor an image data frame received from the source, the processing being a processing for decoding a decodable indicia that can be represented in the image data frame, the activating being responsive to a result of the determining.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the processor is provided by a microprocessor based decoder module.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the source is an imaging module.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the image data frame is the frame of image data.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the activating includes loading the certain decoding algorithm into memory.</claim-text>
</claim>
</claims>
</us-patent-grant>
