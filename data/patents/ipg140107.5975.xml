<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627091-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627091</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13413232</doc-number>
<date>20120306</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>9</main-group>
<subgroup>32</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>9</main-group>
<subgroup>08</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20110101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>21</main-group>
<subgroup>8358</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>9</main-group>
<subgroup>3281</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>21</main-group>
<subgroup>8358</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>9</main-group>
<subgroup>08</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>9</main-group>
<subgroup>0883</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<classification-national>
<country>US</country>
<main-classification>713176</main-classification>
<further-classification>380278</further-classification>
<further-classification>380279</further-classification>
</classification-national>
<invention-title id="d2e43">Generating a secure signature utilizing a plurality of key shares</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4092732</doc-number>
<kind>A</kind>
<name>Ouchi</name>
<date>19780500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5263085</doc-number>
<kind>A</kind>
<name>Shamir</name>
<date>19931100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380 30</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5454101</doc-number>
<kind>A</kind>
<name>Mackay et al.</name>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5485474</doc-number>
<kind>A</kind>
<name>Rabin</name>
<date>19960100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5627893</doc-number>
<kind>A</kind>
<name>Demytko</name>
<date>19970500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380 30</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5774643</doc-number>
<kind>A</kind>
<name>Lubbers et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5802364</doc-number>
<kind>A</kind>
<name>Senator et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5809285</doc-number>
<kind>A</kind>
<name>Hilland</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5890156</doc-number>
<kind>A</kind>
<name>Rekieta et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5987622</doc-number>
<kind>A</kind>
<name>Lo Verso et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5991414</doc-number>
<kind>A</kind>
<name>Garay et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6012159</doc-number>
<kind>A</kind>
<name>Fischer et al.</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6058454</doc-number>
<kind>A</kind>
<name>Gerlach et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6088454</doc-number>
<kind>A</kind>
<name>Nagashima et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380286</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6128277</doc-number>
<kind>A</kind>
<name>Bruck et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6175571</doc-number>
<kind>B1</kind>
<name>Haddock et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6192472</doc-number>
<kind>B1</kind>
<name>Garay et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6256688</doc-number>
<kind>B1</kind>
<name>Suetaka et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6272658</doc-number>
<kind>B1</kind>
<name>Steele et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6301604</doc-number>
<kind>B1</kind>
<name>Nojima</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6356949</doc-number>
<kind>B1</kind>
<name>Katsandres et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6366995</doc-number>
<kind>B1</kind>
<name>Vilkov et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6374336</doc-number>
<kind>B1</kind>
<name>Peters et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>6415373</doc-number>
<kind>B1</kind>
<name>Peters et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>6418539</doc-number>
<kind>B1</kind>
<name>Walker</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>6449688</doc-number>
<kind>B1</kind>
<name>Peters et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>6550009</doc-number>
<kind>B1</kind>
<name>Uranaka et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>6567948</doc-number>
<kind>B2</kind>
<name>Steele et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>6571282</doc-number>
<kind>B1</kind>
<name>Bowman-Amuah</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>6609223</doc-number>
<kind>B1</kind>
<name>Wolfgang</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>6718361</doc-number>
<kind>B1</kind>
<name>Basani et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>6760808</doc-number>
<kind>B2</kind>
<name>Peters et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>6785768</doc-number>
<kind>B2</kind>
<name>Peters et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>6785783</doc-number>
<kind>B2</kind>
<name>Buckland</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>6826711</doc-number>
<kind>B2</kind>
<name>Moulton et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>6879596</doc-number>
<kind>B1</kind>
<name>Dooply</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>7003688</doc-number>
<kind>B1</kind>
<name>Pittelkow et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>7024451</doc-number>
<kind>B2</kind>
<name>Jorgenson</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>7024609</doc-number>
<kind>B2</kind>
<name>Wolfgang et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>7080101</doc-number>
<kind>B1</kind>
<name>Watson et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>7103824</doc-number>
<kind>B2</kind>
<name>Halford</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>7103915</doc-number>
<kind>B2</kind>
<name>Redlich et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>7111115</doc-number>
<kind>B2</kind>
<name>Peters et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>7140044</doc-number>
<kind>B2</kind>
<name>Redlich et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>7146644</doc-number>
<kind>B2</kind>
<name>Redlich et al.</name>
<date>20061200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>7171493</doc-number>
<kind>B2</kind>
<name>Shu et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>7222133</doc-number>
<kind>B1</kind>
<name>Raipurkar et al.</name>
<date>20070500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>7240236</doc-number>
<kind>B2</kind>
<name>Cutts et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>7272613</doc-number>
<kind>B2</kind>
<name>Sim et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>7636764</doc-number>
<kind>B1</kind>
<name>Fein et al.</name>
<date>20091200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709212</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>2001/0038696</doc-number>
<kind>A1</kind>
<name>Frankel et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380286</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>2002/0062422</doc-number>
<kind>A1</kind>
<name>Butterworth et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>2002/0141594</doc-number>
<kind>A1</kind>
<name>MacKenzie et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380286</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>2002/0166079</doc-number>
<kind>A1</kind>
<name>Ulrich et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>2003/0018927</doc-number>
<kind>A1</kind>
<name>Gadir et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>2003/0037261</doc-number>
<kind>A1</kind>
<name>Meffert et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>2003/0065617</doc-number>
<kind>A1</kind>
<name>Watkins et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00058">
<document-id>
<country>US</country>
<doc-number>2003/0084020</doc-number>
<kind>A1</kind>
<name>Shu</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00059">
<document-id>
<country>US</country>
<doc-number>2003/0120929</doc-number>
<kind>A1</kind>
<name>Hoffstein et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713176</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00060">
<document-id>
<country>US</country>
<doc-number>2003/0194086</doc-number>
<kind>A1</kind>
<name>Lambert</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380 44</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00061">
<document-id>
<country>US</country>
<doc-number>2004/0024963</doc-number>
<kind>A1</kind>
<name>Talagala et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00062">
<document-id>
<country>US</country>
<doc-number>2004/0122917</doc-number>
<kind>A1</kind>
<name>Menon et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00063">
<document-id>
<country>US</country>
<doc-number>2004/0215998</doc-number>
<kind>A1</kind>
<name>Buxton et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00064">
<document-id>
<country>US</country>
<doc-number>2004/0228493</doc-number>
<kind>A1</kind>
<name>Ma et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00065">
<document-id>
<country>US</country>
<doc-number>2005/0100022</doc-number>
<kind>A1</kind>
<name>Ramprashad</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00066">
<document-id>
<country>US</country>
<doc-number>2005/0114594</doc-number>
<kind>A1</kind>
<name>Corbett et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00067">
<document-id>
<country>US</country>
<doc-number>2005/0125593</doc-number>
<kind>A1</kind>
<name>Karpoff et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00068">
<document-id>
<country>US</country>
<doc-number>2005/0131993</doc-number>
<kind>A1</kind>
<name>Fatula, Jr.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00069">
<document-id>
<country>US</country>
<doc-number>2005/0132070</doc-number>
<kind>A1</kind>
<name>Redlich et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00070">
<document-id>
<country>US</country>
<doc-number>2005/0144382</doc-number>
<kind>A1</kind>
<name>Schmisseur</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00071">
<document-id>
<country>US</country>
<doc-number>2005/0195973</doc-number>
<kind>A1</kind>
<name>Ibrahim</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380 28</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00072">
<document-id>
<country>US</country>
<doc-number>2005/0229069</doc-number>
<kind>A1</kind>
<name>Hassner</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00073">
<document-id>
<country>US</country>
<doc-number>2006/0047907</doc-number>
<kind>A1</kind>
<name>Shiga et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00074">
<document-id>
<country>US</country>
<doc-number>2006/0136448</doc-number>
<kind>A1</kind>
<name>Cialini et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00075">
<document-id>
<country>US</country>
<doc-number>2006/0153364</doc-number>
<kind>A1</kind>
<name>Beeson</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380 30</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00076">
<document-id>
<country>US</country>
<doc-number>2006/0156059</doc-number>
<kind>A1</kind>
<name>Kitamura</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00077">
<document-id>
<country>US</country>
<doc-number>2006/0224603</doc-number>
<kind>A1</kind>
<name>Correll, Jr.</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00078">
<document-id>
<country>US</country>
<doc-number>2006/0236056</doc-number>
<kind>A1</kind>
<name>Nagata</name>
<date>20061000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711165</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00079">
<document-id>
<country>US</country>
<doc-number>2007/0079081</doc-number>
<kind>A1</kind>
<name>Gladwin et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00080">
<document-id>
<country>US</country>
<doc-number>2007/0079082</doc-number>
<kind>A1</kind>
<name>Gladwin et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00081">
<document-id>
<country>US</country>
<doc-number>2007/0079083</doc-number>
<kind>A1</kind>
<name>Gladwin et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00082">
<document-id>
<country>US</country>
<doc-number>2007/0088970</doc-number>
<kind>A1</kind>
<name>Buxton et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00083">
<document-id>
<country>US</country>
<doc-number>2007/0174192</doc-number>
<kind>A1</kind>
<name>Gladwin et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00084">
<document-id>
<country>US</country>
<doc-number>2007/0214285</doc-number>
<kind>A1</kind>
<name>Au et al.</name>
<date>20070900</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00085">
<document-id>
<country>US</country>
<doc-number>2007/0234110</doc-number>
<kind>A1</kind>
<name>Soran et al.</name>
<date>20071000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00086">
<document-id>
<country>US</country>
<doc-number>2007/0283167</doc-number>
<kind>A1</kind>
<name>Venters, III et al.</name>
<date>20071200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00087">
<document-id>
<country>US</country>
<doc-number>2009/0003663</doc-number>
<kind>A1</kind>
<name>Webster</name>
<date>20090100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382119</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00088">
<document-id>
<country>US</country>
<doc-number>2009/0094251</doc-number>
<kind>A1</kind>
<name>Gladwin et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00089">
<document-id>
<country>US</country>
<doc-number>2009/0094318</doc-number>
<kind>A1</kind>
<name>Gladwin et al.</name>
<date>20090400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00090">
<document-id>
<country>US</country>
<doc-number>2009/0200362</doc-number>
<kind>A1</kind>
<name>Jung et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>2281791</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00091">
<document-id>
<country>US</country>
<doc-number>2009/0265555</doc-number>
<kind>A1</kind>
<name>Royer</name>
<date>20091000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00092">
<document-id>
<country>US</country>
<doc-number>2010/0023524</doc-number>
<kind>A1</kind>
<name>Gladwin et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707 10</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00093">
<document-id>
<country>US</country>
<doc-number>2010/0037056</doc-number>
<kind>A1</kind>
<name>Follis et al.</name>
<date>20100200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713171</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00094">
<document-id>
<country>US</country>
<doc-number>2010/0131755</doc-number>
<kind>A1</kind>
<name>Zhu et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713155</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00095">
<document-id>
<country>US</country>
<doc-number>2010/0161817</doc-number>
<kind>A1</kind>
<name>Xiao et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709229</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00096">
<document-id>
<country>US</country>
<doc-number>2010/0180116</doc-number>
<kind>A1</kind>
<name>Coan et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00097">
<document-id>
<country>US</country>
<doc-number>2010/0235638</doc-number>
<kind>A1</kind>
<name>Irvine</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00098">
<document-id>
<country>US</country>
<doc-number>2010/0242101</doc-number>
<kind>A1</kind>
<name>Reese, Jr.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>726  6</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00099">
<document-id>
<country>US</country>
<doc-number>2010/0262837</doc-number>
<kind>A1</kind>
<name>Kulin</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713189</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00100">
<document-id>
<country>US</country>
<doc-number>2010/0266120</doc-number>
<kind>A1</kind>
<name>Leggette et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380 28</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00101">
<document-id>
<country>US</country>
<doc-number>2010/0266132</doc-number>
<kind>A1</kind>
<name>Bablani et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380286</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00102">
<document-id>
<country>US</country>
<doc-number>2010/0268966</doc-number>
<kind>A1</kind>
<name>Leggette et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713193</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00103">
<document-id>
<country>US</country>
<doc-number>2010/0269008</doc-number>
<kind>A1</kind>
<name>Leggette et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714752</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00104">
<document-id>
<country>US</country>
<doc-number>2010/0275026</doc-number>
<kind>A1</kind>
<name>McLean</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713176</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00105">
<document-id>
<country>US</country>
<doc-number>2011/0047380</doc-number>
<kind>A1</kind>
<name>Miller</name>
<date>20110200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00106">
<document-id>
<country>US</country>
<doc-number>2011/0055578</doc-number>
<kind>A1</kind>
<name>Resch</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713176</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00107">
<document-id>
<country>US</country>
<doc-number>2011/0208970</doc-number>
<kind>A1</kind>
<name>Brown et al.</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713176</main-classification></classification-national>
</us-citation>
<us-citation>
<nplcit num="00108">
<othercit>Shamir; How to Share a Secret; Communications of the ACM; vol. 22, No. 11; Nov. 1979; pp. 612-613.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00109">
<othercit>Rabin; Efficient Dispersal of Information for Security, Load Balancing, and Fault Tolerance; Journal of the Association for Computer Machinery; vol. 36, No. 2; Apr. 1989; pp. 335-348.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00110">
<othercit>Chung; An Automatic Data Segmentation Method for 3D Measured Data Points; National Taiwan University; pp. 1-8; 1998.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00111">
<othercit>Plank, T1: Erasure Codes for Storage Applications; FAST2005, 4th Usenix Conference on File Storage Technologies; Dec. 13-16, 2005; pp. 1-74.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00112">
<othercit>Wildi; Java iSCSi Initiator; Master Thesis; Department of Computer and Information Science, University of Konstanz; Feb. 2007; 60 pgs.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00113">
<othercit>Legg; Lightweight Directory Access Protocol (LDAP): Syntaxes and Matching Rules; IETF Network Working Group; RFC 4517; Jun. 2006; pp. 1-50.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00114">
<othercit>Zeilenga; Lightweight Directory Access Protocol (LDAP): Internationalized String Preparation; IETF Network Working Group; RFC 4518; Jun. 2006; pp. 1-14.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00115">
<othercit>Smith; Lightweight Directory Access Protocol (LDAP): Uniform Resource Locator; IETF Network Working Group; RFC 4516; Jun. 2006; pp. 1-15.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00116">
<othercit>Smith; Lightweight Directory Access Protocol (LDAP): String Representation of Search Filters; IETF Network Working Group; RFC 4515; Jun. 2006; pp. 1-12.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00117">
<othercit>Zeilenga; Lightweight Directory Access Protocol (LDAP): Directory Information Models; IETF Network Working Group; RFC 4512; Jun. 2006; pp. 1-49.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00118">
<othercit>Sciberras; Lightweight Directory Access Protocol (LDAP): Schema for User Applications; IETF Network Working Group; RFC 4519; Jun. 2006; pp. 1-33.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00119">
<othercit>Harrison; Lightweight Directory Access Protocol (LDAP): Authentication Methods and Security Mechanisms; IETF Network Working Group; RFC 4513; Jun. 2006; pp. 1-32.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00120">
<othercit>Zeilenga; Lightweight Directory Access Protocol (LDAP): Technical Specification Road Map; IETF Network Working Group; RFC 4510; Jun. 2006; pp. 1-8.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00121">
<othercit>Zeilenga; Lightweight Directory Access Protocol (LDAP): String Representation of Distinguished Names; IETF Network Working Group; RFC 4514; Jun. 2006; pp. 1-15.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00122">
<othercit>Sermersheim; Lightweight Directory Access Protocol (LDAP): The Protocol; IETF Network Working Group; RFC 4511; Jun. 2006; pp. 1-68.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00123">
<othercit>Satran, et al.; Internet Small Computer Systems Interface (iSCSI); IETF Network Working Group; RFC 3720; Apr. 2004; pp. 1-257.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00124">
<othercit>Xin, et al.; Evaluation of Distributed Recovery in Large-Scale Storage Systems; 13th IEEE International Symposium on High Performance Distributed Computing; Jun. 2004; pp. 172-181.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>14</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>30</number-of-drawing-sheets>
<number-of-figures>40</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>61470524</doc-number>
<date>20110401</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20120254619</doc-number>
<kind>A1</kind>
<date>20121004</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Dhuse</last-name>
<first-name>Greg</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Resch</last-name>
<first-name>Jason K.</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Leggette</last-name>
<first-name>Wesley</first-name>
<address>
<city>Oak Park</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Dhuse</last-name>
<first-name>Greg</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Resch</last-name>
<first-name>Jason K.</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Leggette</last-name>
<first-name>Wesley</first-name>
<address>
<city>Oak Park</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Garlick &#x26; Markison</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Markison</last-name>
<first-name>Timothy W.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Cleversafe, Inc.</orgname>
<role>02</role>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Nalven</last-name>
<first-name>Andrew L</first-name>
<department>2496</department>
</primary-examiner>
<assistant-examiner>
<last-name>Malinowski</last-name>
<first-name>Walter</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method begins by a module to generate a secure signature on an item by selecting a first key representation index of a set of key representation indexes, wherein a first mathematical encoding of a private key generates a first plurality of key shares as a first key representation. The method continues with the module determining whether a first plurality of signature contributions have been received in response to a signature request for the item based on the first key representation index, wherein one of a first set of dispersed storage (DS) units executes a first mathematical signature function using one of the first plurality of key shares on the item to produce a signature contribution of the first plurality of signature contributions and when the first plurality of signature contributions have been received, generating the secure signature on the item from the first plurality of signature contributions.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="183.90mm" wi="203.20mm" file="US08627091-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="239.01mm" wi="189.99mm" orientation="landscape" file="US08627091-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="228.77mm" wi="181.27mm" orientation="landscape" file="US08627091-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="246.13mm" wi="193.89mm" orientation="landscape" file="US08627091-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="246.97mm" wi="188.38mm" orientation="landscape" file="US08627091-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="249.34mm" wi="196.26mm" orientation="landscape" file="US08627091-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="224.79mm" wi="163.83mm" orientation="landscape" file="US08627091-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="207.35mm" wi="189.99mm" orientation="landscape" file="US08627091-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="104.48mm" wi="126.66mm" orientation="landscape" file="US08627091-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="210.57mm" wi="186.77mm" orientation="landscape" file="US08627091-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="214.46mm" wi="179.66mm" orientation="landscape" file="US08627091-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="250.11mm" wi="183.64mm" orientation="landscape" file="US08627091-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="223.18mm" wi="193.12mm" orientation="landscape" file="US08627091-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="220.81mm" wi="190.75mm" orientation="landscape" file="US08627091-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="215.31mm" wi="188.38mm" orientation="landscape" file="US08627091-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="139.28mm" wi="187.62mm" orientation="landscape" file="US08627091-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="119.55mm" wi="186.77mm" orientation="landscape" file="US08627091-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="222.42mm" wi="193.12mm" orientation="landscape" file="US08627091-20140107-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="251.71mm" wi="188.38mm" orientation="landscape" file="US08627091-20140107-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="208.20mm" wi="190.75mm" orientation="landscape" file="US08627091-20140107-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="205.82mm" wi="181.27mm" orientation="landscape" file="US08627091-20140107-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="250.11mm" wi="184.40mm" orientation="landscape" file="US08627091-20140107-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="203.45mm" wi="194.73mm" orientation="landscape" file="US08627091-20140107-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="255.69mm" wi="163.83mm" orientation="landscape" file="US08627091-20140107-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="142.49mm" wi="174.16mm" orientation="landscape" file="US08627091-20140107-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="252.48mm" wi="182.03mm" orientation="landscape" file="US08627091-20140107-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00026" num="00026">
<img id="EMI-D00026" he="108.46mm" wi="203.45mm" orientation="landscape" file="US08627091-20140107-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00027" num="00027">
<img id="EMI-D00027" he="213.70mm" wi="194.73mm" orientation="landscape" file="US08627091-20140107-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00028" num="00028">
<img id="EMI-D00028" he="216.07mm" wi="197.87mm" orientation="landscape" file="US08627091-20140107-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00029" num="00029">
<img id="EMI-D00029" he="250.11mm" wi="188.38mm" orientation="landscape" file="US08627091-20140107-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00030" num="00030">
<img id="EMI-D00030" he="204.98mm" wi="167.81mm" orientation="landscape" file="US08627091-20140107-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED PATENTS</heading>
<p id="p-0002" num="0001">The present U.S. Utility patent application claims priority pursuant to 35 U.S.C. &#xa7;119(e) to U.S. Provisional Application No. 61/470,524, entitled &#x201c;Encoding Data Stored in a Dispersed Storage Network,&#x201d; filed Apr. 1, 2011, pending, which is incorporated herein by reference in its entirety and made part of the present U.S. Utility patent application for all purposes.</p>
<heading id="h-0002" level="1">STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT</heading>
<p id="p-0003" num="0002">Not Applicable</p>
<heading id="h-0003" level="1">INCORPORATION-BY-REFERENCE OF MATERIAL SUBMITTED ON A COMPACT DISC</heading>
<p id="p-0004" num="0003">Not Applicable</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0004" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0005" num="0004">1. Technical Field of the Invention</p>
<p id="p-0006" num="0005">This invention relates generally to computing systems and more particularly to data storage solutions within such computing systems.</p>
<p id="p-0007" num="0006">2. Description of Related Art</p>
<p id="p-0008" num="0007">Computers are known to communicate, process, and store data. Such computers range from wireless smart phones to data centers that support millions of web searches, stock trades, or on-line purchases every day. In general, a computing system generates data and/or manipulates data from one form into another. For instance, an image sensor of the computing system generates raw picture data and, using an image compression program (e.g., JPEG, MPEG, etc.), the computing system manipulates the raw picture data into a standardized compressed image.</p>
<p id="p-0009" num="0008">With continued advances in processing speed and communication speed, computers are capable of processing real time multimedia data for applications ranging from simple voice communications to streaming high definition video. As such, general-purpose information appliances are replacing purpose-built communications devices (e.g., a telephone). For example, smart phones can support telephony communications but they are also capable of text messaging and accessing the Internet to perform functions including email, web browsing, remote applications access, and media communications (e.g., telephony voice, image transfer, music files, video files, real time video streaming, etc.).</p>
<p id="p-0010" num="0009">Each type of computer is constructed and operates in accordance with one or more communication, processing, and storage standards. As a result of standardization and with advances in technology, more and more information content is being converted into digital formats. For example, more digital cameras are now being sold than film cameras, thus producing more digital pictures. As another example, web-based programming is becoming an alternative to over the air television broadcasts and/or cable broadcasts. As further examples, papers, books, video entertainment, home video, etc. are now being stored digitally, which increases the demand on the storage function of computers.</p>
<p id="p-0011" num="0010">A typical computer storage system includes one or more memory devices aligned with the needs of the various operational aspects of the computer's processing and communication functions. Generally, the immediacy of access dictates what type of memory device is used. For example, random access memory (RAM) memory can be accessed in any random order with a constant response time, thus it is typically used for cache memory and main memory. By contrast, memory device technologies that require physical movement such as magnetic disks, tapes, and optical discs, have a variable response time as the physical movement can take longer than the data transfer, thus they are typically used for secondary memory (e.g., hard drive, backup memory, etc.).</p>
<p id="p-0012" num="0011">A computer's storage system will be compliant with one or more computer storage standards that include, but are not limited to, network file system (NFS), flash file system (FFS), disk file system (DFS), small computer system interface (SCSI), internet small computer system interface (iSCSI), file transfer protocol (FTP), and web-based distributed authoring and versioning (WebDAV). These standards specify the data storage format (e.g., files, data objects, data blocks, directories, etc.) and interfacing between the computer's processing function and its storage system, which is a primary function of the computer's memory controller.</p>
<p id="p-0013" num="0012">Despite the standardization of the computer and its storage system, memory devices fail; especially commercial grade memory devices that utilize technologies incorporating physical movement (e.g., a disc drive). For example, it is fairly common for a disc drive to routinely suffer from bit level corruption and to completely fail after three years of use. One solution is to a higher-grade disc drive, which adds significant cost to a computer.</p>
<p id="p-0014" num="0013">Another solution is to utilize multiple levels of redundant disc drives to replicate the data into two or more copies. One such redundant drive approach is called redundant array of independent discs (RAID). In a RAID device, a RAID controller adds parity data to the original data before storing it across the array. The parity data is calculated from the original data such that the failure of a disc will not result in the loss of the original data. For example, RAID 5 uses three discs to protect data from the failure of a single disc. The parity data, and associated redundancy overhead data, reduces the storage capacity of three independent discs by one third (e.g., n&#x2212;1=capacity). RAID 6 can recover from a loss of two discs and requires a minimum of four discs with a storage capacity of n&#x2212;2.</p>
<p id="p-0015" num="0014">While RAID addresses the memory device failure issue, it is not without its own failures issues that affect its effectiveness, efficiency and security. For instance, as more discs are added to the array, the probability of a disc failure increases, which increases the demand for maintenance. For example, when a disc fails, it needs to be manually replaced before another disc fails and the data stored in the RAID device is lost. To reduce the risk of data loss, data on a RAID device is typically copied on to one or more other RAID devices. While this addresses the loss of data issue, it raises a security issue since multiple copies of data are available, which increases the chances of unauthorized access. Further, as the amount of data being stored grows, the overhead of RAID devices becomes a non-trivial efficiency issue.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWING(S)</heading>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic block diagram of an embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic block diagram of an embodiment of a computing core in accordance with the present invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic block diagram of an embodiment of a distributed storage processing unit in accordance with the present invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic block diagram of an embodiment of a grid module in accordance with the present invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram of an example embodiment of error coded data slice creation in accordance with the present invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6A</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6B</figref> is a flowchart illustrating an example of storing key shares in accordance with the present invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6C</figref> is a diagram illustrating an example of a key share storage table in accordance with the present invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 6D</figref> is a flowchart illustrating an example of generating a signature in accordance with the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 6E</figref> is a flowchart illustrating an example of generating a signature contribution in accordance with the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart illustrating another example of generating a signature contribution in accordance with the present invention;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart illustrating an example of replicating encoded data slices in accordance with the present invention;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 9A</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 9B</figref> is a timing diagram illustrating an example of pre-fetching a data segment in accordance with the present invention;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 9C</figref> is a flowchart illustrating an example of pre-fetching a data segment in accordance with the present invention;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 10A</figref> is a diagram illustrating an example of encoding data in accordance with the present invention;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 10B</figref> is a flowchart illustrating an example of encoding data in accordance with the present invention;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 10C</figref> is a flowchart illustrating an example of decoding data in accordance with the present invention;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 11A</figref> is a diagram illustrating an example of appending data in accordance with the present invention;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 11B</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 11C</figref> is a flowchart illustrating an example of appending data in accordance with the present invention;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 11D</figref> is a flowchart illustrating an example of appending slice portions in accordance with the present invention;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 12A</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 12B</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 12C</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 12D</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 12E</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 13A</figref> is a flowchart illustrating an example of rebuilding a Shamir secret share in accordance with the present invention;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 13B</figref> is a flowchart illustrating an example of generating a rebuilt share partial in accordance with the present invention;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 14A</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 14B</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 14C</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 14D</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 15A</figref> is a schematic block diagram of an embodiment of a dispersed storage system in accordance with the present invention;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 15B</figref> is a schematic block diagram of another embodiment of a computing system in accordance with the present invention;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 15C</figref> is a flowchart illustrating an example of updating error recovery information in accordance with the present invention;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 16</figref> is a diagram illustrating an example of a directory file structure in accordance with the present invention;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 17</figref> is a flowchart illustrating an example of deleting a snapshot in accordance with the present invention;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 18</figref> is a diagram illustrating another example of a directory file structure in accordance with the present invention; and</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 19</figref> is a flowchart illustrating another example of deleting a snapshot in accordance with the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic block diagram of a computing system <b>10</b> that includes one or more of a first type of user devices <b>12</b>, one or more of a second type of user devices <b>14</b>, at least one distributed storage (DS) processing unit <b>16</b>, at least one DS managing unit <b>18</b>, at least one storage integrity processing unit <b>20</b>, and a distributed storage network (DSN) memory <b>22</b> coupled via a network <b>24</b>. The network <b>24</b> may include one or more wireless and/or wire lined communication systems; one or more private intranet systems and/or public internet systems; and/or one or more local area networks (LAN) and/or wide area networks (WAN).</p>
<p id="p-0057" num="0056">The DSN memory <b>22</b> includes a plurality of distributed storage (DS) units <b>36</b> for storing data of the system. Each of the DS units <b>36</b> includes a processing module and memory and may be located at a geographically different site than the other DS units (e.g., one in Chicago, one in Milwaukee, etc.).</p>
<p id="p-0058" num="0057">Each of the user devices <b>12</b>-<b>14</b>, the DS processing unit <b>16</b>, the DS managing unit <b>18</b>, and the storage integrity processing unit <b>20</b> may be a portable computing device (e.g., a social networking device, a gaming device, a cell phone, a smart phone, a personal digital assistant, a digital music player, a digital video player, a laptop computer, a handheld computer, a video game controller, and/or any other portable device that includes a computing core) and/or a fixed computing device (e.g., a personal computer, a computer server, a cable set-top box, a satellite receiver, a television set, a printer, a fax machine, home entertainment equipment, a video game console, and/or any type of home or office computing equipment). Such a portable or fixed computing device includes a computing core <b>26</b> and one or more interfaces <b>30</b>, <b>32</b>, and/or <b>33</b>. An embodiment of the computing core <b>26</b> will be described with reference to <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0059" num="0058">With respect to the interfaces, each of the interfaces <b>30</b>, <b>32</b>, and <b>33</b> includes software and/or hardware to support one or more communication links via the network <b>24</b> indirectly and/or directly. For example, interfaces <b>30</b> support a communication link (wired, wireless, direct, via a LAN, via the network <b>24</b>, etc.) between the second type of user device <b>14</b> and the DS processing unit <b>16</b>. As another example, DSN interface <b>32</b> supports a plurality of communication links via the network <b>24</b> between the DSN memory <b>22</b> and the DS processing unit <b>16</b>, the first type of user device <b>12</b>, and/or the storage integrity processing unit <b>20</b>. As yet another example, interface <b>33</b> supports a communication link between the DS managing unit <b>18</b> and any one of the other devices and/or units <b>12</b>, <b>14</b>, <b>16</b>, <b>20</b>, and/or <b>22</b> via the network <b>24</b>.</p>
<p id="p-0060" num="0059">In general and with respect to data storage, the system <b>10</b> supports three primary functions: distributed network data storage management, distributed data storage and retrieval, and data storage integrity verification. In accordance with these three primary functions, data can be distributedly stored in a plurality of physically different locations and subsequently retrieved in a reliable and secure manner regardless of failures of individual storage devices, failures of network equipment, the duration of storage, the amount of data being stored, attempts at hacking the data, etc.</p>
<p id="p-0061" num="0060">The DS managing unit <b>18</b> performs distributed network data storage management functions, which include establishing distributed data storage parameters, performing network operations, performing network administration, and/or performing network maintenance. The DS managing unit <b>18</b> establishes the distributed data storage parameters (e.g., allocation of virtual DSN memory space, distributed storage parameters, security parameters, billing information, user profile information, etc.) for one or more of the user devices <b>12</b>-<b>14</b> (e.g., established for individual devices, established for a user group of devices, established for public access by the user devices, etc.). For example, the DS managing unit <b>18</b> coordinates the creation of a vault (e.g., a virtual memory block) within the DSN memory <b>22</b> for a user device (for a group of devices, or for public access). The DS managing unit <b>18</b> also determines the distributed data storage parameters for the vault. In particular, the DS managing unit <b>18</b> determines a number of slices (e.g., the number that a data segment of a data file and/or data block is partitioned into for distributed storage) and a read threshold value (e.g., the minimum number of slices required to reconstruct the data segment).</p>
<p id="p-0062" num="0061">As another example, the DS managing module <b>18</b> creates and stores, locally or within the DSN memory <b>22</b>, user profile information. The user profile information includes one or more of authentication information, permissions, and/or the security parameters. The security parameters may include one or more of encryption/decryption scheme, one or more encryption keys, key generation scheme, and data encoding/decoding scheme.</p>
<p id="p-0063" num="0062">As yet another example, the DS managing unit <b>18</b> creates billing information for a particular user, user group, vault access, public vault access, etc. For instance, the DS managing unit <b>18</b> tracks the number of times user accesses a private vault and/or public vaults, which can be used to generate a per-access bill. In another instance, the DS managing unit <b>18</b> tracks the amount of data stored and/or retrieved by a user device and/or a user group, which can be used to generate a per-data-amount bill.</p>
<p id="p-0064" num="0063">The DS managing unit <b>18</b> also performs network operations, network administration, and/or network maintenance. As at least part of performing the network operations and/or administration, the DS managing unit <b>18</b> monitors performance of the devices and/or units of the system <b>10</b> for potential failures, determines the devices and/or unit's activation status, determines the devices' and/or units' loading, and any other system level operation that affects the performance level of the system <b>10</b>. For example, the DS managing unit <b>18</b> receives and aggregates network management alarms, alerts, errors, status information, performance information, and messages from the devices <b>12</b>-<b>14</b> and/or the units <b>16</b>, <b>20</b>, <b>22</b>. For example, the DS managing unit <b>18</b> receives a simple network management protocol (SNMP) message regarding the status of the DS processing unit <b>16</b>.</p>
<p id="p-0065" num="0064">The DS managing unit <b>18</b> performs the network maintenance by identifying equipment within the system <b>10</b> that needs replacing, upgrading, repairing, and/or expanding. For example, the DS managing unit <b>18</b> determines that the DSN memory <b>22</b> needs more DS units <b>36</b> or that one or more of the DS units <b>36</b> needs updating.</p>
<p id="p-0066" num="0065">The second primary function (i.e., distributed data storage and retrieval) begins and ends with a user device <b>12</b>-<b>14</b>. For instance, if a second type of user device <b>14</b> has a data file <b>38</b> and/or data block <b>40</b> to store in the DSN memory <b>22</b>, it send the data file <b>38</b> and/or data block <b>40</b> to the DS processing unit <b>16</b> via its interface <b>30</b>. As will be described in greater detail with reference to <figref idref="DRAWINGS">FIG. 2</figref>, the interface <b>30</b> functions to mimic a conventional operating system (OS) file system interface (e.g., network file system (NFS), flash file system (FFS), disk file system (DFS), file transfer protocol (FTP), web-based distributed authoring and versioning (WebDAV), etc.) and/or a block memory interface (e.g., small computer system interface (SCSI), internet small computer system interface (iSCSI), etc.). In addition, the interface <b>30</b> may attach a user identification code (ID) to the data file <b>38</b> and/or data block <b>40</b>.</p>
<p id="p-0067" num="0066">The DS processing unit <b>16</b> receives the data file <b>38</b> and/or data block <b>40</b> via its interface <b>30</b> and performs a distributed storage (DS) process <b>34</b> thereon (e.g., an error coding dispersal storage function). The DS processing <b>34</b> begins by partitioning the data file <b>38</b> and/or data block <b>40</b> into one or more data segments, which is represented as Y data segments. For example, the DS processing <b>34</b> may partition the data file <b>38</b> and/or data block <b>40</b> into a fixed byte size segment (e.g., 2<sup>1 </sup>to 2<sup>n </sup>bytes, where n=&#x3e;2) or a variable byte size (e.g., change byte size from segment to segment, or from groups of segments to groups of segments, etc.).</p>
<p id="p-0068" num="0067">For each of the Y data segments, the DS processing <b>34</b> error encodes (e.g., forward error correction (FEC), information dispersal algorithm, or error correction coding) and slices (or slices then error encodes) the data segment into a plurality of error coded (EC) data slices <b>42</b>-<b>48</b>, which is represented as X slices per data segment. The number of slices (X) per segment, which corresponds to a number of pillars n, is set in accordance with the distributed data storage parameters and the error coding scheme. For example, if a Reed-Solomon (or other FEC scheme) is used in an n/k system, then a data segment is divided into n slices, where k number of slices is needed to reconstruct the original data (i.e., k is the threshold). As a few specific examples, the n/k factor may be 5/3; 6/4; 8/6; 8/5; 16/10.</p>
<p id="p-0069" num="0068">For each slice <b>42</b>-<b>48</b>, the DS processing unit <b>16</b> creates a unique slice name and appends it to the corresponding slice <b>42</b>-<b>48</b>. The slice name includes universal DSN memory addressing routing information (e.g., virtual memory addresses in the DSN memory <b>22</b>) and user-specific information (e.g., user ID, file name, data block identifier, etc.).</p>
<p id="p-0070" num="0069">The DS processing unit <b>16</b> transmits the plurality of EC slices <b>42</b>-<b>48</b> to a plurality of DS units <b>36</b> of the DSN memory <b>22</b> via the DSN interface <b>32</b> and the network <b>24</b>. The DSN interface <b>32</b> formats each of the slices for transmission via the network <b>24</b>. For example, the DSN interface <b>32</b> may utilize an internet protocol (e.g., TCP/IP, etc.) to packetize the slices <b>42</b>-<b>48</b> for transmission via the network <b>24</b>.</p>
<p id="p-0071" num="0070">The number of DS units <b>36</b> receiving the slices <b>42</b>-<b>48</b> is dependent on the distributed data storage parameters established by the DS managing unit <b>18</b>. For example, the DS managing unit <b>18</b> may indicate that each slice is to be stored in a different DS unit <b>36</b>. As another example, the DS managing unit <b>18</b> may indicate that like slice numbers of different data segments are to be stored in the same DS unit <b>36</b>. For example, the first slice of each of the data segments is to be stored in a first DS unit <b>36</b>, the second slice of each of the data segments is to be stored in a second DS unit <b>36</b>, etc. In this manner, the data is encoded and distributedly stored at physically diverse locations to improved data storage integrity and security.</p>
<p id="p-0072" num="0071">Each DS unit <b>36</b> that receives a slice <b>42</b>-<b>48</b> for storage translates the virtual DSN memory address of the slice into a local physical address for storage. Accordingly, each DS unit <b>36</b> maintains a virtual to physical memory mapping to assist in the storage and retrieval of data.</p>
<p id="p-0073" num="0072">The first type of user device <b>12</b> performs a similar function to store data in the DSN memory <b>22</b> with the exception that it includes the DS processing. As such, the device <b>12</b> encodes and slices the data file and/or data block it has to store. The device then transmits the slices <b>11</b> to the DSN memory via its DSN interface <b>32</b> and the network <b>24</b>.</p>
<p id="p-0074" num="0073">For a second type of user device <b>14</b> to retrieve a data file or data block from memory, it issues a read command via its interface <b>30</b> to the DS processing unit <b>16</b>. The DS processing unit <b>16</b> performs the DS processing <b>34</b> to identify the DS units <b>36</b> storing the slices of the data file and/or data block based on the read command. The DS processing unit <b>16</b> may also communicate with the DS managing unit <b>18</b> to verify that the user device <b>14</b> is authorized to access the requested data.</p>
<p id="p-0075" num="0074">Assuming that the user device is authorized to access the requested data, the DS processing unit <b>16</b> issues slice read commands to at least a threshold number of the DS units <b>36</b> storing the requested data (e.g., to at least 10 DS units for a 16/10 error coding scheme). Each of the DS units <b>36</b> receiving the slice read command, verifies the command, accesses its virtual to physical memory mapping, retrieves the requested slice, or slices, and transmits it to the DS processing unit <b>16</b>.</p>
<p id="p-0076" num="0075">Once the DS processing unit <b>16</b> has received a read threshold number of slices for a data segment, it performs an error decoding function and de-slicing to reconstruct the data segment. When Y number of data segments has been reconstructed, the DS processing unit <b>16</b> provides the data file <b>38</b> and/or data block <b>40</b> to the user device <b>14</b>. Note that the first type of user device <b>12</b> performs a similar process to retrieve a data file and/or data block.</p>
<p id="p-0077" num="0076">The storage integrity processing unit <b>20</b> performs the third primary function of data storage integrity verification. In general, the storage integrity processing unit <b>20</b> periodically retrieves slices <b>45</b>, and/or slice names, of a data file or data block of a user device to verify that one or more slices have not been corrupted or lost (e.g., the DS unit failed). The retrieval process mimics the read process previously described.</p>
<p id="p-0078" num="0077">If the storage integrity processing unit <b>20</b> determines that one or more slices is corrupted or lost, it rebuilds the corrupted or lost slice(s) in accordance with the error coding scheme. The storage integrity processing unit <b>20</b> stores the rebuild slice, or slices, in the appropriate DS unit(s) <b>36</b> in a manner that mimics the write process previously described.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic block diagram of an embodiment of a computing core <b>26</b> that includes a processing module <b>50</b>, a memory controller <b>52</b>, main memory <b>54</b>, a video graphics processing unit <b>55</b>, an input/output (IO) controller <b>56</b>, a peripheral component interconnect (PCI) interface <b>58</b>, at least one IO device interface module <b>62</b>, a read only memory (ROM) basic input output system (BIOS) <b>64</b>, and one or more memory interface modules. The memory interface module(s) includes one or more of a universal serial bus (USB) interface module <b>66</b>, a host bus adapter (HBA) interface module <b>68</b>, a network interface module <b>70</b>, a flash interface module <b>72</b>, a hard drive interface module <b>74</b>, and a DSN interface module <b>76</b>. Note the DSN interface module <b>76</b> and/or the network interface module <b>70</b> may function as the interface <b>30</b> of the user device <b>14</b> of <figref idref="DRAWINGS">FIG. 1</figref>. Further note that the IO device interface module <b>62</b> and/or the memory interface modules may be collectively or individually referred to as IO ports.</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic block diagram of an embodiment of a dispersed storage (DS) processing module <b>34</b> of user device <b>12</b> and/or of the DS processing unit <b>16</b>. The DS processing module <b>34</b> includes a gateway module <b>78</b>, an access module <b>80</b>, a grid module <b>82</b>, and a storage module <b>84</b>. The DS processing module <b>34</b> may also include an interface <b>30</b> and the DSnet interface <b>32</b> or the interfaces <b>68</b> and/or <b>70</b> may be part of user <b>12</b> or of the DS processing unit <b>14</b>. The DS processing module <b>34</b> may further include a bypass/feedback path between the storage module <b>84</b> to the gateway module <b>78</b>. Note that the modules <b>78</b>-<b>84</b> of the DS processing module <b>34</b> may be in a single unit or distributed across multiple units.</p>
<p id="p-0081" num="0080">In an example of storing data, the gateway module <b>78</b> receives an incoming data object that includes a user ID field <b>86</b>, an object name field <b>88</b>, and the data field <b>40</b> and may also receive corresponding information that includes a process identifier (e.g., an internal process/application ID), metadata, a file system directory, a block number, a transaction message, a user device identity (ID), a data object identifier, a source name, and/or user information. The gateway module <b>78</b> authenticates the user associated with the data object by verifying the user ID <b>86</b> with the managing unit <b>18</b> and/or another authenticating unit.</p>
<p id="p-0082" num="0081">When the user is authenticated, the gateway module <b>78</b> obtains user information from the management unit <b>18</b>, the user device, and/or the other authenticating unit. The user information includes a vault identifier, operational parameters, and user attributes (e.g., user data, billing information, etc.). A vault identifier identifies a vault, which is a virtual memory space that maps to a set of DS storage units <b>36</b>. For example, vault <b>1</b> (i.e., user <b>1</b>'s DSN memory space) includes eight DS storage units (X=8 wide) and vault <b>2</b> (i.e., user <b>2</b>'s DSN memory space) includes sixteen DS storage units (X=16 wide). The operational parameters may include an error coding algorithm, the width n (number of pillars X or slices per segment for this vault), a read threshold T, a write threshold, an encryption algorithm, a slicing parameter, a compression algorithm, an integrity check method, caching settings, parallelism settings, and/or other parameters that may be used to access the DSN memory layer.</p>
<p id="p-0083" num="0082">The gateway module <b>78</b> uses the user information to assign a source name <b>35</b> to the data. For instance, the gateway module <b>78</b> determines the source name <b>35</b> of the data object <b>40</b> based on the vault identifier and the data object. For example, the source name may contain a file identifier (ID), a vault generation number, a reserved field, and a vault identifier (ID). As another example, the gateway module <b>78</b> may generate the file ID based on a hash function of the data object <b>40</b>. Note that the gateway module <b>78</b> may also perform message conversion, protocol conversion, electrical conversion, optical conversion, access control, user identification, user information retrieval, traffic monitoring, statistics generation, configuration, management, and/or source name determination.</p>
<p id="p-0084" num="0083">The access module <b>80</b> receives the data object <b>40</b> and creates a series of data segments <b>1</b> through Y <b>90</b>-<b>92</b> in accordance with a data storage protocol (e.g., file storage system, a block storage system, and/or an aggregated block storage system). The number of segments Y may be chosen or randomly assigned based on a selected segment size and the size of the data object. For example, if the number of segments is chosen to be a fixed number, then the size of the segments varies as a function of the size of the data object. For instance, if the data object is an image file of 4,194,304 eight bit bytes (e.g., 33,554,432 bits) and the number of segments Y=131,072, then each segment is 256 bits or 32 bytes. As another example, if segment sized is fixed, then the number of segments Y varies based on the size of data object. For instance, if the data object is an image file of 4,194,304 bytes and the fixed size of each segment is 4,096 bytes, the then number of segments Y=1,024. Note that each segment is associated with the same source name.</p>
<p id="p-0085" num="0084">The grid module <b>82</b> receives the data segments and may manipulate (e.g., compression, encryption, cyclic redundancy check (CRC), etc.) each of the data segments before performing an error coding function of the error coding dispersal storage function to produce a pre-manipulated data segment. After manipulating a data segment, if applicable, the grid module <b>82</b> error encodes (e.g., Reed-Solomon, Convolution encoding, Trellis encoding, etc.) the data segment or manipulated data segment into X error coded data slices <b>42</b>-<b>44</b>.</p>
<p id="p-0086" num="0085">The value X, or the number of pillars (e.g., X=16), is chosen as a parameter of the error coding dispersal storage function. Other parameters of the error coding dispersal function include a read threshold T, a write threshold W, etc. The read threshold (e.g., T=10, when X=16) corresponds to the minimum number of error-free error coded data slices required to reconstruct the data segment. In other words, the DS processing module <b>34</b> can compensate for X-T (e.g., 16&#x2212;10=6) missing error coded data slices per data segment. The write threshold W corresponds to a minimum number of DS storage units that acknowledge proper storage of their respective data slices before the DS processing module indicates proper storage of the encoded data segment. Note that the write threshold is greater than or equal to the read threshold for a given number of pillars (X).</p>
<p id="p-0087" num="0086">For each data slice of a data segment, the grid module <b>82</b> generates a unique slice name <b>37</b> and attaches it thereto. The slice name <b>37</b> includes a universal routing information field and a vault specific field and may be 48 bytes (e.g., 24 bytes for each of the universal routing information field and the vault specific field). As illustrated, the universal routing information field includes a slice index, a vault ID, a vault generation, and a reserved field. The slice index is based on the pillar number and the vault ID and, as such, is unique for each pillar (e.g., slices of the same pillar for the same vault for any segment will share the same slice index). The vault specific field includes a data name, which includes a file ID and a segment number (e.g., a sequential numbering of data segments <b>1</b>-Y of a simple data object or a data block number).</p>
<p id="p-0088" num="0087">Prior to outputting the error coded data slices of a data segment, the grid module may perform post-slice manipulation on the slices. If enabled, the manipulation includes slice level compression, encryption, CRC, addressing, tagging, and/or other manipulation to improve the effectiveness of the computing system.</p>
<p id="p-0089" num="0088">When the error coded data slices of a data segment are ready to be outputted, the grid module <b>82</b> determines which of the DS storage units <b>36</b> will store the EC data slices based on a dispersed storage memory mapping associated with the user's vault and/or DS storage unit attributes. The DS storage unit attributes may include availability, self-selection, performance history, link speed, link latency, ownership, available DSN memory, domain, cost, a prioritization scheme, a centralized selection message from another source, a lookup table, data ownership, and/or any other factor to optimize the operation of the computing system. Note that the number of DS storage units <b>36</b> is equal to or greater than the number of pillars (e.g., X) so that no more than one error coded data slice of the same data segment is stored on the same DS storage unit <b>36</b>. Further note that EC data slices of the same pillar number but of different segments (e.g., EC data slice <b>1</b> of data segment <b>1</b> and EC data slice <b>1</b> of data segment <b>2</b>) may be stored on the same or different DS storage units <b>36</b>.</p>
<p id="p-0090" num="0089">The storage module <b>84</b> performs an integrity check on the outbound encoded data slices and, when successful, identifies a plurality of DS storage units based on information provided by the grid module <b>82</b>. The storage module <b>84</b> then outputs the encoded data slices <b>1</b> through X of each segment <b>1</b> through Y to the DS storage units <b>36</b>. Each of the DS storage units <b>36</b> stores its EC data slice(s) and maintains a local virtual DSN address to physical location table to convert the virtual DSN address of the EC data slice(s) into physical storage addresses.</p>
<p id="p-0091" num="0090">In an example of a read operation, the user device <b>12</b> and/or <b>14</b> sends a read request to the DS processing unit <b>14</b>, which authenticates the request. When the request is authentic, the DS processing unit <b>14</b> sends a read message to each of the DS storage units <b>36</b> storing slices of the data object being read. The slices are received via the DSnet interface <b>32</b> and processed by the storage module <b>84</b>, which performs a parity check and provides the slices to the grid module <b>82</b> when the parity check was successful. The grid module <b>82</b> decodes the slices in accordance with the error coding dispersal storage function to reconstruct the data segment. The access module <b>80</b> reconstructs the data object from the data segments and the gateway module <b>78</b> formats the data object for transmission to the user device.</p>
<p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic block diagram of an embodiment of a grid module <b>82</b> that includes a control unit <b>73</b>, a pre-slice manipulator <b>75</b>, an encoder <b>77</b>, a slicer <b>79</b>, a post-slice manipulator <b>81</b>, a pre-slice de-manipulator <b>83</b>, a decoder <b>85</b>, a de-slicer <b>87</b>, and/or a post-slice de-manipulator <b>89</b>. Note that the control unit <b>73</b> may be partially or completely external to the grid module <b>82</b>. For example, the control unit <b>73</b> may be part of the computing core at a remote location, part of a user device, part of the DS managing unit <b>18</b>, or distributed amongst one or more DS storage units.</p>
<p id="p-0093" num="0092">In an example of write operation, the pre-slice manipulator <b>75</b> receives a data segment <b>90</b>-<b>92</b> and a write instruction from an authorized user device. The pre-slice manipulator <b>75</b> determines if pre-manipulation of the data segment <b>90</b>-<b>92</b> is required and, if so, what type. The pre-slice manipulator <b>75</b> may make the determination independently or based on instructions from the control unit <b>73</b>, where the determination is based on a computing system-wide predetermination, a table lookup, vault parameters associated with the user identification, the type of data, security requirements, available DSN memory, performance requirements, and/or other metadata.</p>
<p id="p-0094" num="0093">Once a positive determination is made, the pre-slice manipulator <b>75</b> manipulates the data segment <b>90</b>-<b>92</b> in accordance with the type of manipulation. For example, the type of manipulation may be compression (e.g., Lempel-Ziv-Welch, Huffman, Golomb, fractal, wavelet, etc.), signatures (e.g., Digital Signature Algorithm (DSA), Elliptic Curve DSA, Secure Hash Algorithm, etc.), watermarking, tagging, encryption (e.g., Data Encryption Standard, Advanced Encryption Standard, etc.), adding metadata (e.g., time/date stamping, user information, file type, etc.), cyclic redundancy check (e.g., CRC32), and/or other data manipulations to produce the pre-manipulated data segment.</p>
<p id="p-0095" num="0094">The encoder <b>77</b> encodes the pre-manipulated data segment <b>92</b> using a forward error correction (FEC) encoder (and/or other type of erasure coding and/or error coding) to produce an encoded data segment <b>94</b>. The encoder <b>77</b> determines which forward error correction algorithm to use based on a predetermination associated with the user's vault, a time based algorithm, user direction, DS managing unit direction, control unit direction, as a function of the data type, as a function of the data segment <b>92</b> metadata, and/or any other factor to determine algorithm type. The forward error correction algorithm may be Golay, Multidimensional parity, Reed-Solomon, Hamming, Bose Ray Chauduri Hocquenghem (BCH), Cauchy-Reed-Solomon, or any other FEC encoder. Note that the encoder <b>77</b> may use a different encoding algorithm for each data segment <b>92</b>, the same encoding algorithm for the data segments <b>92</b> of a data object, or a combination thereof.</p>
<p id="p-0096" num="0095">The encoded data segment <b>94</b> is of greater size than the data segment <b>92</b> by the overhead rate of the encoding algorithm by a factor of X/T, where X is the width or number of slices, and T is the read threshold. In this regard, the corresponding decoding process can accommodate at most X-T missing EC data slices and still recreate the data segment <b>92</b>. For example, if X=16 and T=10, then the data segment <b>92</b> will be recoverable as long as 10 or more EC data slices per segment are not corrupted.</p>
<p id="p-0097" num="0096">The slicer <b>79</b> transforms the encoded data segment <b>94</b> into EC data slices in accordance with the slicing parameter from the vault for this user and/or data segment <b>92</b>. For example, if the slicing parameter is X=16, then the slicer <b>79</b> slices each encoded data segment <b>94</b> into 16 encoded slices.</p>
<p id="p-0098" num="0097">The post-slice manipulator <b>81</b> performs, if enabled, post-manipulation on the encoded slices to produce the EC data slices. If enabled, the post-slice manipulator <b>81</b> determines the type of post-manipulation, which may be based on a computing system-wide predetermination, parameters in the vault for this user, a table lookup, the user identification, the type of data, security requirements, available DSN memory, performance requirements, control unit directed, and/or other metadata. Note that the type of post-slice manipulation may include slice level compression, signatures, encryption, CRC, addressing, watermarking, tagging, adding metadata, and/or other manipulation to improve the effectiveness of the computing system.</p>
<p id="p-0099" num="0098">In an example of a read operation, the post-slice de-manipulator <b>89</b> receives at least a read threshold number of EC data slices and performs the inverse function of the post-slice manipulator <b>81</b> to produce a plurality of encoded slices. The de-slicer <b>87</b> de-slices the encoded slices to produce an encoded data segment <b>94</b>. The decoder <b>85</b> performs the inverse function of the encoder <b>77</b> to recapture the data segment <b>90</b>-<b>92</b>. The pre-slice de-manipulator <b>83</b> performs the inverse function of the pre-slice manipulator <b>75</b> to recapture the data segment <b>90</b>-<b>92</b>.</p>
<p id="p-0100" num="0099"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram of an example of slicing an encoded data segment <b>94</b> by the slicer <b>79</b>. In this example, the encoded data segment <b>94</b> includes thirty-two bits, but may include more or less bits. The slicer <b>79</b> disperses the bits of the encoded data segment <b>94</b> across the EC data slices in a pattern as shown. As such, each EC data slice does not include consecutive bits of the data segment <b>94</b> reducing the impact of consecutive bit failures on data recovery. For example, if EC data slice <b>2</b> (which includes bits <b>1</b>, <b>5</b>, <b>9</b>, <b>13</b>, <b>17</b>, <b>25</b>, and <b>29</b>) is unavailable (e.g., lost, inaccessible, or corrupted), the data segment can be reconstructed from the other EC data slices (e.g., 1, 3 and 4 for a read threshold of 3 and a width of 4).</p>
<p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. 6A</figref> is a schematic block diagram of another embodiment of a computing system that includes a device <b>102</b> (e.g., a user device <b>12</b>-<b>14</b>, a dispersed storage (DS) processing unit <b>16</b>, a DS managing unit <b>18</b>, a DS unit <b>36</b>, and a storage integrity processing unit <b>20</b>) and a dispersed storage network (DSN) memory <b>22</b>. The DSN memory <b>22</b> includes a plurality of DS units <b>36</b>. The device <b>102</b> includes a module <b>104</b> to enable the device <b>102</b> to generate a secure signature on an item without a locally stored private key <b>116</b> of the device <b>102</b>. The private key <b>116</b> may be obtained by at least one of receiving, generating a private/public key pair, generating based on an attribute associated with the device <b>102</b>, and generating based on a random number to produce a random key as private key <b>116</b>. The item includes a data element that includes one or more of registry information, key information, encryption algorithm information, a device certificate, a user certificate, a system element identifier (ID), a DSN access request, and a hash of the data element, wherein a hashing function is applied to the data element to produce the hash of the data element. The module <b>104</b> includes a select key index module <b>106</b>, an obtain signature contributions module <b>108</b>, a generate signature module <b>110</b>, a populate key shares module <b>112</b>, and a validate signature module <b>114</b>.</p>
<p id="p-0102" num="0101">The select key index module <b>106</b> is operable to select a first key representation index <b>118</b> of a set of key representation indexes, wherein the first key representation index <b>118</b> includes information regarding a first key representation of a set of key representations, wherein a first mathematical encoding of the private key <b>116</b> generates a first plurality of key shares <b>122</b> as the first key representation, which is stored in a first set of DS units <b>36</b> of the DSN memory <b>22</b>, and a second mathematical encoding of the private key <b>116</b> generates a second plurality of key shares <b>124</b> as a second key representation of the set of key representations, which is stored in a second set of DS units <b>36</b> of the DSN memory <b>22</b>. The select key index module <b>106</b> functions to select the first key representation index <b>118</b> by selecting the first key representation index <b>118</b> based on one or more of DS unit status indicators of the first and second sets of DS units, DS unit performance level indicators of the first and second sets of DS units, DS unit retrieval history indicators of the first and second sets of DS units, a security indicator, a query, a command, a key share storage table lookup, and a message. For example, the select key index module <b>106</b> selects the first key representation index <b>118</b> when DS unit performance level indicators associated with the first set of DS units <b>36</b> are favored (e.g., lower average retrieval access latency time) over DS unit performance level indicators associated with the second set of DS units <b>36</b>.</p>
<p id="p-0103" num="0102">The first mathematical encoding includes the populate key shares module <b>112</b> operable to generate at least one set of key shares for storage in one or more sets of DS units, the generating includes the populate key shares module <b>112</b> of operable to generate one or more first values, generate a second value based on the one or more first values, the private key <b>116</b>, and a key share generating mathematical function, and send the one or more first values and the second value to the first set of DS units. The second mathematical encoding includes the populate key shares module <b>112</b> further operable to generate one or more third values, generate a fourth value based on the one or more third values, the private key <b>116</b>, and the key share generating mathematical function, and send the one or more third values and the fourth value to the second set of DS units. The populate key shares module <b>112</b> is further operable to randomly generate the one or more first values and generate the second value based on key share generating mathematical function of (x+y+z) mod &#x3a6;(n)=d, where d is the private key <b>116</b>, n is a public modulus (e.g., a 1024 bit wide public key paired to the private key <b>116</b>), x and y correspond to the one or more first values, z corresponds to the second value, &#x3a6;(n) is an Euler's totient function &#x3a6;(n)=(p&#x2212;1)*(q&#x2212;1), and p and q are large prime numbers in accordance with n=p*q. After generating the set of key representations, the populate key shares module <b>112</b> destroys the private key <b>116</b>.</p>
<p id="p-0104" num="0103">The obtain signature contributions module <b>108</b> is operable to determine whether a first plurality of signature contributions <b>126</b> have been received in response to a signature request <b>128</b> for the item based on the first key representation index <b>118</b>, wherein one of the first set of DS units executes a first mathematical signature function using one of the first plurality of key shares on the item to produce a signature contribution of the first plurality of signature contributions. For example, the one of the first set of DS units executes the first mathematical signature function as first signature contribution=(item) keyshare mod n, wherein the item is extracted from the request <b>128</b>, the keyshare is retrieved as a corresponding value from a local memory of the one DS unit, and n is a public modulus extracted from the signature request <b>128</b>. The signature request <b>128</b> includes a set of signature requests, wherein each signature request of the set of signature requests includes one or more of the first key index <b>118</b> (e.g., a share set number, a DS unit combination ID, DS unit IDs of the corresponding DS units), a signature payload (e.g., the item to sign), a hash of the signature payload, a DS unit ID, and a public modulus value (e.g., n).</p>
<p id="p-0105" num="0104">When the first plurality of signature contributions <b>126</b> have been received, the generate signature module <b>110</b> is operable to generate the secure signature <b>130</b> on the item from the first plurality of signature contributions <b>126</b>. The generate signature module <b>110</b> functions to generate the secure signature <b>130</b> on the item by multiplying the first plurality of signature contributions <b>126</b> to produce a multiplication result and performing a modulus function on the multiplication result to produce the secure signature <b>130</b>. For example, to generate signature module <b>110</b> produces the secure signature <b>130</b> on the item in accordance with (contribution <b>1</b>*contribution <b>2</b>*contribution <b>3</b>) mod n, when the first plurality of signature contributions <b>126</b> includes three signature contributions.</p>
<p id="p-0106" num="0105">When the first plurality of signature contributions have not been received (e.g., receiving two when the plurality includes three; not receiving all three within a time period), the obtain signature contributions module <b>108</b> is further operable to generate second signature requests <b>132</b> for the item based on a second key representation index <b>120</b> of the set of key representation indexes, send the second signature requests <b>132</b> to the second set of DS units, determine whether a second plurality of signature contributions <b>134</b> have been received from the second set of DS units, and when the second plurality of signature contributions <b>134</b> have been received, the generate signature module <b>110</b> is further operable to generate the secure signature <b>130</b> on the item from the second plurality of signature contributions. For example, the select key index module <b>106</b> identifies the second key representation index <b>120</b> when DS unit performance level indicators associated with the second set of DS units are more favorable (e.g., lower average retrieval access latency time) than DS unit performance level indicators associated with other sets of DS units.</p>
<p id="p-0107" num="0106">The validate signature module <b>114</b> is operable to determine whether the secure signature is valid. For example, the validate signature module <b>114</b> indicates that the secure signature <b>130</b> is not valid when a hash of the item is not substantially the same as a decrypted secure signature, wherein the secure signature <b>130</b> is decrypted utilizing a public key associated with the private key <b>116</b>. When the secure signature <b>130</b> is not valid, the obtain signature contributions module <b>108</b> is further operable to generate second signature requests <b>132</b> for the item based on the second key representation index <b>120</b> of the set of key representation indexes, send the second signature requests <b>132</b> to the second set of DS units, determine whether the second plurality of signature contributions <b>134</b> have been received from the second set of DS units. When the second plurality of signature contributions <b>134</b> have been received, the generate signature module <b>110</b> is further operable to generate the secure signature <b>130</b> on the item from the second plurality of signature contributions <b>134</b>. The validate signature module <b>114</b> is further operable to determine whether the secure signature <b>130</b> on the item from the second plurality of signature contributions <b>134</b> is valid.</p>
<p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. 6B</figref> is a flowchart illustrating an example of storing key shares. The method begins at step <b>144</b> where a processing module obtains a private key (e.g., an encryption key d utilized in an encryption algorithm). The obtaining may be based on one or more of generating a private/public key pair (e.g., a private key and a key), receiving the private key, a query, a lookup, and a user input. The method continues at step <b>146</b> where the processing module determines sharing function parameters. The sharing function parameters includes one or more of a width number (e.g., a number of storage nodes w), a decode threshold (e.g., a number of key shares k), a number of shares sets (e.g., w choose k), a public modulus n (e.g., a public key), security function constants p and q (e.g., large primes such that p*q=n), an encryption algorithm identifier (ID), and a decryption algorithm ID. The determining may be based on one or more of a list, a predetermination, a query, a performance level indicator, a reliability level requirement, a message, and a command. For example, the processing module determines w=4, k=2, a number of shares sets=(4 choose 2)=6, a value for n, and a value for p based on a lookup and generates a value for q in accordance with p*q=n.</p>
<p id="p-0109" num="0108">The method continues at step <b>148</b> where the processing module identifies a plurality of storage nodes for storing key shares. The plurality of storage nodes includes two or more of a user device, a dispersed storage (DS) unit, a storage server, and a memory device. The navigation may be based on one or more of the sharing function parameters, a list, a predetermination, a query, a performance level indicator, a message, and a command. For example, the processing module identifies the plurality of storage nodes to include 4 DS units when the sharing function parameters include a width w=4 and a performance level indicator indicates that a performance level of the 4 DS units compares favorably to a performance level threshold.</p>
<p id="p-0110" num="0109">The method continues at step <b>150</b> where the processing module generates one or more sets of key shares to include the number of shares sets. For example, the processing module generates 6 sets of key shares when the width w=4 and the decode threshold k=2 (e.g., 4 choose 2=6). The generation produces a set of key shares for each combination of a decode threshold k number of key shares stored in the width w number of storage nodes. The generation of each set of key shares includes generation in accordance with a formula (x+y+z) mod &#x3a6;(n)=private key d, wherein &#x3a6;(n)=(p&#x2212;1)* (q&#x2212;1), n=p*q, and x, y, z represent key shares of a corresponding key share set when a number of key shares is three. For example, the processing module randomly chooses values for key shares y and z of a corresponding key share set and generates a value for key share x in accordance with the formula.</p>
<p id="p-0111" num="0110">In an example of generating key share sets, the processing module generates 10 key shares sets to include a first key share set that includes a key share x<b>1</b> to store in DS unit <b>1</b>, a key share y<b>1</b> to store in DS unit <b>2</b>, and a key share z<b>1</b> to store in DS unit <b>3</b>, a second key share set that includes a key share x<b>2</b> to store in DS unit <b>1</b>, a key share y<b>2</b> to store in DS unit <b>2</b>, and a key share z<b>2</b> to store in DS unit <b>4</b>, a third key share set that includes a key share x<b>3</b> to store in DS unit <b>1</b>, a key share y<b>3</b> to store in DS unit <b>2</b>, and a key share z<b>3</b> to store in DS unit <b>5</b>, a fourth key share set that includes a key share x<b>4</b> to store in DS unit <b>1</b>, a key share y<b>4</b> to store in DS unit <b>3</b>, and a key share z<b>4</b> to store in DS unit <b>5</b>, a fifth key share set that includes a key share x<b>5</b> to store in DS unit <b>1</b>, a key share y<b>5</b> to store in DS unit <b>4</b>, and a key share z<b>5</b> to store in DS unit <b>5</b>, a sixth key share set that includes a key share x<b>6</b> to store in DS unit <b>2</b>, a key share y<b>6</b> to store in DS unit <b>3</b>, and a key share z<b>6</b> to store in DS unit <b>4</b>, a seventh key share set that includes a key share x<b>7</b> to store in DS unit <b>2</b>, a key share y<b>7</b> to store in DS unit <b>3</b>, and a key share z<b>7</b> to store in DS unit <b>5</b>, an eighth key share set that includes a key share x<b>8</b> to store in DS unit <b>2</b>, a key share y<b>7</b> to store in DS unit <b>4</b>, and a key share z<b>7</b> to store in DS unit <b>5</b>, a ninth key share set that includes a key share x<b>9</b> to store in DS unit <b>3</b>, a key share y<b>9</b> to store in DS unit <b>4</b>, and a key share z<b>9</b> to store in DS unit <b>5</b>, and a 10th key share set that includes a key share x<b>10</b> to store in DS unit <b>1</b>, a key share y<b>10</b> to store in DS unit <b>3</b>, and a key share z<b>10</b> to store in DS unit <b>4</b> when a number storage nodes is 5 and a decode threshold is 3.</p>
<p id="p-0112" num="0111">The method continues at step <b>152</b> where the processing module outputs the one or more sets of key shares to the plurality of storage nodes. In addition, the processing module may output one or more of the sharing function parameters to each storage node of the plurality of storage nodes. For example, the processing module sends the public modulus n to each storage node of the plurality of storage nodes. The method continues at the step where the processing module destroys the private key d. The destroying of the private key may provide the system with a security performance improvement. A method to generate a signature based on stored shared keys is described in greater detail with reference to <figref idref="DRAWINGS">FIG. 6D</figref>. A method to generate a signature contribution (e.g., by a storage node) is described in greater detail with reference to <figref idref="DRAWINGS">FIG. 6E</figref>.</p>
<p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. 6C</figref> is a diagram illustrating an example of a key share storage table <b>156</b> that includes a share set field <b>158</b>, a node combination field <b>160</b>, and a key share per storage node field <b>162</b>. The share set field <b>158</b> includes a share sets number of share set identifiers of corresponding key share sets. For example, the share set field <b>158</b> includes 6 share set identifiers <b>1</b>-<b>6</b> when a number of storage nodes w=4, a decode threshold k=2, and the share sets number of share set identifiers is w choose k (e.g., 4 choose 2=6). The node combination field <b>160</b> includes a share sets number of node combination entries, wherein each node combination entry corresponds to a combination of a decode threshold number of storage node identifiers. For example, the node combination field includes 6 node combination entries including A-B, A-C, A-D, B-C, B-D, and C-D when storage nodes A-D are utilized to store a share sets number (e.g., 6) of a decode threshold number (e.g., 2) of key shares.</p>
<p id="p-0114" num="0113">The key share per storage node field <b>162</b> includes a share sets number of storage node fields, wherein each storage node field corresponds to a storage node of a number of storage nodes w utilized to store the key shares. Each storage node field includes a key share identifier (e.g., a key representation index) utilized to identify a key share of an associated share set (e.g., key representation) that is stored in a storage node corresponding to the storage node field. For example, share set <b>1</b> includes utilization of storage node combination A-B such that key share x<b>1</b> is stored in storage unit A and key share y<b>1</b> is stored in storage node B, share set <b>2</b> includes utilization of storage node combination A-C such that key share x<b>2</b> is stored in storage unit A and key share y<b>2</b> is stored in storage node C, share set <b>3</b> includes utilization of storage node combination A-D such that key share x<b>3</b> is stored in storage unit A and key share y<b>3</b> is stored in storage node D, share set <b>4</b> includes utilization of storage node combination B-C such that key share x<b>4</b> is stored in storage unit B and key share y<b>4</b> is stored in storage node C, share set <b>5</b> includes utilization of storage node combination B-D such that key share x<b>5</b> is stored in storage unit B and key share y<b>5</b> is stored in storage node D, and share set <b>6</b> includes utilization of storage node combination C-D such that key share x<b>6</b> is stored in storage unit C and key share y<b>6</b> is stored in storage node D. Each set of key shares may be generated in accordance with a formula (x+y) mod &#x3a6;(n)=private key d, wherein &#x3a6;(n)=(p&#x2212;1)*(q&#x2212;1). For example, a value of key share y<b>1</b> is chosen randomly and a value for key share x<b>1</b> is generated in accordance with the formula. Storing more than one key share set corresponding to more than one key representation of a private key in more than one storage node set may provide the system with an availability improvement.</p>
<p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. 6D</figref> is a flowchart illustrating an example of generating a signature, where a device of a distributed storage network (DSN) generates a secure signature on an item without a locally stored private key of the device. The item includes one or more of a data element that includes one or more of registry information, key information, encryption algorithm information, a device certificate, a user certificate, and a system element identifier, and a DSN access request and a hash of the data element.</p>
<p id="p-0116" num="0115">The method begins at step <b>170</b> where a processing module selects a first key representation index of a set of key representation indexes, wherein the first key representation index includes information regarding a first key representation of a set of key representations, wherein a first mathematical encoding of the private key generates a first plurality of key shares as the first key representation, which is stored in a first set of dispersed storage (DS) units of the DSN, and a second mathematical encoding of the private key generates a second plurality of key shares as a second key representation of the set of key representations, which is stored in a second set of dispersed storage (DS) units of the DSN. The first mathematical encoding includes generating one or more first values, generating a second value based on the one or more first values, the private key, and a key share generating mathematical function, and sending the one or more first values and the second value to the first set of DS units. For example, the processing module randomly generates the one or more first values and generates the second value based on key share generating mathematical function of (x+y+z) mod &#x3a6;(n)=d, where d is the private key, x and y correspond to the one or more first values, z corresponds to the second value, and &#x3a6;(n) is an Euler's totient function. The second mathematical encoding includes generating one or more third values, generating a fourth value based on the one or more third values, the private key, and the key share generating mathematical function, and sending the one or more third values and the fourth value to the second set of DS units. After generating the set of key representations, the processing module destroys the private key.</p>
<p id="p-0117" num="0116">At step <b>170</b>, the processing module selects the first key representation index based on one or more of DS unit status indicators of the first and second sets of DS units, DS unit performance level indicators of the first and second sets of DS units, DS unit retrieval history indicators of the first and second sets of DS units, a security indicator, a query, a command, a key share storage table lookup, and a message. The method continues at step <b>172</b> where the processing module determines whether a first plurality of signature contributions have been received in response to a signature request for the item based on the first key representation index, wherein one of the first set of DS units executes a first mathematical signature function using one of the first plurality of key shares on the item to produce a signature contribution of the first plurality of signature contributions. The signature request includes a set of signature requests, wherein each signature request of the set of signature requests includes one or more of a first key representation identifier (ID) (e.g., a share set number, a DS unit combination ID, DS unit IDs of the corresponding DS units), a signature payload (e.g., something to sign like a certificate), a hash of the signature payload, a DS unit ID, and a public modulus value (e.g., n).</p>
<p id="p-0118" num="0117">The method branches to step <b>176</b> when the processing module determines that the first plurality of signature contributions have not been received. The method continues to step <b>174</b> when the processing module determines that the first plurality of signature contributions has been received. The method continues at step <b>174</b> where the processing module generates the secure signature on the item from the first plurality of signature contributions. The generating the secure signature on the item includes multiplying the first plurality of signature contributions to produce a multiplication result and performing a modulus function on the multiplication result to produce the secure signature. The method branches to step <b>184</b>.</p>
<p id="p-0119" num="0118">The method continues at step <b>176</b> where the processing module generates second signature requests for the item based on a second key representation index of the set of key representation indexes when the first plurality of signature contributions have not been received. The method continues at step <b>178</b> where the processing module sends the second signature requests to the second set of DS units. The method continues at step <b>180</b> where the processing module determines whether a second plurality of signature contributions have been received from the second set of DS units. The method loops back to step <b>176</b> to send another signature request when the processing module determines that the second plurality of signature contributions have not been received (e.g., within a time period). The method continues to step <b>182</b> when the processing module determines that the second plurality of signature contributions have been received. The method continues at step <b>182</b> where the processing module generates the secure signature on the item from the second plurality of signature contributions.</p>
<p id="p-0120" num="0119">The method continues at step <b>184</b> where the processing module determines whether the secure signature is valid. For example, the processing module indicates that the secure signature is not valid when a hash of the item is not substantially the same as a decrypted secure signature utilizing and associated public key. The method branches back to step <b>176</b> to send another signature request when the processing module determines that the secure signature is not valid. The method continues to step <b>186</b> when the processing module determines that the secure signature is valid. The method continues at step <b>186</b> where the processing module indicates that the secure signature is valid. The processing module may output the secure signature to a requesting entity.</p>
<p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. 6E</figref> is a flowchart illustrating an example of generating a signature contribution. The method begins at step <b>190</b> where a processing module (e.g., of a storage node, of a dispersed storage (DS) unit) receives a signature contribution request.</p>
<p id="p-0122" num="0121">The method continues at step <b>192</b> where the processing module retrieves a key share based one or more of on sharing function parameters and the signature contribution request. The processing module obtains the sharing function parameters based on one or more of receiving the sharing function parameters, extracting the sharing function parameters from the signature contribution request, a lookup, a message, a command, and a predetermination. For example, the processing module extracts the sharing function parameters from the signature contribution request to include a key share identifier (ID). The retrieving of the key share includes obtaining the key share ID and retrieving the key share based on the key share ID. For example, the processing module obtains key share ID x<b>3</b>, determines a storage node A memory location based on the key share ID x<b>3</b>, and retrieves the key share x<b>3</b> from a memory of the storage node at the storage node memory location.</p>
<p id="p-0123" num="0122">As another example, the processing module extracts the sharing function parameters from the signature contribution request to include a share set ID. The retrieving of the key share includes obtaining the share set ID and retrieving the key share based on the share set ID and a key share storage table lookup. For example, the processing module obtains share set ID A-D, determines a key share ID of x<b>3</b> based on a key share storage table lookup utilizing the share set ID A-D as an index, determines a storage node A memory location based on the key share ID x<b>3</b>, and retrieves the key share x<b>3</b> from a memory of the storage node at the storage node memory location.</p>
<p id="p-0124" num="0123">The method continues at step <b>194</b> where the processing module generates a signature contribution based on the key share and a message (e.g., an item) to sign m. The processing module obtains the message to sign m by at least one of extracting the message to sign m from the signature contribution request and generating a hash of a message payload extracted from the signature contribution request. The generation of the signature contribution includes generating the signature contribution in accordance with an expression signature contribution=m<sup>x </sup>mod n, where m is the message to sign or the hash of the message payload, x is the retrieved key share, and n is a public modulus (e.g., a public key). For example, the processing module generates the signature contribution in accordance with signature contribution A=m<sup>x3 </sup>mod n, when the processing module is associated with storage node A and the key share is x<b>3</b>. The method continues at step <b>196</b> where the processing module outputs the signature contribution to a requesting entity.</p>
<p id="p-0125" num="0124"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart illustrating another example of generating a signature contribution, which includes similar steps to <figref idref="DRAWINGS">FIG. 6E</figref>. The method begins at step <b>200</b> where a processing module (e.g., of a dispersed storage (DS) unit, of a storage node) receives a signature contribution request that includes a payload. The method continues at step <b>202</b> where the processing module logs the signature contribution request. The logging includes one or more of extracting request information from the signature contribution request, obtaining a user identifier (ID), obtaining a vault ID, obtaining a timestamp, aggregating the request information, the user ID, the vault ID, and the timestamp to produce logging information, and facilitating storing of the logging information.</p>
<p id="p-0126" num="0125">The method continues at step <b>204</b> where the processing module determines whether timing of the signature contribution request compares favorably to a timing template. For example, the processing module determines that the comparison is favorable when a difference between the timestamp associated with the signature contribution request and a timestamp associated with a previous signature contribution request is greater than a time threshold of the timing template. The method branches to step <b>208</b> when the processing module determines that the timing of the request compares unfavorably to the timing template. The method continues to step <b>206</b> when the processing module determines that the timing of the request compares favorably to the timing template.</p>
<p id="p-0127" num="0126">The method continues at step <b>206</b> where the processing module determines whether the signature contribution request compares favorably to a functionality template. The determination may be based on one or more of the payload, a payload analysis, and a comparison of the payload analysis to the functionality template. For example, the processing module determines that the request compares favorably to the functionality template when the processing module determines that a registry value of the payload does not conflict with a current registry value. As another example, the processing module determines that the request compares favorably to the functionality template when the payload is not a certificate authority certificate. As yet another example, the processing module determines that the request compares favorably to the functionality template when an Internet protocol (IP) address associated with a requester of the request does not compare unfavorably to an unfavorable IP address list.</p>
<p id="p-0128" num="0127">The method branches to step <b>192</b> of <figref idref="DRAWINGS">FIG. 6E</figref> when the processing module determines that the request compares favorably to the functionality template. The method continues to step <b>208</b> when the processing module determines that the request compares unfavorably to the functionality template. The method continues at step <b>208</b> where the processing module outputs a request rejection message. The outputting includes generating the request rejection message to include one or more of the signature contribution request, the logging information, the timestamp associated with the signature contribution request, and an error code, and sending the request rejection message to one or more of a requester, a dispersed storage (DS) imaging unit, a DS processing unit, a DS unit, and a user device. When the processing module determines that the request compares favorably to the functionality template, the method continues with steps <b>192</b>-<b>196</b> of <figref idref="DRAWINGS">FIG. 6E</figref> where the processing module retrieves a key share based on sharing function parameters, generates a signature result based on the key share and message to sign, and outputs the signature result.</p>
<p id="p-0129" num="0128"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart illustrating an example of replicating encoded data slices. The method begins at step <b>210</b> where a processing module (e.g., of a dispersed storage (DS) unit) determines whether a frequency of slice access of an encoded data slice compares favorably to a slice access threshold. The processing module may obtain the frequency of slice access based on one or more of a frequency of slice access query, a lookup, a list, an error message, a request, and a command. For example, the processing module determines that the frequency of slice access compares unfavorably to the slice access threshold when the frequency of slice access is 500 accesses per minute and the slice access threshold is 100 accesses per minute. The method loops at step <b>210</b> when the processing module determines that the frequency of access compares favorably to the slice access threshold. The method continues to step <b>212</b> when the processing module determines that the frequency of access compares unfavorably to the slice access threshold.</p>
<p id="p-0130" num="0129">The method continues at step <b>212</b> where the processing module determines at least one secondary DS unit. The determination may be based on one or more of a current access performance level, a performance requirement, an estimated access performance level, a request pattern, a candidate secondary DS unit list, a DS unit location, a DS unit performance level, and a DS unit Internet protocol (IP) address. For example, the processing module determines the at least one secondary DS unit to include a West Coast DS unit went the request pattern includes West Coast slice access requests and a DS unit performance level associated with the West Coast DS unit compares favorably to an access latency performance requirement.</p>
<p id="p-0131" num="0130">The method continues at step <b>214</b> where the processing module generates a replicated encoded data slice of the encoded data slice. The generation includes one or more of immediately retrieving the encoded data slice, retrieving the encoded data slice when a dispersed storage network (DSN) activity level compares favorably to an activity level threshold, rebuilding the encoded data slice, and forming the replicated encoded data slice from the encoded data slice such that the replicated encoded is substantially the same as the encoded data slice.</p>
<p id="p-0132" num="0131">The method continues at step <b>216</b> where the processing module sends the replicated encoded data slice to the at least one secondary DS unit for storage therein. Alternatively, or in addition to, the processing module determines whether the replicated encoded data slice is already stored in the at least one secondary DS unit and sends the replicated encoded data slice to the at least one secondary DS unit when the replicated encoded data slice is not already stored in the at least one secondary DS unit. The method continues at step <b>218</b> where the processing module updates a slice storage location table to include an identifier associated with the at least one secondary DS unit. The updating includes updating the slice storage location table to include affiliating a slice name associated with the encoded data slice with the identifier associated with the at least one secondary DS unit.</p>
<p id="p-0133" num="0132">The method continues at step <b>220</b> where the processing module determines whether the frequency of slice access of the encoded data slice compares favorably to a second slice access threshold. For example, the processing module determines that the frequency of slice access compares unfavorably to the second slice access threshold when the frequency of slice access is greater than the second slice access threshold. The method loops at step <b>220</b> when the processing module determines that the frequency of slice access compares unfavorably to the second slice access threshold. The method continues to step <b>222</b> when the processing module determines that the frequency of slice access compares favorably to the second slice access threshold.</p>
<p id="p-0134" num="0133">The method continues at step <b>222</b> where the processing module updates the slice storage location table to exclude at least one of the at least one secondary DS units. The updating includes updating the slice storage table to exclude affiliating the slice name associated with the encoded data slice with an identifier associated with at least one of the at least one secondary DS unit. The at least one secondary DS unit may delete the replicated encoded data slice when a time period since a last replicated encoded data slice access is greater than a deletion time threshold. The method repeats back to step <b>210</b>.</p>
<p id="p-0135" num="0134"><figref idref="DRAWINGS">FIG. 9A</figref> is a schematic block diagram of another embodiment of a computing system that includes a device <b>230</b> (e.g., a user device <b>12</b>, a dispersed storage (DS) processing unit <b>16</b>) and a dispersed storage network (DSN) memory <b>36</b>. The DSN memory <b>36</b> includes at least one set of DS units <b>22</b>. The device <b>230</b> includes a module <b>232</b> and a pre-fetch segment buffer <b>234</b>. The buffer <b>234</b> may be implemented utilizing one or more memory devices, wherein each memory device includes at least one of a magnetic drive memory, a solid-state memory, and an optical drive memory. The module <b>232</b> includes a receive request module <b>236</b>, a process request module <b>238</b>, a determine buffering module <b>240</b>, and a pre-fetch module <b>242</b>.</p>
<p id="p-0136" num="0135">The receive request module <b>236</b> is operable to receive a data segment retrieval request <b>244</b> regarding a data segment <b>246</b> of a plurality of data segments, wherein the data segment <b>246</b> is encoded in accordance with a dispersed storage error coding function (e.g., one or more of the functions, processes, etc. discussed with reference to <figref idref="DRAWINGS">FIG. 4</figref>, an IDA, or other type of FEC), to produce a set of encoded data slices, which is stored in the set of DS units <b>22</b> of the DSN memory <b>36</b>. In response to the data segment retrieval request <b>244</b>, the process request module <b>238</b> is operable to process the data segment retrieval request <b>244</b>. The process request module <b>238</b> functions to process the data segment retrieval request <b>244</b> by determining whether the data segment <b>246</b> is stored in the pre-fetch segment buffer <b>234</b>. When the data segment <b>246</b> is not stored in the pre-fetch segment buffer <b>234</b>, the module <b>238</b> determines whether the data segment <b>246</b> is identified in previous pre-fetch segment buffering information (e.g., a pre-fetch may be in progress). When the data segment <b>246</b> is identified in the previous pre-fetch segment buffering information, the module <b>238</b> retrieves the data segment <b>246</b> from the pre-fetch segment buffer <b>234</b>. When the data segment <b>246</b> is not identified in the previous pre-fetch segment buffering information, the module <b>238</b> generates a set of at least a decode threshold number of encoded data slice retrieval requests <b>248</b> regarding at least a decode threshold number of the set of encoded data slices <b>250</b> (e.g., for sending to the set of DS units <b>22</b>). When encoded data slices are received, the module <b>238</b> decodes at least a decode threshold number of the encoded data slices <b>250</b> (e.g., received from the set of DS units <b>22</b>) to reproduce the data segment <b>246</b>.</p>
<p id="p-0137" num="0136">The pre-fetch segment buffering information <b>252</b> includes one or more of identity of the one or more other data segments, a number of encoded data slices to retrieve for each of the one or more data segments, pillar identifiers (IDs) corresponding to encoded data slices of the number of encoded data slice to retrieve, a set of DS unit IDs associated with the pillar IDs, and a data segment retrieval performance goal. The process request module <b>238</b> further functions to process the data segment retrieval request <b>244</b> by determining whether the data segment <b>246</b> is stored in the pre-fetch segment buffer <b>234</b> and when the data segment <b>246</b> is stored in the pre-fetch segment buffer <b>234</b>, retrieving the data segment <b>246</b> from the pre-fetch segment buffer <b>234</b>.</p>
<p id="p-0138" num="0137">The determine buffering module <b>240</b> is operable to determine the pre-fetch segment buffering information <b>252</b> based on the data segment <b>246</b>, content of the pre-fetch segment buffer <b>234</b>, a data consumption rate, and a DS unit response rate. The DS unit response rate includes a plurality of DS response characteristics for a plurality of DS units, wherein the plurality of DS units includes the set of DS units and wherein a DS response characteristic includes one or more of a pillar identifier (ID), response latency information, processing consumption, network traffic, response history, and reliability information. For example, the determine buffering module <b>240</b> determines the pre-fetch segment buffering information <b>252</b> to include an indication to retrieve slices stored in a first and second DS unit for three segments of the one or more other data segments and an indication to retrieve slices stored in a third DS unit for six segments of the one or more data segments when response latency information indicates a slower than average response latency for the third DS unit and an average response latency for the first and second DS units.</p>
<p id="p-0139" num="0138">The determine buffering module <b>240</b> further functions to determine the pre-fetch segment buffering information <b>252</b> by determining a data segment retrieval trend of the plurality of data segments and determining the pre-fetch segment buffering information <b>252</b> further based on the data segment retrieval trend. For example, the determine buffering module <b>240</b> identifies time intervals between sequential data segment retrieval requests as the data segment retrieval trend. As another example, the determine buffering module <b>240</b> identifies intervals between decoding of retrieve data segments as the data segment retrieval trend.</p>
<p id="p-0140" num="0139">When the pre-fetch segment buffering information <b>252</b> indicates pre-fetching one or more other data segments <b>258</b> of the plurality of data segments, the pre-fetch module <b>242</b> is operable to generate one or more pre-fetch segment retrieval requests for the one or more other data segments <b>258</b> (e.g., for sending to the set of DS units <b>22</b>), receive, in response to the one or more pre-fetch segment retrieval requests, one or more sets of at least a decode threshold number of encoded data slices <b>256</b>, decode, in accordance with the dispersed storage error coding function, the one or more sets of at least a decode threshold number of encoded data slices <b>256</b> to reproduce the one or more other data segments <b>258</b>, and update the pre-fetch segment buffer <b>234</b> with the one or more other data segments <b>258</b>. The pre-fetch module <b>242</b> functions to generate the one or more pre-fetch segment retrieval requests by generating, for a pre-fetch segment retrieval request of the one or more pre-fetch segment retrieval requests, at least a decode threshold number of encoded data slices retrieval requests <b>260</b>.</p>
<p id="p-0141" num="0140">For example, the pre-fetch module <b>242</b> generates the decode threshold number of encoded data slice retrieval requests <b>260</b>. The module <b>242</b> then sends, substantially simultaneously, the decode threshold number of encoded data slice retrieval requests <b>260</b> to the set of DS units <b>22</b>. In response to the requests, the module <b>242</b> receives a decode threshold number of encoded data slices <b>256</b> and decodes them to reproduce another data segment <b>258</b>. As another example, the pre-fetch module <b>242</b> generates the decode threshold number of encoded data slice retrieval requests <b>260</b>, sends a first portion of them to a first portion of DS units (e.g., DS units associated with an above average retrieval latency) at a first point in time, and sends the remaining portion to remaining DS units (e.g., DS units associated with an average retrieval latency) at a second point in time. In response to the requests, the module <b>242</b> receives a decode threshold number of encoded data slices <b>256</b> and decodes them to reproduce another data segment <b>258</b> for storage in the pre-fetch segment buffer <b>234</b>.</p>
<p id="p-0142" num="0141"><figref idref="DRAWINGS">FIG. 9B</figref> is a timing diagram illustrating an example of pre-fetching a data segment where a request timeline <b>262</b> indicates receiving a set of data segment requests (e.g., receive data segment requests <b>1</b>-<b>7</b>) and a delivery timeline <b>264</b> indicates delivering a set of corresponding data segments (e.g., deliver data segments <b>1</b>-<b>7</b>). The set of data segment requests may request sequential data segments of a large data file without requesting all data segments of the large data file. For example, a request for data segment one is received at time t<b>1</b>, a request for data segment <b>2</b> is received at time t<b>2</b>, a request for data segment <b>3</b> is received at time t<b>4</b>, a request for data segment <b>4</b> is received at time t<b>6</b>, a request for data segment <b>5</b> is received at time t<b>7</b>, a request for data segment <b>6</b> is received at time t<b>8</b>, and a request for data segment <b>7</b> is received at time t<b>9</b>.</p>
<p id="p-0143" num="0142">A method to pre-fetch data segments for delivery is utilized to provide a delivery latency improvement. In an example of operation, a new request for data segment <b>1</b> is received at time t<b>1</b> and a data segment retrieval trend is determined that includes anticipation of receiving at least another incremental request for data segment <b>2</b>. Pre-fetch segment buffering information is determined to initiate retrieval of at least data segments <b>1</b>-<b>2</b>. Retrieval of data segment <b>1</b> from a dispersed storage network memory is initiated at time t<b>1</b> based on the pre-fetch segment buffering information. Pre-fetch of data segment <b>2</b> is initiated at time t<b>1</b> based on the pre-fetch segment buffering information. The data segment <b>2</b> request is received at time t<b>2</b> and the data segment retrieval trend is updated noting that a request for data segment two has been received but the pre-fetch of data segment two has not yet been completed. The pre-fetch segment buffering information is updated to indicate a more aggressive pre-fetch requirement to speed up data segment retrievals. As such, pre-fetching of data segments <b>3</b> and <b>4</b> are initiated at time t<b>2</b>. Data segments <b>1</b> and <b>2</b> are delivered at time t<b>3</b> at the completion of the retrieval of data segment <b>1</b> and the pre-fetch of data segment <b>2</b>.</p>
<p id="p-0144" num="0143">The example continues where the data segment <b>3</b> request is received at time t<b>4</b> and the data segment retrieval trend is updated noting that the last three data segment requests are evenly separated by seven time units. The pre-fetch segment buffering information is updated to indicate that a delivery rate of data segments is approximately caught up to a rate of receiving the data segment retrieval requests. As such, pre-fetching of data segment <b>5</b> is initiated at time t<b>4</b>. Data segment <b>3</b> is delivered at time t<b>5</b>. An access latency of nine time units is associated with delivery of data segment <b>1</b>, an access latency of two time units is associated with delivery of data segments <b>2</b> and <b>3</b>. The data segment <b>4</b> request is received at time t<b>6</b> and data segment <b>4</b> is delivered at time t<b>6</b> with a zero time unit access latency due to an adaptation in data segment pre-fetching. The data segment retrieval trend is updated noting that the data segment <b>4</b> retrieval request was received five time units after a previous data segment <b>3</b> request. The pre-fetch segment buffering information is updated to indicate that the rate of receiving the data segment retrieval request is increasing. As such, pre-fetching of data segments <b>6</b> and <b>7</b> is initiated at time t<b>6</b> to attempt to maintain a desired zero latency data segment delivery performance level. The data segment <b>5</b> retrieval request is received at time t<b>7</b> and data segment <b>5</b> is delivered at time t<b>7</b> with a zero time unit access latency. Data segments <b>6</b> and <b>7</b> are also delivered with a zero time unit access latency at times t<b>8</b> and t<b>9</b>. The method to pre-fetch a data segment is discussed in greater detail with reference to <figref idref="DRAWINGS">FIG. 9C</figref>.</p>
<p id="p-0145" num="0144"><figref idref="DRAWINGS">FIG. 9C</figref> is a flowchart illustrating example of pre-fetching a data segment. The method begins with step <b>270</b> where a processing module (e.g., of a device) receives a data segment retrieval request regarding a data segment of a plurality of data segments, wherein the data segment is encoded in accordance with a dispersed storage error coding function to produce a set of encoded data slices, which is stored in a set of dispersed storage (DS) units of a dispersed storage network (DSN) memory. In response to the data segment retrieval request, the method continues at step <b>272</b> where the processing module processes the data segment retrieval request by determining whether the data segment is stored in a pre-fetch segment buffer. The method branches to step <b>276</b> when the processing module determines that the data segment is not stored in the pre-fetch segment buffer. The method continues to step <b>274</b> when the processing module determines that the data segment is stored in the pre-fetch segment buffer. The method continues at step <b>274</b> where the processing module retrieves the data segment from the pre-fetch segment buffer. The method branches to step <b>284</b>.</p>
<p id="p-0146" num="0145">The method continues at step <b>276</b> where the processing module determines whether the data segment is identified in previous pre-fetch segment buffering information when the data segment is not stored in the pre-fetch segment buffer. Pre-fetch segment buffering information includes one or more of identity of the one or more other data segments, a number of encoded data slices to retrieve for each of the one or more data segments, pillar identifiers (IDs) corresponding to encoded data slices of the number of encoded data slice to retrieve, a set of DS unit IDs associated with the pillar IDs, and a data segment retrieval performance goal. The method branches to step <b>280</b> when the processing module determines that the data segment is not identified in previous pre-fetch segment buffering information. The method continues to step <b>278</b> when the processing module determines that the data segment is identified in previous pre-fetch segment buffering information. The method continues at step <b>278</b> where the processing module retrieves the data segment from the pre-fetch segment buffer when the data segment is stored in the pre-fetch segment buffer when the data segment is identified in the previous pre-fetch segment buffering information. The method branches to step <b>284</b>.</p>
<p id="p-0147" num="0146">The method continues at step <b>280</b> where the processing module generates a set of at least a decode threshold number of encoded data slice retrieval requests regarding at least a decode threshold number of the set of encoded data slices when the data segment is not identified in the previous pre-fetch segment buffering information. The method continues at step <b>282</b> where the processing module decodes the at least the decode threshold number of the set of encoded data slices to reproduce the data segment.</p>
<p id="p-0148" num="0147">The method continues at step <b>284</b> where the processing module determines pre-fetch segment buffering information based on the data segment, content of a pre-fetch segment buffer, a data consumption rate, and DS unit response rate. The DS unit response rate includes a plurality of DS response characteristics for a plurality of DS units, wherein the plurality of DS units includes the set of DS units and wherein a DS response characteristic includes one or more of: a pillar identifier (ID), response latency information, processing consumption, network traffic, response history, and reliability information. The determining the pre-fetch segment buffering information includes determining a data segment retrieval trend of the plurality of data segments and determining the pre-fetch segment buffering information further based on the data segment retrieval trend.</p>
<p id="p-0149" num="0148">When the pre-fetch segment buffering information indicates pre-fetching one or more other data segments of the plurality of data segments, the method continues at step <b>286</b> where the processing module generates one or more pre-fetch segment retrieval requests for the one or more other data segments. The generating the one or more pre-fetch segment retrieval requests includes for a pre-fetch segment retrieval request of the one or more pre-fetch segment retrieval requests, generating at least a decode threshold number of encoded data slices retrieval requests. The method continues at step <b>288</b> where the processing module receives, in response to the one or more pre-fetch segment retrieval requests, one or more sets of at least a decode threshold number of encoded data slices. The method continues at step <b>290</b> where the processing module decodes, in accordance with the dispersed storage error coding function, the one or more sets of at least a decode threshold number of encoded data slices to reproduce the one or more other data segments. The method continues at step <b>292</b> where the processing module updates the pre-fetch segment buffer with the one or more other data segments.</p>
<p id="p-0150" num="0149"><figref idref="DRAWINGS">FIG. 10A</figref> is a diagram illustrating an example of encoding data that includes data <b>300</b>, an intermediate matrix <b>302</b>, a column selector <b>304</b>, a generator matrix <b>306</b>, a data selection <b>308</b>, and a slice matrix <b>310</b> and. The data <b>300</b> includes a plurality of data bytes. For example, the data includes 100,000 bytes b<b>1</b>-b<b>100</b>k. The intermediate matrix <b>302</b> includes matrix dimensions (e.g., number of rows, number of columns) based on a size of the data and error coding dispersal storage function parameters (e.g., a decode threshold). For example, the intermediate matrix <b>302</b> includes five rows and 20,000 columns when the error coding dispersal storage function parameters includes a decode threshold of five and a data size of the data is 100,000 bytes (e.g., columns=data size/decode threshold=100k/5=20k). The intermediate matrix <b>302</b> includes entries of sequential data bytes of the data <b>300</b> in a row-by-row fashion. For example, row <b>1</b> includes bytes b<b>1</b>-<b>20</b>k, row <b>2</b> includes bytes b<b>20</b>k+1-b<b>40</b>k, etc.</p>
<p id="p-0151" num="0150">The generator matrix <b>306</b> includes matrix dimensions based on the error coding dispersal storage function parameters (e.g., the decode threshold, a width). For example, the generator matrix <b>306</b> includes five columns and eight rows when the decode threshold is five and the width is eight. The generator matrix <b>306</b> includes entries in accordance with an error coding dispersal storage function to produce encoded data slices such that at least a decode threshold number of encoded data slices may be utilized to reproduce the data.</p>
<p id="p-0152" num="0151">The data selection <b>308</b> includes matrix dimensions of one by the decode threshold (e.g., one by five when the decode threshold is five). The column selector <b>304</b> forms entries of the data selection <b>308</b> based on selecting data of each column of the intermediate matrix <b>302</b> one by one. For example, the column selector selects a second selection of column <b>2</b> to include bytes b<b>2</b>, b<b>20</b>k+2, b<b>40</b>k+2, b<b>60</b>k+2, and b<b>80</b>k+2.</p>
<p id="p-0153" num="0152">The slice matrix <b>310</b> includes matrix dimensions of a width number of rows and a number of columns substantially the same as the number of columns of the intermediate matrix <b>302</b>. The slice matrix <b>310</b> includes entries that form a width number of encoded data slices. Each encoded data slice of the width number of encoded data slices includes a number of bytes substantially the same as the number of columns of the intermediate matrix <b>302</b>. For example, each encoded data slice of the width number of encoded data slices includes 20,000 bytes, when the decode threshold is five and the size of the data is 100,000 bytes.</p>
<p id="p-0154" num="0153">In an example of operation, sequential bytes of the data <b>300</b> forms the decode threshold number of rows of the intermediate matrix <b>302</b> row by row. The column selector <b>304</b> selects one column of the intermediate matrix printer to at a time to produce a data selection <b>308</b> of a plurality of data selections. The generator matrix <b>306</b> is multiplied by each data selection <b>308</b> of the plurality of data selections to produce a corresponding column of a plurality of columns of the intermediate matrix <b>302</b> of the slice matrix <b>310</b>. For example, b<b>1</b>_<b>1</b>=ab<b>1</b>+b(b<b>20</b>k+1)+c(b<b>40</b>k+1)+d(b<b>60</b>k+1)+e(b<b>80</b>k+1), b<b>1</b>_<b>2</b>=fb<b>1</b>+g(b<b>20</b>k+1)+h(b<b>40</b>k+1)+i(b<b>60</b>k+1)+j(b<b>80</b>k+1), etc, and b<b>1</b>_<b>8</b>=ajb<b>1</b>+ak(b<b>20</b>k+1)+al(b<b>40</b>k+1)+am(b<b>60</b>k+1)+an(b<b>80</b>k+1) when the column selector selects a first column. As another example, b<b>2</b>_<b>1</b>=ab<b>2</b>+b(b<b>20</b>k+2)+c(b<b>40</b>k+2)+d(b<b>60</b>k+2)+e(b<b>80</b>k+2), b<b>2</b>_<b>2</b>=fb<b>2</b>+g(b<b>20</b>k+2)+h(b<b>40</b>k+2)+i(b<b>60</b>k+2)+j(b<b>80</b>k+2), etc, and b<b>2</b>_<b>8</b>=ajb<b>2</b>+ak(b<b>20</b>k+2)+al(b<b>40</b>k+2)+am(b<b>60</b>k+2)+an(b<b>80</b>k+2) when the column selector <b>304</b> selects a second column.</p>
<p id="p-0155" num="0154"><figref idref="DRAWINGS">FIG. 10B</figref> is a flowchart illustrating an example of encoding data. The method begins at step <b>312</b> where a processing module (e.g., of a dispersed storage module) receives data for storage. The data may include one or more of a data segment, a data object, a data block, and a data file. The method continues at step <b>314</b> where the processing module generates an intermediate matrix based on the data and error coding dispersal storage function parameters. The method continues at step <b>316</b> where the processing module multiplies a column of the intermediate matrix by a generator matrix to produce a corresponding column of a slice matrix.</p>
<p id="p-0156" num="0155">The method continues at step <b>318</b> where the processing module determines whether to output one or more columns of the slice matrix. The determination may be based on one or more of a memory utilization indicator, a memory utilization threshold, a processor loading indicator, a processor loading threshold, a column count, a predetermination, a message, and a command. For example, the processing module determines to output three columns of the slice matrix when the memory utilization indicator compares unfavorably to the memory utilization threshold. The method repeats back to step <b>316</b> to produce another column of the slice matrix when the processing module determines not to output one or more columns of the slice matrix. The method continues to step <b>320</b> when the processing module determines to output one or more columns of the slice matrix.</p>
<p id="p-0157" num="0156">The method continues at step <b>320</b> where the processing module outputs the one or more columns for storage when the processing module determines output one or more columns of the slice matrix. Each column of the one or more columns includes one or more bytes of a corresponding encoded data slice. For example, a width number of complete encoded data slices are output when the one or more columns includes all columns of the intermediate matrix. As another example, a width number of incomplete encoded slices are output when the one or more columns includes less than all columns of the intermediate matrix.</p>
<p id="p-0158" num="0157">The outputting includes sending the one or more columns and slice information to a dispersed storage (DS) unit storage set for storage therein. The slice information includes one or more of a complete encoded data slice indicator, an append indicator (e.g., to indicate whether incomplete slices may be appended to form complete slices), and at least some of the error coding dispersal storage function parameters. For example, the slice information includes a complete encoded data slice indicator such that the indicator indicates incomplete encoded data slices when the one or more columns includes less than all columns of the intermediate matrix. As another example, the slice information includes an append indicator indicating that incomplete slices may be appended to form complete slices when the intermediate matrix is generated based on all bytes of the data. As yet another example, the slice information includes an append indicator indicating that incomplete or complete slices of a second portion of data may not be appended to incomplete or complete slices of a first portion of the data when a first intermediate matrix is generated based on the first portion of the data and a second intermediate matrix is generated based on the second portion of the data.</p>
<p id="p-0159" num="0158">The method continues at step <b>322</b> where the processing module determines whether all columns of intermediate matrix have been processed. The method repeats back to step <b>316</b> to produce a corresponding column of the slice matrix for a next column. The method ends at step <b>324</b> when the processing module determines that all columns of the intermediate matrix have been processed.</p>
<p id="p-0160" num="0159"><figref idref="DRAWINGS">FIG. 10C</figref> is a flowchart illustrating an example of decoding data. The method begins at step <b>326</b> where a processing module receives a data retrieval request to retrieve data. The request may include a data identifier (ID) and a user ID. The method continues at step <b>328</b> where the processing module determines whether the data is stored as incomplete encoded data slices. The determination may be based on one or more of the data ID, a lookup, a query, an encoded data slice retrieval response, a message, and obtaining slice information. For example, the processing module determines at least one slice name associated with the data based on generating the slice name based on the data ID and a vault ID corresponding to the user ID. The processing module sends an encoded data slice retrieval request, wherein the request includes the at least one slice name. The processing module receives an encoded data slice retrieval response corresponding to the encoded data slice retrieval request. The receiving may include receiving an encoded data slice and/or receiving slice information. The processing module determines that the data is stored as incomplete encoded data slices when the encoded data slice is incomplete and/or when the slice information indicates that the data is stored as incomplete encoded slices.</p>
<p id="p-0161" num="0160">The method branches to step <b>332</b> when the processing module determines that the data is stored as incomplete encoded data slices. The method continues to step <b>330</b> when the processing module determines that the data is not stored as incomplete encoded data slices. The method continues at step <b>330</b> where the processing module retrieves a set of encoded data slices and branches to step <b>336</b>.</p>
<p id="p-0162" num="0161">The method continues at step <b>332</b> where the process module retrieves incomplete encoded data slices of each encoded data slice of the set of encoded data slices when the processing module determines that the data is stored as incomplete encoded data slices. The method continues at step <b>334</b> where the processing module aggregates the incomplete encoded data slices to reproduce each encoded data slice of the set of encoded data slices. For example, the processing module reproduces a slice matrix such that sequential columns of corresponding incomplete encoded data slices form the slice matrix. The method continues at step <b>336</b> where the processing module dispersed storage error decodes the set of encoded data slices to reproduce the data. The method may repeat to form a plurality of data segments of the data when the data includes the plurality of data segments.</p>
<p id="p-0163" num="0162"><figref idref="DRAWINGS">FIG. 11A</figref> is a diagram illustrating another example of encoding data, which includes similar elements as discussed with reference to <figref idref="DRAWINGS">FIG. 10A</figref>. The encoding of data includes data <b>300</b>, an alternative intermediate matrix <b>340</b>, a column selector <b>304</b>, a generator matrix <b>306</b>, a data selection <b>342</b>, and a slice matrix <b>344</b>. The data <b>300</b> includes a plurality of data bytes. The alternative intermediate matrix <b>340</b> includes matrix dimensions (e.g., number of rows, number of columns) based on a size of the data <b>300</b> and error coding dispersal storage function parameters (e.g., a decode threshold). For example, the alternative intermediate matrix <b>340</b> includes five rows and 20,000 columns when the error coding dispersal storage function parameters includes a decode threshold of five and a data size of the data is 100,000 bytes (e.g., columns=data size/decode threshold=100k/5=20k). The alternative intermediate matrix <b>340</b> includes entries of sequential data bytes of the data <b>300</b> in a column-by-column fashion. For example, column <b>1</b> includes bytes b<b>1</b>-<b>15</b>, column <b>2</b> includes bytes b<b>6</b>-<b>10</b>, etc.</p>
<p id="p-0164" num="0163">The column selector <b>304</b> forms entries of the data selection <b>342</b> based on selecting data of each column of the intermediate matrix <b>340</b> one by one. For example, the column selector <b>304</b> selects a second selection of column <b>2</b> to include bytes b<b>6</b>-b<b>10</b> of the data <b>300</b>. The slice matrix <b>344</b> includes matrix dimensions of the width number of rows and a number of columns substantially the same as a number of columns of the alternative intermediate matrix <b>340</b>. The slice matrix <b>344</b> includes entries that form a width number of encoded data slices. Each encoded data slice of the width number of encoded data slices includes a number of bytes substantially the same as the number of columns of the alternative intermediate matrix <b>340</b>.</p>
<p id="p-0165" num="0164">In an example of operation, sequential bytes of the data <b>300</b> forms the columns of the alternative intermediate matrix <b>340</b> column by column. The column selector <b>304</b> selects one column of the alternative intermediate matrix <b>340</b> at a time to produce a data selection <b>342</b> of a plurality of data selections. The generator matrix <b>306</b> is multiplied by each data selection <b>342</b> of the plurality of data selections to produce a corresponding column of a plurality of columns of the alternative intermediate matrix <b>340</b> of the slice matrix <b>344</b>. For example, b<b>1</b>_<b>1</b>=ab<b>1</b>+bb<b>2</b>+cb<b>3</b>+db<b>4</b>+eb<b>5</b>, b<b>1</b>_<b>2</b>=fb<b>1</b>+gb<b>2</b>+hb<b>3</b>+ib<b>4</b>+jb<b>5</b>, etc, and b<b>1</b>_<b>8</b>=ajb<b>1</b>+akb<b>2</b>+alb<b>3</b>+amb<b>4</b>+anb<b>5</b> when the column selector <b>304</b> selects a first column. As another example, b<b>2</b>_<b>1</b>=ab<b>6</b>+bb<b>7</b>+cb<b>8</b>+db<b>9</b>+eb<b>10</b>, b<b>2</b>_<b>2</b>=fb<b>6</b>+gb<b>7</b>+hb<b>8</b>+ib<b>9</b>+jb<b>10</b>, etc, and b<b>2</b>_<b>8</b>=ajb<b>6</b>+akb<b>7</b>+alb<b>8</b>+amb<b>9</b>+anb<b>10</b> when the column selector <b>304</b> selects a second column.</p>
<p id="p-0166" num="0165">Utilizing such an alternative intermediate matrix <b>340</b> enables appending incomplete slices of corresponding encoded slices to form complete encoded data slices when the data is partitioned into two or more data partitions. For example, an a first incomplete encoded data slice of encoded data slice <b>1</b> may be appended to a second incomplete encoded data slice of encoded data slice <b>1</b>, when the data includes byte <b>1</b>-byte <b>100</b>k+5 and the data is partitioned into two partitions which includes a first partition including bytes b<b>1</b>-b<b>100</b>k and a second partition including byte b<b>100</b>k+1-byte <b>100</b>k+5. An apparatus to execute the appending is described in greater detail with reference to <figref idref="DRAWINGS">FIG. 11B</figref> and methods of appending is described in greater detail with reference to <figref idref="DRAWINGS">FIGS. 11C and 11D</figref>.</p>
<p id="p-0167" num="0166"><figref idref="DRAWINGS">FIG. 11B</figref> is a schematic block diagram of another embodiment of a computing system that includes a dispersed storage (DS) processing unit <b>16</b> and dispersed storage network (DSN) memory <b>36</b>. The DS processing unit <b>16</b> includes a module <b>350</b> (e.g., a DS module <b>34</b>). Alternatively, the DS processing unit <b>16</b> may be implemented utilizing a DS module <b>34</b> of a user device <b>12</b>. The module <b>350</b> includes a receive request module <b>352</b>, a determine append module <b>354</b>, an encode module <b>356</b>, a generate commands module <b>358</b>, and an output commands module <b>360</b>. The DSN memory <b>36</b> includes at least one set of DS units <b>22</b>. Each DS unit <b>22</b> includes a module <b>362</b> (e.g., a DS module <b>34</b>) and a memory <b>370</b>. The module <b>362</b> includes a store slice module <b>364</b>, a receive append module <b>366</b>, and an update storage module <b>368</b>. The memory <b>370</b> may be implemented as one or more memory devices utilizing one or more of a solid-state memory, a magnetic drive memory, and an optical drive memory.</p>
<p id="p-0168" num="0167">The receive request module <b>352</b> is operable to receive a request <b>372</b> to store data <b>374</b> in the DSN memory <b>36</b>. The determine append module <b>354</b> is operable to determine whether the data <b>374</b> is to be appended to existing data <b>376</b> stored in the DSN memory <b>22</b>, wherein the existing data <b>376</b> is stored in the DSN memory <b>36</b> as a set of encoded data slices and wherein the existing data <b>376</b> is encoded using a dispersed storage error coding function to produce the set of encoded data slices. The determine append module <b>354</b> functions to determine whether the data <b>374</b> is to be appended by at least one of receiving an append instruction with the data <b>374</b>, interpreting account information associated with an issuer of the request to store the data <b>374</b>, and interpreting directory information of at least one of the data <b>374</b> and the existing data <b>376</b>.</p>
<p id="p-0169" num="0168">When the data <b>374</b> is to be appended, the encode module <b>356</b> is operable to encode, using an append dispersed storage error coding function, the data <b>374</b> to produce a set of encoded append data slices <b>378</b>. The encode module <b>356</b> is further operable to encode the existing data using <b>376</b> the dispersed storage error coding function by arranging data blocks of the existing data into a plurality of groups of data blocks and on a group of data block by group of data block basis, matrix-multiplying the plurality of groups of data blocks with a dispersed storage error encoding matrix to produce a plurality of sets of encoded data slice portions and wherein an encoded data slice of the set of encoded data slices includes an encoded data slice portion from each of the plurality of sets of encoded data slice portions.</p>
<p id="p-0170" num="0169">The encode module <b>356</b> is further operable to encode the data <b>374</b> using the append dispersed storage error coding function by partitioning the data into data blocks based on size of the data blocks of the existing data, arranging the data blocks of the data into a second plurality of groups of data blocks, wherein a group of data blocks of the second plurality of groups of data blocks includes a same number of data blocks as a group of data blocks of the plurality of groups of data blocks, and on the group of data block by group of data block basis, matrix-multiplying the second plurality of groups of data blocks with the dispersed storage error encoding matrix to produce a second plurality of sets of encoded data slice portions and wherein an encoded append data slice of the set of encoded append data slices includes an encoded data slice portion from each of the second plurality of sets of encoded data slice portions.</p>
<p id="p-0171" num="0170">The generate commands module <b>358</b> is operable to generate a set of append commands <b>380</b>, wherein an append command of the set of append commands <b>380</b> includes an encoded append data slice of the set of encoded append data slices <b>378</b> and identity of one of the set of DS units <b>22</b> of the DSN memory <b>36</b>. The append command further includes at least one of a slice name of a corresponding one of set of encoded data slices, an offset indicator, and a column identifier of a slice matrix. The output commands module <b>360</b> is operable to output at least a write threshold number of the set of append commands <b>380</b> to at least a write threshold number of the set of DS units <b>22</b>. For example, the output commands module <b>360</b> outputs an append command <b>384</b> of the set of append commands <b>380</b> a DS unit <b>22</b> of the set of DS units <b>22</b>.</p>
<p id="p-0172" num="0171">The receive request module <b>352</b> is further operable to receive second data for storage in the DSN memory <b>36</b>. The determine append module <b>354</b> is further operable to determine whether the second data is to be appended to existing appended data <b>376</b> stored in the DSN memory <b>36</b>, wherein the existing appended data includes the set of encoded data slices and the set of encoded append data slices <b>378</b>. When the second data is to be appended, the encode module <b>356</b> is further operable to encode, using the append dispersed storage error coding function, the second data to produce a second set of encoded append data slices, the generate commands module <b>358</b> is further operable to generate a second set of append commands, and the output commands module <b>360</b> is further operable to output at least a write threshold number of the second set of append commands to the at least a write threshold number of the set of DS units <b>22</b>.</p>
<p id="p-0173" num="0172">The store slice module <b>364</b> is operable to store an encoded data slice <b>382</b> of the set of encoded data slices, wherein the existing data <b>376</b> is encoded using a dispersed storage error coding function to produce the set of encoded data slices. The receive append module <b>366</b> is operable to receive the append command <b>384</b> that includes an encoded append data slice <b>386</b> of the set of encoded append data slices <b>378</b> and an instruction to append the encoded append data slice <b>386</b> to the encoded data slice <b>382</b>, wherein the data <b>374</b> is encoded using an append dispersed storage error coding function to produce the set of encoded append data slices <b>378</b>.</p>
<p id="p-0174" num="0173">The update storage module <b>368</b> is operable to update storage of the encoded data slice <b>382</b> based on the encoded append data slice <b>386</b> to produce an updated encoded data slice <b>388</b>. The update storage module <b>368</b> is further operable to interpret the append command <b>384</b> to identify a slice name of the encoded append data slice <b>386</b>, identify the encoded data slice <b>382</b> based on the slice name, append the encoded append data slice <b>386</b> to the encoded data slice <b>382</b> to produce the updated encoded data slice <b>388</b>, and update a slice table to associate the slice name with the updated encoded data slice <b>388</b>. The update storage module <b>368</b> functions to update storage of the encoded data slice <b>382</b> by identifying the encoded data slice <b>382</b> (e.g., by data identifier (ID), by a slice name, by a pillar number), retrieving the encoded data slice <b>382</b> to produce a retrieved encoded data slice, appending the encoded append data slice <b>386</b> to the retrieved encoded data slice to produce the updated encoded data slice <b>388</b>, and storing the updated encoded data slice <b>388</b>. The receive append module <b>366</b> is further operable to receive a second append command that includes a second encoded append data slice of a second set of encoded append data slices and another instruction to append the second encoded append data slice to the updated encoded data slice <b>388</b>, wherein second data is encoded using the append dispersed storage error coding function to produce the second set of encoded append data slices and the update storage module <b>368</b> is further operable to update storage of the updated encoded data slice based on the second key encoded append data slice to produce a second updated encoded data slice.</p>
<p id="p-0175" num="0174"><figref idref="DRAWINGS">FIG. 11C</figref> is a flowchart illustrating an example of appending data. The method begins at step <b>400</b> where a processing module (e.g., of a dispersed storage (DS) processing unit, of a user device) receives a request to store data in dispersed storage network (DSN) memory. The method continues at step <b>402</b> where the processing module determines whether the data is to be appended to existing data stored in the DSN memory, wherein the existing data is stored in the DSN memory as a set of encoded data slices and wherein the existing data is encoded using a dispersed storage error coding function to produce the set of encoded data slices. The encoding the existing data using the dispersed storage error coding function includes arranging data blocks of the existing data into a plurality of groups of data blocks and on a group of data block by group of data block basis, matrix-multiplying the plurality of groups of data blocks with a dispersed storage error encoding matrix to produce a plurality of sets of encoded data slice portions and wherein an encoded data slice of the set of encoded data slices includes an encoded data slice portion from each of the plurality of sets of encoded data slice portions.</p>
<p id="p-0176" num="0175">The determining whether the data is to be appended further includes at least one of receiving an append instruction with the data, interpreting account information associated with an issuer of the request to store the data, and interpreting directory information of at least one of the data and the existing data. When the data is to be appended, the method continues at step <b>404</b> where the processing module encodes, using an append dispersed storage error coding function, the data to produce a set of encoded append data slices. The encoding the data using the append dispersed storage error coding function includes partitioning the data into data blocks based on size of the data blocks of the existing data, arranging the data blocks of the data into a second plurality of groups of data blocks, wherein a group of data blocks of the second plurality of groups of data blocks includes a same number of data blocks as a group of data blocks of the plurality of groups of data blocks, and on the group of data block by group of data block basis, matrix-multiplying the second plurality of groups of data blocks with the dispersed storage error encoding matrix to produce a second plurality of sets of encoded data slice portions and wherein an encoded append data slice of the set of encoded append data slices includes an encoded data slice portion from each of the second plurality of sets of encoded data slice portions.</p>
<p id="p-0177" num="0176">The method continues at step <b>406</b> where the processing module generates a set of append commands, wherein an append command of the set of append commands includes one or more of an encoded append data slice of the set of encoded append data slices and identity of one of a set of DS units of the DSN memory. The append command further includes at least one of a slice name of a corresponding one of set of encoded data slices, an incremental slice revision level indicator, an offset indicator, and a column identifier of a slice matrix. The method continues at step <b>408</b> where the processing module outputs at least a write threshold number of the set of append commands to at least a write threshold number of the set of DS units.</p>
<p id="p-0178" num="0177">The method continues at step <b>410</b> where the processing module receives second data (e.g., additional data to append) for storage in the DSN memory. The method continues at step <b>412</b> where the processing module determines whether the second data is to be appended to existing appended data stored in the DSN memory, wherein the existing pending data includes the set of encoded data slices and the set of encoded append data slices. When the second data is to be appended, the method continues at step <b>414</b> where the processing module encodes, using the append dispersed storage error coding function, the second data to produce a second set of encoded append data slices. The method continues at step <b>416</b> where the processing module generates a second set of append commands. The method continues at step <b>418</b> where the processing module outputs at least a write threshold number of the second set of append commands to the at least a write threshold number of the set of DS units.</p>
<p id="p-0179" num="0178"><figref idref="DRAWINGS">FIG. 11D</figref> is a flowchart illustrating an example of appending slice portions. The method begins at step <b>430</b> where a processing module (e.g., of a dispersed storage (DS) unit) stores an encoded data slice of a set of encoded data slices, wherein existing data is encoded using a dispersed storage error coding function to produce the set of encoded data slices. The method continues at step <b>432</b> where the processing module receives an append command that includes an encoded append data slice of a set of encoded append data slices and an instruction to append the encoded append data slice to the encoded data slice, wherein data is encoded using an append dispersed storage error coding function to produce the set of encoded append data slices.</p>
<p id="p-0180" num="0179">The method continues at step <b>434</b> where the processing module interprets the append command to identify one or more of a slice name of the encoded append data slice and an incremental revision level indicator. The method continues at step <b>436</b> where the processing module identifies the encoded data slice based on one or more of the slice name and the incremental revision level indicator. The method continues at step <b>438</b> where the processing module appends the encoded append data slice to the encoded data slice to produce the updated encoded data slice. The method continues at step <b>440</b> where the processing module updates storage of the encoded data slice based on the encoded append data slice to produce an updated encoded data slice. The updating storage of the encoded data slice includes identifying the encoded data slice (e.g., by data identifier (ID), by a slice name, by a pillar number, by the incremental revision level indicator), retrieving the encoded data slice to produce a retrieved encoded data slice, appending the encoded append data slice to the retrieved encoded data slice to produce the updated encoded data slice, and storing the updated encoded data slice.</p>
<p id="p-0181" num="0180">The method continues at step <b>442</b> where the processing module updates a slice table to associate the slice name with the updated encoded data slice. The method continues at step <b>444</b> where the processing module receives a second append command that includes a second encoded append data slice of a second set of encoded append data slices and another instruction to append the second encoded append data slice to the updated encoded data slice, wherein second data is encoded using the append dispersed storage error coding function to produce the second set of encoded append data slices. The method continues at step <b>446</b> where the processing module updates storage of the updated encoded data slice based on the second encoded append data slice to produce a second updated encoded data slice.</p>
<p id="p-0182" num="0181"><figref idref="DRAWINGS">FIGS. 12A-E</figref> are schematic block diagrams of another embodiment of the computing system that each include a dispersed storage (DS) processing unit <b>16</b> and DS units <b>1</b>-<b>5</b>, wherein each figure of <figref idref="DRAWINGS">FIGS. 12A-E</figref> correspond a step of a Shamir secret share rebuilding scenario. In such a Shamir secret share rebuilding scenario, a first step includes generating and storing a set of Shamir secret shares in DS units <b>1</b>-<b>5</b>, a second step includes determining a Shamir secret share of the set of Shamir secret shares to be rebuilt, a third step includes requesting a decode threshold number of rebuilt Shamir secret share partials, a fourth step includes generating the decode threshold number of rebuilt Shamir secret share partials, and a fifth step includes decoding the decode threshold number of rebuilt Shamir secret share partials to produce a rebuilt Shamir secret share and storing the rebuilt Shamir secret share. The method of operation is discussed in greater detail with reference to <figref idref="DRAWINGS">FIGS. 12A-13B</figref>.</p>
<p id="p-0183" num="0182"><figref idref="DRAWINGS">FIG. 12A</figref> is a schematic block diagram of another embodiment of a computing system of a first step of a Shamir secret share rebuilding scenario, where a dispersed storage (DS) processing unit <b>16</b> utilizes a Shamir shared secret function on a secret to produce a width number of Shamir secret shares <b>1</b>-<b>5</b>. The DS processing unit <b>16</b> sends the width number of Shamir secret shares <b>1</b>-<b>5</b> to corresponding DS units <b>1</b>-<b>5</b> for storage therein.</p>
<p id="p-0184" num="0183"><figref idref="DRAWINGS">FIG. 12B</figref> is a schematic block diagram of another embodiment of a computing system of a second step of a Shamir secret sharing rebuilding scenario, where a dispersed storage (DS) processing unit <b>16</b> determines a Shamir secret share to be rebuilt. For example, the processing module sends a width number of Shamir secret share retrieval requests to a width number of DS units <b>1</b>-<b>5</b> and determines that a Shamir secret share corresponding to DS unit <b>2</b> is missing based on receiving Shamir secret shares corresponding to DS units <b>1</b>, and DS units <b>3</b>-<b>5</b> (e.g., and not from DS unit <b>2</b>).</p>
<p id="p-0185" num="0184"><figref idref="DRAWINGS">FIG. 12C</figref> is a schematic block diagram of another embodiment of a computing system of a third step of a Shamir secret sharing rebuilding scenario, where a dispersed storage (DS) processing unit <b>16</b> generates a decode threshold number of partial request messages and sends the decode threshold number of partial request messages to a decode threshold number of DS units associated with other Shamir secret shares. The partial request message of the decode threshold number of partial request messages includes an identifier of a Shamir secret share to be rebuilt. For example, the processing module generates the decode threshold number of partial request messages to include an identifier of <b>2</b> for the Shamir secret share to be rebuilt and sends the decode threshold number of partial request messages to the decode threshold number of DS units including DS units <b>1</b>, <b>3</b>, and <b>4</b>.</p>
<p id="p-0186" num="0185"><figref idref="DRAWINGS">FIG. 12D</figref> is a schematic block diagram of another embodiment of a computing system of a fourth step of a Shamir secret sharing rebuilding scenario, where each dispersed storage (DS) unit of a decode threshold number of DS units generates a rebuilt share partial based on an identifier of a Shamir secret share to be rebuilt and a corresponding local Shamir secret share and sends the rebuilt share partial to a DS processing unit <b>16</b>. For example, DS unit <b>1</b> generates the rebuilt share partial <b>2</b>-<b>1</b> based on an identifier of <b>2</b> for the Shamir secret share to be rebuilt and a corresponding local Shamir secret share <b>1</b> and sends the rebuilt share partial <b>2</b>-<b>1</b> to the DS processing unit <b>16</b>, DS unit <b>3</b> generates the rebuilt share partial <b>2</b>-<b>3</b> based on the identifier of <b>2</b> for the Shamir secret share to be rebuilt and a corresponding local Shamir secret share <b>3</b> and sends the rebuilt share partial <b>2</b>-<b>3</b> to the DS processing unit <b>16</b>, and DS unit <b>4</b> generates the rebuilt share partial <b>2</b>-<b>4</b> based on the identifier of <b>2</b> for the Shamir secret share to be rebuilt and a corresponding local Shamir secret share <b>4</b> and sends the rebuilt share partial <b>2</b>-<b>4</b> to the DS processing unit <b>16</b>.</p>
<p id="p-0187" num="0186"><figref idref="DRAWINGS">FIG. 12E</figref> is a schematic block diagram of another embodiment of a computing system of a fifth step of a Shamir secret sharing rebuilding scenario, where a dispersed storage (DS) processing unit <b>16</b> receives a decode threshold number of rebuilt share partials, decodes the decode threshold number of rebuilt share partials to produce a rebuilt Shamir secret share, and stores the rebuilt Shamir secret share in a DS unit corresponding to a Shamir secret share to be rebuilt. For example, the processing unit <b>16</b> receives rebuilt share partials <b>2</b>-<b>1</b>, <b>2</b>-<b>3</b>, and <b>2</b>-<b>4</b>, decodes the rebuilt share partials <b>2</b>-<b>1</b>, <b>2</b>-<b>3</b>, and <b>2</b>-<b>4</b> to produce rebuilt Shamir secret share <b>2</b>, and sends the rebuilt Shamir secret share <b>2</b> to DS unit <b>2</b> for storage therein.</p>
<p id="p-0188" num="0187"><figref idref="DRAWINGS">FIG. 13A</figref> is a flowchart illustrating an example of rebuilding a Shamir secret share. The method begins with step <b>450</b> where a processing module (e.g., of a dispersed storage (DS) processing unit) determines a Shamir secret share to be rebuilt. The determination may be based on one or more of a query, a Shamir secret share retrieval sequence, an error message, and a decode result. The method continues at step <b>452</b> where the processing module determines which other Shamir secret shares to utilize in a rebuilding function. The determination may be based on one or more of a DS unit status indicator, a decode threshold, a decode result, a retrieval result, a query, and a message. For example, the processing module determines other Shamir secret shares to utilize in the rebuilding function to include DS units <b>1</b>, <b>3</b>, and <b>4</b> when the decode threshold is three and a corresponding Shamir secret share has been successfully retrieved from each DS unit of DS units <b>1</b>, <b>3</b>, and <b>4</b>.</p>
<p id="p-0189" num="0188">The method continues at step <b>454</b> where the processing module generates a decode threshold number of partial request messages. The messages include one or more of an identifier (ID) associated with the Shamir secret share to be rebuilt, which other Shamir secret shares are being utilized in the rebuilding function, and encoding matrix, a square matrix, an inverted square matrix, and a row of the matrix corresponding to the Shamir secret share to be rebuilt (e.g., wrote <b>2</b> for Shamir secret share <b>2</b> to be rebuilt). The method continues at step <b>456</b> where the processing module sends the decode threshold number of partial request messages to a decode threshold number of DS units associated with the other Shamir secret shares. For example, the processing module sends a partial request message that includes a request for rebuilt share partial <b>2</b>-<b>1</b> to DS unit <b>1</b>, the processing module sends a partial request message that includes a request for rebuilt share partial <b>2</b>-<b>3</b> to DS unit <b>3</b>, and the processing module sends a partial request message that includes a request for rebuilt share partial <b>2</b>-<b>4</b> to DS unit <b>4</b>.</p>
<p id="p-0190" num="0189">The method continues at step <b>458</b> where the processing module receives a decode threshold number of rebuilt share partials. For example, the processing module receives rebuilt share partial <b>2</b>-<b>1</b>, <b>2</b>-<b>3</b>, and <b>2</b>-<b>4</b>. The method continues at step <b>460</b> where the processing module decodes the decode threshold number of rebuilt share partials to produce a rebuilt Shamir secret share. For example, the processing module decodes the decode threshold number of rebuilt share partials <b>2</b>-<b>1</b>, <b>2</b>-<b>3</b>, and <b>2</b>-<b>4</b> in accordance with the formula rebuilt Shamir secret share <b>2</b>=(rebuilt share partial <b>2</b>-<b>1</b>) exclusive OR (XOR) (rebuilt share partial <b>2</b>-<b>3</b>) XOR (rebuilt share partial <b>2</b>-<b>4</b>). The method continues at step <b>462</b> where the processing module outputs the rebuilt Shamir secret share to a DS unit for storage therein, wherein the DS unit is associated with the Shamir secret share to be rebuilt. For example, the processing module sends rebuilt Shamir secret share <b>2</b> to DS unit <b>2</b> for storage therein.</p>
<p id="p-0191" num="0190"><figref idref="DRAWINGS">FIG. 13B</figref> is a flowchart illustrating an example of generating a rebuilt share partial. The method begins at step <b>464</b> where processing module (e.g., of a dispersed (DS) storage unit) receives a partial request message to provide a rebuilt share partial. The method continues at step <b>466</b> where the processing module generates an inverted square matrix. The generation includes one or more of receiving the inverted square matrix, obtaining an encoding matrix (e.g., extracted from the request message, retrieved), selecting a decode threshold number of rows of the encoding matrix to produce a square matrix (e.g., corresponding to other Shamir secret shares to be utilized in a rebuilding function), and inverting the square matrix to produce the inverted square matrix.</p>
<p id="p-0192" num="0191">The method continues at step <b>468</b> where the processing module retrieves a local Shamir secret share. The retrieving includes identifying the local Shamir secret share to produce a local Shamir secret share identifier (ID) based on the partial request message and retrieving the local Shamir secret share based on the local Shamir secret share ID. For example, the processing module identifies the local Shamir secret share as local Shamir secret share <b>1</b> based on receiving a request message for rebuilt share partial <b>2</b>-<b>1</b> and retrieves Shamir secret share <b>1</b> from a local memory of a dispersed storage (DS) unit.</p>
<p id="p-0193" num="0192">The method continues at step <b>470</b> where the processing module obtains a row of a full encoding matrix associated with the Shamir secret share to be rebuilt as a target row. The obtaining may include one or more of receiving the target row in the partial request message and extracting the target row from the full encoding matrix based on an ID of the Shamir secret share to be rebuilt. The processing module may obtain the full encoding matrix based on one or more of extracting the full encoding matrix from the partial request message and retrieving the full encoding matrix. For example, the processing module extracts row <b>2</b> of the full encoding matrix when the request message includes a request for rebuilt share partial <b>2</b>-<b>1</b>.</p>
<p id="p-0194" num="0193">The method continues at step <b>472</b> where the processing module generates the rebuilt share partial based on the inverted square matrix, the local Shamir secret share, and the target row. For example, the processing module multiplies the inverted square matrix by the local Shamir secret (e.g., in matrix form wherein the local Shamir secret share is placed in a row corresponding to an ID of the local Shamir secret share) by the target row to produce the rebuilt share partial. The method continues at step <b>474</b> where the processing module outputs the rebuilt share partial. For example, the processing module sends the rebuilt share partial to a requesting entity (e.g. a DS processing unit), associated with the partial request message.</p>
<p id="p-0195" num="0194"><figref idref="DRAWINGS">FIGS. 14A-D</figref> are schematic block diagrams of another embodiment of a computing system that each include a dispersed storage (DS) processing unit <b>16</b> and DS units <b>1</b>-<b>6</b>, wherein each figure of <figref idref="DRAWINGS">FIGS. 14A-D</figref> correspond a step of a data update scenario. In such a data update scenario, a first step includes the DS processing unit <b>16</b> generating and storing data as data <b>1</b>-<b>4</b> and parity of the data as parity <b>5</b>-<b>6</b> in DS units <b>1</b>-<b>6</b> when an associated encoding function includes a decode threshold of 4 and a width of 6, a second step includes the DS processing unit <b>16</b> storing updated data as updated data <b>2</b> by sending updated data <b>2</b> to DS unit <b>2</b> for storage therein, a third step includes DS unit <b>2</b> generating delta parity <b>5</b> and delta parity <b>6</b> based on data <b>2</b> and updated data <b>2</b> and sending delta parity <b>5</b> and delta parity <b>6</b> to DS processing unit <b>16</b>, and a fourth step includes the DS processing unit <b>16</b> forwarding delta parity <b>5</b> to DS unit <b>5</b> and delta parity <b>6</b> to DS unit <b>6</b>, DS unit <b>5</b> generates and stores updated parity <b>5</b> based on parity <b>5</b> and delta parity <b>5</b>, and DS unit <b>6</b> generates and stores updated parity <b>6</b> based on parity <b>6</b> and delta parity <b>6</b>.</p>
<p id="p-0196" num="0195">Alternatively, the third step includes the DS processing unit <b>16</b> retrieving data <b>2</b> from DS unit <b>2</b> and generating delta parity <b>5</b> and delta parity <b>6</b> based on data <b>2</b> and updated data <b>2</b>. Alternatively, the fourth step includes the DS processing unit <b>16</b> retrieving parity <b>5</b> from DS unit <b>5</b> and retrieving parity <b>6</b> from DS unit <b>6</b>, generating updated parity <b>5</b> and updated parity <b>6</b>, and sending updated parity <b>5</b> to DS unit <b>5</b> for storage therein and sending updated parity <b>6</b> to DS unit <b>6</b> for storage therein. The method of operation is discussed in greater detail with reference to <figref idref="DRAWINGS">FIGS. 14A-15C</figref>.</p>
<p id="p-0197" num="0196"><figref idref="DRAWINGS">FIG. 14A</figref> is a schematic block diagram of another embodiment of a computing system of a first step of a data update scenario, where a dispersed storage (DS) processing unit <b>16</b> generates and stores data as data <b>1</b>-<b>4</b> and parity of the data as parity <b>5</b>-<b>6</b> in DS units <b>1</b>-<b>6</b>. The generation of data <b>1</b>-<b>4</b> and parity <b>5</b>-<b>6</b> is in accordance with a data encoding function, wherein the data encoding function includes utilizing an encoding matrix. In a first embodiment, the encoding matrix includes a unity square matrix (e.g., a first decode threshold number of rows each includes a one in a single column of a decode threshold number of columns producing a diagonal string of one's) and includes a width number minus the decode threshold number of parity rows. The parity rows include encoding matrix entries in accordance with the data encoding function. In a second embodiment, encoding matrix does not include the unity square matrix.</p>
<p id="p-0198" num="0197">The generation of data <b>1</b>-<b>4</b> and parity <b>5</b>-<b>6</b> includes matrix multiplying the encoding matrix by the data to produce a width number of encoded data slices, wherein encoded data slices <b>1</b>-<b>4</b> produce data <b>1</b>-<b>4</b> and encoded data slices <b>5</b>-<b>6</b> produce parity <b>5</b>-<b>6</b>. The storing of the data includes sending data <b>1</b> to DS unit <b>1</b> for storage therein, sending data <b>2</b> to DS unit <b>2</b> for storage therein, sending data <b>3</b> to DS unit <b>3</b> for storage therein, sending data <b>4</b> to DS unit <b>4</b> for storage therein, sending parity <b>5</b> to DS unit <b>5</b> for storage therein, and sending parity <b>6</b> to DS unit <b>6</b> for storage therein.</p>
<p id="p-0199" num="0198"><figref idref="DRAWINGS">FIG. 14B</figref> is a schematic block diagram of another embodiment of a computing system of a second step of a data update scenario, where a dispersed storage (DS) processing unit <b>16</b> obtains an updated portion of data to produce updated data and sends an updated data storage request message to a corresponding DS unit to replace a corresponding portion of the data. The obtaining may include receiving the updated portion of data, receiving data that includes the updated portion of data, and analyzing data to identify the updated portion of data. The storage request message may include one or more of the updated data, encoding information, and a request for delta parity information. The encoding information may include one or more of an encoding matrix, a width, and a decode threshold. For example, the DS processing unit <b>16</b> receives an updated portion of data corresponding to a second portion of data to produce updated data <b>2</b> and sends a storage request message to DS unit <b>2</b> that includes the updated data <b>2</b>.</p>
<p id="p-0200" num="0199"><figref idref="DRAWINGS">FIG. 14C</figref> is a schematic block diagram of another embodiment of a computing system of a third step of a data update scenario, where a dispersed storage (DS) unit generates delta parity information based on updated data, data (e.g., previous data which is being replaced by the updated data), and an encoding function and sends the delta parity information to a corresponding DS processing unit <b>16</b>. Alternatively, the DS unit directly sends the delta parity information to one or more other DS units associated with storage of parity information. For example, DS unit <b>2</b> generates the delta parity information to include delta parity <b>5</b> and delta parity <b>6</b> based on updated data <b>2</b>, data <b>2</b>, and the encoding function and sends the delta parity information to the DS processing unit <b>16</b>. For instance, DS unit <b>2</b> generates the delta parity information in accordance with formulas delta parity <b>5</b>=rebuilt partial (for parity <b>5</b> based on updated data <b>2</b>)&#x2212;rebuilt partial (for parity <b>5</b> based on data <b>2</b>) and delta parity <b>6</b>=rebuilt partial (for parity <b>6</b> based on updated data <b>2</b>)&#x2212;rebuilt partial (for parity <b>6</b> based on data <b>2</b>) and sends the delta parity information to a corresponding DS processing unit <b>16</b>. The DS unit <b>2</b> generates such a rebuilt partial (for parity <b>5</b> based on updated data <b>2</b>) by multiplying an inverted square matrix of a unity matrix of an encoding matrix of the encoding function by a data matrix including the updated data <b>2</b> by a row of the encoding matrix corresponding to parity <b>5</b>.</p>
<p id="p-0201" num="0200"><figref idref="DRAWINGS">FIG. 14D</figref> is a schematic block diagram of another embodiment of a computing system of a fourth step of a data update scenario, where a dispersed storage (DS) processing unit <b>16</b> outputs delta parity information to one or more DS units associated with storing parity information and each of the one or more DS units generates and stores updated parity information based on the parity information, stored parity information, and encoding information. For example, the DS processing unit <b>16</b> outputs delta parity <b>5</b> to DS unit <b>5</b> and delta parity <b>6</b> to DS unit <b>6</b>. DS unit <b>5</b> retrieves parity <b>5</b> (e.g., from a local DS unit <b>5</b> memory), wherein parity <b>5</b> is associated with updated parity <b>5</b>. DS unit <b>5</b> generates updated parity <b>5</b> in accordance with a formula updated parity <b>5</b>=parity <b>5</b>+delta parity <b>5</b>. DS unit <b>5</b> stores updated parity <b>5</b> (e.g., in the local memory), replacing parity <b>5</b>. DS unit <b>6</b> retrieves parity <b>6</b> (e.g., from a local DS unit <b>6</b> memory), wherein parity <b>6</b> is associated with updated parity <b>5</b>. DS unit <b>6</b> generates updated parity <b>6</b> in accordance with a formula updated parity <b>6</b>=parity <b>6</b>+delta parity <b>6</b>. DS unit <b>6</b> stores updated parity <b>6</b> (e.g., in the local DS unit <b>6</b> memory), replacing parity <b>6</b>.</p>
<p id="p-0202" num="0201"><figref idref="DRAWINGS">FIG. 15A</figref> is a schematic block diagram of an embodiment of a dispersed storage system that includes an update slice module <b>480</b>, a generate error recovery information module <b>482</b>, and an update error recovery information module <b>484</b>. The update slice module <b>480</b>, when operable within a computing device, causes the computing device to update an encoded data slice <b>490</b> of a set of encoded data slices to produce an updated encoded data slice <b>486</b>, wherein data is encoded in accordance with a dispersed storage error coding function to produce the set of encoded data slices and wherein at least some of the encoded data slices of the set of encoded data slices include error recovery information. For example, the update slice module <b>480</b> receives updated data, determines an identity of the encoded data slice <b>490</b> based on at least one difference between the data and the updated data, and generates the updated encoded data slice <b>486</b> based on the difference and in accordance with the dispersed storage error coding function.</p>
<p id="p-0203" num="0202">The generate error recovery information module <b>482</b>, when operable within a second computing device, causes the second computing device to, for each one of the at least some of the encoded data slices that include error recovery information, generate partial error recovery information based on one or more of: the encoded data slice <b>490</b>, the updated encoded data slice <b>486</b>, update information, and the dispersed storage error coding function to produce a collection of partial error recovery information <b>488</b>. The update information includes one or more of a slice name, a revision number of the updated encoded data slice, a generator matrix, an encoding matrix, a pillar number of the updated encoded data slice.</p>
<p id="p-0204" num="0203">The generate error recovery information module <b>482</b> functions to generate one of the collection of partial error recovery information by generating a first term (e.g., a partially encoded data slice utilizing the updated encoded data source <b>486</b>) of a corresponding one of the at least some of the encoded data slices that includes the error recovery information based on the updated encoded data slice <b>486</b> in accordance with the dispersed storage error coding function, generating a second term (e.g., another partially encoded data slice utilizing the encoded data slice <b>490</b>) of the corresponding one of the at least some of the encoded data slices that includes the error recovery information based on the encoded data slice <b>490</b> in accordance with the dispersed storage error coding function, and performing a mathematical function on the first and second terms to produce the one of the collection of partial error recovery information. For example, the generate error recovery information module <b>482</b> adds the first and second terms to produce the one of the collection of partial error recovery information. As another example, the generate error recovery information module <b>482</b> performs an exclusive OR logical function on the first and second terms to produce the one of the collection of partial error recovery information.</p>
<p id="p-0205" num="0204">The generate error recovery information module <b>482</b> functions to generate the first term by obtaining an encoding matrix of the dispersed storage error coding function (e.g., retrieve from local memory, receive), reducing the encoding matrix to produce a square matrix that excludes one or more rows including a row associated with the corresponding one of the at least some of the encoded data slices that includes the error recovery information (e.g., alternatively may receive the square matrix), inverting the square matrix to produce an inverted matrix (e.g., alternately may receive the inverted matrix), matrix multiplying the inverted matrix by the updated encoded data slice <b>486</b> to produce a vector, and matrix multiplying the vector by a row of the encoding matrix corresponding to the corresponding one of the at least some of the encoded data slices that includes the error recovery information to produce the first term. The generate error recovery information module <b>482</b> functions to generate the second term by matrix multiplying the inverted matrix by the encoded data slice <b>490</b> to produce a second vector and matrix multiplying the second vector by the row of the encoding matrix corresponding to the corresponding one of the at least some of the encoded data slices that includes the error recovery information to produce the second term.</p>
<p id="p-0206" num="0205">The update error recovery information module <b>484</b>, when operable within the first or the second computing device, causes the first or the second computing device to update the error recovery information of an encoded data slice <b>492</b> of the at least some of the encoded data slices that include error recovery information based on a corresponding one of the collection of partial error recovery information <b>488</b> to produce an encoded data slice that includes updated error recovery information <b>494</b>. The update error recovery information module <b>484</b> functions to update the error recovery information by executing a mathematical function on the encoded data slice that includes the error recovery information <b>492</b> and the corresponding one of the collection of partial error recovery information <b>488</b> to produce the encoded data slice that includes updated error recovery information <b>494</b>. For example, update error recovery information module <b>484</b> adds the encoded data slice that includes the error recovery information <b>492</b> and the corresponding one of the collection of partial error recovery information <b>488</b> to produce the encoded data slice that includes updated error recovery information <b>494</b>. As another example, update error recovery information module <b>484</b> performs an exclusive OR function on the encoded data slice that includes the error recovery information <b>492</b> and the corresponding one of the collection of partial error recovery information <b>488</b> to produce the encoded data slice that includes updated error recovery information <b>494</b>.</p>
<p id="p-0207" num="0206"><figref idref="DRAWINGS">FIG. 15B</figref> is a schematic block diagram of another embodiment of a computing system that includes a dispersed storage (DS) processing unit <b>16</b>, a computing device <b>501</b> (e.g., a DS unit <b>22</b>, a user device, another DS processing unit), and a set of DS units <b>22</b>. The computing device <b>501</b> includes a DS module <b>500</b> and a memory <b>502</b>. The memory <b>502</b> may be implemented utilizing one or more memory devices, wherein each memory device includes at least one of a magnetic drive memory, a solid-state memory, and an optical drive memory. The DS module <b>500</b> includes a receive slice module <b>504</b>, a generate error recovery information module <b>482</b>, and an output error recovery information module <b>506</b>.</p>
<p id="p-0208" num="0207">The receive slice module <b>504</b>, when operable within the computing device <b>501</b>, causes the computing device to facilitate receiving an updated encoded data slice <b>486</b>, wherein the updated encoded data slice <b>486</b> is an updated version of an encoded data slice <b>490</b> of a set of encoded data slices, wherein data is encoded in accordance with a dispersed storage error coding function to produce the set of encoded data slices and wherein at least some of the encoded data slices of the set of encoded data slices include error recovery information. The receive slice module <b>504</b> is further operable to facilitate storing the updated encoded data slice <b>486</b> (e.g., in memory <b>502</b>).</p>
<p id="p-0209" num="0208">The generate error recovery information module <b>482</b>, when operable within the computing device <b>501</b>, causes the computing device to, for each one of the at least some of the encoded data slices that include error recovery information, generate partial error recovery information <b>508</b> based on one or more of: the encoded data slice <b>490</b>, the updated encoded data slice <b>486</b>, update information, and the dispersed storage error coding function to produce a collection of partial error recovery information <b>488</b>. The update information includes one or more of a slice name, a revision number of the updated encoded data slice, a generator matrix, an encoding matrix, a pillar number of the updated encoded data slice. The output error recovery information module <b>506</b>, when operable within the computing device <b>501</b>, causes the computing device to facilitate outputting the collection of partial error recovery information <b>488</b> for storage in at least some of the set of DS units <b>22</b>, which store the at least some of the encoded data slices that include error recovery information. For example, the output error recovery information module <b>506</b> outputs partial error recovery information <b>508</b> to a fifth DS unit, wherein the fifth DS unit corresponds to one of the at least some of the encoded data slices of the set of encoded data slices that includes error recovery information and the partial error recovery information <b>508</b> corresponds to the fifth DS unit.</p>
<p id="p-0210" num="0209"><figref idref="DRAWINGS">FIG. 15C</figref> is a flowchart illustrating an example of updating error recovery information. The method begins at step <b>520</b> where a dispersed storage (DS) processing module (e.g., of a DS processing unit) updates an encoded data slice of a set of encoded data slices to produce an updated encoded data slice, wherein data is encoded in accordance with a dispersed storage error coding function to produce the set of encoded data slices and wherein at least some of the encoded data slices of the set of encoded data slices include error recovery information. The method continues at step <b>522</b> where the DS processing module sends the updated encoded data slice to a first DS unit of a set of DS units. The method continues at step <b>524</b> where the DS processing module generates update information to include one or more of: a slice name, a revision number of the updated encoded data slice, a generator matrix, an encoding matrix, a pillar number of the updated encoded data slice. The method continues at step <b>526</b> where the DS processing module sends the update information to the first DS unit.</p>
<p id="p-0211" num="0210">The method continues at step <b>528</b> where the first DS unit stores the updated encoded data slice. In addition, the first DS unit stores the update information when the first DS unit receives the update information. For each one of the at least some of the encoded data slices that include error recovery information, the method continues at step <b>530</b> where the first DS unit generates partial error recovery information based on one or more of: the encoded data slice, the updated encoded data slice, update information, and the dispersed storage error coding function to produce a collection of partial error recovery information. The generating the one of the collection of partial error recovery information includes generating a first term of a corresponding one of the at least some of the encoded data slices that includes the error recovery information based on the updated encoded data slice in accordance with the dispersed storage error coding function, generating a second term of the corresponding one of the at least some of the encoded data slices that includes the error recovery information based on the encoded data slice in accordance with the dispersed storage error coding function, and performing a mathematical function (e.g., subtraction, exclusive OR) on the first and second terms to produce the one of the collection of partial error recovery information.</p>
<p id="p-0212" num="0211">The generating the first term includes obtaining an encoding matrix of the dispersed storage error coding function, reducing the encoding matrix to produce a square matrix that excludes one or more rows including a row associated with the corresponding one of the at least some of the encoded data slices that includes the error recovery information, inverting the square matrix to produce an inverted matrix, matrix multiplying the inverted matrix by the updated encoded data slice to produce a vector, and matrix multiplying the vector by a row of the encoding matrix corresponding to the corresponding one of the at least some of the encoded data slices that includes the error recovery information to produce the first term. The generating the second term includes matrix multiplying the inverted matrix by the encoded data slice to produce a second vector and matrix multiplying the second vector by the row of the encoding matrix corresponding to the corresponding one of the at least some of the encoded data slices that includes the error recovery information to produce the second term.</p>
<p id="p-0213" num="0212">The method continues at step <b>532</b> where the first DS unit outputs the collection of partial error recovery information for storage (e.g., as a portion of updated encoded data slices) in at least some of the set of DS units, which store the at least some of the encoded data slices that include error recovery information. The method continues at step <b>534</b> where one of the at least some of the set of DS units updates the error recovery information of an encoded data slice of the at least some of the encoded data slices that includes the error recovery information based on a corresponding one of the collection of partial error recovery information to produce an encoded data slice that includes updated error recovery information. The updating the error recovery information includes executing a mathematical function (e.g., summing, exclusive OR) on the encoded data slice that includes the error recovery information and the corresponding one of the collection of partial error recovery information to produce the encoded data slice that includes updated error recovery information. Next, the one of the at least some of the set of DS units stores the encoded data slice that includes updated error recovery information.</p>
<p id="p-0214" num="0213"><figref idref="DRAWINGS">FIG. 16</figref> is a diagram illustrating an example of a directory file structure that includes directory files <b>1</b>-<b>3</b>. Alternatively, any number of directory files may be included. The directory files <b>1</b>-<b>3</b> may be utilized to affiliate file system filenames to storage locations within a dispersed storage network (DSN) memory. The storage location may be specified by a source name within the DSN memory. The source name may include one or more of a vault identifier (ID), a generation ID, and an object number. The object number may include a random number that is permanently assigned to data to be stored in the DSN memory upon a first storage sequence of the data. A vault source name includes a source name and a data segment ID.</p>
<p id="p-0215" num="0214">Each directory file of the directory files <b>1</b>-<b>3</b> may be stored as encoded directory slices in the DSN memory at a location affiliated with the directory file. For example, directory file <b>1</b> is dispersed storage error encoded to produce one or more sets of encoded directory <b>1</b> slices that are stored in the DSN memory at location source name <b>1</b> (e.g., B<b>530</b>). As another example, directory file <b>2</b> is dispersed storage error encoded to produce one or more sets of encoded directory <b>2</b> slices that are stored in the DSN memory at location source name <b>2</b> (e.g., <b>42</b>DA). As yet another example, directory file <b>3</b> is dispersed storage error encoded to produce one or more sets of encoded directory <b>3</b> slices that are stored in the DSN memory at location source name <b>3</b> (e.g., E<b>9</b>C<b>2</b>).</p>
<p id="p-0216" num="0215">Each directory file of the directory files <b>1</b>-<b>3</b> includes a file name field <b>540</b>, a file source name field <b>542</b>, a snapshot field <b>544</b>, an extended data field <b>546</b>, and a linked directory source names field <b>548</b>. Each field of the directory file includes one or more entries, wherein each entry of the one or more entries per field is associated with an entry within each other field of a common row of the directory file. The file name field <b>540</b> includes one or more entries, wherein each entry of the one or more entries includes a file system file name including at least one of a root directory name, a directory name, and a file name. For example, a directory name entry of the file name field includes /lists and a file name entry of the file name field includes /file.doc and /pic2.jpg.</p>
<p id="p-0217" num="0216">The file source name field <b>542</b> includes one or more entries, wherein each entry of the one or more entries includes a source name of a corresponding entry (e.g., same row) in the file name field. For example, a file source name field entry of B<b>673</b> associated with a file name field entry of /file.doc indicates that the file with file name /file.doc is stored in the DSN memory (e.g., as a plurality of sets of encoded data slices) at a location with a source name of B<b>673</b>. As another example, a file with file name /pic2.jpg is stored in the DSN memory at a location with a source name of <b>7</b>AA<b>7</b>. As yet another example, a directory file with directory name /lists is stored in the DSN memory at a location with a source name of <b>90</b>DE. Accessing such a directory file associated with /lists may be utilized to access one or more files under the directory /lists. For example, accessing the directory file stored in the DSN memory at the location with the source name of <b>90</b>DE may be utilized to access a file associated with a file name of /lists/summary.doc. As another example, accessing the directory file stored in the DSN memory at the location with the source name of <b>90</b>DE may be utilized to access a sub-directory of lists/documents and accessing the sub-directory of lists/documents may be utilized access a file associated with a file name of lists/documents/reportA.doc. As such, the directory file structure may be associated with any number of levels (e.g., sub-directories).</p>
<p id="p-0218" num="0217">The snapshot field <b>544</b> includes one or more entries, wherein each entry the one or more entries includes a snapshot ID of a corresponding entry (e.g., same row) in the file name field. For example, a snapshot field entry of <b>1</b> associated with the file name field entry of /file.doc indicates that the file with file name /file.doc is associated with a snapshot ID of <b>1</b>. As another example, the file with file name /pic2.jpg is associated with a snapshot ID of <b>2</b>. As yet another example, the directory file with directory name /lists is associated with a snapshot ID of <b>5</b>.</p>
<p id="p-0219" num="0218">The extended data field <b>546</b> includes one or more entries, wherein each entry of the one or more entries includes at least one of a timestamp, a size indicator, a segmentation allocation table (SAT) vault source name, metadata, and a content portion associated with a corresponding entry (e.g., same row) in the file name field. For example, an extended data field entry of <b>329</b>d associated with the file name field entry of /file.doc indicates that the file with file name /file.doc is associated with an extended data value of <b>329</b>d. As another example, the file with file name /pic2.jpg is associated with an extended data value of a<b>401</b>. As yet another example, the directory file with directory name /lists is associated with an extended data value of fb<b>79</b>.</p>
<p id="p-0220" num="0219">The linked directory source names field <b>548</b> includes one or more entries, wherein each entry the one or more entries includes zero or more source names of linked directory files associated with a corresponding entry (e.g., same row) in the file name field and/or a corresponding entry in the snapshot field. For example, a linked directory source names field entry of <b>42</b>DA associated with the file name field entry of /file.doc indicates that the file with file name /file.doc and snapshot ID <b>1</b> is associated with a linked directory file with a DSN address of <b>42</b>DA. As another example, the file with file name /pic2.jpg and snapshot ID <b>2</b> is associated with the linked directory file with the DSN address of <b>42</b>DA and is associated with a linked directory file with a DSN address of E<b>9</b>C<b>2</b>. As yet another example, the directory file with directory name /lists is not associated with a linked directory file.</p>
<p id="p-0221" num="0220">The linked directory source name field <b>548</b> provides linkage between two or more portions of the directory file structure. The linkage may be utilized when directory files include affiliated entries. The affiliation includes entries that share common filenames with different snapshot IDs, entries that share common filenames with different revisions, entries of file names that are moved from a first directory to a second directory, and entries of filenames that are cloned from a first directory to a second directory. For example, a second revision of file name /pic2.jpg of a second snapshot included in directory file <b>1</b> is linked to a first revision of file name /pic.jpg of a first snapshot included in directory file <b>2</b> and is linked to a third revision of file name /pic3/jpg of a third snapshot included in directory file <b>3</b>. As another example, a first revision of file name /file.doc of a first snapshot included in directory file <b>1</b> is linked to a second revision of file name /file2.doc of a second snapshot included in directory file <b>2</b>.</p>
<p id="p-0222" num="0221">A request to delete a file may result in deletion of an associated directory file entry and in deletion of encoded data slices associated with the file in accordance with a deletion method. The deletion method may be based on one or more of a snapshot ID associated with a file name of the file from a primary directory file and one or more associated snapshot IDs and corresponding filenames from one or more linked directory files (e.g., utilizing one or more linked directory source names from the primary directory file).</p>
<p id="p-0223" num="0222">For example, a plurality of encoded data slices associated with file name /file2.doc at source name B<b>775</b> are deleted, a plurality of encoded data slices associated with file name /file.doc at source name B<b>673</b> are deleted, a directory file <b>2</b> entry associated with file name /file2.doc is deleted, and a directory file <b>1</b> entry associated with file name /file.doc is deleted when a request is received to delete the file associated with the file name /file2.doc since file name/file2.doc is associated with a snapshot ID of <b>2</b>, only one linked directory exists (e.g., directory file <b>1</b>), an associated entry of linked directory file <b>1</b> for file name /file.doc is associated with a snapshot ID of <b>1</b> (e.g., older), and the deletion method specifies to delete older snapshots when a newer snapshot is deleted.</p>
<p id="p-0224" num="0223">As another example, the directory file <b>1</b> entry associated with file name /file.doc is deleted when a request is received to delete the file associated with the file name /file.doc since file name/file.doc is associated with a snapshot ID of <b>1</b>, only one linked directory exists (e.g., directory file <b>2</b>), an associated entry of linked directory file <b>2</b> for file name /file2.doc is associated with a snapshot ID of <b>2</b> (e.g., newer), and the deletion method specifies to not delete newer snapshots and associated older snapshots one and older snapshot is deleted. The method to process a request to delete a file is discussed in greater detail with reference to <figref idref="DRAWINGS">FIG. 17</figref>.</p>
<p id="p-0225" num="0224"><figref idref="DRAWINGS">FIG. 17</figref> is a flowchart illustrating an example of deleting a snapshot. The method begins at step <b>550</b> where a processing module receives a delete snapshot request. The delete snapshot request includes one or more of a snapshot identifier (ID), a file name, a primary directory source name, and a vault ID. The method continues at step <b>552</b> where the processing module accesses an entry of a primary directory corresponding to the snapshot ID. The accessing includes one or more of obtaining (e.g., receiving, traversing a directory structure, a query) a source name of the primary directory, retrieving at least one set of encoded primary directory slices from a dispersed storage network (DSN) memory, dispersed storage error decoding the at least one set of encoded primary directory slices to produce a primary directory file, identifying an entry of the primary directory file corresponding to the snapshot ID and/or the file name, and extracting the entry of the primary directory file.</p>
<p id="p-0226" num="0225">The method continues at step <b>554</b> where the processing module determines whether there are one or more linked secondary directories. The determination may be based on accessing a linked directory source names field of the entry of the primary directory file to determine whether at least one linked directory source name is present. The method branches to step <b>562</b> when the processing module determines that there is not one or more linked secondary directories (e.g., no linked directory source name is present). The method continues to step <b>556</b> when the processing module determines that there is one or more linked secondary directories.</p>
<p id="p-0227" num="0226">The method continues at step <b>556</b> where the processing module accesses each of the one or more linked secondary directories. The accessing includes utilizing the at least one linked directory source name to retrieve at least one set of encoded secondary directory slices from the DSN memory, dispersed storage error decoding the at least one set of encoded secondary directory slices to produce one or more secondary directory files, identifying an entry of each secondary directory file of the one or more secondary directory files corresponding to the snapshot ID and/or the file name, and extracting the entry of each secondary directory file of the one or more secondary directory files.</p>
<p id="p-0228" num="0227">The method continues at step <b>558</b> where the processing module removes a source name reference of the primary directory from each of the linked secondary directories. The removing includes deleting the source name of the primary directory from a linked directory source names field of each secondary directory file of the one or more secondary directory files, dispersed storage error encoding each secondary directory file to produce one or more sets of encoded secondary directory slices, and storing the one or more sets of encoded secondary directory slices in the DSN memory utilizing the at least one linked directory source name.</p>
<p id="p-0229" num="0228">The method continues at step <b>560</b> where the processing module determines whether there is at least one newer snapshot. The determination may be based on extracting a snapshot ID entry from a snapshot of each entry of each secondary directory file of the one or more secondary directory files and comparing each snapshot ID entry to the snapshot ID of the primary directory. The processing module determines that there is at least one newer snapshot when at least one snapshot ID entry is greater than the snapshot ID of the primary directory. The method branches to step <b>564</b> when the processing module determines that there is at least one newer snapshot. The method continues to step <b>562</b> when the processing module determines that there is not at least one newer snapshot.</p>
<p id="p-0230" num="0229">The method continues at step <b>562</b> where the processing module deletes the data file associated with the snapshot ID. The deleting includes extracting a source name of the data file from the entry of the primary directory file and outputting one or more delete encoded data slice messages to the DSN memory utilizing the source name of the data file such that a plurality of sets of encoded data slices associated with the data file and the snapshot ID are deleted from the DSN memory.</p>
<p id="p-0231" num="0230">The method continues at step <b>564</b> where the processing module deletes the entry of the primary directory corresponding to the snapshot ID. The deleting includes deleting the entry of the primary directory file to produce a modified primary directory file, dispersed storage error encoding the modified primary directory file to produce at least one set of encoded modified primary directory slices, and outputting the at least one set of encoded modified primary directory slices to the DSN memory for storage therein utilizing the source name of the primary directory.</p>
<p id="p-0232" num="0231"><figref idref="DRAWINGS">FIG. 18</figref> is a diagram illustrating another example of a directory file structure that includes directory files <b>1</b>-<b>2</b>, segment allocation tables (SAT) <b>1</b>-<b>2</b>, a plurality of data segments <b>1</b>.<b>11</b>, <b>1</b>.<b>12</b> etc., and a plurality of data segments <b>2</b>.<b>11</b>, <b>2</b>.<b>12</b> etc. Alternatively, any number of directory files, SATs, and data segments may be included. The directory files <b>1</b>-<b>2</b> may be utilized to affiliate file system filenames to storage locations within a dispersed storage network (DSN) memory. The storage location may be specified by a source name and/or a vault source name within the DSN memory.</p>
<p id="p-0233" num="0232">Each directory file of the directory files <b>1</b>-<b>2</b> may be stored as encoded directory slices in the DSN memory at a location affiliated with the directory file. For example, directory file <b>1</b> is dispersed storage error encoded to produce one or more sets of encoded directory <b>1</b> slices that are stored in the DSN memory at location source name <b>1</b> (e.g., B<b>530</b>). As another example, directory file <b>2</b> is dispersed storage error encoded to produce one or more sets of encoded directory <b>2</b> slices that are stored in the DSN memory at location source name <b>2</b> (e.g., <b>42</b>DA).</p>
<p id="p-0234" num="0233">Each directory file of the directory files <b>1</b>-<b>2</b> includes a file name field <b>540</b>, a snapshot field <b>544</b>, an extended data field <b>546</b>, a linked directory source names field <b>548</b>, and a SAT source name field <b>566</b>. Each field of the directory file includes one or more entries, wherein each entry of the one or more entries per field is associated with an entry within each other field of a common row of the directory file. The file name field <b>540</b> includes one or more entries, wherein each entry of the one or more entries includes a file system file name including at least one of a root directory name, a directory name, and a file name. For example, a directory name entry of the file name field includes /lists and a file name entry of the file name field includes /file.doc and /pic2.jpg.</p>
<p id="p-0235" num="0234">The snapshot field <b>544</b> includes one or more entries, wherein each entry the one or more entries includes a snapshot ID of a corresponding entry (e.g., same row) in the file name field. For example, a snapshot field entry of <b>1</b> associated with the file name field entry of /file.doc indicates that the file with file name /file.doc is associated with a snapshot ID of <b>1</b>. As another example, the file with file name /pic2.jpg is associated with a snapshot ID of <b>2</b>. As yet another example, the directory file with directory name /lists is associated with a snapshot ID of <b>5</b>.</p>
<p id="p-0236" num="0235">The extended data field <b>546</b> includes one or more entries, wherein each entry of the one or more entries includes at least one of a timestamp, a size indicator, metadata, and a content portion associated with a corresponding entry (e.g., same row) in the file name field. For example, an extended data field entry of <b>329</b>d associated with the file name field entry of /file.doc indicates that the file with file name /file.doc is associated with an extended data value of <b>329</b>d. As another example, the file with file name /pic2.jpg is associated with an extended data value of a<b>401</b>. As yet another example, the directory file with directory name /lists is associated with an extended data value of fb<b>79</b>.</p>
<p id="p-0237" num="0236">The linked directory source names field <b>548</b> includes one or more entries, wherein each entry the one or more entries includes zero or more source names of linked directory files associated with a corresponding entry (e.g., same row) in the file name field and/or a corresponding entry in the snapshot field. For example, a linked directory source names field entry of <b>42</b>DA associated with the file name field entry of /file.doc indicates that the file with file name /file.doc and snapshot ID <b>1</b> is associated with a linked directory file with a DSN address of <b>42</b>DA. As another example, the file with file name /pic2.jpg and snapshot ID <b>2</b> is associated with the linked directory file with the DSN address of <b>42</b>DA. As yet another example, the directory file with directory name /lists is not associated with a linked directory file.</p>
<p id="p-0238" num="0237">The linked directory source name field <b>548</b> further provides linkage between two or more portions of the directory file structure. The linkage may be utilized when directory files include affiliated entries. The affiliation includes entries that share common filenames with different snapshot IDs, entries that share common filenames with different revisions, entries of file names that are moved from a first directory to a second directory, and entries of filenames that are cloned from a first directory to a second directory. For example, a second revision of file name /pic2.jpg of a second snapshot included in directory file <b>1</b> is linked to a first revision of file name /pic.jpg of a first snapshot included in directory file <b>2</b>. As another example, a first revision of file name /file.doc of a first snapshot included in directory file <b>1</b> is linked to a second revision of file name /file2.doc of a second snapshot included in directory file <b>2</b>.</p>
<p id="p-0239" num="0238">The SAT source name field <b>566</b> includes one or more entries, wherein each entry of the one or more entries includes a SAT source name of a corresponding entry (e.g., same row) in the file name field. For example, a SAT source name field entry of B<b>672</b> associated with a file name field entry of /file.doc indicates that the file with file name /file.doc is stored in the DSN memory (e.g., as a plurality of sets of encoded data slices) at a location specified in a SAT <b>1</b>, wherein SAT <b>1</b> is stored in the DSN memory at location B<b>672</b>. As another example, a file with file name /pic2.jpg is stored in the DSN memory at a location specified in a SAT, wherein the SAT is stored in the DSN memory at location <b>7</b>AA<b>6</b>. As yet another example, a directory file with directory name /lists is stored in the DSN memory at a location specified in a SAT, wherein the SAT is stored in the DSN memory at location <b>90</b>DE. Accessing such a directory file associated with /lists may be utilized to access one or more files under the directory /lists. For example, accessing the directory file stored in the DSN memory may be utilized to access a file associated with a file name of /lists/summary.doc. As another example, accessing the directory file stored in the DSN memory may be utilized to access a sub-directory of /lists/documents and accessing the sub-directory of lists/documents may be utilized access a file associated with a file name of lists/documents/reportA.doc. As such, the directory file structure may be associated with any number of levels (e.g., sub-directories).</p>
<p id="p-0240" num="0239">Each SAT of SATs <b>1</b>-<b>2</b> includes an other data field <b>568</b> and a start vault source name field <b>570</b>. Each field of the SAT includes one or more entries, wherein each entry of the one or more entries per field is associated with an entry within each other field of a common row of the SAT. The other data field <b>568</b> includes one or more entries, wherein each entry of the one or more entries includes a data segment size indicator, a segmentation approach (e.g., fixed size, ramping size), and a total length of all segments indicator.</p>
<p id="p-0241" num="0240">The start vault source name field <b>570</b> includes one or more entries, wherein each entry of the one or more entries includes a vault source name associated with a first data segment of an associated file. A first set of encoded data slices corresponding to the first data segment are stored in the DSN memory at a location specified by the vault source name. A second set of encoded data slices corresponding to a second data segment is stored in the DSN memory at a location specified by the vault source name plus offset of one. Each successive set of encoded data slices corresponding to successive data segments is stored in the DSN memory allocation specified by the vault source name plus a segment number offset (e.g., data segment number&#x2212;1). A number of successive sets of encoded data slices corresponding to the number of successive data segments is based on the total length of all data segments indicator of the other data entry of the SAT. For example, a first set of encoded data slices corresponding to a first data segment <b>1</b>.<b>11</b> of the file /file.doc is stored in the DSN memory at a vault source name of B<b>673</b>, a second set of encoded data slices corresponding to a second data segment <b>1</b>.<b>12</b> of the file /file.doc is stored in the DSN memory at a vault source name of B<b>674</b> (e.g., B<b>673</b>+2&#x2212;1), etc. until the entire data file stored (e.g., a number of data segments multiplied by the size of each data segment equals the total length of all data segments indicator).</p>
<p id="p-0242" num="0241">A request to delete a file may result in deletion of an associated directory file entry, deletion of an associated SAT, and deletion of encoded data slices associated with the file in accordance with a deletion method. The deletion method may be based on one or more of a snapshot ID associated with a file name of the file from a primary directory file and one or more associated snapshot IDs and corresponding filenames from one or more linked directory files (e.g., utilizing one or more linked directory source names from the primary directory file).</p>
<p id="p-0243" num="0242">For example, a plurality of encoded data slices associated with file name /file2.doc starting at vault source name B<b>775</b> are deleted, one or more sets of encoded SAT slices associated with file name /file2.doc at vault source name B<b>774</b> are deleted, a plurality of encoded data slices associated with file name /file.doc starting at vault source name B<b>673</b> are deleted, one or more sets of encoded SAT slices associated with file name /file.doc at vault source name B<b>672</b> are deleted, a directory file <b>2</b> entry associated with file name /file2.doc is deleted, and a directory file <b>1</b> entry associated with file name /file.doc is deleted when a request is received to delete the file associated with the file name /file2.doc since file name/file2.doc is associated with a snapshot ID of <b>2</b>, only one linked directory exists (e.g., directory file <b>1</b>), an associated entry of linked directory file <b>1</b> for file name /file.doc is associated with a snapshot ID of <b>1</b> (e.g., older), and the deletion method specifies to delete older snapshots when a newer snapshot is deleted.</p>
<p id="p-0244" num="0243">As another example, the directory file <b>1</b> entry associated with file name /file.doc is deleted and the one or more sets of encoded SAT slices associated with file name /file.doc at vault source name B<b>672</b> are deleted, when a request is received to delete the file associated with the file name /file.doc since file name/file.doc is associated with a snapshot ID of <b>1</b>, only one linked directory exists (e.g., directory file <b>2</b>), an associated entry of linked directory file <b>2</b> for file name /file2.doc is associated with a snapshot ID of <b>2</b> (e.g., newer), and the deletion method specifies to not delete newer snapshots and associated older snapshots one and older snapshot is deleted. The method to process a request to delete a file is discussed in greater detail with reference to <figref idref="DRAWINGS">FIG. 19</figref>.</p>
<p id="p-0245" num="0244"><figref idref="DRAWINGS">FIG. 19</figref> is a flowchart illustrating another example of deleting a snapshot, which include similar steps to <figref idref="DRAWINGS">FIG. 17</figref>. The method begins with steps <b>550</b>-<b>554</b> of <figref idref="DRAWINGS">FIG. 17</figref> where a processing module receives a delete snapshot request, accesses an entry of a primary directory corresponding to the snapshot identifier (ID), and determines whether there are one or more linked secondary directories. The method branches to step <b>572</b> when the processing module determines that there is not one or more linked secondary directories (e.g., no linked directory source name is present). The method continues to step <b>556</b> of <figref idref="DRAWINGS">FIG. 17</figref> when the processing module determines that there is one or more linked secondary directories.</p>
<p id="p-0246" num="0245">The method continues with steps <b>556</b>-<b>560</b> of <figref idref="DRAWINGS">FIG. 17</figref> where the processing module accesses each of the one or more linked secondary directories, removes a source name reference of the primary directory from each of the linked secondary directories, and determines whether there is at least one newer snapshot. The method branches to step <b>564</b> of <figref idref="DRAWINGS">FIG. 17</figref> when the processing module determines that there is at least one newer snapshot. The method continues to step <b>572</b> when the processing module determines that there is not at least one newer snapshot.</p>
<p id="p-0247" num="0246">The method continues at step <b>572</b> where the processing module deletes the data file associated with the snapshot ID. The deleting includes extracting a segmentation allocation table (SAT) source name from the entry of the primary directory file, retrieving at least one set of encoded SAT slices based on the SAT source name, dispersed storage error decoding the at least one set of encoded SAT slices to produce a SAT, extracting a start vault source name of a first data segment corresponding to the data file from the SAT, determining a plurality of vault source names associated with other data segments corresponding to the data file based on extracting other data from the SAT (e.g., a data segment size indicator, a total length of all segments indicator), and outputting one or more delete encoded data slice messages to a dispersed storage network (DSN) memory utilizing the start vault source name and the plurality of vault source names such that a plurality of sets of encoded data slices associated with the data file and the snapshot ID are deleted from the DSN memory.</p>
<p id="p-0248" num="0247">The method continues with step <b>564</b> of <figref idref="DRAWINGS">FIG. 17</figref> where the processing module deletes the entry of the primary directory corresponding to the snapshot ID and continues at step <b>574</b> where the processing module deletes a segmentation allocation table associated with the snapshot ID. The deleting includes outputting one or more delete encoded SAT slice messages to the DSN memory utilizing the SAT source name corresponding to the entry of the primary directory file such that at least one set of encoded SAT slices associated with the data file and the snapshot ID are deleted from the DSN memory.</p>
<p id="p-0249" num="0248">As may be used herein, the terms &#x201c;substantially&#x201d; and &#x201c;approximately&#x201d; provides an industry-accepted tolerance for its corresponding term and/or relativity between items. Such an industry-accepted tolerance ranges from less than one percent to fifty percent and corresponds to, but is not limited to, component values, integrated circuit process variations, temperature variations, rise and fall times, and/or thermal noise. Such relativity between items ranges from a difference of a few percent to magnitude differences. As may also be used herein, the term(s) &#x201c;operably coupled to&#x201d;, &#x201c;coupled to&#x201d;, and/or &#x201c;coupling&#x201d; includes direct coupling between items and/or indirect coupling between items via an intervening item (e.g., an item includes, but is not limited to, a component, an element, a circuit, and/or a module) where, for indirect coupling, the intervening item does not modify the information of a signal but may adjust its current level, voltage level, and/or power level. As may further be used herein, inferred coupling (i.e., where one element is coupled to another element by inference) includes direct and indirect coupling between two items in the same manner as &#x201c;coupled to&#x201d;. As may even further be used herein, the term &#x201c;operable to&#x201d; or &#x201c;operably coupled to&#x201d; indicates that an item includes one or more of power connections, input(s), output(s), etc., to perform, when activated, one or more its corresponding functions and may further include inferred coupling to one or more other items. As may still further be used herein, the term &#x201c;associated with&#x201d;, includes direct and/or indirect coupling of separate items and/or one item being embedded within another item. As may be used herein, the term &#x201c;compares favorably&#x201d;, indicates that a comparison between two or more items, signals, etc., provides a desired relationship. For example, when the desired relationship is that signal <b>1</b> has a greater magnitude than signal <b>2</b>, a favorable comparison may be achieved when the magnitude of signal <b>1</b> is greater than that of signal <b>2</b> or when the magnitude of signal <b>2</b> is less than that of signal <b>1</b>.</p>
<p id="p-0250" num="0249">As may also be used herein, the terms &#x201c;processing module&#x201d;, &#x201c;processing circuit&#x201d;, and/or &#x201c;processing unit&#x201d; may be a single processing device or a plurality of processing devices. Such a processing device may be a microprocessor, micro-controller, digital signal processor, microcomputer, central processing unit, field programmable gate array, programmable logic device, state machine, logic circuitry, analog circuitry, digital circuitry, and/or any device that manipulates signals (analog and/or digital) based on hard coding of the circuitry and/or operational instructions. The processing module, module, processing circuit, and/or processing unit may be, or further include, memory and/or an integrated memory element, which may be a single memory device, a plurality of memory devices, and/or embedded circuitry of another processing module, module, processing circuit, and/or processing unit. Such a memory device may be a read-only memory, random access memory, volatile memory, non-volatile memory, static memory, dynamic memory, flash memory, cache memory, and/or any device that stores digital information. Note that if the processing module, module, processing circuit, and/or processing unit includes more than one processing device, the processing devices may be centrally located (e.g., directly coupled together via a wired and/or wireless bus structure) or may be distributedly located (e.g., cloud computing via indirect coupling via a local area network and/or a wide area network). Further note that if the processing module, module, processing circuit, and/or processing unit implements one or more of its functions via a state machine, analog circuitry, digital circuitry, and/or logic circuitry, the memory and/or memory element storing the corresponding operational instructions may be embedded within, or external to, the circuitry comprising the state machine, analog circuitry, digital circuitry, and/or logic circuitry. Still further note that, the memory element may store, and the processing module, module, processing circuit, and/or processing unit executes, hard coded and/or operational instructions corresponding to at least some of the steps and/or functions illustrated in one or more of the Figures. Such a memory device or memory element can be included in an article of manufacture.</p>
<p id="p-0251" num="0250">The present invention has been described above with the aid of method steps illustrating the performance of specified functions and relationships thereof. The boundaries and sequence of these functional building blocks and method steps have been arbitrarily defined herein for convenience of description. Alternate boundaries and sequences can be defined so long as the specified functions and relationships are appropriately performed. Any such alternate boundaries or sequences are thus within the scope and spirit of the claimed invention. Further, the boundaries of these functional building blocks have been arbitrarily defined for convenience of description. Alternate boundaries could be defined as long as the certain significant functions are appropriately performed. Similarly, flow diagram blocks may also have been arbitrarily defined herein to illustrate certain significant functionality. To the extent used, the flow diagram block boundaries and sequence could have been defined otherwise and still perform the certain significant functionality. Such alternate definitions of both functional building blocks and flow diagram blocks and sequences are thus within the scope and spirit of the claimed invention. One of average skill in the art will also recognize that the functional building blocks, and other illustrative blocks, modules and components herein, can be implemented as illustrated or by discrete components, application specific integrated circuits, processors executing appropriate software and the like or any combination thereof.</p>
<p id="p-0252" num="0251">The present invention may have also been described, at least in part, in terms of one or more embodiments. An embodiment of the present invention is used herein to illustrate the present invention, an aspect thereof, a feature thereof, a concept thereof, and/or an example thereof. A physical embodiment of an apparatus, an article of manufacture, a machine, and/or of a process that embodies the present invention may include one or more of the aspects, features, concepts, examples, etc. described with reference to one or more of the embodiments discussed herein. Further, from figure to figure, the embodiments may incorporate the same or similarly named functions, steps, modules, etc. that may use the same or different reference numbers and, as such, the functions, steps, modules, etc. may be the same or similar functions, steps, modules, etc. or different ones.</p>
<p id="p-0253" num="0252">While the transistors in the above described figure(s) is/are shown as field effect transistors (FETs), as one of ordinary skill in the art will appreciate, the transistors may be implemented using any type of transistor structure including, but not limited to, bipolar, metal oxide semiconductor field effect transistors (MOSFET), N-well transistors, P-well transistors, enhancement mode, depletion mode, and zero voltage threshold (VT) transistors.</p>
<p id="p-0254" num="0253">Unless specifically stated to the contra, signals to, from, and/or between elements in a figure of any of the figures presented herein may be analog or digital, continuous time or discrete time, and single-ended or differential. For instance, if a signal path is shown as a single-ended path, it also represents a differential signal path. Similarly, if a signal path is shown as a differential path, it also represents a single-ended signal path. While one or more particular architectures are described herein, other architectures can likewise be implemented that use one or more data buses not expressly shown, direct connectivity between elements, and/or indirect coupling between other elements as recognized by one of average skill in the art.</p>
<p id="p-0255" num="0254">The term &#x201c;module&#x201d; is used in the description of the various embodiments of the present invention. A module includes a processing module, a functional block, hardware, and/or software stored on memory for performing one or more functions as may be described herein. Note that, if the module is implemented via hardware, the hardware may operate independently and/or in conjunction software and/or firmware. As used herein, a module may contain one or more sub-modules, each of which may be one or more modules.</p>
<p id="p-0256" num="0255">While particular combinations of various functions and features of the present invention have been expressly described herein, other combinations of these features and functions are likewise possible. The present invention is not limited by the particular examples disclosed herein and expressly incorporates these other combinations.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for a device of a distributed storage network (DSN) to generate a secure signature on an item without a locally stored private key of the device, the method comprises:
<claim-text>selecting a first key representation index of a set of key representation indexes,
<claim-text>wherein the first key representation index includes information regarding a first key representation of a set of key representations,</claim-text>
<claim-text>wherein a first mathematical encoding of the private key generates a first plurality of key shares as the first key representation, which is stored in a first set of dispersed storage (DS) units of the DSN, and a second mathematical encoding of the private key generates a second plurality of key shares as a second key representation of the set of key representations, which is stored in a second set of dispersed storage (DS) units of the DSN;</claim-text>
</claim-text>
<claim-text>determining whether a first plurality of signature contributions have been received in response to a signature request for the item based on the first key representation index, wherein one of the first set of DS units executes a first mathematical signature function using one of the first plurality of key shares on the item to produce a signature contribution of the first plurality of signature contributions; and</claim-text>
<claim-text>when the first plurality of signature contributions have been received, generating the secure signature on the item from the first plurality of signature contributions, wherein:</claim-text>
<claim-text>the first mathematical encoding includes:
<claim-text>randomly generating one or more first values; and</claim-text>
<claim-text>generating a second value based on key share generating mathematical function of (x+y+z) mod &#x3a6;(n)=d, where d is the private key, x and y correspond to the one or more first values, z corresponds to the second value, and &#x3a6;(n) is an Euler's totient function; and</claim-text>
<claim-text>sending the one or more first values and the second value to the first set of DS units;</claim-text>
</claim-text>
<claim-text>the second mathematical encoding includes:
<claim-text>generating one or more third values;</claim-text>
<claim-text>generating a fourth value based on the one or more third values, the private key, and the key share generating mathematical function; and</claim-text>
<claim-text>sending the one or more third values and the fourth value to the second set of DS units; and</claim-text>
</claim-text>
<claim-text>after generating the set of key representations, destroying the private key.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprises:
<claim-text>when the first plurality of signature contributions have not been received:
<claim-text>generating second signature requests for the item based on a second key representation index of the set of key representation indexes;</claim-text>
<claim-text>sending the second signature requests to the second set of DS units;</claim-text>
<claim-text>determining whether a second plurality of signature contributions have been received from the second set of DS units; and</claim-text>
<claim-text>when the second plurality of signature contributions have been received, generating the secure signature on the item from the second plurality of signature contributions.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generating the secure signature on the item comprises:
<claim-text>multiplying the first plurality of signature contributions to produce a multiplication result; and</claim-text>
<claim-text>performing a modulus function on the multiplication result to produce the secure signature.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signature request comprises:
<claim-text>a set of signature requests, wherein each signature request of the set of signature requests includes one or more of a first key representation identifier (ID), a signature payload, a hash of the signature payload, a DS unit ID, and a public modulus value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the item comprises one or more of:
<claim-text>a data element that includes one or more of registry information, key information, encryption algorithm information, a device certificate, a user certificate, and a system element identifier, and a DSN access request; and</claim-text>
<claim-text>a hash of the data element.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprises:
<claim-text>determining whether the secure signature is valid; and</claim-text>
<claim-text>when the secure signature is not valid:
<claim-text>generating second signature requests for the item based on a second key representation index of the set of key representation indexes;</claim-text>
<claim-text>sending the second signature requests to the second set of DS units;</claim-text>
<claim-text>determining whether a second plurality of signature contributions have been received from the second set of DS units; and</claim-text>
<claim-text>when the second plurality of signature contributions have been received, generating the secure signature on the item from the second plurality of signature contributions.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the selecting the first key representation index comprises:
<claim-text>selecting the first key representation index based on one or more of: DS unit status indicators of the first and second sets of DS units, DS unit performance level indicators of the first and second sets of DS units, DS unit retrieval history indicators of the first and second sets of DS units, a security indicator, a query, a command, a key share storage table lookup, and a message.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A module to enable a device of a distributed storage network (DSN) to generate a secure signature on an item without a locally stored private key of the device, the module comprises:
<claim-text>a first module operable to select a first key representation index of a set of key representation indexes,
<claim-text>wherein the first key representation index includes information regarding a first key representation of a set of key representations,</claim-text>
<claim-text>wherein a first mathematical encoding of the private key generates a first plurality of key shares as the first key representation, which is stored in a first set of dispersed storage (DS) units of the DSN, and a second mathematical encoding of the private key generates a second plurality of key shares as a second key representation of the set of key representations, which is stored in a second set of dispersed storage (DS) units of the DSN;</claim-text>
</claim-text>
<claim-text>a second module operable to determine whether a first plurality of signature contributions have been received in response to a signature request for the item based on the first key representation index, wherein one of the first set of DS units executes a first mathematical signature function using one of the first plurality of key shares on the item to produce a signature contribution of the first plurality of signature contributions; and</claim-text>
<claim-text>when the first plurality of signature contributions have been received, a third module operable to generate the secure signature on the item from the first plurality of signature contributions,</claim-text>
<claim-text>wherein:</claim-text>
<claim-text>the first mathematical encoding includes:
<claim-text>randomly generating one or more first values; and</claim-text>
<claim-text>generating a second value based on key share generating mathematical function of (x+y+z) mod &#x3a6;(n)=d, where d is the private key, x and y correspond to the one or more first values, z corresponds to the second value, and &#x3a6;(n) is an Euler's totient function; and</claim-text>
<claim-text>sending the one or more first values and the second value to the first set of DS units;</claim-text>
</claim-text>
<claim-text>the second mathematical encoding includes:
<claim-text>generating one or more third values;</claim-text>
<claim-text>generating a fourth value based on the one or more third values, the private key, and the key share generating mathematical function; and</claim-text>
<claim-text>sending the one or more third values and the fourth value to the second set of DS units; and</claim-text>
</claim-text>
<claim-text>after generating the set of key representations, destroying the private key.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The module of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprises:
<claim-text>when the first plurality of signature contributions have not been received:
<claim-text>the second module is further operable to:
<claim-text>generate second signature requests for the item based on a second key representation index of the set of key representation indexes;</claim-text>
<claim-text>send the second signature requests to the second set of DS units;</claim-text>
<claim-text>determine whether a second plurality of signature contributions have been received from the second set of DS units; and</claim-text>
</claim-text>
<claim-text>when the second plurality of signature contributions have been received, the third module is further operable to generate the secure signature on the item from the second plurality of signature contributions.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The module of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the third module functions to generate the secure signature on the item by:
<claim-text>multiplying the first plurality of signature contributions to produce a multiplication result; and</claim-text>
<claim-text>performing a modulus function on the multiplication result to produce the secure signature.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The module of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the signature request comprises:
<claim-text>a set of signature requests, wherein each signature request of the set of signature requests includes one or more of a first key representation identifier (ID), a signature payload, a hash of the signature payload, a DS unit ID, and a public modulus value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The module of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the item comprises one or more of:
<claim-text>a data element that includes one or more of registry information, key information, encryption algorithm information, a device certificate, a user certificate, and a system element identifier, and a DSN access request; and</claim-text>
<claim-text>a hash of the data element.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The module of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprises:
<claim-text>a fifth module operable to determine whether the secure signature is valid; and</claim-text>
<claim-text>when the secure signature is not valid:
<claim-text>the second module further operable to:
<claim-text>generate second signature requests for the item based on a second key representation index of the set of key representation indexes;</claim-text>
<claim-text>send the second signature requests to the second set of DS units;</claim-text>
<claim-text>determine whether a second plurality of signature contributions have been received from the second set of DS units; and</claim-text>
</claim-text>
<claim-text>when the second plurality of signature contributions have been received, the third module further operable to generate the secure signature on the item from the second plurality of signature contributions.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The module of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first module functions to select the first key representation index by:
<claim-text>selecting the first key representation index based on one or more of: DS unit status indicators of the first and second sets of DS units, DS unit performance level indicators of the first and second sets of DS units, DS unit retrieval history indicators of the first and second sets of DS units, a security indicator, a query, a command, a key share storage table lookup, and a message. </claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
