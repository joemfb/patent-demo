<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624909-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624909</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11285643</doc-number>
<date>20051121</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1976</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345582</main-classification>
<further-classification>345422</further-classification>
<further-classification>345644</further-classification>
</classification-national>
<invention-title id="d2e53">Image processing system and method thereof</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6016151</doc-number>
<kind>A</kind>
<name>Lin</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345582</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6035364</doc-number>
<kind>A</kind>
<name>Lambrecht et al.</name>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710305</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6226012</doc-number>
<kind>B1</kind>
<name>Priem et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345606</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6311258</doc-number>
<kind>B1</kind>
<name>Gibson et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711200</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6952211</doc-number>
<kind>B1</kind>
<name>Cote et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7092035</doc-number>
<kind>B1</kind>
<name>Pether</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348581</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7158132</doc-number>
<kind>B1</kind>
<name>Moffitt et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345421</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2003/0160793</doc-number>
<kind>A1</kind>
<name>Emberling et al.</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345506</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2004/0130552</doc-number>
<kind>A1</kind>
<name>Duluk et al.</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345506</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2005/0125369</doc-number>
<kind>A1</kind>
<name>Buck et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 12</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0197977</doc-number>
<kind>A1</kind>
<name>Buck et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 12</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2005/0219415</doc-number>
<kind>A1</kind>
<name>Young et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348554</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2006/0056708</doc-number>
<kind>A1</kind>
<name>Shen et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382232</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2006/0204119</doc-number>
<kind>A1</kind>
<name>Feng et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382250</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345422</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345582</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345644</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070115294</doc-number>
<kind>A1</kind>
<date>20070524</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Laksono</last-name>
<first-name>Indra</first-name>
<address>
<city>Richmond Hill</city>
<country>CA</country>
</address>
</addressbook>
<residence>
<country>CA</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Laksono</last-name>
<first-name>Indra</first-name>
<address>
<city>Richmond Hill</city>
<country>CA</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>ViXS Systems Inc.</orgname>
<role>03</role>
<address>
<city>Toronto, ON</city>
<country>CA</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>McDowell, Jr.</last-name>
<first-name>Maurice L</first-name>
<department>2677</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and system is described by which a graphics engine can be shared to implement the functions of video encoder, such as video compression, to generate motion vectors.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="154.43mm" wi="152.65mm" file="US08624909-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="244.43mm" wi="145.63mm" file="US08624909-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="246.30mm" wi="104.56mm" file="US08624909-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="219.88mm" wi="149.27mm" file="US08624909-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="243.16mm" wi="112.95mm" file="US08624909-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="229.79mm" wi="153.84mm" file="US08624909-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="231.90mm" wi="146.98mm" file="US08624909-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE DISCLOSURE</heading>
<p id="p-0002" num="0001">The present disclosure relates generally to data processing and more specifically to processing image data.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">Two major types of image data have been historically recognized in the image processing arts&#x2014;graphics data and video data. Graphics data generally refers to computer generated data that defines still images using primitive shape definitions, such as triangles, rectangles and ovals. These primitive shape definitions are converted to pixel information, in the form of bit maps, before being sent to a display device. Video data generally refers to data that stores pixel information to generate a sequence of still pictures back-to-back to produce a moving image.</p>
<p id="p-0004" num="0003">Traditionally, video data was analog data transmitted to a television, which would use analog circuitry to create a sequence of still pictures back-to-back to produce a moving image. The ready availability of high-speed digital electronics resulted in video coding/decoding (codec) technology, whereby each still image of a video sequence is digitally encoded and subsequently decoded for display.</p>
<p id="p-0005" num="0004">In order to efficiently process graphics data, graphics based digital systems, generally referred to as graphics processors and graphics engines, were developed to address graphics-specific needs associated with generating images from primitive-based definitions. Specialized graphics processors have evolved, and include sophisticated processing modules that facilitate the display of images onto a 2-Dimensional display device. For example state-of-the-art graphics systems are capable of synthesizing three-dimensional images onto two-dimensional display devices, such as a traditional computer monitor, using specialized digital processing modules to provide lighting, shading, texture, and Z-data.</p>
<p id="p-0006" num="0005">Prior art <figref idref="DRAWINGS">FIG. 1</figref> illustrates a system <b>10</b> comprising a graphics engine <b>14</b> and an encoder <b>16</b>. Data paths <b>21</b> and <b>22</b> are illustrated at <figref idref="DRAWINGS">FIG. 1</figref> to represent a sequence of connections and devices through which information received by the graphics engine <b>14</b> and encoder/decoder <b>16</b>, respectively, for a specific operation. The fact that data paths <b>21</b> and <b>22</b> do not overlap is indicative of the fact that the graphics engine <b>14</b> does not share resources with the encoder <b>16</b>, which has resources implemented separately from the graphics engine <b>14</b>. Therefore, it is noted that the recent convergence of multi-media systems has resulted in systems comprising both video processing-specific modules, such as encoder <b>16</b>, and graphics processing-specific modules, such as graphics engine <b>14</b>. However, while such systems allow for easy replication of existing technology, it often results in multiple system components, or system components having large areas that can result in unnecessary power consumption. Therefore, a system or method that reduces the size of components in a such a system would be useful.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0007" num="0006">The present disclosure may be better understood, and its numerous features and advantages made apparent to those skilled in the art by referencing the accompanying drawings.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a prior art system.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> illustrates, in block diagram form, a system in accordance with a specific embodiment of the present disclosure.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 3</figref> illustrates, in flow diagram form, a method in accordance with a specific embodiment of the present disclosure.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 4</figref> illustrates, in flow diagram form, a detail method of a portion of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 5</figref> illustrates, in flow diagram form, a method in accordance with a specific embodiment of the present disclosure.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 6</figref> illustrates the block diagram of <figref idref="DRAWINGS">FIG. 2</figref> illustrating specific data paths.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 7</figref> illustrates a portion of the block diagram of <figref idref="DRAWINGS">FIG. 2</figref> illustrating specific data paths.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. 8 and 10</figref> illustrate a data paths for modules of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. 9 and 11</figref> illustrate a data path for functions implemented at modules of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0017" num="0016">The use of the same reference symbols in different drawings indicates similar or identical items.</p>
<heading id="h-0004" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENT(S)</heading>
<p id="p-0018" num="0017">In accordance with a specific embodiment of the present disclosure, resources of a graphics engine are shared with an encoding engine. A specific implementation of the sharing of such resources will be better understood with reference to <figref idref="DRAWINGS">FIGS. 2-11</figref> discussed below.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an integrated circuit device <b>110</b> disposed at a die <b>112</b>. Device <b>110</b> includes modules <b>120</b> and <b>140</b>. In one embodiment, module <b>120</b> represents a graphics engine (also referred to as graphics engine <b>120</b>) and module <b>140</b> represents an image encoder (also referred to as encoder <b>140</b>). Graphics engine <b>120</b> includes the connections and components needed to implement a set of graphics functions. Modules <b>121</b>-<b>125</b> represent some traditional graphics functions implemented by graphics engines. For example, module <b>121</b> is a texture engine module for implementing texture mapping functions, module <b>122</b> is a pixel blender module for blending images, module <b>123</b> is a Z-test module determining relative depths of images in three dimensional space, module <b>124</b> is a scaler module for scaling images, module <b>125</b> is a set-up and geometry engine module that pre-processes some types of information for use by other modules. It will be appreciated that each of the modules <b>121</b>-<b>125</b> of <figref idref="DRAWINGS">FIG. 2</figref> can themselves have sub-modules associated with them, for example, the Z-test module <b>123</b> can have access to a compare module used to implement the Z-test function. A compare module used by the Z-test module can be dedicated to the Z-test module, such as module <b>129</b>, or can be a module accessible to other modules such as module <b>126</b>. Various portions of graphics engine <b>120</b> can be implemented, for example, using hardware, software, or a combination thereof.</p>
<p id="p-0020" num="0019">Encoder <b>140</b> is illustrated to overlap with graphics engine <b>120</b>. The overlapping portion <b>142</b> is represented by a dashed line, and indicates that resources of graphics engine <b>120</b> are shared with encoder <b>140</b>. A specific embodiment of sharing resources between graphics engine <b>120</b> and encoder <b>140</b> is discussed with reference to a specific embodiment illustrated in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 3</figref> includes an illustration of a flow diagram for determining motion vectors, such as motion vectors for MPEG, as part of an image encoding process. At <b>301</b>, variables are initialized. In accordance with a specific embodiment, each element of a matrix MVR is initialized to a large value, which for exemplary purposes has been chosen to be 100. MVR has a size of MX&#xd7;MY, where Mx is the number of image blocks, usually 16&#xd7;16 pixel blocks referred to as macroblocks, in the x-direction for a current picture (CP), and MY is the number of image blocks in the y-direction for the CP. Note that the value of 100 for the elements of the matrix MVR was selected based on an assumption that the graphics engine being used treats a Z-buffer value of zero (0) as the front-most plane for three-dimensional images.</p>
<p id="p-0022" num="0021">At <b>302</b> a current picture (CP) to be encoded is identified.</p>
<p id="p-0023" num="0022">At <b>303</b> a reference picture (RP) to be searched to determine motion vectors for CP is identified.</p>
<p id="p-0024" num="0023">At <b>304</b> the CP is scaled by &#xbc; using shared graphics engine resources to generate a scaled matrix CP&#x2032;. In one embodiment, a scaler engine is used to implement a scaling function: D&#x2190;SCALE(S, Xscale, Yscale); where D is the destination matrix, S is the source matrix, Xscale is a scale factor in the X-direction to be applied to S, and Yscale is a scale factor in the Y-direction to be applied to the S. Therefore, the operation CP&#x2032;&#x2190;SCALE(CP, &#xbc;, &#xbc;) represents a scaler function of the graphics engine that scales CP by &#xbc; in both the X-direction and Y-direction, and writes the result to CP&#x2032;. As a result, 4&#xd7;4 blocks of CP picture elements are represented as a single element in CP&#x2032;. Therefore, a macroblock of CP, comprising sixteen (16) 4&#xd7;4 blocks, is represented in CP&#x2032; by one (1) 4&#xd7;4 block.</p>
<p id="p-0025" num="0024">At <b>305</b>, RP is scaled by &#xbc; using a shared graphics engine resources to generate a scaled matrix RP&#x2032;. In one embodiment a scaler engine is used to implement the operation RP&#x2032;&#x2190;SCALE(RP, &#xbc;, &#xbc;). Each 4&#xd7;4 block of RP picture elements is represented as a single element in RP&#x2032;. Therefore, a macroblock of RP, comprising sixteen (16) 4&#xd7;4 blocks, is represented in RP&#x2032; by one (1) 4&#xd7;4 block.</p>
<p id="p-0026" num="0025">It will be appreciated that graphics engine modules other than a scaler can be used as a shared graphics engine resource to scale data. For example, a texture engine, which itself may use the scaler, can be used in a manner similar to that discussed below.</p>
<p id="p-0027" num="0026">At <b>306</b>, first motion vectors for the CP are determined using a low-resolution search using shared graphics engine resources. First motion vectors determined at <b>306</b>, if any, can be used as a starting point for a high-resolution motion vector search at <b>307</b>.</p>
<p id="p-0028" num="0027">In one embodiment, a texture engine of a graphics engine is used to implement the following texture mapping operations:</p>
<p id="p-0029" num="0028">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="119pt" align="left"/>
<colspec colname="1" colwidth="98pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>Texture Mapping Operation (1)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="63pt" align="left"/>
<colspec colname="2" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry>D1 <img id="CUSTOM-CHARACTER-00001" he="2.12mm" wi="2.79mm" file="US08624909-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>  TXTMAP (</entry>
<entry>T1 = RP&#x2032;,</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>T2 = CP&#x2032;,</entry>
</row>
<row>
<entry/>
<entry>Destination Space Triangle =</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>V1 = 0, 0, 25;</entry>
</row>
<row>
<entry/>
<entry>V2 = Xmax/4, 0, 25;</entry>
</row>
<row>
<entry/>
<entry>V3 = 0, Ymax/4, 25;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Texture Space Triangle =</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>V1 = 0+DX, 0+DY;</entry>
</row>
<row>
<entry/>
<entry>V2 = Xmax+DX, 0+DY;</entry>
</row>
<row>
<entry/>
<entry>V3 = 0+DX, Ymax+DY;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Op = If Z-test true then Store(T1 &#x2212; T2)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="42pt" align="left"/>
<colspec colname="1" colwidth="175pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="119pt" align="left"/>
<colspec colname="1" colwidth="98pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Texture Mapping Operation (2)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="63pt" align="left"/>
<colspec colname="2" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry>D1 <img id="CUSTOM-CHARACTER-00002" he="2.12mm" wi="2.79mm" file="US08624909-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>  TXTMAP (</entry>
<entry>T1 = RP&#x2032;,</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>T2 = CP&#x2032;,</entry>
</row>
<row>
<entry/>
<entry>D1 Z Buffer = MVR,</entry>
</row>
<row>
<entry/>
<entry>Destination Space Triangle =</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>V1 = Xmax/4, Ymax/4, 25;</entry>
</row>
<row>
<entry/>
<entry>V2 = Xmax/4, 0, 25;</entry>
</row>
<row>
<entry/>
<entry>V3 = 0, Ymax/4, 25,</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Texture Space Triangle =</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>V1 = Xmax+DX, Ymax+DY;</entry>
</row>
<row>
<entry/>
<entry>V2 = Xmax+DX, 0+DY;</entry>
</row>
<row>
<entry/>
<entry>V3 = 0+DX, Ymax+DY;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Op = If Z-test true then Store(T1 &#x2212; T2)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="42pt" align="left"/>
<colspec colname="1" colwidth="175pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="14pt" align="left"/>
<colspec colname="1" colwidth="203pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>where:</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="28pt" align="left"/>
<colspec colname="1" colwidth="189pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>-- Xmax is the number of elements of RP&#x2032; in the x-direction</entry>
</row>
<row>
<entry/>
<entry>-- Ymax is the number of elements of RP&#x2032; in the y-direction</entry>
</row>
<row>
<entry/>
<entry>-- DX is offset that is a multiple of 4;</entry>
</row>
<row>
<entry/>
<entry>-- DY is offset that is a multiple of 4;</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0030" num="0029">Texture mapping operation (1) defines triangles corresponding to a lower-left half of a picture, while texture mapping operation (2) defines triangles corresponding to an upper-right half of a picture, such that operations (1) and (2) combined be used to fully process information for square pictures, such as the CP and the RP. Note that while triangles have been described as the texture space shape being used, in other embodiments other shapes, such as quadshapes, ovals, and the like can also be used.</p>
<p id="p-0031" num="0030">Operations (1) and (2) treat CP&#x2032; and RP&#x2032; as textures, and will generate a &#xbc;&#xd7;&#xbc; destination bitmap of the difference of the bitmap CP&#x2032; subtracted by RP&#x2032; for locations passing a Z-test criteria. Note that the matrix MVR is used as the Z-buffer for the destination matrix. Since each element of MVR has been initialized to have a Z-value of 100, every location of CP&#x2032; and RP&#x2032; will be processed by operations (1) and (2) during a first pass because the destination triangle has a depth value, i.e. a Z-value of 25, which is less than 100. Scaling of RP&#x2032; at the destination bitmap by &#xbc; in both the x-direction and the y-direction occurs, as well as the indicated subtraction between the scaled CP and RP results. The resulting values are stored at the destination D<b>1</b>. Each value of D<b>1</b> corresponds to a specific macroblock of CP, and represents an estimated entropy value between a a CP macroblock and a RP macroblock.</p>
<p id="p-0032" num="0031">Note that the texture space triangles can be offset from the destination space triangles by multiples of 4 to predict the entropy between macroblocks of CP and macroblocks of DP that are not co-located. For example, a value of (DX, DY)=(0, 0) results evaluating each macroblock of CP with its co-located macroblock of DP. A value of (DX, DY)=(4, 0) would result in evaluating each macroblock of CP with a corresponding macroblock of DP that is offset by 1 macroblock from its co-located macroblock. Note that a value of 4 for DX or DY indicates an offset of four elements of RP&#x2032;. In addition, an offset of four (4) RP&#x2032; elements represents a corresponding offset of 16 elements of RP, because each element of RP&#x2032; represents four elements of RP. Therefore, an offset of four elements of RP&#x2032; corresponds to an offset of one macroblock. As a result, each increment of four in the value of DX represents a different macroblock in the x-direction, while each increment of four in the value of DY represents a different macroblock in the y-direction.)</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 4</figref> illustrates an exemplary implementation of <b>306</b>. At <b>321</b>, values are selected for (DX, DY). For example, (DX, DY) can be set to (0, 0), representing the motion vector zero. The motion vector zero is a good starting point since there is a strong likelihood that entropy between co-located macroblocks will be low. Variable MVID is set to a value associated with the specific (DX, DY) being used. For motion vector zero it is assumed that MVID has a value of 0.</p>
<p id="p-0034" num="0033">At <b>322</b> the entropy for each macroblock of CP relative to a macroblock of RP indicated by the value of (DX, DY). As described previously, each element of destination matrix D<b>1</b> will contain a predicted entropy value for each macroblock of CP.</p>
<p id="p-0035" num="0034">At <b>323</b> the predicted entropy for each macroblock of CP is checked to determine if the it meets a threshold. If so, the value of MVID is written to a corresponding location of MVR, to indicate that the current offset value (DX, DY) is likely to represents a intermediate motion vector for a corresponding macroblock of CP that is at or near a final motion vector. By selecting MVID to be less than the value to which MVR was initialized, it is readily determined which value of (DX, DY), and therefore which macroblocks of CP, resulted in an entropy value below the threshold. For example, by storing MVID values at corresponding macroblock locations of MVR, those macroblocks having a low predicted entropy for a motion vector zero can be later identified.</p>
<p id="p-0036" num="0035">In one embodiment, <b>323</b> is accomplished using a shared graphics engine function. For example, a Z-test engine can be used to compare the predicted entropy values of D<b>1</b> to a threshold value. In one embodiment, a Z-test engine of a graphics engine is used to implement the following Z-test operations:</p>
<p id="p-0037" num="0036">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="119pt" align="left"/>
<colspec colname="1" colwidth="98pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>Z-Test Operation (1)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="63pt" align="left"/>
<colspec colname="2" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry>MVA <img id="CUSTOM-CHARACTER-00003" he="2.12mm" wi="2.79mm" file="US08624909-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>  ZTEST (</entry>
<entry>Z-buffer = D1;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Destination Space Triangle =</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>V1 = 0, 0, Vth;</entry>
</row>
<row>
<entry/>
<entry>V2 = Xmax/16, 0, Vth;</entry>
</row>
<row>
<entry/>
<entry>V3 = 0, Ymax/16, Vth;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Op = (If Destination Space Triangle is Front then</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>store Z-buffer value at Destination)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="28pt" align="left"/>
<colspec colname="1" colwidth="189pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="119pt" align="left"/>
<colspec colname="1" colwidth="98pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Z-Test Operation (2)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="63pt" align="left"/>
<colspec colname="2" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry>MVA <img id="CUSTOM-CHARACTER-00004" he="2.12mm" wi="2.79mm" file="US08624909-20140107-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/>  ZTEST (</entry>
<entry>Z-buffer = D1;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Destination Space Triangle =</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>V1 = Xmax/16, Ymax/16, Vth;</entry>
</row>
<row>
<entry/>
<entry>V2 = Xmax/16, 0, Vth;</entry>
</row>
<row>
<entry/>
<entry>V3 = 0, Ymax/16, Vth;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Op = (If Destination Space Triangle is Front then</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>store Z-buffer value at Destination)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="28pt" align="left"/>
<colspec colname="1" colwidth="189pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>)</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0038" num="0037">Z-test operation (1) defines triangles corresponding to a lower-left half of a picture, while Z-test operation (2) defines triangles corresponding to an upper-right half of a picture, such that operations (1) and (2) combined be used to fully process a square matrix, such as D<b>1</b> being used as a Z-buffer.</p>
<p id="p-0039" num="0038">Z-test operations (1) and (2) treat the destination matrix D<b>1</b> as a Z-buffer to which a depth of a Destination Space Triangle is being compared. The Destination Space Triangle is represented in three-dimensional (3D) coordinates, with the Z-coordinate, i.e. the depth coordinate, being set equal to a desired threshold value to which each element of D<b>1</b> will be compared. For example, the Z-test operations (1) and (2) result in a value equal to the current MVID being written to those locations of matrix MVR corresponding to CP frames where the predicted entropy for a corresponding CP frame meets a threshold Vth. Therefore, after a first application of Z-Test operations (1) and (2) for motion vector zero, each element of MVR will have a value equal to zero (0), thereby predicting motion vector zero as a motion vector from which a detailed search can be perform, or a value equal to the initialization value, which is selected to be larger than any anticipate value of MVID, to allow sharing of the Z-test resource.</p>
<p id="p-0040" num="0039">At <b>324</b> a determination is made whether a new motion vector is to be evaluated using the low-resolution search of <b>306</b>. In one embodiment, a fixed number of motion vectors, such as five (5) motion vectors or nine (9) motion vectors are tried. (The five motion vectors would typically include motion vector zero and the four motion vectors immediately adjacent to motion vector zero in an orthogonal direction, while the nine motion vectors would include the 5 motion vectors and the 4 motion vectors immediately adjacent motion vector zero in a diagonal direction). If additional motion vectors are to be tried, flow proceeds to <b>325</b>, otherwise flow proceeds to <b>307</b>.</p>
<p id="p-0041" num="0040">At <b>325</b>, (DX, DY) is set to a new value representative of a new motion vector. The value of MVID will incremented to a new value that is uniquely associated with the new value (DX, DY). Each element of a destination matrix D<b>1</b> is initialized to a value that is larger than any expected threshold value Vth, such as the value 100 in the present embodiment.</p>
<p id="p-0042" num="0041">Flow proceeds from <b>325</b> back to <b>322</b> to determine predicted entropy between CP and DP for the new value of (DX, DY). During subsequent implementations of <b>322</b>, the Z-test feature of texture mapping operations (1) and (2) will prevent D<b>1</b> from being updated at those locations where a predicted motion vector has been determined. For example, if the value of MVR, which is treated as a Z-buffer for destination D<b>1</b>, was set to 0 at a specific location to predict a motion vector zero, then the specific location is not evaluated using subsequent motion vectors. In accordance with a specific embodiment, selective processing of only those locations not yet associated with a predicted motion vector is accomplished by using MVR as the destination Z-buffer, and setting the destination triangles to have depth values (z-dimensions) larger than any anticipated MCID values, such as 25, but lower than the value to which MVR was initialized at <b>302</b>. Note that during subsequent implementations of <b>323</b>, locations of D<b>1</b> that were not updated with entropy values based on the motion vector will still have their initialized value from <b>325</b>, which is 100 in the present example. This initialization value of D<b>1</b> at <b>325</b> was selected to be larger than Vth to assure the once an MVID value is written to MVR that it is not over-written by a subsequent motion vector.</p>
<p id="p-0043" num="0042">Once the desired values of (DX, DY) have been processed, each value of MVR will correspond to a specific motion vector if a sufficiently low entropy was predicted for its corresponding macroblock, or have the initialization value of 100 if a sufficiently low entropy was not was predicted by any value of (DX, DY) for its corresponding macroblock.</p>
<p id="p-0044" num="0043">At <b>307</b> of <figref idref="DRAWINGS">FIG. 3</figref>, the values of MVR that identify a predicted motion vector based on a low-resolution search are used to control which macroblocks of CP are to be subjected to a high-resolution search. For example, each location of MVR having a motion vector indicator, i.e. a value between 0-4 if five motion vectors are considered at <b>306</b>, can be evaluated using a high-resolution motion vector search to determine if a final motion vector can be identified.</p>
<p id="p-0045" num="0044">During high-resolution searches at <b>307</b>, an attempt is made to identify a final motion vector based on a more accurate search using the results of the low-resolution search of <b>306</b> as a starting point. Therefore, each element of MVR having a value indicative of a motion vector, i.e. a value between 0-4, is subject to the high-resolution search of <b>307</b>. For elements of MVR not associated with an estimated motion vector from the low-resolution search the corresponding macroblock of CP will be treated as an intra-macroblock having no motion vectors, and be encoded appropriately.</p>
<p id="p-0046" num="0045">Therefore, a high-resolution search will be performed at <b>307</b> for each MVR[i,j] having a predicted motion vector value in MVR. For example, a full subpixel &#xb1;2 search can be performed starting at the predicted motion vector as indicated at MVR[i,j] to determine if a motion vector resides at or near an associated offset (DX, DY). For example, a value of 0 stored at MVR[i,j] would indicate that the motion vector zero has been predicted and the high-resolution search can be performed near (0, 0). It will be appreciated that this high-resolution search can be performed using graphics engine functions similar to those described previously. Note that instead of performing each search with the full picture CP as described previous, a search can be performed for each macroblock of CP individually.</p>
<p id="p-0047" num="0046">It will be appreciated that a &#xbd; pel displacement in each DX, DY can be obtained using a bilinear operation where we use (p<b>1</b>+p<b>2</b>+1)*&#xbd; for each consecutive pixels p<b>1</b>,p<b>2</b>. A &#xbc; pel displacement can be treated as (&#xbc;*p<b>1</b>+&#xbe;*p<b>2</b>). It will be further appreciated that there are other more complex arithmetic operations within the subpixel treatment of motion vectors within other codecs, but it is readily recognized that by modifying this approach, there can be small changes to the texture mapping operation to handle the different blending of subpixel construction.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 5</figref> illustrates in flow diagram form a method in accordance with the present disclosure. At <b>501</b>, a first operation is applied to modify a first set of data to implement a first image rendering function, wherein the first image rendering function generates an image bit map to be displayed. A first set of data paths at an integrated circuit die is associated with implementation of the image rendering function, wherein the first operation is associated with data paths that are a subset of first set of data paths.</p>
<p id="p-0049" num="0048">In a specific embodiment, a first image rendering function can be associated with a specific graphics engine command that is implemented at the graphics engine using a subset of the graphics engine components and connections. The term &#x201c;data path&#x201d; is used herein to refer to a set of components and connections through which information can flow to implement a specific function. For example, graphics engine <b>120</b> has a data path, represented in <figref idref="DRAWINGS">FIG. 6</figref> by arrow <b>511</b>, through which execution of its functions, i.e. commands, is implemented. Similarly, encoder <b>140</b> has a data path, represented in <figref idref="DRAWINGS">FIG. 6</figref> by arrow <b>512</b>, through which execution of its functions, i.e. commands, is implemented. Note that the graphics engine data path <b>511</b> is part of the data path <b>512</b> of the encoder engine <b>140</b> because the encoder engine <b>140</b> can use functions of the graphics engine <b>120</b> to implement its own commands.</p>
<p id="p-0050" num="0049">It will be further appreciated that the submodules <b>121</b>-<b>126</b> of graphics engine <b>120</b>, as well their subcomponents, each have associated data paths. A data path of a sub-module of graphics engine <b>120</b> is, by definition, a subset, i.e., subpath, of the graphics engine <b>120</b> data path <b>511</b>. For example, <figref idref="DRAWINGS">FIG. 7</figref> illustrates texture module <b>121</b> having a data path <b>621</b>, pixel blender <b>122</b> having a data path <b>622</b>, Z-test module <b>123</b> having a data path <b>623</b>, scaler <b>124</b> having a data path <b>624</b>, set-up &#x26; geometry engine <b>125</b> having a data path <b>625</b>, and module <b>126</b> having a data path <b>626</b>. In addition, Z-test engine <b>123</b> has a sub-module <b>129</b>, which has a data path <b>629</b> that is a subset, or a portion, of data path <b>623</b>. <figref idref="DRAWINGS">FIG. 8</figref> graphically illustrates the data path <b>511</b> of graphics engine <b>120</b> as including each of the data paths <b>621</b>-<b>626</b>. Note that data path illustrations herein are different than data flow diagrams, in that the relative location of sub-modules data path does provide data flow information. For example, referring to <figref idref="DRAWINGS">FIG. 8</figref>, the location of data path <b>622</b> does not represent a sequential order of its use relative to the other data paths making up data path <b>511</b>. Instead, the inclusion of data path <b>622</b> in data path <b>511</b> only indicates that data path <b>622</b> is used by graphics engine <b>120</b> to implement at least one graphics engine function.</p>
<p id="p-0051" num="0050">While every function of the graphics engine can be implemented using data path <b>511</b>, individual functions of graphics engine <b>120</b> are typically implemented using only a portion of the data paths making up the data path <b>511</b>. For example, <figref idref="DRAWINGS">FIG. 9</figref> represents a data path <b>821</b> used to implement a specific function using graphics engine <b>120</b>, such as a function that scales an image and blends it with another image. Such a function is illustrated to include data paths <b>622</b>, <b>624</b>, and <b>626</b>. Data paths shown as part of data path <b>821</b> are needed implement the specific function to which data path <b>821</b> is associate. For example, inclusion of data paths <b>622</b>, <b>624</b>, and <b>626</b> in data path <b>821</b> indicates that the specific function associated with data path <b>821</b> share function associated with the pixel blender <b>122</b>, the scaler <b>124</b>, and the module <b>126</b>. Note module <b>126</b> can represent, for example, a matrix arithmetic engine.</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 10</figref> is a specific representation of the data path <b>512</b> of the encoder <b>140</b>, which includes data paths <b>911</b>-<b>913</b>, associated with specific sub-modules (not illustrated) of the encoder <b>120</b>, and data path <b>511</b>. The inclusion of data path <b>511</b> in data path <b>512</b> is indicative of the fact that encoder functions need to share at least some of the graphics engine resources. Sharing of graphics engine resources can be accomplished by by using issuing commands to the graphics engine <b>140</b> from a controller of the encoder <b>140</b>.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 11</figref> represents a data path <b>831</b> used to implement a specific encoder engine <b>140</b> function. For example, the specific function can perform a motion vector search. The data paths associated with data path <b>831</b> include data path <b>912</b> from a sub-module (not illustrated) of the encoder engine <b>140</b>, and data paths <b>622</b> and <b>626</b> from sub-modules of the graphics engine, which are used to implement at least one specific graphics engine function. For example, the specific encoder function associated with data path <b>821</b> utilizes the data path <b>622</b> of the pixel blender <b>122</b> and the data path <b>626</b> of the module <b>126</b>.</p>
<p id="p-0054" num="0053">With respect to <b>501</b> of the method of <figref idref="DRAWINGS">FIG. 5</figref>, an example of a first image rendering function would be the scale/blend function discussed with reference to <figref idref="DRAWINGS">FIG. 9</figref> that both scales and blends an image. An example of the first operation of <b>501</b> would be the scaling function implemented using data path <b>624</b> of the scaler <b>124</b>.</p>
<p id="p-0055" num="0054">At <b>502</b> (<figref idref="DRAWINGS">FIG. 5</figref>), the first operation is applied to modify a second set of data to implement a first image encoding function, wherein the first image encoding function generates an encoded data representing an image of the second set of data, such as motion vectors. A second set of data paths at the integrated circuit die is associated with the implementation of the image encoding function, wherein the data paths of the first operation are members, i.e. a subset, of the second set of data paths. For example, comparing data path <b>831</b>, as represented at <figref idref="DRAWINGS">FIG. 11</figref>, with the data path <b>821</b>, of <figref idref="DRAWINGS">FIG. 9</figref>, reveals that the blending operation <b>122</b> having data path <b>622</b> is used by both the first image rendering function having data path <b>821</b> and the first image encoding function having data path <b>831</b>.</p>
<p id="p-0056" num="0055">The specific embodiments described above illustrate specific usage of shared graphics engine resources to encode an image by identifying motion vectors. The use of shared graphics engine resources can be useful in other areas of encoding as well. For example, many encoding techniques use compression that allows for lossiness, resulting in the need to quantize image information. Quantization is performed by having each element divided by another matrix of scalar values. The scalar divide is simple M[i,j]/Q[i,j] where Q is the quantization matrix. Let INVQ=(1/Q)={1/Q[i,j]}. It will be readily appreciated by one skilled in the art that if M and INVQ are treated as two textures, it would be a simple operation to perform D&#x2190;M*INVQ and complete the quantization using a graphics engine function, such as the blend engine <b>622</b>, or a texture mapping having blending capabilities.</p>
<p id="p-0057" num="0056">It will be appreciated that a specific embodiment of the present disclosure anticipates a first set of image data being provided to a graphics engine for processing. For example, the encoder engine <b>140</b> can provide image data to the graphics engine <b>120</b> for processing as previously described. The graphics engine provides a second data based upon the first set of image data that is received at the encoder engine <b>140</b>. Note that one of ordinary skill in the art will recognize that the data between processing engines can be received and provide through the use of pointers to memory locations. The processed information is then used by the graphics engine to determine a motion vector for the first set of image data.</p>
<p id="p-0058" num="0057">One of ordinary skill in the art will recognize that encoder control logic can be used to submit commands to a graphics engine for processing. Alternatively, encoder control logic can multiplex into specific functions of a graphics engine, and use their functionality without specifically submitting actual graphics engine commands.</p>
<p id="p-0059" num="0058">Note that not all of the activities described above in the general description or the examples are required, that a portion of a specific activity may not be required, and that one or more further activities may be performed in addition to those described. Still further, the order in which activities are listed are not necessarily the order in which they are performed. After reading this specification, skilled artisans will be capable of determining what activities can be used for their specific needs or desires.</p>
<p id="p-0060" num="0059">In the foregoing specification, principles of the invention have been described above in connection with specific embodiments. However, one of ordinary skill in the art appreciates that one or more modifications or one or more other changes can be made to any one or more of the embodiments without departing from the scope of the invention as set forth in the claims below. Accordingly, the specification and figures are to be regarded in an illustrative rather than a restrictive sense and any and all such modifications and other changes are intended to be included within the scope of invention.</p>
<p id="p-0061" num="0060">Any one or more benefits, one or more other advantages, one or more solutions to one or more problems, or any combination thereof have been described above with regard to one or more specific embodiments. However, the benefit(s), advantage(s), solution(s) to problem(s), or any element(s) that may cause any benefit, advantage, or solution to occur or become more pronounced is not to be construed as a critical, required, or essential feature or element of any or all the claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method comprising:
<claim-text>applying a first operation to modify a first set of data to implement a first image rendering function, wherein the first image rendering function generates an image bit map to be displayed, and wherein a first set of data paths at an integrated circuit die is associated with implementation of the first image rendering function and a first subset of the first set of data paths is associated with an implementation of the first operation; and</claim-text>
<claim-text>applying the first operation to a modify a second set of data to implement a first image encoding function, wherein a second set of data paths at the integrated circuit is associated with an implementation of the first image encoding function and the second set of data paths includes the first subset of the first set of data paths.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first image rendering function is a texture mapping function and the first set of data includes texture data.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref> wherein the texture mapping function is a Z-test function.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref> wherein the first operation is a matrix compare operation.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first operation is a matrix compare operation.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first image encoding function determines a set of motion vectors based on the second set of data.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the first operation is a matrix arithmetic operation.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first operation is a matrix arithmetic operation.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second set of data includes an image bit map.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the first set of data includes an image bit map and primitive shape information, wherein the image bit map is to be provide a texture to a primitive corresponding to the primitive information.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the second set of data includes an image bit map.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first image encoding function quantizes a set of image data.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first image rendering function is a pixel blending function.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first operation is a dot product operation.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A system comprising:
<claim-text>a first set of hardware data paths that comprise a first set of components and connections through which information flows to implement a first image rendering function, the first set of data paths including a first subset associated with an implementation of the first imagine rendering function; and</claim-text>
<claim-text>a second set of hardware data paths that comprise a second set of components and connections through which information flows to implement a first image encoding function, wherein the first and second sets are different and wherein the second set of data paths includes the first subset of the first set of data paths.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first subset of the fit set of data paths implements a matrix arithmetic operation.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first subset of the first set of data paths implements a matrix compare operation.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the first image rendering function is a Z-test function.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the second set of data paths determine motion vectors for an image bit map.</claim-text>
</claim>
</claims>
</us-patent-grant>
