<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08624842-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08624842</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>13129977</doc-number>
<date>20090827</date>
</document-id>
</application-reference>
<us-application-series-code>13</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="regional">
<country>EP</country>
<doc-number>08305813</doc-number>
<date>20081118</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>331</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345168</main-classification>
</classification-national>
<invention-title id="d2e71">Projected and secured virtual keyboard</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5008847</doc-number>
<kind>A</kind>
<name>Lapeyre</name>
<date>19910400</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6169538</doc-number>
<kind>B1</kind>
<name>Nowlan et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6209104</doc-number>
<kind>B1</kind>
<name>Jalili</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2002/0171633</doc-number>
<kind>A1</kind>
<name>Brinjes</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345168</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>EP</country>
<doc-number>0 980 039</doc-number>
<kind>A2</kind>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>FR</country>
<doc-number>2 834 157</doc-number>
<kind>A1</kind>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>WO</country>
<doc-number>WO 99/14657</doc-number>
<kind>A1</kind>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00008">
<othercit>International Search Report (PCT/ISA/210) issued on Nov. 18, 2009, by European Patent Office as the International Searching Authority for International Application No. PCT/EP2009/061057.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
<us-citation>
<nplcit num="00009">
<othercit>Written Opinion (PCT/ISA/237) issued on Nov. 18, 2009, by European Patent Office as the International Searching Authority for International Application No. PCT/EP2009/061057.</othercit>
</nplcit>
<category>cited by applicant</category>
</us-citation>
</us-references-cited>
<number-of-claims>12</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110221681</doc-number>
<kind>A1</kind>
<date>20110915</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Rouchouze</last-name>
<first-name>Bruno</first-name>
<address>
<city>St Cyr sur Mer</city>
<country>FR</country>
</address>
</addressbook>
<residence>
<country>FR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Rouchouze</last-name>
<first-name>Bruno</first-name>
<address>
<city>St Cyr sur Mer</city>
<country>FR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Buchanan Ingersoll &#x26; Rooney PC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>Gemalto SA</orgname>
<role>03</role>
<address>
<city>Meudon</city>
<country>FR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Giesy</last-name>
<first-name>Adam R</first-name>
<department>2695</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/EP2009/061057</doc-number>
<kind>00</kind>
<date>20090827</date>
</document-id>
<us-371c124-date>
<date>20110518</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO2010/057692</doc-number>
<kind>A </kind>
<date>20100527</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The invention relates to a method for inputting a text in a distributed system that comprises a secured device, or server, communicating with at least one electronic device, or terminal. The method makes it possible to prepare an image by associating certain values to areas defining said image. The image is projected to the user who can touch the areas of the images that he wants to select as he would do with the keys of keyboard. The finger movements are analysed and the position of the virtual keys selected by the user is transmitted to the server that establishes a correlation between these positions and the previously associated values.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="175.26mm" wi="176.02mm" file="US08624842-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="212.51mm" wi="172.64mm" file="US08624842-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="213.87mm" wi="194.39mm" file="US08624842-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="193.72mm" wi="184.15mm" file="US08624842-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="137.75mm" wi="176.95mm" file="US08624842-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">The invention relates to a projected and secured virtual keyboard.</p>
<p id="p-0003" num="0002">The invention more particularly relates to a method for inputting a text based on the positioning space of the fingers while referring to a projected image.</p>
<p id="p-0004" num="0003">The European patent EP980039 describes a method for inputting characters through a virtual keyboard. A virtual keyboard is a means for inputting texts in the absence of a peripheral unit including one key per character and which is more particularly intended for equipment such as interactive television, cellular phones or personal terminals PDAs. Virtual keyboards can also be applied in the field of secured exchanges.</p>
<p id="p-0005" num="0004">Patent PCT W09914657 is known in the state of the art and discloses a virtual keyboard used on a computer screen to emulate a conventional keyboard. The coordinates of the keys of the virtual keyboard are stored in a memory as a table, by the computer. The key coordinates are sorted in the table as a function of their occurring frequency. A pointing device makes it possible to select the keys on the virtual keyboard. The input points generated by the pointing device are compared one by one to the coordinates of the keys kept in the coordinates table. To decide whether the input point matches a considered key, defined criteria are applied to a terminal function. If they match, the key is affected to the input point and the search stops. The search for the matching key goes on until a match is detected or until the end of the table.</p>
<p id="p-0006" num="0005">The American patent U.S. Pat. No. 5,008,847 discloses another type of virtual keyboard including a means of selection by a cursor moved on a graphic representation of a keyboard.</p>
<p id="p-0007" num="0006">These prior art solutions have the drawback of having a fixed geometry and of being easily spied on within the scope of the inputting of secret information. In addition, the prior art solutions are particularly vulnerable in case of presence of an hostile module on the electronic device in charge of presenting the virtual keyboard.</p>
<heading id="h-0002" level="1">BRIEF SUMMARY OF THE INVENTION</heading>
<p id="p-0008" num="0007">The object of the present invention is to remedy this drawback by providing a secured method for inputting a text using a virtual keyboard.</p>
<p id="p-0009" num="0008">Firstly, the invention is a method for inputting a text in a distributed system that comprises at least a secured device called a server, communicating with at least one electronic device called the terminal, and the method includes at least:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0009">a step of pre-calculation wherein at least one look-up table is established an image, at least an area of the image, and at least a value,</li>
        <li id="ul0002-0002" num="0010">a step of transmission of the image from the server to the terminal,</li>
        <li id="ul0002-0003" num="0011">a step of projection by the terminal of the image towards the user,</li>
        <li id="ul0002-0004" num="0012">a step of identification of the positions in space of the user's fingers in relation with the projection of the image,</li>
        <li id="ul0002-0005" num="0013">a step of restitution of the positions in space to the server,</li>
        <li id="ul0002-0006" num="0014">a step of interpretation by the server of the positions received in relation with the look-up table so as to obtain values of so-called candidate values.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0010" num="0015">The projection can be executed against a surface which is used as a screen.</p>
<p id="p-0011" num="0016">In one embodiment, the image shows several geometrically distinct areas. Such areas can form a set of keys.</p>
<p id="p-0012" num="0017">In one embodiment, the look-up table makes it possible to apply the positions to a second image.</p>
<p id="p-0013" num="0018">In one embodiment, the look-up table makes it possible to apply shifts to the positions so as to obtain corrected positions.</p>
<p id="p-0014" num="0019">In one embodiment, the method also includes a previous step during which the image can either be selected among a list of images saved in a memory which can be accessed by the server, or generated.</p>
<p id="p-0015" num="0020">The invention is also a terminal for inputting a text in relation with at least one secured device called a server, this terminal includes means for
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0021">receiving from the server an image</li>
        <li id="ul0004-0002" num="0022">projecting this image onto a support to a user</li>
        <li id="ul0004-0003" num="0023">identifying the positions in space of the user's fingers in relation with the projection of the image</li>
        <li id="ul0004-0004" num="0024">restituting the positions in space to the server.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0016" num="0025">In one embodiment, the means of identification of the positions in space of the user's fingers can be video capture means, pressure sensors positioned in said projection medium or radar emitters and receivers.</p>
<p id="p-0017" num="0026">The advantage of the invention is that the image sent by the server is not interpreted by the terminal. As a matter of fact, since the image is monolithic and not dissociated into areas, it makes the terminal unable to interpret the fingers positions that it noted.</p>
<p id="p-0018" num="0027">Now, the method is particularly adapted to a case where the server does not trust the terminal.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0028">Other characteristics and advantages of the invention will clearly appear upon reading the following description thereof, which is given as an indication and not as a limitation, while referring to the appended drawings wherein:</p>
<p id="p-0020" num="0029"><figref idref="DRAWINGS">FIG. 1</figref> shows an exemplary implementation of the invention;</p>
<p id="p-0021" num="0030"><figref idref="DRAWINGS">FIG. 2</figref> shows an exemplary implementation of the invention with an intermediate device intended for establishing the communication between the terminal and the server;</p>
<p id="p-0022" num="0031"><figref idref="DRAWINGS">FIG. 3</figref> shows an exemplary image which can be used by the invention wherein the graphic areas showing the keys are positioned in a circle;</p>
<p id="p-0023" num="0032"><figref idref="DRAWINGS">FIG. 4</figref> shows an exemplary image which can be used by the invention wherein the graphic areas showing the keys are mixed;</p>
<p id="p-0024" num="0033"><figref idref="DRAWINGS">FIG. 5</figref> shows an exemplary image which can be used by the invention wherein the graphic areas showing the keys are shown as a geographic map;</p>
<p id="p-0025" num="0034"><figref idref="DRAWINGS">FIG. 6</figref> is an illustration of an implementation of the invention where the projection of the image makes a positive angle with the supporting angle;</p>
<p id="p-0026" num="0035"><figref idref="DRAWINGS">FIG. 7</figref> is an illustration of an implementation of the invention where the projection of the image is on a surface sensitive to pressure.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0027" num="0036">The invention may be schematically and not limitatively a method for inputting a text in a distributed system that comprises at least a secured device called a server, communicating with at least one electronic device called the terminal.</p>
<p id="p-0028" num="0037">This method can, among other things, make it possible to prepare an image by associating values with some areas which it is composed of.</p>
<p id="p-0029" num="0038">This image is projected to the user which will touch the areas of the image he wishes to select, as he would do for the keys of a keyboard.</p>
<p id="p-0030" num="0039">The motions of the fingers are analysed and the positions of the virtual keys that he selected are transmitted to the server which will make the correlation between these positions and the previously associated values.</p>
<p id="p-0031" num="0040">Thus, <figref idref="DRAWINGS">FIG. 1</figref> illustrates an implementation of the invention wherein a user tries to access a remote service, hosted by a server <b>2</b>, via a network <b>4</b>. In order to authentify the user, the server <b>2</b> transmits <b>3</b> an image to a terminal <b>1</b> which is directly in contact with the user. This terminal is provided with means making it possible to display <b>5</b> the received image to the user's view. In the example illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, the display of the image is executed by a projection onto a medium. In a previous step, the server <b>2</b> &#x201c;builds&#x201d; the image by identifying thereon particular areas which information is associated with. An example is the image of a numeric keypad and to each one of the areas matching each one of the keys is associated the value of a key. In another example, a geographic map of a country can be divided into areas and a value can be affected to each one of these areas. According to the embodiments, the correlation information between the image and the areas and the associated values can be stored in a memory of the server or in any other memory accessible by the server.</p>
<p id="p-0032" num="0041">In one particularly advantageous implementation of the invention, this correlation information can be saved in a secured electronic device. This secured electronic device can be for example a secured mobile device giving independence to the functionality of the server and of the server hardware. Any communicating electronic device may potentially become a server if it is placed in contact with the secured mobile device which contains the correlation information.</p>
<p id="p-0033" num="0042">The terminal <b>1</b> is provided with means making it possible to analyse the motions about the projection <b>5</b>. This analysis includes several steps and several devices. As a matter of fact, such an analysis includes a capture of motions close to the displayed image <b>5</b> and the analysis thereof in order to extract positions from said inputs. Such inputting positions will represent the selection by the user of geographic areas of the image <b>5</b>. A particularly explicit illustration of this analysis is given by the example where the image <b>5</b> shows a computer keypad. The user puts his fingers close to the surface of the image <b>5</b> and places his fingers on the areas of the image which correspond to the keys of the digital code he wants to input. Then, the analysis according to the invention consists in capturing the motions of the user's fingers close to the image <b>5</b> of the digital keyboard <b>5</b>, and analyses these so as to provide positions corresponding to the areas touched by the user.</p>
<p id="p-0034" num="0043">In the example illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, such an analysis can be executed by using video capture means <b>6</b>. Any other means for identifying the movement of a physical object in a defined space can be used for analysing the motions and these are solutions which can be used. In a particular implementation, two cameras are associated together in order to obtain an optimum accuracy in the motion analysis. In one embodiment, the video capture means can have, with the display medium <b>5</b>, a positive angle as illustrated by <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0035" num="0044">Such analysis is sent back <b>7</b> to terminal <b>2</b> which will in turn process such data in relation with the information of correlation between the image <b>5</b>, the areas composing it and the values associated thereto.</p>
<p id="p-0036" num="0045">The result of this authentication will decide on the further action given to the user's request.</p>
<p id="p-0037" num="0046"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an implementation of the invention wherein the terminal <b>11</b> is in relation with the server <b>12</b> thanks to a communicating electronic device <b>16</b>, which is itself able to communicate with the server <b>12</b> through a network <b>14</b>, for example radiotelephony. This embodiment is particularly adapted to the case where the communicating electronic device and the server offer the user a service requiring a high authentication, for example a banking service. Considering the large diversity of the communicating electronic devices, it is very difficult for the server to build the security of the service on a device which is it does not control and for which is not able to guarantee safety. By associating the terminal with the electronic device, the server authenticates the user through the communication channel represented by the electronic device without being afraid of possible security flaws therein. As a matter of fact, the communicating device as well as the terminal, sees an image sent in one direction and positions sent in another direction, but without having information making it possible to correlate both and to extract operational values therefrom. In a particularly advantageous mode of the embodiment, the terminal has authentication means which are its own and can be authentified with the server so that the exchanges <b>13</b> and <b>15</b> can be carried out through a secured communication channel, for example using a session key, which still reinforces the system safety.</p>
<p id="p-0038" num="0047">In <figref idref="DRAWINGS">FIGS. 3</figref>, <b>4</b> and <b>5</b> various exemplary images can be seen which can be used according to the invention. <figref idref="DRAWINGS">FIG. 3</figref> illustrates the case where the areas composing the images are mixed together, so that the geography of the virtual keyboard shown by the images changes. Similarly, <figref idref="DRAWINGS">FIG. 4</figref> illustrates the case where geography of the &#x201c;virtual keyboard&#x201d; remains unchanged, but the values of the areas are rearranged. Both techniques can advantageously be combined to vary both the organisation of areas and their sequences. In a particularly interesting embodiment of the invention, during each session the sent image is either selected among a pre-defined list of images, or generated. This precaution makes it possible to get protection against a possible recording of exchanges between the terminal and the server during several sessions, and to make a correlation between the information supplied by each recording.</p>
<p id="p-0039" num="0048"><figref idref="DRAWINGS">FIG. 5</figref> shows an exemplary image through which information is input through a symbolic convention. For example, the image can represent a series of colours and the convention between the user and the server is that the user must select the blue, green and red colours.</p>
<p id="p-0040" num="0049"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an implementation of the invention wherein the means for analysing the motions at the periphery of the projection of the image according to the invention makes a positive angle with the supporting angle. The terminal according to the invention is shown in <figref idref="DRAWINGS">FIG. 6</figref> by the element <b>51</b>. In this example, the terminal <b>51</b> projects an image <b>55</b> onto a plane <b>56</b>. This plane can for example be a plane surface on which the terminal will be positioned. The terminal further has means <b>52</b> for analysing motions. As illustrated by the symbolic axis <b>53</b>, this means is oriented so as to analyse motions at the direct periphery of the projection <b>55</b> of the image. <figref idref="DRAWINGS">FIG. 6</figref> illustrates the particularly advantageous case where the analysis means <b>52</b> has an angle <b>54</b> which is positive to the surface of projection <b>56</b>. This particular implementation significantly increases the performances of the motion analysis. An angle <b>54</b> close to 90 degrees will give large facilities for an analysis.</p>
<p id="p-0041" num="0050">In another embodiment, <figref idref="DRAWINGS">FIG. 7</figref> illustrates the case where the device <b>61</b> projects an image <b>65</b> according to the invention on a surface <b>62</b> sensitive to pressure. This surface <b>62</b> will then be able to identify the places where the user puts his fingers on the surface thereof and to restitute this analysis to the terminal <b>61</b>.</p>
<p id="p-0042" num="0051">An additional advantage of the invention is that, contrary to the standard inputting means, the use of an input terminal according to the invention leaves no trace on the keyboard after it has been used, since the disappearance of the image eliminates any reference at the same time. Similarly, it is not possible to study a possible wearing of the keys in order to deduce possible information therefrom.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for inputting a text in a distributed system that comprises at least a secured device or server communicating with at least one electronic device or terminal, wherein the method includes:
<claim-text>a step of pre-calculation wherein at least a look-up table is created between an image, at least an area in said image, and at least a value,</claim-text>
<claim-text>a step of transmission of said image from said server to said terminal,</claim-text>
<claim-text>a step of projection by said terminal of said image to a user,</claim-text>
<claim-text>a step of identification of the positions in space of the user's fingers in relation with said projection of said image,</claim-text>
<claim-text>a step of restitution of said positions in space to said server, and</claim-text>
<claim-text>a step of interpretation by the server of the received positions in relation with said at least one look-up table in order to obtain candidate values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said projection is executed against a surface which is used as a screen.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image shows several geometrically distinct areas.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein said image defines a set of keys.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said look-up table makes it possible to apply said positions to a second image.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said look-up table makes it possible to apply shifts to said positions in order to obtain corrected positions.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image is selected from among a list of images saved in a memory which can be accessed by said server.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image is generated in a step preceding said pre-calculation step.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A terminal for inputting text in relation with at least one secured device or server, wherein the terminal includes means for:
<claim-text>receiving, from said server, an image</claim-text>
<claim-text>projecting said image onto a medium for receiving by a user</claim-text>
<claim-text>identifying the positions in space of the user's fingers in relation with such projection of said image</claim-text>
<claim-text>restituting said positions in space to said server.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A terminal for inputting text according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein said means for identifying the positions in space of the user's fingers are video capture means.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A terminal for inputting text according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein said means for identifying the positions in space of the user's fingers are pressure sensors positioned in said projection medium.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A terminal for inputting text according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein said means for identifying the positions in space of the user's fingers are radar emitters and receivers. </claim-text>
</claim>
</claims>
</us-patent-grant>
