<!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v44-2013-05-16.dtd" [ ]>
<us-patent-grant lang="EN" dtd-version="v4.4 2013-05-16" file="US08627236-20140107.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20131224" date-publ="20140107">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>08627236</doc-number>
<kind>B2</kind>
<date>20140107</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>12881993</doc-number>
<date>20100914</date>
</document-id>
</application-reference>
<us-application-series-code>12</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2009-0105637</doc-number>
<date>20091103</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>599</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20130101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>033</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20140107</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>715863</main-classification>
<further-classification>712702</further-classification>
<further-classification>712836</further-classification>
<further-classification>712849</further-classification>
<further-classification>712864</further-classification>
</classification-national>
<invention-title id="d2e71">Terminal and control method thereof</invention-title>
<us-references-cited>
<us-citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2304434</doc-number>
<kind>A</kind>
<name>Ayres</name>
<date>19421200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>355 46</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4078860</doc-number>
<kind>A</kind>
<name>Globus et al.</name>
<date>19780300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>352 69</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5515486</doc-number>
<kind>A</kind>
<name>Amro et al.</name>
<date>19960500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5678015</doc-number>
<kind>A</kind>
<name>Goh</name>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715782</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5767854</doc-number>
<kind>A</kind>
<name>Anwar</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5898435</doc-number>
<kind>A</kind>
<name>Nagahara et al.</name>
<date>19990400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715841</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5963213</doc-number>
<kind>A</kind>
<name>Guedalia et al.</name>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345427</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5995110</doc-number>
<kind>A</kind>
<name>Litwinowicz</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6028584</doc-number>
<kind>A</kind>
<name>Chiang et al.</name>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345628</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6069606</doc-number>
<kind>A</kind>
<name>Sciammarella et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345660</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6144501</doc-number>
<kind>A</kind>
<name>Nalwa</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>359725</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6184884</doc-number>
<kind>B1</kind>
<name>Nagahara et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715828</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6236398</doc-number>
<kind>B1</kind>
<name>Kojima et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6243093</doc-number>
<kind>B1</kind>
<name>Czerwinski et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6266098</doc-number>
<kind>B1</kind>
<name>Cove et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348563</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6285365</doc-number>
<kind>B1</kind>
<name>Nalwa</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715835</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6335737</doc-number>
<kind>B1</kind>
<name>Grossman et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715719</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6337683</doc-number>
<kind>B1</kind>
<name>Gilbert et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345418</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6448987</doc-number>
<kind>B1</kind>
<name>Easty et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715834</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6466237</doc-number>
<kind>B1</kind>
<name>Miyao et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715838</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6505194</doc-number>
<kind>B1</kind>
<name>Nikolovska et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707768</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6590586</doc-number>
<kind>B1</kind>
<name>Swenton-Wall et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715730</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6654019</doc-number>
<kind>B2</kind>
<name>Ripley et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345474</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>6774914</doc-number>
<kind>B1</kind>
<name>Benayoun</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345650</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>6880132</doc-number>
<kind>B2</kind>
<name>Uemura</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>6978051</doc-number>
<kind>B2</kind>
<name>Edwards</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382284</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>7091998</doc-number>
<kind>B2</kind>
<name>Miller-Smith</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715810</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>7317473</doc-number>
<kind>B2</kind>
<name>Chen et al.</name>
<date>20080100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 39</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>7346373</doc-number>
<kind>B2</kind>
<name>Kim</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455566</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>7383503</doc-number>
<kind>B2</kind>
<name>Banks</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715273</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>7400782</doc-number>
<kind>B2</kind>
<name>Zhou et al.</name>
<date>20080700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382284</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>7424218</doc-number>
<kind>B2</kind>
<name>Baudisch et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396322</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>7426467</doc-number>
<kind>B2</kind>
<name>Nashida et al.</name>
<date>20080900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704275</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>7437005</doc-number>
<kind>B2</kind>
<name>Drucker et al.</name>
<date>20081000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382224</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>7486324</doc-number>
<kind>B2</kind>
<name>Driscoll, Jr. et al.</name>
<date>20090200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348335</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>7503014</doc-number>
<kind>B2</kind>
<name>Tojo et al.</name>
<date>20090300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715810</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>7543245</doc-number>
<kind>B2</kind>
<name>Irimajiri</name>
<date>20090600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715836</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>7567274</doc-number>
<kind>B2</kind>
<name>Ekpar</name>
<date>20090700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482119</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>7590995</doc-number>
<kind>B2</kind>
<name>Nakamura et al.</name>
<date>20090900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 52</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>7675514</doc-number>
<kind>B2</kind>
<name>Ni et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>7681150</doc-number>
<kind>B2</kind>
<name>Hsieh et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715854</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>7710423</doc-number>
<kind>B2</kind>
<name>Drucker et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345474</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>7730425</doc-number>
<kind>B2</kind>
<name>de los Reyes et al.</name>
<date>20100600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715835</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>7761813</doc-number>
<kind>B2</kind>
<name>Kim et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715836</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>7797641</doc-number>
<kind>B2</kind>
<name>Karukka et al.</name>
<date>20100900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715802</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>7814439</doc-number>
<kind>B2</kind>
<name>Fitzmaurice et al.</name>
<date>20101000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715856</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>7898529</doc-number>
<kind>B2</kind>
<name>Fitzmaurice et al.</name>
<date>20110300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>7961980</doc-number>
<kind>B2</kind>
<name>Shih</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382285</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>7966575</doc-number>
<kind>B1</kind>
<name>Jetha et al.</name>
<date>20110600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715817</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>7992102</doc-number>
<kind>B1</kind>
<name>De Angelo</name>
<date>20110800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715834</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>8028250</doc-number>
<kind>B2</kind>
<name>Vronay et al.</name>
<date>20110900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715853</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>8111255</doc-number>
<kind>B2</kind>
<name>Park</name>
<date>20120200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>8120605</doc-number>
<kind>B2</kind>
<name>Lee et al.</name>
<date>20120200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>8217956</doc-number>
<kind>B1</kind>
<name>Jin</name>
<date>20120700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345585</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>8223127</doc-number>
<kind>B2</kind>
<name>Park et al.</name>
<date>20120700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345169</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>8291341</doc-number>
<kind>B2</kind>
<name>Tseng et al.</name>
<date>20121000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715786</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>8325187</doc-number>
<kind>B2</kind>
<name>Shenhav et al.</name>
<date>20121200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345427</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00058">
<document-id>
<country>US</country>
<doc-number>8370770</doc-number>
<kind>B2</kind>
<name>Vance et al.</name>
<date>20130200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715834</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00059">
<document-id>
<country>US</country>
<doc-number>8375334</doc-number>
<kind>B2</kind>
<name>Nakano et al.</name>
<date>20130200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00060">
<document-id>
<country>US</country>
<doc-number>2001/0010546</doc-number>
<kind>A1</kind>
<name>Chen</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348218</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00061">
<document-id>
<country>US</country>
<doc-number>2001/0028369</doc-number>
<kind>A1</kind>
<name>Gallo et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00062">
<document-id>
<country>US</country>
<doc-number>2002/0054114</doc-number>
<kind>A1</kind>
<name>Shuping et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345764</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00063">
<document-id>
<country>US</country>
<doc-number>2002/0118890</doc-number>
<kind>A1</kind>
<name>Rondinelli</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382276</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00064">
<document-id>
<country>US</country>
<doc-number>2003/0063089</doc-number>
<kind>A1</kind>
<name>Chen et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345473</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00065">
<document-id>
<country>US</country>
<doc-number>2003/0167466</doc-number>
<kind>A1</kind>
<name>Nakamura et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725 39</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00066">
<document-id>
<country>US</country>
<doc-number>2004/0100479</doc-number>
<kind>A1</kind>
<name>Nakano et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345700</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00067">
<document-id>
<country>US</country>
<doc-number>2004/0155907</doc-number>
<kind>A1</kind>
<name>Yamaguchi et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345810</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00068">
<document-id>
<country>US</country>
<doc-number>2004/0257384</doc-number>
<kind>A1</kind>
<name>Park et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345646</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00069">
<document-id>
<country>US</country>
<doc-number>2005/0086612</doc-number>
<kind>A1</kind>
<name>Gettman et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715848</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00070">
<document-id>
<country>US</country>
<doc-number>2005/0091596</doc-number>
<kind>A1</kind>
<name>Anthony et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715712</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00071">
<document-id>
<country>US</country>
<doc-number>2005/0192924</doc-number>
<kind>A1</kind>
<name>Drucker et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  1</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00072">
<document-id>
<country>US</country>
<doc-number>2005/0278656</doc-number>
<kind>A1</kind>
<name>Goldthwaite et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715810</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00073">
<document-id>
<country>US</country>
<doc-number>2006/0004873</doc-number>
<kind>A1</kind>
<name>Wong et al.</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>7071041</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00074">
<document-id>
<country>US</country>
<doc-number>2006/0156228</doc-number>
<kind>A1</kind>
<name>Gallo et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715523</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00075">
<document-id>
<country>US</country>
<doc-number>2006/0156246</doc-number>
<kind>A1</kind>
<name>Williams et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715764</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00076">
<document-id>
<country>US</country>
<doc-number>2007/0011617</doc-number>
<kind>A1</kind>
<name>Akagawa et al.</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715738</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00077">
<document-id>
<country>US</country>
<doc-number>2007/0081796</doc-number>
<kind>A1</kind>
<name>Fredlund et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386125</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00078">
<document-id>
<country>US</country>
<doc-number>2007/0083911</doc-number>
<kind>A1</kind>
<name>Madden et al.</name>
<date>20070400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>725135</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00079">
<document-id>
<country>US</country>
<doc-number>2007/0162853</doc-number>
<kind>A1</kind>
<name>Weber et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715719</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00080">
<document-id>
<country>US</country>
<doc-number>2007/0269198</doc-number>
<kind>A1</kind>
<name>Park et al.</name>
<date>20071100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396322</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00081">
<document-id>
<country>US</country>
<doc-number>2008/0033641</doc-number>
<kind>A1</kind>
<name>Medalia</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701209</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00082">
<document-id>
<country>US</country>
<doc-number>2008/0034326</doc-number>
<kind>A1</kind>
<name>Chiu et al.</name>
<date>20080200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715849</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00083">
<document-id>
<country>US</country>
<doc-number>2008/0062141</doc-number>
<kind>A1</kind>
<name>Chandhri</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345173</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00084">
<document-id>
<country>US</country>
<doc-number>2008/0066016</doc-number>
<kind>A1</kind>
<name>Dowdy et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715854</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00085">
<document-id>
<country>US</country>
<doc-number>2008/0074500</doc-number>
<kind>A1</kind>
<name>Chen et al.</name>
<date>20080300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482071</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00086">
<document-id>
<country>US</country>
<doc-number>2008/0143709</doc-number>
<kind>A1</kind>
<name>Fassero et al.</name>
<date>20080600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00087">
<document-id>
<country>US</country>
<doc-number>2008/0291201</doc-number>
<kind>A1</kind>
<name>Lafon</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345427</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00088">
<document-id>
<country>US</country>
<doc-number>2008/0292213</doc-number>
<kind>A1</kind>
<name>Chau</name>
<date>20081100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382294</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00089">
<document-id>
<country>US</country>
<doc-number>2009/0119589</doc-number>
<kind>A1</kind>
<name>Rowell et al.</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715716</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00090">
<document-id>
<country>US</country>
<doc-number>2009/0138823</doc-number>
<kind>A1</kind>
<name>Bradea</name>
<date>20090500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715835</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00091">
<document-id>
<country>US</country>
<doc-number>2009/0204920</doc-number>
<kind>A1</kind>
<name>Beverley et al.</name>
<date>20090800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715768</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00092">
<document-id>
<country>US</country>
<doc-number>2010/0023895</doc-number>
<kind>A1</kind>
<name>Benko et al.</name>
<date>20100100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715863</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00093">
<document-id>
<country>US</country>
<doc-number>2010/0054628</doc-number>
<kind>A1</kind>
<name>Levy et al.</name>
<date>20100300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382284</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00094">
<document-id>
<country>US</country>
<doc-number>2010/0093400</doc-number>
<kind>A1</kind>
<name>Ju et al.</name>
<date>20100400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455566</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00095">
<document-id>
<country>US</country>
<doc-number>2010/0111429</doc-number>
<kind>A1</kind>
<name>Wang et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382233</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00096">
<document-id>
<country>US</country>
<doc-number>2010/0123737</doc-number>
<kind>A1</kind>
<name>Williamson et al.</name>
<date>20100500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345672</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00097">
<document-id>
<country>US</country>
<doc-number>2010/0175026</doc-number>
<kind>A1</kind>
<name>Bortner et al.</name>
<date>20100700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715818</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00098">
<document-id>
<country>US</country>
<doc-number>2011/0096089</doc-number>
<kind>A1</kind>
<name>Shenhav et al.</name>
<date>20110400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345619</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00099">
<document-id>
<country>US</country>
<doc-number>2011/0099524</doc-number>
<kind>A1</kind>
<name>Jeong et al.</name>
<date>20110400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715843</main-classification></classification-national>
</us-citation>
<us-citation>
<patcit num="00100">
<document-id>
<country>US</country>
<doc-number>2011/0105192</doc-number>
<kind>A1</kind>
<name>Jung et al.</name>
<date>20110500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>455566</main-classification></classification-national>
</us-citation>
</us-references-cited>
<number-of-claims>18</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>715702</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715836</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715849</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715864</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>16</number-of-drawing-sheets>
<number-of-figures>23</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20110105192</doc-number>
<kind>A1</kind>
<date>20110505</date>
</document-id>
</related-publication>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="001" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Jung</last-name>
<first-name>Sungon</first-name>
<address>
<city>Gyeonggi-Do</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="002" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Namsu</first-name>
<address>
<city>Gyeonggi-Do</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="003" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Park</last-name>
<first-name>Booil</first-name>
<address>
<city>Gyeonggi-Do</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
<us-applicant sequence="004" app-type="applicant" designation="us-only">
<addressbook>
<last-name>Kwak</last-name>
<first-name>Jeongmin</first-name>
<address>
<city>Gyeongbuk</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="001" designation="us-only">
<addressbook>
<last-name>Jung</last-name>
<first-name>Sungon</first-name>
<address>
<city>Gyeonggi-Do</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="002" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Namsu</first-name>
<address>
<city>Gyeonggi-Do</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="003" designation="us-only">
<addressbook>
<last-name>Park</last-name>
<first-name>Booil</first-name>
<address>
<city>Gyeonggi-Do</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="004" designation="us-only">
<addressbook>
<last-name>Kwak</last-name>
<first-name>Jeongmin</first-name>
<address>
<city>Gyeongbuk</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Lee, Hong, Degerman, Kang &#x26; Waimey</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>LG Electronics Inc.</orgname>
<role>03</role>
<address>
<city>Seoul</city>
<country>KR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Theriault</last-name>
<first-name>Steven B</first-name>
<department>2179</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Disclosed is a mobile terminal and a control method thereof capable of displaying an image or data in a particular object shape. When an image list is displayed and then any one particular image of the list is selected, the selected image is converted into a particular preset object shape to be displayed if the selected image is a panorama-type image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="124.97mm" wi="165.44mm" file="US08627236-20140107-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="207.26mm" wi="151.21mm" file="US08627236-20140107-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="226.57mm" wi="172.38mm" file="US08627236-20140107-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="212.85mm" wi="165.10mm" file="US08627236-20140107-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="202.86mm" wi="167.56mm" file="US08627236-20140107-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="236.98mm" wi="105.07mm" file="US08627236-20140107-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="224.11mm" wi="122.51mm" file="US08627236-20140107-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="153.25mm" wi="165.10mm" file="US08627236-20140107-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="165.18mm" wi="110.91mm" file="US08627236-20140107-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="99.48mm" wi="118.28mm" file="US08627236-20140107-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="243.16mm" wi="158.16mm" file="US08627236-20140107-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="194.65mm" wi="157.82mm" file="US08627236-20140107-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="110.41mm" wi="172.30mm" file="US08627236-20140107-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="215.14mm" wi="174.33mm" file="US08627236-20140107-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="240.96mm" wi="163.07mm" file="US08627236-20140107-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="248.07mm" wi="102.45mm" file="US08627236-20140107-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="87.63mm" wi="92.63mm" file="US08627236-20140107-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATION</heading>
<p id="p-0002" num="0001">Pursuant to 35 U.S.C. &#xa7;119(a), this application claims the benefit of earlier filing date and right of priority to Korean Application No. 10-2009-0105637, filed on Nov. 3, 2009, the contents of which is incorporated by reference herein in its entirety.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to a mobile terminal and a control method thereof capable of displaying an image or data in a particular object shape.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Terminals can be classified into two types, such as a mobile terminal and a stationary terminal based on its mobility. Furthermore, the mobile terminal can be further classified into two types, such as a handheld terminal and a vehicle mount terminal based on whether or not it can be directly carried by a user.</p>
<p id="p-0007" num="0006">As it becomes multifunctional, furthermore, such a terminal is allowed to capture still images or moving images, play music or video files, play games, receive broadcast and the like, so as to be implemented as an integrated multimedia player. For a functional support and enhancement of the terminal, it may be considered to improve a structural and/or software aspect of the terminal.</p>
<p id="p-0008" num="0007">The mobile terminal can capture a panorama photo. The panorama photo is made to be longer in a horizontal or vertical direction than a normal photo, which contains more scenes or screens than the normal photo. The panorama photo may be accomplished by pasting several copies of partially-captured photos together to be longer in a horizontal or vertical direction without overlapping one another.</p>
<p id="p-0009" num="0008">However, in case of displaying the panorama photo, it may be displayed to be longer in a horizontal or vertical direction like a flat sticker shape. Therefore, it has a problem in which a vertical width thereof becomes narrow according to the horizontal length, and a horizontal width thereof becomes narrow according to the vertical length. Furthermore, an entire image should be enlarged to find a user's desired portion on that image because the width of the image is narrow as described above, thereby causing a problem in which the panorama photo cannot be seen as a whole in case of enlarging a portion of the image.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">The present invention is to provide a mobile terminal and a control method thereof capable of displaying an image or data in a particular object shape.</p>
<p id="p-0011" num="0010">Furthermore, the present invention is to provide a mobile terminal and a control method thereof capable of displaying an image according to a capture angle.</p>
<p id="p-0012" num="0011">Furthermore, the present invention is to provide a mobile terminal and a control method thereof capable of displaying an image according to a capture orientation.</p>
<p id="p-0013" num="0012">Furthermore, the present invention is to provide a mobile terminal and a control method thereof capable of automatically rotating and displaying an image according to a particular preset condition.</p>
<p id="p-0014" num="0013">Furthermore, the present invention is to provide a mobile terminal and a control method thereof capable of displaying other parties on a video call in a particular object shape.</p>
<p id="p-0015" num="0014">In order to accomplish the foregoing object, the present invention may include a display unit, a touch pad configured to select an image displayed on the display unit, and a controller configured to determine the type of the selected image, and convert into a particular preset object shape to display the image if the image is a panorama-type image.</p>
<p id="p-0016" num="0015">Furthermore, in order to accomplish the foregoing object, when an image list is displayed and then any one particular image of the list is selected, the present invention is provided to convert the selected image into a particular preset object shape and display the converted image if the selected image is a panorama-type image.</p>
<p id="p-0017" num="0016">A mobile terminal associated with at least one embodiment of the present invention having the foregoing configuration can display a panorama-type image with a particular object shape, and rotate and display the image displayed with the object shape according to a particular preset condition.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0018" num="0017">The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of this specification, illustrate embodiments of the invention and together with the description serve to explain the principles of the invention.</p>
<p id="p-0019" num="0018">In the drawings:</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a mobile terminal associated with an embodiment of the present invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 2</figref><i>a </i>is a front perspective view illustrating a portable terminal associated with an embodiment of the present invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 2</figref><i>b </i>is a rear perspective view illustrating a portable terminal associated with an embodiment of the present invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>3</b><i>b </i>are illustrative views for explaining a difference between a normal photo and a panorama photo;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 4</figref><i>a </i>and <b>4</b><i>b </i>are illustrative views for explaining an advantage of an image display method associated with the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 5</figref> is an illustrative view for explaining a method of displaying a panorama photo selected in a mobile terminal associated with the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 6</figref> is an illustrative view illustrating objects displayed with a panorama photo in a mobile terminal associated with the present invention;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 7</figref> is an illustrative view for explaining a method of displaying a panorama photo in such a manner that the photo is captured by the user according to the present invention;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIGS. 8</figref><i>a </i>through <b>8</b><i>c </i>are illustrative views for explaining a method of rotating an image displayed on a mobile terminal associated with the present invention according to a particular condition;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. 9</figref><i>a </i>through <b>9</b><i>c </i>are illustrative views for explaining a method of suspending an image to be rotated on a mobile terminal associated with the present invention according to a particular condition;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. 10</figref><i>a </i>and <b>10</b><i>b </i>are illustrative views for explaining a method of changing the shape of an image displayed on a mobile terminal associated with the present invention;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 11</figref> is an illustrative view for explaining a method of setting an image displayed with a particular object shape to a standby screen according to the present invention;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIGS. 12</figref><i>a </i>through <b>12</b><i>c </i>are illustrative views for explaining a method of additionally displaying supplementary information on an image displayed with a particular object shape according to the present invention; and</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 13</figref> is an illustrative view for explaining a method of displaying user menus with a particular object shape according to the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0034" num="0033">Hereinafter, a mobile terminal associated with the present invention will be described in more detail with reference to the accompanying drawings. A suffix &#x201c;module&#x201d; or &#x201c;unit&#x201d; used for constituent elements disclosed in the following description is merely intended for easy description of the specification, and the suffix itself does not give any special meaning or function.</p>
<p id="p-0035" num="0034">A mobile terminal disclosed herein may include a portable phone, a smart phone, a laptop computer, a digital broadcast terminal, a personal digital assistant (PDA), a portable multimedia player (PMP), a navigation device, and the like. However, it would be easily understood by those skilled in the art that a configuration according to the embodiments disclosed herein may be applicable to stationary terminals such as digital TVs, desktop computers, and the like, as well as mobile terminals.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a mobile terminal associated with an embodiment of the present invention.</p>
<p id="p-0037" num="0036">The mobile terminal <b>100</b> may include a wireless communication unit <b>110</b>, an Audio/Video (NV) input unit <b>120</b>, a user input unit <b>130</b>, a sensing unit <b>140</b>, an output unit <b>150</b>, a memory <b>160</b>, an interface unit <b>170</b>, a controller <b>180</b>, a power supply unit <b>190</b>, and the like. However, the constituent elements as illustrated in <figref idref="DRAWINGS">FIG. 1</figref> are not necessarily required, and the mobile terminal may be implemented with greater or less number of elements than those illustrated elements.</p>
<p id="p-0038" num="0037">Hereinafter, the constituent elements will be described in sequence.</p>
<p id="p-0039" num="0038">The wireless communication unit <b>110</b> typically includes one or more modules allowing radio communication between the mobile terminal <b>100</b> and a wireless communication system, or allowing radio communication between radio communication the mobile terminal <b>100</b> and a network in which the mobile terminal <b>100</b> is located. For example, the wireless communication unit <b>110</b> may include a broadcast receiving module <b>111</b>, a mobile communication module <b>112</b>, a wireless Internet module <b>113</b>, a short-range communication module <b>114</b>, a location information module <b>115</b>, and the like.</p>
<p id="p-0040" num="0039">The broadcast receiving module <b>111</b> receives broadcast signals and/or broadcast associated information from an external broadcast management server through a broadcast channel.</p>
<p id="p-0041" num="0040">The broadcast channel may include a satellite channel and/or a terrestrial channel. The broadcast management server may mean a server that generates and transmits a broadcast signal and/or broadcast associated information or a server that receives a previously generated broadcast signal and/or broadcast associated information and transmits to the mobile terminal <b>100</b>. The broadcast signal may include a TV broadcast signal, a radio broadcast signal and a data broadcast signal as well as a broadcast signal in a form that a data broadcast signal is combined with the TV or radio broadcast signal.</p>
<p id="p-0042" num="0041">The broadcast associated information may mean information regarding a broadcast channel, a broadcast program, a broadcast service provider, and the like. The broadcast associated information may also be provided through a mobile communication network, and in this case, the broadcast associated information may be received by the mobile communication module <b>112</b>.</p>
<p id="p-0043" num="0042">The broadcast associated information may exist in various forms. For example, it may exist in the form of an electronic program guide (EPG) of digital multimedia broadcasting (DMB), electronic service guide (ESG) of digital video broadcast-handheld (DVB-H), and the like.</p>
<p id="p-0044" num="0043">The broadcast receiving module <b>111</b> may receive a broadcast signal using various types of broadcast systems. In particular, the broadcast receiving module <b>111</b> may receive a digital broadcast signal using a digital broadcast system such as digital multimedia broadcasting-terrestrial (DMB-T), digital multimedia broadcasting-satellite (DMB-S), media forward link only (MediaFLO), digital video broadcast-handheld (DVB-H), integrated services digital broadcast-terrestrial (ISDB-T), and the like. The broadcast receiving module <b>111</b> is, of course, configured to be suitable for every broadcast system that provides a broadcast signal as well as the above-mentioned digital broadcast systems.</p>
<p id="p-0045" num="0044">The broadcast signal and/or broadcast-associated information received through the broadcast receiving module <b>111</b> may be stored in the memory <b>160</b>.</p>
<p id="p-0046" num="0045">The mobile communication module <b>112</b> transmits and/or receives a radio signal to and/or from at least one of a base station, an external terminal and a server over a mobile communication network. Here, the radio signal may include a voice call signal, a video call signal and/or various types of data according to text and/or multimedia message transmission and/or reception.</p>
<p id="p-0047" num="0046">The wireless Internet module <b>113</b> means a module for supporting wireless Internet access. The wireless Internet module <b>113</b> may be built-in or externally installed to the mobile terminal <b>100</b>. Here, it may be used a wireless Internet access technique including a WLAN (Wireless LAN), Wi-Fi, Wibro (Wireless Broadband), Wimax (World Interoperability for Microwave Access), HSDPA (High Speed Downlink Packet Access), and the like.</p>
<p id="p-0048" num="0047">The short-range communication module <b>114</b> is a module for supporting a short-range communication. Here, it may be used a short-range communication technology including Bluetooth, Radio Frequency IDentification (RFID), Infrared Data Association (IrDA), Ultra WideBand (UWB), ZigBee, and the like.</p>
<p id="p-0049" num="0048">The location information module <b>115</b> is a module for checking or acquiring a location of the mobile terminal, and there is a GPS module as a representative example.</p>
<p id="p-0050" num="0049">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, the A/V (audio/video) input unit <b>120</b> receives an audio or video signal, and the NV (audio/video) input unit <b>120</b> may include a camera <b>121</b> and a microphone <b>122</b>. The camera <b>121</b> processes a image frame, such as still picture or video, obtained by an image sensor in a video phone call or image capturing mode. The processed image frame may be displayed on a display unit <b>151</b>.</p>
<p id="p-0051" num="0050">The image frames processed by the camera <b>121</b> may be stored in the memory <b>160</b> or transmitted to an external device through the wireless communication unit <b>110</b>. Two or more cameras <b>121</b> may be provided according to the use environment of the mobile terminal.</p>
<p id="p-0052" num="0051">The microphone <b>122</b> receives an external audio signal through a microphone in a phone call mode, a recording mode, a voice recognition mode, and the like, and processes the audio signal into electrical voice data. The processed voice data may be converted and outputted into a format that is transmittable to a mobile communication base station through the mobile communication module <b>112</b> in the phone call mode. The microphone <b>122</b> may implement various types of noise canceling algorithms to cancel noise generated in a procedure of receiving the external audio signal.</p>
<p id="p-0053" num="0052">The user input unit <b>130</b> may generate input data to control an operation of the terminal. The user input unit <b>130</b> may be configured by including a keypad, a dome switch, a touch pad (pressure/capacitance), a jog wheel, a jog switch, and the like.</p>
<p id="p-0054" num="0053">The sensing unit <b>140</b> detects a current status of the mobile terminal <b>100</b> such as an opened or closed state of the mobile terminal <b>100</b>, a location of the mobile terminal <b>100</b>, an orientation of the mobile terminal <b>100</b>, and the like, and generates a sensing signal for controlling the operation of the mobile terminal <b>100</b>. For example, when the mobile terminal <b>100</b> is a slide phone type, it may sense an opened or closed state of the slide phone. Furthermore, the sensing unit <b>140</b> takes charge of a sensing function associated with whether or not power is supplied from the power supply unit <b>190</b>, or whether or not an external device is coupled to the interface unit <b>170</b>. On the other hand, the sensing unit <b>140</b> may include a proximity sensor <b>141</b>.</p>
<p id="p-0055" num="0054">The output unit <b>150</b> is configured to provide an output for audio signal, video signal, or alarm signal, and the output unit <b>150</b> may include the display unit <b>151</b>, an audio output module <b>152</b>, an alarm unit <b>153</b>, a haptic module <b>154</b>, and the like.</p>
<p id="p-0056" num="0055">The display unit <b>151</b> may display(output) information processed in the mobile terminal <b>100</b>. For example, when the mobile terminal <b>100</b> is in a phone call mode, the display unit <b>151</b> may display a User Interface (UI) or a Graphic User Interface (GUI) associated with a call. When the mobile terminal <b>100</b> is in a video call mode or image capturing mode, the display unit <b>151</b> may display a captured image and/or received image, a UI or GUI.</p>
<p id="p-0057" num="0056">The display unit <b>151</b> may include at least one of a Liquid Crystal Display (LCD), a Thin Film Transistor-LCD (TFT-LCD), an Organic Light Emitting Diode (OLED) display, a flexible display, a three-dimensional (3D) display.</p>
<p id="p-0058" num="0057">Some of those displays may be configured with a transparent or optical transparent type to allow viewing of the exterior through the display unit, which may be called transparent displays. An example of the typical transparent displays may include a transparent LCD (TOLED), and the like. Under this configuration, a user can view an object positioned at a rear side of a terminal body through a region occupied by the display unit <b>151</b> of the terminal body.</p>
<p id="p-0059" num="0058">The display unit <b>151</b> may be implemented in two or more in number according to a configured aspect of the portable terminal <b>100</b>. For instance, a plurality of the display units <b>151</b> may be arranged on one surface to be spaced apart from or integrated with each other, or may be arranged on different surfaces.</p>
<p id="p-0060" num="0059">Here, if the display unit <b>151</b> and a touch sensitive sensor (referred to as a touch sensor) have a layered structure therebetween, the structure may be referred to as a touch screen. The display unit <b>151</b> may be used as an input device rather than an output device. The touch sensor may be implemented as a touch film, a touch sheet, a touch pad, and the like.</p>
<p id="p-0061" num="0060">The touch sensor may be configured to convert changes of a pressure applied to a specific part of the display unit <b>151</b>, or a capacitance occurring from a specific part of the display unit <b>151</b>, into electric input signals. Also, the touch sensor may be configured to sense not only a touched position and a touched area, but also a touch pressure.</p>
<p id="p-0062" num="0061">When touch inputs are sensed by the touch sensors, corresponding signals are transmitted to a touch controller (not shown). The touch controller processes the received signals, and then transmits corresponding data to the controller <b>180</b>. Accordingly, the controller <b>180</b> may sense which region of the display unit <b>151</b> has been touched.</p>
<p id="p-0063" num="0062">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, a proximity sensor <b>141</b> may be arranged at an inner region of the portable terminal <b>100</b> covered by the touch screen, or near the touch screen. The proximity sensor indicates a sensor to sense presence or absence of an object approaching to a surface to be sensed, or an object disposed near a surface to be sensed, by using an electromagnetic field or infrared rays without a mechanical contact. The proximity sensor has a longer lifespan and a more enhanced utility than a contact sensor.</p>
<p id="p-0064" num="0063">The proximity sensor may include an optical transmission type photoelectric sensor, a direct reflective type photoelectric sensor, a mirror reflective type photoelectric sensor, a high-frequency oscillation proximity sensor, a capacitance type proximity sensor, a magnetic type proximity sensor, an infrared rays proximity sensor, and so on. When the touch screen is implemented as a capacitance type, proximity of a pointer to the touch screen is sensed by changes of an electromagnetic field. In this case, the touch screen (touch sensor) may be categorized into a proximity sensor.</p>
<p id="p-0065" num="0064">Hereinafter, for the sake of convenience of brief explanation, a status that the pointer is positioned to be proximate onto the touch screen without contact will be referred to as &#x201c;proximity touch&#x201d;, whereas a status that the pointer substantially comes in contact with the touch screen will be referred to as &#x201c;contact touch&#x201d;. For the position corresponding to the proximity touch of the pointer on the touch screen, such position corresponds to a position where the pointer faces perpendicular to the touch screen upon the proximity touch of the pointer.</p>
<p id="p-0066" num="0065">The proximity sensor senses proximity touch, and proximity touch patterns (e.g., distance, direction, speed, time, position, moving status, etc.). Information relating to the sensed proximity touch and the sensed proximity touch patterns may be output onto the touch screen.</p>
<p id="p-0067" num="0066">The audio output module <b>152</b> may output audio data received from the wireless communication unit <b>110</b> or stored in the memory <b>160</b>, in a call-receiving mode, a call-placing mode, a recording mode, a voice recognition mode, a broadcast reception mode, and so on. The audio output module <b>152</b> may output audio signals relating to functions performed in the portable terminal <b>100</b>, e.g., sound alarming a call received or a message received, and so on. The audio output module <b>152</b> may include a receiver, a speaker, a buzzer, and so on.</p>
<p id="p-0068" num="0067">The alarm <b>153</b> outputs signals notifying occurrence of events from the portable terminal <b>100</b>. The events occurring from the portable terminal <b>100</b> may include call received, message received, key signal input, touch input, and so on. The alarm <b>153</b> may output not only video or audio signals, but also other types of signals such as signals notifying occurrence of events in a vibration manner. Since the video or audio signals can be output through the display unit <b>151</b> or the audio output unit <b>152</b>, the display unit <b>151</b> and the audio output module <b>152</b> may be categorized into a part of the alarm <b>153</b>.</p>
<p id="p-0069" num="0068">The haptic module <b>154</b> generates various tactile effects which a user can feel. A representative example of the tactile effects generated by the haptic module <b>154</b> includes vibration. Vibration generated by the haptic module <b>154</b> may have a controllable intensity, a controllable pattern, and so on. For instance, different vibration may be output in a synthesized manner or in a sequential manner.</p>
<p id="p-0070" num="0069">The haptic module <b>154</b> may generate various tactile effects, including not only vibration, but also arrangement of pins vertically moving with respect to a skin being touched (contacted), air injection force or air suction force through an injection hole or a suction hole, touch by a skin surface, presence or absence of contact with an electrode, effects by stimulus such as an electrostatic force, reproduction of cold or hot feeling using a heat absorbing device or a heat emitting device, and the like.</p>
<p id="p-0071" num="0070">The haptic module <b>154</b> may be configured to transmit tactile effects (signals) through a user's direct contact, or a user's muscular sense using a finger or a hand. The haptic module <b>154</b> may be implemented in two or more in number according to the configuration of the portable terminal <b>100</b>.</p>
<p id="p-0072" num="0071">The memory <b>160</b> may store a program for the processing and control of the controller <b>180</b>. Alternatively, the memory <b>160</b> may temporarily store input/output data (e.g., phonebook data, messages, still images, video and the like). Also, the memory <b>160</b> may store data related to various patterns of vibrations and audio output upon the touch input on the touch screen.</p>
<p id="p-0073" num="0072">The memory <b>160</b> may be implemented using any type of suitable storage medium including a flash memory type, a hard disk type, a multimedia card micro type, a memory card type (e.g., SD or DX memory), Random Access Memory (RAM), Static Random Access Memory (SRAM), Read-Only Memory (ROM), Electrically Erasable Programmable Read-only Memory (EEPROM), Programmable Read-only Memory (PROM), magnetic memory, magnetic disk, optical disk, and the like. Also, the mobile terminal <b>100</b> may operate a web storage which performs the storage function of the memory <b>160</b> on the Internet.</p>
<p id="p-0074" num="0073">The interface unit <b>170</b> may generally be implemented to interface the portable terminal with external devices. The interface unit <b>170</b> may allow a data reception from an external device, a power delivery to each component in the portable terminal <b>100</b>, or a data transmission from the portable terminal <b>100</b> to an external device. The interface unit <b>170</b> may include, for example, wired/wireless headset ports, external charger ports, wired/wireless data ports, memory card ports, ports for coupling devices having an identification module, audio Input/Output (I/O) ports, video I/O ports, earphone ports, and the like.</p>
<p id="p-0075" num="0074">The identification module may be configured as a chip for storing various information required to authenticate an authority to use the portable terminal <b>100</b>, which may include a User Identity Module (UIM), a Subscriber Identity Module (SIM), and the like. Also, the device having the identification module (hereinafter, referred to as &#x2018;identification device&#x2019;) may be implemented in a type of smart card. Hence, the identification device can be coupled to the portable terminal <b>100</b> via a port.</p>
<p id="p-0076" num="0075">The interface unit may serve as a path for power to be supplied from an external cradle to the portable terminal <b>100</b> when the portable terminal <b>100</b> is connected to the external cradle or as a path for transferring various command signals inputted from the cradle by a user to the portable terminal <b>100</b>. Such various command signals or power inputted from the cradle may operate as signals for recognizing that the portable terminal <b>100</b> has accurately been mounted to the cradle.</p>
<p id="p-0077" num="0076">The controller <b>180</b> typically controls the overall operations of the portable terminal <b>100</b>. For example, the controller <b>180</b> performs the control and processing associated with telephony calls, data communications, video calls, and the like. The controller <b>180</b> may include a multimedia module <b>181</b> which provides multimedia playback. The multimedia module <b>181</b> may be configured as part of the controller <b>180</b> or as a separate component.</p>
<p id="p-0078" num="0077">The controller <b>180</b> can perform a pattern recognition processing so as to recognize writing or drawing input on the touch screen as text or image.</p>
<p id="p-0079" num="0078">The power supply unit <b>190</b> provides power required by various components under the control of the controller <b>180</b>. The provided power may be internal power, external power, or combination thereof.</p>
<p id="p-0080" num="0079">Various embodiments described herein may be implemented in a computer-readable medium using, for example, software, hardware, or some combination thereof.</p>
<p id="p-0081" num="0080">For a hardware implementation, the embodiments described herein may be implemented within one or more of Application Specific Integrated Circuits (ASICs), Digital Signal Processors (DSPs), Digital Signal Processing Devices (DSPDs), Programmable Logic Devices (PLDs), Field Programmable Gate Arrays (FPGAs), processors, controllers, micro-controllers, micro processors, other electronic units designed to perform the functions described herein, or a selective combination thereof. In some cases, such embodiments are implemented by the controller <b>180</b>.</p>
<p id="p-0082" num="0081">For a software implementation, the embodiments such as procedures and functions may be implemented together with separate software modules each of which performs at least one of functions and operations. The software codes can be implemented with a software application written in any suitable programming language. Also, the software codes may be stored in the memory <b>160</b> and executed by the controller <b>180</b>.</p>
<p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. 2</figref><i>a </i>is a front perspective view illustrating an example of a mobile terminal or portable terminal associated with the present invention.</p>
<p id="p-0084" num="0083">The portable terminal <b>100</b> disclosed herein is provided with a bar-type terminal body. However, the present invention is not only limited to this type of terminal, but also applicable to various structures of terminals such as slide type, folder type, swivel type, swing type, and the like, in which two and more bodies are combined with each other in a relatively movable manner.</p>
<p id="p-0085" num="0084">The terminal body includes a case (casing, housing, cover, etc.) forming an appearance of the terminal. Various electronic components are built in a space formed between the front case <b>101</b> and the rear case <b>102</b>. In this embodiment, the case may be divided into a front case <b>101</b> and a rear case <b>102</b>. At least one middle case may be additionally disposed between the front case <b>101</b> and the rear case <b>102</b>.</p>
<p id="p-0086" num="0085">The cases may be formed by injection-molding a synthetic resin or may be also formed of a metal material such as stainless steel (STS), titanium (Ti), or the like.</p>
<p id="p-0087" num="0086">A display unit <b>151</b>, an audio output module <b>152</b>, a camera <b>121</b>, a user input unit <b>130</b>/<b>131</b>, <b>132</b>, a microphone <b>122</b>, an interface <b>170</b>, and the like may be arranged on the terminal body, mainly on the front case <b>101</b>.</p>
<p id="p-0088" num="0087">The display unit <b>151</b> occupies a most portion of the front case <b>101</b>. The audio output unit <b>152</b> and the camera <b>121</b> are disposed on a region adjacent to one of both ends of the display unit <b>151</b>, and the user input unit <b>131</b> and the microphone <b>122</b> are disposed on a region adjacent to the other end thereof. The user interface <b>132</b> and the interface <b>170</b>, and the like, may be disposed on a lateral surface of the front case <b>101</b> and the rear case <b>102</b>.</p>
<p id="p-0089" num="0088">The user input unit <b>130</b> is manipulated to receive a command for controlling the operation of the portable terminal <b>100</b>, and may include a plurality of manipulation units <b>131</b>, <b>132</b>. The manipulation units <b>131</b>, <b>132</b> may be commonly designated as a manipulating portion, and any method may be employed if it is a tactile manner allowing the user to perform manipulation with a tactile feeling.</p>
<p id="p-0090" num="0089">The content inputted by the manipulation units <b>131</b>, <b>132</b> may be set in various ways. For example, the first manipulation unit <b>131</b> may be used to receive a command, such as start, end, scroll, 3D browser execution, or the like, and the second manipulation unit <b>132</b> may be used to receive a command, such as controlling a volume level being outputted from the audio output unit <b>152</b>, or switching it into a touch recognition mode of the display unit <b>151</b>.</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 2</figref><i>b </i>is a rear perspective view illustrating a portable terminal of <figref idref="DRAWINGS">FIG. 2</figref><i>a. </i></p>
<p id="p-0092" num="0091">Referring to <figref idref="DRAWINGS">FIG. 2</figref><i>b</i>, a camera <b>121</b>&#x2032; may be additionally mounted on a rear surface of the terminal body, namely, the rear case <b>102</b>. The camera <b>121</b>&#x2032; has an image capturing direction, which is substantially opposite to the direction of the camera <b>121</b> (refer to <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>), and may have different pixels from those of the first video input unit <b>121</b>.</p>
<p id="p-0093" num="0092">For example, it is preferable that the camera <b>121</b> has a relatively small number of pixels enough not to cause a difficulty when the user captures his or her own face and sends it to the other party during a video call or the like, and the camera <b>121</b>&#x2032; has a relatively large number of pixels since the user often captures a general object that is not sent immediately. The cameras <b>121</b>, <b>121</b>&#x2032; may be provided in the terminal body in a rotatable and popupable manner.</p>
<p id="p-0094" num="0093">Furthermore, a flash <b>123</b> and a mirror <b>124</b> may be additionally disposed adjacent to the camera <b>121</b>&#x2032;. The flash <b>123</b> illuminates light toward an object when capturing the object with the camera <b>121</b>&#x2032;. The mirror <b>124</b> allows the user to look at his or her own face, or the like, in a reflected way when capturing himself or herself (in a self-portrait mode) by using the camera <b>121</b>&#x2032;.</p>
<p id="p-0095" num="0094">Furthermore, an audio output unit <b>152</b>&#x2032; may be additionally disposed on a rear surface of the terminal body. The audio output unit <b>152</b>&#x2032; together with the audio output unit <b>152</b> (refer to <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>) can implement a stereo function, and it may be also used to implement a speaker phone mode during a phone call.</p>
<p id="p-0096" num="0095">Furthermore, an antenna <b>116</b> for receiving broadcast signals may be additionally disposed on a lateral surface of the terminal body. The antenna <b>116</b> constituting a broadcast receiving module <b>111</b> (refer to <figref idref="DRAWINGS">FIG. 1</figref>) may be provided so as to be pulled out from the terminal body.</p>
<p id="p-0097" num="0096">Furthermore, a power supply unit <b>190</b> for supplying power to the portable terminal <b>100</b> may be mounted on a rear surface of the terminal body. The power supply unit <b>190</b> may be configured so as to be incorporated in the terminal body, or directly detachable from the outside of the terminal body.</p>
<p id="p-0098" num="0097">A touch pad <b>135</b> for detecting a touch may be additionally mounted on the rear case <b>102</b>. The touch pad <b>135</b> may be configured in an optical transmission type similarly to the display unit <b>151</b>. In this case, if the display unit <b>151</b> is configured to output visual information from both sides of the display unit <b>151</b>, then the visual information may be also recognized through the touch pad <b>135</b>. The information being outputted from the both sides thereof may be controlled by the touch pad <b>135</b>. In addition, a display may be additionally mounted on the touch pad <b>135</b>, and a touch screen may be also disposed on the rear case <b>102</b>.</p>
<p id="p-0099" num="0098">The touch pad <b>135</b> operates in a reciprocal relation to the display unit <b>151</b> of the front case <b>101</b>. The touch pad <b>135</b> may be disposed in parallel on a rear side of the display unit <b>151</b>. The touch pad <b>135</b> may have the same or a smaller size as or than that of the display unit <b>151</b>.</p>
<p id="p-0100" num="0099">Various kinds of visual information may be displayed on the display unit <b>151</b>. The visual information may be displayed in a form of characters, numerals, symbols, graphics, or icons. For an input of the visual information, at least one of the characters, numerals, symbols, graphics, or icons may be displayed with a predetermined arrangement so as to be implemented in a form of keypad. Such a keypad may be referred to as a so-called &#x201c;soft key.&#x201d;</p>
<p id="p-0101" num="0100">Hereinafter, preferred embodiments associated with a control method that can be implemented in a terminal having the foregoing configuration will be described with reference to the accompanying drawings. The following embodiments may be used alone or in combination with one another. Furthermore, the following embodiments may be used in combination with the foregoing user interface (UI).</p>
<p id="p-0102" num="0101"><figref idref="DRAWINGS">FIGS. 3</figref><i>a </i>and <b>3</b><i>b </i>are illustrative views for explaining a difference between a normal photo and a panorama photo.</p>
<p id="p-0103" num="0102">Typically, a lot of normal photos <b>211</b> have a rectangular form with a width-to-height ratio of about 4:3 such as the width-to-height length of 640*480 pixels, or a rectangular form with a width-to-height ratio of about 3:4 such as the width-to-height length of 480*640 pixels. Furthermore, a lot of panorama photos <b>213</b> have a form in which the length of either one side of the width and height is several times longer than the length of the other side.</p>
<p id="p-0104" num="0103">The panorama photo is a photo that is captured while rotating a camera to the left or right by a desired angle at a state of being fixed to a certain axis. At this time, in typical cases, the rotating surface is a horizontal direction, but it does not make a difference even if the rotating surface is a vertical or oblique direction.</p>
<p id="p-0105" num="0104">Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. 3</figref><i>b</i>, the panorama photo may be immediately captured by using a dedicated camera <b>214</b> but it may be also captured by using a general camera. In the latter case, several copies of photos <b>212</b> are continuously captured by rotating the camera such that some regions are duplicated (for example, 30%) and then the duplicated potions are connected with one another to be converted into a panorama form. In recent years, a lot of 360&#xb0; or 180&#xb0; panorama photos are also captured. The 360&#xb0; panorama photo is a photo in which the capture starting and ending portions are made to be same.</p>
<p id="p-0106" num="0105"><figref idref="DRAWINGS">FIGS. 4</figref><i>a </i>and <b>4</b><i>b </i>are illustrative views for explaining an advantage of an image display method associated with the present invention.</p>
<p id="p-0107" num="0106">As described above, a panorama photo has a feature capable of providing a widely spread-out screen that cannot be obtained by a conventional camera. However, the feature may be an advantage when the panorama photo is printed on a paper but the feature may be also a disadvantage when it is displayed on a fixed-sized screen.</p>
<p id="p-0108" num="0107">In other words, as illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>a</i>, for a normal photo <b>211</b>, the width-to-height ratio is substantially similar to a screen aspect ratio and thus it may be displayed on an entire screen. However, for a panorama photo <b>221</b>, the width-to-height ratio is greatly different from a screen aspect ratio and thus it may be difficult to see the photo, because the size thereof becomes smaller to display the panorama photo as a whole on the screen.</p>
<p id="p-0109" num="0108">For example, assuming that a panorama photo having a long horizontal length is displayed on a screen, the horizontal length <b>222</b> of the panorama photo should be adjusted to a width <b>223</b> of the screen and displayed like a flat sticker shape <b>224</b> to display the panorama photo <b>221</b> as a whole on the screen while maintaining the same width-to-height ratio. Accordingly, a vertical length of the panorama photo <b>221</b> is necessarily required to be reduced to be displayed. In other words, since a width of the screen is fixed, the larger the horizontal length of the panorama photo, the smaller the vertical length thereof, and thus the photo is reduced to be displayed. On the contrary, the smaller the horizontal length thereof, the larger the vertical length thereof, and thus the photo is enlarged to be displayed.</p>
<p id="p-0110" num="0109">As a result, according to the present invention, there is provided a method of displaying the panorama photo as a whole while the horizontal length thereof being reduced, thereby resulting in displaying the panorama photo as enlarged as possible. In other words, as illustrated in <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>, when the panorama photo <b>221</b> is displayed in a particular object shape (for example, circular band) (see <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>) the vertical length is elongated compared to when displayed in a sticker shape on the same-sized display unit <b>151</b> (see <figref idref="DRAWINGS">FIG. 4</figref><i>a</i>), and thus it may be possible to display a more enlarged photo.</p>
<p id="p-0111" num="0110">As described above, according to the present invention, a panorama photo is changed into a particular object shape (for example, circular band, polygonal band, cylindrical, spherical, spiral, or wave-shaped band). When a panorama photo is changed into a particular object shape in this manner, one side length (for example, horizontal length) of the panorama photo is reduced by at least a particular ratio (for example, 1/2), and accordingly, it may be possible to increase a vertical length of the image being displayed as an object shape. In other words, the panorama photo is more enlarged to be displayed.</p>
<p id="p-0112" num="0111">When a panorama photo is displayed in an object shape in which both outer and inner sides (or front and rear surfaces) thereof are simultaneously viewed like a circular band <b>225</b> as described above, the controller <b>180</b> can reverse an image that is seen from the inner side <b>226</b> or outer side <b>227</b> to display the reversed image. In other words, the image display direction may be switched and displayed to a direction that can be conveniently seen by the user.</p>
<p id="p-0113" num="0112">In this manner, according to the present invention, there is provided an effect of allowing the user to view a more enlarged panorama photo than a conventional panorama photo that has been displayed in a flat sticker shape, as well as to view the panorama photo in three-dimension.</p>
<p id="p-0114" num="0113"><figref idref="DRAWINGS">FIG. 5</figref> is an illustrative view for explaining a method of displaying a panorama photo selected in a mobile terminal associated with the present invention.</p>
<p id="p-0115" num="0114">When a photo album menu is implemented by the user, the controller <b>180</b> displays a photo list <b>231</b>. The photo list may be displayed with a preview form or file names. Moreover, the information (not shown) for determining whether it is a normal or panorama photo may be additionally displayed, and the normal and panorama photos are classified to be displayed in different regions (not shown).</p>
<p id="p-0116" num="0115">The user may select his or her desired photo from the photo list to display on an entire screen, and at this time, it may be displayed in a particular preset object shape <b>232</b> when the selected photo is a panorama photo. In other words, the panorama photo is displayed as a plane such as sticker in the related art while the panorama photo is displayed as a three-dimensional object shape in the present invention.</p>
<p id="p-0117" num="0116"><figref idref="DRAWINGS">FIG. 6</figref> is an illustrative view illustrating objects displayed with a panorama photo in a mobile terminal associated with the present invention.</p>
<p id="p-0118" num="0117">The objects may be constructed in the shape of a band that can be easily seen by the user in which an entire image can be displayed at the outer and inner sides (or front and rear surfaces) of the object even if the shape of the objects is folded, turned over, rotated, or moved.</p>
<p id="p-0119" num="0118">For example, the band shape may be constructed with a band having a curved shape such as a circular band shape <b>241</b> with no edge, a polygonal band shape <b>242</b> with edges, a spiral shape <b>243</b>, or a sine wave shape <b>244</b> (for example, wave-shaped band). The foregoing three-dimensional shapes allow the user to use a screen size to the maximum extent, thereby displaying a more enlarged photo.</p>
<p id="p-0120" num="0119">At this time, the height (or depth) of the object can be varied according to the length of the panorama photo. For example, the object may be changed from a circular band shape to a cylindrical shape <b>245</b> if the height (or depth) of the object is increased.</p>
<p id="p-0121" num="0120">On the other hand, when a panorama photo is three-dimensionally displayed as described above, an image displayed at the front surface thereof will be easily seen to the user while an image displayed on the rear surface thereof will be hided by the front surface image not to be easily seen to the user. In particular, when the height of the object is long such as a cylindrical shape, the rear surface image will be hided by the front surface image not to be easily seen because a portion being overlapped with the front and rear surface images is increased.</p>
<p id="p-0122" num="0121">As a result, according to the present invention, a panorama photo displayed in three dimension can be rotated in a particular direction (for example, upward, downward, left, and right). The rotation direction may be indicated by the user or automatically indicated according to a particular preset condition. Furthermore, when rotating the panorama photo, the rotation speed may be indicated by the user or automatically indicated according to a particular preset condition.</p>
<p id="p-0123" num="0122"><figref idref="DRAWINGS">FIG. 7</figref> is an illustrative view for explaining a method of displaying a panorama photo in such a manner that the photo is captured by the user according to the present invention.</p>
<p id="p-0124" num="0123">The manner that the photo is captured by the user is a manner in which a capture angle of the camera when the photo is captured by the user, and a moving direction or flow while being continuously captured are considered. According to the present invention, a panorama image may be constructed to be displayed with the same angle or path (for example, the orientation to which the camera faces when captured) as the manner that the photo is captured by the user.</p>
<p id="p-0125" num="0124">In other words, if capturing a photo is started by the user (S<b>101</b>), then the controller <b>180</b> detects a capture angle and a capture path (S<b>102</b>). Then, the information associated with the capture angle or path is added to the photo (S<b>103</b>). The capturing a photo is continuously carried out, and if the capturing is completed and then converted into a panorama photo (an example of S<b>104</b>), then the controller <b>180</b> estimates the information (for example, capture angle, capture path, image-overlapped region) added to the photo (S<b>105</b>), and displays a panorama photo using the information (S<b>106</b>).</p>
<p id="p-0126" num="0125">For example, when images are continuously captured by the user while moving a camera of the mobile terminal in a wave shape, the controller <b>180</b> can display a panorama photo in the wave shape using the continuously captured photos. Furthermore, when images are continuously captured by the user while moving a capture path in an oblique line, the controller <b>180</b> can display a panorama photo in the oblique line direction using the continuously captured photos.</p>
<p id="p-0127" num="0126">Accordingly, in addition to the aforementioned shapes, various shapes of panorama photos can be captured according to the user's capture method. Here, the user's capture path can be estimated by using an overlapped portion on the continuously captured photos, but an orientation detection sensor (not shown) and a tilt sensor (not shown) are provided and their sensed information may be additionally used to trace a more accurate path.</p>
<p id="p-0128" num="0127">As described above, according to this embodiment, a panorama photo may be displayed in a desired shape using the user's capture method.</p>
<p id="p-0129" num="0128"><figref idref="DRAWINGS">FIGS. 8</figref><i>a </i>through <b>8</b><i>c </i>are illustrative views for explaining a method of rotating an image displayed on a mobile terminal associated with the present invention according to a particular condition.</p>
<p id="p-0130" num="0129">As illustrated in <figref idref="DRAWINGS">FIG. 8</figref><i>a</i>, it is assumed that any image (for example, panorama photo) is displayed in a particular object shape (for example, band shape) <b>241</b> on the display unit <b>151</b>. Accordingly, the controller <b>180</b> checks time to automatically rotate the image with a particular time interval. The direction for rotating the image may be clockwise or counter clockwise around the A-axis. Otherwise, it may be rotated in an upward or downward direction around the B-axis. As described above, the image can be rotated, thereby allowing the user to see the image on the front or rear surfaces of the particular object.</p>
<p id="p-0131" num="0130">Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. 8</figref><i>b</i>, the controller <b>180</b> can detect a direction (or orientation) faced by a particular surface of the mobile terminal (for example, a surface faced by the camera, or a surface faced by the display), thereby rotating the image to correspond to the direction.</p>
<p id="p-0132" num="0131">For example, as illustrated in <figref idref="DRAWINGS">FIG. 8</figref><i>b </i>(<i>a</i>), if a particular surface of the mobile terminal faces the south (S), then the controller <b>180</b> rotates the image to coincide a portion corresponding to the south with the direction faced by the particular surface. Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. 8</figref><i>b </i>(<i>a</i>), if a particular surface of the mobile terminal faces the north (N), then the controller <b>180</b> rotates the image to coincide a portion corresponding to the north with the direction faced by the particular surface.</p>
<p id="p-0133" num="0132">Here, the image may correspond to every direction (for example, 360&#xb0;). Accordingly, an image can be rotated to correspond to every direction that is faced by the mobile terminal. As a result, if the direction that is faced by the mobile terminal is continuously changed, then the image may be also continuously rotated to correspond to the changed direction.</p>
<p id="p-0134" num="0133">Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. 8</figref><i>c</i>, the controller <b>180</b> can detect the user's touch and flicking to rotate the image in the flicking direction. For example, when the user touches the image and then flicks to one side direction (for example, upward, downward, left, and right), the controller <b>180</b> can rotate fast or slowly at a particular speed (for example, flicked speed) to correspond to the flicked direction. In other words, it may be rotated fast if the flicking speed is fast, and it may be rotated slowly if the flicking speed is slow. On the other hand, in the above embodiment, the rotation direction is not only limited to the left or right, but may be also rotated in a upward or downward direction.</p>
<p id="p-0135" num="0134"><figref idref="DRAWINGS">FIGS. 9</figref><i>a </i>through <b>9</b><i>c </i>are illustrative views for explaining a method of suspending an image to be rotated on a mobile terminal associated with the present invention according to a particular condition.</p>
<p id="p-0136" num="0135">As described above, according to the present invention, an image may be three-dimensionally displayed by using a particular object shape, and also an object being displayed with the image may be rotated in a particular direction. The foregoing image to be rotated may be automatically or manually suspended.</p>
<p id="p-0137" num="0136">For example, when an image displayed with an object shape is manually rotated by the user's flicking as described above, as illustrated in <figref idref="DRAWINGS">FIG. 9</figref><i>a</i>, the controller <b>180</b> can strongly rotate the image being displayed with an object shape at first, and then decrease the rotation speed to a predetermined speed as time passes, and then automatically suspend the rotation at last.</p>
<p id="p-0138" num="0137">Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. 9</figref><i>b</i>, when an image displayed with an object shape is automatically rotated, if the user touches any position of the image or screen while the user's desired portion is displayed on the image being rotated, then the controller <b>180</b> will suspend the rotation of the image. In addition, if any position of the image or screen is touched once more, or the touch is released, then the controller <b>180</b> will rotate the suspended image again. Furthermore, if the user drags the image in a particular direction in a state that the rotation of the image is suspended, namely, touched, then the controller <b>180</b> can rotate or move the object by a particular angle at his or her discretion.</p>
<p id="p-0139" num="0138">Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. 9</figref><i>c</i>, if a desired portion is long-touched or double-touched on the image by the user, then the controller <b>180</b> will display an image around the touched portion on an entire screen. Furthermore, if any portion of the image displayed on the entire screen is touched, long-touched, or double-touched, then the image displayed on the entire screen will be displayed again as the original object shape.</p>
<p id="p-0140" num="0139"><figref idref="DRAWINGS">FIGS. 10</figref><i>a </i>and <b>10</b><i>b </i>are illustrative views for explaining a method of changing the shape of an image displayed on a mobile terminal associated with the present invention.</p>
<p id="p-0141" num="0140">As described above, it is assumed that any image (for example, panorama photo) is displayed in a particular object shape (for example, band shape) on the display unit <b>151</b>. Furthermore, the controller <b>180</b> can detect a multi-touch being inputted on the display unit <b>151</b>.</p>
<p id="p-0142" num="0141">The user can change an area or size of the object by inputting a multi-touch.</p>
<p id="p-0143" num="0142">For example, as illustrated in <figref idref="DRAWINGS">FIG. 10</figref><i>a</i>, if two positions (for example, top and bottom sides) are multi-touched in one side (for example, left or right side) of the object displayed with the image, and then an interval of the multi-touch is widened, then the controller <b>180</b> widens the top/bottom side length of the object (for example, L&#x2192;2L). On the contrary, in case of narrowing an interval of the multi-touch, the top/bottom side length of the object will be reduced. At this time, two positions may be a point that is brought in contact with the image or located within a particular predetermined distance from the image.</p>
<p id="p-0144" num="0143">Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. 10</figref><i>b</i>, if two positions (for example, left right sides) are multi-touched in another one side (for example, top or bottom side) of the object, and then an interval of the multi-touch is narrowed, then the controller <b>180</b> narrows the left/right side length of the object (for example, W&#x2192;&#xbd;W). On the contrary, in case of widening an interval of the multi-touch, the left/right side length of the object will be increased. In other words, an area or size of the image displayed with an object shape will be enlarged or reduced.</p>
<p id="p-0145" num="0144"><figref idref="DRAWINGS">FIG. 11</figref> is an illustrative view for explaining a method of setting an image displayed with a particular object shape to a standby screen according to the present invention.</p>
<p id="p-0146" num="0145">According to the present invention, as described above, an image selected from a photo album is displayed in a particular object shape, and then the image that has been displayed in the particular object shape may be set to a standby screen. Here, it is assumed that the image is a panorama photo in which a surrounding scene is captured by rotating 360&#xb0;.</p>
<p id="p-0147" num="0146">Even if an image displayed in a particular object shape is set to a standby screen as described above, the options set for the image may be maintained as it is. Assuming that a rotation option is set for the image, the image will be rotated in the previously indicated direction at a predetermined speed even subsequent to being set to a standby screen.</p>
<p id="p-0148" num="0147">For example, assuming that the image is allowed to correspond to the rotation speed and direction of the earth, the controller <b>180</b> rotates the image such that a portion corresponding to the east (E) of the image is displayed at a front surface thereof at a particular time in the morning, and gradually rotates the image such that a portion corresponding to the south (S) of the image is displayed at the front surface thereof at a particular time at noon, and gradually rotates the image such that a portion corresponding to the west (W) of the image is displayed at the front surface thereof at a particular time in the evening, and gradually rotates the image such that a portion corresponding to the north (N) of the image is displayed at the front surface thereof at a particular time at midnight.</p>
<p id="p-0149" num="0148">According to this embodiment, an image set to a standby screen as described above may be rotated to correspond to time. The image may include orientation information for rotating the image to correspond to the rotation direction or speed (=time) of the earth as described above.</p>
<p id="p-0150" num="0149"><figref idref="DRAWINGS">FIGS. 12</figref><i>a </i>through <b>12</b><i>c </i>are illustrative views for explaining a method of additionally displaying supplementary information on an image displayed with a particular object shape according to the present invention.</p>
<p id="p-0151" num="0150">According to this embodiment, a photo that has been previously captured in a panorama form (panorama type) can be displayed in a particular object shape, and a photo in which a plurality of normal photos have been sequentially connected and converted into a panorama form can be also displayed in a particular object shape. For the sake of convenience, it is assumed that the object shape is a circular band shape in which the inside is vacant.</p>
<p id="p-0152" num="0151">As illustrated in <figref idref="DRAWINGS">FIG. 12</figref><i>a</i>, the controller <b>180</b> may display supplementary information (for example, clock, orientation information, portrait information) within the object (for example, circular band) according to the preset option. Furthermore, the supplementary information may be overlapped with the object to be displayed. Furthermore, any image of the supplementary information may be added to any one side of outer sides (for example, top, bottom, left, and right) of the object to be displayed.</p>
<p id="p-0153" num="0152">On the other hand, assuming that the panorama photo is a photo that is made by connecting portrait photos registered in a phone book, as illustrated in <figref idref="DRAWINGS">FIG. 12</figref><i>b</i>, the controller <b>180</b> can display supplementary information (for example, enlarged portrait image, or information registered in a phone book of the portrait) <b>252</b> associated with a particular portrait (for example, a portrait displayed at a front surface among the portraits included in the rotating circular band) <b>251</b> within the object from the supplementary information. Accordingly, if a portrait displayed at the front surface thereof is changed according to the rotation of the object, then the information being displayed at the inside thereof will be immediately changed.</p>
<p id="p-0154" num="0153">For another embodiment, as illustrated in <figref idref="DRAWINGS">FIG. 12</figref><i>c</i>, assuming that a multiplexed video phone conversation is performed by the user, the controller <b>180</b> can connect callers participating in the multiplexed video phone conversation to one another, and thus they are displayed in a circular band shape. Furthermore, the controller <b>180</b> can display any one <b>253</b> of the callers in an enlarged image <b>254</b> within the object (for example, circular band). Here, any one of the callers may be a caller who is currently speaking or the user himself or herself.</p>
<p id="p-0155" num="0154">Here, the controller <b>180</b> may display the supplementary information using an on-screen display (OSD) method, or display the supplementary information to be overlapped on an image displayed in the particular object shape using an overlay method.</p>
<p id="p-0156" num="0155"><figref idref="DRAWINGS">FIG. 13</figref> is an illustrative view for explaining a method of displaying user menus with a particular object shape according to the present invention.</p>
<p id="p-0157" num="0156">Typically, mobile terminals have a menu (for example, user menu) in which the menus primarily used by the user are separately collected. According to this embodiment, when the mobile terminal have user menus as described above, the controller <b>180</b> sequentially connects the menus to convert into a panorama form, and then displays them in a particular object shape (for example, circular band).</p>
<p id="p-0158" num="0157">For the sake of convenience, it is assumed that the object shape is a circular band shape.</p>
<p id="p-0159" num="0158">The user menus provided in a particular object shape as described above may be rotated at a particular speed in a particular direction similarly to the foregoing image. In other words, consecutively connected user menus are sequentially rotated. At this time, the menus displayed at a rear surface thereof may be displayed in an reversed form, or may be displayed in a non-reversed form.</p>
<p id="p-0160" num="0159">As described above, preferred embodiments of the present invention have been described with reference to the accompanying drawings.</p>
<p id="p-0161" num="0160">Here, the terms and words used herein and the claims should not be construed by limiting to their typical or lexical meaning, but should be construed based on the meaning and concept conforming to the technical spirit of the present invention.</p>
<p id="p-0162" num="0161">Accordingly, the configuration illustrated in the embodiments disclosed herein and the drawings is merely the most preferred embodiment of the present invention, and is not intended to represent all the technical spirit of the present invention, and thereby it should be appreciated that there may exist various equivalents and modifications for substituting those at the time of filing this application.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of controlling a mobile terminal, the method comprising:
<claim-text>displaying an image list;</claim-text>
<claim-text>receiving an input selecting a particular image from the image list;</claim-text>
<claim-text>converting an entire panorama of the selected image into a preset three-dimensional curved shape when the selected image is a panorama-type image;</claim-text>
<claim-text>displaying an image comprising the preset three-dimensional curved shape; and</claim-text>
<claim-text>changing a size or length of the preset three-dimensional curved shape in response to detecting at least one multi-touching input on the preset three-dimensional curved shape,</claim-text>
<claim-text>wherein the preset three-dimensional curved shape comprises a circular band, polygonal band, spiral shape, sine wave, spherical shape, or cylindrical shape.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>detecting whether an option associated with the display of the image is set;</claim-text>
<claim-text>detecting whether a condition corresponding to the option is satisfied if the option associated with the display of the image is set; and</claim-text>
<claim-text>applying the option to the preset three-dimensional curved shape if the condition corresponding to the set option is satisfied.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising continuously displaying the selected particular image on inner and outer sides of the preset three-dimensional curved shape.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the option comprises an option for rotating the image comprising the preset three-dimensional curved shape in a particular direction.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the option for rotating the image comprises an option for rotating the image comprising the preset three-dimensional curved shape at a particular time interval.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the option for rotating the image further comprises an option for rotating an image comprising a portion captured in a particular direction to which the mobile terminal faces to be oriented in the particular direction.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the option for rotating the image further comprises an option for detecting a user's touch and flicking to rotate the image in the flicking direction.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:
<claim-text>rotating the preset three-dimensional curved shape if the condition corresponding to the set option is satisfied;</claim-text>
<claim-text>suspending the rotation if a user's touch input is detected; and</claim-text>
<claim-text>re-starting the rotation according to the set option if the user's touch input is released.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>widening a length of one side of the preset three-dimensional curved shape when the at least one multi-touching input is detected on one side of the object and a spacing of the at least one multi-touching input is widened; and</claim-text>
<claim-text>narrowing the length of the one side of the preset three-dimensional curved shape when the at least one multi-touching input is detected on the one side of the object the spacing of the at least one multi-touching input is narrowed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the option comprises an option to display preset supplementary information overlapped on an inner side or an outer side of the image comprising the preset three-dimensional curved shape.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the present supplementary information comprises at least clock information, orientation information, phone conversation information, videophone conversation information, portrait information, phone book information, or a graphic image.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A mobile terminal, comprising:
<claim-text>a display unit;</claim-text>
<claim-text>a touch pad configured to receive an input selecting an image displayed on the display unit; and</claim-text>
<claim-text>a controller configured to:</claim-text>
<claim-text>determine a type of the selected image;</claim-text>
<claim-text>convert an entire panorama of the selected image into a preset three-dimensional curved shape and display the image comprising the preset three-dimensional curved shape when the image is a panorama-type image; and</claim-text>
<claim-text>change a size or length of the preset three-dimensional curved shape in response to detecting at least one multi-touching input on the preset three-dimensional curved shape,</claim-text>
<claim-text>wherein the preset three-dimensional curved shape comprises a circular band, polygonal band, spiral shape, sine wave, spherical shape, or cylindrical shape.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The mobile terminal of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the controller is further configured to apply an option associated with the display of the image to the preset three-dimensional curved shape when the option is set and a condition corresponding to the option is satisfied.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The mobile terminal of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the controller is further configured to rotate the image comprising the preset three-dimensional curved shape in a particular direction according to the set option.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The mobile terminal of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the controller is further configured to rotate the image comprising the preset three-dimensional curved shape at a particular time interval according to the set option.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The mobile terminal of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the controller is further configured to rotate an image comprising a portion captured in a particular direction to which the mobile terminal faces such that the image is oriented in the particular direction according to the set option.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The mobile terminal of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the controller is further configured to detect a user's touch and flicking to rotate the image in the flicking direction according to the set option.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The mobile terminal of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the controller is further configured to display preset supplementary information overlapped on an inner side or an outer side of the image comprising the preset three-dimensional curved shape according to the set option. </claim-text>
</claim>
</claims>
</us-patent-grant>
